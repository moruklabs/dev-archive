<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Sat, 09 Aug 2025 01:29:13 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>openai/openai-python</title>
      <link>https://github.com/openai/openai-python</link>
      <description>&lt;p&gt;The official Python library for the OpenAI API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenAI Python API library&lt;/h1&gt; 
&lt;!-- prettier-ignore --&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/openai/"&gt;&lt;img src="https://img.shields.io/pypi/v/openai.svg?label=pypi%20(stable)" alt="PyPI version"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The OpenAI Python library provides convenient access to the OpenAI REST API from any Python 3.8+ application. The library includes type definitions for all request params and response fields, and offers both synchronous and asynchronous clients powered by &lt;a href="https://github.com/encode/httpx"&gt;httpx&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;It is generated from our &lt;a href="https://github.com/openai/openai-openapi"&gt;OpenAPI specification&lt;/a&gt; with &lt;a href="https://stainlessapi.com/"&gt;Stainless&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The REST API documentation can be found on &lt;a href="https://platform.openai.com/docs/api-reference"&gt;platform.openai.com&lt;/a&gt;. The full API of this library can be found in &lt;a href="https://raw.githubusercontent.com/openai/openai-python/main/api.md"&gt;api.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# install from PyPI
pip install openai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;The full API of this library can be found in &lt;a href="https://raw.githubusercontent.com/openai/openai-python/main/api.md"&gt;api.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The primary API for interacting with OpenAI models is the &lt;a href="https://platform.openai.com/docs/api-reference/responses"&gt;Responses API&lt;/a&gt;. You can generate text from the model with the code below.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from openai import OpenAI

client = OpenAI(
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)

response = client.responses.create(
    model="gpt-4o",
    instructions="You are a coding assistant that talks like a pirate.",
    input="How do I check if a Python object is an instance of a class?",
)

print(response.output_text)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The previous standard (supported indefinitely) for generating text is the &lt;a href="https://platform.openai.com/docs/api-reference/chat"&gt;Chat Completions API&lt;/a&gt;. You can use that API to generate text from the model with the code below.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI()

completion = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "developer", "content": "Talk like a pirate."},
        {
            "role": "user",
            "content": "How do I check if a Python object is an instance of a class?",
        },
    ],
)

print(completion.choices[0].message.content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;While you can provide an &lt;code&gt;api_key&lt;/code&gt; keyword argument, we recommend using &lt;a href="https://pypi.org/project/python-dotenv/"&gt;python-dotenv&lt;/a&gt; to add &lt;code&gt;OPENAI_API_KEY="My API Key"&lt;/code&gt; to your &lt;code&gt;.env&lt;/code&gt; file so that your API key is not stored in source control. &lt;a href="https://platform.openai.com/settings/organization/api-keys"&gt;Get an API key here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Vision&lt;/h3&gt; 
&lt;p&gt;With an image URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;prompt = "What is in this image?"
img_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/2023_06_08_Raccoon1.jpg/1599px-2023_06_08_Raccoon1.jpg"

response = client.responses.create(
    model="gpt-4o-mini",
    input=[
        {
            "role": "user",
            "content": [
                {"type": "input_text", "text": prompt},
                {"type": "input_image", "image_url": f"{img_url}"},
            ],
        }
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With the image as a base64 encoded string:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import base64
from openai import OpenAI

client = OpenAI()

prompt = "What is in this image?"
with open("path/to/image.png", "rb") as image_file:
    b64_image = base64.b64encode(image_file.read()).decode("utf-8")

response = client.responses.create(
    model="gpt-4o-mini",
    input=[
        {
            "role": "user",
            "content": [
                {"type": "input_text", "text": prompt},
                {"type": "input_image", "image_url": f"data:image/png;base64,{b64_image}"},
            ],
        }
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Async usage&lt;/h2&gt; 
&lt;p&gt;Simply import &lt;code&gt;AsyncOpenAI&lt;/code&gt; instead of &lt;code&gt;OpenAI&lt;/code&gt; and use &lt;code&gt;await&lt;/code&gt; with each API call:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
import asyncio
from openai import AsyncOpenAI

client = AsyncOpenAI(
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)


async def main() -&amp;gt; None:
    response = await client.responses.create(
        model="gpt-4o", input="Explain disestablishmentarianism to a smart five year old."
    )
    print(response.output_text)


asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Functionality between the synchronous and asynchronous clients is otherwise identical.&lt;/p&gt; 
&lt;h3&gt;With aiohttp&lt;/h3&gt; 
&lt;p&gt;By default, the async client uses &lt;code&gt;httpx&lt;/code&gt; for HTTP requests. However, for improved concurrency performance you may also use &lt;code&gt;aiohttp&lt;/code&gt; as the HTTP backend.&lt;/p&gt; 
&lt;p&gt;You can enable this by installing &lt;code&gt;aiohttp&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# install from PyPI
pip install openai[aiohttp]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can enable it by instantiating the client with &lt;code&gt;http_client=DefaultAioHttpClient()&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from openai import DefaultAioHttpClient
from openai import AsyncOpenAI


async def main() -&amp;gt; None:
    async with AsyncOpenAI(
        api_key="My API Key",
        http_client=DefaultAioHttpClient(),
    ) as client:
        chat_completion = await client.chat.completions.create(
            messages=[
                {
                    "role": "user",
                    "content": "Say this is a test",
                }
            ],
            model="gpt-4o",
        )


asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Streaming responses&lt;/h2&gt; 
&lt;p&gt;We provide support for streaming responses using Server Side Events (SSE).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI()

stream = client.responses.create(
    model="gpt-4o",
    input="Write a one-sentence bedtime story about a unicorn.",
    stream=True,
)

for event in stream:
    print(event)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The async client uses the exact same interface.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from openai import AsyncOpenAI

client = AsyncOpenAI()


async def main():
    stream = await client.responses.create(
        model="gpt-4o",
        input="Write a one-sentence bedtime story about a unicorn.",
        stream=True,
    )

    async for event in stream:
        print(event)


asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Realtime API beta&lt;/h2&gt; 
&lt;p&gt;The Realtime API enables you to build low-latency, multi-modal conversational experiences. It currently supports text and audio as both input and output, as well as &lt;a href="https://platform.openai.com/docs/guides/function-calling"&gt;function calling&lt;/a&gt; through a WebSocket connection.&lt;/p&gt; 
&lt;p&gt;Under the hood the SDK uses the &lt;a href="https://websockets.readthedocs.io/en/stable/"&gt;&lt;code&gt;websockets&lt;/code&gt;&lt;/a&gt; library to manage connections.&lt;/p&gt; 
&lt;p&gt;The Realtime API works through a combination of client-sent events and server-sent events. Clients can send events to do things like update session configuration or send text and audio inputs. Server events confirm when audio responses have completed, or when a text response from the model has been received. A full event reference can be found &lt;a href="https://platform.openai.com/docs/api-reference/realtime-client-events"&gt;here&lt;/a&gt; and a guide can be found &lt;a href="https://platform.openai.com/docs/guides/realtime"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Basic text based example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import asyncio
from openai import AsyncOpenAI

async def main():
    client = AsyncOpenAI()

    async with client.beta.realtime.connect(model="gpt-4o-realtime-preview") as connection:
        await connection.session.update(session={'modalities': ['text']})

        await connection.conversation.item.create(
            item={
                "type": "message",
                "role": "user",
                "content": [{"type": "input_text", "text": "Say hello!"}],
            }
        )
        await connection.response.create()

        async for event in connection:
            if event.type == 'response.text.delta':
                print(event.delta, flush=True, end="")

            elif event.type == 'response.text.done':
                print()

            elif event.type == "response.done":
                break

asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;However the real magic of the Realtime API is handling audio inputs / outputs, see this example &lt;a href="https://github.com/openai/openai-python/raw/main/examples/realtime/push_to_talk_app.py"&gt;TUI script&lt;/a&gt; for a fully fledged example.&lt;/p&gt; 
&lt;h3&gt;Realtime error handling&lt;/h3&gt; 
&lt;p&gt;Whenever an error occurs, the Realtime API will send an &lt;a href="https://platform.openai.com/docs/guides/realtime-model-capabilities#error-handling"&gt;&lt;code&gt;error&lt;/code&gt; event&lt;/a&gt; and the connection will stay open and remain usable. This means you need to handle it yourself, as &lt;em&gt;no errors are raised directly&lt;/em&gt; by the SDK when an &lt;code&gt;error&lt;/code&gt; event comes in.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;client = AsyncOpenAI()

async with client.beta.realtime.connect(model="gpt-4o-realtime-preview") as connection:
    ...
    async for event in connection:
        if event.type == 'error':
            print(event.error.type)
            print(event.error.code)
            print(event.error.event_id)
            print(event.error.message)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using types&lt;/h2&gt; 
&lt;p&gt;Nested request parameters are &lt;a href="https://docs.python.org/3/library/typing.html#typing.TypedDict"&gt;TypedDicts&lt;/a&gt;. Responses are &lt;a href="https://docs.pydantic.dev"&gt;Pydantic models&lt;/a&gt; which also provide helper methods for things like:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Serializing back into JSON, &lt;code&gt;model.to_json()&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Converting to a dictionary, &lt;code&gt;model.to_dict()&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Typed requests and responses provide autocomplete and documentation within your editor. If you would like to see type errors in VS Code to help catch bugs earlier, set &lt;code&gt;python.analysis.typeCheckingMode&lt;/code&gt; to &lt;code&gt;basic&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Pagination&lt;/h2&gt; 
&lt;p&gt;List methods in the OpenAI API are paginated.&lt;/p&gt; 
&lt;p&gt;This library provides auto-paginating iterators with each list response, so you do not have to request successive pages manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI()

all_jobs = []
# Automatically fetches more pages as needed.
for job in client.fine_tuning.jobs.list(
    limit=20,
):
    # Do something with job here
    all_jobs.append(job)
print(all_jobs)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, asynchronously:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from openai import AsyncOpenAI

client = AsyncOpenAI()


async def main() -&amp;gt; None:
    all_jobs = []
    # Iterate through items across all pages, issuing requests as needed.
    async for job in client.fine_tuning.jobs.list(
        limit=20,
    ):
        all_jobs.append(job)
    print(all_jobs)


asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can use the &lt;code&gt;.has_next_page()&lt;/code&gt;, &lt;code&gt;.next_page_info()&lt;/code&gt;, or &lt;code&gt;.get_next_page()&lt;/code&gt; methods for more granular control working with pages:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;first_page = await client.fine_tuning.jobs.list(
    limit=20,
)
if first_page.has_next_page():
    print(f"will fetch next page using these details: {first_page.next_page_info()}")
    next_page = await first_page.get_next_page()
    print(f"number of items we just fetched: {len(next_page.data)}")

# Remove `await` for non-async usage.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or just work directly with the returned data:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;first_page = await client.fine_tuning.jobs.list(
    limit=20,
)

print(f"next page cursor: {first_page.after}")  # =&amp;gt; "next page cursor: ..."
for job in first_page.data:
    print(job.id)

# Remove `await` for non-async usage.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Nested params&lt;/h2&gt; 
&lt;p&gt;Nested parameters are dictionaries, typed using &lt;code&gt;TypedDict&lt;/code&gt;, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI()

response = client.chat.responses.create(
    input=[
        {
            "role": "user",
            "content": "How much ?",
        }
    ],
    model="gpt-4o",
    response_format={"type": "json_object"},
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;File uploads&lt;/h2&gt; 
&lt;p&gt;Request parameters that correspond to file uploads can be passed as &lt;code&gt;bytes&lt;/code&gt;, or a &lt;a href="https://docs.python.org/3/library/os.html#os.PathLike"&gt;&lt;code&gt;PathLike&lt;/code&gt;&lt;/a&gt; instance or a tuple of &lt;code&gt;(filename, contents, media type)&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from pathlib import Path
from openai import OpenAI

client = OpenAI()

client.files.create(
    file=Path("input.jsonl"),
    purpose="fine-tune",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The async client uses the exact same interface. If you pass a &lt;a href="https://docs.python.org/3/library/os.html#os.PathLike"&gt;&lt;code&gt;PathLike&lt;/code&gt;&lt;/a&gt; instance, the file contents will be read asynchronously automatically.&lt;/p&gt; 
&lt;h2&gt;Webhook Verification&lt;/h2&gt; 
&lt;p&gt;Verifying webhook signatures is &lt;em&gt;optional but encouraged&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;For more information about webhooks, see &lt;a href="https://platform.openai.com/docs/guides/webhooks"&gt;the API docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Parsing webhook payloads&lt;/h3&gt; 
&lt;p&gt;For most use cases, you will likely want to verify the webhook and parse the payload at the same time. To achieve this, we provide the method &lt;code&gt;client.webhooks.unwrap()&lt;/code&gt;, which parses a webhook request and verifies that it was sent by OpenAI. This method will raise an error if the signature is invalid.&lt;/p&gt; 
&lt;p&gt;Note that the &lt;code&gt;body&lt;/code&gt; parameter must be the raw JSON string sent from the server (do not parse it first). The &lt;code&gt;.unwrap()&lt;/code&gt; method will parse this JSON for you into an event object after verifying the webhook was sent from OpenAI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI
from flask import Flask, request

app = Flask(__name__)
client = OpenAI()  # OPENAI_WEBHOOK_SECRET environment variable is used by default


@app.route("/webhook", methods=["POST"])
def webhook():
    request_body = request.get_data(as_text=True)

    try:
        event = client.webhooks.unwrap(request_body, request.headers)

        if event.type == "response.completed":
            print("Response completed:", event.data)
        elif event.type == "response.failed":
            print("Response failed:", event.data)
        else:
            print("Unhandled event type:", event.type)

        return "ok"
    except Exception as e:
        print("Invalid signature:", e)
        return "Invalid signature", 400


if __name__ == "__main__":
    app.run(port=8000)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Verifying webhook payloads directly&lt;/h3&gt; 
&lt;p&gt;In some cases, you may want to verify the webhook separately from parsing the payload. If you prefer to handle these steps separately, we provide the method &lt;code&gt;client.webhooks.verify_signature()&lt;/code&gt; to &lt;em&gt;only verify&lt;/em&gt; the signature of a webhook request. Like &lt;code&gt;.unwrap()&lt;/code&gt;, this method will raise an error if the signature is invalid.&lt;/p&gt; 
&lt;p&gt;Note that the &lt;code&gt;body&lt;/code&gt; parameter must be the raw JSON string sent from the server (do not parse it first). You will then need to parse the body after verifying the signature.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import json
from openai import OpenAI
from flask import Flask, request

app = Flask(__name__)
client = OpenAI()  # OPENAI_WEBHOOK_SECRET environment variable is used by default


@app.route("/webhook", methods=["POST"])
def webhook():
    request_body = request.get_data(as_text=True)

    try:
        client.webhooks.verify_signature(request_body, request.headers)

        # Parse the body after verification
        event = json.loads(request_body)
        print("Verified event:", event)

        return "ok"
    except Exception as e:
        print("Invalid signature:", e)
        return "Invalid signature", 400


if __name__ == "__main__":
    app.run(port=8000)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Handling errors&lt;/h2&gt; 
&lt;p&gt;When the library is unable to connect to the API (for example, due to network connection problems or a timeout), a subclass of &lt;code&gt;openai.APIConnectionError&lt;/code&gt; is raised.&lt;/p&gt; 
&lt;p&gt;When the API returns a non-success status code (that is, 4xx or 5xx response), a subclass of &lt;code&gt;openai.APIStatusError&lt;/code&gt; is raised, containing &lt;code&gt;status_code&lt;/code&gt; and &lt;code&gt;response&lt;/code&gt; properties.&lt;/p&gt; 
&lt;p&gt;All errors inherit from &lt;code&gt;openai.APIError&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import openai
from openai import OpenAI

client = OpenAI()

try:
    client.fine_tuning.jobs.create(
        model="gpt-4o",
        training_file="file-abc123",
    )
except openai.APIConnectionError as e:
    print("The server could not be reached")
    print(e.__cause__)  # an underlying Exception, likely raised within httpx.
except openai.RateLimitError as e:
    print("A 429 status code was received; we should back off a bit.")
except openai.APIStatusError as e:
    print("Another non-200-range status code was received")
    print(e.status_code)
    print(e.response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Error codes are as follows:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Status Code&lt;/th&gt; 
   &lt;th&gt;Error Type&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;400&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;BadRequestError&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;401&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;AuthenticationError&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;403&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;PermissionDeniedError&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;404&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;NotFoundError&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;422&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;UnprocessableEntityError&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;429&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;RateLimitError&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;gt;=500&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;InternalServerError&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;APIConnectionError&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Request IDs&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For more information on debugging requests, see &lt;a href="https://platform.openai.com/docs/api-reference/debugging-requests"&gt;these docs&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;All object responses in the SDK provide a &lt;code&gt;_request_id&lt;/code&gt; property which is added from the &lt;code&gt;x-request-id&lt;/code&gt; response header so that you can quickly log failing requests and report them back to OpenAI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;response = await client.responses.create(
    model="gpt-4o-mini",
    input="Say 'this is a test'.",
)
print(response._request_id)  # req_123
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that unlike other properties that use an &lt;code&gt;_&lt;/code&gt; prefix, the &lt;code&gt;_request_id&lt;/code&gt; property &lt;em&gt;is&lt;/em&gt; public. Unless documented otherwise, &lt;em&gt;all&lt;/em&gt; other &lt;code&gt;_&lt;/code&gt; prefix properties, methods and modules are &lt;em&gt;private&lt;/em&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;br&gt; If you need to access request IDs for failed requests you must catch the &lt;code&gt;APIStatusError&lt;/code&gt; exception&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import openai

try:
    completion = await client.chat.completions.create(
        messages=[{"role": "user", "content": "Say this is a test"}], model="gpt-4"
    )
except openai.APIStatusError as exc:
    print(exc.request_id)  # req_123
    raise exc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Retries&lt;/h2&gt; 
&lt;p&gt;Certain errors are automatically retried 2 times by default, with a short exponential backoff. Connection errors (for example, due to a network connectivity problem), 408 Request Timeout, 409 Conflict, 429 Rate Limit, and &amp;gt;=500 Internal errors are all retried by default.&lt;/p&gt; 
&lt;p&gt;You can use the &lt;code&gt;max_retries&lt;/code&gt; option to configure or disable retry settings:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

# Configure the default for all requests:
client = OpenAI(
    # default is 2
    max_retries=0,
)

# Or, configure per-request:
client.with_options(max_retries=5).chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "How can I get the name of the current day in JavaScript?",
        }
    ],
    model="gpt-4o",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Timeouts&lt;/h2&gt; 
&lt;p&gt;By default requests time out after 10 minutes. You can configure this with a &lt;code&gt;timeout&lt;/code&gt; option, which accepts a float or an &lt;a href="https://www.python-httpx.org/advanced/timeouts/#fine-tuning-the-configuration"&gt;&lt;code&gt;httpx.Timeout&lt;/code&gt;&lt;/a&gt; object:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

# Configure the default for all requests:
client = OpenAI(
    # 20 seconds (default is 10 minutes)
    timeout=20.0,
)

# More granular control:
client = OpenAI(
    timeout=httpx.Timeout(60.0, read=5.0, write=10.0, connect=2.0),
)

# Override per-request:
client.with_options(timeout=5.0).chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "How can I list all files in a directory using Python?",
        }
    ],
    model="gpt-4o",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On timeout, an &lt;code&gt;APITimeoutError&lt;/code&gt; is thrown.&lt;/p&gt; 
&lt;p&gt;Note that requests that time out are &lt;a href="https://raw.githubusercontent.com/openai/openai-python/main/#retries"&gt;retried twice by default&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Advanced&lt;/h2&gt; 
&lt;h3&gt;Logging&lt;/h3&gt; 
&lt;p&gt;We use the standard library &lt;a href="https://docs.python.org/3/library/logging.html"&gt;&lt;code&gt;logging&lt;/code&gt;&lt;/a&gt; module.&lt;/p&gt; 
&lt;p&gt;You can enable logging by setting the environment variable &lt;code&gt;OPENAI_LOG&lt;/code&gt; to &lt;code&gt;info&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ export OPENAI_LOG=info
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or to &lt;code&gt;debug&lt;/code&gt; for more verbose logging.&lt;/p&gt; 
&lt;h3&gt;How to tell whether &lt;code&gt;None&lt;/code&gt; means &lt;code&gt;null&lt;/code&gt; or missing&lt;/h3&gt; 
&lt;p&gt;In an API response, a field may be explicitly &lt;code&gt;null&lt;/code&gt;, or missing entirely; in either case, its value is &lt;code&gt;None&lt;/code&gt; in this library. You can differentiate the two cases with &lt;code&gt;.model_fields_set&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;if response.my_field is None:
  if 'my_field' not in response.model_fields_set:
    print('Got json like {}, without a "my_field" key present at all.')
  else:
    print('Got json like {"my_field": null}.')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Accessing raw response data (e.g. headers)&lt;/h3&gt; 
&lt;p&gt;The "raw" Response object can be accessed by prefixing &lt;code&gt;.with_raw_response.&lt;/code&gt; to any HTTP method call, e.g.,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;from openai import OpenAI

client = OpenAI()
response = client.chat.completions.with_raw_response.create(
    messages=[{
        "role": "user",
        "content": "Say this is a test",
    }],
    model="gpt-4o",
)
print(response.headers.get('X-My-Header'))

completion = response.parse()  # get the object that `chat.completions.create()` would have returned
print(completion)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These methods return a &lt;a href="https://github.com/openai/openai-python/tree/main/src/openai/_legacy_response.py"&gt;&lt;code&gt;LegacyAPIResponse&lt;/code&gt;&lt;/a&gt; object. This is a legacy class as we're changing it slightly in the next major version.&lt;/p&gt; 
&lt;p&gt;For the sync client this will mostly be the same with the exception of &lt;code&gt;content&lt;/code&gt; &amp;amp; &lt;code&gt;text&lt;/code&gt; will be methods instead of properties. In the async client, all methods will be async.&lt;/p&gt; 
&lt;p&gt;A migration script will be provided &amp;amp; the migration in general should be smooth.&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;.with_streaming_response&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;The above interface eagerly reads the full response body when you make the request, which may not always be what you want.&lt;/p&gt; 
&lt;p&gt;To stream the response body, use &lt;code&gt;.with_streaming_response&lt;/code&gt; instead, which requires a context manager and only reads the response body once you call &lt;code&gt;.read()&lt;/code&gt;, &lt;code&gt;.text()&lt;/code&gt;, &lt;code&gt;.json()&lt;/code&gt;, &lt;code&gt;.iter_bytes()&lt;/code&gt;, &lt;code&gt;.iter_text()&lt;/code&gt;, &lt;code&gt;.iter_lines()&lt;/code&gt; or &lt;code&gt;.parse()&lt;/code&gt;. In the async client, these are async methods.&lt;/p&gt; 
&lt;p&gt;As such, &lt;code&gt;.with_streaming_response&lt;/code&gt; methods return a different &lt;a href="https://github.com/openai/openai-python/tree/main/src/openai/_response.py"&gt;&lt;code&gt;APIResponse&lt;/code&gt;&lt;/a&gt; object, and the async client returns an &lt;a href="https://github.com/openai/openai-python/tree/main/src/openai/_response.py"&gt;&lt;code&gt;AsyncAPIResponse&lt;/code&gt;&lt;/a&gt; object.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;with client.chat.completions.with_streaming_response.create(
    messages=[
        {
            "role": "user",
            "content": "Say this is a test",
        }
    ],
    model="gpt-4o",
) as response:
    print(response.headers.get("X-My-Header"))

    for line in response.iter_lines():
        print(line)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The context manager is required so that the response will reliably be closed.&lt;/p&gt; 
&lt;h3&gt;Making custom/undocumented requests&lt;/h3&gt; 
&lt;p&gt;This library is typed for convenient access to the documented API.&lt;/p&gt; 
&lt;p&gt;If you need to access undocumented endpoints, params, or response properties, the library can still be used.&lt;/p&gt; 
&lt;h4&gt;Undocumented endpoints&lt;/h4&gt; 
&lt;p&gt;To make requests to undocumented endpoints, you can make requests using &lt;code&gt;client.get&lt;/code&gt;, &lt;code&gt;client.post&lt;/code&gt;, and other http verbs. Options on the client will be respected (such as retries) when making this request.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import httpx

response = client.post(
    "/foo",
    cast_to=httpx.Response,
    body={"my_param": True},
)

print(response.headers.get("x-foo"))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Undocumented request params&lt;/h4&gt; 
&lt;p&gt;If you want to explicitly send an extra param, you can do so with the &lt;code&gt;extra_query&lt;/code&gt;, &lt;code&gt;extra_body&lt;/code&gt;, and &lt;code&gt;extra_headers&lt;/code&gt; request options.&lt;/p&gt; 
&lt;h4&gt;Undocumented response properties&lt;/h4&gt; 
&lt;p&gt;To access undocumented response properties, you can access the extra fields like &lt;code&gt;response.unknown_prop&lt;/code&gt;. You can also get all the extra fields on the Pydantic model as a dict with &lt;a href="https://docs.pydantic.dev/latest/api/base_model/#pydantic.BaseModel.model_extra"&gt;&lt;code&gt;response.model_extra&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Configuring the HTTP client&lt;/h3&gt; 
&lt;p&gt;You can directly override the &lt;a href="https://www.python-httpx.org/api/#client"&gt;httpx client&lt;/a&gt; to customize it for your use case, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for &lt;a href="https://www.python-httpx.org/advanced/proxies/"&gt;proxies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Custom &lt;a href="https://www.python-httpx.org/advanced/transports/"&gt;transports&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Additional &lt;a href="https://www.python-httpx.org/advanced/clients/"&gt;advanced&lt;/a&gt; functionality&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import httpx
from openai import OpenAI, DefaultHttpxClient

client = OpenAI(
    # Or use the `OPENAI_BASE_URL` env var
    base_url="http://my.test.server.example.com:8083/v1",
    http_client=DefaultHttpxClient(
        proxy="http://my.test.proxy.example.com",
        transport=httpx.HTTPTransport(local_address="0.0.0.0"),
    ),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also customize the client on a per-request basis by using &lt;code&gt;with_options()&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;client.with_options(http_client=DefaultHttpxClient(...))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Managing HTTP resources&lt;/h3&gt; 
&lt;p&gt;By default the library closes underlying HTTP connections whenever the client is &lt;a href="https://docs.python.org/3/reference/datamodel.html#object.__del__"&gt;garbage collected&lt;/a&gt;. You can manually close the client using the &lt;code&gt;.close()&lt;/code&gt; method if desired, or with a context manager that closes when exiting.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;from openai import OpenAI

with OpenAI() as client:
  # make requests here
  ...

# HTTP client is now closed
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Microsoft Azure OpenAI&lt;/h2&gt; 
&lt;p&gt;To use this library with &lt;a href="https://learn.microsoft.com/azure/ai-services/openai/overview"&gt;Azure OpenAI&lt;/a&gt;, use the &lt;code&gt;AzureOpenAI&lt;/code&gt; class instead of the &lt;code&gt;OpenAI&lt;/code&gt; class.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The Azure API shape differs from the core API shape which means that the static types for responses / params won't always be correct.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;from openai import AzureOpenAI

# gets the API Key from environment variable AZURE_OPENAI_API_KEY
client = AzureOpenAI(
    # https://learn.microsoft.com/azure/ai-services/openai/reference#rest-api-versioning
    api_version="2023-07-01-preview",
    # https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource
    azure_endpoint="https://example-endpoint.openai.azure.com",
)

completion = client.chat.completions.create(
    model="deployment-name",  # e.g. gpt-35-instant
    messages=[
        {
            "role": "user",
            "content": "How do I output all files in a directory using Python?",
        },
    ],
)
print(completion.to_json())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to the options provided in the base &lt;code&gt;OpenAI&lt;/code&gt; client, the following options are provided:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;azure_endpoint&lt;/code&gt; (or the &lt;code&gt;AZURE_OPENAI_ENDPOINT&lt;/code&gt; environment variable)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;azure_deployment&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;api_version&lt;/code&gt; (or the &lt;code&gt;OPENAI_API_VERSION&lt;/code&gt; environment variable)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;azure_ad_token&lt;/code&gt; (or the &lt;code&gt;AZURE_OPENAI_AD_TOKEN&lt;/code&gt; environment variable)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;azure_ad_token_provider&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;An example of using the client with Microsoft Entra ID (formerly known as Azure Active Directory) can be found &lt;a href="https://github.com/openai/openai-python/raw/main/examples/azure_ad.py"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Versioning&lt;/h2&gt; 
&lt;p&gt;This package generally follows &lt;a href="https://semver.org/spec/v2.0.0.html"&gt;SemVer&lt;/a&gt; conventions, though certain backwards-incompatible changes may be released as minor versions:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Changes that only affect static types, without breaking runtime behavior.&lt;/li&gt; 
 &lt;li&gt;Changes to library internals which are technically public but not intended or documented for external use. &lt;em&gt;(Please open a GitHub issue to let us know if you are relying on such internals.)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Changes that we do not expect to impact the vast majority of users in practice.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;We take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.&lt;/p&gt; 
&lt;p&gt;We are keen for your feedback; please open an &lt;a href="https://www.github.com/openai/openai-python/issues"&gt;issue&lt;/a&gt; with questions, bugs, or suggestions.&lt;/p&gt; 
&lt;h3&gt;Determining the installed version&lt;/h3&gt; 
&lt;p&gt;If you've upgraded to the latest version but aren't seeing any new features you were expecting then your python environment is likely still using an older version.&lt;/p&gt; 
&lt;p&gt;You can determine the version that is being used at runtime with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import openai
print(openai.__version__)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;Python 3.8 or higher.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/openai/openai-python/main/CONTRIBUTING.md"&gt;the contributing documentation&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>netbirdio/netbird</title>
      <link>https://github.com/netbirdio/netbird</link>
      <description>&lt;p&gt;Connect your devices into a secure WireGuardÂ®-based overlay network with SSO, MFA and granular access controls.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br&gt; 
 &lt;br&gt; 
 &lt;p align="center"&gt; &lt;img width="234" src="https://raw.githubusercontent.com/netbirdio/netbird/main/docs/media/logo-full.png"&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://img.shields.io/badge/license-BSD--3-blue)"&gt; &lt;img src="https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;amp;metric=alert_status"&gt; &lt;/a&gt; &lt;a href="https://github.com/netbirdio/netbird/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/license-BSD--3-blue"&gt; &lt;/a&gt; &lt;br&gt; &lt;a href="https://docs.netbird.io/slack-url"&gt; &lt;img src="https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack"&gt; &lt;/a&gt; &lt;a href="https://forum.netbird.io"&gt; &lt;img src="https://img.shields.io/badge/community%20forum-@netbird-red.svg?logo=discourse"&gt; &lt;/a&gt; &lt;br&gt; &lt;a href="https://gurubase.io/g/netbird"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt; Start using NetBird at &lt;a href="https://netbird.io/pricing"&gt;netbird.io&lt;/a&gt; &lt;br&gt; See &lt;a href="https://netbird.io/docs/"&gt;Documentation&lt;/a&gt; &lt;br&gt; Join our &lt;a href="https://docs.netbird.io/slack-url"&gt;Slack channel&lt;/a&gt; or our &lt;a href="https://forum.netbird.io"&gt;Community forum&lt;/a&gt; &lt;br&gt; &lt;/strong&gt; &lt;br&gt; &lt;a href="https://registry.terraform.io/providers/netbirdio/netbird/latest"&gt; New: NetBird terraform provider &lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Connect.&lt;/strong&gt; NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Secure.&lt;/strong&gt; NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.&lt;/p&gt; 
&lt;h3&gt;Open Source Network Security in a Single Platform&lt;/h3&gt; 
&lt;img width="1188" alt="centralized-network-management 1" src="https://github.com/user-attachments/assets/c28cc8e4-15d2-4d2f-bb97-a6433db39d56"&gt; 
&lt;h3&gt;NetBird on Lawrence Systems (Video)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Kwrff6h0rEw"&gt;&lt;img src="https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg" alt="Watch the video"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Key features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connectivity&lt;/th&gt; 
   &lt;th&gt;Management&lt;/th&gt; 
   &lt;th&gt;Security&lt;/th&gt; 
   &lt;th&gt;Automation&lt;/th&gt; 
   &lt;th&gt;Platforms&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Kernel WireGuard&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://github.com/netbirdio/dashboard"&gt;Admin Web UI&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login"&gt;SSO &amp;amp; MFA support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/api"&gt;Public API&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Linux&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer connections&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Auto peer discovery and configuration&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-network-access"&gt;Access control - groups &amp;amp; rules&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/register-machines-using-setup-keys"&gt;Setup keys for bulk network provisioning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Mac&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Connection relay fallback&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/identity-providers"&gt;IdP integrations&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/audit-events-logging"&gt;Activity logging&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-quickstart"&gt;Self-hosting quickstart script&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Windows&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/routing-traffic-to-private-networks"&gt;Routes to external networks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-dns-in-your-network"&gt;Private DNS&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-posture-checks"&gt;Device posture checks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] IdP groups sync with JWT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Android&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] NAT traversal with BPF&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/add-users-to-your-network"&gt;Multiuser support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer encryption&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] iOS&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn"&gt;Quantum-resistance with Rosenpass&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] OpenWRT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/enforce-periodic-user-authentication"&gt;Periodic re-authentication&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/netbird-on-faas"&gt;Serverless&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Docker&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Quickstart with NetBird Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and install NetBird at &lt;a href="https://app.netbird.io/install"&gt;https://app.netbird.io/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.&lt;/li&gt; 
 &lt;li&gt;Check NetBird &lt;a href="https://app.netbird.io/"&gt;admin UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add more machines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quickstart with self-hosted NetBird&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM. Follow the &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider"&gt;Advanced guide with a custom identity provider&lt;/a&gt; for installations with different IDPs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Linux VM with at least &lt;strong&gt;1CPU&lt;/strong&gt; and &lt;strong&gt;2GB&lt;/strong&gt; of memory.&lt;/li&gt; 
 &lt;li&gt;The VM should be publicly accessible on TCP ports &lt;strong&gt;80&lt;/strong&gt; and &lt;strong&gt;443&lt;/strong&gt; and UDP ports: &lt;strong&gt;3478&lt;/strong&gt;, &lt;strong&gt;49152-65535&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Public domain&lt;/strong&gt; name pointing to the VM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Software requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker installed on the VM with the docker-compose plugin (&lt;a href="https://docs.docker.com/engine/install/"&gt;Docker installation guide&lt;/a&gt;) or docker with docker-compose in version 2 or higher.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://jqlang.github.io/jq/"&gt;jq&lt;/a&gt; installed. In most distributions Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install jq&lt;/code&gt; or &lt;code&gt;sudo yum install jq&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://curl.se/"&gt;curl&lt;/a&gt; installed. Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install curl&lt;/code&gt; or &lt;code&gt;sudo yum install curl&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and run the installation script:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started-with-zitadel.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Once finished, you can manage the resources via &lt;code&gt;docker-compose&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;A bit on NetBird internals&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Every machine in the network runs &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/client/"&gt;NetBird Agent (or Client)&lt;/a&gt; that manages WireGuard.&lt;/li&gt; 
 &lt;li&gt;Every agent connects to &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/management/"&gt;Management Service&lt;/a&gt; that holds network state, manages peer IPs, and distributes network updates to agents (peers).&lt;/li&gt; 
 &lt;li&gt;NetBird agent uses WebRTC ICE implemented in &lt;a href="https://github.com/pion/ice"&gt;pion/ice library&lt;/a&gt; to discover connection candidates when establishing a peer-to-peer connection between machines.&lt;/li&gt; 
 &lt;li&gt;Connection candidates are discovered with the help of &lt;a href="https://en.wikipedia.org/wiki/STUN"&gt;STUN&lt;/a&gt; servers.&lt;/li&gt; 
 &lt;li&gt;Agents negotiate a connection through &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/signal/"&gt;Signal Service&lt;/a&gt; passing p2p encrypted messages with candidates.&lt;/li&gt; 
 &lt;li&gt;Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn't possible. When this occurs the system falls back to a relay server called &lt;a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT"&gt;TURN&lt;/a&gt;, and a secure WireGuard tunnel is established via the TURN server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt; is the one that has been successfully used for STUN and TURN in NetBird setups.&lt;/p&gt; 
&lt;p float="left" align="middle"&gt; &lt;img src="https://docs.netbird.io/docs-static/img/architecture/high-level-dia.png" width="700"&gt; &lt;/p&gt; 
&lt;p&gt;See a complete &lt;a href="https://docs.netbird.io/about-netbird/how-netbird-works#architecture"&gt;architecture overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Community projects&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/physk/netbird-installer"&gt;NetBird installer script&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/"&gt;NetBird ansible collection by Dominion Solutions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;main&lt;/code&gt; branch may be in an &lt;em&gt;unstable or even broken state&lt;/em&gt; during development. For stable versions, see &lt;a href="https://github.com/netbirdio/netbird/releases"&gt;releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Support acknowledgement&lt;/h3&gt; 
&lt;p&gt;In November 2022, NetBird joined the &lt;a href="https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure"&gt;StartUpSecure program&lt;/a&gt; sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with &lt;a href="https://cispa.de/en"&gt;CISPA Helmholtz Center for Information Security&lt;/a&gt; NetBird brings the security best practices and simplicity to private networking.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png" alt="CISPA_Logo_BLACK_EN_RZ_RGB (1)"&gt;&lt;/p&gt; 
&lt;h3&gt;Testimonials&lt;/h3&gt; 
&lt;p&gt;We use open-source technologies like &lt;a href="https://www.wireguard.com/"&gt;WireGuardÂ®&lt;/a&gt;, &lt;a href="https://github.com/pion/ice"&gt;Pion ICE (WebRTC)&lt;/a&gt;, &lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt;, and &lt;a href="https://rosenpass.eu"&gt;Rosenpass&lt;/a&gt;. We very much appreciate the work these guys are doing and we'd greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).&lt;/p&gt; 
&lt;h3&gt;Legal&lt;/h3&gt; 
&lt;p&gt;This repository is licensed under BSD-3-Clause license that applies to all parts of the repository except for the directories management/, signal/ and relay/. Those directories are licensed under the GNU Affero General Public License version 3.0 (AGPLv3). See the respective LICENSE files inside each directory.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;WireGuard&lt;/em&gt; and the &lt;em&gt;WireGuard&lt;/em&gt; logo are &lt;a href="https://www.wireguard.com/trademark-policy/"&gt;registered trademarks&lt;/a&gt; of Jason A. Donenfeld.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>e2b-dev/awesome-ai-agents</title>
      <link>https://github.com/e2b-dev/awesome-ai-agents</link>
      <description>&lt;p&gt;A list of AI autonomous agents&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; ð® Awesome AI Agents &lt;p align="center"&gt; &lt;a href="https://discord.gg/U7KEcGErtQ" target="_blank"&gt; &lt;img src="https://img.shields.io/static/v1?label=Join&amp;amp;message=%20discord!&amp;amp;color=mediumslateblue"&gt; &lt;/a&gt; &lt;a href="https://twitter.com/e2b" target="_blank"&gt; &lt;img src="https://img.shields.io/twitter/follow/e2b.svg?logo=twitter"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/h1&gt; 
&lt;h3 align="center"&gt; Add &lt;a href="https://e2b.dev/docs?ref=awesome-sdks"&gt;Code Interpreter&lt;/a&gt; to your AI App &lt;/h3&gt; 
&lt;h5 align="center"&gt;ð &lt;a href="https://e2b.dev/ai-agents"&gt;See this list in web UI&lt;/a&gt;&lt;/h5&gt; 
&lt;h5 align="center"&gt;ð &lt;a href="https://forms.gle/UXQFCogLYrPFvfoUA"&gt;Submit new product here&lt;/a&gt;&lt;/h5&gt; 
&lt;img src="https://raw.githubusercontent.com/e2b-dev/awesome-ai-agents/main/assets/landscape-latest.png" width="100%" alt="Chart of AI Agents Landscape"&gt; 
&lt;p&gt;Welcome to our list of AI agents. We structured the list into two parts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/e2b-dev/awesome-ai-agents/main/#open-source-projects"&gt;Open source projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/e2b-dev/awesome-ai-agents/main/#closed-source-projects-and-companies"&gt;Closed-source projects and companies&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To filter the products by categories and use-cases, see the ð &lt;a href="https://e2b.dev/ai-agents"&gt;web version of this list&lt;/a&gt;. ð&lt;/p&gt; 
&lt;p&gt;The list is done according to our best knowledge, although definitely not comprehensive. Check out also &lt;a href="https://github.com/e2b-dev/awesome-sdks-for-ai-agents"&gt;the Awesome List of SDKs for AI Agents&lt;/a&gt;. Discussion and feedback appreciated! &lt;span&gt;â¤ï¸&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;Have anything to add?&lt;/h2&gt; 
&lt;p&gt;Create a pull request or fill in this &lt;a href="https://forms.gle/UXQFCogLYrPFvfoUA"&gt;form&lt;/a&gt;. Please keep the alphabetical order and in the correct category.&lt;/p&gt; 
&lt;p&gt;For adding AI agents'-related SDKs, frameworks and tools, please visit &lt;a href="https://github.com/e2b-dev/awesome-sdks-for-ai-agents"&gt;Awesome SDKs for AI Agents&lt;/a&gt;. This list is only for AI assistants and agents.&lt;/p&gt; 
&lt;!--
## Who's behind this?
This list is made by the team behind [e2b](https://github.com/e2b-dev/e2b). E2b is building AWS for AI agents. We help developers to deploy, test, and monitor AI agents. E2b is agnostic to your tech stack and aims to work with any tooling for building AI agents.
---&gt; 
&lt;h2&gt;Check out E2B - Code Interpreting for AI apps&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out &lt;a href="https://e2b.dev/docs?ref=awesome-sdk"&gt;Code Interpreter SDK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Explore examples in &lt;a href="https://github.com/e2b-dev/e2b-cookbook"&gt;E2B Cookbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Read our &lt;a href="https://e2b.dev/docs?ref=awesome-sdks"&gt;docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Contact us at &lt;a href="mailto:hello@e2b.dev"&gt;hello@e2b.dev&lt;/a&gt; or &lt;a href="https://discord.gg/35NF4Y8WSE"&gt;on Discord&lt;/a&gt;. Follow us on &lt;a href="https://twitter.com/e2b"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Open-source projects&lt;/h1&gt; 
&lt;h2&gt;&lt;a href="https://github.com/HumanSignal/Adala"&gt;Adala&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Adala: Autonomous Data (Labeling) Agent framework&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/HumanSignal/Adala/raw/master/docs/src/img/logo-dark-mode.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Reliable agents&lt;/strong&gt;: Built on ground truth data for consistent, trustworthy results.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Controllable output&lt;/strong&gt;: Tailor output with flexible constraints to fit your needs.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Specialized in data processing&lt;/strong&gt;: Agents excel in custom data labeling and processing tasks.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Autonomous learning&lt;/strong&gt;: Agents evolve through observations and reflections, not just automation.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Flexible and extensible runtime&lt;/strong&gt;: Adaptable framework with community-driven evolution for diverse needs.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Easily customizable&lt;/strong&gt;: Develop agents swiftly for unique challenges, no steep learning curve.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://humansignal.github.io/Adala/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/QBtgTbXTgU"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/HumanSignal/Adala"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/LehengTHU/Agent4Rec"&gt;Agent4Rec&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Recommender system simulator with 1,000 agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/LehengTHU/Agent4Rec/raw/master/assets/sandbox.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Agent4Rec is a recommender system simulator that utilizes 1,000 LLM-empowered generative agents.&lt;/li&gt; 
  &lt;li&gt;These agents are initialized from the &lt;a href="https://grouplens.org/datasets/movielens/1m/"&gt;MovieLens-1M&lt;/a&gt; dataset, embodying varied social traits and preferences.&lt;/li&gt; 
  &lt;li&gt;Each agent interacts with personalized movie recommendations in a page-by-page manner and undertakes various actions such as watching, rating, evaluating, exiting, and interviewing.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.10108"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/DataBassGit/AgentForge"&gt;AgentForge&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;LLM-agnostic platform for agent building &amp;amp; testing&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1667167265060528129/l8S9vtP2_400x400.jpg" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A low-code framework designed for the swift creation, testing, and iteration of AI-powered autonomous agents and Cognitive Architectures, compatible with various LLM models.&lt;/li&gt; 
  &lt;li&gt;Facilitates building custom agents and cognitive architectures with ease.&lt;/li&gt; 
  &lt;li&gt;Supports multiple LLM models including OpenAI, Anthropic's Claude, and local Oobabooga, allowing flexibility in running different models for different agents based on specific requirements.&lt;/li&gt; 
  &lt;li&gt;Provides customizable agent memory management and on-the-fly prompt editing for rapid development and testing.&lt;/li&gt; 
  &lt;li&gt;Comes with a database-agnostic design ensuring seamless extensibility, with straightforward integration with different databases like ChromaDB for various AI projects.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/DataBassGit/AgentForge"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.agentforge.net/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/ttpXHUtCW6"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/AgentForge"&gt;X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://agentgpt.reworkd.ai/"&gt;AgentGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Browser-based no-code version of AutoGPT&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/reworkd/AgentGPT/main/next/public/banner.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A no-code platform&lt;/li&gt; 
  &lt;li&gt;Process: 
   &lt;ul&gt; 
    &lt;li&gt;Assigning a goal to the agent&lt;/li&gt; 
    &lt;li&gt;Witnessing its thinking process&lt;/li&gt; 
    &lt;li&gt;Formulation of an execution plan&lt;/li&gt; 
    &lt;li&gt;Taking actions accordingly&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Uses OpenAI functions&lt;/li&gt; 
  &lt;li&gt;Supports gpt-3.5-16k, pinecone and pg_vector databases&lt;/li&gt; 
  &lt;li&gt;Stack 
   &lt;ul&gt; 
    &lt;li&gt;Frontend: NextJS + Typescript&lt;/li&gt; 
    &lt;li&gt;Backend: FastAPI + Python&lt;/li&gt; 
    &lt;li&gt;DB: MySQL through docker with the option of running SQLite locally&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--
### Features
- Uses OpenAI **functions**
- Supports gpt-3.5-16k, pinecone and pg_vector databases

### Stack
- Frontend: NextJS + Typescript
- Backend: FastAPI + Python
	- DB: MySQL through docker with the option of running SQLite locally
	--&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.reworkd.ai/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://agentgpt.reworkd.ai/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/reworkd/AgentGPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;!-- This is a comment that appears only in the raw text --&gt; 
&lt;h2&gt;&lt;a href="https://github.com/jbexta/AgentPilot"&gt;AgentPilot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build, manage, and chat with agents in desktop app&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/jbexta/AgentPilot/raw/master/docs/demo.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Integrated into Open Interpreter and MemGPT&lt;/li&gt; 
  &lt;li&gt;Group chats feature&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jbexta/AgentPilot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/AgentPilotAI"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/aiwaves-cn/agents"&gt;Agents&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Library/framework for building language agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/aiwaves-cn/agents/raw/master/assets/agents-logo.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Long-short Term Memory&lt;/strong&gt;: Language agents in the library are equipped with both long-term memory implemented via VectorDB + Semantic Search and short-term memory (working memory) maintained and updated by an LLM.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Tool Usage&lt;/strong&gt;: Language agents in the library can use any external tools via &lt;a href="https://platform.openai.com/docs/guides/gpt/function-calling"&gt;function-calling&lt;/a&gt; and developers can add customized tools/APIs &lt;a href="https://github.com/aiwaves-cn/agents/raw/master/src/agents/Component/ToolComponent.py"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Web Navigation&lt;/strong&gt;: Language agents in the library can use search engines to navigate the web and get useful information.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Multi-agent Communication&lt;/strong&gt;: In addition to single language agents, the library supports building multi-agent systems in which language agents can communicate with other language agents and the environment. Different from most existing frameworks for multi-agent systems that use pre-defined rules to control the order for agents' action, &lt;strong&gt;Agents&lt;/strong&gt; includes a &lt;em&gt;controller&lt;/em&gt; function that dynamically decides which agent will perform the next action using an LLM by considering the previous actions, the environment, and the target of the current states. This makes multi-agent communication more flexible.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Human-Agent interaction&lt;/strong&gt;: In addition to letting language agents communicate with each other in an environment, our framework seamlessly supports human users to play the role of the agent by himself/herself and input his/her own actions, and interact with other language agents in the environment.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Symbolic Control&lt;/strong&gt;: Different from existing frameworks for language agents that only use a simple task description to control the entire multi-agent system over the whole task completion process, &lt;strong&gt;Agents&lt;/strong&gt; allows users to use an &lt;strong&gt;SOP (Standard Operation Process)&lt;/strong&gt; that defines subgoals/subtasks for the overall task to customize fine-grained workflows for the language agents.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https:github.com/aiwaves-cn"&gt;AIWaves Inc.&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2309.07870.pdf"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aiwaves-cn/agents"&gt;GitHub Repository&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://agents-readthedocsio.readthedocs.io/en/latest/index.html"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/wangchunshu/status/1702512370785100133"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/OpenBMB/AgentVerse"&gt;AgentVerse&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Platform for task-solving &amp;amp; simulation agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/card_img/1744672970822615040/m870GGf1?format=jpg&amp;amp;name=medium" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Assembles multiple agents to collaboratively accomplish tasks.&lt;/li&gt; 
  &lt;li&gt;Allows custom environments for observing or interacting with multiple agents.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2308.10848"&gt;AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Agentverse71134"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/gDAXfjMw"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/spaces/AgentVerse/agentVerse"&gt;Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/eumemic/ai-legion"&gt;AI Legion&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi-agent TS platform, similar to AutoGPT&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://res.cloudinary.com/apideck/image/upload/w_1500,f_auto/v1681330426/marketplaces/ckhg56iu1mkpc0b66vj7fsj3o/listings/ai-legion/screenshots/Screenshot_2023-04-12_at_22.13.24_d9kdoj.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An LLM-powered autonomous agent platform&lt;/li&gt; 
  &lt;li&gt;A framework for autonomous agents who can work together to accomplish tasks&lt;/li&gt; 
  &lt;li&gt;Interaction with agents done via console direct messages&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://github.com/eumemic"&gt;eumemic&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://gpt3demo.com/apps/ai-legion"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/eumemic/ai-legion"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/dysmemic"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/paul-gauthier/aider"&gt;Aider&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Use command line to edit code in your local repo&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://repository-images.githubusercontent.com/638629097/1d3d6251-f8be-4d11-bbb1-4e44b7364b74" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Aider is a command line tool that lets you pair program with GPT-3.5/GPT-4, to edit code stored in your local git repository&lt;/li&gt; 
  &lt;li&gt;You can start a new project or work with an existing repo. And you can fluidly switch back and forth between the aider chat where you ask GPT to edit the code and your own editor to make changes yourself&lt;/li&gt; 
  &lt;li&gt;Aider makes sure edits from you and GPT are committed to git with sensible commit messages. Aider is unique in that it works well with pre-existing, larger codebases&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://aider.chat/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://github.com/paul-gauthier"&gt;Paul Gauthier&lt;/a&gt; (Github)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/Tv2uQnR88V"&gt;Discord Invite&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/myshell-ai/AIlice"&gt;AIlice&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Create agents-calling tree to execute your tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/myshell-ai/AIlice/raw/master/AIlice.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Personal assistant, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"An Agent in the form of a chatbot independently plans tasks given in natural language and dynamically creates an agents calling tree to execute tasks.&lt;/li&gt; 
  &lt;li&gt;There is an interaction mechanism between agents to ensure fault tolerance.&lt;/li&gt; 
  &lt;li&gt;External interaction modules can be automatically built for self-expansion.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/myshell-ai/AIlice"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/microsoft/autogen"&gt;AutoGen&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi-agent framework with diversity of agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/microsoft/autogen/raw/main/website/static/img/autogen_agentchat.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A framework for developing LLM (Large Language Model) applications with multiple conversational agents.&lt;/li&gt; 
  &lt;li&gt;These agents can collaborate to solve tasks and can interact seamlessly with humans.&lt;/li&gt; 
  &lt;li&gt;It simplifies complex LLM workflows, enhancing automation and optimization.&lt;/li&gt; 
  &lt;li&gt;It offers a range of working systems across various domains and complexities.&lt;/li&gt; 
  &lt;li&gt;It improves LLM inference with easy performance tuning and utility features like API unification and caching.&lt;/li&gt; 
  &lt;li&gt;It supports advanced usage patterns, including error handling, multi-config inference, and context programming.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/pdf/2308.08155.pdf"&gt;AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/pAbnFJrkgZ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/pyautogen"&gt;Twitter thread describing the system&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://agpt.co/?utm_source=awesome-ai-agents"&gt;AutoGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Experimental attempt to make GPT4 fully autonomous&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://news.agpt.co/wp-content/uploads/2023/04/Logo_-_Auto_GPT-B-800x363.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An experimental open-source attempt to make GPT-4 fully autonomous, with &amp;gt;140k stars on GitHub&lt;/li&gt; 
  &lt;li&gt;Chains together LLM "thoughts", to autonomously achieve whatever goal you set&lt;/li&gt; 
  &lt;li&gt;Internet access for searches and information gathering&lt;/li&gt; 
  &lt;li&gt;Long-term and short-term memory management&lt;/li&gt; 
  &lt;li&gt;Can execute many commands such as Google Search, browse websites, write to files, and execute Python files and much more&lt;/li&gt; 
  &lt;li&gt;GPT-4 instances for text generation&lt;/li&gt; 
  &lt;li&gt;Access to popular websites and platforms&lt;/li&gt; 
  &lt;li&gt;File storage and summarization with GPT-3.5&lt;/li&gt; 
  &lt;li&gt;Extensibility with Plugins&lt;/li&gt; 
  &lt;li&gt;"A lot like BabyAGI combined with LangChain tools"&lt;/li&gt; 
  &lt;li&gt;Features added in release 0.4.0 
   &lt;ul&gt; 
    &lt;li&gt;File reading&lt;/li&gt; 
    &lt;li&gt;Commands customization&lt;/li&gt; 
    &lt;li&gt;Enhanced testing&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--
### Features added in release 0.4.0
- File reading
- Commands customization
- Enhanced testing
--&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Auto_GPT/?utm_source=awesome-ai-agents"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Significant-Gravitas/Auto-GPT/?utm_source=awesome-ai-agents"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.facebook.com/groups/1330282574368178/?utm_source=awesome-ai-agents"&gt;Facebook&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/autogpt/?utm_source=awesome-ai-agents"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/autogpt/?utm_source=awesome-ai-agents"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/SigGravitas/?utm_source=awesome-ai-agents"&gt;Significant Gravitas&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/emrgnt-cmplxty/automata"&gt;Automata&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generate code based on your project context&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/emrgnt-cmplxty/Automata/assets/68796651/61fe3c33-9b7a-4c1b-9726-a77140476b83" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Model: GPT 4&lt;/li&gt; 
  &lt;li&gt;Automata takes your project as a context, receives tasks, and executes the instructions seamlessly.&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Automata aims to evolve into a fully autonomous, self-programming Artificial Intelligence system.&lt;/li&gt; 
    &lt;li&gt;It's designed for seamless integration with all available agent platforms and LLM providers.&lt;/li&gt; 
    &lt;li&gt;Utilizes the novel code search algorithm, SymbolRank, and associated tools to build superior coding intelligence.&lt;/li&gt; 
    &lt;li&gt;Modular, fully configurable design with minimal reliance on external dependencies&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/emrgnt-cmplxty/automata"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://automata.readthedocs.io/en/latest/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/ocolegro"&gt;Owen Colegrove&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--

### Features
- Automata aims to evolve into a fully autonomous, self-programming Artificial Intelligence system.
- It's designed for seamless integration with all available agent platforms and LLM providers.
- Utilizes the novel code search algorithm, SymbolRank, and associated tools to build superior coding intelligence.
- Modular, fully configurable design with minimal reliance on external dependencies.

--&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/irgolic/AutoPR"&gt;AutoPR&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-generated pull requests agent that fixes issues&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/irgolic/AutoPR/raw/main/website/static/img/AutoPR_Mark_color.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Triggered by adding a label containing AutoPR to an issue, AutoPR will: 
   &lt;ul&gt; 
    &lt;li&gt;Plan a fix&lt;/li&gt; 
    &lt;li&gt;Write the code&lt;/li&gt; 
    &lt;li&gt;Push a branch&lt;/li&gt; 
    &lt;li&gt;Open a pull request&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/ykk7Znt3K6"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/stepanogil/autonomous-hr-chatbot"&gt;Autonomous HR Chatbot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that answers HR-related queries using tools&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/stepanogil/autonomous-hr-chatbot/raw/main/assets/sample_chat.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;HR, Business intelligence, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A prototype enterprise application - an Autonomous HR Assistant powered by GPT-3.5.&lt;/li&gt; 
  &lt;li&gt;An agent that can answer HR related queries autonomously using the tools it has on hand.&lt;/li&gt; 
  &lt;li&gt;Powered by GPT-3.5&lt;/li&gt; 
  &lt;li&gt;Current tools assigned to the agent (with more on the way): 
   &lt;ul&gt; 
    &lt;li&gt;Timekeeping Policy&lt;/li&gt; 
    &lt;li&gt;Employee Data&lt;/li&gt; 
    &lt;li&gt;Calculator&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Medium: &lt;a href="https://pub.towardsai.net/creating-a-mostly-autonomous-hr-assistant-with-chatgpt-and-langchains-agents-and-tools-1cdda0aa70ef"&gt;Creating a (mostly) Autonomous HR Assistant with ChatGPT and LangChainâs Agents and Tools&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/stepanogil/autonomous-hr-chatbot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/Stepanogil"&gt;Stephen Bonifacio&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=id7XRcEIBvg&amp;amp;ab_channel=StephenBonifacio"&gt;YouTube demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pub.towardsai.net/creating-a-mostly-autonomous-hr-assistant-with-chatgpt-and-langchains-agents-and-tools-1cdda0aa70ef"&gt;Blog post&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A simple framework for managing tasks using AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/21254008/235015461-543a897f-70cc-4b63-941a-2ae3c9172b11.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A pared-down version of the original &lt;a href="https://twitter.com/yoheinakajima/status/1640934493489070080?s=20"&gt;Task-Driven Autonomous Agent&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Creates tasks based on the result of previous tasks and a predefined objective.&lt;/li&gt; 
  &lt;li&gt;The script then uses OpenAI's NLP capabilities to create new tasks based on the objective&lt;/li&gt; 
  &lt;li&gt;Leverages OpenAI's GPT-4, pinecone vector search, and LangChainAI framework&lt;/li&gt; 
  &lt;li&gt;Default model is OpenAI GPT3-turbo&lt;/li&gt; 
  &lt;li&gt;The system maintains a task list for managing and prioritizing tasks&lt;/li&gt; 
  &lt;li&gt;It autonomously creates new tasks based on completed results and reprioritizes the task list accordingly, showcasing the adaptability of AI-powered language models&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Paper: &lt;a href="https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/"&gt;Task-driven Autonomous Agent Utilizing GPT-4, Pinecone, and LangChain for Diverse Applications&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/TMUw26XUcg"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima"&gt;Founder's Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1640934493489070080"&gt;Twitter thread describing the system&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://yoheinakajima.com/babybeeagi-task-management-and-functionality-expansion-on-top-of-babyagi/"&gt;BabyBeeAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Task management &amp;amp; functionality BabyAGI expansion&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://yoheinakajima.com/wp-content/uploads/2023/04/image.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A more advanced version of the original BabyAGI code&lt;/li&gt; 
  &lt;li&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Improves upon the original framework, by introducing a more complex task management prompt, allowing for more comprehensive analysis and synthesis of information&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Designed to handle multiple functions within one task management prompt&lt;/li&gt; 
  &lt;li&gt;Built on top of the GPT-4 architecture, resulting in slower processing speeds and occasional errors&lt;/li&gt; 
  &lt;li&gt;Provides a framework that can be further built upon and improved, paving the way for more sophisticated AI applications&lt;/li&gt; 
  &lt;li&gt;One of the significant differences between BabyAGI and BabyBeeAGI is the complexity of the task management prompt&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1652732735344246784"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/raw/main/classic/BabyBeeAGI.py"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyBeeAGI?v=1"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/yoheinakajima"&gt;@yoheinakajima&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyCatAGI"&gt;BabyCatAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;BabyCatAGI is a mod of BabyBeeAGI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/FwBwoRracAI99iP?format=jpg&amp;amp;name=medium" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Just 300 lines of code&lt;/li&gt; 
  &lt;li&gt;This was built as a d iteration on the original BabyAGI code in a lightweight way. Differences to BabyAGI include the following: 
   &lt;ul&gt; 
    &lt;li&gt;Task Creation Agent runs once&lt;/li&gt; 
    &lt;li&gt;Execution Agent loops through tasks&lt;/li&gt; 
    &lt;li&gt;Task dependencies for pulling relevant results&lt;/li&gt; 
    &lt;li&gt;Two tools: search tool and text completion&lt;/li&gt; 
    &lt;li&gt;âMini-agentâ as tool&lt;/li&gt; 
    &lt;li&gt;Search tool combines search, scrape, chunking, and extraction.&lt;/li&gt; 
    &lt;li&gt;Results combined to create summary report&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--
### How to use
- Fork this into a private Repl
- Add your OpenAI API Key (required) and SerpAPI Key (optional)
- Update the OBJECTIVE variable
- Press "Run" at the top.
--&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1657448504112091136"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/raw/main/classic/BabyCatAGI.py"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyCatAGI"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/yoheinakajima"&gt;@yoheinakajima&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1666313838868992001"&gt;BabyDeerAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Mod of BabyAGI with only ~350 lines of code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/Fx_tr0yaUAYP1Q0?format=jpg&amp;amp;name=medium" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Parallel tasks (making it faster)&lt;/li&gt; 
    &lt;li&gt;3.5-turbo only (GPT-4 not required)&lt;/li&gt; 
    &lt;li&gt;User input tool&lt;/li&gt; 
    &lt;li&gt;Query rewrite in web search tool&lt;/li&gt; 
    &lt;li&gt;Saves results&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1666313838868992001"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/raw/main/classic/BabyDeerAGI.py"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyDeerAGI"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/yoheinakajima"&gt;@yoheinakajima&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1678443482866933760"&gt;BabyElfAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Mod of BabyDeerAGI, with ~895 lines of code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/F0sHc04aMAEVn3D?format=jpg&amp;amp;name=medium" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Skills class allows for creation of new skills&lt;/li&gt; 
    &lt;li&gt;'Dynamic task list' example with vector search&lt;/li&gt; 
    &lt;li&gt;Beta reflection agent&lt;/li&gt; 
    &lt;li&gt;Can read, write, and review its own code&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1678443482866933760"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/raw/main/classic/BabyElfAGI/main.py"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyElfAGI"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/yoheinakajima"&gt;@yoheinakajima&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/saten-private/BabyCommandAGI"&gt;BabyCommandAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Test what happens when you combine CLI and LLM&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/saten-private/BabyCommandAGI/raw/main/docs/Architecture.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;gent designed to test what happens when you combine CLI and LLM, which are more traditional interfaces than GUI (created by @saten-private)&lt;/li&gt; 
  &lt;li&gt;An AI agent based on @yoheinakajima's &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt; which executes shell commands&lt;/li&gt; 
  &lt;li&gt;Automatic Programming, Successfully created an app automatically just by providing feedback. The procedure can be found &lt;a href="https://twitter.com/saten_work/status/1674855573412810753"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;Automatic Environment Setup, Successfully installed a Flutter environment on Linux in a container, created the Flutter app, and launched it. The procedure can be found &lt;a href="https://twitter.com/saten_work/status/1667126272072491009"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;Aside from setting up the environment, it seems to be able to handle a bit of general tasks such as &lt;a href="https://anyaitools.com/babycommandagi/?utm_source=SocialAutoPoster&amp;amp;utm_medium=Social&amp;amp;utm_campaign=Twitter"&gt;Generating text, like poems, code, scripts, musical pieces, email, and letters, translating languages&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;There is a risk of breaking the environment. Please run in a virtual environment such as Docker.&lt;/li&gt; 
  &lt;li&gt;GPT-4 or higher is recommended&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/saten_work"&gt;Founder's Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/saten_work/status/1654571194111393793"&gt;Twitter thread describing the system&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/tree/main/classic/babyfoxagi"&gt;BabyFoxAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Mod of BabyAGI with a new parallel UI panel&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/F2Vpt4EbIAAa326?format=jpg&amp;amp;name=medium" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A mod of BabyElfAGI, in a series of mods w the naming of Baby
   &lt;animal&gt;
    AGI in alphabetical order
   &lt;/animal&gt;&lt;/li&gt; 
  &lt;li&gt;Self-improving task lists (FOXY method) 
   &lt;ul&gt; 
    &lt;li&gt;By storing a final reflection at the end, and pulling the most relevant reflection to guide future runs, BabyAGI slowly generates better and better tasks lists&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Novel Chat UI w parallel tasks 
   &lt;ul&gt; 
    &lt;li&gt;You can chat w BabyAGI! It has an experimental UI where the chat is separate from the tasks/output panel, allowing you to request multiple tasks in parallel&lt;/li&gt; 
    &lt;li&gt;The Chat UI can use a single skill quickly, or chain multiple skills together using a tasklist&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;New skills 
   &lt;ul&gt; 
    &lt;li&gt;ð¨ DALLE skill with prompt assist&lt;/li&gt; 
    &lt;li&gt;ð¶ Music player w Deezer&lt;/li&gt; 
    &lt;li&gt;ð Airtable search (add your own table/base ID)&lt;/li&gt; 
    &lt;li&gt;ð Startup Analyst (example of beefy function call as a skill)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Itâs own README&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1697539193768116449"&gt;Twitter thread describing the system&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/pgalko/BambooAI"&gt;BambooAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Data exploration and analysis for non-programmers&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/card_img/1745187734602313730/f-W5kbIU?format=jpg&amp;amp;name=medium" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;BambooAI runs in a loop (until user decides to end it).&lt;/li&gt; 
  &lt;li&gt;Allows mixing of different models with different capabilities, token costs and context windows for different tasks.&lt;/li&gt; 
  &lt;li&gt;Maintains the memory of previous conversations.&lt;/li&gt; 
  &lt;li&gt;Builds the prompts dynamically utilising relevant context from Pinecone vector DB.&lt;/li&gt; 
  &lt;li&gt;Offers a narrative or asks follow up questions if required.&lt;/li&gt; 
  &lt;li&gt;For codified responses, the task is broken down into a list of steps and a pseudo-code algorithm is built.&lt;/li&gt; 
  &lt;li&gt;Based on the algorithm, it ises the python code for dataset analysis, modeling or plotting.&lt;/li&gt; 
  &lt;li&gt;Debugs the code which then executes, auto-corrects if needs to, and displays the output to user.&lt;/li&gt; 
  &lt;li&gt;Ranks the final answers, and asks user for feedback.&lt;/li&gt; 
  &lt;li&gt;Builds a vector DB knowledge-base, based on the rank and the user feedback.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/pgalko/BambooAI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/pgalko"&gt;Creators's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/AutoPackAI/beebot"&gt;BeeBot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Early-stage project for wide range of tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://camo.githubusercontent.com/72231056f7393fa18ee2baa5cedf2688d1fc15478bb6131936e222e5d23ccbb6/68747470733a2f2f6572696b6c702e636f6d2f6d6173636f742e706e67" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"BeeBot is currently a work in progress and should be treated as an early stage research project. Its focus is not on production usage at this time."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/AutoPackAI/beebot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Douglas_Schon/status/1681094815021187072?s=20"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/seahyinghang8/blinky"&gt;Blinky&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;An open-source AI debugging agent for VSCode&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/seahyinghang8/blinky/raw/master/media/banner.png" alt="Banner"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Debugging&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Blinky is an open-source AI debugging agent for VSCode that uses LLMs to help identify and fix backend code errors (inspired by SWE-agent).&lt;/li&gt; 
  &lt;li&gt;Blinky leverages the VSCode API, Language Server Protocol (LSP), and print statement debugging to triangulate and address bugs in real-world backend systems.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=blinky.blinky"&gt;VSCode Extension&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/d3AUNHDb"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/seahyinghang8/blinky"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://bloop.ai/"&gt;Bloop&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI code search, works for Rust and Typescript&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://bloop.ai/_next/static/media/logo_white.b3bdedc0.svg?sanitize=true" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A GPT-4 powered semantic code search engine that uses an AI agent&lt;/li&gt; 
  &lt;li&gt;Precise code navigation&lt;/li&gt; 
  &lt;li&gt;Built on stack graphs and scope queries&lt;/li&gt; 
  &lt;li&gt;Fast code search and regex matching engine written in Rust&lt;/li&gt; 
  &lt;li&gt;Allows to find Code on Rust and Typescript&lt;/li&gt; 
  &lt;li&gt;Allows to stage changes&lt;/li&gt; 
  &lt;li&gt;The agent searches both your local and remote repositories with natural language, regex and filtered queries&lt;/li&gt; 
  &lt;li&gt;Bloop can be run via app (easy to download via GitHub)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/BloopAI/bloop"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://bloop.ai/docs/getting-started"&gt;"Getting started" guide&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/BloopAI/bloop/releases"&gt;Bloop apps&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://bondai.dev/"&gt;BondAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Code interpreter with CLI &amp;amp; RESTful/WebSocket API&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://bondai.dev/assets/images/bondai-logo-9bec7e27b93b804d375221ff8fb6d336.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A highly capable, autonomous AI Agent with an easy to use CLI, RESTful/WebSocket API, Pre-built Docker image and a robust suite of integrated tools.&lt;/li&gt; 
  &lt;li&gt;Support for all GPT-N, Embeddings and Dall-E OpenAI Models&lt;/li&gt; 
  &lt;li&gt;Support for Azure OpenAI Services&lt;/li&gt; 
  &lt;li&gt;Easy to use SDK for integration into any application&lt;/li&gt; 
  &lt;li&gt;Powerful &lt;strong&gt;Code Interpreter&lt;/strong&gt; capabilities&lt;/li&gt; 
  &lt;li&gt;Powerful data query capabilities via Postgres DB integration&lt;/li&gt; 
  &lt;li&gt;Pre-built Docker image provides safe execution environment for code generation/execution&lt;/li&gt; 
  &lt;li&gt;Support for telephony applications (via BlandAI)&lt;/li&gt; 
  &lt;li&gt;Support for stock trading (via Alpaca Markets)&lt;/li&gt; 
  &lt;li&gt;Integrates with Gmail and Google Search&lt;/li&gt; 
  &lt;li&gt;Easy to install &lt;code&gt;pip install bondai&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;To start the CLI just run &lt;code&gt;bondai&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;To start the RESTful/WebSocket API just run &lt;code&gt;bondai --server&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://bondai.dev"&gt;BondAI Homepage/Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/krohling/bondai"&gt;Github Repository&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://hub.docker.com/r/krohling/bondai"&gt;Docker Image&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/xeol-io/bumpgen"&gt;bumpgen&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent that keeps npm dependencies up-to-date&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/65af8f02f12662528cdc93d6/662e6061d42954630a191417_tanstack-ezgif.com-speed%20(1).gif" alt="demo"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Put dependency management and upgrades on autopilot&lt;/li&gt; 
  &lt;li&gt;bumpgen BUMPs an npm package's version up then GENerates the code fixes for breaking changes&lt;/li&gt; 
  &lt;li&gt;Supports gpt-4-turbo&lt;/li&gt; 
  &lt;li&gt;Easy install &amp;gt; &lt;code&gt;npm install -g bumpgen&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Easy start &amp;gt; &lt;code&gt;bumpgen @tanstack/react-query 5.28.14&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/xeol-io/bumpgen"&gt;Repo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.xeol.io/bumpgen/home"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://cal.ai"&gt;Cal.ai&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source scheduling assistant built on Cal.com&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://3620107743-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FpmUOqZjfGqNkiPmqgnMv%2Fuploads%2F9Qaq1hlaTcqKfrc9k4OG%2Fimage.png?alt=media&amp;amp;token=1ffe8530-19ff-4aea-b020-a99cdc224ce1" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Cal.ai can book meetings, summarize your week, and find time with others based on natural language.&lt;/li&gt; 
  &lt;li&gt;Responds flexibly to unseen tasks eg. "move my second-last meeting to tomorrow morning".&lt;/li&gt; 
  &lt;li&gt;Uses GPT-4 and LangChain Agent Executor under the hood.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/calcom/cal.com/tree/main/apps/ai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Authors: &lt;a href="https://github.com/calcom/cal.com/graphs/contributors"&gt;Cal.com core team&lt;/a&gt;, &lt;a href="https://github.com/dexterstorey"&gt;Dexter Storey&lt;/a&gt;, &lt;a href="https://github.com/tedspare"&gt;Ted Spare&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/camel-ai/camel"&gt;CAMEL&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Architecture for âMindâ Exploration of agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CAMEL is an open-source library designed for the study of autonomous and communicative agents. 1)AI user agent: give instructions to the AI assistant with the goal of completing the task.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;AI assistant agent: follow AI userâs instructions and respond with solutions to the task&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CAMEL also has an open-source community dedicated to the study of autonomous and communicative agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.camel-ai.org/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://ghli.org/camel.pdf"&gt;Paper - CAMEL: Communicative Agents for âMindâ Exploration of Large Scale Language Model Society&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://colab.research.google.com/drive/1AzP33O8rnMW__7ocWJhVBXjKziJXPtim?usp=sharing"&gt;Colab demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/camel-ai/camel"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/camel-ai"&gt;Hugging face datasets&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://camel-kwr1314.slack.com/join/shared_invite/zt-1vy8u9lbo-ZQmhIAyWSEfSwLCl2r2eKA#/shared-invite/email"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2F1508613885-atari-embeds.googleusercontent.com%2F&amp;amp;ref_src=twsrc%5Etfw%7Ctwcamp%5Ebuttonembed%7Ctwterm%5Efollow%7Ctwgr%5ECamelAIOrg&amp;amp;screen_name=CamelAIOrg"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Authors: Guohao Liâ Hasan Abed Al Kader Hammoud* Hani Itani* Dmitrii Khizbullin, Bernard Ghanem&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.chatarena.org/"&gt;ChatArena&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A chat tool for multi agent interaction&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/Farama-Foundation/chatarena/raw/main/docs/images/chatarena_architecture.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Design, Build-your-own, SDK for AI apps, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ChatArena (or Chat Arena) is a Multi-Agent Language Game Environments for LLMs. The goal is to develop communication and collaboration capabilities of AIs. ChatArena provides:&lt;/li&gt; 
  &lt;li&gt;A general framework for building interactive environments for multiple large language models (LLMs).&lt;/li&gt; 
  &lt;li&gt;A collection of pre-built or community-created environments.&lt;/li&gt; 
  &lt;li&gt;User-friendly interfaces with both Web UI and commandline interfaces.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.chatarena.org/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Farama-Foundation/chatarena"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/_chatarena"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chatarena.slack.com/join/shared_invite/zt-1t5fpbiep-CbKucEHdJ5YeDLEpKWxDOg#/shared-invite/email"&gt;Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/OpenBMB/ChatDev"&gt;ChatDev&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Communicative agents for software development&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/OpenBMB/ChatDev/raw/main/misc/logo1.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ChatDev is a virtual software company driven by a multitude of intelligent agents assuming different roles such as CEO, CPO, CTO, programmer, reviewer, tester, and art designer, each represented by unique icons.&lt;/li&gt; 
  &lt;li&gt;These agents collaborate in a structured organizational environment, fulfilling the company's mission to "revolutionize the digital world through programming." They engage in functional seminars focusing on design, coding, testing, and documentation.&lt;/li&gt; 
  &lt;li&gt;ChatDev aims to provide an accessible, modular, and extensible platform based on large language models, facilitating the study of collective intelligence in a controlled setting.&lt;/li&gt; 
  &lt;li&gt;The framework allows for extensive customization, empowering users to tailor the software development process, define phases, and establish specific roles within the virtual company.&lt;/li&gt; 
  &lt;li&gt;ChatDev is committed to open-source principles, encouraging contributions from the community and sharing advancements transparently.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2307.07924"&gt;Paper - ChatDev: Communicative Agents for Software Development&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/raw/main/wiki.md#local-demo"&gt;Local demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/ur-whitelab/chemcrow-public"&gt;ChemCrow&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;LangChain agent for chemistry-related tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/ur-whitelab/chemcrow-public/raw/main/assets/chemcrow_dark_bold.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Science, Chemistry&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ChemCrow is an open source package for the accurate solution of reasoning-intensive chemical tasks&lt;/li&gt; 
  &lt;li&gt;It integrates 13 expert-design tools to augment LLM performance in chemistry and demonstrate effectiveness in automating chemical tasks&lt;/li&gt; 
  &lt;li&gt;Built with Langchain&lt;/li&gt; 
  &lt;li&gt;The LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output. It is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation. One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results. (Source: &lt;a href="https://lilianweng.github.io/posts/2023-06-23-agent/"&gt;Weng, Lilian. (Jun 2023). LLM-powered Autonomous Agents". LilâLog. https://lilianweng.github.io/posts/2023-06-23-agent/.&lt;/a&gt;)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2304.05376"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ur-whitelab/chemcrow-public"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=35607616"&gt;HackerNews Discussion&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/ennucore/clippy/"&gt;Clippy&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that can plan, write, debug, and test code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://lev.la/images/clippy.jpg" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The purpose of Clippy is to elop code for or with the user.&lt;/li&gt; 
  &lt;li&gt;It can plan, write, debug, and test some projects autonomously.&lt;/li&gt; 
  &lt;li&gt;For harder tasks, the best way to use it is to look at its work and provide feedback to it.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ennucore/clippy/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="http://lev.la/"&gt;Lev Chizhov&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/codefuse-ai/codefuse-chatbot"&gt;CodeFuse-ChatBot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent serving entire SW development lifecycle&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/codefuse-ai/codefuse-chatbot/raw/main/sources/docs_imgs/objective_v4.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An intelligent assistant serving the entire software development lifecycle, powered by a Multi-Agent Framework, working with DevOps Toolkits, Code&amp;amp;Doc Repo RAG, etc.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/codefuse-ai/codefuse-chatbot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/ajhous44/cody"&gt;Cody by ajhous44&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Query and navigate your codebase&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An AI assistant designed to let you interactively query your codebase using natural language.&lt;/li&gt; 
  &lt;li&gt;By utilizing vector embeddings, chunking, and OpenAI's language models, Cody can help you navigate through your code in an efficient and intuitive manner.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ajhous44/cody"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://github.com/ajhous44/"&gt;@ajhous44&lt;/a&gt; (Github)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://docs.sourcegraph.com/cody"&gt;Cody by Sourcegraph&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that writes code and answers your questions&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://sourcegraph.com/.assets/img/sourcegraph-mark.svg?v2" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;An AI code assistant from Sourcegraph that writes code and answers questions for you by reading your entire codebase and the code graph.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/sourcegraph/sourcegraph/tree/main/client/cody"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/sourcegraph"&gt;@sourcegraph&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://continue.dev/"&gt;Continue&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source autopilot for software development&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://continue.dev/docs/assets/images/continue-cover-logo-aa135cc83fe8a14af480d1633ed74eb5.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An open-source autopilot for software developmentâbring the power of ChatGPT to VS Code&lt;/li&gt; 
  &lt;li&gt;Features: 
   &lt;ul&gt; 
    &lt;li&gt;Answer coding questions&lt;/li&gt; 
    &lt;li&gt;Edit in natural language&lt;/li&gt; 
    &lt;li&gt;Generate files from scratch&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://continue.dev/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/continuedev/continue"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://continue.dev/docs/intro"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/continuedev"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/joaomdmoura/crewai"&gt;CrewAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Framework for orchestrating role-playing agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/joaomdmoura/crewAI/raw/main/docs/crewai_logo.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, SDK for agents, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Cutting-edge framework for orchestrating role-playing, autonomous AI agents.&lt;/li&gt; 
  &lt;li&gt;By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/li&gt; 
  &lt;li&gt;Crew AI is a multi-agent framework built on LangChain, aiming to empower engineers to harness the collective power of AI agents. In contrast to traditional automation methods, Crew AI introduces a new approach to collaborative decision-making, enhanced creativity, and solving complex problems.&lt;/li&gt; 
  &lt;li&gt;The design philosophy of Crew AI advocates simplicity through modularity. Its main components include agents, tools, tasks, processes, and crews. Each agent is akin to a team member, possessing specific roles, background stories, goals, and memories. Through modular design, we make the intricate world of AI agents accessible, manageable, and more engaging.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/joaomdmoura/crewai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/joaomdmoura"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://crewai.net/posts/how-to-use-crew-ai"&gt;Blog post: How to use Crew AI&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/joaomdmoura/CrewAI/wiki"&gt;Crew AI Wiki with examples and guides&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/joaomdmoura/CrewAI/wiki"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/X4JWnZnxPb"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/Technion-Kishony-lab/data-to-paper"&gt;data-to-paper&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-driven research from data to human-verifiable research papers&lt;/p&gt; 
&lt;details&gt; 
 &lt;br&gt; 
 &lt;img src="https://github.com/Technion-Kishony-lab/data-to-paper/assets/65530510/e33bcb52-5f4e-4fd0-8be9-ebd64607c449" width="400" align="center"&gt; 
 &lt;br&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Science, Research, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://arxiv.org/abs/2404.17605"&gt;&lt;em&gt;data-to-paper&lt;/em&gt;&lt;/a&gt; is a framework for systematically navigating the power of AI to perform complete end-to-end scientific research, starting from raw data and concluding with comprehensive, transparent, and human-verifiable scientific papers.&lt;/p&gt; 
 &lt;p&gt;Towards this goal, &lt;em&gt;data-to-paper&lt;/em&gt; systematically guides interacting LLM and rule-based agents through the conventional scientific path, from annotated data, through creating research hypotheses, conducting literature search, writing and debugging data analysis code, interpreting the results, and ultimately the step-by-step writing of a complete research paper.&lt;/p&gt; 
 &lt;p&gt;The &lt;em&gt;data-to-paper&lt;/em&gt; framework is created as a research project to understand the capacities and limitations of LLM-driven scientific research, and to develop ways of harnessing LLM to accelerate research while maintaining, and even enhancing, key scientific values, such as transparency, traceability and verifiability, and while allowing scientist to oversee and direct the process [see also: &lt;a href="https://www.nature.com/articles/d41586-023-03266-1"&gt;living guidelines&lt;/a&gt;].&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Technion-Kishony-lab/data-to-paper"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2404.17605"&gt;arXiv preprint&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=Nt_460MmM8k"&gt;Demo video&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.databerry.ai/"&gt;Databerry&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;(Pivoted to Chaindesk) No-code chatbot building&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.chaindesk.ai/_next/image?url=%2Fapp-logo-icon.png&amp;amp;w=256&amp;amp;q=75" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A super-easy no-code platform for creating AI chatbots trained on your own data&lt;/li&gt; 
  &lt;li&gt;After creating new agent, picking a model, data and other settings, they are ready to be deployed to website, Slack, Crisp, or Zapier&lt;/li&gt; 
  &lt;li&gt;Limit of agent in the free version&lt;/li&gt; 
  &lt;li&gt;Stack 
   &lt;ul&gt; 
    &lt;li&gt;Next.js&lt;/li&gt; 
    &lt;li&gt;Joy UI&lt;/li&gt; 
    &lt;li&gt;LangchainJS&lt;/li&gt; 
    &lt;li&gt;PostgreSQL&lt;/li&gt; 
    &lt;li&gt;Prisma&lt;/li&gt; 
    &lt;li&gt;Qdrant&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Streamline customer support, onboard new team members, and more&lt;/li&gt; 
    &lt;li&gt;Load data from anywhere&lt;/li&gt; 
    &lt;li&gt;No-code: User-friendly interface to manage your datastores and chat with your data&lt;/li&gt; 
    &lt;li&gt;Secured API endpoint for querying your data&lt;/li&gt; 
    &lt;li&gt;Auto sync data sources (coming soon)&lt;/li&gt; 
    &lt;li&gt;Auto generates a ChatGPT Plugin for each datastore&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.chaindesk.ai/introduction"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/FSWKj49ckX"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/gmpetrov/databerry"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/melih-unsal/DemoGPT"&gt;DemoGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generates demo of a new app (of any purpose)&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/melih-unsal/DemoGPT/raw/main/assets/banner_small.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;DemoGPT leverages the power of Language Models (LLMs) to provide fast and effective demo creation for applications.&lt;/li&gt; 
  &lt;li&gt;Automates the prototyping process, making it more efficient and saving valuable time.&lt;/li&gt; 
  &lt;li&gt;Understands and processes the given prompts to generate relevant applications.&lt;/li&gt; 
  &lt;li&gt;Integrated with LangChain for generating application code through iterative parsing of LangChain's documentation with a "Tree of Transformations" (ToT) approach.&lt;/li&gt; 
  &lt;li&gt;The roadmap for DemoGPT includes constant updates and improvements based on user feedback and real-world application, working towards refining the technology and solving the hallucination problem.&lt;/li&gt; 
  &lt;li&gt;"We are planning to introduce features that will further enhance the application generation process, making it more user-friendly and efficient."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/melih-unsal/DemoGPT"&gt;Github&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.demogpt.io/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/demo_gpt"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://demogpt.streamlit.app/"&gt;Streamlit App&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/spaces/melihunsal/demogpt"&gt;Hugging Face Space&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/jina-ai/dev-gpt"&gt;DevGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Team of virtual developers&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1684472754597142529/tyM92sRA_400x400.jpg" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Tell your AI team what microservice you want to build, and they will do it for you. Your imagination is the limit!!&lt;/li&gt; 
  &lt;li&gt;Welcome to Dev-GPT, where we bring your ideas to life with the power of advanced artificial intelligence! Our automated development team is designed to create microservices tailored to your specific needs, making your software development process seamless and efficient. Comprised of a virtual Product Manager, Developer, and DevOps, our AI team ensures that every aspect of your project is covered, from concept to deployment.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/AWXCCC6G2P"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/stitionai/devika"&gt;Devika&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agentic AI Software Engineer&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/stitionai/devika/raw/main/.assets/devika-screenshot.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, general purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Devika is an Agentic AI Software Engineer that can understand high-level human instructions, break them down into steps, research relevant information, and write code to achieve the given objective.&lt;/li&gt; 
  &lt;li&gt;Devika aims to be a competitive open-source alternative to Devin by Cognition AI.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/stitionai/devika"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/entropy-research/Devon"&gt;Devon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source Devin alternative&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, general purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Open-source alternative to Devin by Entropy research&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/entropy-research/Devon"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/kuafuai/DevOpsGPT"&gt;DevOpsGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-Driven SW Development Automation Solution&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/kuafuai/DevOpsGPT/raw/master/docs/files/intro-flow-simple.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Welcome to the AI Driven Software Development Automation Solution, abbreviated as DevOpsGPT. We combine LLM (Large Language Model) with DevOps tools to convert natural language requirements into working software. This innovative feature greatly improves development efficiency, shortens development cycles, and reduces communication costs, resulting in higher-quality software delivery.&lt;/p&gt; 
 &lt;h3&gt;Features and Benefits&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Improved development efficiency: No need for tedious requirement document writing and explanations. Users can interact directly with DevOpsGPT to quickly convert requirements into functional software.&lt;/li&gt; 
  &lt;li&gt;Shortened development cycles: The automated software development process significantly reduces delivery time, accelerating software deployment and iterations.&lt;/li&gt; 
  &lt;li&gt;Reduced communication costs: By accurately understanding user requirements, DevOpsGPT minimizes the risk of communication errors and misunderstandings, enhancing collaboration efficiency between development and business teams.&lt;/li&gt; 
  &lt;li&gt;High-quality deliverables: DevOpsGPT generates code and performs validation, ensuring the quality and reliability of the delivered software.&lt;/li&gt; 
  &lt;li&gt;[Enterprise Edition] Existing project analysis: Through AI, automatic analysis of existing project information, accurate decomposition and development of required tasks on the basis of existing projects.&lt;/li&gt; 
  &lt;li&gt;[Enterprise Edition] Professional model selection: Support language model services stronger than GPT in the professional field to better complete requirements development tasks, and support private deployment.&lt;/li&gt; 
  &lt;li&gt;[Enterprise Edition] Support more DevOps platforms: can connect with more DevOps platforms to achieve the development and deployment of the whole process.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.kuafuai.net/"&gt;Creator Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://youtu.be/IWUPbGrJQOU"&gt;Demo Video&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/dot-agent/dotagent"&gt;dotagent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Deploy agents on cloud, PCs, or mobile devices&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/133483033?s=200&amp;amp;v=4" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An agent management system that facilitates the creation of robust AI applications and experimental autonomous agents through a rich suite of developer tools.&lt;/li&gt; 
  &lt;li&gt;Enables the deployment of agents across multiple platforms including cloud, PCs, or mobile devices, and extends functionality through Python or plain English integrations.&lt;/li&gt; 
  &lt;li&gt;Advances prompt engineering with a powerful prompt compiler, offering a higher degree of control over Language Models, significantly optimizing the response generation process.&lt;/li&gt; 
  &lt;li&gt;Allows seamless export of agents into portable files for execution in any environment, along with an optional Agentbox feature for optimized computing resource management within a sandboxed environment.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=uE_fykl8AVI&amp;amp;ab_channel=FahdMirza"&gt;YouTube video&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://eidolonai.com/"&gt;Eidolon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi Agent SDK with pluggable, modular components&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.eidolonai.com/_astro/default.jKAYXmpI_ZWVg5E.webp" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms), SDK for AI apps&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Eidolon is an open source SDK for AI agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://eidolonai.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/eidolon-ai/eidolon"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/august-data/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/dave-brewster-first/"&gt;Dave Brewster - LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/ravi-nextlevelgtm/"&gt;Ravi Ramachandran - LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/lukehlalor/"&gt;Luke Lalor - LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/uilicious/english-compiler"&gt;English Compiler&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Converting markdown specs into functional code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/uilicious/english-compiler/raw/main/notes/imgs/EnglishCommand-CLI-help.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;OC AI based Compiler, for converting english based markdown specs, into functional code&lt;/li&gt; 
  &lt;li&gt;"We know that all greatâ¢ projects start with awesomeâ¢ detailed functional specifications. Which is typically written in English, or its many other spoken language alternatives.&lt;/li&gt; 
  &lt;li&gt;So what if, instead of writing code from functional specs, we simply compile it directly to code?&lt;/li&gt; 
  &lt;li&gt;Into a future, where we replace nearly everything, with just written text."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/picocreator"&gt;Creator's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://evo.ninja/"&gt;evo.ninja&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent that adapts its persona to achive tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://camo.githubusercontent.com/3333c49067bddef0b208e36e22cf6ec8066f5be1da1dc327532427a395ed8069/68747470733a2f2f6861636b6d642e696f2f5f75706c6f6164732f4279576a4c4b41686e2e706e67" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Research, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;What makes evo.ninja special is that it adapts itself in real-time, based on the tasks at hand.&lt;/li&gt; 
  &lt;li&gt;Evo utilizes pre-defined agent personas that are tailored to specific domains of tasks.&lt;/li&gt; 
  &lt;li&gt;Each iteration of evo's execution loop it will select and adopt the persona that fits the task at hand best.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://evo.ninja/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/polywrap/evo.ninja/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/r3rwh69cCa"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://fastagency.ai/latest/"&gt;FastAgency&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The fastest way to deploy multi-agent workflows&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://fastagency.ai/latest/assets/img/logo.svg?sanitize=true" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms), SDK for AI apps, Multi-agent, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"FastAgency is an open-source framework designed to accelerate the transition from prototype to production for multi-agent AI workflows.&lt;/li&gt; 
  &lt;li&gt;For developers who use the AutoGen framework, FastAgency enables you to seamlessly scale Jupyter notebook prototypes into fully functional, production-ready applications.&lt;/li&gt; 
  &lt;li&gt;With multi-framework support, a unified programming interface, and powerful API integration capabilities, FastAgency streamlines the deployment process, saving time and effort while maintaining flexibility and performance.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://fastagency.ai/latest/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/airtai/fastagency"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://flowiseai.com/"&gt;Flowise&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Low code Agent builder&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://flowiseai.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-color-high.e60de2f8.png&amp;amp;w=384&amp;amp;q=75" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms)&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Flowise is an open source low-code tool for developers to build customized LLM orchestration flow &amp;amp; AI agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://flowiseai.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/FlowiseAI/Flowise"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/FlowiseAI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/flowiseai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/amirrezasalimi/friday/"&gt;Friday&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI developer assistant for Node.js&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/amirrezasalimi/friday/raw/main/screenshot.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A developer assistant able to make whole nodejs project with unlimited prompts&lt;/li&gt; 
  &lt;li&gt;Provides a core prompt for building the foundation of your application&lt;/li&gt; 
  &lt;li&gt;Allows you to add unlimited sections, each of which is a prompt representing a specific part of your app&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Friday utilizes GPT-4 for AI assistance, but it has been tested and optimized with GPT-4-32k for improved speed and better results.&lt;/li&gt; 
    &lt;li&gt;It requires 2 small requests for your app's base and 1 request per section you provide.&lt;/li&gt; 
    &lt;li&gt;Friday employs esbuild behind the scenes for every app created by it.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Author:&lt;/strong&gt; &lt;a href="https://twitter.com/amirsalimiiii"&gt;Amirreza Salimi&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/genia-dev/GeniA"&gt;GeniA&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Engineering platform engineering AI team member&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/genia-dev/GeniA/raw/main/media/genia_title.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GeniA is able to work along side you on your production enviroment, executing tasks on your behalf in your dev &amp;amp; cloud environments, AWS/k8s/Argo/GitHub etc.&lt;/li&gt; 
  &lt;li&gt;Allows you to enhance the platform by integrating your own tools and APIs.&lt;/li&gt; 
  &lt;li&gt;Slack App Bot integration.&lt;/li&gt; 
  &lt;li&gt;Supports GPT-3.5 &amp;amp; GPT-4.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Authors: &lt;a href="https://github.com/cmpxchg16"&gt;Uri Shamay&lt;/a&gt;, &lt;a href="https://github.com/shlomsh"&gt;Shlomi Shemesh&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://godmode.space/"&gt;Godmode&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Inspired by AutoGPT and BabyAGI, with nice UI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://toolpulse.ai/wp-content/uploads/2023/11/godmode-ai.jpg" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Godmode is a project inspired by Auto-GPT and BabyAGI, conducting various kinds of tasks via nice UI&lt;/li&gt; 
  &lt;li&gt;A web platform inspired by AutoGPT and BabyAGI&lt;/li&gt; 
  &lt;li&gt;What it can do: 
   &lt;ul&gt; 
    &lt;li&gt;Order your coffee at Starbucks&lt;/li&gt; 
    &lt;li&gt;Perform market analysis&lt;/li&gt; 
    &lt;li&gt;Find and negotiate a lease&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Supports GPT-3.5 &amp;amp; GPT-4&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/FOLLGAD/Godmode-GPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/emilahlback"&gt;Emil AhlbÃ¤ck&lt;/a&gt;, &lt;a href="https://twitter.com/_Lonis_"&gt;Lonis&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/vSzCcDDwz3"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/_Lonis_/status/1646641412182536196"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/Kav-K/GPTDiscord"&gt;GPT Discord&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The ultimate AI agent integration for Discord&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://camo.githubusercontent.com/c02e68bf20c853637e8cfb02c9406bd2b3b20637ea4ed95b7d68819e94a01dfe/68747470733a2f2f692e696d6775722e636f6d2f425a644f52544c2e706e67" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Content creation, Productivity, General purpose, Discord&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GPT Discord is a robust, all-in-one GPT interface for Discord.&lt;/li&gt; 
  &lt;li&gt;GPT Discord supports everything from multi-modality image understanding, code interpretation, advanced data analysis, Q&amp;amp;A on your own documents, internet-connected chat with Wolfram Alpha and Google access, AI-moderation, image generation with DALL-E, and much more!&lt;/li&gt; 
  &lt;li&gt;Featuring code execution and environment manipulation by E2B&lt;/li&gt; 
  &lt;li&gt;&lt;img src="https://camo.githubusercontent.com/6806eb5cd7f4a14e693bc732a304f18c5413a493c92b4b73202ec3205017b9c8/68747470733a2f2f692e696d6775722e636f6d2f547366677455322e706e67" alt="image"&gt;&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported: 
   &lt;ul&gt; 
    &lt;li&gt;OpenAI models&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Kav-K/GPTDiscord"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://kaveenk.com/"&gt;Kaveen Kumarasinghe - founder of GPT Discord - website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/kaveenk/"&gt;Kaveen Kumarasinghe - founder of GPT Discord - LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://gptengineer.app/"&gt;GPT Engineer&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generates entire codebase based on a prompt&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/GDA3bYrXYAE5XDQ?format=jpg&amp;amp;name=4096x4096" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GPT Engineer is an AI agent that generates an entire codebase based on a prompt.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Model: GPT 4&lt;/li&gt; 
  &lt;li&gt;Specify your project, and the AI agent asks for clarification, and then constructs the entire code base&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt&lt;/li&gt; 
    &lt;li&gt;You can specify the "identity" of the AI agent by editing the files in the identity folder&lt;/li&gt; 
    &lt;li&gt;Editing the identity and evolving the main prompt is currently how you make the agent remember things between projects&lt;/li&gt; 
    &lt;li&gt;Each step in steps.py will have its communication history with GPT4 stored in the logs folder, and can be rerun with scripts/rerun_edited_message_logs.py&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://gptengineer.app"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/AntonOsika/gpt-engineer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/8tcDQ89Ej2"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/antonosika"&gt;Anton Osika&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Attack/status/1671165869064609792"&gt;Twitter review by @Attack&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/0xpayne/gpt-migrate"&gt;GPT Migrate&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Migrate codebase between frameworks/languages&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://opengraph.githubassets.com/678543c5159118a70ea974db32bb95b310a3fbb6ad4296e97d54335031f8df82/joshpxyne/gpt-migrate" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GOT Migrate easily migrates your codebase from one framework or language to another.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Pick from different LLMs&lt;/li&gt; 
  &lt;li&gt;Ability to allow GPT Migration to generate and run unit tests for the new codebase&lt;/li&gt; 
  &lt;li&gt;Ability to select source and target language of the migration&lt;/li&gt; 
  &lt;li&gt;Ability to customize the agent's workflow (setup -&amp;gt; migrate -&amp;gt; test)&lt;/li&gt; 
  &lt;li&gt;GPT Migrate team is working on adding &lt;a href="https://github.com/0xpayne/gpt-migrate#-benchmarks"&gt;benchmarks&lt;/a&gt; for the agent&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://gpt-migrate.com/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/joshpxyne"&gt;Josh Payne&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/joshpxyne/status/1675254164165910528"&gt;Announcement&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/Pythagora-io/gpt-pilot"&gt;GPT Pilot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Code the entire scalable app from scratch&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://techcrunch.com/wp-content/uploads/2023/08/gpt_pilot_logo.png?w=150" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GPT Pilot is an AI agent that codes the entire app as you oversee the code being written&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dev tool that writes scalable apps from scratch while the developer oversees the implementation&lt;/li&gt; 
  &lt;li&gt;A research project to see how can GPT-4 be utilized to generate fully working, production-ready, apps&lt;/li&gt; 
  &lt;li&gt;The main idea is that AI can write most of the code for an app (maybe 95%) but for the rest 5%, a developer is and will be needed until we get full AGI&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Pythagora-io/gpt-pilot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/HaqXugmxr9"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/assafelovic/gpt-researcher"&gt;GPT Researcher&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that researches entire internet on any topic&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://camo.githubusercontent.com/b3ab3e2b5612657816d64e174672498cd50027b75aa0a795833aee2ddab585b2/68747470733a2f2f636f7772697465722d696d616765732e73332e616d617a6f6e6177732e636f6d2f6172636869746563747572652e706e67" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, Science&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GPT Researcher is a GPT-based autonomous agent that does online comprehensive research on any given topic&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Can produce detailed, factual and unbiased research reports&lt;/li&gt; 
  &lt;li&gt;Offers customization options for focusing on relevant resources, outlines, and lessons&lt;/li&gt; 
  &lt;li&gt;Addresses issues of speed and determinism, offering a more stable performance and increased speed through parallelized agent work, as opposed to synchronous operation&lt;/li&gt; 
  &lt;li&gt;Inspired by AutoGPT and the Plan-and-Solve paper&lt;/li&gt; 
  &lt;li&gt;The main idea is to run "planner" and "execution" agents, whereas the planner generates questions to research, and the execution agents seek the most related information based on each generated research question&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://tavily.com/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/2pFkc83fRq"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/assaf_elovic"&gt;Assaf Elovic&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/nicepkg/gpt-runner"&gt;GPT Runner&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that converses with your files&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://repository-images.githubusercontent.com/640476297/30741f73-caac-48bc-b500-1b7d6efde4c4" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, Science&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Conversation with your files which selected by you, no embedding, no vector database!&lt;/li&gt; 
  &lt;li&gt;It's also a AI Prompt Storybook. You can use it to manage some AI preset with your team. It support any IDE and language developer. We provide cli to run web and VSCode extension, Jetbrains plugin is coming soon.&lt;/li&gt; 
  &lt;li&gt;Private first, all data is local.&lt;/li&gt; 
  &lt;li&gt;We support both OpenAI and Anthropic (Claude-2)&lt;/li&gt; 
  &lt;li&gt;It support support for multiple languages.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/nicepkg/gpt-runner"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://github.com/2214962083"&gt;Jinming Yang&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://gptswarm.org/"&gt;GPTSwarm&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Language Agents as Optimizable Graphs&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://gptswarm.org/images/gptswarm.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms), General purpose, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ð GPTSwarm is a graph-based framework for LLM-based agents, providing two high-level features: 
   &lt;ul&gt; 
    &lt;li&gt;It lets you build LLM-based agents from graphs.&lt;/li&gt; 
    &lt;li&gt;It enables the customized and automatic self-organization of agent swarms with self-improvement capabilities.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases. We unify these approaches by describing LLM-based agents as computational graphs. Each node implements a function to process multimodal data or query other LLMs. Each edge describes the information flow between operations and agents. Graphs can be recursively combined into larger composite graphs representing hierarchies of inter-agent collaboration. Our novel automatic graph optimizers (1) refine node-level LLM prompts (node optimization) and (2) improve agent orchestration by changing graph connectivity (edge optimization). Experiments demonstrate that our framework can be used to efficiently develop, integrate, and automatically improve diverse LLM agents.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://gptswarm.org/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/metauto-ai/GPTSwarm"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/MingchenZhuge"&gt;Founder's X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/kreneskyp/ix"&gt;IX&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agents building, debugging, and deploying platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/kreneskyp/ix/raw/master/ix_350.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;IX is a platform for building, debugging, and deploying collaborative Agents and cognitive workflows. -IX is a LangChain-based agent platform that includes all the tools to build and deploy fleets of agents that collaborate to complete tasks. IX is both an editor and a runtime. The editor is a no-code graph style editor for the design of agents, chains, tools, retrieval functions, and collaborative workflows.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Intuitive graph style no-code editor.&lt;/li&gt; 
  &lt;li&gt;Horizontally scaling agent worker fleet.&lt;/li&gt; 
  &lt;li&gt;Multi-user, multi-agent chat interface.&lt;/li&gt; 
  &lt;li&gt;Smart input auto-completes &lt;code&gt;@mentions&lt;/code&gt; and &lt;code&gt;{file}&lt;/code&gt; references.&lt;/li&gt; 
  &lt;li&gt;Supports Chroma and other vector databases for document search.&lt;/li&gt; 
  &lt;li&gt;Supports OpenAI API, Anthropic, PaLM, and LLama based models.&lt;/li&gt; 
  &lt;li&gt;Component library is easily extended.&lt;/li&gt; 
  &lt;li&gt;Powered by LangChain&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=hAJ8ectypas&amp;amp;list=PLR8AMvFecu1hyMHFzaehbfFcMcECMafVs"&gt;Youtube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/jtrMKxzZZQ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/kreneskyp"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/microsoft/JARVIS"&gt;JARVIS&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;System that connects LLMs with the ML community&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/microsoft/JARVIS/raw/main/hugginggpt/assets/intro.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;JARVIS is a system to connect LLMs with the ML community.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Task Planning: Using ChatGPT to analyze the requests of users to understand their intention, and disassemble them into possible solvable tasks.&lt;/li&gt; 
  &lt;li&gt;Model Selection: To solve the planned tasks, ChatGPT selects expert models hosted on Hugging Face based on their descriptions.&lt;/li&gt; 
  &lt;li&gt;Task Execution: Invokes and executes each selected model, and returns the results to ChatGPT.&lt;/li&gt; 
  &lt;li&gt;Response Generation: Use ChatGPT to integrate the prediction of all models, and generate responses.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2303.17580"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/langroid/langroid"&gt;Langroid&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi-agent framework for building LLM apps&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/langroid/langroid/raw/main/docs/assets/langroid-card-lambda-ossem-rust-1200-630.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;&lt;code&gt;Langroid&lt;/code&gt; is an intuitive, lightweight, extensible and principled Python framework to easily build LLM-powered applications. You set up Agents, equip them with optional components (LLM, vector-store and methods), assign them tasks, and have them collaboratively solve a problem by exchanging messages. This Multi-Agent paradigm is inspired by the &lt;a href="https://en.wikipedia.org/wiki/Actor_model"&gt;Actor Framework&lt;/a&gt; (but you do not need to know anything about this!).&lt;/p&gt; 
 &lt;p&gt;&lt;code&gt;Langroid&lt;/code&gt; is a fresh take on LLM app-development, where considerable thought has gone into simplifying the developer experience; it does not use &lt;code&gt;Langchain&lt;/code&gt;.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Works with most commercial/remote and open/local LLMs.&lt;/li&gt; 
  &lt;li&gt;Set up Multi-agent, multi-LLM system: use stronger LLMs for agents requiring strong reasoning and instruction-following, and delegate simpler tasks to weaker/local LLMs.&lt;/li&gt; 
  &lt;li&gt;Supports OpenAI function-calling as well as native equivalent called &lt;code&gt;ToolMessage&lt;/code&gt;, which works with LLMs that do not have built-in function-calling. Simply specify structure as a (nested) Pydantic object.&lt;/li&gt; 
  &lt;li&gt;Batteries-included: vector-databases for RAG (Retrieval-Augmented Generation), caching, logging/observability.&lt;/li&gt; 
  &lt;li&gt;Specialized agents available: &lt;code&gt;DocChatAgent&lt;/code&gt;, &lt;code&gt;SQLChatAgent&lt;/code&gt;, &lt;code&gt;TableChatAgent&lt;/code&gt; (for tabular data, e.g. csv/dataframes).&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;DocChatAgent&lt;/code&gt; handles text, PDF, Docx files/URLS, and has state-of-the art techniques for retrieval combining lexical and semantic search.&lt;/li&gt; 
  &lt;li&gt;Documentation: &lt;a href="https://langroid.github.io/langroid/"&gt;https://langroid.github.io/langroid/&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/felixbrock/lemon-agent"&gt;Lemon Agent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Plan-Validate-Solve agent for workflow automation&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/F3l2kEsXIAA0Gsm?format=jpg&amp;amp;name=large" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Lemon agent is a Plan-Validate-Solve (PVS) Agent for accurate, reliable and reproducable workflow automation&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A standalone supervised Plan and Solve Agent specialized on performing read and write operations on various tools like GitHub, HubSpot or Airtable &lt;em&gt;(ACL 2023 Paper "&lt;a href="https://arxiv.org/abs/2305.04091"&gt;Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models&lt;/a&gt;")&lt;/em&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Separation of tasks and human-in-the-loop interactions&lt;/strong&gt;: Lemon Agent is currently holding a Planner Agent and a Solver Agent to keep the agents focussed and increase accuracy. We are planning on adding additional agents real soon. In addition, Lemon Agent will ask for approval at relevant workflow steps to make sure the intended actions are executed.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Unlimited configuration options&lt;/strong&gt;: Lemon Agent gives you unlimited configuration options (see example here) when defining your workflow. For instance, you can tell Lemon Agent to ask for permission before executing a workflow step or to drop a ð§ââï¸ dad joke every time the model executes a workflow step.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;UI flexibility&lt;/strong&gt;: Build any UI on top or engage with Lemon Agent via the built-in CLI.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[Soon] Model &amp;amp; framework agnostic operations&lt;/strong&gt;: Lemon Agent is a standalone agent, but can easily be integrated into frameworks like LangChain and be used with any model.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Bonus&lt;/strong&gt;: Identify weak spots in your agentâs decision-making capabilities and move to a more deterministic behavior by further configuring your Lemon Agent workflows. &lt;strong&gt;(.html file that can be run without any additional installation)&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/fWU4rDYSxw"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/felixbrockm"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/mpaepper/llm_agents"&gt;LLM Agents&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Library for building agents, using tools, planning&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;A minimalistic library for building agents that leverage large language models to automate tasks through a loop of commands and tool integrations.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Executing Python code in a REPL environment.&lt;/li&gt; 
  &lt;li&gt;Conducting searches on Google and Hacker News.&lt;/li&gt; 
  &lt;li&gt;Iterating through a cycle of Thought, Action, Observation, and New Thought based on the output of integrated tools.&lt;/li&gt; 
  &lt;li&gt;Dynamically appending new information to the prompt for informed decision-making by the agent.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/mpaepper/llm_agents"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.paepper.com/blog/posts/intelligent-agents-guided-by-llms/"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://llmstack.ai/"&gt;LLM Stack&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;No-code platform to build LLM Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://llmstack.ai/img/logo-grayscale.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, no-code, web UI&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;LLM Stack is a no-code platform to build LLM Agents, workflows and applications with your data&lt;/li&gt; 
  &lt;li&gt;LLMStack supports all major model providers, like OpenAI, Cohere, Stability AI, Hugging Face, and more. Easily use these models to build powerful apps.&lt;/li&gt; 
  &lt;li&gt;With LLM Stack, you can build generative AI agents like AI SDRs, Research Analysts, RPA Automations etc., without writing any code. Connect agents to your internal or external tools, search the web or browse the internet with agents.&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported 
   &lt;ul&gt; 
    &lt;li&gt;OpenAI&lt;/li&gt; 
    &lt;li&gt;Cohere&lt;/li&gt; 
    &lt;li&gt;Stability AI&lt;/li&gt; 
    &lt;li&gt;Hugging Face&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://llmstack.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/trypromptly/LLMStack"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://llmstack.ai/blog"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/PromtEngineer/localGPT"&gt;Local GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Chat with documents without compromising privacy&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, Data analysis, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;LocalGPT is an open-source initiative that allows you to converse with your documents without compromising your privacy. Inspired by privateGPT, allows using your own documents as an information source&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Chat with your documents on your local device using GPT models. No data leaves your device and 100% private&lt;/li&gt; 
  &lt;li&gt;With everything running locally, you can be assured that no data ever leaves your computer&lt;/li&gt; 
  &lt;li&gt;Dive into the world of secure, local document interactions with LocalGPT&lt;/li&gt; 
  &lt;li&gt;Most of the description on readme is inspired by the original privateGPT&lt;/li&gt; 
  &lt;li&gt;Model: Vicuna-7B&lt;/li&gt; 
  &lt;li&gt;Using InstructorEmbeddings&lt;/li&gt; 
  &lt;li&gt;Both Embeddings as well as LLM will run on GPU. It also has CPU support if you do not have a GPU&lt;/li&gt; 
  &lt;li&gt;Built with Langchain&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/PromtEngineer/localGPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.reddit.com/r/LocalGPT/"&gt;Subreddit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=MlyoObdIHyo&amp;amp;ab_channel=PromptEngineering"&gt;YouTube - LocalGPT: OFFLINE CHAT FOR YOUR FILES [Installation &amp;amp; Code Walkthrough]&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/farizrahman4u/loopgpt/tree/main"&gt;Loop GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Re-implementation of AutoGPT as a Python package&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/farizrahman4u/loopgpt/raw/main/docs/assets/imgs/loopgpt_demo_pic.png?raw=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Loop GPT is a re-implementation of the popular Auto-GPT project as a proper python package, written with modularity and extensibility in mind&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Languages: Python&lt;/li&gt; 
  &lt;li&gt;Default model: GPT-3.5-turbo (also possible with GPT-4)&lt;/li&gt; 
  &lt;li&gt;Modular Auto-GPT Framework&lt;/li&gt; 
  &lt;li&gt;Plug N Play" API - Extensible and modular "Pythonic" framework, not just a command line tool&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;"Easy to add new features, integrations and custom agent capabilities, all from python code, no nasty config files!"&lt;/li&gt; 
    &lt;li&gt;"Minimal prompt overhead - Every token counts. We are continuously working on getting the best results with the least possible number of tokens."&lt;/li&gt; 
    &lt;li&gt;"Human in the Loop - Ability to "course correct" agents who go astray via human feedback."&lt;/li&gt; 
    &lt;li&gt;"Full state serialization - can save the complete state of an agent, including memory and the states of its tools to a file or python object. No external databases or vector stores required (but they are still supported)!"&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--
### Features
- "Easy to add new features, integrations and custom agent capabilities, all from python code, no nasty config files!"
- "Minimal prompt overhead - Every token counts. We are continuously working on getting the best results with the least possible number of tokens."
- "Human in the Loop - Ability to "course correct" agents who go astray via human feedback."
- "Full state serialization - can save the complete state of an agent, including memory and the states of its tools to a file or python object. No external databases or vector stores required (but they are still supported)!"

--&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/samholt/l2mac"&gt;L2MAC&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent framework able to produce large complex codebases and entire books&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/samholt/L2MAC/master/docs/public/l2mac-icon-white.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, Coding, Build your own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;L2MAC is a multi-agent generation framework that, a single input prompt can generate an extensive unbounded output, such as an entire codebase or an entire book.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;L2MAC can create near unbounded outputs that align exactly with the user input prompt over very long generation tasks&lt;/li&gt; 
  &lt;li&gt;It achieves strong empirical performance of state-of-the-art generation for large codebase tasks and is in the top 3 for the HumanEval coding global benchmark. As L2MAC can detect invalid code and failing unit tests when generating code and automatically error corrects them.&lt;/li&gt; 
  &lt;li&gt;Internally persists a complete file-store memory that enables LLM agents to read files and write to files, creating a large output over many iterations&lt;/li&gt; 
  &lt;li&gt;It can be instructed to follow an exact prompt program&lt;/li&gt; 
  &lt;li&gt;As it generates the output one part at a time, it enables an LLM with a fixed context token limit to be bypassed&lt;/li&gt; 
  &lt;li&gt;The paper, peer-reviewed and recently accepted and published at ICLR 2024, introduces L2MAC.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/samholt/l2mac"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/z27CxnwdhY"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/samianholt"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.02003"&gt;Paper - L2MAC: Large Language Model Automatic Computer for Extensive Code Generation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://maige.app"&gt;Maige&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Natural-language workflows for your GitHub repo.&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSNrQ3hXkHi0qTI-XThXwx7wA33LcAZZzLp5af6UjY0Vg&amp;amp;s" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity, Debugging, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Maige is a codebase agent that runs when new issues and pull requests come up. Its core features are labelling, assigning, and answering questions.&lt;/li&gt; 
  &lt;li&gt;Maige can search the entire codebase, spin up a sandbox to run scripts, and even write basic code.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://maige.app"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/RubricLab/maige"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=YN-y-iweZTc&amp;amp;ab_channel=TerezaTizkova"&gt;Video - testing Maige&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/building-open-source-codebase-copilot-with-code-execution-layer"&gt;Interview - founder about building Maige&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/rubriclabs"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/tedspare"&gt;Founder's X - Ted Spare&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.magickml.com/"&gt;Magick&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AIDE for creating, deploying, monetizing agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/6507b4af22875d0b8abf95a7/6507bbdc3085cf26d1e8041e_white-wm-tiny.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, SDK for agents, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Magick is an AIDE for creating, deploying, scaling, and monetizing useful AI agents, and prompt chaining.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A full suite, model agnostic AIDE for creating, deploying, scaling, and monetizing useful AI agents, and prompt chaining.&lt;/li&gt; 
  &lt;li&gt;Magick allows to build things like BabyAGI within an hour. You can watch the graph executing in real time, watch the thought process as it executes, and understand the flow.&lt;/li&gt; 
  &lt;li&gt;"Visual development of autonomous agents is incoming. We have built Magick specifically for the rapid development of cognitive architecture and scalable event-driven autonomous agents."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.magickml.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Oneirocom/Magick"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/magickml"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/7Xx5DmbJCe"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/magickml/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/mrmetaverse/"&gt;Founder's LinkedIn - Jesse Alton&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/michaelpsharpe/"&gt;Founder's LinkedIn - Michael Sharpe&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/memfreeme/memfree"&gt;MemFree&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open Source Hybrid AI Search Engine&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/memfreeme/memfree/main/frontend/public/og.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Open Source, AI Search, Build your own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Open Source Hybrid AI Search Engine, Instantly Get Accurate Answers from the Internet, Bookmarks, Notes, and Docs.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;One-Click Chrome Bookmarks Sync and Index&lt;/li&gt; 
  &lt;li&gt;Support multiple traditional search engines as source&lt;/li&gt; 
  &lt;li&gt;Self-hosted Super Fast Serverless Vector Database&lt;/li&gt; 
  &lt;li&gt;Self-hosted Super Fast Local Embedding and Rerank Service&lt;/li&gt; 
  &lt;li&gt;Full Code Open Source&lt;/li&gt; 
  &lt;li&gt;One-Click Deployment On Production&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.memfree.me/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/7QqyMSTaRq"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ahaapple2023"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.memfree.me"&gt;Website&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/cpacker/MemGPT"&gt;MemGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Memory management system, providing context to LLM&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://files.readme.io/da7f719-small-memgpt_logo_circle_nuno.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Memory management, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A system that intelligently manages different memory tiers in LLMs to effectively provide the extended context within the LLM's limited context window.&lt;/li&gt; 
  &lt;li&gt;Chat with your data - talk to your local files or SQL database&lt;/li&gt; 
  &lt;li&gt;Create perpetual chatbots with self-editing memory&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.08560"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://memgpt.readthedocs.io/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/9GEQrxmVyE"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/MemGPT"&gt;Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/biobootloader/mentat"&gt;Mentat&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Assists you with coding task from command line&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/64bad175c3f1fe8957a06faf/64bef0d57ca34f97c26b2c63_abante-ai-icon_transparent_271.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Mentat is the AI tool that assists you with any coding task, right from your command line. Unlike Copilot, Mentat coordinates edits across multiple locations and files. And unlike ChatGPT, Mentat already has the context of your project - no copy and pasting required!&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.mentat.codes/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=lODjaWclwpY"&gt;Youtube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/bio_bootloader"&gt;Bio Bootloader&lt;/a&gt; (Twitter)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/zbvd9qx9Pb"&gt;Discord Invite&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/geekan/MetaGPT"&gt;MetaGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent framework returning Design, Tasks, or Repo&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/geekan/MetaGPT/raw/main/docs/resources/MetaGPT-new-log.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, Coding, Build your own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;MetaGPT is a multi-agent framework that, given one line requirement, returns PRD, Design, Tasks, or Repo.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;MetaGPT allows to assign different roles to GPTs to form a collaborative software entity for complex tasks&lt;/li&gt; 
  &lt;li&gt;It takes a one line requirement as input and outputs user stories / competitive analysis / requirements / data structures / APIs / documents, etc.&lt;/li&gt; 
  &lt;li&gt;Internally, MetaGPT includes product managers / architects / project managers / engineers&lt;/li&gt; 
  &lt;li&gt;It provides the entire process of a software company along with carefully orchestrated SOPs. Code = SOP(Team) is the core philosophy&lt;/li&gt; 
  &lt;li&gt;The paper about LLM-based multi-agent work spushes forward the idea of autonomous agents collaborating with each other to do more than one can on its own.&lt;/li&gt; 
  &lt;li&gt;MetaGPT incorporates efficient human workflows as a meta programming approach into LLM-based multi-agent collaboration&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/geekan/MetaGPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/4WdszVjv"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/DeepWisdom2019"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2308.00352"&gt;Paper - MetaGPT: Meta Programming for Multi-Agent Collaborative Framework&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/muellerberndt/mini-agi"&gt;Mini AGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;General-purpose agent based on GPT-3.5 / GPT-4&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/muellerberndt/mini-agi/raw/main/static/mini-agi-cover.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;MiniAGI is a minimal general-purpose autonomous agent based on GPT-3.5 / GPT-4&lt;/li&gt; 
  &lt;li&gt;Can analyze stock prices, perform network security tests, create art, and order pizza&lt;/li&gt; 
  &lt;li&gt;MiniAGI is a simple autonomous agent compatible with GPT-3.5-Turbo and GPT-4&lt;/li&gt; 
  &lt;li&gt;It combines a robust prompt with a minimal set of tools, chain-of-thoughts, and short-term memory with summarization&lt;/li&gt; 
  &lt;li&gt;Capable of inner monologue and self-criticism&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/muellerberndt/mini-agi"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/composable-models/llm_multiagent_debate"&gt;Multiagent Debate&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Implementation of a paper on Multiagent Debate&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://composable-models.github.io/llm_debate/img/accuracy_small.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Multiagent Debate is an implementation of the paper "Improving Factuality and Reasoning in Language Models through Multiagent Debate".&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The paper illustrates how we may treat different instances of the same language models as a "multiagent society", where individual language model generate and critique the language generations of other instances of the language model&lt;/li&gt; 
  &lt;li&gt;The authors find that the final answer generated after such a procedure is both more factually accurate and solves reasoning questions more accurately&lt;/li&gt; 
  &lt;li&gt;Illustrating the quantitative difference between multiagent debate and single agent generation on different domains in reasoning and factual validity&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/composable-models/llm_multiagent_debate"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://composable-models.github.io/llm_debate/"&gt;Project page&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2305.14325"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/rumpfmax/Multi-GPT"&gt;Multi GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Experimental multi-agent system&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An experimental open-source attempt to make GPT-4 fully autonomous&lt;/li&gt; 
  &lt;li&gt;Multiple "expertGPTs" collaborate to perform a task&lt;/li&gt; 
  &lt;li&gt;Each with their own short and long-term memory and the ability to communicate with each other&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Set a task and watch the experts get to work.&lt;/li&gt; 
    &lt;li&gt;Internet access for searches and information gathering&lt;/li&gt; 
    &lt;li&gt;Long-Term and Short-Term memory management&lt;/li&gt; 
    &lt;li&gt;GPT-4 instances for text generation&lt;/li&gt; 
    &lt;li&gt;Access to popular websites and platforms&lt;/li&gt; 
    &lt;li&gt;File storage and summarization with GPT-3.5&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.loom.com/share/b6bec93065794eb8a47e2109697afa39"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/md_rumpf"&gt;Max Rumpf&lt;/a&gt; and &lt;a href="https://twitter.com/SigGravitas"&gt;Significant Gravitas&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/codeintegrity-ai/mutahunter"&gt;MutahunterAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;MutahunterAI: Accelerate developer productivity and code security with our open-source AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/152569327?s=48&amp;amp;v=4" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Developer tools, Software security, Multi-agent, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Use Mutahunter to generate unit tests for your codebase, that specifically target the code vulnerabilities. By targeting the exact weaknesses in the code, we boost developer productivity.&lt;/li&gt; 
  &lt;li&gt;Unlike copilots which blindly generates test cases for your code, Mutahunter makes use of our mutation testing engine to generate unit tests that specifically target the vulnerabilities in your code&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Support all major languages.&lt;/li&gt; 
    &lt;li&gt;We can be used locally or can be integrated into any CI/CD runner as part of your existing workflow&lt;/li&gt; 
    &lt;li&gt;You can use Mutahunter with your own LLM APIs for privacy.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/codeintegrity-ai/mutahunter?tab=readme-ov-file#mutahunter"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/9P5V9qmKJn"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/codeintegrity-ai/mutahunter"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/mczhuge/NLSOM"&gt;NLSOM&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Natural Language-Based Societies of Mind&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/mczhuge/NLSOM/raw/main/assets/nlsom.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Science, Multimodal, Social, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Natural Language-Based Societies of Mind - concept with societies and communities of agents&lt;/li&gt; 
  &lt;li&gt;Concept, which contains societies and communities of agents&lt;/li&gt; 
  &lt;li&gt;Agents can be either LLMs, NN-based experts, APIs and role-players. They all communicate in natural language.&lt;/li&gt; 
  &lt;li&gt;To solve tasks, these agents use a collaborative "Mindstorm" process involving mutual interviews.&lt;/li&gt; 
  &lt;li&gt;Additional components for NLSOM can be easily added in a modular way.&lt;/li&gt; 
  &lt;li&gt;"What magical trick makes us intelligent? The trick is that there is no trick. The power of intelligence stems from our vast diversity, not from any single, perfect principle." â Marvin Minsky, The Society of Mind, p. 308&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/mczhuge/NLSOM"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2305.17066.pdf"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/SchmidhuberAI"&gt;Author's X - JÃ¼rgen Schmidhuber&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/MingchenZhuge"&gt;Author's X - Mingchen Zhuge&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/xlang-ai/OpenAgents"&gt;OpenAgents&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi-agent general purpose platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/xlang-ai/OpenAgents/raw/main/pics/openagents_overview.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;OpenAgents is an Open Platform for Language Agents in the Wild, ChatGPT Plus Replica for Researchers, Developers, and General Users.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;User-centric 
   &lt;ul&gt; 
    &lt;li&gt;Chat Web UI&lt;/li&gt; 
    &lt;li&gt;Productive Agents&lt;/li&gt; 
    &lt;li&gt;Online Demo&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Fully open-sourced 
   &lt;ul&gt; 
    &lt;li&gt;Full-stack&lt;/li&gt; 
    &lt;li&gt;Easy deployment&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Extensible 
   &lt;ul&gt; 
    &lt;li&gt;LLMs&lt;/li&gt; 
    &lt;li&gt;Tools&lt;/li&gt; 
    &lt;li&gt;Agent methods&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/xlang-ai/OpenAgents"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.10634"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chat.xlang.ai/"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/agiresearch/OpenAGI"&gt;OpenAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;R&amp;amp;D agents platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/agiresearch/OpenAGI/raw/main/images/illustration.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;OpenAGI is an open-source AGI R&amp;amp;D platform that enables agents for both benchmark tasks and open-ended tasks&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Powered by various language models such as GPT-4, Vicuna, LLaMA, and Flan-T5&lt;/li&gt; 
  &lt;li&gt;Supports multi-modality tool learning and task solving such as text, image, video and audio&lt;/li&gt; 
  &lt;li&gt;Supports task decomposition into both linear task-solving plans and non-linear task-solving plans&lt;/li&gt; 
  &lt;li&gt;Allows both benchmark task solving and open-ended task solving&lt;/li&gt; 
  &lt;li&gt;Provides easy-to-use evaluation protocols to evaluate task-solving ability&lt;/li&gt; 
  &lt;li&gt;Provide Reinforcement Learning from Task Feedback (RLTF) to allow continuously self-improving agent&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/agiresearch/OpenAGI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2304.04370"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=7RaXPPXi0-Y"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/OpenDevin/OpenDevin"&gt;OpenDevin&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;OpenDevin: Code Less, Make More&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/OpenDevin/OpenDevin/raw/main/logo.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, general purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The OpenDevin project is born out of a desire to replicate, enhance, and innovate beyond the original Devin model.&lt;/li&gt; 
  &lt;li&gt;By engaging the open-source community, we aim to tackle the challenges faced by Code LLMs in practical scenarios, producing works that significantly contribute to the community and pave the way for future advancements.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OpenDevin/OpenDevin"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://openinterpreter.com/"&gt;Open Interpreter&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Code interpreter that lets LLMs execute code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://openinterpreter.com/assets/ncu_thumbnail.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Open Interpreter is an open-source interpreter that lets LLMs run code on your computer to complete tasks&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Runs locally&lt;/li&gt; 
  &lt;li&gt;Can for example summarize PDFs, visualize datasets, control your browser&lt;/li&gt; 
  &lt;li&gt;Works from a ChatGPT-like interface in your terminal.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://openinterpreter.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/KillianLucas/open-interpreter"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/hellokillian"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.pezzo.ai/"&gt;Pezzo&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Development toolkit for prompt management &amp;amp; more&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.pezzo.ai/_next/static/media/Logo.b7e3878b.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Pezzo is a development toolkit designed to streamline prompt design, version management, publishing, collaboration, troubleshooting, observability and more&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Whether you are a technical person or a stakeholder, you can use Pezzo effectively. We don't believe that AI prompts should be designed in a developer's code editor. Aside from the technical issues with this approach, it blocks productivity."&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Centralized Prompt Management: Manage all AI prompts in one place for maximum visibility and efficiency.&lt;/li&gt; 
    &lt;li&gt;Streamlined Prompt Design, Publishing &amp;amp; Versioning: Create, edit, test and publish prompts with ease.&lt;/li&gt; 
    &lt;li&gt;Observability: Access detailed prompt execution history, stats and metrics (duration, prompt cost, completion cost, etc.) for better insights.&lt;/li&gt; 
    &lt;li&gt;Troubleshooting: Effortlessly resolve issues with your prompts. Time travel to retroactively fine-tune failed prompts and commit the fix instantly.&lt;/li&gt; 
    &lt;li&gt;Cost Transparency: Gain comprehensive cost transparency across all prompts and AI models.&lt;/li&gt; 
    &lt;li&gt;Simplified Integration: Reduce code overhead by 90% by consuming your AI prompts using the Pezzo Client, regardless of the model provider.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.pezzo.ai/docs/intro.html"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/pezzolabs/pezzo"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.privategpt.io/"&gt;Private GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Tool for private interaction with your documents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/6408872e49e0944a088f17c1/640f3c6e8640895f2cbf95ba_logo%20full.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Private GPT is A tool for private interaction with documents, without a need for internet connection&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Built with LangChain, GPT4All, LlamaCpp, Chroma and SentenceTransformers&lt;/li&gt; 
  &lt;li&gt;A test project to validate the feasibility of a fully private solution for question answering using LLMs and Vector embeddings, not production ready&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/imartinez/privateGPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/topoteretes/PromethAI-Backend"&gt;PromethAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent that helps with nutrition and other goals&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/125468716?s=280&amp;amp;v=4" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Personalized AI assistant that decomposes problems, offers solutions, and lets you use Agent actions to automate your flows"&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Helps users reach a solution by decomposing their requests into categories with a set of options (cuisine -&amp;gt; European)&lt;/li&gt; 
    &lt;li&gt;Has a dynamic UX/UI that helps avoid prompting&lt;/li&gt; 
    &lt;li&gt;Voice input supported&lt;/li&gt; 
    &lt;li&gt;Provides users with results of their queries and automates actions around them&lt;/li&gt; 
    &lt;li&gt;Remembers your past preferences and uses them to optimize your choices&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Tech 
   &lt;ul&gt; 
    &lt;li&gt;Powered by Langchain, decomposable async prompts + vector DB + Redis cache&lt;/li&gt; 
    &lt;li&gt;App built with Flutter + Dart 
     &lt;ul&gt; 
      &lt;li&gt;Connected to Zapier NLP&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/topoteretes/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://prometh.ai"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/tricalt"&gt;Vasilije M&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://reactagent.io/"&gt;React Agent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source React.js Autonomous LLM Agent&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://reactagent.io/logo-dark.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h2&gt;Description&lt;/h2&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An experimental autonomous agent&lt;/li&gt; 
  &lt;li&gt;Model: GPT-4&lt;/li&gt; 
  &lt;li&gt;Purpose: Gnerate and compose React components from user stories&lt;/li&gt; 
  &lt;li&gt;Stack 
   &lt;ul&gt; 
    &lt;li&gt;React&lt;/li&gt; 
    &lt;li&gt;TailwindCSS&lt;/li&gt; 
    &lt;li&gt;Typescript&lt;/li&gt; 
    &lt;li&gt;Radix UI&lt;/li&gt; 
    &lt;li&gt;Shandcn UI&lt;/li&gt; 
    &lt;li&gt;OpenAI API&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;The agent is taking a user story text and generating and composing multiple react components to generate the relevant screens, based on atomic design principles&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Generate React Components from user stories&lt;/li&gt; 
    &lt;li&gt;Compose React Components from existing components&lt;/li&gt; 
    &lt;li&gt;Use a local design system to generate React Components&lt;/li&gt; 
    &lt;li&gt;Use React, TailwindCSS, Typescript, Radix UI, Shandcn UI&lt;/li&gt; 
    &lt;li&gt;Built with Atomic Design Principles&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;It is still experimental but very interesting results, It is completely open-sourced, looking for contributors!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h2&gt;Links&lt;/h2&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/eylonmiz/react-agent"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.reactagent.io/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/EylonMiz"&gt;Eylon Miz and&lt;/a&gt; and &lt;a href="https://twitter.com/LeeTwito"&gt;Lee Twito&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.hyperwriteai.com/self-operating-computer"&gt;Self-operating computer&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Let multimodal models operate a computer&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/63fcd79d410b22ddf397e1b8/654272554402410a71c84ab9_6405c1cabdf9c69f05b1080e_otherside_logo_symbol.webp" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Research&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Using the same inputs and outputs as a human operator, the model views the screen and decides on a series of mouse and keyboard actions to reach an objective.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.hyperwriteai.com/self-operating-computer"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OthersideAI/self-operating-computer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/smol-ai/developer"&gt;Smol developer&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Your own junior AI developer, deployed via E2B UI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://smol.ai/logo.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Smol is your own junior developer. &lt;a href="https://app.e2b.dev/agent/smol-developer/?utm_source=awesome-ai-agents"&gt;Deployed in few seconds via e2b&lt;/a&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Human-centric, coherent whole program synthesis&lt;/li&gt; 
  &lt;li&gt;Your own junior developer&lt;/li&gt; 
  &lt;li&gt;Allows to develop, debug, and decompile&lt;/li&gt; 
  &lt;li&gt;200 LOC, half english&lt;/li&gt; 
  &lt;li&gt;100k context can summarize both content and codebases&lt;/li&gt; 
  &lt;li&gt;Markdown is the best prompting DSL&lt;/li&gt; 
  &lt;li&gt;Copy and paste your errors as prompts&lt;/li&gt; 
  &lt;li&gt;Copy and paste curl output as prompts&lt;/li&gt; 
  &lt;li&gt;Write CSS animation by describing what u want&lt;/li&gt; 
  &lt;li&gt;GPT4 &amp;gt;&amp;gt;&amp;gt; GPT3.5/Anthropic Claude for codegen&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/swyx"&gt;Swyx&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=UCo7YeTy-aE"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/SmolModels"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://smol.ai/"&gt;Meme&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/stackwiseai/stackwise"&gt;Stackwise&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;VSCode extension that writes nodejs functions&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1723911660232945664/CtumfUuB_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Tool for agents, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Stackwise is a VS Code extension that writes and imports nodejs functions so that you can write code without context switching&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The open source function collection&lt;/li&gt; 
  &lt;li&gt;Explain what you want a function to do, and AI builds it.&lt;/li&gt; 
  &lt;li&gt;Stackwise is a VS Code extension that automatically writes and imports nodejs functions so that you can write code without context switching. No more hunting for documentation to integrate with APIs or back and forth with ChatGPT. Just pure functionality within your code!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/stackwiseai/stackwise"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/stackwiseai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/merwanehamadi"&gt;Founder's X - Wayne&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/silennai"&gt;Founder's X - Silen Naihin&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.superagent.sh/"&gt;Superagent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Tool that allows creating agents without coding&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://api.typedream.com/v0/document/public/b9d688ba-8f34-40e4-a24a-c62b403b402d/2YukgQsvbVkUp7u1HLsrBKCjfrO_superagent_logo_candidate_2_invisible_background_small.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, General purpose, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Superagent is not a single agent, but a tool that allows creating agents without coding&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Simplifies the configuration and deployment of LLM Agents to production&lt;/li&gt; 
  &lt;li&gt;"One of the core principals of SuperAgent is to build with any third-party dependencies to proprietary tech"&lt;/li&gt; 
  &lt;li&gt;It provides a range of features and functionalities to make it easier for developers to build, manage and deploy AI agents to production including features such as built in memory and document retrieval via vector dbs, powerful tools, webhooks, cron jobs etc.&lt;/li&gt; 
  &lt;li&gt;There are two main types of agents: action agents and plan-and-execute agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/homanp/superagent"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.superagent.sh/introduction"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/mhmJUTjW4b"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/pelaseyed"&gt;Ismail Pelaseyed&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/discussing-agents-challenges-with-ismail-pelaseyed-the-founder-of-superagent"&gt;Interview: Discussing agents' tracing, observability, and debugging with Ismail Pelaseyed, the founder of Superagent&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/ai-agents-in-2024"&gt;Blog post: What Ismail from Superagent and other developers predict for the future of AI Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://superagi.com/"&gt;SuperAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Framework to develop and deploy AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1678659510041456640/rxUIfulT_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;SuperAGI is an open-source autonomous AI framework to enable development and deployment autonomous agents&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An AI agent framework&lt;/li&gt; 
  &lt;li&gt;Open source, but infrastructure is -source&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Provision, Spawn &amp;amp; Deploy Autonomous AI Agents&lt;/li&gt; 
    &lt;li&gt;Extend Agent Capabilities with Tools&lt;/li&gt; 
    &lt;li&gt;Run Concurrent Agents Seamlessly&lt;/li&gt; 
    &lt;li&gt;Graphical User Interface&lt;/li&gt; 
    &lt;li&gt;Action Console&lt;/li&gt; 
    &lt;li&gt;Multiple Vector DBs&lt;/li&gt; 
    &lt;li&gt;Multi-Modal Agents&lt;/li&gt; 
    &lt;li&gt;Agent Trajectory Fine-Tuning&lt;/li&gt; 
    &lt;li&gt;Performance Telemetry&lt;/li&gt; 
    &lt;li&gt;Optimized Token Usage&lt;/li&gt; 
    &lt;li&gt;Agent Memory Storage&lt;/li&gt; 
    &lt;li&gt;Looping Detection Heuristics&lt;/li&gt; 
    &lt;li&gt;Concurrent Agents&lt;/li&gt; 
    &lt;li&gt;Resource Manager&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@_superagi"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/dXbRe5BHJC"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.reddit.com/r/Super_AGI/"&gt;Subreddit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/_superAGI"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/ishaanbhola"&gt;Ishaan Bhola&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/CR-Gjx/Suspicion-Agent"&gt;Suspicion Agent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Paper on imperfect information games&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/CR-Gjx/Suspicion-Agent/raw/main/figures/counterfactual.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Playing Imperfect Information Games with Theory of Mind Aware GPT-4&lt;/li&gt; 
  &lt;li&gt;The paper delves into the applicability of GPT-4's learned knowledge for imperfect information games&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/CR-Gjx/Suspicion-Agent"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2309.17277"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/spaces/cr7-gjx/Suspicion-Agent-Demo"&gt;Project demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/spaces/cr7-gjx/Suspicion-Agent-Data-Visualization"&gt;Game data replay&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/princeton-nlp/SWE-agent"&gt;SWE Agent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source Devin alternative&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/princeton-nlp/SWE-agent/raw/main/assets/swe-agent-banner.png" alt="Image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, general purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;This Devin alternative scores 12.3% on the FULL swe benchmark&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/danielhanchen/status/1775120334305607781"&gt;"An open source Devin getting 12.29% on 100% of the SWE Bench test set vs Devin's 13.84% on 25% of the test set!"&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;SWE-agent works by interacting with a specialized terminal, which allows it to: 
   &lt;ul&gt; 
    &lt;li&gt;ð Open, scroll and search through files&lt;/li&gt; 
    &lt;li&gt;âï¸ Edit specific lines w/ automatic syntax check&lt;/li&gt; 
    &lt;li&gt;ð§ª Write and execute tests&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;This custom-built interface is critical for good performance. Simply connecting an LM to a vanilla bash terminal does not work well.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/jyangballin/status/1775114448513958134"&gt;"Our key insight is that LMs require carefully designed agent-computer interfaces (similar to how humans like good UI design). E.g. When the LM messes up indentation, our editor prevents it and gives feedback."&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;SWE-agent was released by the Princeton NLP team.&lt;/li&gt; 
  &lt;li&gt;What makes SWE-agent special is that it performs almost as well as Devin on the SWE-bench.&lt;/li&gt; 
  &lt;li&gt;It is important to say that the performance &lt;a href="https://www.swebench.com/"&gt;varies&lt;/a&gt; based on the model used by the agent.&lt;/li&gt; 
  &lt;li&gt;The changes and innovations in SWE-agent compared to Devin are: 
   &lt;ul&gt; 
    &lt;li&gt;The code in SWE Agent is executed locally via Docker.&lt;/li&gt; 
    &lt;li&gt;It uses âAgent-Computer Interfaceâ (ACI) - constraining the interface makes the agent easier to use for LMs. Only a few commants are allowed: run code, look for code, edit code and submit changes to GitHub.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Any code the agent writes goes through a syntax check (linter) before being submitted. If the syntax is incorrect, the agent gets feedback and is forced to redo the code.&lt;/li&gt; 
  &lt;li&gt;The agent can only read 100 lines of code at a time, rather than the entire file. This makes it easier for the language model to understand the code.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/princeton-nlp/SWE-agent"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://swe-agent.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://swe-agent.com/demo"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/AVEFbBn2rH"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://sweep.dev/"&gt;Sweep&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Github assistant that fixes issues &amp;amp; writes code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/127925974?s=200&amp;amp;v=4" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Sweep is a Github assistant the helps fix small bugs and implement small features&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;To install, click the install button&lt;/li&gt; 
  &lt;li&gt;Then add the repository you want, make a quick ticket (e.g. writing tests)&lt;/li&gt; 
  &lt;li&gt;Prepend the ticket with "Sweep:" and let Sweep handle the rest&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/sweepai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/sweep-ai"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/sweep-founders-share-learnings-from-building-an-ai-coding-assistant"&gt;Interview: Sweep founders share learnings from building an AI coding assistant&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://sweep-ai.notion.site/Tricks-for-prompting-Sweep-3124d090f42e42a6a53618eaa88cdbf1"&gt;Tricks for prompting Sweep&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/TaxyAI/browser-extension"&gt;Taxy AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Taxy AI is a full browser automation&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/TaxyAI/browser-extension/raw/main/src/assets/img/icon-128.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Taxy uses GPT-4 to control your browser and perform repetitive actions on your behalf&lt;/li&gt; 
  &lt;li&gt;Currently it allows you to define ad-hoc instructions&lt;/li&gt; 
  &lt;li&gt;In the future it will also support saved and scheduled workflows&lt;/li&gt; 
  &lt;li&gt;Currently in an early stage with a waitlist&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/TaxyAI/browser-extension"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.google.com/forms/d/e/1FAIpQLScAFKI1fZ1cXhBmSp2HM93Jvuc8Jvrxh5iSbkKhtwKN-OHoTQ/viewform"&gt;Waitlist&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/seanpixel/Teenage-AGI/raw/main/README.md#experiments"&gt;Teenage AGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;BabyAGI-inspired agent, can recall infinite memory&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;A BabyAGI-inspired agent that can recall infinite memory, "thinks" before making action, and doesn't lose memory after being shutting down&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Model: GPT-4&lt;/li&gt; 
  &lt;li&gt;Language: Python&lt;/li&gt; 
  &lt;li&gt;Uses OpenAI and Pinecone to give memory to an AI agent and also allows it to "think" before making an action (outputting text)&lt;/li&gt; 
  &lt;li&gt;Also, just by shutting down the AI, it doesn't forget its memories since it lives on Pinecone and its memory counter saves the index that it's on&lt;/li&gt; 
  &lt;li&gt;A process that happens every time the AI is queried by the user: 
   &lt;ul&gt; 
    &lt;li&gt;AI vectorizes the query and stores it in a Pinecone Vector Database&lt;/li&gt; 
    &lt;li&gt;AI looks inside its memory and finds memories and past queries that are relevant to the current query&lt;/li&gt; 
    &lt;li&gt;AI thinks about what action to take&lt;/li&gt; 
    &lt;li&gt;AI stores the thought from Step 3&lt;/li&gt; 
    &lt;li&gt;Based on the thought from Step 3 and relevant memories from Step 2, AI generates an output&lt;/li&gt; 
    &lt;li&gt;AI stores the current query and its answer in its Pinecone vector database memory&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Created by &lt;a href="https://twitter.com/sean_pixel"&gt;@sean_pixel&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Inspired by paper &lt;a href="https://arxiv.org/abs/2304.03442"&gt;"Generative Agents: Interactive Simulacra of Human Behavior"&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/microsoft/UFO"&gt;UFO&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A UI-Focused agent on Windows OS&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/microsoft/UFO/raw/main/assets/ufo_blue.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, GUI Agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Agent by Microsoft&lt;/li&gt; 
  &lt;li&gt;UFO is a UI-Focused dual-agent framework to fulfill user requests on Windows OS by seamlessly navigating and operating within individual or spanning multiple applications.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/microsoft/UFO"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=""&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2402.07939"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://vanna.ai/"&gt;Vanna.AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Python-based AI SQL agent trained on your schema&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://vanna.ai/img/vanna.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Debugging, Code migration, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Vanna is an Open-Source Python-based AI SQL agent trained on your schema that writes complex SQL in seconds&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI-driven business intelligence assistant&lt;/li&gt; 
  &lt;li&gt;Vanna helps you generate and run accurate SQL for your database using LLMs via Retrieval-Augmented Generation&lt;/li&gt; 
  &lt;li&gt;Vanna works in two easy steps - train a RAG "model" on your data, and then ask questions which will return SQL queries that can be set up to automatically run on your database&lt;/li&gt; 
  &lt;li&gt;The Vanna Python package and the various frontend integrations are all open-source&lt;/li&gt; 
  &lt;li&gt;Vannaâs capabilities are tied to the training data you give it. More training data means better accuracy for large and complex datasets&lt;/li&gt; 
  &lt;li&gt;Your database contents are never sent to the LLM. The metadata storage layer only sees schemas, documentation, and queries&lt;/li&gt; 
  &lt;li&gt;As you use Vanna more, your model continuously improves as we augment your training data&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://vanna.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/vanna-ai/vanna"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/qUZYKHremx"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/vanna-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://vanna.ai/docs/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://voyager.minedojo.org/"&gt;Voyager&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;LLM-powered lifelong learning agent in Minecraft&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://voyager.minedojo.org/assets/images/exploration_performance.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention&lt;/li&gt; 
  &lt;li&gt;Voyager consists of three key components: 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;ol&gt; 
      &lt;li&gt;an automatic curriculum that maximizes exploration&lt;/li&gt; 
     &lt;/ol&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;ol start="2"&gt; 
      &lt;li&gt;an ever-growing skill library of executable code for storing and retrieving complex behaviors&lt;/li&gt; 
     &lt;/ol&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;ol start="3"&gt; 
      &lt;li&gt;a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement&lt;/li&gt; 
     &lt;/ol&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/MineDojo/Voyager"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2305.16291"&gt;Paper - Voyager: An Open-Ended Embodied Agent with Large Language Models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=uTg39rNMojo"&gt;YouTube video&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/DrJimFan/status/1662115266933972993"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://w3gpt.ai/"&gt;Web3 GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Write &amp;amp; deploy smart contracts to EVM blockchains&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1701486001120567296/u84M3Ruo_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Blockchain, Coding, Generating apps, Smart contract&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Write and deploy smart contracts to EVM blockchains.&lt;/li&gt; 
  &lt;li&gt;Connect wallet to manually deploy contracts, even from you old chats.&lt;/li&gt; 
  &lt;li&gt;Enable Web2/3 users to interact with blockchains without a dedicated web3 wallet using account abstraction and a gas master account.&lt;/li&gt; 
  &lt;li&gt;Leverage Chat-GPT to interact with and control Web3-GPT functionalities.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://w3gpt.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/markeljan/web3gpt?tab=readme-ov-file"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/0xmarkeljan"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/markeljan/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://theolvs.github.io/westworld/"&gt;âWestworldâ simulation&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A multi-agent environment simulation library&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://theolvs.github.io/westworld/img/cover_hq_westworld1.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;A- multi-agent simulation library, with a goal to simulate and optimize systems and environments with multiple agents interacting&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Researchers from Stanford and Google created an interactive sandbox env with 25 Gen AI agents can simulate human behavior&lt;/li&gt; 
  &lt;li&gt;They walk in the park, join for coffee at a cafe, and share news with colleagues. They demonstrated surprisingly good social&lt;/li&gt; 
  &lt;li&gt;Westworld's inspiration is drawn from Unity software and Unity ML Agents, adapted in Python&lt;/li&gt; 
  &lt;li&gt;Languages 
   &lt;ul&gt; 
    &lt;li&gt;The library is available on PyPi via pip install westworld&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/TheoLvs/westworldjs"&gt;Javascript version (being developed)&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Easy creation of Grid and non-grid environments&lt;/li&gt; 
    &lt;li&gt;Objects (Agents, Obstacles, Collectibles, Triggers)&lt;/li&gt; 
    &lt;li&gt;Subclassing of different objects to create custom objects&lt;/li&gt; 
    &lt;li&gt;Spawner to generate objects randomly in the environment&lt;/li&gt; 
    &lt;li&gt;Basic rigid body system for all objects&lt;/li&gt; 
    &lt;li&gt;Simple agent behaviors (pathfinding, wandering, random walk, fleeing, vision range)&lt;/li&gt; 
    &lt;li&gt;Automatic maze generation&lt;/li&gt; 
    &lt;li&gt;Layer integration to convert image to obstacle and snap it to a grid&lt;/li&gt; 
    &lt;li&gt;Sample simulations and sample agents for classic simulations&lt;/li&gt; 
    &lt;li&gt;Simulation visualization, replay and export (gif or video)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/TheoLvs/westworld"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://theolvs.github.io/westworld/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2304.03442"&gt;Underlying paper - Generative Agents&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;A paper simulating interactions between tens of agents&lt;/li&gt; 
  &lt;li&gt;Presenting an architecture that extends a language model to store and synthesize the agent's experiences, enabling dynamic behavior planning in an interactive sandbox environment with generative agents&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/team-openpm/workgpt"&gt;WorkGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;GPT agent framework for invoking APIs&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/card_img/1744902310336118784/AVnD3MC-?format=jpg&amp;amp;name=medium" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;WorkGPT is an agent framework in a similar fashion to AutoGPT or LangChain. You give it a directive and an array of APIs and it will converse back and forth with the AI until its directive is complete.&lt;/li&gt; 
  &lt;li&gt;For example, a directive could be to research the web for something, to crawl a website, or to order you an Uber. We support any and all APIs that can be represented with an OpenAPI file.&lt;/li&gt; 
  &lt;li&gt;WorkGPT now has OpenAI's new function invocation feature baked into it 
   &lt;ul&gt; 
    &lt;li&gt;While chaining together APIs was possible before (see AutoGPT), it was slow, expensive, and error prone&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://twitter.com/maccaw/status/1669367224694607875"&gt;The tweet announcing this feature&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/maccaw"&gt;Alex MacCaw&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.getwren.ai/"&gt;Wren&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Natural Language Interface to Your Databases&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://cdn.prod.website-files.com/65e9b9dd95692faa9f5bb1c0/65f99924ac1b1f225c356d74_logo.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;"WrenAI is an AI-powered data assistant designed to help you retrieve results and insights quickly and effortlessly, without the need for SQL coding. It's also open-source, which means you can customize and use it to suit your specific needs.&lt;/p&gt; 
 &lt;p&gt;There are four key principles that we followed when developing WrenAI:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Explainability: We made sure that every SQL query generated by WrenAI is accurate, concise, and reliable, so you can trust the results it provides.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Interoperability: WrenAI lets you query data from multiple sources, regardless of different data formats and dialects. You can enjoy a standard interface across various sources, saving you time and hassle.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Interactive Experience: Our AI-powered assistant engages users in a dialogue, helping to clarify their queries, and refine results in real-time. You can interact with WrenAI in a natural and intuitive way.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Continuous Learning: WrenAI continually learns from its interactions with users, feedback, and query history. It incorporates new patterns, information, and data structures into its LLM knowledge base, ensuring that it gets better and more accurate over time."&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.getwren.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Canner/WrenAI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/getwrenai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.getwren.ai/overview/introduction"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://blog.getwren.ai/"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/OpenBMB/XAgent"&gt;XAgent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Experimental LLM agent that solves various tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_banners/1713881934991093760/1697456782/1500x500" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;XAgent is an open-source experimental Large Language Model (LLM) driven autonomous agent that can automatically solve various tasks&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Emergence &amp;amp; Autonomy&lt;/strong&gt;: XAgent's autonomous operations transcend biases.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Safety &amp;amp; Operation&lt;/strong&gt;: Secure execution within docker environments.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Expert-Knowledge Free&lt;/strong&gt;: Effective operation without sole expert reliance.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Interface &amp;amp; Interaction&lt;/strong&gt;: Interact via a user-friendly GUI or command line, while it adapts and collaborates.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Dual-loop Mechanism&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Outer-Loop&lt;/strong&gt;: Manages plans and task refinements.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Inner-Loop&lt;/strong&gt;: Dispatch, ReACT-based execution, feedback.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Universal Language - Function Calling&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ToolAgent &amp;amp; ReACT&lt;/strong&gt;: Optimal action series for subtasks.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;ð File Editor&lt;/li&gt; 
    &lt;li&gt;ð Python Notebook&lt;/li&gt; 
    &lt;li&gt;ð Web Browser&lt;/li&gt; 
    &lt;li&gt;ð¥ï¸ Shell&lt;/li&gt; 
    &lt;li&gt;ð§© Rapid API&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/XAgentTeam"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OpenBMB/XAgent"&gt;GitHub Repository&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/zncs5aQkWZ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=QGkpd-tsFPA"&gt;Youtube Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/yeagerai/yeagerai-agent"&gt;yAgents&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Capable of designing, coding and debugging tools&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;yAgents is an Agent-Builder Agent made by Yeager.ai capable of designing, coding and debugging its own tools.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Designed to help build, prototype, and deploy AI-powered tools and agents easily and efficiently.&lt;/li&gt; 
  &lt;li&gt;Built on the LangChain framework, allowing users of any technical background to create, improve, and deploy AI agents.&lt;/li&gt; 
  &lt;li&gt;Equipped with an interactive command line interface for real-time feedback and ease of navigation.&lt;/li&gt; 
  &lt;li&gt;Features session persistent memory to ensure data preservation across multiple sessions&lt;/li&gt; 
  &lt;li&gt;Quick and easy installation via pip.&lt;/li&gt; 
  &lt;li&gt;Contributions to expand and improve yAgents are highly encouraged.&lt;/li&gt; 
  &lt;li&gt;Warnings 
   &lt;ul&gt; 
    &lt;li&gt;Requires GPT-4 API access.&lt;/li&gt; 
    &lt;li&gt;Not tested for Windows systems&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yeagerai/yeagerai-agent/?utm_source=awesome-ai-agents"&gt;GitHub Repository&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/wKds24jdAX/?utm_source=awesome-ai-agents"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yeagerai/yeagerai-agent/raw/main/LICENSE/?utm_source=awesome-ai-agents"&gt;License: MIT&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/pj4533/yourgoal/?utm_source=awesome-ai-agents"&gt;Yourgoal&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Swift implementation of BabyAGI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"This is a Swift port of BabyAGI, an example of an AI-powered task management system that uses OpenAI and Pinecone APIs to create, prioritize, and execute tasks. The main idea behind this system is that it creates tasks based on the result of previous tasks and a predefined objective."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/pj4533/?utm_source=awesome-ai-agents"&gt;PJ Gray&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;Closed-source projects and companies&lt;/h1&gt; 
&lt;h2&gt;&lt;a href="https://ability.ai/"&gt;Ability AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Secure, People-Centric Autonomous AI Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://ability.ai/assets/images/image01.svg?v=e0c18927" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Empowering Businesses with Secure, People-Centric Autonomous AI Agents&lt;/li&gt; 
  &lt;li&gt;Still in early version&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://ability.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.adept.ai/?utm_source=awesome-ai-agents"&gt;Adept AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;ML research and product lab building intelligence&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/C4E0BAQHoZ-QBmwsa0g/company-logo_200_200/0/1677107534930/adeptailabs_logo?e=1713398400&amp;amp;v=beta&amp;amp;t=ykMLRWaek147bz9BpCaLCuYFrVorWWT3iaDsrWQa6Do" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A ML research and product lab building general intelligence by enabling humans and computers to work together creatively&lt;/li&gt; 
  &lt;li&gt;An AI teammate for everyone&lt;/li&gt; 
  &lt;li&gt;"Adept is building an entirely new way to get things done. It takes your goals, in plain language, and turns them into actions on the software you use every day."&lt;/li&gt; 
  &lt;li&gt;In early stage&lt;/li&gt; 
  &lt;li&gt;"Weâre building a machine learning model that can interact with everything on your computer."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.adept.ai/?utm_source=awesome-ai-agents"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/adeptai/?utm_source=awesome-ai-agents"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.agents.inc/"&gt;AGENTS.inc&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agents for company/regulations, search&amp;amp;monitoring&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.agents.inc/wp-content/uploads/2023/08/AGENTS.inc-logo.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Science, Monitoring, General purpose, Business intelligence, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI agents for specific tasks: 
   &lt;ul&gt; 
    &lt;li&gt;Global News Radar AI Agent&lt;/li&gt; 
    &lt;li&gt;Company Identification AI Agent&lt;/li&gt; 
    &lt;li&gt;EU Policy Watch AI Agent&lt;/li&gt; 
    &lt;li&gt;Report AI Agent&lt;/li&gt; 
    &lt;li&gt;Scientific Knowledge Agent&lt;/li&gt; 
    &lt;li&gt;Patent Analysis Agent&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.agents.inc/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/agentsdotinc"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/agentsdotinc/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/c/agentsdotinc"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.facebook.com/agentsdotinc"&gt;Facebook&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/agentsinc"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://agentscale.ai/"&gt;AgentScale&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Your assistant, email writer, calendar scheduler&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/64e879914c784ca827df6d6d/6594ec15997b8276945f35a6_logo_side_white_cropped-p-500.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;AgentScale is your very own personal assistant, email writer, calendar scheduler, and internet surfer&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AgentScale is your very own AI personal assistant&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://agentscale.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/agentscale"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/agentscale-ai/about/"&gt;LInkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's web: &lt;a href="https://jetnew.io/"&gt;Jet New&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://codestory.ai/"&gt;Aide by Codestory&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI code interpreter, AI-powered mod of VSCode&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/135339264?s=200&amp;amp;v=4" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Still in early stage, new features coming soon&lt;/li&gt; 
  &lt;li&gt;Now available for JS/TS&lt;/li&gt; 
  &lt;li&gt;Can the codebase, identify the root cause, make the fix and auto-generate tests to evaluate whether the bug was resolved&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://codestory.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.codestory.ai/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/DNnh6tC9VA"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/codestoryai"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/codestory-ai/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://ailaflow.com"&gt;AilaFlow&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;No-code platform for building AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://yt3.googleusercontent.com/TkDmYBaXRvIegqkJoujtXpIlK9X5dMAjiDldAlqSHAUaekbvbYXlOaZq1DsV8neqBUZqlWAc5w=s900-c-k-c0x00ffffff-no-rj" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AilaFlow is no-code platform for building AI agents&lt;/li&gt; 
  &lt;li&gt;Use a template, adjust it using no-code editor to your needs&lt;/li&gt; 
  &lt;li&gt;Category: Productivity, Framework for building agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://ailaflow.com"&gt;AilaFlow - AI Agents No-code Platform&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's X account: &lt;a href="https://twitter.com/b4rtaz"&gt;b4rtaz&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.airkit.ai"&gt;Airkit.ai&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Platform for building, testing, deploying Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://airkit.ai/_gatsby/image/4d7db4337bbde82f2bf7ffb0e5046c81/a46b36f8203bc3f33cb41b43956d7bd2/IMG_1847.avif?u=https%3A%2F%2Flive-airkit-ai.pantheonsite.io%2Fapp%2Fuploads%2F2023%2F11%2FIMG_1847.png&amp;amp;a=w%3D480%26h%3D174%26fm%3Davif%26q%3D100&amp;amp;cd=c7e6c2e0828656c0553ba410f22d3684" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A browser based studio for managing prompts, building tools, and testing your agents.&lt;/li&gt; 
  &lt;li&gt;Built in short-term and long-term memory management&lt;/li&gt; 
  &lt;li&gt;1 click deployment. Embed anywhere with our Web SDK.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.airkit.ai"&gt;Profile of the company&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/AirkitAI"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.airplane.dev/autopilot/?utm_source=awesome-ai-agents/"&gt;Airplane Autopilot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Autopilot AI assistant of the Airplane company&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.airplane.dev/autopilot/hero/autopilot-logo.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A developer-centric approach to building internal UIs and workflows&lt;/li&gt; 
  &lt;li&gt;Turning APIs, SQL queries, and scripts into apps for the entire team&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Airplane lets you turn SQL queries, JavaScript/Python code, HTTP requests, etc into tasks&lt;/li&gt; 
    &lt;li&gt;Allows to run tasks through a no-code dashboard&lt;/li&gt; 
    &lt;li&gt;Tasks for customer support, on-call runbooks, and scheduled tasks&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.airplane.dev/?utm_source=awesome-ai-agents"&gt;Profile of the company&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.airplane.dev/?utm_source=awesome-ai-agents"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/AirplaneDev/?utm_source=awesome-ai-agents"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.airplane.dev/autopilot/?utm_source=awesome-ai-agents"&gt;They're building an AI assistant here&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.aomni.com/?utm_source=awesome-ai-agents"&gt;Aomni&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent designed for business intelligence&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.aomni.com/icons/aomni-logo-black.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Breaks down a high level research question into a step-by-step plan, and executes it&lt;/li&gt; 
  &lt;li&gt;Diverse tools, including a full web browser&lt;/li&gt; 
  &lt;li&gt;Can access internet information without the need for an API&lt;/li&gt; 
  &lt;li&gt;"We don't generate content using AI, as it can be unreliable. Instead, we extract relevant information from trusted sources, cluster and process it into a user-friendly format."&lt;/li&gt; 
  &lt;li&gt;AI-powered query planner intelligently routes and executes requests, ensuring correctness and diverse source selection&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/a367ncqEsm/?utm_source=awesome-ai-agents"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/david-zhang-from-aomni-gives-his-view-on-ai-agents"&gt;Interview: David Zhang from Aomni gives his view agents' reliability, debugging and orchestration&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://apidna.ai/"&gt;APIDNA&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multiple AI Agents for the integration of APIs.&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://apidna.ai/wp-content/uploads/2023/12/api-dna-logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Multi-agent, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"At APIDNA, we're connecting software companies to connect the world. And we're doing this with our proprietary no-code multiple Autonomous AI Agent platform, to address one of the major pain points in software development today â the integration of API endpoints."&lt;/li&gt; 
  &lt;li&gt;"Our multiple Autonomous AI Agents instantly integrate API endpoints. This simplifies and accelerates the software integration process, typically taking only three steps - and completing within minutes. A task that traditionally could take hours, days, weeks, or even months."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://apidna.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/apidna/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/timdutta-ai/"&gt;Tim D. - LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/Artisan-AI"&gt;Artisian AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agents for sales, e-mails, book keeping &amp;amp; more&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1723059970609225728/WxC0wUQ-_400x400.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;YC company&lt;/li&gt; 
  &lt;li&gt;"Creating the first human-like digital workers, called Artisans"&lt;/li&gt; 
  &lt;li&gt;Artisans are advanced human-like digital workers trained to do specific roles, who integrate alongside human teams&lt;/li&gt; 
  &lt;li&gt;They have unique faces, names, memories &amp;amp; skills, and they continuously improve once they are employed, molding to each company's needs&lt;/li&gt; 
  &lt;li&gt;The first Artisan, Ava, automates the entire outbound sales process and can be set up with a 10-minute conversation. Ava creates TCPs, prospects with her database of over 270,000,000 contacts, crafts &amp;amp; sends highly bespoke email sequences, and books meetings into your calendar. And, you can manage all features &amp;amp; settings by talking to Ava via Slack.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Artisan-AI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/GetArtisanAI"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/artisanai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/jasparcjack"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/rupertdodkins/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://tech.eu/2023/11/17/ai-startup-artisan-raises-23m-to-develop-human-like-digital-workers/"&gt;Article&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://askpandi.com/ask"&gt;Ask Pandi&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Answer engine to search and generate knowledge&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://askpandi.com/logo.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Research, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Pandi compiles your search's final stretch into a concise, distraction-free webpage.&lt;/li&gt; 
  &lt;li&gt;It offers multi-modal answers with citations from top web creators, eliminating the need for link sifting, cookie consents, or ads.&lt;/li&gt; 
  &lt;li&gt;You can use the internet as a data source, create your own library, or do both.&lt;/li&gt; 
  &lt;li&gt;You can also use Pandi in creative mode for writing or coding.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://askpandi.com/ask"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ask_pandi"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://asktosell.com/"&gt;AskToSell&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Meet autonomous AI sales agents that close deals&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/64dc76096a7dfdd761e62e16/64dc9b12f89067d1657f3103_asktosell%20transparent%20logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Sales, Build-your-own, Business intelligence, Marketing&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A web platform to deploy &amp;amp; manage autonomous AI sales agents that close small deals.&lt;/li&gt; 
  &lt;li&gt;Autonomous agents will contact your leads, qualify, prepare offers, handle objections, negotiate, and close the deal with superhuman-like performance&lt;/li&gt; 
  &lt;li&gt;AskToSell autonomously moves your leads through the pipeline. AI Sales Agents will learn about your product, contact your leads, qualify, prepare proposals, handle objections, negotiate, and close the deals.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://asktosell.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/asktosell/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/laimonasn/"&gt;Founder's LinkedIn - Laimonas Noreika&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.askyourdatabase.com/"&gt;AskYourDatabase&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Chat with SQL database, explore and visualize data&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.askyourdatabase.com/_next/image?url=%2Flogo-light.png&amp;amp;w=64&amp;amp;q=75" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Business intelligence, Productivity, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"ChatGPT for SQL"&lt;/li&gt; 
  &lt;li&gt;No SQL, Connect your database and chat with your data in ChatGPT&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.askyourdatabase.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/AZ2WnRxTD8"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/sheldon-niu-a174bb243/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.athenaintelligence.ai/"&gt;Athena Intelligence&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;24/7 Enterprise AI Data Analyst&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/6484b03566311009ccef7599/6602dcd93264ffed31406081_athena_logo_full%201.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Athena is an AI-native analytics platform designed to accelerate analytics workflows for enterprise teams.&lt;/li&gt; 
  &lt;li&gt;It offers both co-pilot and auto-pilot modes, learning users' workflows to allow for autonomous execution with confidence.&lt;/li&gt; 
  &lt;li&gt;Athena supports querying data, generating visualizations, analyzing enterprise data, and codifying workflows, making it a powerful tool for data-driven decision-making.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.athenaintelligence.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/brendongeils/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://avanz.ai/"&gt;Avanzai&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agents for portfolio risk and asset allocation&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/abZ2DpGylwpNlOcvhmiTEHLvU.png?scale-down-to=512" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis, Research, Build-your-own (agent-builing frameworks and platforms), Finance, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Avanzai helps users build autonomous AI agents that scrape news, fetch real time data and write Python code that helps them calculate risk exposures of their portfolio.&lt;/li&gt; 
  &lt;li&gt;Users can then deploy these agents to work around the clock, saving users time from doing this themselves.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://avanz.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/gmanmalena_"&gt;Founder's X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/avanzai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.bardeen.ai/"&gt;Bardeen&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agent for automating repetitive tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/v2/D560BAQEzSXhSE2SQDg/company-logo_200_200/company-logo_200_200/0/1716353067827/bardeen_logo?e=1735776000&amp;amp;v=beta&amp;amp;t=ME3uHoIaMtWAPGQAyBiVFjA4U799mmBj5pjCTjrj5eM" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Sales&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Agent for automating repetitive tasks&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.bardeen.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/bardeenai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://beam.ai/"&gt;Beam&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A wide selection of AI agents automating workflows&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/frmJOXg5roLaxUZMpGF6efXw9A.png?scale-down-to=512" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Productivity, Build-your-own (agent-builing frameworks and platforms), Business intelligence, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;End-to-end process and workflow automation with intelligent AI agents.&lt;/li&gt; 
  &lt;li&gt;With multiple B2B2C use-cases among a myriad of industries - healthcare, insurance, logistics, customer service, etc. - Beam allows businesses to customise their own automations or choose from existing agent templates to minimize the time it takes to execute complex tasks, repetitive tasks, and 100% of back office tasks.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://beam.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/join__beam"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/beam-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@beam-ai"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.blackbox.ai/"&gt;Blackbox AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Software That Builds Software&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.blackbox.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FBlackbox-Logo-4x.85cc4976.png&amp;amp;w=384&amp;amp;q=75" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;General purpose, coding, data analysis&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;BLACKBOX.AI is a coding LLM designed to transform the way we build software.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;By building BLACKBOX.AI, our goal is to:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Accelerate the pace of innovation within companies by making engineers 10X faster in building and releasing products&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Accelerate the growth in software engineers around the world and 10X the number of engineers from ~100M to 1B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.blackbox.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.runcode.ai/"&gt;Blackbox AI Code Interpreter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pypi.org/project/blackboxai/"&gt;Blackbox AI Code Interpreter in terminal&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/aiblckbx?lang=cs"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.facebook.com/blckbxai/"&gt;Facebook&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chromewebstore.google.com/detail/mcgbeeipkmelnpldkobichboakdfaeon"&gt;Chrome extension&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Written about Blackbox:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://medium.com/@blackbox.ai/blackbox-ai-vs-codium-ai-7016abb93ec0"&gt;BLACKBOX AI vs Codium AI&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/pulse/blackbox-ai-supercharging-your-coding-workflow-swarup-mukharjee-5gqbe/"&gt;Blackbox AI: Supercharging Your Coding Workflow&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/pulse/unveiling-untold-story-blackboxai-revolution-software-yaqoot-kashif-em75f/"&gt;Unveiling the Untold Story of Blackbox.ai: A Revolution in Software Quality Assurance&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.blobr.io/"&gt;Blobr&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI business assistant connected to all your tools&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/5f1ace21b47b368069989680/65cdd7ab62643c6baa204181_logo-blobr-white.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Productivity, Marketig, Sales, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Blobr is an AI assistant making sense of your business data stored in all your siloed SaaS. Reveal insights, understand variations and customer patterns without technical effort.&lt;/li&gt; 
  &lt;li&gt;Blobr helps Sales Ops, Marketing Ops and growth people to make better decisions.&lt;/li&gt; 
  &lt;li&gt;Blobr adds an intelligence layer connected to all your SaaS (Hubspot, Google Analytics, Stripe, etc.).&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.blobr.io/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Blobr_io"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/alexandre-airvault-aabaa758/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;BrainSoup&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build an AI team that works for you, on your PC&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.nurgo-software.com/images/BrainSoup/BrainSoupCard512.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity, Data analysis, Multi-agent, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Custom AI agents that remember, learn and work together.&lt;/li&gt; 
  &lt;li&gt;Local native app, for privacy and responsiveness.&lt;/li&gt; 
  &lt;li&gt;Your data fuels your AI agents without leaving your PC.&lt;/li&gt; 
  &lt;li&gt;Multimodal: your AI agents understand text, voice, and images.&lt;/li&gt; 
  &lt;li&gt;Reactive: your agents can respond to user defined events and leverage real-time data.&lt;/li&gt; 
  &lt;li&gt;Autonomous: your agents can run in the background without user intervention.&lt;/li&gt; 
  &lt;li&gt;Collaborate safely: AIs can read, write execute and share files in a sandboxed environment.&lt;/li&gt; 
  &lt;li&gt;Multi-LLM: local and cloud-based AI models can be combined for best of both worlds.&lt;/li&gt; 
  &lt;li&gt;Tinkerable &amp;amp; extensible: empower your agents with custom tools and scripts.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://help.nurgo-software.com/collection/148-brainsoup"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Nurgo"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/xt7PyCnH9S"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.broadn.io/?utm_source=awesome-ai-agents"&gt;broadn&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;No-code copilot that allows users to build AI apps&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://api.typedream.com/v0/document/public/9727d7a5-4819-4564-beac-0284be31fddc/2aOWIGcm82x5hyT6p1gN9X7cn62_broadn_logo_new.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;broadn is a no-code platform that helps non-technical people build AI products in minutes. We're faster and more flexible than traditional no-code tools through an LLM powered conversational interface and an agent architecture that automates complex backend/workflow operations&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Conversational interface&lt;/li&gt; 
    &lt;li&gt;LLM/AI model connectors (text, image models, etc)&lt;/li&gt; 
    &lt;li&gt;Create bespoke chatbots&lt;/li&gt; 
    &lt;li&gt;Render UI components&lt;/li&gt; 
    &lt;li&gt;Connect to external data via APIs&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/calindrimbau"&gt;Calin Drimbau&lt;/a&gt; and &lt;a href="https://twitter.com/vicpara"&gt;Victor Paraschiv&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/getbroadn"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://butternut.ai/"&gt;Butternut AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build fully-functioning, ready-to-launch website&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://butternut.ai/_next/image?url=%2Fimages%2Flogo%2Flogo-text.png&amp;amp;w=384&amp;amp;q=75" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Web design, Design, Coding, Marketing&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;A tool for creating a fully-functioning, ready-to-launch website in 20 seconds&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;No coding required thanks to user-friendly interface&lt;/li&gt; 
  &lt;li&gt;Full SEO optimization&lt;/li&gt; 
  &lt;li&gt;Picture Upload: Users can conveniently upload and regenerate their own pictures for unlimited customization of their profiles&lt;/li&gt; 
  &lt;li&gt;Profile Customization: Users have the flexibility to customize their profiles by hiding sections, adding social media links, and sharing contact details, allowing them to showcase their unique personality and brand&lt;/li&gt; 
  &lt;li&gt;Instant Preview: Users can instantly visualize their profile changes through a conveniently placed preview button, ensuring a quick assessment of the desired appearance&lt;/li&gt; 
  &lt;li&gt;30% Faster Speed: The app achieves an impressive 30% increase in website generation speed, providing users with a fast and efficient website building experience.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://butternut.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.b2.work/"&gt;B2 AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Autocomplete AI assistant for work&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://static.vecteezy.com/system/resources/previews/024/246/469/non_2x/advanced-ai-assistant-icon-in-illustration-vector.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Personal assistant, Business intelligence, Productivity, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;B2 is an autonomous AI assistant to help you get things done&lt;/li&gt; 
  &lt;li&gt;Share useful workflows with your team members or schedule AI-powered recurring workflows.&lt;/li&gt; 
  &lt;li&gt;Granular data-controls so your company's data doesn't end up in the wrong hands. Fully configurable role-based access.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.b2.work/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/amazng_wanderer"&gt;Founder's X - Ethan&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://chathelp.ai/"&gt;ChatHelp&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-powered Business, Work, Study Assistant&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://chathelp.ai/wp-content/uploads/chathelp_black.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Content creation, Productivity, Research, Marketig, Sales, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ð Chat with Private AI Knowledge Base - Increase daily work efficiency, by having an AI assistant, who knows everything about your business &amp;amp; competitors, your work or studies...&lt;/li&gt; 
  &lt;li&gt;ð Save time &amp;amp; money on customer support. Drive more sales, by letting AI interact with potential customers 24/7, via Website Chat Widget. Train AI with your Website data &amp;amp; other documentation!&lt;/li&gt; 
  &lt;li&gt;ð 100+ Unique AI Tools, for all your Business, Work &amp;amp; Study needs. Like, AI Writing Assistant &amp;amp; WordPress Auto Poster.&lt;/li&gt; 
  &lt;li&gt;ð Understand your customers better with AI-powered Feedback, Voting &amp;amp; Survey Widgets!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;âï¸ Supported file formats: pdf, doc, docx, ppt, pptx, xls, xlsx, csv, json, epub, mp3, jpg, jpeg, png âï¸ WordPress Plugin âï¸ Youtube Transcripts âï¸ Analyze Yelp Reviews âï¸ +175 Languages âï¸ Create an AI-powered Website Chat Widget. âï¸ Create a Custom AI-powered Knowledge Base ð Zapier, Notion, ZenDesk, Hubspot, Trello, Monday.com, Slack, Gmail &amp;amp; Google Doc. support."&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://chathelp.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ChatHelpAI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/chathelp/about/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/BK5QtfKxbB"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.facebook.com/ChatHelpAI"&gt;Facebook&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/chathelpai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.claros.so/"&gt;Claros AI Shopper&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI shopper that finds products for your taste&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.claros.so/logo-circle.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Personal assistant&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Claros is an AI personal shopper that finds you interesting products, and learns your taste over time&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Shopping Assistants for Ecom + Everyone&lt;/li&gt; 
  &lt;li&gt;Claros is an AI personal shopper that finds you cool and interesting products. It can also learn your taste over time to give you the best results possible&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.claros.so/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/so_claros"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/clarosai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/thiteanish"&gt;Founder's X - Anish&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://twitter.com/asapdar"&gt;Founder's X - Ammar Safdari&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.clay.com/learn/claygent"&gt;Claygent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that scrapes and summarize data from the web&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/61477f2c24a826836f969afe/65b22bf376c1cc60a9e0de93_img-logo-clay.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Marketig, Sales, Finance, General purpose, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Claygent is an AI web scraper that can search and browse the web to find information for you and replace a huge amount of the manual work your SDRs are doing on account research!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.clay.com/learn/claygent"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/adam-eldefrawy-8623a815a/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.codeautopilot.com/"&gt;Code Autopilot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Assistant for your project&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.codeautopilot.com/_next/static/media/logo_purple.fa331d81.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Assistant for your GitHub issues and pull requests. Create entire features and fix bugs on complex GitHub projects at a distance of a text description.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.codeautopilot.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.codeautopilot.com/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/code_autopilot"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Gsandec"&gt;Gustavo Silva - co-founder of Code Autopilot&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/fjrdomingues"&gt;FÃ¡bio ZÃ© Domingues - co-founder of Code Autopilot&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.codegen.com/"&gt;Codegen&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Solve tickets, write tests, level up your workflow&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/652ef464dd4ef344367c4fd1/652efb93dcbbba956ee773f2_Codegen%20-%20Logo%20-%20Primary%20-%20Dark%20Theme-p-500.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Codegen is an agent that allows automatically solve tickets, write tests and level up user's development workflow with the power of GPT-4.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Use-case: Coding, debugging, code migration etc.&lt;/li&gt; 
  &lt;li&gt;Models used: GPT-4&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.codegen.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Codegen"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/mathemagic1an"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://codewp.ai/"&gt;CodeWP&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agent for WordPress websites&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://codewp.ai/wp-content/uploads/2023/09/New-Icon.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Faster WordPress Development with domain-specific AI modes, tools, and features.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://codewp.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/wpai-inc/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/codewp_ai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/wpai-inc/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/codewp_ai"&gt;James LePage - founder of CodeWP&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.codium.ai/"&gt;Codium AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Coding multipurpose AI assistant for developers&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.codium.ai/wp-content/uploads/2023/01/codium-logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Generating meaningful tests for busy devs&lt;/li&gt; 
  &lt;li&gt;Exploring and analyzing your code, docstrings, comments, and by interacting with you&lt;/li&gt; 
  &lt;li&gt;Non-trivial tests (and trivial, too!) suggested right inside your IDE 
   &lt;ul&gt; 
    &lt;li&gt;Generates tests&lt;/li&gt; 
    &lt;li&gt;Covers edge cases&lt;/li&gt; 
    &lt;li&gt;Best practice, readability code suggestions&lt;/li&gt; 
    &lt;li&gt;Gives you the code explanation&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;It is free&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/CodiumAI"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/codiumai"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@Codium-AI"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/SgSxuQ65GF"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Codium-ai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://commit.dev"&gt;Commit&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Career Copilot and AI Agent for SW Developers&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://commit.dev/wp-content/uploads/2021/05/commit-logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Comprehensive job search&lt;/li&gt; 
  &lt;li&gt;Accurate job recommendations based on your skills, experience, and preferences&lt;/li&gt; 
  &lt;li&gt;AI-powered auto-applications&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CEO: &lt;a href="https://www.linkedin.com/in/gunnr"&gt;Greg Gunn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;CTO: &lt;a href="https://www.linkedin.com/in/beiercai"&gt;Beier Cai&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://cognosys.ai"&gt;Cognosys&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Web-based version of AutoGPT or BabyAGI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_banners/1646414136811855873/1704327520/1500x500" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Research&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Friendly UI for building AI agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/SullyOmarr"&gt;Sully Omarr&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/about-deployment-evaluation-and-testing-of-agents-with-sully-omar-the-ceo-of-cognosys-ai"&gt;Interview: About deployment, evaluation, and testing of agents with Sully Omar, the CEO of Cognosys AI&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://contextqa.com/"&gt;ContextQA&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agents for Software Testing&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://contextqa.com/wp-content/themes/contextQA/assets/images/cqa-logo-with-text.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Agentic AI for Complete Test Coverage&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://contextqa.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/ContextQa"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.cursor.so/"&gt;Cursor&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-powered Code Editor with VSCode-like UI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://cursor.sh/brand/logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Cursor is the AI-first Code Editor. Build software faster in an editor designed for pair-programming with AI.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.cursor.so/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/getcursor/cursor"&gt;GitHub (Issue Only)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/PJEgRywgRy"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.cykel.ai/"&gt;Cykel&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Interact with any UI, website or API&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1704063452271058944/sZEVZIqG_400x400.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Cykel is an AI co-pilot model that can interact with any UI, website or API in response to natural language commands&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Use-case: General purpose, Personal assistant (helping with daily tasks)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.cykel.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/CykelAI"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/cykelai"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/EwanCollinge"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.cognition-labs.com/introducing-devin"&gt;Devin&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The first AI software engineer&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/65cf071d26e52092bc212f6e/65ed4622397bb038560f1ef3_cropped-p-500.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Devin is in early phase now, but according to demo, it has the following capabilities:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Can learn how to use unfamiliar technologies.&lt;/li&gt; 
  &lt;li&gt;Can build and deploy apps end to end.&lt;/li&gt; 
  &lt;li&gt;Can autonomously find and fix bugs in codebases.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.cognition-labs.com/introducing-devin"&gt;Blog post&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/cognition_labs"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://diagram.com/"&gt;Diagram&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI design tools for everyone, acquired by Figma&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://uploads-ssl.webflow.com/6408bea3de5aef58b7e197d4/6408c50680c7dae0a89901a1_logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Design, Content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI-powered design tools for everything from copywriting to generating unique icons from text&lt;/li&gt; 
  &lt;li&gt;Magic Copy writes, edits, and rewrites Figma text layers so you can design with real copy&lt;/li&gt; 
  &lt;li&gt;Generating images in Figma while designing&lt;/li&gt; 
  &lt;li&gt;Magic Rename intelligently names your layers so you can spend more time designing&lt;/li&gt; 
  &lt;li&gt;Magician works right inside your favorite design tool (e.g., Figma)&lt;/li&gt; 
  &lt;li&gt;Possible to get all the latest AI design advancements + future spells in one convenient plugin&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://diagram.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://docketai.net/"&gt;Docket AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Sales Engineer for somplex B2B sales&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://cdn.prod.website-files.com/64b81d5300b4d493cead41a3/66a0a76ea06f179159040503_Docket%20Logo%201.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Sales&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Docket AI is your personal AI Sales Engineer, empowers AEs to win more.&lt;/li&gt; 
  &lt;li&gt;It provides instant sales answers, automated RFP responses, and insights from top producers.&lt;/li&gt; 
  &lt;li&gt;Powered by the Sales Knowledge Lakeâ¢, Docket unifies your companyâs sales data with genAI. Transforming sales productivity and win rates.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docketai.net/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://dosu.dev/"&gt;Dosu&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;GitHub repo AI teammate helping also with docs&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/146474245?s=200&amp;amp;v=4" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dosu is an AI teammate that lives in your github repo, helping you respond to issues, triage bugs, and build better documentation.&lt;/li&gt; 
  &lt;li&gt;Dosu responds to issues within minutes in the user's native language.&lt;/li&gt; 
  &lt;li&gt;Dosu is a wizard when it comes to documentation, even when there is none. Not only will it remind you to update your documentation and help you write it, but Dosu can also ride shotgun as you code that next big feature, answering questions about external code as if youâre sitting next to the author.&lt;/li&gt; 
  &lt;li&gt;Dosu keeps a watchful eye on open issues, resolving those that you might have missed and deprecating issues that no longer exist. Itâll even ask you if itâs not sure.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://dosu.dev/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/dosu_ai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/dosu-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/devstein/"&gt;Founder's LinkedIn - Devin Stein&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/devstein"&gt;Founder's GitHub - Devin Stein&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.getdot.ai/"&gt;Dot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Virtual assistant that help with data analytics&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/644a347ea803e322d9c0feb8/644a36f6d9f2d08386070b0d_fox_avatar_7.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dot allows to chat with your Data Warehouse (e.g. Snowflake, BigQuery, RedShift, Postgres ...) or Semantic Layer (e.g. Looker, dbt, dotML).&lt;/li&gt; 
  &lt;li&gt;Answer most business questions instantly 24/7, so data teams can focus on deep work, not on answering easy questions about dashboards&lt;/li&gt; 
  &lt;li&gt;Category: Research, Business intelligence, Data analysis&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.getdot.ai/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/sled-software/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's linkedin - &lt;a href="https://www.linkedin.com/in/radewagen/"&gt;Rick Radewagen&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://duckie.ai/"&gt;Duckie AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Team of AI SW development companions (Ducklings)&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://duckie.ai/images/duckie_logo.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Duckie AI is a platform that lets engineers manage a team of AI software development companions (Ducklings) that get their dev work done&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ducklings work with engineers to complete end-to-end feature development, from design to implementation Ducklings chat with users to define their goals, come up with engineering designs, and generate code&lt;/li&gt; 
  &lt;li&gt;Founded: 2023&lt;/li&gt; 
  &lt;li&gt;Location: San Francisco&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://duckie.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/duckie_ai"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/duckie-ai/about/"&gt;LInkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/JwQSRj9Wx2"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.ycombinator.com/companies/duckie-ai"&gt;YCombinator profile&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://ellipsis.dev/?utm_source=awesome-ai-agents"&gt;Ellipsis&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;(Previously BitBuilder) "Automated code reviews and bug fixes"&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://app.ellipsis.dev/images/ellipsis_github_logo_white_bg.png&amp;amp;w=640&amp;amp;q=75" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub, GitLab&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Create an Issue&lt;/li&gt; 
  &lt;li&gt;Approve the Implementation Plan&lt;/li&gt; 
  &lt;li&gt;Review the Pull Request&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Writing code&lt;/li&gt; 
    &lt;li&gt;Reviewing changes&lt;/li&gt; 
    &lt;li&gt;Addressing comments&lt;/li&gt; 
    &lt;li&gt;Answering questions&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.ellipsis.dev"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.ellipsis.dev/"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://encode.software"&gt;encode&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Fully autonomous AI SW engineer in early stage&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://encode.software/_next/image?url=%2Fslack2.png&amp;amp;w=1920&amp;amp;q=75" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;in alpha&lt;/li&gt; 
  &lt;li&gt;encode works with you and your team to get work done&lt;/li&gt; 
  &lt;li&gt;demo: &lt;a href="https://encode.software/demo"&gt;https://encode.software/demo&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.factory.ai/"&gt;Factory&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Coding Droids for building software end-to-end&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/644b0c1743a3f6abb4f7f149/659c69f2d6e5ba953d5aed58_t%20(1)-p-500.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;In aplha stage&lt;/li&gt; 
  &lt;li&gt;Itâs not supposed to be just another coding copilots like GitHub Copilot or Codeium, but autonomous agents capable of autonomously building software from end to end&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/matangrinberg"&gt;CEO&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.fine.dev/"&gt;Fine&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build Software with AI Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/6290be8d112ee934eeb6aaf2/64e2150d1d1c34380ec59254_logo%20white%20with%20name.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Deploy, manage, and run AI agents that serve as your virtual teammates.&lt;/li&gt; 
  &lt;li&gt;Built for teams, with organizational memory and collaboration in mind.&lt;/li&gt; 
  &lt;li&gt;Privacy oriented, we don't store your code, everything runs locally.&lt;/li&gt; 
  &lt;li&gt;Multiagent platform: Build your own custom agents.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/thisisfinedev"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/nxW8sA5yqe"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@thisisfinedev"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://fine-tuner.ai/"&gt;Fine Tuner&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;(Pivoted to Synthflow) No-code platform for agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://1a3c84454236f952546f01b263468144.cdn.bubble.io/f1704473650779x346108115281154240/gray%20logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, General purpose&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;With Fine-Tuner, you can build sophisticated, tailored AI agents at scale without any need for technical skills or coding. Just bring your data and ideas, and we'll provide the toolset you need to transform them into powerful AI solutions, capable of handling vast amounts of data and users. Take advantage of our scalable platform to meet your growing needs with ease and efficiency&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Connecting Your Chatbot to Your App&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;FineTuner.ai is a no-code AI platform that enables users to create and deploy custom AI agents and components without any coding. With an intuitive UI/UX and rapid API deployment, FineTuner.ai simplifies AI development, allowing users to focus on their unique use cases and ideas.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;4.1. Access the API tab for an overview of the required tokens and parameters to connect your chatbot to your app using REST API endpoints.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The Fine-Tuner REST API provides API endpoints for Fine-Tuner data types that allow to interact with your AI models remotely by sending and receiving JSON&lt;/li&gt; 
  &lt;li&gt;Authentication to the Fine-Tuner API is performed via HTTP Bearer Authentication&lt;/li&gt; 
  &lt;li&gt;Front end: Bubble&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/finetuner_ai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://fine-tuner.ai/resources?res=1682544317646x963647349155168300"&gt;Step-by-step guide&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/0xAlbert_S3"&gt;Author&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.fixie.ai/"&gt;Fixie&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Platform for creating LLM-powered AI apps&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1715406291349143552/-wRzF29t_400x400.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Building and managing LLM powered applications&lt;/li&gt; 
  &lt;li&gt;A cloud-based platform-as-a-service that allows developers to build smart agents that couple LLMs with back-end logic to interface to data, systems, and tools&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/fixie-ai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.fixie.ai/"&gt;Fixie Developer Portal&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.ai-jsx.com/"&gt;AI.JSX&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/fixieai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/MsKAeKF8kU"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://floodehq.com/"&gt;Floode&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Executive agent automating communication busywork&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1670794260579270658/sLUFAGGs_400x400.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Works across all your communication and work tools: emails, social media DMs, calendar, Notion, etc.&lt;/li&gt; 
  &lt;li&gt;Adapted to your work habits.&lt;/li&gt; 
  &lt;li&gt;Ask your assistant to: 
   &lt;ul&gt; 
    &lt;li&gt;Craft messages&lt;/li&gt; 
    &lt;li&gt;Auto-sort&lt;/li&gt; 
    &lt;li&gt;Auto-schedule&lt;/li&gt; 
    &lt;li&gt;Summarize, extract tasks and information&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/SarahAllali7"&gt;Sarah Allali&lt;/a&gt; and &lt;a href="https://twitter.com/Nicowcbg"&gt;Nicolas Cabrignac&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/floodehq"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/features/preview/copilot-x"&gt;GitHub Copilot X&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-powered software developer&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://techcommunity.microsoft.com/t5/image/serverpage/image-id/439603i2263F871BE5D381D/image-size/original?v=v2&amp;amp;px=-1" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI pair programmer&lt;/li&gt; 
  &lt;li&gt;Chat and terminal interfaces&lt;/li&gt; 
  &lt;li&gt;Support for pull requests&lt;/li&gt; 
  &lt;li&gt;Early adoption of OpenAIâs GPT-4&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/orgs/community/discussions/"&gt;Community&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.github.com/en"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/GitHubCopilot"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://about.gitlab.com/gitlab-duo/"&gt;GitLab Duo&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI for every step of SW development lifecycle&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://about.gitlab.com/nuxt-images/solutions/ai/duo-logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A suite of AI-powered capabilities for #DevSecOps workflows&lt;/li&gt; 
  &lt;li&gt;A toolbox of features integrated into the DevSecOps Platform to help teams across the entire software development environment become more efficient&lt;/li&gt; 
  &lt;li&gt;Examples of what GitLab Duo can do: 
   &lt;ul&gt; 
    &lt;li&gt;Planning refinement&lt;/li&gt; 
    &lt;li&gt;Security risk resolution&lt;/li&gt; 
    &lt;li&gt;CI/CD pipeline health&lt;/li&gt; 
    &lt;li&gt;Analytics charting.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/gitlab"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.gitwit.dev/"&gt;GitWit&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automate code generation with AI. In beta version&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/SmLDF79Mns070VHglJVQyuQ1A.png?scale-down-to=512" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GitWit uses a GPT-based agent to generate code and git to track changes made to files&lt;/li&gt; 
  &lt;li&gt;GitWit ties together large language models and modern developer tools&lt;/li&gt; 
  &lt;li&gt;It can spawn and modify codebases using just a single prompt&lt;/li&gt; 
  &lt;li&gt;GitWit is primarily aimed at full-stack developers, and is particularly loved by those with a learning mindsetâsuch as those learning a new stack or technology&lt;/li&gt; 
  &lt;li&gt;It is in early beta and may require some experimentation with the prompts you enter&lt;/li&gt; 
  &lt;li&gt;You are offered to choose from code bases: 
   &lt;ul&gt; 
    &lt;li&gt;React + NextJS&lt;/li&gt; 
    &lt;li&gt;Python using pip&lt;/li&gt; 
    &lt;li&gt;A Chrome extension written in JavaScript&lt;/li&gt; 
    &lt;li&gt;An AngularJS using npm.&lt;/li&gt; 
    &lt;li&gt;Custom stack&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://gocharlie.ai/"&gt;GoCharlie&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multimodal content creation autonomous agent&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://gocharlie.ai/wp-content/uploads/2023/08/gocharlie_logo_ai_2x-230x49@2x.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Content creation, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GoCharlie is a multimodal content creation autonomous agent.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/GocharlieAI"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/gocharlieai/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founders' X accounts: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://twitter.com/kostashatalis"&gt;Kostas Hatalis&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://twitter.com/BrennanWoodruff"&gt;Brennan M. Woodruff&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.graphlit.com/"&gt;Graphlit&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;API-first data platform for building apps with AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_banners/1651090820773335040/1687935300/1500x500" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Built on a serverless, cloud-native platform, Graphlit simplifies complex data workflows, including data ingestion, knowledge extraction, semantic search, alerting and application integrations.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.graphlit.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/graphlit"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/graphlit"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/WjxCHhV8Cz"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's LInkedin: &lt;a href="https://www.linkedin.com/in/kirkmarple/"&gt;Kirk Marple&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's X: &lt;a href="https://twitter.com/kirkmarple"&gt;Kirk Marple&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.graphlit.dev/getting-started/readme"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.grit.io/"&gt;Grit&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automating code migrations and dependency upgrades&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/kBmTJBFuy8F87jwrhcMkN9SRI.png?scale-down-to=512" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Grit uses machine learning and static analysis to auto-generate pull requests for cleaning up technical debt&lt;/li&gt; 
  &lt;li&gt;Users can declare how they want their code to be structured and let Grit rewrite it for them&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/getgrit/0"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/gritdotio"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.gumloop.com/"&gt;Gumloop&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automate any workflow with AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.gumloop.com/images/gumloop_logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, data analysis, general purpose, marketing, legal, sales, HR, finance, education&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;(Previously called AgentHub)&lt;/li&gt; 
  &lt;li&gt;A platform to build and host LLM powered automations&lt;/li&gt; 
  &lt;li&gt;Fuel your workspace with our growing library of nodes.&lt;/li&gt; 
  &lt;li&gt;Pass data from A to Z with drag-and-click connections. No code required.&lt;/li&gt; 
  &lt;li&gt;Run your workflow. Test in our sandbox. See results. When you're ready, share it with anyone (or no one). You control that.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.gumloop.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/gumloop_ai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/gumloop/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/xtbrafmzC7"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.gumloop.com/getting-started/introduction"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@AgentHub_Ai"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://medium.com/@max_82395"&gt;Medium blog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.gumloop.com/templates"&gt;Templates&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.heightsplatform.com/"&gt;Heights Platform&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;For course creators, community builders &amp;amp; coaches&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://yt3.googleusercontent.com/ytc/AIf8zZRVnjibds6hCRgPhxIuFs2UA7E5wIr9a6Iq69-_sw=s900-c-k-c0x00ffffff-no-rj" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Heights AI Chat can make edits to your digital products, answer support questions, and provide advice on growing your business.&lt;/li&gt; 
  &lt;li&gt;Heights AI Coach is your personal autonomous coach, helping you accomplish your unique goals 
   &lt;ul&gt; 
    &lt;li&gt;Your AI coach will ask you questions and analyze the products you create to provide you with new tasks and recommendations every week.&lt;/li&gt; 
    &lt;li&gt;Information you share with your AI Coach will never be shared with another creator's AI Coach.&lt;/li&gt; 
    &lt;li&gt;Any information submitted will never be used for AI language model training data.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.heightsplatform.com/features/ai"&gt;AI Features&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/HeightsPlatform"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://hex.tech/product/magic-ai/"&gt;Hex Magic&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI tools for doing amazing things with data&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://images.ctfassets.net/mmgv7yhaaeds/4UFip8DgC0pJEOXeNppEQS/d97b0b1916c9b298f2480c1c28460015/social-sharing-magic.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"A suite of powerful AI features meant to augment data people"&lt;/li&gt; 
  &lt;li&gt;Hex can explain and document your code&lt;/li&gt; 
  &lt;li&gt;Hex Magic features know about database schemas, past operations, and the projectâs execution graph, so they can make deeper, more insightful recommendations&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;You can see more â and sign up for the waitlist â over here.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://hex.tech/blog/magic-private-beta/"&gt;Launch post&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://heymoon.ai/"&gt;Heymoon.ai&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Keep you on top of your calendar, tasks and info&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://heymoon.ai/assets/images/image04.png?v=a3b31dce" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Personal assistant for life: to keep you on top of your calendar, tasks and information&lt;/li&gt; 
  &lt;li&gt;Currently in a beta version&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://heymoon.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.imean.ai/"&gt;iMean.AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI personal assistant that automates browser task&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.imean.ai/icon.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Daily life, Build-your-own (agent-builing frameworks and platforms)&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;iMean is the first public product that automates browser task end to end deterministically.&lt;/li&gt; 
  &lt;li&gt;Unlike existing solutions that either stuck at middle steps or output only text instructions, iMean can automate the task for you and get you real results.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.imean.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/iMeanAI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/imean-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/zyonwu"&gt;Co-founder's X(Twitter) 1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/zyonwu/"&gt;Co-founder's LinkedIn 1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/yanni-shawn-a6222318b/"&gt;Co-founder's LinkedIn 2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/zyonwu/status/1747801290368004424?s=20"&gt;Launch post&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://useinput.com/"&gt;Input&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-powered teammate that can collaborate on code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://useinput.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FlightLogo.196eccc1.png&amp;amp;w=640&amp;amp;q=75" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI assistant (or team of assistants) for coding&lt;/li&gt; 
  &lt;li&gt;Allows to invite team members to collaborate with you and AI&lt;/li&gt; 
  &lt;li&gt;Agents do the work, and push it to GitHub autonomously&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://useinput.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/useinputai"&gt;X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/blob42/Instrukt"&gt;Instrukt&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Terminal env for interacting with with AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Enables users to create and instruct modular AI agents, generate document indexes for question-answering, and attach tools to agents for enhanced functionalities.&lt;/li&gt; 
  &lt;li&gt;Facilitates coding assistance and conversational capabilities through predefined agents, along with the option to design custom agents, all within a keyboard and mouse-friendly terminal interface.&lt;/li&gt; 
  &lt;li&gt;Provides secure execution environments for agents through Docker containers, allowing for safe and private operations, along with an integrated developer console for debugging and introspection.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/blob42/Instrukt"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://invictai.io/"&gt;Invicta&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build your first team of Autonomous AI Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://invictai.io/_next/image?url=%2Fimages%2Finvicta-text-black.svg&amp;amp;w=3840&amp;amp;q=75" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms), Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Your AI autopilot, not just a co-pilot.&lt;/li&gt; 
  &lt;li&gt;In-sync Knowledge Base: Notion, Google&amp;nbsp;Drive, URLs, all file types and&amp;nbsp;more&lt;/li&gt; 
  &lt;li&gt;Self-improving: They get better with each interaction and collaboration.&lt;/li&gt; 
  &lt;li&gt;LLM Agnostic. Use the best LLMs from OpenAI, Google, Mistral, and Anthropic, etc.&lt;/li&gt; 
  &lt;li&gt;Deploy agents where your team is: Zendesk, Slack, Discord, etc.&lt;/li&gt; 
  &lt;li&gt;Cooperative AI Teams: your agents can collaborate with each other as a team to complete complex workflows&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://invictai.io/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Invicta-AI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/InvictaAI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/invicta-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://julius.ai/"&gt;Julius&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI data processing, analysis, and visualization&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1704414144798261248/PN4b_sxH_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Chat-powered data analytics and AI agents, all in a notebook interface&lt;/li&gt; 
  &lt;li&gt;Allows to answer any question about users' data with a single prompt&lt;/li&gt; 
  &lt;li&gt;An intelligent data analyst tool that interprets, analyzes, and visualizes complex data in an intuitive, user-friendly manner&lt;/li&gt; 
  &lt;li&gt;"Jupyter Notebooks on steroids"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://julius.ai/docs/chat-start-guide"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://julius.ai/use_cases"&gt;Use cases&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/JuliusAI_"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Team Twitter profiles: &lt;a href="https://twitter.com/badphilosopher"&gt;Matt Brockman&lt;/a&gt;, &lt;a href="https://twitter.com/0interestrates"&gt;rahul&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.kadoa.com/"&gt;Kadoa&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Web Scraping on Autopilot with AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.kadoa.com/images/kadoa.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Using LLMs to generate web scrapers and data processing steps on the fly that adapt to website changes.&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;No coding or browser extension required.&lt;/li&gt; 
    &lt;li&gt;The autonomous crawling agent efficiently locates the desired information on websites.&lt;/li&gt; 
    &lt;li&gt;Adaptability to website changes makes it maintenance-free&lt;/li&gt; 
    &lt;li&gt;Transforms data from multiple sources into the same structure&lt;/li&gt; 
    &lt;li&gt;Handles all clicking and scrolling automatically&lt;/li&gt; 
    &lt;li&gt;Handles proxies&lt;/li&gt; 
    &lt;li&gt;Powerful integrations&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.kadoa.com/playground"&gt;Playground&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/krebs_adrian"&gt;Adrian Krebs&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://heyjuno.co/"&gt;Juno&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-led user interviews for rich human insights&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/PobjUKj7qACciStbW7PAArGYXc.png?scale-down-to=512" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Research, Business intelligence, web UI&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Meet Juno! An AI-moderated research platform that conducts research and collects human insights. Itâs unsupervised, multilingual and autonomous. Trained by veteran researchers, Juno empowers everyone to conduct in-depth qualitative research, without prior experience.&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported 
   &lt;ul&gt; 
    &lt;li&gt;OpenAI&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://heyjuno.co/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/heyjunoco"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/heyjunoco/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/heyjunoco"&gt;Privacy overview&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://kompas.ai/"&gt;Kompas AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pick your LLM &amp;amp; build custom conversational agent&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1712005262633271296/2c9Vdj2B_400x400.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Build-your-own, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Kompas AI is an advanced AI assistant for your team.&lt;/li&gt; 
  &lt;li&gt;It's designed to assist and enhance your productivity.&lt;/li&gt; 
  &lt;li&gt;It processes multiple tasks simultaneously.&lt;/li&gt; 
  &lt;li&gt;Kompas AI outperforms ChatGPT Pro in response speed, using Microsoft Azure's OpenAI Service.&lt;/li&gt; 
  &lt;li&gt;Kompas AI offers a free trial that allows you to use the Pro version for 10 days.&lt;/li&gt; 
  &lt;li&gt;Kompas AI primarily uses the gpt-4-turbo, gpt-4-vision and gpt-3.5-turbo models, but it also supports other models like Gemini, Claude 2, and open-source models. Notably, Kompas AI features a larger context window, through gpt-4-turbo utilizing a 128K tokens Context Window that allows it to remember up to 512,000 characters of past conversation for more complex tasks.&lt;/li&gt; 
  &lt;li&gt;Kompas AI prioritizes data security. Your files are protected with strong encryption, and data in transit is safeguarded. Unused data is regularly removed from the system.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://kompas.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Kompas_AI"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/KompasAI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/kompas-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://medium.com/@Kompas.ai"&gt;Medium&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.kompas.ai/docs/kompas-ai-intro/service-introduction"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://kusho.ai/"&gt;Kusho&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent for API testing&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D560BAQFE0UatBCw0_w/company-logo_200_200/0/1702642519517/kusho_logo?e=1714003200&amp;amp;v=beta&amp;amp;t=mihS31C5JOQPva4d17sJvNj_QOS1TS9slFp4VAH16u8" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity, Debugging&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;KushoAI instantly generates and runs test suites for your APIs so you can push code effortlessly.&lt;/li&gt; 
  &lt;li&gt;Save hours of manual effort by delegating API testing to KushoAI. Unlock crash-free releases starting today.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Add a link to your Postman collection to instantly generate exhaustive test suites for each API and save hours of manual effort.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Get AI-analysed test results in a single click.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Auto-run relevant test suites at any stage of your CI/CD pipeline."&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Works on your Postman collections&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;"At KushoAI, we believe that the job of technology is to empower people. Weâre building AI agents trained for specific problems to unlock value at a pace faster than ever before."&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://kusho.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/kushoai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/kusho/?originalSubdomain=in"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://blog.kusho.ai/"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@KushoAI"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/sourabhgawande/"&gt;Sourabh Gawande - cofounder at Kusho&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/abhishek1315/"&gt;Abhishek Saikia - cofounder at Kusho&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.kwal.ai/"&gt;Kwal&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Voice Agents for Recruiting&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://static.wixstatic.com/media/d84692_0e36f4d5a7974924a68d537a0c8184f9~mv2.png/v1/fill/w_302,h_166,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/d84692_0e36f4d5a7974924a68d537a0c8184f9~mv2.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.kwal.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/Kwal_AI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/kwal/about/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.lindy.ai/"&gt;Lindy&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI assistant that can help with daily tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/63e15df811f9df22b231e58f/65473d5a31149f709f0d6c39_Group%201266.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Lindy is still in a beta version&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Lindy triages your email&lt;/li&gt; 
    &lt;li&gt;She learns from your inbox and automatically surfaces the highest-priority emails for you&lt;/li&gt; 
    &lt;li&gt;Automatic conflict handling&lt;/li&gt; 
    &lt;li&gt;Daily briefing&lt;/li&gt; 
    &lt;li&gt;Contract management&lt;/li&gt; 
    &lt;li&gt;Meeting note taking&lt;/li&gt; 
    &lt;li&gt;Summarization&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/Altimor"&gt;Flo Crivello&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://lutra.ai/"&gt;Lutra AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Platform for creating AI workflows and apps&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D4D0BAQE_KlQYa63Cbg/company-logo_200_200/0/1701917707502/lutra_ai_logo?e=1713398400&amp;amp;v=beta&amp;amp;t=-c8RMYvjM4j06XsJVx1DUJAJ336S80bWO4CSD_IHQao" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Business intelligence, Productivity, Content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A platform for creating your personal AI workflows and apps. Lutra first converses with you to understand your goals, and then writes code to produce AI workflows.&lt;/li&gt; 
  &lt;li&gt;These AI workflows are akin to specialized agents that help you with all kinds of tasks. Because these workflows are based in code, Lutra is able to securely and reliably execute them, ensuring that your data is always protected.&lt;/li&gt; 
  &lt;li&gt;Get a personalized newsletter everyday with concise summaries of news tailored to your interests.&lt;/li&gt; 
  &lt;li&gt;Have AI automatically label your incoming emails into categories you choose. Get things done!&lt;/li&gt; 
  &lt;li&gt;Collect public information about a person and the company they work for, so that you can be ready when you meet them.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://lutra.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/lutra-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Lutra_AI"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/9ZDFvRXe8V"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/vijay-vasudevan-a5062434/"&gt;Founder's LinkedIn - Vijay Vasudevan&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/jngiam/"&gt;Founder's LinkedIn - Jiquan Ngiam&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://magicloops.dev/"&gt;Magic Loops&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Personal automations made easy&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/134019091?s=200&amp;amp;v=4" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Content creation, Productivity, Build-your-own (agent-builing frameworks and platforms), SDK for AI apps, Art, Marketig, Sales, Finance, General purpose, Personal computing&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Magic Loops are the fastest way to automate (almost) anything. By combining generative AI with code, we make it easy for anyone (yes, even non-programmers!) to setup repeatable tasks and automated workflows.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://magicloops.dev/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/magicloops"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/magicloops/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/magicloopsdev"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/adam-williams-0995a949/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/jumploops"&gt;Founder's X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://makedraft.com/"&gt;Makedraft&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generate + edit HTML components with text prompts&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1719412088492445696/qoVdGYth_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity, Generating apps, Design, Content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Makedraft is an AI that generates frontend code based on your instructions. You can then copy the HTML to any project&lt;/li&gt; 
  &lt;li&gt;You can generate HTML templates with text prompts or highlight the code you want changed and instruct the AI on what to change&lt;/li&gt; 
  &lt;li&gt;Makedraft also generates Javascript, as well as Alpine.js. Vue.js is coming soon&lt;/li&gt; 
  &lt;li&gt;Makedraft will be introducing a Showcase for people to see Showcase projects. Makedraft is currently in open beta and is free to use. A Pro plan will be available soon. Users who subscribe to the Pro plan will have have their generated projects set to private by default&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://makedraft.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.makedraft.com/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/makedraft"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@makedraft"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/realdavidma"&gt;Founder's X: David Ma&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/makedraft"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://manaflow.ai/"&gt;Manaflow&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automate technical business workflows&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://bookface-images.s3.amazonaws.com/logos/5e452772f87fd93353d19538fd8f1c9f3ab9b6eb.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Coding, Workflow automation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Manaflow empowers non-technical teams to automate recurring workflows that require analyzing data, connecting APIs, and taking actions.&lt;/li&gt; 
  &lt;li&gt;Using English, you can train Manaflow agents to interface with multiple third-party apps concurrently, host custom-built APIs, conduct customer interviews, build persistent data dashboards, run custom ML models, and execute actions for your business.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://manaflow.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/manaflowai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/manaflow-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.ycombinator.com/companies/manaflow"&gt;YCombinator&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://minion.ai/"&gt;Minion AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;By creator of GitHub Copilot, in waitlist stage&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://minion.ai/img/minion-1.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;By creator of GitHub Copilot, in waitlist stage&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ai_minion"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/alexgraveley"&gt;Alex Graveley&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://multion.ai/"&gt;MultiOn&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Book a flight or order a burger with MultiOn&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1735699647744864256/jrKJWM78_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The agent runs and controls the local Google Chrome, which allows it to interact with the world/services/web apps, just like people interact with the world/services/web apps using Google Chrome&lt;/li&gt; 
  &lt;li&gt;The agent itself probably also runs locally and currently, it needs the local Google Chrome to function&lt;/li&gt; 
  &lt;li&gt;Our understanding from the demo video is that they use local code and a custom plugin in ChatGPT to control a web browser (e.g., Google Chrome). This setup enables MultiOn to perform tasks like ordering plane tickets as if a human were interacting with the browser directly&lt;/li&gt; 
  &lt;li&gt;Use cases 
   &lt;ul&gt; 
    &lt;li&gt;A lot of cool real use cases, e.g., -Sending an email fully autonomously -Posting a tweet -Sending a tweet reply to a specific person with a specific message -Sending a Facebook message to a friend -Searching for vacation rentals and check pricing for an upcoming trip -Searching for a wedding venue and starting the wedding planning process -Scheduling a car wash&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;After introducing the GPT function calling, MultiOn can call itself recursively to spawn more sub-agents&lt;/li&gt; 
  &lt;li&gt;Instead of calling multiple functions or APIs you just need one Universal Function that can interact with all services and have it call itself to accomplish more complex tasks in parallel&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/MultiON_AI"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/DivGarg9"&gt;Div Garg&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://mutable.ai/"&gt;Mutable AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-Accelerated Software Development&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://mutable.ai/Reverse-noMargin1000w-p-500.acf1588e.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;AI Autocomplete&lt;/li&gt; 
    &lt;li&gt;Production Quality Code with One Click&lt;/li&gt; 
    &lt;li&gt;Prompt driven development&lt;/li&gt; 
    &lt;li&gt;Test Generation (coming soon)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/zAwadbmuVk"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/mutableai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/mutableai/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.naut.ai/"&gt;Naut&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build your own agents. In early stage&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1643093020097609730/XmHqIOhJ_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;"Build your team of AI agents that work for you. Early access now live. Join waitlist."&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/naut_ai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://gpt.nexus/"&gt;NexusGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build AI agents in minutes, without coding&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1784129822320467968/n_9UYcHR_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Technical challenges of building AI products, Business/marketing challenges of building AI products&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;NexusGPT enables anyone to build, finetune, and integrate autonomous AI agents without touching a single line of code.&lt;/li&gt; 
  &lt;li&gt;On Nexus, you can create agents able to perform about any task you can imagine and integrate them where it matters the most for you (from your website all the way to your internal Slack channel).&lt;/li&gt; 
  &lt;li&gt;To do that, nexus provides an existing marketplace of over 1000 ready-made agents as well as over 1500 tools ready to add to your agent.&lt;/li&gt; 
  &lt;li&gt;You can also add custom knowledge (from pdf, pptx, docx, website, notion, etc.) and add it as well to your own agent to make it relevant for your own use case and business.&lt;/li&gt; 
  &lt;li&gt;Finally, once you want to deploy your agent, you can do it simply directly on your website, WhatsApp, Slack, Teams, etc. in one click."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://gpt.nexus/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/nexus_gpt"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/nexusgpt/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.hyperwriteai.com/"&gt;Otherside's AI Assistant - Hyperwrite&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Chrome extension - general purpose AI agent&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/63fcd79d410b22ddf397e1b8/654272554402410a71c84ab9_6405c1cabdf9c69f05b1080e_otherside_logo_symbol.webp" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Hyperwrite is a chrome app that can take control of your browser and complete high level tasks for you.&lt;/li&gt; 
  &lt;li&gt;AI agent that can use a web browser like a human&lt;/li&gt; 
  &lt;li&gt;"Just describe what you want it to do, and it will automatically operate Chrome to achieve your task."&lt;/li&gt; 
  &lt;li&gt;Examples of use cases: Booking flights, ordering food, researching complex topics, managing your email&lt;/li&gt; 
  &lt;li&gt;Designed to handle tasks from booking flights to conducting in-depth research, and everything in between.&lt;/li&gt; 
  &lt;li&gt;Examples of usage: 
   &lt;ul&gt; 
    &lt;li&gt;Organize Gmail inbox&lt;/li&gt; 
    &lt;li&gt;Booking a flight&lt;/li&gt; 
    &lt;li&gt;Ordering online&lt;/li&gt; 
    &lt;li&gt;Finding hire candidates&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/mattshumer_/status/1673730806865358848"&gt;Launch announcement&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/hyperwrite-ai-writing-com/kljjoeapehcmaphfcjkmbhkinoaopdnd"&gt;Google Chrome Extension&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://venturebeat.com/ai/hyperwrite-unveils-breakthrough-ai-agent-that-can-surf-the-web-like-a-human/"&gt;Article&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.phind.com/"&gt;Phind&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Personal programming and research AI assistant&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.phind.com/images/phind_v2.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, research&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Phind is an AI search engine and pair programmer&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.phind.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/S25yW8TebZ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/phindsearch"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;CEO's Twitter: &lt;a href="https://twitter.com/MichaelRoyzen"&gt;Michael Royzen&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://powerdrill.ai/"&gt;Powerdrill AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent that completes your data job 10x faster&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D4E0BAQGwWRCWd6izLg/company-logo_200_200/0/1686636701294?e=1726099200&amp;amp;v=beta&amp;amp;t=oFa1Z8ulQzNuasFcQBdrzZD8L1RJ_vjPhbbl4KXkN7g" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Productivity, Research, Marketig, Sales, Finance&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Powerdrill is an AI SaaS service centered around personal and enterprise datasets.&lt;/li&gt; 
  &lt;li&gt;Designed to unlock the full potential of your data, Powerdrill enables you to use natural language to effortlessly interact with your datasets for tasks ranging from simple Q&amp;amp;As to insightful BI analysis.&lt;/li&gt; 
  &lt;li&gt;By breaking down barriers to knowledge acquisition and data analysis, Powerdrill boosts data processing efficiency exponentially.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://powerdrill.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/powerdrillai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.powerdrill.ai/introduction"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://proficientai.com"&gt;Proficient AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Interaction APIs and SDKs for building AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.phind.com/images/phind_v2.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An end-to-end solution, with which it takes 3 minutes not weeks to get a user-facing agent up and running in your app (currently 3 SDKs including React)&lt;/li&gt; 
  &lt;li&gt;Powerful tools built into the admin dashboard and Admin API including analytics, monitoring, rate-limiting, content moderation, etc.&lt;/li&gt; 
  &lt;li&gt;minimizes or eliminates the need for custom backend infrastructure so you can focus on implementing the business logic&lt;/li&gt; 
  &lt;li&gt;Technology-agnostic solution that supports multiple LLM providers (currently 7 models from OpenAI and Anthropic) allowing you to easily switch between models with 1 click&lt;/li&gt; 
  &lt;li&gt;Ready-to-use, highly customizable and beautiful UI components rendering complex interaction trees with support for advanced features like streaming&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.proficientai.com"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/proficientai/js"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/DVbwTM8erb"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.trypromptly.com/"&gt;Promptly&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generative AI for Your Enterprise&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/64627565e0cbc380d04ed8ae/6488f9eb9992aa1dc3bc1a63_logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, no-code, web UI&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Build tailor-made generative AI agents, applications and chatbots that cater to your users' unique needs.&lt;/li&gt; 
  &lt;li&gt;Seamlessly integrate your own data and GPT-powered models without any coding experience.&lt;/li&gt; 
  &lt;li&gt;Promptly supports all major model providers, like OpenAI, Cohere, Stability AI, Hugging Face, and more. Easily use these models to build powerful apps.&lt;/li&gt; 
  &lt;li&gt;Promptly provides embeddable widgets that you can easily integrate into your website. Use these widgets to build conversational AI applications or to add a chatbot to your website.&lt;/li&gt; 
  &lt;li&gt;Import your own data and connect it to LLM models to supercharge your generative AI applications and chatbots. Promptly supports a wide variety of data sources, including Web URLs, Sitemaps, PDFs, Audio, PPTs, Google Drive, Notion imports etc&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported 
   &lt;ul&gt; 
    &lt;li&gt;OpenAI&lt;/li&gt; 
    &lt;li&gt;Cohere&lt;/li&gt; 
    &lt;li&gt;Stability AI&lt;/li&gt; 
    &lt;li&gt;Hugging Face&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.trypromptly.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/trypromptly"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/trypromptly"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/3JsEzSXspJ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/trypromptly/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@trypromptly"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://q-bot.suchica.com/"&gt;Q, ChatGPT for Slack&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI workforce on Slack for under-resourced SMEs&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://q-bot.suchica.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FDALLE_2023-01-10_QRobot.86c0521b.png&amp;amp;w=256&amp;amp;q=75" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Personal assistant, Business intelligence, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Q functions like ChatGPT, but within your workspace.&lt;/li&gt; 
  &lt;li&gt;Secure and shareable, Q won't store or learn your data.&lt;/li&gt; 
  &lt;li&gt;Unlike ChatGPT, Q can read various types of URLs and files on-demand with your input.&lt;/li&gt; 
  &lt;li&gt;Ideal for summarizing, evaluating, brainstorming ideas, self-reviewing, Q&amp;amp;A, and more.&lt;/li&gt; 
  &lt;li&gt;We also support URLs that require authentication, such as Google Workspace Apps.&lt;/li&gt; 
  &lt;li&gt;Itemize your team-specific rules, guidelines, and templates.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://q-bot.suchica.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/hiroshinishio"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/suchica/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/QBotGPT"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@q-aibot-2182/videos"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/hiroshi-nishio-084595216/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/hnishio0105"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://questflow.ai"&gt;Questflow&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Marketplace for autonomous AI workers with no-code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.aitoolsclub.com/content/images/2023/07/Screenshot-2023-07-26-184451.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Questflow is a marketplace designed for SMBs to connect with autonomous AI workers.&lt;/li&gt; 
  &lt;li&gt;Our platform enables digital workers to discover and deploy AI agents for seamless workflow automation.&lt;/li&gt; 
  &lt;li&gt;With a no-code editor, we empower digital knowledge providers to create, distribute, and monetize AI workers.&lt;/li&gt; 
  &lt;li&gt;Similar to Upwork, Questflow offers a marketplace where users can utilize AI agents to accomplish tasks across various digital workspaces.&lt;/li&gt; 
  &lt;li&gt;Creators have the opportunity to transform their specialized knowledge into AI agents, expanding their reach and generating revenue.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/questflow"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://t.me/+lAFNg26e5aA5NGNl"&gt;Telegram&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/questflow"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://rebyte.ai/"&gt;Rebyte&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A Multi ai agents builder platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1700140660702257152/xTLqugBI_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Generating apps, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A Multi ai agents builder platform built for GenAI applications.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://rebyte.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ReByteAI"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/e4AYNnFg2F"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/realchar/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/jian-cai-8611094/"&gt;Founder's LinkedIn - Jian cai&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://www.linkedin.com/in/shaunwei/"&gt;Founder's LinkedIn - Xiao(Shaun) W.&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://relevanceai.com/"&gt;Relevance AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build your AI Workforce&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://mintlify.s3-us-west-1.amazonaws.com/relevanceai/images/logo/dark.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Content creation, Productivity, Research, Build-your-own (agent-builing frameworks and platforms), Marketig, Sales, General purpose, Multi-agent, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Relevance AI is a fast platform to build and deploy AI apps &amp;amp; agents. It's the home of the AI Workforce.&lt;/li&gt; 
  &lt;li&gt;AI Workforce is a digital team you can hire to assist you in completing mundane and repetitive tasks.&lt;/li&gt; 
  &lt;li&gt;An AI Workforce consists of Agents equipped with Tools specific to your business operations crafted by domain experts.&lt;/li&gt; 
  &lt;li&gt;With Relevance, you will have the home of the AI Workforce with a single platform to create your Tools, equip them to Agents and deploy it to your organisation as a Multi-Agent System (MAS).&lt;/li&gt; 
  &lt;li&gt;Relevance supports OpenAI, Anthropic, Cohere, PaLM, and more.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://relevanceai.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/RelevanceAI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/RelevanceAI_"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/relevanceai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/JackyGKoh"&gt;Jacky Koh - X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/thedanvass"&gt;Daniel Vassilev - X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://saga.so/ai"&gt;Saga&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Digital AI assistant for notes, tasks, and tools&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://uploads-ssl.webflow.com/600abb9dfd0530004ee876c0/62bd6a08f11f1f89bb1d1170_saga-logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Generating content&lt;/li&gt; 
  &lt;li&gt;Brainstorming ideas&lt;/li&gt; 
  &lt;li&gt;Translation&lt;/li&gt; 
  &lt;li&gt;Grammer check&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://sagahq.canny.io/"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/saga_hq"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://sagacommunity.slack.com/join/shared_invite/zt-13m3lrrdt-1x6~l6sLuR8CX~4c3fWwHA#/shared-invite/email"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/cgz2mUEq7P"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.second.dev/"&gt;Second&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automated migrations and upgrades for your code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/63717dfd25366f06c3ed64cc/645dcdc2d70f00fded6f6c0b_second-logo-white.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Migrate frameworks such as Angular to React, libraries such as Redux to React Context, or languages such as JavaScript to TypeScript&lt;/li&gt; 
  &lt;li&gt;Perform major version upgrades on any number of applications, of any size&lt;/li&gt; 
  &lt;li&gt;Upgrade frameworks such as Next.js 12 to 13, libraries such as MUI 4 to 5, or languages such as Python 2 to 3&lt;/li&gt; 
  &lt;li&gt;Target users: enterprise codebases&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://second.canny.io/"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.ycombinator.com/companies/second"&gt;YCombinator&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/SecondDevHQ"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/secondhq/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/ZhYUEjsW3Z"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder: &lt;a href="https://twitter.com/ericdrowell"&gt;Eric Rowell&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.sentius.ai/"&gt;Sentius&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agent operates browser to do your tasks for you&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/65322c702cb29c000a4d7f49/65323973bde43d64e5b01d0f_logo.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Multi-agent, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Autonomous Agents for the Enterprise&lt;/li&gt; 
  &lt;li&gt;Sentius's high-load Autonomous Agents platform runs inside the company's secure perimeter, either in cloud or on-premises, and enables safe creation, deployment, and management of Enterprise Autonomous Agents&lt;/li&gt; 
  &lt;li&gt;Sentius provides an integrated suite of no-code development tools to build, test, deploy, and manage Autonomous Agents inside your organization&lt;/li&gt; 
  &lt;li&gt;Sentius offers robust and efficient Autonomous Agents for critical use cases tailored to your organization's specific needs&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.sentius.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Generative-Assistants/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/sentiusai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=amjFOO_v28Q&amp;amp;ab_channel=DanielKornev"&gt;YouTube Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/sentiusai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Team LinkedIn profiles: &lt;a href="https://www.linkedin.com/in/eugene-izhikevich/"&gt;1&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/dilyara-zharikova/"&gt;2&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/mikhail-burtsev-85a47b9/"&gt;3&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/danielkornev/"&gt;4&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://shoppal.ai"&gt;ShopPal&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI assistant, enhance shopping experience.&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1777239533094150144/a28xyvug_400x400.jpg" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Research, Ecommerce&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"ðï¸ShopPal: Your Curated AI Shopping Assistantð¥ð°ð³&lt;/li&gt; 
  &lt;li&gt;Curated AI shopping assistant, aiming to enhance and accompany your shopping experience.&lt;/li&gt; 
  &lt;li&gt;To enhance and accompany your shopping experience, ShopPal delivers summary insights, tailored recommendations, visual comparisons, and the best deals, which are all personalized just for you! "&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://shoppal.ai"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://spell.so/"&gt;Spell&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AutoGPT agents with plugins&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://spell.so/_next/static/media/logo.32731dee.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Delegate your tasks to autonomous AI agents. Transform your daily work with revolutionary and intuitive AI tools powered by GPT4"&lt;/li&gt; 
  &lt;li&gt;Access APIs like Zapier, Wolfram, etc.&lt;/li&gt; 
  &lt;li&gt;Open links&lt;/li&gt; 
  &lt;li&gt;Manipulate files&lt;/li&gt; 
  &lt;li&gt;Search web&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/rafal_makes"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://superluminal.dev"&gt;Superluminal&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI copilot to your product's data dashboard&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://superluminal.dev/176fae26858de1966f98.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Get set up in minutes with the Superluminal React component, or use the API directly for custom solutions.&lt;/li&gt; 
  &lt;li&gt;Writes Python code to answer questions and perform tasks, similar to ChatGPT + CodeInterpreter.&lt;/li&gt; 
  &lt;li&gt;Fully managed compute infrastructure for the secure execution of generated code.&lt;/li&gt; 
  &lt;li&gt;Customize the look and feel to fit your product.&lt;/li&gt; 
  &lt;li&gt;Full support for graphs, pivots and filters in addition to textual answers.&lt;/li&gt; 
  &lt;li&gt;Enable your customers to extract more value from the data already on their dashboard with meaningful answers to high-level questions.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/getluminal/"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/74930600/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://talktodata.ai/"&gt;TalktoData&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Data discovery, cleaing, analysis &amp;amp; visualization&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://talktodata.ai/hubfs/logo-transparant-04-1.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Data Analyst that works with your CSV, Excel, Goolge Sheets and SQL Databases&lt;/li&gt; 
  &lt;li&gt;AI Agent for all the data analytics needs&lt;/li&gt; 
  &lt;li&gt;Allows users to generate beautiful visualizations, followup question and refine requirements&lt;/li&gt; 
  &lt;li&gt;"ChatGPT for Data Analysis"&lt;/li&gt; 
  &lt;li&gt;A Data Analyst the never sleeps and always available(A chat away)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://talktodata.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/TalktoData"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/talktodata/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Team Twitter profiles: &lt;a href="https://twitter.com/vinodvarma24"&gt;Vinod Varma&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.taskade.com/"&gt;Taskade&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Create, train, and run custom AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.taskade.com/static_images/taskade-circle-logo-full-black.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Agent for custom tasks, automation, and workflows&lt;/li&gt; 
  &lt;li&gt;AI Generator for flowcharts, mind mapping, task management&lt;/li&gt; 
  &lt;li&gt;AI Chat Assistant and Media Q&amp;amp;A with projects, docs, and more&lt;/li&gt; 
  &lt;li&gt;Custom AI Agents: Craft AI agents with custom commands, tools, and knowledge to automate tasks&lt;/li&gt; 
  &lt;li&gt;Engage with projects and documents through a dynamic AI Chat Assistant, providing media Q&amp;amp;A and contextual support.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://taskade.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/taskade"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/taskade/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Team Twitter profiles: &lt;a href="https://twitter.com/johnxie"&gt;John Xie&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.thinkchain.ai/"&gt;ThinkChain AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Financial AI agent platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D4E0BAQGc0T7tqN-IZQ/company-logo_200_200/0/1688338143903?e=2147483647&amp;amp;v=beta&amp;amp;t=bwM2YckiHgvHaMtmYQjB6XGUT5FNtUbvFNHJvepsGu4" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Finance, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ThinkChain provides a large and growing set of advanced AI agents, e.g. 
   &lt;ul&gt; 
    &lt;li&gt;Discover agent - can access search and your Knowledge base for informed answers&lt;/li&gt; 
    &lt;li&gt;Chain of Thought agent - breaks questions into parts to be addressed independently&lt;/li&gt; 
    &lt;li&gt;Analyst agent - creates realtime financial analysis, from DCF to LBO and everything in between&lt;/li&gt; 
    &lt;li&gt;Auto Agent - can create an entire workflow from scratch&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Currently in an early access version&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.thinkchain.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder: &lt;a href="https://twitter.com/_tony_lewis"&gt;Tony Lewis&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://testdriver.ai/"&gt;Test Driver&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agent for QA in GitHub&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/in0q3dhCrmymGzApkC4KBzdpcE.png?scale-down-to=512" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity, Debugging, Testing&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"No more writing automated tests or waiting on manual testing.&lt;/li&gt; 
  &lt;li&gt;Instruct @testdriverai to test any PR with natural language.&lt;/li&gt; 
  &lt;li&gt;TestDriver will perform a test on your PR and send back video and log recording of what occurred."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://testdriver.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/sunglassesface"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/adam-eldefrawy-8623a815a/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://usetusk.ai/"&gt;Tusk&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI engineer that pushes and tests code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://usetusk.ai/tusk-logo.eed7968a.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Tusk is an AI engineer that helps product managers ship simple front-end changes fast, letting their software engineers focus on more important work&lt;/li&gt; 
  &lt;li&gt;Assign a product ticket to Tusk, and let our AI write, push, and test the code for you&lt;/li&gt; 
  &lt;li&gt;Use-cases: Coding, debugging, code migration etc.&lt;/li&gt; 
  &lt;li&gt;Tusk is a &lt;a href="https://www.ycombinator.com/companies/tusk"&gt;Y-combinator company&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://usetusk.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/apps/use-tusk"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/usetusk"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/usetusk/about/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/sohilkshirsagar"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Marcel7an"&gt;Founder's X 2&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.vortic.ai/"&gt;Vortic&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent helping Insurance Sales and Claims&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D560BAQEG1EZ0w5b_pw/company-logo_200_200/0/1710090819045/vortic_ai_logo?e=2147483647&amp;amp;v=beta&amp;amp;t=cNHAuR0hBAAO_LAhV9iNj0Ha3s8gkQkl1esp3i1RGD4" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Build-your-own (agent-builing frameworks and platforms), Sales, General purpose, Multi-agent, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Vortic wants to make it easy for the enterprises to embed the agents with the real purpose business outcomes.&lt;/li&gt; 
  &lt;li&gt;Vortic aims to provide the real time value realisation with the pre built agents embedding with their ecosystem providing customised toolkits.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.vortic.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/harshnagalla/"&gt;Co-founder's LinkedIn 1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/divyajot-singh-06b78559/"&gt;Co-founder's LinkedIn 2&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://v0.dev/"&gt;v0 by Vercel&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Get React code based on Shadcn UI &amp;amp; Tailwind CSS&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://ph-files.imgix.net/2c7b17e3-7a6d-4872-ab81-471803a924ce.png?auto=format" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;v0 is a generative user interface system by Vercel Labs powered by AI. It generates copy-and-paste friendly React code based on Shadcn UI and Tailwind CSS.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Currently in waitlist stage&lt;/li&gt; 
  &lt;li&gt;v0 generates custom components on the fly that you can copy and paste into your existing codebase&lt;/li&gt; 
  &lt;li&gt;Built on NextJS App Router&lt;/li&gt; 
  &lt;li&gt;AI by the Vercel &lt;code&gt;ai&lt;/code&gt; SDK&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://v0.dev/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/rauchg/status/1702353417375826303?s=20"&gt;X post&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://wispy.technicalmagic.ai/"&gt;Wispy&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Summarize content, compose content, create quizzes&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://wispy.technicalmagic.ai/assets/icon-white.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Wispy is a web-browsing AI assistant that can summarize content, compose content, explain things or create quizzes for topics you are learning&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Wispy is stil in Beta version&lt;/li&gt; 
  &lt;li&gt;With Wispy, you can effortlessly transform web content to perfectly suit your unique needs, all without leaving the comfort of your browser&lt;/li&gt; 
  &lt;li&gt;Chat-based AI like Llama and GPT-4 are not the only ways to incorporate AI into your life&lt;/li&gt; 
  &lt;li&gt;With Wispy, go beyond chatbots with a browser-native AI companion that makes your browsing more delightful, productive, and streamlined!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://wispy.technicalmagic.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/wispy-your-personalized-a/nbljfchpacfegmmmajcneihieeglpofc"&gt;Chrome extension&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.wordware.ai/"&gt;Wordware&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build better language model apps, fast.&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D4D0BAQFwJFfvXQ7j4A/company-logo_200_200/0/1693909474889/wordware_logo?e=1714003200&amp;amp;v=beta&amp;amp;t=65DGJQN1bRfjKhVmkWwH393y1_1L7ej8qd6yGYtmdpM" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Wordware is your all-in-one platform for deploying LLM applications.&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported 
   &lt;ul&gt; 
    &lt;li&gt;GPT-3.5&lt;/li&gt; 
    &lt;li&gt;GPT-4 Turbo&lt;/li&gt; 
    &lt;li&gt;GPT-4&lt;/li&gt; 
    &lt;li&gt;GPT-4 Vision&lt;/li&gt; 
    &lt;li&gt;MISTRAL&lt;/li&gt; 
    &lt;li&gt;MIXTRAL&lt;/li&gt; 
    &lt;li&gt;Claude instant&lt;/li&gt; 
    &lt;li&gt;Claude 2&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://x.com/bertie_ai/status/1734539295187214423?s=20"&gt;Post on X about supported models&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.wordware.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/wordware_ai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/wordware/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/filipkozera/"&gt;Filip Kozera - founder at Wordware&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://workhub.ai/"&gt;WorkBot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The Only AI Platform you will ever need!&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://workhub.ai/wp-content/uploads/2023/05/workhub-logo-horizontal.png" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Science, Productivity, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"A privacy-centric Conversational AI platform leveraging AI Agents, Commercial and Opensource LLM support to centralize knowledge, thereby enriching collaboration and facilitating streamlined automation.&lt;/li&gt; 
  &lt;li&gt;WorkHub empowers users with versatile conversational bots and tools that provide insights, knowledge, and data-driven actions.&lt;/li&gt; 
  &lt;li&gt;With seamless integration capabilities, Workhub can be connected to any database and applications, ensuring comprehensive access to information."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://workhub.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/workhub-official/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/WorkHubOfficiaI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://zapier.com/central"&gt;Zapier Central&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Work hand in hand with AI bots&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://bot-templates-dbuh9gyx1.vercel.zapier-deployment.com/_next/static/media/logo-color.9fac53e4.svg?sanitize=true" alt="image"&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, Productivity, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Zapier Central is an experimental AI workspace where you can teach bots to work across 6,000+ apps.&lt;/li&gt; 
  &lt;li&gt;Features: 
   &lt;ul&gt; 
    &lt;li&gt;Give your bot access to your company's source of truth to get instant answers.&lt;/li&gt; 
    &lt;li&gt;Ask bots to act in 6,000+ apps&lt;/li&gt; 
    &lt;li&gt;Central runs on Zapier's ecosystem to help you automate the tools you already use.&lt;/li&gt; 
    &lt;li&gt;Teach your bot once, then watch it workâeven when you're not around.&lt;/li&gt; 
    &lt;li&gt;Everything in one workspace&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://zapier.com/central"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;span&gt;â´&lt;/span&gt; AI apps &amp;amp; agents with sandbox integration or native support&lt;/h2&gt; 
&lt;h3&gt;&lt;span&gt;â´&lt;/span&gt; &lt;a href="https://www.superagent.sh/"&gt;Superagent&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;p&gt;Superagent uses E2B as a &lt;a href="https://x.com/pelaseyed/status/1709592941226831916?s=20"&gt;code execution tool&lt;/a&gt;. To try Superagent with E2B, create a Code interpreter API and then select it for your agent to use.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;span&gt;â´&lt;/span&gt; &lt;a href="https://e2b.dev/docs/llm-platforms/openai/"&gt;OpenAI's Assistants&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;p&gt;You can define actions for your AI assistant and E2B will automatically execute them inside a sandbox. This allows you to create powerful AI assistants with custom tools completely predefined by you. To &lt;a href="https://e2b.dev/docs/llm-platforms/openai"&gt;try the OpenAI Assistants with E2B&lt;/a&gt;, you can follow our guide in &lt;a href="https://e2b.dev/docs/llm-platforms/openai#python"&gt;Python&lt;/a&gt; or &lt;a href="https://e2b.dev/docs/llm-platforms/openai#java-script"&gt;JavaScript&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;span&gt;â´&lt;/span&gt; &lt;a href="https://python.langchain.com/docs/integrations/tools/e2b_data_analysis"&gt;Langchain Data Analyst&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;p&gt;E2B Data Analysis sandbox &lt;a href="https://python.langchain.com/docs/integrations/tools/e2b_data_analysis"&gt;integrated into Langchain&lt;/a&gt; allows you to:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Run Python code&lt;/li&gt; 
  &lt;li&gt;Generate charts via matplotlib&lt;/li&gt; 
  &lt;li&gt;Install Python packages dynamically during runtime&lt;/li&gt; 
  &lt;li&gt;Install system packages dynamically during runtime&lt;/li&gt; 
  &lt;li&gt;Run shell commands&lt;/li&gt; 
  &lt;li&gt;Upload and download files. See also a guide &lt;a href="https://e2b.dev/blog/build-ai-data-analyst-with-langchain-and-e2b"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Want to use E2B with your AI product?&lt;/h2&gt; 
&lt;p&gt;Contact us at &lt;a href="mailto:hello@e2b.dev"&gt;hello@e2b.dev&lt;/a&gt; or &lt;a href="https://discord.gg/35NF4Y8WSE"&gt;on discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We are open-source and you can get started with E2B &lt;a href="https://e2b.dev/docs?ref=awesome-sdks"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- 
&lt;img src="/assets/footer.png" width="100%" alt="SDKs Repo Visual" /&gt;
--&gt; 
&lt;h2&gt;Join the community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://twitter.com/e2b"&gt;X &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/35NF4Y8WSE"&gt;Hit us up on discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feel free to reach out to us at &lt;a href="mailto:hello@e2b.dev"&gt;hello@e2b.dev&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- 
&lt;a href="https://discord.gg/U7KEcGErtQ" target="_blank"&gt;
	&lt;img src="https://img.shields.io/static/v1?label=Join&amp;message=%20discord!&amp;color=mediumslateblue"&gt;
&lt;/a&gt;
&lt;a href="https://twitter.com/e2b" target="_blank"&gt;
	&lt;img src="https://img.shields.io/twitter/follow/e2b.svg?logo=twitter"&gt;
&lt;/a&gt;
--&gt; 
&lt;!-- More agents to add in the future

- GPTeam https://twitter.com/itstimconnors/status/1672278464362336256
- https://github.com/101dotxyz/GPTeam

- Neurite https://github.com/satellitecomponent/Neurite

- AutoGPT.js https://github.com/zabirauf/AutoGPT.js

- Street Fighter https://github.com/linyiLYi/street-fighter-ai

- GPT RPG https://github.com/dzoba/gptrpg

- Autopilot https://github.com/fjrdomingues/autopilot

- WinGPT - AI assistant for Windows https://news.ycombinator.com/item?id=36472854



--&gt;</description>
    </item>
    
    <item>
      <title>browserbase/stagehand</title>
      <link>https://github.com/browserbase/stagehand</link>
      <description>&lt;p&gt;The AI Browser Automation Framework&lt;/p&gt;&lt;hr&gt;&lt;div id="toc" align="center" style="margin-bottom: 0;"&gt; 
 &lt;ul style="list-style: none; margin: 0; padding: 0;"&gt; 
  &lt;a href="https://stagehand.dev"&gt; 
   &lt;picture&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="media/dark_logo.png"&gt; 
    &lt;img alt="Stagehand" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/light_logo.png" width="200" style="margin-right: 30px;"&gt; 
   &lt;/picture&gt; &lt;/a&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt;The AI Browser Automation Framework&lt;/strong&gt;&lt;br&gt; &lt;a href="https://docs.stagehand.dev"&gt;Read the Docs&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/browserbase/stagehand/tree/main?tab=MIT-1-ov-file#MIT-1-ov-file"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="media/dark_license.svg"&gt; 
   &lt;img alt="MIT License" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/light_license.svg?sanitize=true"&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;a href="https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="media/dark_slack.svg"&gt; 
   &lt;img alt="Slack Community" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/light_slack.svg?sanitize=true"&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/12122" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12122" alt="browserbase%2Fstagehand | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; If you're looking for the Python implementation, you can find it &lt;a href="https://github.com/browserbase/stagehand-python"&gt; here&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center" style="display: flex; align-items: center; justify-content: center; gap: 4px; margin-bottom: 0;"&gt; 
 &lt;b&gt;Vibe code&lt;/b&gt; 
 &lt;span style="font-size: 1.05em;"&gt; Stagehand with &lt;/span&gt; 
 &lt;a href="https://director.ai" style="display: flex; align-items: center;"&gt; &lt;span&gt;Director&lt;/span&gt; &lt;/a&gt; 
 &lt;span&gt; &lt;/span&gt; 
 &lt;picture&gt; 
  &lt;img alt="Director" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/director_icon.svg?sanitize=true" width="25"&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;h2&gt;Why Stagehand?&lt;/h2&gt; 
&lt;p&gt;Most existing browser automation tools either require you to write low-level code in a framework like Selenium, Playwright, or Puppeteer, or use high-level agents that can be unpredictable in production. By letting developers choose what to write in code vs. natural language, Stagehand is the natural choice for browser automations in production.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Choose when to write code vs. natural language&lt;/strong&gt;: use AI when you want to navigate unfamiliar pages, and use code (&lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt;) when you know exactly what you want to do.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preview and cache actions&lt;/strong&gt;: Stagehand lets you preview AI actions before running them, and also helps you easily cache repeatable actions to save time and tokens.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Computer use models with one line of code&lt;/strong&gt;: Stagehand lets you integrate SOTA computer use models from OpenAI and Anthropic into the browser with one line of code.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;Here's how to build a sample browser automation with Stagehand:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;div style="max-width:300px;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/github_demo.gif" alt="See Stagehand in Action"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Use Playwright functions on the page object
const page = stagehand.page;
await page.goto("https://github.com/browserbase");

// Use act() to execute individual actions
await page.act("click on the stagehand repo");

// Use Computer Use agents for larger actions
const agent = stagehand.agent({
    provider: "openai",
    model: "computer-use-preview",
});
await agent.execute("Get to the latest PR");

// Use extract() to read data from the page
const { author, title } = await page.extract({
  instruction: "extract the author and title of the PR",
  schema: z.object({
    author: z.string().describe("The username of the PR author"),
    title: z.string().describe("The title of the PR"),
  }),
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href="https://docs.stagehand.dev"&gt;docs.stagehand.dev&lt;/a&gt; to view the full documentation.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Start with Stagehand with one line of code, or check out our &lt;a href="https://docs.stagehand.dev/get_started/quickstart"&gt;Quickstart Guide&lt;/a&gt; for more information:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx create-browser-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7"&gt; &lt;p&gt;Watch Anirudh demo create-browser-app to create a Stagehand project!&lt;/p&gt; &lt;/a&gt; 
 &lt;a href="https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7"&gt; &lt;img style="max-width:300px;" src="https://cdn.loom.com/sessions/thumbnails/f5107f86d8c94fa0a8b4b1e89740f7a7-ec3f428b6775ceeb-full-play.gif"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Build and Run from Source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/browserbase/stagehand.git
cd stagehand
pnpm install
pnpm playwright install
pnpm run build
pnpm run example # run the blank script at ./examples/example.ts
pnpm run example 2048 # run the 2048 example at ./examples/2048.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Stagehand is best when you have an API key for an LLM provider and Browserbase credentials. To add these to your project, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
nano .env # Edit the .env file to add API keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br&gt; We highly value contributions to Stagehand! For questions or support, please join our &lt;a href="https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg"&gt;Slack community&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;At a high level, we're focused on improving reliability, speed, and cost in that order of priority. If you're interested in contributing, we strongly recommend reaching out to &lt;a href="https://x.com/miguel_gonzf"&gt;Miguel Gonzalez&lt;/a&gt; or &lt;a href="https://x.com/pk_iv"&gt;Paul Klein&lt;/a&gt; in our &lt;a href="https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg"&gt;Slack community&lt;/a&gt; before starting to ensure that your contribution aligns with our goals.&lt;/p&gt; 
&lt;p&gt;For more information, please see our &lt;a href="https://docs.stagehand.dev/examples/contributing"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project heavily relies on &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt; as a resilient backbone to automate the web. It also would not be possible without the awesome techniques and discoveries made by &lt;a href="https://github.com/reworkd/tarsier"&gt;tarsier&lt;/a&gt;, &lt;a href="https://github.com/jbeoris/gemini-zod"&gt;gemini-zod&lt;/a&gt;, and &lt;a href="https://github.com/normal-computing/fuji-web"&gt;fuji-web&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We'd like to thank the following people for their major contributions to Stagehand:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pkiv"&gt;Paul Klein&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kamath"&gt;Anirudh Kamath&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seanmcguire12"&gt;Sean McGuire&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/miguelg719"&gt;Miguel Gonzalez&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sameelarif"&gt;Sameel Arif&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/filip-michalsky"&gt;Filip Michalsky&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/jeremypress"&gt;Jeremy Press&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/navidpour"&gt;Navid Pour&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the MIT License.&lt;/p&gt; 
&lt;p&gt;Copyright 2025 Browserbase, Inc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nautechsystems/nautilus_trader</title>
      <link>https://github.com/nautechsystems/nautilus_trader</link>
      <description>&lt;p&gt;A high-performance algorithmic trading platform and event-driven backtester&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png" width="500"&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://codecov.io/gh/nautechsystems/nautilus_trader"&gt;&lt;img src="https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H" alt="codecov"&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/nautechsystems/nautilus_trader"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="codspeed"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/nautilus_trader" alt="pythons"&gt; &lt;img src="https://img.shields.io/pypi/v/nautilus_trader" alt="pypi-version"&gt; &lt;img src="https://img.shields.io/pypi/format/nautilus_trader?color=blue" alt="pypi-format"&gt; &lt;a href="https://pepy.tech/project/nautilus-trader"&gt;&lt;img src="https://pepy.tech/badge/nautilus-trader" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/NautilusTrader"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Branch&lt;/th&gt; 
   &lt;th align="left"&gt;Version&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;master&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json" alt="version"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly" alt="build"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;nightly&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json" alt="version"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly" alt="build"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;develop&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json" alt="version"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop" alt="build"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Rust&lt;/th&gt; 
   &lt;th align="left"&gt;Python&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.89.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.89.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.89.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.89.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13*&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;* Windows builds are currently pinned to CPython 3.13.2, see &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/docs/getting_started/installation.md"&gt;installation guide&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://nautilustrader.io/docs/"&gt;https://nautilustrader.io/docs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support&lt;/strong&gt;: &lt;a href="mailto:support@nautilustrader.io"&gt;support@nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform, providing quantitative traders with the ability to backtest portfolios of automated trading strategies on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.&lt;/p&gt; 
&lt;p&gt;The platform is &lt;em&gt;AI-first&lt;/em&gt;, designed to develop and deploy algorithmic trading strategies within a highly performant and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest environment consistent with the production live trading environment.&lt;/p&gt; 
&lt;p&gt;NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting and live deployment workloads.&lt;/p&gt; 
&lt;p&gt;The platform is also universal, and asset-class-agnostic â with any REST API or WebSocket feed able to be integrated via modular adapters. It supports high-frequency trading across a wide range of asset classes and instrument types including FX, Equities, Futures, Options, Crypto, DeFi, and Betting, enabling seamless operations across multiple venues simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png" alt="nautilus-trader" title="nautilus-trader"&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: Core is written in Rust with asynchronous networking using &lt;a href="https://crates.io/crates/tokio"&gt;tokio&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable&lt;/strong&gt;: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Portable&lt;/strong&gt;: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: Modular adapters mean any REST API or WebSocket feed can be integrated.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced&lt;/strong&gt;: Time in force &lt;code&gt;IOC&lt;/code&gt;, &lt;code&gt;FOK&lt;/code&gt;, &lt;code&gt;GTC&lt;/code&gt;, &lt;code&gt;GTD&lt;/code&gt;, &lt;code&gt;DAY&lt;/code&gt;, &lt;code&gt;AT_THE_OPEN&lt;/code&gt;, &lt;code&gt;AT_THE_CLOSE&lt;/code&gt;, advanced order types and conditional triggers. Execution instructions &lt;code&gt;post-only&lt;/code&gt;, &lt;code&gt;reduce-only&lt;/code&gt;, and icebergs. Contingency orders including &lt;code&gt;OCO&lt;/code&gt;, &lt;code&gt;OUO&lt;/code&gt;, &lt;code&gt;OTO&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable&lt;/strong&gt;: Add user-defined custom components, or assemble entire systems from scratch leveraging the &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; and &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backtesting&lt;/strong&gt;: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live&lt;/strong&gt;: Use identical strategy implementations between backtesting and live deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-venue&lt;/strong&gt;: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Training&lt;/strong&gt;: Backtest engine fast enough to be used to train AI trading agents (RL/ES).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png" alt="Alt text" title="nautilus"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;nautilus - from ancient Greek 'sailor' and naus 'ship'.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral. The idea is that this can be translated to the aesthetics of design and architecture.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Why NautilusTrader?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Highly performant event-driven Python&lt;/strong&gt;: Native binary core components.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parity between backtesting and live trading&lt;/strong&gt;: Identical strategy code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reduced operational risk&lt;/strong&gt;: Enhanced risk management functionality, logical accuracy, and type safety.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Highly extendable&lt;/strong&gt;: Message bus, custom components and actors, custom data, custom adapters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Traditionally, trading strategy research and backtesting might be conducted in Python using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot express the granular time and event dependent complexity of real-time trading, where compiled languages have proven to be more suitable due to their inherently higher performance, and type safety.&lt;/p&gt; 
&lt;p&gt;One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform have all been written entirely in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; or &lt;a href="https://cython.org/"&gt;Cython&lt;/a&gt;. This means we're using the right tools for the job, where systems programming languages compile performant binaries, with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.&lt;/p&gt; 
&lt;h2&gt;Why Python?&lt;/h2&gt; 
&lt;p&gt;Python was originally created decades ago as a simple scripting language with a clean straightforward syntax. It has since evolved into a fully fledged general purpose object-oriented programming language. Based on the TIOBE index, Python is currently the most popular programming language in the world. Not only that, Python has become the &lt;em&gt;de facto lingua franca&lt;/em&gt; of data science, machine learning, and artificial intelligence.&lt;/p&gt; 
&lt;p&gt;developer/user communities. However, Python has performance and typing limitations for large-scale, latency-sensitive systems. Cython addresses many of these issues by introducing static typing into Python's rich ecosystem of libraries and communities.&lt;/p&gt; 
&lt;h2&gt;Why Rust?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; is a multi-paradigm programming language designed for performance and safety, especially safe concurrency. Rust is "blazingly fast" and memory-efficient (comparable to C and C++) with no garbage collector. It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.&lt;/p&gt; 
&lt;p&gt;Rustâs rich type system and ownership model guarantees memory-safety and thread-safety deterministically â eliminating many classes of bugs at compile-time.&lt;/p&gt; 
&lt;p&gt;The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and &lt;a href="https://pyo3.rs"&gt;PyO3&lt;/a&gt;âno Rust toolchain is required at install time.&lt;/p&gt; 
&lt;p&gt;This project makes the &lt;a href="https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html"&gt;Soundness Pledge&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âThe intent of this project is to be free of soundness bugs. The developers will do their best to avoid them, and welcome help in analyzing and fixing them.â&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;MSRV:&lt;/strong&gt; NautilusTrader relies heavily on improvements in the Rust language and compiler. As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is modularly designed to work with &lt;em&gt;adapters&lt;/em&gt;, enabling connectivity to trading venues and data providers by translating their raw APIs into a unified interface and normalized domain model.&lt;/p&gt; 
&lt;p&gt;The following integrations are currently supported; see &lt;a href="https://nautilustrader.io/docs/latest/integrations/"&gt;docs/integrations/&lt;/a&gt; for details:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Name&lt;/th&gt; 
   &lt;th align="left"&gt;ID&lt;/th&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
   &lt;th align="left"&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://betfair.com"&gt;Betfair&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BETFAIR&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sports Betting Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/betfair.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://binance.com"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://binance.us"&gt;Binance US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.binance.com/en/futures"&gt;Binance Futures&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bybit.com"&gt;Bybit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BYBIT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/bybit.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coinbase.com/en/international-exchange"&gt;Coinbase International&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;COINBASE_INTX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/coinbase_intx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://databento.com"&gt;Databento&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DATABENTO&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/databento.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dydx.exchange/"&gt;dYdX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DYDX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/dydx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hyperliquid.xyz"&gt;Hyperliquid&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;HYPERLIQUID&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/building-orange" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/hyperliquid.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.interactivebrokers.com"&gt;Interactive Brokers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;INTERACTIVE_BROKERS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brokerage (multi-venue)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/ib.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://okx.com"&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OKX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/beta-yellow" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/okx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://polymarket.com"&gt;Polymarket&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;POLYMARKET&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Prediction Market (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/polymarket.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tardis.dev"&gt;Tardis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TARDIS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/tardis.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ID&lt;/strong&gt;: The default client ID for the integrations adapter clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt;: The type of integration (often the venue type).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Status&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;building&lt;/code&gt;: Under construction and likely not in a usable state.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;beta&lt;/code&gt;: Completed to a minimally working state and in a beta testing phase.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt;: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/integrations/index.html"&gt;Integrations&lt;/a&gt; documentation for further details.&lt;/p&gt; 
&lt;h2&gt;Versioning and releases&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;NautilusTrader is still under active development&lt;/strong&gt;. Some features may be incomplete, and while the API is becoming more stable, breaking changes can occur between releases. We strive to document these changes in the release notes on a &lt;strong&gt;best-effort basis&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;We aim to follow a &lt;strong&gt;bi-weekly release schedule&lt;/strong&gt;, though experimental or larger features may cause delays.&lt;/p&gt; 
&lt;h3&gt;Branches&lt;/h3&gt; 
&lt;p&gt;We aim to maintain a stable, passing build across all branches.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;master&lt;/code&gt;: Reflects the source code for the latest released version; recommended for production use.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt;: Daily snapshots of the &lt;code&gt;develop&lt;/code&gt; branch for early testing; merged at &lt;strong&gt;14:00 UTC&lt;/strong&gt; or on demand.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt;: Active development branch for contributors and feature work.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Our &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md"&gt;roadmap&lt;/a&gt; aims to achieve a &lt;strong&gt;stable API for version 2.x&lt;/strong&gt; (likely after the Rust port). Once this milestone is reached, we plan to implement a formal deprecation process for any API changes. This approach allows us to maintain a rapid development pace for now.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Precision mode&lt;/h2&gt; 
&lt;p&gt;NautilusTrader supports two precision modes for its core value types (&lt;code&gt;Price&lt;/code&gt;, &lt;code&gt;Quantity&lt;/code&gt;, &lt;code&gt;Money&lt;/code&gt;), which differ in their internal bit-width and maximum decimal precision.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High-precision&lt;/strong&gt;: 128-bit integers with up to 16 decimals of precision, and a larger value range.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard-precision&lt;/strong&gt;: 64-bit integers with up to 9 decimals of precision, and a smaller value range.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;By default, the official Python wheels &lt;strong&gt;ship&lt;/strong&gt; in high-precision (128-bit) mode on Linux and macOS. On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support. For the Rust crates, the default is standard-precision unless you explicitly enable the &lt;code&gt;high-precision&lt;/code&gt; feature flag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Rust feature flag&lt;/strong&gt;: To enable high-precision mode in Rust, add the &lt;code&gt;high-precision&lt;/code&gt; feature to your Cargo.toml:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
nautilus_model = { version = "*", features = ["high-precision"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We recommend using the latest supported version of Python and installing &lt;a href="https://pypi.org/project/nautilus_trader/"&gt;nautilus_trader&lt;/a&gt; inside a virtual environment to isolate dependencies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;There are two supported ways to install&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pre-built binary wheel from PyPI &lt;em&gt;or&lt;/em&gt; the Nautech Systems package index.&lt;/li&gt; 
 &lt;li&gt;Build from source.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;We highly recommend installing using the &lt;a href="https://docs.astral.sh/uv"&gt;uv&lt;/a&gt; package manager with a "vanilla" CPython.&lt;/p&gt; 
 &lt;p&gt;Conda and other Python distributions &lt;em&gt;may&lt;/em&gt; work but arenât officially supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;From PyPI&lt;/h3&gt; 
&lt;p&gt;To install the latest binary wheel (or sdist package) from PyPI using Python's pip package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From the Nautech Systems package index&lt;/h3&gt; 
&lt;p&gt;The Nautech Systems package index (&lt;code&gt;packages.nautechsystems.io&lt;/code&gt;) complies with &lt;a href="https://peps.python.org/pep-0503/"&gt;PEP-503&lt;/a&gt; and hosts both stable and development binary wheels for &lt;code&gt;nautilus_trader&lt;/code&gt;. This enables users to install either the latest stable release or pre-release versions for testing.&lt;/p&gt; 
&lt;h4&gt;Stable wheels&lt;/h4&gt; 
&lt;p&gt;Stable wheels correspond to official releases of &lt;code&gt;nautilus_trader&lt;/code&gt; on PyPI, and use standard versioning.&lt;/p&gt; 
&lt;p&gt;To install the latest stable release:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Development wheels&lt;/h4&gt; 
&lt;p&gt;Development wheels are published from both the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;develop&lt;/code&gt; branches, allowing users to test features and fixes ahead of stable releases.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Wheels from the &lt;code&gt;develop&lt;/code&gt; branch are only built for the Linux x86_64 platform to save time and compute resources, while &lt;code&gt;nightly&lt;/code&gt; wheels support additional platforms as shown below.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Nightly&lt;/th&gt; 
   &lt;th align="left"&gt;Develop&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;â&lt;/td&gt; 
   &lt;td align="left"&gt;â&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;â&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;â&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;â&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;This process also helps preserve compute resources and ensures easy access to the exact binaries tested in CI pipelines, while adhering to &lt;a href="https://peps.python.org/pep-0440/"&gt;PEP-440&lt;/a&gt; versioning standards:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; wheels use the version format &lt;code&gt;dev{date}+{build_number}&lt;/code&gt; (e.g., &lt;code&gt;1.208.0.dev20241212+7001&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; wheels use the version format &lt;code&gt;a{date}&lt;/code&gt; (alpha) (e.g., &lt;code&gt;1.208.0a20241212&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;We do not recommend using development wheels in production environments, such as live trading controlling real capital.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Installation commands&lt;/h4&gt; 
&lt;p&gt;By default, pip will install the latest stable release. Adding the &lt;code&gt;--pre&lt;/code&gt; flag ensures that pre-release versions, including development wheels, are considered.&lt;/p&gt; 
&lt;p&gt;To install the latest available pre-release (including development wheels):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install a specific development wheel (e.g., &lt;code&gt;1.208.0a20241212&lt;/code&gt; for December 12, 2024):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install nautilus_trader==1.208.0a20241212 --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Available versions&lt;/h4&gt; 
&lt;p&gt;You can view all available versions of &lt;code&gt;nautilus_trader&lt;/code&gt; on the &lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;package index&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To programmatically fetch and list available versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP '(?&amp;lt;=&amp;lt;a href=")[^"]+(?=")' | awk -F'#' '{print $1}' | sort
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Branch updates&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): Build and publish continuously with every merged commit.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): Build and publish daily when we automatically merge the &lt;code&gt;develop&lt;/code&gt; branch at &lt;strong&gt;14:00 UTC&lt;/strong&gt; (if there are changes).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Retention policies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): We retain only the most recent wheel build.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): We retain only the 10 most recent wheel builds.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;p&gt;It's possible to install from source using pip if you first install the build dependencies as specified in the &lt;code&gt;pyproject.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt; (the Rust toolchain installer):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl https://sh.rustup.rs -sSf | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Download and install &lt;a href="https://win.rustup.rs/x86_64"&gt;&lt;code&gt;rustup-init.exe&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;Install "Desktop development with C++" with &lt;a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&amp;amp;rel=16"&gt;Build Tools for Visual Studio 2019&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;rustc --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;cargo&lt;/code&gt; in the current shell:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Start a new PowerShell&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://clang.llvm.org/"&gt;clang&lt;/a&gt; (a C language frontend for LLVM):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get install clang
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ol&gt; 
     &lt;li&gt; &lt;p&gt;Add Clang to your &lt;a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&amp;amp;rel=16"&gt;Build Tools for Visual Studio 2019&lt;/a&gt;:&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;Start | Visual Studio Installer | Modify | C++ Clang tools for Windows (12.0.0 - x64â¦) = checked | Modify&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;clang&lt;/code&gt; in the current shell:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;[System.Environment]::SetEnvironmentVariable('path', "C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\Llvm\x64\bin\;" + $env:Path,"User")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;clang --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install uv (see the &lt;a href="https://docs.astral.sh/uv/getting-started/installation"&gt;uv installation guide&lt;/a&gt; for more details):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the source with &lt;code&gt;git&lt;/code&gt;, and install from the project's root directory:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone --branch develop --depth 1 https://github.com/nautechsystems/nautilus_trader
cd nautilus_trader
uv sync --all-extras
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;The &lt;code&gt;--depth 1&lt;/code&gt; flag fetches just the latest commit for a faster, lightweight clone.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt; &lt;p&gt;Set environment variables for PyO3 compilation (Linux and macOS only):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Set the library path for the Python interpreter (in this case Python 3.13.4)
export LD_LIBRARY_PATH="$HOME/.local/share/uv/python/cpython-3.13.4-linux-x86_64-gnu/lib:$LD_LIBRARY_PATH"

# Set the Python executable path for PyO3
export PYO3_PYTHON=$(pwd)/.venv/bin/python
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Adjust the Python version and architecture in the &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; to match your system. Use &lt;code&gt;uv python list&lt;/code&gt; to find the exact path for your Python installation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for other options and further details.&lt;/p&gt; 
&lt;h2&gt;Redis&lt;/h2&gt; 
&lt;p&gt;Using &lt;a href="https://redis.io"&gt;Redis&lt;/a&gt; with NautilusTrader is &lt;strong&gt;optional&lt;/strong&gt; and only required if configured as the backend for a &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; database or &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;. See the &lt;strong&gt;Redis&lt;/strong&gt; section of the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation#redis"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;h2&gt;Makefile&lt;/h2&gt; 
&lt;p&gt;A &lt;code&gt;Makefile&lt;/code&gt; is provided to automate most installation and build tasks for development. Some of the targets include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;make install&lt;/code&gt;: Installs in &lt;code&gt;release&lt;/code&gt; build mode with all dependency groups and extras.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-debug&lt;/code&gt;: Same as &lt;code&gt;make install&lt;/code&gt; but with &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-just-deps&lt;/code&gt;: Installs just the &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;dev&lt;/code&gt; and &lt;code&gt;test&lt;/code&gt; dependencies (does not install package).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build&lt;/code&gt;: Runs the build script in &lt;code&gt;release&lt;/code&gt; build mode (default).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-debug&lt;/code&gt;: Runs the build script in &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;release&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel-debug&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;debug&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make cargo-test&lt;/code&gt;: Runs all Rust crate tests using &lt;code&gt;cargo-nextest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;: Deletes all build results, such as &lt;code&gt;.so&lt;/code&gt; or &lt;code&gt;.dll&lt;/code&gt; files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make distclean&lt;/code&gt;: &lt;strong&gt;CAUTION&lt;/strong&gt; Removes all artifacts not in the git index from the repository. This includes source files which have not been &lt;code&gt;git add&lt;/code&gt;ed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make docs&lt;/code&gt;: Builds the documentation HTML using Sphinx.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pre-commit&lt;/code&gt;: Runs the pre-commit checks over all files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make ruff&lt;/code&gt;: Runs ruff over all files using the &lt;code&gt;pyproject.toml&lt;/code&gt; config (with autofix).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pytest&lt;/code&gt;: Runs all tests with &lt;code&gt;pytest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make test-performance&lt;/code&gt;: Runs performance tests with &lt;a href="https://codspeed.io"&gt;codspeed&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make help&lt;/code&gt; for documentation on all available make targets.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;See the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/crates/infrastructure/TESTS.md"&gt;crates/infrastructure/TESTS.md&lt;/a&gt; file for running the infrastructure integration tests.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Indicators and strategies can be developed in both Python and Cython. For performance and latency-sensitive applications, we recommend using Cython. Below are some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/indicators/ema_python.py"&gt;indicator&lt;/a&gt; example written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/indicators/"&gt;indicator&lt;/a&gt; examples written in Cython.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/strategies/"&gt;strategy&lt;/a&gt; examples written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/examples/backtest/"&gt;backtest&lt;/a&gt; examples using a &lt;code&gt;BacktestEngine&lt;/code&gt; directly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;Docker containers are built using the base image &lt;code&gt;python:3.12-slim&lt;/code&gt; with the following variant tags:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:latest&lt;/code&gt; has the latest release version installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:latest&lt;/code&gt; has the latest release version installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can pull the container images as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/&amp;lt;image_variant_tag&amp;gt; --platform linux/amd64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can launch the backtest example container by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/jupyterlab:nightly --platform linux/amd64
docker run -p 8888:8888 ghcr.io/nautechsystems/jupyterlab:nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then open your browser at the following address:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;http://127.0.0.1:8888/lab
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader currently exceeds the rate limit for Jupyter notebook logging (stdout output). Therefore, we set the &lt;code&gt;log_level&lt;/code&gt; to &lt;code&gt;ERROR&lt;/code&gt; in the examples. Lowering this level to see more logging will cause the notebook to hang during cell execution. We are investigating a fix that may involve either raising the configured rate limits for Jupyter or throttling the log flushing from Nautilus.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jupyterlab/jupyterlab/issues/12845"&gt;https://github.com/jupyterlab/jupyterlab/issues/12845&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/deshaw/jupyterlab-limit-output"&gt;https://github.com/deshaw/jupyterlab-limit-output&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;We aim to provide the most pleasant developer experience possible for this hybrid codebase of Python, Cython and Rust. See the &lt;a href="https://nautilustrader.io/docs/latest/developer_guide/index.html"&gt;Developer Guide&lt;/a&gt; for helpful information.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make build-debug&lt;/code&gt; to compile after changes to Rust or Cython code for the most efficient development workflow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Testing with Rust&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://nexte.st"&gt;cargo-nextest&lt;/a&gt; is the standard Rust test runner for NautilusTrader. Its key benefit is isolating each test in its own process, ensuring test reliability by avoiding interference.&lt;/p&gt; 
&lt;p&gt;You can install cargo-nextest by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-nextest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run Rust tests with &lt;code&gt;make cargo-test&lt;/code&gt;, which uses &lt;strong&gt;cargo-nextest&lt;/strong&gt; with an efficient profile.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to NautilusTrader! We welcome any and all help to improve the project. If you have an idea for an enhancement or a bug fix, the first step is to open an &lt;a href="https://github.com/nautechsystems/nautilus_trader/issues"&gt;issue&lt;/a&gt; on GitHub to discuss it with the team. This helps to ensure that your contribution will be well-aligned with the goals of the project and avoids duplication of effort.&lt;/p&gt; 
&lt;p&gt;Before getting started, be sure to review the &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md#open-source-scope"&gt;open-source scope&lt;/a&gt; outlined in the projectâs roadmap to understand whatâs in and out of scope.&lt;/p&gt; 
&lt;p&gt;Once you're ready to start working on your contribution, make sure to follow the guidelines outlined in the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file. This includes signing a Contributor License Agreement (CLA) to ensure that your contributions can be included in the project.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Pull requests should target the &lt;code&gt;develop&lt;/code&gt; branch (the default branch). This is where new features and improvements are integrated before release.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thank you again for your interest in NautilusTrader! We look forward to reviewing your contributions and working with you to improve the project.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our community of users and contributors on &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord&lt;/a&gt; to chat and stay up-to-date with the latest announcements and features of NautilusTrader. Whether you're a developer looking to contribute or just want to learn more about the platform, all are welcome on our Discord server.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader does not issue, promote, or endorse any cryptocurrency tokens. Any claims or communications suggesting otherwise are unauthorized and false.&lt;/p&gt; 
 &lt;p&gt;All official updates and communications from NautilusTrader will be shared exclusively through &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;, our &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord server&lt;/a&gt;, or our X (Twitter) account: &lt;a href="https://x.com/NautilusTrader"&gt;@NautilusTrader&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;If you encounter any suspicious activity, please report it to the appropriate platform and contact us at &lt;a href="mailto:info@nautechsystems.io"&gt;info@nautechsystems.io&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The source code for NautilusTrader is available on GitHub under the &lt;a href="https://www.gnu.org/licenses/lgpl-3.0.en.html"&gt;GNU Lesser General Public License v3.0&lt;/a&gt;. Contributions to the project are welcome and require the completion of a standard &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CLA.md"&gt;Contributor License Agreement (CLA)&lt;/a&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;NautilusTraderâ¢ is developed and maintained by Nautech Systems, a technology company specializing in the development of high-performance trading systems. For more information, visit &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Â© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ns-logo.png" alt="nautechsystems" title="nautechsystems"&gt; &lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ferris.png" width="128"&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>FFmpeg/asm-lessons</title>
      <link>https://github.com/FFmpeg/asm-lessons</link>
      <description>&lt;p&gt;FFMPEG Assembly Language Lessons&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Welcome to the FFmpeg School of Assembly Language. You have taken the first step on the most interesting, challenging, and rewarding journey in programming. These lessons will give you a grounding in the way assembly language is written in FFmpeg and open your eyes to what's actually going on in your computer.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Required Knowledge&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Knowledge of C, in particular pointers. If you don't know C, work through &lt;a href="https://en.wikipedia.org/wiki/The_C_Programming_Language"&gt;The C Programming Language&lt;/a&gt; book&lt;/li&gt; 
 &lt;li&gt;High School Mathematics (scalar vs vector, addition, multiplication etc)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Lessons&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In this Git repository there are lessons and assignments (not uploaded yet) that correspond with each lessons. By the end of the lessons you'll be able to contribute to FFmpeg.&lt;/p&gt; 
&lt;p&gt;A discord server is available to answer questions: &lt;a href="https://discord.com/invite/Ks5MhUhqfB"&gt;https://discord.com/invite/Ks5MhUhqfB&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Translations&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/FFmpeg/asm-lessons/main/README.fr.md"&gt;FranÃ§ais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/FFmpeg/asm-lessons/main/README.es.md"&gt;Spanish&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>google/adk-samples</title>
      <link>https://github.com/google/adk-samples</link>
      <description>&lt;p&gt;A collection of sample agents built with Agent Development (ADK)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agent Development Kit (ADK) Samples&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://github.com/google/adk-docs/raw/main/docs/assets/agent-development-kit.png" alt="Agent Development Kit Logo" width="150"&gt; 
&lt;p&gt;Welcome to the ADK Sample Agents repository! This collection provides ready-to-use agents built on top of the &lt;a href="https://google.github.io/adk-docs/"&gt;Agent Development Kit&lt;/a&gt;, designed to accelerate your development process. These agents cover a range of common use cases and complexities, from simple conversational bots to complex multi-agent workflows.&lt;/p&gt; 
&lt;h2&gt;â¨ Getting Started&lt;/h2&gt; 
&lt;p&gt;This repo contains ADK sample agents for both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;Java.&lt;/strong&gt; Navigate to the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/python/"&gt;Python&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/java/"&gt;Java&lt;/a&gt;&lt;/strong&gt; subfolders to see language-specific setup instructions, and learn more about the available sample agents.&lt;/p&gt; 
&lt;p&gt;To learn more, check out the &lt;a href="https://google.github.io/adk-docs/"&gt;ADK Documentation&lt;/a&gt;, and the GitHub repositories for &lt;a href="https://github.com/google/adk-python"&gt;ADK Python&lt;/a&gt; and &lt;a href="https://github.com/google/adk-java"&gt;ADK Java&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ð³ Repository Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;âââ java
â&amp;nbsp;&amp;nbsp; âââ agents
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ software-bug-assistant
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ time-series-forecasting
â&amp;nbsp;&amp;nbsp; âââ README.md
âââ python
â&amp;nbsp;&amp;nbsp; âââ agents
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ academic-research
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ brand-search-optimization
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ camel
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ customer-service
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ data-science
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ financial-advisor
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ fomc-research
â   â   âââ gemini-fullstack
â&amp;nbsp;&amp;nbsp; â&amp;nbsp;&amp;nbsp; âââ image-scoring
â   â   âââ llm-auditor
â   â   âââ machine-learning-engineering
â   â   âââ marketing-agency
â   â   âââ personalized-shopping
â   â   âââ RAG
â   â   âââ README.md
â   â   âââ software-bug-assistant  
â   â   âââ travel-concierge
â   âââ README.md
âââ README.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â¹ï¸ Getting help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or if you found any problems with this repository, please report through &lt;a href="https://github.com/google/adk-samples/issues"&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ð¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether it's bug reports, feature requests, documentation improvements, or code contributions, please see our &lt;a href="https://github.com/google/adk-samples/raw/main/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing Guidelines&lt;/strong&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;ð License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://github.com/google/adk-samples/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Disclaimers&lt;/h2&gt; 
&lt;p&gt;This is not an officially supported Google product. This project is not eligible for the &lt;a href="https://bughunters.google.com/open-source-security"&gt;Google Open Source Software Vulnerability Rewards Program&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is intended for demonstration purposes only. It is not intended for use in a production environment.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;OpenAI Codex CLI&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.&lt;br&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, see &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="50%"&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Table of contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;!-- Begin ToC --&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#quickstart"&gt;Quickstart&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#installing-and-running-codex-cli"&gt;Installing and running Codex CLI&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#using-codex-with-your-chatgpt-plan"&gt;Using Codex with your ChatGPT plan&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#usage-based-billing-alternative-use-an-openai-api-key"&gt;Usage-based billing alternative: Use an OpenAI API key&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#choosing-codexs-level-of-autonomy"&gt;Choosing Codex's level of autonomy&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#1-readwrite"&gt;&lt;strong&gt;1. Read/write&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#2-read-only"&gt;&lt;strong&gt;2. Read-only&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#3-advanced-configuration"&gt;&lt;strong&gt;3. Advanced configuration&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#can-i-run-without-any-approvals"&gt;Can I run without ANY approvals?&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#fine-tuning-in-configtoml"&gt;Fine-tuning in &lt;code&gt;config.toml&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#using-open-source-models"&gt;Using Open Source Models&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#platform-sandboxing-details"&gt;Platform sandboxing details&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#experimental-technology-disclaimer"&gt;Experimental technology disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#system-requirements"&gt;System requirements&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#cli-reference"&gt;CLI reference&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#memory--project-docs"&gt;Memory &amp;amp; project docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#non-interactive--ci-mode"&gt;Non-interactive / CI mode&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#zero-data-retention-zdr-usage"&gt;Zero data retention (ZDR) usage&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#codex-open-source-fund"&gt;Codex open source fund&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#contributing"&gt;Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#development-workflow"&gt;Development workflow&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#writing-high-impact-code-changes"&gt;Writing high-impact code changes&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#opening-a-pull-request"&gt;Opening a pull request&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#review-process"&gt;Review process&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#community-values"&gt;Community values&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#getting-help"&gt;Getting help&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#contributor-license-agreement-cla"&gt;Contributor license agreement (CLA)&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#quick-fixes"&gt;Quick fixes&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#releasing-codex"&gt;Releasing &lt;code&gt;codex&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#security--responsible-ai"&gt;Security &amp;amp; responsible AI&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- End ToC --&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex  # Alternatively: `brew install codex`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="50%"&gt; &lt;/p&gt; 
&lt;p&gt;After you run &lt;code&gt;codex&lt;/code&gt; select Sign in with ChatGPT. You'll need a Plus, Pro, or Team ChatGPT account, and will get access to our latest models, including &lt;code&gt;gpt-5&lt;/code&gt;, at no extra cost to your plan. (Enterprise is coming soon.)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: If you've used the Codex CLI before, you'll need to follow these steps to migrate from usage-based billing with your API key:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Update the CLI with &lt;code&gt;codex update&lt;/code&gt; and ensure &lt;code&gt;codex --version&lt;/code&gt; is greater than 0.13&lt;/li&gt; 
  &lt;li&gt;Ensure that there is no &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; environment variable set. (Check that &lt;code&gt;env | grep 'OPENAI_API_KEY'&lt;/code&gt; returns empty)&lt;/li&gt; 
  &lt;li&gt;Run &lt;code&gt;codex login&lt;/code&gt; again&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you encounter problems with the login flow, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage-based billing alternative: Use an OpenAI API key&lt;/h3&gt; 
&lt;p&gt;If you prefer to pay-as-you-go, you can still authenticate with your OpenAI API key by setting it as an environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export OPENAI_API_KEY="your-api-key-here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;This command only sets the key for your current terminal session, which we recommend. To set it for all future sessions, you can also add the &lt;code&gt;export&lt;/code&gt; line to your shell's configuration file (e.g., &lt;code&gt;~/.zshrc&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;If you have signed in with ChatGPT, Codex will default to using your ChatGPT credits. If you wish to use your API key, use the &lt;code&gt;/logout&lt;/code&gt; command to clear your ChatGPT authentication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Choosing Codex's level of autonomy&lt;/h3&gt; 
&lt;p&gt;We always recommend running Codex in its default sandbox that gives you strong guardrails around what the agent can do. The default sandbox prevents it from editing files outside its workspace, or from accessing the network.&lt;/p&gt; 
&lt;p&gt;When you launch Codex in a new folder, it detects whether the folder is version controlled and recommends one of two levels of autonomy:&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;1. Read/write&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Codex can run commands and write files in the workspace without approval.&lt;/li&gt; 
 &lt;li&gt;To write files in other folders, access network, update git or perform other actions protected by the sandbox, Codex will need your permission.&lt;/li&gt; 
 &lt;li&gt;By default, the workspace includes the current directory, as well as temporary directories like &lt;code&gt;/tmp&lt;/code&gt;. You can see what directories are in the workspace with the &lt;code&gt;/status&lt;/code&gt; command. See the docs for how to customize this behavior.&lt;/li&gt; 
 &lt;li&gt;Advanced: You can manually specify this configuration by running &lt;code&gt;codex --sandbox workspace-write --ask-for-approval on-request&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;This is the recommended default for version-controlled folders.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;2. Read-only&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Codex can run read-only commands without approval.&lt;/li&gt; 
 &lt;li&gt;To edit files, access network, or perform other actions protected by the sandbox, Codex will need your permission.&lt;/li&gt; 
 &lt;li&gt;Advanced: You can manually specify this configuration by running &lt;code&gt;codex --sandbox read-only --ask-for-approval on-request&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;This is the recommended default non-version-controlled folders.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;3. Advanced configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Codex gives you fine-grained control over the sandbox with the &lt;code&gt;--sandbox&lt;/code&gt; option, and over when it requests approval with the &lt;code&gt;--ask-for-approval&lt;/code&gt; option. Run &lt;code&gt;codex help&lt;/code&gt; for more on these options.&lt;/p&gt; 
&lt;h4&gt;Can I run without ANY approvals?&lt;/h4&gt; 
&lt;p&gt;Yes, run codex non-interactively with &lt;code&gt;--ask-for-approval never&lt;/code&gt;. This option works with all &lt;code&gt;--sandbox&lt;/code&gt; options, so you still have full control over Codex's level of autonomy. It will make its best attempt with whatever contrainsts you provide. For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;codex --ask-for-approval never --sandbox read-only&lt;/code&gt; when you are running many agents to answer questions in parallel in the same workspace.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;codex --ask-for-approval never --sandbox workspace-write&lt;/code&gt; when you want the agent to non-interactively take time to produce the best outcome, with strong guardrails around its behavior.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;codex --ask-for-approval never --sandbox danger-full-access&lt;/code&gt; to dangerously give the agent full autonomy. Because this disables important safety mechanisms, we recommend against using this unless running Codex in an isolated environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Fine-tuning in &lt;code&gt;config.toml&lt;/code&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# approval mode
approval_policy = "untrusted"
sandbox_mode    = "read-only"

# full-auto mode
approval_policy = "on-request"
sandbox_mode    = "workspace-write"

# Optional: allow network in workspace-write mode
[sandbox_workspace_write]
network_access = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also save presets as &lt;strong&gt;profiles&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[profiles.full_auto]
approval_policy = "on-request"
sandbox_mode    = "workspace-write"

[profiles.readonly_quiet]
approval_policy = "never"
sandbox_mode    = "read-only"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example prompts&lt;/h3&gt; 
&lt;p&gt;Below are a few bite-size examples you can copy-paste. Replace the text in quotes with your own task. See the &lt;a href="https://github.com/openai/codex/raw/main/codex-cli/examples/prompting_guide.md"&gt;prompting guide&lt;/a&gt; for more tips and usage patterns.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;â¨&lt;/th&gt; 
   &lt;th&gt;What you type&lt;/th&gt; 
   &lt;th&gt;What happens&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Refactor the Dashboard component to React Hooks"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Codex rewrites the class component, runs &lt;code&gt;npm test&lt;/code&gt;, and shows the diff.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Generate SQL migrations for adding a users table"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Infers your ORM, creates migration files, and runs them in a sandboxed DB.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Write unit tests for utils/date.ts"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Generates tests, executes them, and iterates until they pass.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Bulk-rename *.jpeg -&amp;gt; *.jpg with git mv"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Safely renames files and updates imports/usages.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Explain what this regex does: ^(?=.*[A-Z]).{8,}$"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Outputs a step-by-step human explanation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Carefully review this repo, and propose 3 high impact well-scoped PRs"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Suggests impactful PRs in the current codebase.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Look for vulnerabilities and create a security review report"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Finds and explains security bugs.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Running with a prompt as input&lt;/h2&gt; 
&lt;p&gt;You can also run Codex CLI with a prompt as input:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex "explain this codebase to me"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex --full-auto "create the fanciest todo-list app"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it - Codex will scaffold a file, run it inside a sandbox, install any missing dependencies, and show you the live result. Approve the changes and they'll be committed to your working directory.&lt;/p&gt; 
&lt;h2&gt;Using Open Source Models&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Use &lt;code&gt;--profile&lt;/code&gt; to use other models&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Codex also allows you to use other providers that support the OpenAI Chat Completions (or Responses) API.&lt;/p&gt; 
 &lt;p&gt;To do so, you must first define custom &lt;a href="https://raw.githubusercontent.com/openai/codex/main/config.md#model_providers"&gt;providers&lt;/a&gt; in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For example, the provider for a standard Ollama setup would be defined as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.ollama]
name = "Ollama"
base_url = "http://localhost:11434/v1"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;base_url&lt;/code&gt; will have &lt;code&gt;/chat/completions&lt;/code&gt; appended to it to build the full URL for the request.&lt;/p&gt; 
 &lt;p&gt;For providers that also require an &lt;code&gt;Authorization&lt;/code&gt; header of the form &lt;code&gt;Bearer: SECRET&lt;/code&gt;, an &lt;code&gt;env_key&lt;/code&gt; can be specified, which indicates the environment variable to read to use as the value of &lt;code&gt;SECRET&lt;/code&gt; when making a request:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.openrouter]
name = "OpenRouter"
base_url = "https://openrouter.ai/api/v1"
env_key = "OPENROUTER_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Providers that speak the Responses API are also supported by adding &lt;code&gt;wire_api = "responses"&lt;/code&gt; as part of the definition. Accessing OpenAI models via Azure is an example of such a provider, though it also requires specifying additional &lt;code&gt;query_params&lt;/code&gt; that need to be appended to the request URL:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.azure]
name = "Azure"
# Make sure you set the appropriate subdomain for this URL.
base_url = "https://YOUR_PROJECT_NAME.openai.azure.com/openai"
env_key = "AZURE_OPENAI_API_KEY"  # Or "OPENAI_API_KEY", whichever you use.
# Newer versions appear to support the responses API, see https://github.com/openai/codex/pull/1321
query_params = { api-version = "2025-04-01-preview" }
wire_api = "responses"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Once you have defined a provider you wish to use, you can configure it as your default provider as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;model_provider = "azure"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!TIP] If you find yourself experimenting with a variety of models and providers, then you likely want to invest in defining a &lt;em&gt;profile&lt;/em&gt; for each configuration like so:&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[profiles.o3]
model_provider = "azure"
model = "o3"

[profiles.mistral]
model_provider = "ollama"
model = "mistral"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This way, you can specify one command-line argument (.e.g., &lt;code&gt;--profile o3&lt;/code&gt;, &lt;code&gt;--profile mistral&lt;/code&gt;) to override multiple settings together.&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;Codex can run fully locally against an OpenAI-compatible OSS host (like Ollama) using the &lt;code&gt;--oss&lt;/code&gt; flag:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interactive UI: 
  &lt;ul&gt; 
   &lt;li&gt;codex --oss&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Non-interactive (programmatic) mode: 
  &lt;ul&gt; 
   &lt;li&gt;echo "Refactor utils" | codex exec --oss&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model selection when using &lt;code&gt;--oss&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you omit &lt;code&gt;-m/--model&lt;/code&gt;, Codex defaults to -m gpt-oss:20b and will verify it exists locally (downloading if needed).&lt;/li&gt; 
 &lt;li&gt;To pick a different size, pass one of: 
  &lt;ul&gt; 
   &lt;li&gt;-m "gpt-oss:20b"&lt;/li&gt; 
   &lt;li&gt;-m "gpt-oss:120b"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Point Codex at your own OSS host:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;By default, &lt;code&gt;--oss&lt;/code&gt; talks to &lt;a href="http://localhost:11434/v1"&gt;http://localhost:11434/v1&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;To use a different host, set one of these environment variables before running Codex: 
  &lt;ul&gt; 
   &lt;li&gt;CODEX_OSS_BASE_URL, for example: 
    &lt;ul&gt; 
     &lt;li&gt;CODEX_OSS_BASE_URL="&lt;a href="http://my-ollama.example.com:11434/v1"&gt;http://my-ollama.example.com:11434/v1&lt;/a&gt;" codex --oss -m gpt-oss:20b&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;or CODEX_OSS_PORT (when the host is localhost): 
    &lt;ul&gt; 
     &lt;li&gt;CODEX_OSS_PORT=11434 codex --oss&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Advanced: you can persist this in your config instead of environment variables by overriding the built-in &lt;code&gt;oss&lt;/code&gt; provider in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.oss]
name = "Open Source"
base_url = "http://my-ollama.example.com:11434/v1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;h3&gt;Platform sandboxing details&lt;/h3&gt; 
&lt;p&gt;The mechanism Codex uses to implement the sandbox policy depends on your OS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS 12+&lt;/strong&gt; uses &lt;strong&gt;Apple Seatbelt&lt;/strong&gt; and runs commands using &lt;code&gt;sandbox-exec&lt;/code&gt; with a profile (&lt;code&gt;-p&lt;/code&gt;) that corresponds to the &lt;code&gt;--sandbox&lt;/code&gt; that was specified.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; uses a combination of Landlock/seccomp APIs to enforce the &lt;code&gt;sandbox&lt;/code&gt; configuration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that when running Linux in a containerized environment such as Docker, sandboxing may not work if the host/container configuration does not support the necessary Landlock/seccomp APIs. In such cases, we recommend configuring your Docker container so that it provides the sandbox guarantees you are looking for and then running &lt;code&gt;codex&lt;/code&gt; with &lt;code&gt;--sandbox danger-full-access&lt;/code&gt; (or, more simply, the &lt;code&gt;--dangerously-bypass-approvals-and-sandbox&lt;/code&gt; flag) within your container.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Experimental technology disclaimer&lt;/h2&gt; 
&lt;p&gt;Codex CLI is an experimental project under active development. It is not yet stable, may contain bugs, incomplete features, or undergo breaking changes. We're building it in the open with the community and welcome:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug reports&lt;/li&gt; 
 &lt;li&gt;Feature requests&lt;/li&gt; 
 &lt;li&gt;Pull requests&lt;/li&gt; 
 &lt;li&gt;Good vibes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Help us improve by filing issues or submitting PRs (see the section below for how to contribute)!&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;System requirements&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Requirement&lt;/th&gt; 
   &lt;th&gt;Details&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operating systems&lt;/td&gt; 
   &lt;td&gt;macOS 12+, Ubuntu 20.04+/Debian 10+, or Windows 11 &lt;strong&gt;via WSL2&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Git (optional, recommended)&lt;/td&gt; 
   &lt;td&gt;2.23+ for built-in PR helpers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RAM&lt;/td&gt; 
   &lt;td&gt;4-GB minimum (8-GB recommended)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h2&gt;CLI reference&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Interactive TUI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex "..."&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Initial prompt for interactive TUI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "fix lint errors"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex exec "..."&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Non-interactive "automation mode"&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex exec "explain utils.ts"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Key flags: &lt;code&gt;--model/-m&lt;/code&gt;, &lt;code&gt;--ask-for-approval/-a&lt;/code&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Memory &amp;amp; project docs&lt;/h2&gt; 
&lt;p&gt;You can give Codex extra instructions and guidance using &lt;code&gt;AGENTS.md&lt;/code&gt; files. Codex looks for &lt;code&gt;AGENTS.md&lt;/code&gt; files in the following places, and merges them top-down:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;~/.codex/AGENTS.md&lt;/code&gt; - personal global guidance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; at repo root - shared project notes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; in the current working directory - sub-folder/feature specifics&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h2&gt;Non-interactive / CI mode&lt;/h2&gt; 
&lt;p&gt;Run Codex head-less in pipelines. Example GitHub Action step:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;- name: Update changelog via Codex
  run: |
    npm install -g @openai/codex
    export OPENAI_API_KEY="${{ secrets.OPENAI_KEY }}"
    codex exec --full-auto "update CHANGELOG for next release"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;The Codex CLI can be configured to leverage MCP servers by defining an &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#mcp_servers"&gt;&lt;code&gt;mcp_servers&lt;/code&gt;&lt;/a&gt; section in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. It is intended to mirror how tools such as Claude and Cursor define &lt;code&gt;mcpServers&lt;/code&gt; in their respective JSON config files, though the Codex format is slightly different since it uses TOML rather than JSON, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# IMPORTANT: the top-level key is `mcp_servers` rather than `mcpServers`.
[mcp_servers.server-name]
command = "npx"
args = ["-y", "mcp-server"]
env = { "API_KEY" = "value" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] It is somewhat experimental, but the Codex CLI can also be run as an MCP &lt;em&gt;server&lt;/em&gt; via &lt;code&gt;codex mcp&lt;/code&gt;. If you launch it with an MCP client such as &lt;code&gt;npx @modelcontextprotocol/inspector codex mcp&lt;/code&gt; and send it a &lt;code&gt;tools/list&lt;/code&gt; request, you will see that there is only one tool, &lt;code&gt;codex&lt;/code&gt;, that accepts a grab-bag of inputs, including a catch-all &lt;code&gt;config&lt;/code&gt; map for anything you might want to override. Feel free to play around with it and provide feedback via GitHub issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Tracing / verbose logging&lt;/h2&gt; 
&lt;p&gt;Because Codex is written in Rust, it honors the &lt;code&gt;RUST_LOG&lt;/code&gt; environment variable to configure its logging behavior.&lt;/p&gt; 
&lt;p&gt;The TUI defaults to &lt;code&gt;RUST_LOG=codex_core=info,codex_tui=info&lt;/code&gt; and log messages are written to &lt;code&gt;~/.codex/log/codex-tui.log&lt;/code&gt;, so you can leave the following running in a separate terminal to monitor log messages as they are written:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;tail -F ~/.codex/log/codex-tui.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By comparison, the non-interactive mode (&lt;code&gt;codex exec&lt;/code&gt;) defaults to &lt;code&gt;RUST_LOG=error&lt;/code&gt;, but messages are printed inline, so there is no need to monitor a separate file.&lt;/p&gt; 
&lt;p&gt;See the Rust documentation on &lt;a href="https://docs.rs/env_logger/latest/env_logger/#enabling-logging"&gt;&lt;code&gt;RUST_LOG&lt;/code&gt;&lt;/a&gt; for more information on the configuration options.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;DotSlash&lt;/h3&gt; 
&lt;p&gt;The GitHub Release also contains a &lt;a href="https://dotslash-cli.com/"&gt;DotSlash&lt;/a&gt; file for the Codex CLI named &lt;code&gt;codex&lt;/code&gt;. Using a DotSlash file makes it possible to make a lightweight commit to source control to ensure all contributors use the same version of an executable, regardless of what platform they use for development.&lt;/p&gt;  
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build from source&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository and navigate to the root of the Cargo workspace.
git clone https://github.com/openai/codex.git
cd codex/codex-rs

# Install the Rust toolchain, if necessary.
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
source "$HOME/.cargo/env"
rustup component add rustfmt
rustup component add clippy

# Build Codex.
cargo build

# Launch the TUI with a sample prompt.
cargo run --bin codex -- "explain this codebase to me"

# After making changes, ensure the code is clean.
cargo fmt -- --config imports_granularity=Item
cargo clippy --tests

# Run the tests.
cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Codex supports a rich set of configuration options documented in &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md"&gt;&lt;code&gt;codex-rs/config.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;By default, Codex loads its configuration from &lt;code&gt;~/.codex/config.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Though &lt;code&gt;--config&lt;/code&gt; can be used to set/override ad-hoc config values for individual invocations of &lt;code&gt;codex&lt;/code&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenAI released a model called Codex in 2021 - is this related?&lt;/summary&gt; 
 &lt;p&gt;In 2021, OpenAI released Codex, an AI system designed to generate code from natural language prompts. That original Codex model was deprecated as of March 2023 and is separate from the CLI tool.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which models are supported?&lt;/summary&gt; 
 &lt;p&gt;Any model available with &lt;a href="https://platform.openai.com/docs/api-reference/responses"&gt;Responses API&lt;/a&gt;. The default is &lt;code&gt;o4-mini&lt;/code&gt;, but pass &lt;code&gt;--model gpt-4.1&lt;/code&gt; or set &lt;code&gt;model: gpt-4.1&lt;/code&gt; in your config file to override.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Why does &lt;code&gt;o3&lt;/code&gt; or &lt;code&gt;o4-mini&lt;/code&gt; not work for me?&lt;/summary&gt; 
 &lt;p&gt;It's possible that your &lt;a href="https://help.openai.com/en/articles/10910291-api-organization-verification"&gt;API account needs to be verified&lt;/a&gt; in order to start streaming responses and seeing chain of thought summaries from the API. If you're still running into issues, please let us know!&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do I stop Codex from editing my files?&lt;/summary&gt; 
 &lt;p&gt;Codex runs model-generated commands in a sandbox. If a proposed command or file change doesn't look right, you can simply type &lt;strong&gt;n&lt;/strong&gt; to deny the command or give the model feedback.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Does it work on Windows?&lt;/summary&gt; 
 &lt;p&gt;Not directly. It requires &lt;a href="https://learn.microsoft.com/en-us/windows/wsl/install"&gt;Windows Subsystem for Linux (WSL2)&lt;/a&gt; - Codex has been tested on macOS and Linux with Node 22.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;Zero data retention (ZDR) usage&lt;/h2&gt; 
&lt;p&gt;Codex CLI &lt;strong&gt;does&lt;/strong&gt; support OpenAI organizations with &lt;a href="https://platform.openai.com/docs/guides/your-data#zero-data-retention"&gt;Zero Data Retention (ZDR)&lt;/a&gt; enabled. If your OpenAI organization has Zero Data Retention enabled and you still encounter errors such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OpenAI rejected the request. Error details: Status: 400, Code: unsupported_parameter, Type: invalid_request_error, Message: 400 Previous response cannot be used for this organization due to Zero Data Retention.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure you are running &lt;code&gt;codex&lt;/code&gt; with &lt;code&gt;--config disable_response_storage=true&lt;/code&gt; or add this line to &lt;code&gt;~/.codex/config.toml&lt;/code&gt; to avoid specifying the command line option each time:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;disable_response_storage = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#disable_response_storage"&gt;the configuration documentation on &lt;code&gt;disable_response_storage&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Codex open source fund&lt;/h2&gt; 
&lt;p&gt;We're excited to launch a &lt;strong&gt;$1 million initiative&lt;/strong&gt; supporting open source projects that use Codex CLI and other OpenAI models.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Grants are awarded up to &lt;strong&gt;$25,000&lt;/strong&gt; API credits.&lt;/li&gt; 
 &lt;li&gt;Applications are reviewed &lt;strong&gt;on a rolling basis&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Interested? &lt;a href="https://openai.com/form/codex-open-source-fund/"&gt;Apply here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project is under active development and the code will likely change pretty significantly. We'll update this message once that's complete!&lt;/p&gt; 
&lt;p&gt;More broadly we welcome contributions - whether you are opening your very first pull request or you're a seasoned maintainer. At the same time we care about reliability and long-term maintainability, so the bar for merging code is intentionally &lt;strong&gt;high&lt;/strong&gt;. The guidelines below spell out what "high-quality" means in practice and should make the whole process transparent and friendly.&lt;/p&gt; 
&lt;h3&gt;Development workflow&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a &lt;em&gt;topic branch&lt;/em&gt; from &lt;code&gt;main&lt;/code&gt; - e.g. &lt;code&gt;feat/interactive-prompt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Keep your changes focused. Multiple unrelated fixes should be opened as separate PRs.&lt;/li&gt; 
 &lt;li&gt;Following the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/#development-workflow"&gt;development setup&lt;/a&gt; instructions above, ensure your change is free of lint warnings and test failures.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Writing high-impact code changes&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Start with an issue.&lt;/strong&gt; Open a new one or comment on an existing discussion so we can agree on the solution before code is written.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add or update tests.&lt;/strong&gt; Every new feature or bug-fix should come with test coverage that fails before your change and passes afterwards. 100% coverage is not required, but aim for meaningful assertions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document behaviour.&lt;/strong&gt; If your change affects user-facing behaviour, update the README, inline help (&lt;code&gt;codex --help&lt;/code&gt;), or relevant example projects.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Keep commits atomic.&lt;/strong&gt; Each commit should compile and the tests should pass. This makes reviews and potential rollbacks easier.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Opening a pull request&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fill in the PR template (or include similar information) - &lt;strong&gt;What? Why? How?&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;strong&gt;all&lt;/strong&gt; checks locally (&lt;code&gt;cargo test &amp;amp;&amp;amp; cargo clippy --tests &amp;amp;&amp;amp; cargo fmt -- --config imports_granularity=Item&lt;/code&gt;). CI failures that could have been caught locally slow down the process.&lt;/li&gt; 
 &lt;li&gt;Make sure your branch is up-to-date with &lt;code&gt;main&lt;/code&gt; and that you have resolved merge conflicts.&lt;/li&gt; 
 &lt;li&gt;Mark the PR as &lt;strong&gt;Ready for review&lt;/strong&gt; only when you believe it is in a merge-able state.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Review process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;One maintainer will be assigned as a primary reviewer.&lt;/li&gt; 
 &lt;li&gt;We may ask for changes - please do not take this personally. We value the work, we just also value consistency and long-term maintainability.&lt;/li&gt; 
 &lt;li&gt;When there is consensus that the PR meets the bar, a maintainer will squash-and-merge.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Community values&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Be kind and inclusive.&lt;/strong&gt; Treat others with respect; we follow the &lt;a href="https://www.contributor-covenant.org/"&gt;Contributor Covenant&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Assume good intent.&lt;/strong&gt; Written communication is hard - err on the side of generosity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teach &amp;amp; learn.&lt;/strong&gt; If you spot something confusing, open an issue or PR with improvements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting help&lt;/h3&gt; 
&lt;p&gt;If you run into problems setting up the project, would like feedback on an idea, or just want to say &lt;em&gt;hi&lt;/em&gt; - please open a Discussion or jump into the relevant issue. We are happy to help.&lt;/p&gt; 
&lt;p&gt;Together we can make Codex CLI an incredible tool. &lt;strong&gt;Happy hacking!&lt;/strong&gt; &lt;span&gt;ð&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;Contributor license agreement (CLA)&lt;/h3&gt; 
&lt;p&gt;All contributors &lt;strong&gt;must&lt;/strong&gt; accept the CLA. The process is lightweight:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Open your pull request.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Paste the following comment (or reply &lt;code&gt;recheck&lt;/code&gt; if you've signed before):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-text"&gt;I have read the CLA Document and I hereby sign the CLA
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The CLA-Assistant bot records your signature in the repo and marks the status check as passed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;No special Git commands, email attachments, or commit footers required.&lt;/p&gt; 
&lt;h4&gt;Quick fixes&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amend last commit&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;git commit --amend -s --no-edit &amp;amp;&amp;amp; git push -f&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The &lt;strong&gt;DCO check&lt;/strong&gt; blocks merges until every commit in the PR carries the footer (with squash this is just the one).&lt;/p&gt; 
&lt;h3&gt;Releasing &lt;code&gt;codex&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;For admins only.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Make sure you are on &lt;code&gt;main&lt;/code&gt; and have no local changes. Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;VERSION=0.2.0  # Can also be 0.2.0-alpha.1 or any valid Rust version.
./codex-rs/scripts/create_github_release.sh "$VERSION"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will make a local commit on top of &lt;code&gt;main&lt;/code&gt; with &lt;code&gt;version&lt;/code&gt; set to &lt;code&gt;$VERSION&lt;/code&gt; in &lt;code&gt;codex-rs/Cargo.toml&lt;/code&gt; (note that on &lt;code&gt;main&lt;/code&gt;, we leave the version as &lt;code&gt;version = "0.0.0"&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;This will push the commit using the tag &lt;code&gt;rust-v${VERSION}&lt;/code&gt;, which in turn kicks off &lt;a href="https://raw.githubusercontent.com/openai/codex/main/.github/workflows/rust-release.yml"&gt;the release workflow&lt;/a&gt;. This will create a new GitHub Release named &lt;code&gt;$VERSION&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If everything looks good in the generated GitHub Release, uncheck the &lt;strong&gt;pre-release&lt;/strong&gt; box so it is the latest release.&lt;/p&gt; 
&lt;p&gt;Create a PR to update &lt;a href="https://github.com/Homebrew/homebrew-core/raw/main/Formula/c/codex.rb"&gt;&lt;code&gt;Formula/c/codex.rb&lt;/code&gt;&lt;/a&gt; on Homebrew.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Security &amp;amp; responsible AI&lt;/h2&gt; 
&lt;p&gt;Have you discovered a vulnerability or have concerns about model output? Please e-mail &lt;strong&gt;&lt;a href="mailto:security@openai.com"&gt;security@openai.com&lt;/a&gt;&lt;/strong&gt; and we will respond promptly.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>python-poetry/poetry</title>
      <link>https://github.com/python-poetry/poetry</link>
      <description>&lt;p&gt;Python packaging and dependency management made easy&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Poetry: Python packaging and dependency management made easy&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://python-poetry.org/"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://python-poetry.org/badge/v0.json" alt="Poetry"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/poetry/#history"&gt;&lt;img src="https://img.shields.io/pypi/v/poetry?label=stable" alt="Stable Version"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/poetry/#history"&gt;&lt;img src="https://img.shields.io/github/v/release/python-poetry/poetry?label=pre-release&amp;amp;include_prereleases&amp;amp;sort=semver" alt="Pre-release Version"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/poetry/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/poetry" alt="Python Versions"&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/poetry"&gt;&lt;img src="https://img.shields.io/pypi/dm/poetry" alt="Download Stats"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/awxPgve"&gt;&lt;img src="https://img.shields.io/discord/487711540787675139?logo=discord" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Poetry helps you declare, manage and install dependencies of Python projects, ensuring you have the right stack everywhere.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/python-poetry/poetry/main/assets/install.gif" alt="Poetry Install"&gt;&lt;/p&gt; 
&lt;p&gt;Poetry replaces &lt;code&gt;setup.py&lt;/code&gt;, &lt;code&gt;requirements.txt&lt;/code&gt;, &lt;code&gt;setup.cfg&lt;/code&gt;, &lt;code&gt;MANIFEST.in&lt;/code&gt; and &lt;code&gt;Pipfile&lt;/code&gt; with a simple &lt;code&gt;pyproject.toml&lt;/code&gt; based project format.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[project]
name = "my-package"
version = "0.1.0"
description = "The description of the package"

license = { text = "MIT" }
readme = "README.md"

# No python upper bound for package metadata
requires-python = "&amp;gt;=3.9"

authors = [
    { name = "SeÌbastien Eustace", email = "sebastien@eustace.io" },
]

# Keywords (translated to tags on the package index)
keywords = ["packaging", "poetry"]

dependencies = [
    # equivalent to ^3.8.1 with semver constraints
    "aiohttp (&amp;gt;=3.8.1,&amp;lt;4.0.0)",
    # dependency with extras
    "requests[security] (&amp;gt;=2.28,&amp;lt;3.0)",
    # version-specific dependency with prereleases allowed (see below)
    "tomli (&amp;gt;=2.0.1,&amp;lt;3.0.0) ; python_version &amp;lt; '3.11'",
    # git dependency with branch specified
    "cleo @ git+https://github.com/python-poetry/cleo.git@main",
]

[project.urls]
repository = "https://github.com/python-poetry/poetry"
homepage = "https://python-poetry.org"

# Scripts are easily expressed
[project.scripts]
my_package_cli = 'my_package.console:run'

[project.optional-dependencies]
# optional dependency to be installed via 'poetry install -E my-extra'
my-extra = ["pendulum (&amp;gt;=3.1.0,&amp;lt;4.0.0)"]

[tool.poetry.dependencies]
# Python upper bound for locking
python = "&amp;gt;=3.9,&amp;lt;4.0"
# Version-specific dependencies with prereleases allowed
tomli = { allow-prereleases = true }

# Dependency groups are supported for organizing your dependencies
[tool.poetry.group.dev.dependencies]
pytest = "^7.1.2"
pytest-cov = "^3.0"

# ...and can be installed only when explicitly requested
# via 'poetry install --with docs'
[tool.poetry.group.docs]
optional = true
[tool.poetry.group.docs.dependencies]
Sphinx = "^5.1.1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Poetry supports multiple installation methods, including a simple script found at &lt;a href="https://install.python-poetry.org"&gt;install.python-poetry.org&lt;/a&gt;. For full installation instructions, including advanced usage of the script, alternate install methods, and CI best practices, see the full &lt;a href="https://python-poetry.org/docs/#installation"&gt;installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://python-poetry.org/docs/"&gt;Documentation&lt;/a&gt; for the current version of Poetry (as well as the development branch and recently out of support versions) is available from the &lt;a href="https://python-poetry.org"&gt;official website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;Poetry is a large, complex project always in need of contributors. For those new to the project, a list of &lt;a href="https://github.com/python-poetry/poetry/contribute"&gt;suggested issues&lt;/a&gt; to work on in Poetry and poetry-core is available. The full &lt;a href="https://python-poetry.org/docs/contributing"&gt;contributing documentation&lt;/a&gt; also provides helpful guidance.&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/poetry/#history"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://python-poetry.org"&gt;Official Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://python-poetry.org/docs/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-poetry/poetry/issues"&gt;Issue Tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.com/invite/awxPgve"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-poetry/poetry-core"&gt;poetry-core&lt;/a&gt;: PEP 517 build-system for Poetry projects, and dependency-free core functionality of the Poetry frontend&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-poetry/poetry-plugin-export"&gt;poetry-plugin-export&lt;/a&gt;: Export Poetry projects/lock files to foreign formats like requirements.txt&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-poetry/poetry-plugin-bundle"&gt;poetry-plugin-bundle&lt;/a&gt;: Install Poetry projects/lock files to external formats like virtual environments&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-poetry/install.python-poetry.org"&gt;install.python-poetry.org&lt;/a&gt;: The official Poetry installation script&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-poetry/website"&gt;website&lt;/a&gt;: The official Poetry website and blog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supporters&lt;/h2&gt; 
&lt;p&gt;Thanks to &lt;a href="https://www.jetbrains.com"&gt;JetBrains&lt;/a&gt; for supporting us with licenses for their tools.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.jetbrains.com"&gt;&lt;img src="https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg?sanitize=true" width="150" alt="JetBrains logo."&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>polarsource/polar</title>
      <link>https://github.com/polarsource/polar</link>
      <description>&lt;p&gt;An open source engine for your digital products. Sell SaaS and digital products in minutes.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://polar.sh"&gt; &lt;img src="https://github.com/user-attachments/assets/89a588e5-0c58-429a-8bbe-20f70af41372"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.producthunt.com/posts/polar-5?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-polar-5" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=484271&amp;amp;theme=dark&amp;amp;period=daily" alt="Polar - An open source monetization platform for developers | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54"&gt;&lt;/a&gt; &lt;a href="https://www.producthunt.com/posts/polar-5?embed=true&amp;amp;utm_source=badge-top-post-topic-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-polar-5" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=484271&amp;amp;theme=dark&amp;amp;period=monthly&amp;amp;topic_id=267" alt="Polar - An open source monetization platform for developers | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://polar.sh"&gt;Website&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;â¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://polar.sh/blog"&gt;Blog&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;â¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://polar.sh/docs"&gt;Docs&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;â¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://docs.polar.sh/api-reference"&gt;API Reference&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://discord.gg/Pnhfz3UThd"&gt; &lt;img src="https://img.shields.io/badge/chat-on%20discord-7289DA.svg?sanitize=true" alt="Discord Chat"&gt; &lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=polar_sh"&gt; &lt;img src="https://img.shields.io/twitter/follow/polar_sh.svg?label=Follow%20@polar_sh" alt="Follow @polar_sh"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;Polar: Open Source payments infrastructure for the 21st century&lt;/h2&gt; 
&lt;p&gt;Focus on building your passion, while we focus on the infrastructure to get you paid.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sell SaaS and digital products in minutes&lt;/li&gt; 
 &lt;li&gt;All-in-one funding &amp;amp; monetization platform for developers.&lt;/li&gt; 
 &lt;li&gt;Sell access to GitHub repositories, Discord Support channels, File Downloads, License Keys &amp;amp; much more with Digital Products &amp;amp; Subscriptions.&lt;/li&gt; 
 &lt;li&gt;We're the merchant of record handling the... 
  &lt;ul&gt; 
   &lt;li&gt;...boilerplate (billing, receipts, customer accounts etc)&lt;/li&gt; 
   &lt;li&gt;...headaches (sales tax, VAT)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Pricing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;4% + 40Â¢&lt;/li&gt; 
 &lt;li&gt;No fixed monthly costs&lt;/li&gt; 
 &lt;li&gt;Additional fees may apply. &lt;a href="https://docs.polar.sh/documentation/polar-as-merchant-of-record/fees"&gt;Read more&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap, Issues &amp;amp; Feature Requests&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ð¯ Upcoming milestones.&lt;/strong&gt; &lt;a href="https://github.com/polarsource/polar/issues/3242"&gt;Check out what we're building towards&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ð¬ Shape the future of Polar with us.&lt;/strong&gt; &lt;a href="https://discord.gg/Pnhfz3UThd"&gt;Join our Discord&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ð Found a bug?&lt;/strong&gt; &lt;a href="https://github.com/polarsource/polar/issues"&gt;Submit it here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ð Found a security vulnerability?&lt;/strong&gt; We greatly appreciate responsible and private disclosures. See &lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/SECURITY.md"&gt;Security&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Polar API &amp;amp; SDK&lt;/h3&gt; 
&lt;p&gt;You can integrate Polar on your docs, sites or services using our &lt;a href="https://docs.polar.sh/api-reference"&gt;Public API&lt;/a&gt; and &lt;a href="https://docs.polar.sh/developers/webhooks"&gt;Webhook API&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We also maintain SDKs for the following languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JavaScript (Node.js and browsers): &lt;a href="https://github.com/polarsource/polar-js"&gt;polarsource/polar-js&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Python: &lt;a href="https://github.com/polarsource/polar-python"&gt;polarsource/polar-python&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Our &lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/DEVELOPMENT.md"&gt;&lt;code&gt;DEVELOPMENT.md&lt;/code&gt;&lt;/a&gt; file contains everything you need to know to configure your development environment.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Want to get started quickly? Use GitHub Codespaces.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://codespaces.new/polarsource/polar?machine=standardLinux32gb"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="Open in GitHub Codespaces"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;a href="https://github.com/polarsource/polar/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=polarsource/polar"&gt; &lt;/a&gt; 
&lt;h2&gt;Monorepo&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/server/README.md"&gt;server&lt;/a&gt;&lt;/strong&gt; â Python / FastAPI / Dramatiq / SQLAlchemy (PostgreSQL) / Redis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/clients/README.md"&gt;clients&lt;/a&gt;&lt;/strong&gt; â Turborepo 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/clients/apps/web"&gt;web&lt;/a&gt; (Dashboard) â NextJS (TypeScript)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/clients/packages/polarkit"&gt;polarkit&lt;/a&gt; - Shared React components&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;sub&gt;â¥ï¸ð To our &lt;code&gt;pyproject.toml&lt;/code&gt; friends: &lt;a href="https://github.com/tiangolo/fastapi"&gt;FastAPI&lt;/a&gt;, &lt;a href="https://github.com/pydantic/pydantic"&gt;Pydantic&lt;/a&gt;, &lt;a href="https://github.com/Bogdanp/dramatiq"&gt;Dramatiq&lt;/a&gt;, &lt;a href="https://github.com/sqlalchemy/sqlalchemy"&gt;SQLAlchemy&lt;/a&gt;, &lt;a href="https://github.com/yanyongyu/githubkit"&gt;Githubkit&lt;/a&gt;, &lt;a href="https://github.com/sysid/sse-starlette"&gt;sse-starlette&lt;/a&gt;, &lt;a href="https://github.com/encode/uvicorn"&gt;Uvicorn&lt;/a&gt;, &lt;a href="https://github.com/frankie567/httpx-oauth"&gt;httpx-oauth&lt;/a&gt;, &lt;a href="https://github.com/pallets/jinja"&gt;jinja&lt;/a&gt;, &lt;a href="https://github.com/pallets-eco/blinker"&gt;blinker&lt;/a&gt;, &lt;a href="https://github.com/jpadilla/pyjwt"&gt;pyjwt&lt;/a&gt;, &lt;a href="https://github.com/getsentry/sentry"&gt;Sentry&lt;/a&gt; + more&lt;/sub&gt;&lt;br&gt; &lt;sub&gt;â¥ï¸ð To our &lt;code&gt;package.json&lt;/code&gt; friends: &lt;a href="https://github.com/vercel/next.js/"&gt;Next.js&lt;/a&gt;, &lt;a href="https://github.com/TanStack/query"&gt;TanStack Query&lt;/a&gt;, &lt;a href="https://github.com/tailwindlabs/tailwindcss"&gt;tailwindcss&lt;/a&gt;, &lt;a href="https://github.com/pmndrs/zustand"&gt;zustand&lt;/a&gt;, &lt;a href="https://github.com/ferdikoomen/openapi-typescript-codegen"&gt;openapi-typescript-codegen&lt;/a&gt;, &lt;a href="https://github.com/axios/axios"&gt;axios&lt;/a&gt;, &lt;a href="https://github.com/radix-ui/primitives"&gt;radix-ui&lt;/a&gt;, &lt;a href="https://github.com/pacocoursey/cmdk"&gt;cmdk&lt;/a&gt;, &lt;a href="https://github.com/framer/motion"&gt;framer-motion&lt;/a&gt; + more&lt;/sub&gt;&lt;br&gt; &lt;sub&gt;â¥ï¸ð To &lt;a href="https://ipinfo.io"&gt;IPinfo&lt;/a&gt; that provides IP address data to help us geolocate customers during checkout.&lt;/sub&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;Apache License, Version 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/openai-cookbook</title>
      <link>https://github.com/openai/openai-cookbook</link>
      <description>&lt;p&gt;Examples and guides for using the OpenAI API&lt;/p&gt;&lt;hr&gt;&lt;a href="https://cookbook.openai.com" target="_blank"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="/images/openai-cookbook-white.png" style="max-width: 100%; width: 400px; margin-bottom: 20px"&gt; 
  &lt;img alt="OpenAI Cookbook Logo" src="https://raw.githubusercontent.com/openai/openai-cookbook/main/images/openai-cookbook.png" width="400px"&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h3&gt;&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;â¨ Navigate at &lt;a href="https://cookbook.openai.com"&gt;cookbook.openai.com&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Example code and guides for accomplishing common tasks with the &lt;a href="https://platform.openai.com/docs/introduction"&gt;OpenAI API&lt;/a&gt;. To run these examples, you'll need an OpenAI account and associated API key (&lt;a href="https://platform.openai.com/signup"&gt;create a free account here&lt;/a&gt;). Set an environment variable called &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; with your API key. Alternatively, in most IDEs such as Visual Studio Code, you can create an &lt;code&gt;.env&lt;/code&gt; file at the root of your repo containing &lt;code&gt;OPENAI_API_KEY=&amp;lt;your API key&amp;gt;&lt;/code&gt;, which will be picked up by the notebooks.&lt;/p&gt; 
&lt;p&gt;Most code examples are written in Python, though the concepts can be applied in any language.&lt;/p&gt; 
&lt;p&gt;For other useful tools, guides and courses, check out these &lt;a href="https://cookbook.openai.com/related_resources"&gt;related resources from around the web&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google/adk-python</title>
      <link>https://github.com/google/adk-python</link>
      <description>&lt;p&gt;An open-source, code-first Python toolkit for building, evaluating, and deploying sophisticated AI agents with flexibility and control.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agent Development Kit (ADK)&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-python/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;a href="https://github.com/google/adk-python/actions/workflows/python-unit-tests.yml"&gt;&lt;img src="https://github.com/google/adk-python/actions/workflows/python-unit-tests.yml/badge.svg?sanitize=true" alt="Python Unit Tests"&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/agentdevelopmentkit/"&gt;&lt;img src="https://img.shields.io/badge/Reddit-r%2Fagentdevelopmentkit-FF4500?style=flat&amp;amp;logo=reddit&amp;amp;logoColor=white" alt="r/agentdevelopmentkit"&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/google/adk-python"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki"&gt;&lt;/a&gt;&lt;/p&gt;  
&lt;h2 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/google/adk-python/main/assets/agent-development-kit.png" width="256"&gt; &lt;/h2&gt; 
&lt;h3 align="center"&gt; An open-source, code-first Python toolkit for building, evaluating, and deploying sophisticated AI agents with flexibility and control. &lt;/h3&gt; 
&lt;h3 align="center"&gt; Important Links: &lt;a href="https://google.github.io/adk-docs/"&gt;Docs&lt;/a&gt;, &lt;a href="https://github.com/google/adk-samples"&gt;Samples&lt;/a&gt;, &lt;a href="https://github.com/google/adk-java"&gt;Java ADK&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/google/adk-web"&gt;ADK Web&lt;/a&gt;. &lt;/h3&gt;  
&lt;p&gt;Agent Development Kit (ADK) is a flexible and modular framework for developing and deploying AI agents. While optimized for Gemini and the Google ecosystem, ADK is model-agnostic, deployment-agnostic, and is built for compatibility with other frameworks. ADK was designed to make agent development feel more like software development, to make it easier for developers to create, deploy, and orchestrate agentic architectures that range from simple tasks to complex workflows.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;â¨ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rich Tool Ecosystem&lt;/strong&gt;: Utilize pre-built tools, custom functions, OpenAPI specs, or integrate existing tools to give agents diverse capabilities, all for tight integration with the Google ecosystem.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Code-First Development&lt;/strong&gt;: Define agent logic, tools, and orchestration directly in Python for ultimate flexibility, testability, and versioning.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Modular Multi-Agent Systems&lt;/strong&gt;: Design scalable applications by composing multiple specialized agents into flexible hierarchies.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deploy Anywhere&lt;/strong&gt;: Easily containerize and deploy agents on Cloud Run or scale seamlessly with Vertex AI Agent Engine.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ð¤ Agent2Agent (A2A) Protocol and ADK Integration&lt;/h2&gt; 
&lt;p&gt;For remote agent-to-agent communication, ADK integrates with the &lt;a href="https://github.com/google-a2a/A2A/"&gt;A2A protocol&lt;/a&gt;. See this &lt;a href="https://github.com/a2aproject/a2a-samples/tree/main/samples/python/agents"&gt;example&lt;/a&gt; for how they can work together.&lt;/p&gt; 
&lt;h2&gt;ð Installation&lt;/h2&gt; 
&lt;h3&gt;Stable Release (Recommended)&lt;/h3&gt; 
&lt;p&gt;You can install the latest stable version of ADK using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install google-adk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The release cadence is weekly.&lt;/p&gt; 
&lt;p&gt;This version is recommended for most users as it represents the most recent official release.&lt;/p&gt; 
&lt;h3&gt;Development Version&lt;/h3&gt; 
&lt;p&gt;Bug fixes and new features are merged into the main branch on GitHub first. If you need access to changes that haven't been included in an official PyPI release yet, you can install directly from the main branch:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/google/adk-python.git@main
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: The development version is built directly from the latest code commits. While it includes the newest fixes and features, it may also contain experimental changes or bugs not present in the stable release. Use it primarily for testing upcoming changes or accessing critical fixes before they are officially released.&lt;/p&gt; 
&lt;h2&gt;ð Documentation&lt;/h2&gt; 
&lt;p&gt;Explore the full documentation for detailed guides on building, evaluating, and deploying agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://google.github.io/adk-docs"&gt;Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ð Feature Highlight&lt;/h2&gt; 
&lt;h3&gt;Define a single agent:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from google.adk.agents import Agent
from google.adk.tools import google_search

root_agent = Agent(
    name="search_assistant",
    model="gemini-2.0-flash", # Or your preferred Gemini model
    instruction="You are a helpful assistant. Answer user questions using Google Search when needed.",
    description="An assistant that can search the web.",
    tools=[google_search]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Define a multi-agent system:&lt;/h3&gt; 
&lt;p&gt;Define a multi-agent system with coordinator agent, greeter agent, and task execution agent. Then ADK engine and the model will guide the agents works together to accomplish the task.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from google.adk.agents import LlmAgent, BaseAgent

# Define individual agents
greeter = LlmAgent(name="greeter", model="gemini-2.0-flash", ...)
task_executor = LlmAgent(name="task_executor", model="gemini-2.0-flash", ...)

# Create parent agent and assign children via sub_agents
coordinator = LlmAgent(
    name="Coordinator",
    model="gemini-2.0-flash",
    description="I coordinate greetings and tasks.",
    sub_agents=[ # Assign sub_agents here
        greeter,
        task_executor
    ]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development UI&lt;/h3&gt; 
&lt;p&gt;A built-in development UI to help you test, evaluate, debug, and showcase your agent(s).&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/google/adk-python/main/assets/adk-web-dev-ui-function-call.png"&gt; 
&lt;h3&gt;Evaluate Agents&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;adk eval \
    samples_for_testing/hello_world \
    samples_for_testing/hello_world/hello_world_eval_set_001.evalset.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ð¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether it's bug reports, feature requests, documentation improvements, or code contributions, please see our&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://google.github.io/adk-docs/contributing-guide/"&gt;General contribution guideline and flow&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Then if you want to contribute code, please read &lt;a href="https://raw.githubusercontent.com/google/adk-python/main/CONTRIBUTING.md"&gt;Code Contributing Guidelines&lt;/a&gt; to get started.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Vibe Coding&lt;/h2&gt; 
&lt;p&gt;If you are to develop agent via vibe coding the &lt;a href="https://raw.githubusercontent.com/google/adk-python/main/llms.txt"&gt;llms.txt&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/google/adk-python/main/llms-full.txt"&gt;llms-full.txt&lt;/a&gt; can be used as context to LLM. While the former one is a summarized one and the later one has the full information in case your LLM has big enough context window.&lt;/p&gt; 
&lt;h2&gt;ð License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://raw.githubusercontent.com/google/adk-python/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;em&gt;Happy Agent Building!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>backstage/backstage</title>
      <link>https://github.com/backstage/backstage</link>
      <description>&lt;p&gt;Backstage is an open framework for building developer portals&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://backstage.io/"&gt;&lt;img src="https://raw.githubusercontent.com/backstage/backstage/master/docs/assets/headline.png" alt="headline"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;a href="https://backstage.io"&gt;Backstage&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/backstage/backstage/master/README-ko_kr.md"&gt;íêµ­ì´&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/backstage/backstage/master/README-zh_Hans.md"&gt;ä¸­æç&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/backstage/backstage/master/README-fr_FR.md"&gt;FranÃ§ais&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;a href="https://www.cncf.io/projects"&gt;&lt;img src="https://img.shields.io/badge/cncf%20status-incubation-blue.svg?sanitize=true" alt="CNCF Status"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/backstage-687207715902193673"&gt;&lt;img src="https://img.shields.io/discord/687207715902193673?logo=discord&amp;amp;label=Discord&amp;amp;color=5865F2&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/code_style-prettier-ff69b4.svg?sanitize=true" alt="Code style"&gt; &lt;a href="https://codecov.io/gh/backstage/backstage"&gt;&lt;img src="https://img.shields.io/codecov/c/github/backstage/backstage" alt="Codecov"&gt;&lt;/a&gt; &lt;a href="https://github.com/backstage/backstage/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/backstage/backstage" alt=""&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/7678"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/7678/badge" alt="OpenSSF Best Practices"&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/backstage/backstage"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/backstage/backstage/badge" alt="OpenSSF Scorecard"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What is Backstage?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://backstage.io/"&gt;Backstage&lt;/a&gt; is an open source framework for building developer portals. Powered by a centralized software catalog, Backstage restores order to your microservices and infrastructure and enables your product teams to ship high-quality code quickly without compromising autonomy.&lt;/p&gt; 
&lt;p&gt;Backstage unifies all your infrastructure tooling, services, and documentation to create a streamlined development environment from end to end.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/backstage/backstage/master/docs/assets/header.png" alt="software-catalog"&gt;&lt;/p&gt; 
&lt;p&gt;Out of the box, Backstage includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/docs/features/software-catalog/"&gt;Backstage Software Catalog&lt;/a&gt; for managing all your software such as microservices, libraries, data pipelines, websites, and ML models&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/docs/features/software-templates/"&gt;Backstage Software Templates&lt;/a&gt; for quickly spinning up new projects and standardizing your tooling with your organizationâs best practices&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/docs/features/techdocs/"&gt;Backstage TechDocs&lt;/a&gt; for making it easy to create, maintain, find, and use technical documentation, using a "docs like code" approach&lt;/li&gt; 
 &lt;li&gt;Plus, a growing ecosystem of &lt;a href="https://github.com/backstage/backstage/tree/master/plugins"&gt;open source plugins&lt;/a&gt; that further expand Backstageâs customizability and functionality&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Backstage was created by Spotify but is now hosted by the &lt;a href="https://www.cncf.io"&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt; as an Incubation level project. For more information, see the &lt;a href="https://backstage.io/blog/2022/03/16/backstage-turns-two#out-of-the-sandbox-and-into-incubation"&gt;announcement&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Project roadmap&lt;/h2&gt; 
&lt;p&gt;For information about the detailed project roadmap including delivered milestones, see &lt;a href="https://backstage.io/docs/overview/roadmap"&gt;the Roadmap&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To start using Backstage, see the &lt;a href="https://backstage.io/docs/getting-started"&gt;Getting Started documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The documentation of Backstage includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/docs"&gt;Main documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/docs/features/software-catalog/"&gt;Software Catalog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/docs/overview/architecture-overview"&gt;Architecture&lt;/a&gt; (&lt;a href="https://backstage.io/docs/architecture-decisions/"&gt;Decisions&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/docs/dls/design"&gt;Designing for Backstage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/storybook"&gt;Storybook - UI components&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;To engage with our community, you can use the following resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/backstage-687207715902193673"&gt;Discord chatroom&lt;/a&gt; - Get support or discuss the project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/backstage/backstage/raw/master/CONTRIBUTING.md"&gt;Contributing to Backstage&lt;/a&gt; - Start here if you want to contribute&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/backstage/backstage/labels/rfc"&gt;RFCs&lt;/a&gt; - Help shape the technical direction&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/docs/faq"&gt;FAQ&lt;/a&gt; - Frequently Asked Questions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/backstage/backstage/master/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; - This is how we roll&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/backstage/backstage/master/ADOPTERS.md"&gt;Adopters&lt;/a&gt; - Companies already using Backstage&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://backstage.io/blog/"&gt;Blog&lt;/a&gt; - Announcements and updates&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spoti.fi/backstagenewsletter"&gt;Newsletter&lt;/a&gt; - Subscribe to our email newsletter&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/backstage/community"&gt;Backstage Community Sessions&lt;/a&gt; - Join monthly meetups and explore Backstage community&lt;/li&gt; 
 &lt;li&gt;Give us a star â­ï¸ - If you are using Backstage or think it is an interesting project, we would love a star â¤ï¸&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Governance&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/backstage/community/raw/main/GOVERNANCE.md"&gt;GOVERNANCE.md&lt;/a&gt; document in the &lt;a href="https://github.com/backstage/community"&gt;backstage/community&lt;/a&gt; repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright 2020-2025 Â© The Backstage Authors. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our Trademark Usage page: &lt;a href="https://www.linuxfoundation.org/trademark-usage"&gt;https://www.linuxfoundation.org/trademark-usage&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0: &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;Please report sensitive security issues using Spotify's &lt;a href="https://hackerone.com/spotify"&gt;bug-bounty program&lt;/a&gt; rather than GitHub.&lt;/p&gt; 
&lt;p&gt;For further details, see our complete &lt;a href="https://raw.githubusercontent.com/backstage/backstage/master/SECURITY.md"&gt;security release process&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>