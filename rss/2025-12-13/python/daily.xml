<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Fri, 12 Dec 2025 01:38:29 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>mindsdb/mindsdb</title>
      <link>https://github.com/mindsdb/mindsdb</link>
      <description>&lt;p&gt;Federated query engine for AI - The only MCP Server you'll ever need&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://pypi.org/project/MindsDB/" target="_blank"&gt;&lt;img src="https://badge.fury.io/py/MindsDB.svg?sanitize=true" alt="MindsDB Release" /&gt;&lt;/a&gt; 
 &lt;a href="https://www.python.org/downloads/" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/python-3.10.x%7C%203.11.x%7C%203.12.x%7C%203.13.x-brightgreen.svg?sanitize=true" alt="Python supported" /&gt;&lt;/a&gt; 
 &lt;a href="https://hub.docker.com/u/mindsdb" target="_blank"&gt;&lt;img src="https://img.shields.io/docker/pulls/mindsdb/mindsdb" alt="Docker pulls" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/3068" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3068" alt="mindsdb%2Fmindsdb | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;a href="https://github.com/mindsdb/mindsdb"&gt; &lt;img src="https://raw.githubusercontent.com/mindsdb/mindsdb/main/docs/assets/mindsdb_logo.png" alt="MindsDB" width="300" /&gt; &lt;/a&gt; 
 &lt;p align="center"&gt; &lt;br /&gt; &lt;a href="https://www.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Website&lt;/a&gt; ¬∑ &lt;a href="https://docs.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://mindsdb.com/contact"&gt;Contact us for a Demo&lt;/a&gt; ¬∑ &lt;a href="https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Community Slack&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;MindsDB enables humans, AI, agents, and applications to get highly accurate answers across large scale data sources.&lt;/p&gt; 
&lt;a href="https://www.youtube.com/watch?v=MX3OKpnsoLM" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/119e7b82-f901-4214-a26f-ff7c5ad86064" alt="MindsDB Demo" /&gt; &lt;/a&gt; 
&lt;h2&gt;Install MindsDB Server&lt;/h2&gt; 
&lt;p&gt;MindsDB is an open-source server that can be deployed anywhere - from your laptop to the cloud, and everywhere in between. And yes, you can customize it to your heart's content.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/setup/self-hosted/docker-desktop"&gt;Using Docker Desktop&lt;/a&gt;. This is the fastest and recommended way to get started and have it all running.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/setup/self-hosted/docker"&gt;Using Docker&lt;/a&gt;. This is also simple, but gives you more flexibility on how to further customize your server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://docs.mindsdb.com/mcp/overview"&gt;MindsDB has an MCP server built in&lt;/a&gt; that enables your MCP applications to connect, unify and respond to questions over large-scale federated data‚Äîspanning databases, data warehouses, and SaaS applications.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Core Philosophy: Connect, Unify, Respond&lt;/h1&gt; 
&lt;p&gt;MindsDB's architecture is built around three fundamental capabilities:&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/integrations/data-overview"&gt;Connect&lt;/a&gt; Your Data&lt;/h2&gt; 
&lt;p&gt;You can connect to hundreds of enterprise &lt;a href="https://docs.mindsdb.com/integrations/data-overview"&gt;data sources (learn more)&lt;/a&gt;. These integrations allow MindsDB to access data wherever it resides, forming the foundation for all other capabilities.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/overview"&gt;Unify&lt;/a&gt; Your Data&lt;/h2&gt; 
&lt;p&gt;In many situations, it‚Äôs important to be able to prepare and unify data before generating responses from it. MindsDB SQL offers knowledge bases and views that allow indexing and organizing structured and unstructured data as if it were unified in a single system.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/knowledge-bases"&gt;&lt;strong&gt;KNOWLEDGE BASES&lt;/strong&gt;&lt;/a&gt; ‚Äì Index and organize unstructured data for efficient Q&amp;amp;A.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/sql/create/view"&gt;&lt;strong&gt;VIEWS&lt;/strong&gt;&lt;/a&gt; ‚Äì Simplify data access by creating unified views across different sources (no-ETL).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Unification of data can be automated using JOBs&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/sql/create/jobs"&gt;&lt;strong&gt;JOBS&lt;/strong&gt;&lt;/a&gt; ‚Äì Schedule synchronization and transformation tasks for real-time processing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/agents/agent"&gt;Respond&lt;/a&gt; From Your Data&lt;/h2&gt; 
&lt;p&gt;Chat with Your Data&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/agents/agent"&gt;&lt;strong&gt;AGENTS&lt;/strong&gt;&lt;/a&gt; ‚Äì Configure built-in agents specialized in answering questions over your connected and unified data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mcp/overview"&gt;&lt;strong&gt;MCP&lt;/strong&gt;&lt;/a&gt; ‚Äì Connect to MindsDB through the MCP (Model Context Protocol) for seamless interaction.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contribute&lt;/h2&gt; 
&lt;p&gt;Interested in contributing to MindsDB? Follow our &lt;a href="https://docs.mindsdb.com/contribute/install?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;installation guide for development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find our &lt;a href="https://docs.mindsdb.com/contribute/contribute?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;contribution guide here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We welcome suggestions! Feel free to open new issues with your ideas, and we‚Äôll guide you.&lt;/p&gt; 
&lt;p&gt;This project adheres to a &lt;a href="https://github.com/mindsdb/mindsdb/raw/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating, you agree to follow its terms.&lt;/p&gt; 
&lt;p&gt;Also, check out our &lt;a href="https://mindsdb.com/community?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;community rewards and programs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ç Support&lt;/h2&gt; 
&lt;p&gt;If you find a bug, please submit an &lt;a href="https://github.com/mindsdb/mindsdb/issues/new/choose"&gt;issue on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Here‚Äôs how you can get community support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ask a question in our &lt;a href="https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Slack Community&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://github.com/mindsdb/mindsdb/discussions"&gt;GitHub Discussions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Post on &lt;a href="https://stackoverflow.com/questions/tagged/mindsdb"&gt;Stack Overflow&lt;/a&gt; with the MindsDB tag.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For commercial support, please &lt;a href="https://mindsdb.com/contact?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;contact the MindsDB team&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üíö Current Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/mindsdb/mindsdb/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=mindsdb/mindsdb" /&gt; &lt;/a&gt; 
&lt;p&gt;Generated with &lt;a href="https://contributors-img.web.app"&gt;contributors-img&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üîî Subscribe for Updates&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://mindsdb.com/joincommunity"&gt;Slack community&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>srbhr/Resume-Matcher</title>
      <link>https://github.com/srbhr/Resume-Matcher</link>
      <description>&lt;p&gt;Improve your resumes with Resume Matcher. Get insights, keyword suggestions and tune your resumes to job descriptions.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.resumematcher.fyi"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/page_2.png" alt="Resume Matcher" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;Resume Matcher&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://dsc.gg/resume-matcher"&gt;ùôπùöòùöíùöó ùô≥ùöíùöúùöåùöòùöõùöç&lt;/a&gt; ‚ú¶ &lt;a href="https://resumematcher.fyi"&gt;ùöÜùöéùöãùöúùöíùöùùöé&lt;/a&gt; ‚ú¶ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#how-to-install"&gt;ùô∑ùöòùö† ùöùùöò ùô∏ùöóùöúùöùùöäùöïùöï&lt;/a&gt; ‚ú¶ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#contributors"&gt;ùô≤ùöòùöóùöùùöõùöíùöãùöûùöùùöòùöõùöú&lt;/a&gt; ‚ú¶ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#support-the-development-by-donating"&gt;ùô≥ùöòùöóùöäùöùùöé&lt;/a&gt; ‚ú¶ &lt;a href="https://twitter.com/ssrbhr"&gt;ùöÉùö†ùöíùöùùöùùöéùöõ/ùöá&lt;/a&gt; ‚ú¶ &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;ùôªùöíùöóùöîùöéùöçùô∏ùöó&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Stop getting auto-rejected by ATS bots.&lt;/strong&gt; Resume Matcher is the AI-powered platform that reverse-engineers hiring algorithms to show you exactly how to tailor your resume. Get the keywords, formatting, and insights that actually get you past the first screen and into human hands.&lt;/p&gt; 
 &lt;p&gt;Hoping to make this, &lt;strong&gt;VS Code for making resumes&lt;/strong&gt;.&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Stars" /&gt; &lt;img src="https://img.shields.io/github/license/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Apache 2.0" /&gt; &lt;img src="https://img.shields.io/github/forks/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Forks" /&gt; &lt;img src="https://img.shields.io/badge/Version-0.1%20Veridis%20Quo-FFF?labelColor=black&amp;amp;logo=LinkedIn&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="version" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://dsc.gg/resume-matcher"&gt;&lt;img src="https://img.shields.io/discord/1122069176962531400?labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=c20a71&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://resumematcher.fyi"&gt;&lt;img src="https://img.shields.io/badge/website-Resume%20Matcher-FFF?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Website" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-Resume%20Matcher-FFF?labelColor=black&amp;amp;logo=LinkedIn&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="LinkedIn" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/565" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/565" alt="srbhr%2FResume-Matcher | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://vercel.com/oss/program-badge.svg?sanitize=true" alt="Vercel OSS Program" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;This project is in active development. New features are being added continuously, and we welcome contributions from the community. There are some breaking changes on the &lt;code&gt;main&lt;/code&gt; branch. If you have any suggestions or feature requests, please feel free to open an issue on GitHub or discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started with Resume Matcher&lt;/h2&gt; 
&lt;p&gt;Resume Matcher is designed to help you optimize your resume with the aim to highlight your skills and experience in a way that resonates with potential employers.&lt;/p&gt; 
&lt;p&gt;We're actively working on improving the platform, building towards a &lt;strong&gt;VS Code for making resumes&lt;/strong&gt;, and adding new features. The best way to stay updated is to join the Discord discussion and be part of the active development community.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Join our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; community üëá &lt;a href="https://dsc.gg/resume-matcher"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_discord.png" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Follow us on &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;LinkedIn&lt;/a&gt; ‚ú® &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_linkedin.png" alt="LinkedIn" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚≠ê Star Resume Matcher to support the development and get updates on GitHub. &lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/star_resume_matcher.png" alt="Star Resume Matcher" /&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_features.png" alt="resume_matcher_features" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Works locally&lt;/strong&gt;: No need to upload your resume to a server. Everything runs on your machine with open source AI models by Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ATS Compatibility&lt;/strong&gt;: Get a detailed analysis of your resume's compatibility with ATS systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instant Match Score&lt;/strong&gt;: Upload resume &amp;amp; job description for a quick match score and key improvement areas.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Keyword Optimizer&lt;/strong&gt;: Align your resume with job keywords and identify critical content gaps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Guided Improvements&lt;/strong&gt;: Get clear suggestions to make your resume stand out.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Roadmap&lt;/h3&gt; 
&lt;p&gt;If you have any suggestions or feature requests, please feel free to open an issue on GitHub. And discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visual keyword highlighting.&lt;/li&gt; 
 &lt;li&gt;AI Canvas, which can help to craft impactful, metric-driven resume content.&lt;/li&gt; 
 &lt;li&gt;Multi-job description optimization.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/how_to_install_resumematcher.png" alt="Installation" /&gt;&lt;/p&gt; 
&lt;p&gt;Follow the instructions in the &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/SETUP.md"&gt;SETUP.md&lt;/a&gt; file to set up the project locally. The setup script will install all the necessary dependencies and configure your environment.&lt;/p&gt; 
&lt;p&gt;The project is built using:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;FastAPI for the backend.&lt;/li&gt; 
 &lt;li&gt;Next.js for the frontend.&lt;/li&gt; 
 &lt;li&gt;Ollama for local AI model serving.&lt;/li&gt; 
 &lt;li&gt;Tailwind CSS for styling.&lt;/li&gt; 
 &lt;li&gt;SQLite for the database.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Technology&lt;/th&gt; 
   &lt;th&gt;Info/Version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;3.12+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Next.js&lt;/td&gt; 
   &lt;td&gt;15+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;0.6.7&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Join Us and Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/how_to_contribute.png" alt="how to contribute" /&gt;&lt;/p&gt; 
&lt;p&gt;We welcome contributions from everyone! Whether you're a developer, designer, or just someone who wants to help out. All the contributors are listed in the &lt;a href="https://resumematcher.fyi/about"&gt;about page&lt;/a&gt; on our website and on the GitHub Readme here.&lt;/p&gt; 
&lt;p&gt;Check out the roadmap if you would like to work on the features that are planned for the future. If you have any suggestions or feature requests, please feel free to open an issue on GitHub and discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/contributors.png" alt="Contributors" /&gt;&lt;/p&gt; 
&lt;a href="https://github.com/srbhr/Resume-Matcher/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=srbhr/Resume-Matcher" /&gt; &lt;/a&gt; 
&lt;h2&gt;Support the Development by Donating&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/supporting_resume_matcher.png" alt="donate" /&gt;&lt;/p&gt; 
&lt;p&gt;If you would like to support the development of Resume Matcher, you can do so by donating. Your contributions will help us keep the project alive and continue adding new features.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GitHub&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/sponsors/srbhr"&gt;&lt;img src="https://img.shields.io/github/sponsors/srbhr?style=for-the-badge&amp;amp;color=c20a71&amp;amp;labelColor=black&amp;amp;logo=github" alt="GitHub Sponsors" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Buy Me a Coffee&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.buymeacoffee.com/srbhr"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;color=c20a72&amp;amp;logoColor=white" alt="BuyMeACoffee" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;amp;theme=dark&amp;amp;type=Date" /&gt; 
  &lt;img width="100%" src="https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;amp;theme=dark&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; 
&lt;/details&gt; 
&lt;h2&gt;Resume Matcher is a part of &lt;a href="https://vercel.com/oss"&gt;Vercel Open Source Program&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://vercel.com/oss/program-badge.svg?sanitize=true" alt="Vercel OSS Program" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TEN-framework/ten-framework</title>
      <link>https://github.com/TEN-framework/ten-framework</link>
      <description>&lt;p&gt;Open-source framework for conversational voice AI agents&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="readme-top"&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/799584b2-61ff-4255-bdd1-2548d0fdba52" alt="Image" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/ten-framework/ten-framework?color=369eff&amp;amp;labelColor=gray&amp;amp;logo=github&amp;amp;style=flat-square" alt="TEN Releases" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/TEN-framework/ten-framework?branch=main"&gt;&lt;img src="https://coveralls.io/repos/github/TEN-framework/ten-framework/badge.svg?branch=main" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/ten-framework/ten-framework?labelColor=gray&amp;amp;style=flat-square" alt="Release Date" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/commit-activity"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/TEN-framework/ten-framework?labelColor=gray&amp;amp;color=pink" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/issues"&gt;&lt;img src="https://img.shields.io/github/issues-search?query=repo%3ATEN-framework%2Ften-framework%20is%3Aclosed&amp;amp;label=issues%20closed&amp;amp;labelColor=gray&amp;amp;color=green" alt="Issues closed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/ten-framework/ten-framework?color=c4f042&amp;amp;labelColor=gray&amp;amp;style=flat-square" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0_with_certain_conditions-blue.svg?labelColor=%20%23155EEF&amp;amp;color=%20%23528bff" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/English-lightgrey" alt="README in English" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-CN.md"&gt;&lt;img src="https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-lightgrey" alt="ÁÆÄ‰Ωì‰∏≠ÊñáÊìç‰ΩúÊåáÂçó" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-JP.md"&gt;&lt;img src="https://img.shields.io/badge/%E6%97%A5%E6%9C%AC%E8%AA%9E-lightgrey" alt="Êó•Êú¨Ë™û„ÅÆREADME" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-KR.md"&gt;&lt;img src="https://img.shields.io/badge/%ED%95%9C%EA%B5%AD%EC%96%B4-lightgrey" alt="README in ÌïúÍµ≠Ïñ¥" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-ES.md"&gt;&lt;img src="https://img.shields.io/badge/Espa%C3%B1ol-lightgrey" alt="README en Espa√±ol" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-FR.md"&gt;&lt;img src="https://img.shields.io/badge/Fran%C3%A7ais-lightgrey" alt="README en Fran√ßais" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-IT.md"&gt;&lt;img src="https://img.shields.io/badge/Italiano-lightgrey" alt="README in Italiano" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11978"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11978" alt="TEN-framework%2Ften_framework | Trendshift" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://theten.ai"&gt;Official Site&lt;/a&gt; ‚Ä¢ &lt;a href="https://theten.ai/docs"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://theten.ai/blog"&gt;Blog&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;kbd&gt;Table of Contents&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#welcome-to-ten"&gt;Welcome to TEN&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#agent-examples"&gt;Agent Examples&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#quick-start-with-agent-examples"&gt;Quick Start with Agent Examples&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#localhost"&gt;Localhost&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#codespaces"&gt;Codespaces&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#agent-examples-self-hosting"&gt;Agent Examples Self-Hosting&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#deploying-with-docker"&gt;Deploying with Docker&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#deploying-with-other-cloud-services"&gt;Deploying with other cloud services&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#stay-tuned"&gt;Stay Tuned&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#ten-ecosystem"&gt;TEN Ecosystem&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#questions"&gt;Questions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#contributing"&gt;Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#code-contributors"&gt;Code Contributors&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#contribution-guidelines"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;br /&gt; 
&lt;/details&gt; 
&lt;h2&gt;Welcome to TEN&lt;/h2&gt; 
&lt;p&gt;TEN is an open-source framework for real-time multimodal conversational AI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#ten-ecosystem"&gt;TEN Ecosystem&lt;/a&gt; includes &lt;a href="https://github.com/ten-framework/ten-framework"&gt;TEN Framework&lt;/a&gt;, &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/agents/examples"&gt;Agent Examples&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-vad"&gt;VAD&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;Turn Detection&lt;/a&gt; and &lt;a href="https://github.com/ten-framework/portal"&gt;Portal&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Community Channel&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/intent/follow?screen_name=TenFramework"&gt;&lt;img src="https://img.shields.io/twitter/follow/TenFramework?logo=X&amp;amp;color=%20%23f5f5f5" alt="Follow on X" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on X for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/VnPftUzAMJ"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20TEN%20Community-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord TEN Community" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Discord community to connect with developers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/company/ten-framework"&gt;&lt;img src="https://custom-icon-badges.demolab.com/badge/LinkedIn-TEN_Framework-0A66C2?logo=linkedin-white&amp;amp;logoColor=fff" alt="Follow on LinkedIn" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on LinkedIn for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/TEN-framework"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-TEN%20Framework-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face Space" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Hugging Face community to explore our spaces and models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-agent/discussions/170"&gt;&lt;img src="https://img.shields.io/badge/TEN_Framework-WeChat_Group-%2307C160?logo=wechat&amp;amp;labelColor=darkgreen&amp;amp;color=gray" alt="WeChat" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our WeChat group for Chinese community discussions&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h2&gt;Agent Examples&lt;/h2&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/dce3db80-fb48-4e2a-8ac7-33f50bcffa32" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Multi-Purpose Voice Assistant&lt;/strong&gt; ‚Äî This low-latency, high-quality real-time assistant supports both RTC and &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/websocket-example"&gt;WebSocket&lt;/a&gt; connections, and you can extend it with &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-with-memU"&gt;Memory&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-with-ten-vad"&gt;VAD&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-with-turn-detection"&gt;Turn Detection&lt;/a&gt;, and other extensions.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant"&gt;Example code&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/51ab1504-b67c-49d4-8a7a-5582d9b254da" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Lip Sync Avatars&lt;/strong&gt; ‚Äî Works with multiple avatar vendors, the main character features Kei, an anime character with MotionSync-powered lip sync, and also supports realistic avatars from Trulience, HeyGen, and Tavus.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-live2d"&gt;Example code&lt;/a&gt; for different Live2D characters.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/f94b21b8-9dda-4efc-9274-b028cc01296a" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Speech Diarization&lt;/strong&gt; ‚Äî Real-time diarization that detects and labels speakers, the Who Likes What game shows an interactive use case.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/speechmatics-diarization"&gt;Example code&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/6ed5b04d-945a-4a30-a1cc-f8014b602b38" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SIP Call&lt;/strong&gt; ‚Äî SIP extension that enables phone calls powered by TEN.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-sip-twilio"&gt;Example code&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/d793bc6c-c8de-4996-bd85-9ce88c69dd8d" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Transcription&lt;/strong&gt; ‚Äî A transcription tool that transcribes audio to text.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/transcription"&gt;Example code&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3d60f1ff-0f82-4fe7-b5c2-ac03d284f60c" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ESP32-S3 Korvo V3&lt;/strong&gt; ‚Äî Runs TEN agent example on the Espressif ESP32-S3 Korvo V3 development board to integrate LLM-powered communication with hardware.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/esp32-client"&gt;integration guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Quick Start with Agent Examples&lt;/h2&gt; 
&lt;h3&gt;Localhost&lt;/h3&gt; 
&lt;h4&gt;Step ‚ìµ - Prerequisites&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Requirements&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Keys&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚Ä¢ Agora &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App ID&lt;/a&gt; and &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App Certificate&lt;/a&gt;&lt;br /&gt;‚Ä¢ &lt;a href="https://openai.com/index/openai-api/"&gt;OpenAI&lt;/a&gt; API key&lt;br /&gt;‚Ä¢ &lt;a href="https://deepgram.com/"&gt;Deepgram&lt;/a&gt; ASR &lt;br /&gt;‚Ä¢ &lt;a href="https://elevenlabs.io/"&gt;ElevenLabs&lt;/a&gt; TTS&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚Ä¢ &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; / &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;br /&gt;‚Ä¢ &lt;a href="https://nodejs.org/en"&gt;Node.js (LTS) v18&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Minimum System Requirements&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚Ä¢ CPU &amp;gt;= 2 cores&lt;br /&gt;‚Ä¢ RAM &amp;gt;= 4 GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;!-- &gt; [!NOTE]
&gt; **macOS: Docker setting on Apple Silicon**
&gt;
&gt; Uncheck "Use Rosetta for x86/amd64 emulation" in Docker settings, it may result in slower build times on ARM, but performance will be normal when deployed to x64 servers. --&gt; 
&lt;h4&gt;Step ‚ì∂ - Build agent examples in VM&lt;/h4&gt; 
&lt;h5&gt;1. Clone the repo, &lt;code&gt;cd&lt;/code&gt; into &lt;code&gt;ai_agents&lt;/code&gt;, and create a &lt;code&gt;.env&lt;/code&gt; file from &lt;code&gt;.env.example&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai_agents
cp ./.env.example ./.env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;2. Set up the Agora App ID and App Certificate in &lt;code&gt;.env&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;AGORA_APP_ID=
AGORA_APP_CERTIFICATE=

# Deepgram (required for speech-to-text)
DEEPGRAM_API_KEY=

# OpenAI (required for language model)
OPENAI_API_KEY=

# ElevenLabs (required for text-to-speech)
ELEVENLABS_TTS_KEY=
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;3. Start agent development containers&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;4. Enter the container&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it ten_agent_dev bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;5. Build the agent with the default example (~5-8 min)&lt;/h5&gt; 
&lt;p&gt;Check the &lt;code&gt;agents/examples&lt;/code&gt; folder for additional samples. Start with one of these defaults:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# use the chained voice assistant
cd agents/examples/voice-assistant

# or use the speech-to-speech voice assistant in real time
cd agents/examples/voice-assistant-realtime
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;6. Start the web server&lt;/h5&gt; 
&lt;p&gt;Run &lt;code&gt;task build&lt;/code&gt; if you changed any local source code. This step is required for compiled languages (for example, TypeScript or Go) and not needed for Python.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;task install
task run
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;7. Access the agent&lt;/h5&gt; 
&lt;p&gt;Once the agent example is running, you can access the following interfaces:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;localhost:49483&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;localhost:3000&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://github.com/user-attachments/assets/191a7c0a-d8e6-48f9-866f-6a70c58f0118" alt="Screenshot 1" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://github.com/user-attachments/assets/13e482b6-d907-4449-a779-9454bb24c0b1" alt="Screenshot 2" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;TMAN Designer: &lt;a href="http://localhost:49483"&gt;localhost:49483&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Agent Examples UI: &lt;a href="http://localhost:3000"&gt;localhost:3000&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;h4&gt;Step ‚ì∑ - Customize your agent example&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:49483"&gt;localhost:49483&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Right-click the STT, LLM, and TTS extensions.&lt;/li&gt; 
 &lt;li&gt;Open their properties and enter the corresponding API keys.&lt;/li&gt; 
 &lt;li&gt;Submit your changes, now you can see the updated Agent Example in &lt;a href="http://localhost:3000"&gt;localhost:3000&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h4&gt;Run a transcriber app from TEN Manager without Docker (Beta)&lt;/h4&gt; 
&lt;p&gt;TEN also provides a transcriber app that you can run from TEN Manager without using Docker.&lt;/p&gt; 
&lt;p&gt;Check the &lt;a href="https://theten.ai/docs/ten_framework/getting-started/quick-start"&gt;quick start guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;Codespaces&lt;/h3&gt; 
&lt;p&gt;GitHub offers free Codespaces for each repository. You can run Agent Examples in Codespaces without using Docker. Codespaces typically start faster than local Docker environments.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/ten-framework/ten-agent"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://theten.ai/docs/ten_agent_examples/setup_development_env/setting_up_development_inside_codespace"&gt;this guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Agent Examples Self-Hosting&lt;/h2&gt; 
&lt;h3&gt;Deploying with Docker&lt;/h3&gt; 
&lt;p&gt;Once you have customized your agent (either by using the TMAN Designer or editing &lt;code&gt;property.json&lt;/code&gt; directly), you can deploy it by creating a release Docker image for your service.&lt;/p&gt; 
&lt;h5&gt;Release as Docker image&lt;/h5&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The following commands need to be executed outside of any Docker container.&lt;/p&gt; 
&lt;h6&gt;Build image&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai_agents
docker build -f agents/examples/&amp;lt;example-name&amp;gt;/Dockerfile -t example-app .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;Run&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it --env-file .env -p 3000:3000 example-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;h3&gt;Deploying with other cloud services&lt;/h3&gt; 
&lt;p&gt;You can split the deployment into two pieces when you want to host TEN on providers such as &lt;a href="https://vercel.com"&gt;Vercel&lt;/a&gt; or &lt;a href="https://www.netlify.com"&gt;Netlify&lt;/a&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run the TEN backend on any container-friendly platform (a VM with Docker, Fly.io, Render, ECS, Cloud Run, or similar). Use the example Docker image without modifying it and expose port &lt;code&gt;8080&lt;/code&gt; from that service.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Deploy only the frontend to Vercel or Netlify. Point the project root to &lt;code&gt;ai_agents/agents/examples/&amp;lt;example&amp;gt;/frontend&lt;/code&gt;, run &lt;code&gt;pnpm install&lt;/code&gt; (or &lt;code&gt;bun install&lt;/code&gt;) followed by &lt;code&gt;pnpm build&lt;/code&gt; (or &lt;code&gt;bun run build&lt;/code&gt;), and keep the default &lt;code&gt;.next&lt;/code&gt; output directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Configure environment variables in your hosting dashboard so that &lt;code&gt;AGENT_SERVER_URL&lt;/code&gt; points to the backend URL, and add any &lt;code&gt;NEXT_PUBLIC_*&lt;/code&gt; keys the UI needs (for example, Agora credentials you surface to the browser).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ensure your backend accepts requests from the frontend origin ‚Äî via open CORS or by using the built-in proxy middleware.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;With this setup, the backend handles long-running worker processes, while the hosted frontend simply forwards API traffic to it.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Stay Tuned&lt;/h2&gt; 
&lt;p&gt;Get instant notifications for new releases and updates. Your support helps us grow and improve TEN!&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/72c6cc46-a2a2-484d-82a9-f3079269c815" alt="Image" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;TEN Ecosystem&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project&lt;/th&gt; 
   &lt;th&gt;Preview&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-framework"&gt;&lt;strong&gt;Ô∏èTEN Framework&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;Open-source framework for conversational AI Agents.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-framework?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/799584b2-61ff-4255-bdd1-2548d0fdba52" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-vad"&gt;&lt;strong&gt;TEN VAD&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;Low-latency, lightweight and high-performance streaming voice activity detector (VAD).&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-vad?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/e504135e-67fd-4fa1-b0e4-d495358d8aa5" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;&lt;strong&gt;Ô∏è TEN Turn Detection&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN Turn Detection enables full-duplex dialogue communication.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-turn-detection?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/c72d82cc-3667-496c-8bd6-3d194a91c452" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/agents/examples"&gt;&lt;strong&gt;TEN Agent Examples&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;Usecases powered by TEN.&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/7f735633-c7f6-4432-b6b4-d2a2977ca588" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/portal"&gt;&lt;strong&gt;TEN Portal&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;The official site of the TEN Framework with documentation and a blog.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/portal?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/f56c75b9-722c-4156-902d-ae98ce2b3b5e" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Questions&lt;/h2&gt; 
&lt;p&gt;TEN Framework is available on these AI-powered Q&amp;amp;A platforms. They can help you find answers quickly and accurately in multiple languages, covering everything from basic setup to advanced implementation details.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepWiki&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ReadmeX&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome all forms of open-source collaboration! Whether you're fixing bugs, adding features, improving documentation, or sharing ideas, your contributions help advance personalized AI tools. Check out our GitHub Issues and Projects to find ways to contribute and show your skills. Together, we can build something amazing!&lt;/p&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Welcome all kinds of contributions&lt;/strong&gt; üôè&lt;/p&gt; 
 &lt;p&gt;Join us in building TEN better! Every contribution makes a difference, from code to documentation. Share your TEN Agent projects on social media to inspire others!&lt;/p&gt; 
 &lt;p&gt;Connect with one of the TEN maintainers &lt;a href="https://x.com/elliotchen200"&gt;@elliotchen200&lt;/a&gt; on ùïè or &lt;a href="https://github.com/cyfyifanchen"&gt;@cyfyifanchen&lt;/a&gt; on GitHub for project updates, discussions, and collaboration opportunities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;h3&gt;Code Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=TEN-framework/ten-framework" alt="TEN" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contribution Guidelines&lt;/h3&gt; 
&lt;p&gt;Contributions are welcome! Please read the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/docs/code-of-conduct/contributing.md"&gt;contribution guidelines&lt;/a&gt; first.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;The entire TEN framework (except for the folders explicitly listed below) is released under the Apache License, Version 2.0, with additional restrictions. For details, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/LICENSE"&gt;LICENSE&lt;/a&gt; file located in the root directory of the TEN framework.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The components within the &lt;code&gt;packages&lt;/code&gt; directory are released under the Apache License, Version 2.0. For details, please refer to the &lt;code&gt;LICENSE&lt;/code&gt; file located in each package's root directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The third-party libraries used by the TEN framework are listed and described in detail. For more information, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/third_party/"&gt;third_party&lt;/a&gt; folder.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- Navigation --&gt; 
&lt;!-- Header badges --&gt; 
&lt;!-- Localized READMEs --&gt; 
&lt;!-- Primary sites --&gt; 
&lt;!-- Welcome --&gt; 
&lt;!-- Community --&gt; 
&lt;!-- Agent examples --&gt; 
&lt;!-- Quick start --&gt; 
&lt;!-- Codespaces --&gt; 
&lt;!-- Deployment --&gt; 
&lt;!-- Stay tuned --&gt; 
&lt;!-- TEN ecosystem --&gt; 
&lt;!-- Contributing --&gt;</description>
    </item>
    
    <item>
      <title>odoo/odoo</title>
      <link>https://github.com/odoo/odoo</link>
      <description>&lt;p&gt;Odoo. Open Source Apps To Grow Your Business.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Odoo&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://runbot.odoo.com/runbot"&gt;&lt;img src="https://runbot.odoo.com/runbot/badge/flat/1/master.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://www.odoo.com/documentation/master"&gt;&lt;img src="https://img.shields.io/badge/master-docs-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F" alt="Tech Doc" /&gt;&lt;/a&gt; &lt;a href="https://www.odoo.com/forum/help-1"&gt;&lt;img src="https://img.shields.io/badge/master-help-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F" alt="Help" /&gt;&lt;/a&gt; &lt;a href="https://nightly.odoo.com/"&gt;&lt;img src="https://img.shields.io/badge/master-nightly-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F" alt="Nightly Builds" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Odoo is a suite of web based open source business apps.&lt;/p&gt; 
&lt;p&gt;The main Odoo Apps include an &lt;a href="https://www.odoo.com/page/crm"&gt;Open Source CRM&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/website"&gt;Website Builder&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/ecommerce"&gt;eCommerce&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/inventory"&gt;Warehouse Management&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/project"&gt;Project Management&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/accounting"&gt;Billing &amp;amp; Accounting&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/point-of-sale-shop"&gt;Point of Sale&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/employees"&gt;Human Resources&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/social-marketing"&gt;Marketing&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/manufacturing"&gt;Manufacturing&lt;/a&gt;, &lt;a href="https://www.odoo.com/"&gt;...&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Odoo Apps can be used as stand-alone applications, but they also integrate seamlessly so you get a full-featured &lt;a href="https://www.odoo.com"&gt;Open Source ERP&lt;/a&gt; when you install several Apps.&lt;/p&gt; 
&lt;h2&gt;Getting started with Odoo&lt;/h2&gt; 
&lt;p&gt;For a standard installation please follow the &lt;a href="https://www.odoo.com/documentation/master/administration/install/install.html"&gt;Setup instructions&lt;/a&gt; from the documentation.&lt;/p&gt; 
&lt;p&gt;To learn the software, we recommend the &lt;a href="https://www.odoo.com/slides"&gt;Odoo eLearning&lt;/a&gt;, or &lt;a href="https://www.odoo.com/page/scale-up-business-game"&gt;Scale-up, the business game&lt;/a&gt;. Developers can start with &lt;a href="https://www.odoo.com/documentation/master/developer/howtos.html"&gt;the developer tutorials&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you believe you have found a security issue, check our &lt;a href="https://www.odoo.com/security-report"&gt;Responsible Disclosure page&lt;/a&gt; for details and get in touch with us via email.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jamwithai/arxiv-paper-curator</title>
      <link>https://github.com/jamwithai/arxiv-paper-curator</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Mother of AI Project&lt;/h1&gt; 
&lt;h2&gt;Phase 1 RAG Systems: arXiv Paper Curator&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;A Learner-Focused Journey into Production RAG Systems&lt;/h3&gt; 
 &lt;p&gt;Learn to build modern AI systems from the ground up through hands-on implementation&lt;/p&gt; 
 &lt;p&gt;Master the most in-demand AI engineering skills: &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;img src="https://img.shields.io/badge/Python-3.12+-blue.svg?sanitize=true" alt="Python Version" /&gt; &lt;img src="https://img.shields.io/badge/FastAPI-0.115+-green.svg?sanitize=true" alt="FastAPI" /&gt; &lt;img src="https://img.shields.io/badge/OpenSearch-2.19-orange.svg?sanitize=true" alt="OpenSearch" /&gt; &lt;img src="https://img.shields.io/badge/Docker-Compose-blue.svg?sanitize=true" alt="Docker" /&gt; &lt;img src="https://img.shields.io/badge/Status-Week%207%20Advanced%20Features-brightgreen.svg?sanitize=true" alt="Status" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/#-about-this-course"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/mother_of_ai_project_rag_architecture.gif" alt="RAG Architecture" width="700" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üìñ About This Course&lt;/h2&gt; 
&lt;p&gt;This is a &lt;strong&gt;learner-focused project&lt;/strong&gt; where you'll build a complete research assistant system that automatically fetches academic papers, understands their content, and answers your research questions using advanced RAG techniques.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The arXiv Paper Curator&lt;/strong&gt; will teach you to build a &lt;strong&gt;production-grade RAG system using industry best practices&lt;/strong&gt;. Unlike tutorials that jump straight to vector search, we follow the &lt;strong&gt;professional path&lt;/strong&gt;: master keyword search foundations first, then enhance with vectors for hybrid retrieval.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üéØ The Professional Difference:&lt;/strong&gt; We build RAG systems the way successful companies do - solid search foundations enhanced with AI, not AI-first approaches that ignore search fundamentals.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;By the end of this course, you'll have your own AI research assistant and the deep technical skills to build production RAG systems for any domain.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéì What You'll Build&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Week 1:&lt;/strong&gt; Complete infrastructure with Docker, FastAPI, PostgreSQL, OpenSearch, and Airflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 2:&lt;/strong&gt; Automated data pipeline fetching and parsing academic papers from arXiv&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 3:&lt;/strong&gt; Production BM25 keyword search with filtering and relevance scoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 4:&lt;/strong&gt; Intelligent chunking + hybrid search combining keywords with semantic understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 5:&lt;/strong&gt; Complete RAG pipeline with local LLM, streaming responses, and Gradio interface&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 6:&lt;/strong&gt; Production monitoring with Langfuse tracing and Redis caching for optimized performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 7:&lt;/strong&gt; &lt;strong&gt;Agentic RAG with LangGraph and Telegram Bot for mobile access&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è System Architecture Evolution&lt;/h2&gt; 
&lt;h3&gt;Week 7: Agentic RAG &amp;amp; Telegram Bot Integration&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week7_telegram_and_agentic_ai.png" alt="Week 7 Telegram and Agentic AI Architecture" width="800" /&gt; 
 &lt;p&gt;&lt;em&gt;Complete Week 7 architecture showing Telegram bot integration with the agentic RAG system&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;LangGraph Agentic RAG Workflow&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/langgraph-mermaid.png" alt="LangGraph Agentic RAG Flow" width="800" /&gt; 
 &lt;p&gt;&lt;em&gt;Detailed LangGraph workflow showing decision nodes, document grading, and adaptive retrieval&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Week 7 Code walkthrough + blog:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/agentic-rag-with-langgraph-and-telegram"&gt;Agentic RAG with LangGraph and Telegram&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Innovations in Week 7:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Decision-Making&lt;/strong&gt;: Agents evaluate and adapt retrieval strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Grading&lt;/strong&gt;: Automatic relevance assessment with semantic evaluation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query Rewriting&lt;/strong&gt;: Adaptive query refinement when results are insufficient&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Guardrails&lt;/strong&gt;: Out-of-domain detection prevents hallucination&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile Access&lt;/strong&gt;: Telegram bot for conversational AI on any device&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transparency&lt;/strong&gt;: Full reasoning step tracking for debugging and trust&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;üìã Prerequisites&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Desktop&lt;/strong&gt; (with Docker Compose)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.12+&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UV Package Manager&lt;/strong&gt; (&lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;Install Guide&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;8GB+ RAM&lt;/strong&gt; and &lt;strong&gt;20GB+ free disk space&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;‚ö° Get Started&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Clone and setup
git clone &amp;lt;repository-url&amp;gt;
cd arxiv-paper-curator

# 2. Configure environment (IMPORTANT!)
cp .env.example .env
# The .env file contains all necessary configuration for OpenSearch, 
# arXiv API, and service connections. Defaults work out of the box.
# You need to add Jina embeddings free api key and langfuse keys (check the blogs)

# 3. Install dependencies
uv sync

# 4. Start all services
docker compose up --build -d

# 5. Verify everything works
curl http://localhost:8000/health
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üìö Weekly Learning Path&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Week&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Blog Post&lt;/th&gt; 
   &lt;th&gt;Code Release&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;The Mother of AI project - 6 phases&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-mother-of-ai-project"&gt;The Mother of AI project&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 1&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Infrastructure Foundation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-infrastructure-that-powers-rag"&gt;The Infrastructure That Powers RAG Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week1.0"&gt;week1.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Data Ingestion Pipeline&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/bringing-your-rag-system-to-life"&gt;Building Data Ingestion Pipelines for RAG&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week2.0"&gt;week2.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 3&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenSearch ingestion &amp;amp; BM25 retrieval&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-search-foundation-every-rag-system"&gt;The Search Foundation Every RAG System Needs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week3.0"&gt;week3.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 4&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Chunking &amp;amp; Hybrid Search&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/chunking-strategies-and-hybrid-rag"&gt;The Chunking Strategy That Makes Hybrid Search Work&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week4.0"&gt;week4.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 5&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Complete RAG system&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-complete-rag-system"&gt;The Complete RAG System&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week5.0"&gt;week5.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 6&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Production monitoring &amp;amp; caching&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/production-ready-rag-monitoring-and"&gt;Production-ready RAG: Monitoring &amp;amp; Caching&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week6.0"&gt;week6.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 7&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Agentic RAG &amp;amp; Telegram Bot&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/agentic-rag-with-langgraph-and-telegram"&gt;Agentic RAG with LangGraph and Telegram&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week7.0"&gt;week7.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;üì• Clone a specific week's release:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone a specific week's code
git clone --branch &amp;lt;WEEK_TAG&amp;gt; https://github.com/jamwithai/arxiv-paper-curator
cd arxiv-paper-curator
uv sync
docker compose down -v
docker compose up --build -d

# Replace &amp;lt;WEEK_TAG&amp;gt; with: week1.0, week2.0, etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üìä Access Your Services&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;URL&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Documentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Interactive API testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gradio RAG Interface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:7861"&gt;http://localhost:7861&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;User-friendly chat interface&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Langfuse Dashboard&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;RAG pipeline monitoring &amp;amp; tracing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Airflow Dashboard&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Workflow management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenSearch Dashboards&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:5601"&gt;http://localhost:5601&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid search engine UI&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Check airflow/simple_auth_manager_passwords.json.generated for Airflow username and password&lt;/h4&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 1: Infrastructure Foundation ‚úÖ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Start here!&lt;/strong&gt; Master the infrastructure that powers modern RAG systems.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Complete infrastructure setup with Docker Compose&lt;/li&gt; 
 &lt;li&gt;FastAPI development with automatic documentation and health checks&lt;/li&gt; 
 &lt;li&gt;PostgreSQL database configuration and management&lt;/li&gt; 
 &lt;li&gt;OpenSearch hybrid search engine setup&lt;/li&gt; 
 &lt;li&gt;Ollama local LLM service configuration&lt;/li&gt; 
 &lt;li&gt;Service orchestration and health monitoring&lt;/li&gt; 
 &lt;li&gt;Professional development environment with code quality tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week1_infra_setup.png" alt="Week 1 Infrastructure Setup" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;: REST endpoints with async support (Port 8000)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL 16&lt;/strong&gt;: Paper metadata storage (Port 5432)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenSearch 2.19&lt;/strong&gt;: Search engine with dashboards (Ports 9200, 5601)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apache Airflow 3.0&lt;/strong&gt;: Workflow orchestration (Port 8080)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: Local LLM server (Port 11434)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 1 notebook
uv run jupyter notebook notebooks/week1/week1_setup.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week1/week1_setup.ipynb"&gt;Week 1 notebook&lt;/a&gt; for hands-on setup and verification steps.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/the-infrastructure-that-powers-rag"&gt;The Infrastructure That Powers RAG Systems&lt;/a&gt; - Detailed walkthrough and production insights&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 2: Data Ingestion Pipeline ‚úÖ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 1 infrastructure:&lt;/strong&gt; Learn to fetch, process, and store academic papers automatically.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;arXiv API integration with rate limiting and retry logic&lt;/li&gt; 
 &lt;li&gt;Scientific PDF parsing using Docling&lt;/li&gt; 
 &lt;li&gt;Automated data ingestion pipelines with Apache Airflow&lt;/li&gt; 
 &lt;li&gt;Metadata extraction and storage workflows&lt;/li&gt; 
 &lt;li&gt;Complete paper processing from API to database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week2_data_ingestion_flow.png" alt="Week 2 Data Ingestion Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Data Pipeline Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MetadataFetcher&lt;/strong&gt;: üéØ Main orchestrator coordinating the entire pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ArxivClient&lt;/strong&gt;: Rate-limited paper fetching with retry logic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PDFParserService&lt;/strong&gt;: Docling-powered scientific document processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Airflow DAGs&lt;/strong&gt;: Automated daily paper ingestion workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL Storage&lt;/strong&gt;: Structured paper metadata and content&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Implementation Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 2 notebook  
uv run jupyter notebook notebooks/week2/week2_arxiv_integration.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week2/week2_arxiv_integration.ipynb"&gt;Week 2 notebook&lt;/a&gt; for hands-on implementation and verification steps.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/bringing-your-rag-system-to-life"&gt;Building Data Ingestion Pipelines for RAG&lt;/a&gt; - arXiv API integration and PDF processing&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 3: Keyword Search First - The Critical Foundation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Weeks 1-2 foundation:&lt;/strong&gt; Implement the keyword search foundation that professional RAG systems rely on.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Why keyword search is essential for RAG systems (foundation first approach)&lt;/li&gt; 
 &lt;li&gt;OpenSearch index management, mappings, and search optimization&lt;/li&gt; 
 &lt;li&gt;BM25 algorithm and the math behind effective keyword search&lt;/li&gt; 
 &lt;li&gt;Query DSL for building complex search queries with filters and boosting&lt;/li&gt; 
 &lt;li&gt;Search analytics for measuring relevance and performance&lt;/li&gt; 
 &lt;li&gt;Production patterns used by real companies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week3_opensearch_flow.png" alt="Week 3 OpenSearch Flow Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Search Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenSearch Service&lt;/strong&gt;: &lt;code&gt;src/services/opensearch/&lt;/code&gt; - Professional search service implementation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search API&lt;/strong&gt;: &lt;code&gt;src/routers/search.py&lt;/code&gt; - Search API endpoints with BM25 scoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Materials&lt;/strong&gt;: &lt;code&gt;notebooks/week3/&lt;/code&gt; - Complete OpenSearch integration guide&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality Metrics&lt;/strong&gt;: Precision, recall, and relevance scoring&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 3 notebook
uv run jupyter notebook notebooks/week3/week3_opensearch.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week3/week3_opensearch.ipynb"&gt;Week 3 notebook&lt;/a&gt; for hands-on OpenSearch setup and BM25 search implementation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/the-search-foundation-every-rag-system"&gt;The Search Foundation Every RAG System Needs&lt;/a&gt; - Complete BM25 implementation with OpenSearch&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 4: Chunking &amp;amp; Hybrid Search - The Semantic Layer&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 3 foundation:&lt;/strong&gt; Add the semantic layer that makes search truly intelligent.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Section-based chunking with intelligent document segmentation&lt;/li&gt; 
 &lt;li&gt;Production embeddings with Jina AI integration and fallback strategies&lt;/li&gt; 
 &lt;li&gt;Hybrid search mastery using RRF fusion for keyword + semantic retrieval&lt;/li&gt; 
 &lt;li&gt;Unified API design with single endpoint supporting multiple search modes&lt;/li&gt; 
 &lt;li&gt;Performance analysis and trade-offs between search approaches&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week4_hybrid_opensearch.png" alt="Week 4 Hybrid Search Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hybrid Search Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text Chunker&lt;/strong&gt;: &lt;code&gt;src/services/indexing/text_chunker.py&lt;/code&gt; - Section-aware chunking with overlap strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embeddings Service&lt;/strong&gt;: &lt;code&gt;src/services/embeddings/&lt;/code&gt; - Production embedding pipeline with Jina AI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid Search API&lt;/strong&gt;: &lt;code&gt;src/routers/hybrid_search.py&lt;/code&gt; - Unified search API supporting all modes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Materials&lt;/strong&gt;: &lt;code&gt;notebooks/week4/&lt;/code&gt; - Complete hybrid search implementation guide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 4 notebook
uv run jupyter notebook notebooks/week4/week4_hybrid_search.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week4/week4_hybrid_search.ipynb"&gt;Week 4 notebook&lt;/a&gt; for hands-on implementation and verification steps.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/chunking-strategies-and-hybrid-rag"&gt;The Chunking Strategy That Makes Hybrid Search Work&lt;/a&gt; - Production chunking and RRF fusion implementation&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 5: Complete RAG Pipeline with LLM Integration&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 4 hybrid search:&lt;/strong&gt; Add the LLM layer that turns search into intelligent conversation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Local LLM integration with Ollama for complete data privacy&lt;/li&gt; 
 &lt;li&gt;Performance optimization with 80% prompt reduction (6x speed improvement)&lt;/li&gt; 
 &lt;li&gt;Streaming implementation using Server-Sent Events for real-time responses&lt;/li&gt; 
 &lt;li&gt;Dual API design with standard and streaming endpoints&lt;/li&gt; 
 &lt;li&gt;Interactive Gradio interface with advanced parameter controls&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week5_complete_rag.png" alt="Week 5 Complete RAG System Architecture" width="900" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Complete RAG Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RAG Endpoints&lt;/strong&gt;: &lt;code&gt;src/routers/ask.py&lt;/code&gt; - Dual endpoints (&lt;code&gt;/api/v1/ask&lt;/code&gt; + &lt;code&gt;/api/v1/stream&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ollama Service&lt;/strong&gt;: &lt;code&gt;src/services/ollama/&lt;/code&gt; - LLM client with optimized prompts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System Prompt&lt;/strong&gt;: &lt;code&gt;src/services/ollama/prompts/rag_system.txt&lt;/code&gt; - Optimized for academic papers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gradio Interface&lt;/strong&gt;: &lt;code&gt;src/gradio_app.py&lt;/code&gt; - Interactive web UI with streaming support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Launcher Script&lt;/strong&gt;: &lt;code&gt;gradio_launcher.py&lt;/code&gt; - Easy-launch script (runs on port 7861)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 5 notebook
uv run jupyter notebook notebooks/week5/week5_complete_rag_system.ipynb

# Launch Gradio interface
uv run python gradio_launcher.py
# Open http://localhost:7861
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week5/week5_complete_rag_system.ipynb"&gt;Week 5 notebook&lt;/a&gt; for hands-on LLM integration and RAG pipeline implementation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/the-complete-rag-system"&gt;The Complete RAG System&lt;/a&gt; - Complete RAG system with local LLM integration and optimization techniques&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 6: Production Monitoring and Caching&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 5 complete RAG system:&lt;/strong&gt; Add observability, performance optimization, and production-grade monitoring.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Langfuse integration for end-to-end RAG pipeline tracing&lt;/li&gt; 
 &lt;li&gt;Redis caching strategy with intelligent cache keys and TTL management&lt;/li&gt; 
 &lt;li&gt;Performance monitoring with real-time dashboards for latency and costs&lt;/li&gt; 
 &lt;li&gt;Production patterns for observability and optimization&lt;/li&gt; 
 &lt;li&gt;Cost analysis and LLM usage optimization (150-400x speedup with caching)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week6_monitoring_and_caching.png" alt="Week 6 Monitoring &amp;amp; Caching Architecture" width="900" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Production Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Langfuse Service&lt;/strong&gt;: &lt;code&gt;src/services/langfuse/&lt;/code&gt; - Complete tracing integration with RAG-specific metrics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cache Service&lt;/strong&gt;: &lt;code&gt;src/services/cache/&lt;/code&gt; - Redis client with exact-match caching and graceful fallback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Updated Endpoints&lt;/strong&gt;: &lt;code&gt;src/routers/ask.py&lt;/code&gt; - Integrated tracing and caching middleware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Config&lt;/strong&gt;: &lt;code&gt;docker-compose.yml&lt;/code&gt; - Added Redis service and Langfuse local instance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Materials&lt;/strong&gt;: &lt;code&gt;notebooks/week6/&lt;/code&gt; - Complete monitoring and caching implementation guide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 6 notebook
uv run jupyter notebook notebooks/week6/week6_cache_testing.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week6/week6_cache_testing.ipynb"&gt;Week 6 notebook&lt;/a&gt; for hands-on Langfuse tracing and Redis caching implementation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/production-ready-rag-monitoring-and"&gt;Production-ready RAG: Monitoring &amp;amp; Caching&lt;/a&gt; - Production-ready RAG with monitoring and caching&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 7: Agentic RAG with LangGraph and Telegram Bot&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 6 production system:&lt;/strong&gt; Add intelligent reasoning, multi-step decision-making, and Telegram bot integration for mobile-first AI interactions.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;LangGraph workflows for state-based agent orchestration with decision nodes&lt;/li&gt; 
 &lt;li&gt;Guardrail implementation for query validation and domain boundary detection&lt;/li&gt; 
 &lt;li&gt;Document grading with semantic relevance evaluation&lt;/li&gt; 
 &lt;li&gt;Query rewriting for automatic query refinement and better retrieval&lt;/li&gt; 
 &lt;li&gt;Adaptive retrieval with multi-attempt retrieval and intelligent fallback&lt;/li&gt; 
 &lt;li&gt;Telegram bot integration with async operations and error handling&lt;/li&gt; 
 &lt;li&gt;Reasoning transparency by exposing agent decision-making process&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week7_telegram_and_agentic_ai.png" alt="Week 7 Agentic RAG &amp;amp; Telegram Architecture" width="900" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agentic RAG Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Agent Nodes&lt;/strong&gt;: &lt;code&gt;src/services/agents/nodes/&lt;/code&gt; - Guardrail, retrieve, grade, rewrite, and generate nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workflow Orchestration&lt;/strong&gt;: &lt;code&gt;src/services/agents/agentic_rag.py&lt;/code&gt; - LangGraph workflow coordination&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Telegram Bot&lt;/strong&gt;: &lt;code&gt;src/services/telegram/&lt;/code&gt; - Command handlers and message processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agentic Endpoint&lt;/strong&gt;: &lt;code&gt;src/routers/agentic_ask.py&lt;/code&gt; - Agentic RAG API endpoint&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Materials&lt;/strong&gt;: &lt;code&gt;notebooks/week7/&lt;/code&gt; - Week 7 learning materials and examples&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 7 notebook
uv run jupyter notebook notebooks/week7/week7_agentic_rag.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week7/week7_agentic_rag.ipynb"&gt;Week 7 notebook&lt;/a&gt; for hands-on LangGraph agentic RAG and Telegram bot implementation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/agentic-rag-with-langgraph-and-telegram"&gt;Agentic RAG with LangGraph and Telegram&lt;/a&gt; - Building intelligent agents with decision-making, adaptive retrieval, and mobile access&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚öôÔ∏è Configuration&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
# Edit .env for your environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Key Variables:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;JINA_API_KEY&lt;/code&gt; - Required for Week 4+ (hybrid search with embeddings)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TELEGRAM__BOT_TOKEN&lt;/code&gt; - Required for Week 7 (Telegram bot integration)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;LANGFUSE__PUBLIC_KEY&lt;/code&gt; &amp;amp; &lt;code&gt;LANGFUSE__SECRET_KEY&lt;/code&gt; - Optional for Week 6 (monitoring)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Complete Configuration:&lt;/strong&gt; See &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/.env.example"&gt;.env.example&lt;/a&gt; for all available options and detailed documentation.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîß Reference &amp;amp; Development Guide&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;üõ†Ô∏è Technology Stack&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;REST API with automatic docs&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PostgreSQL 16&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper metadata and content storage&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenSearch 2.19&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid search engine (BM25 + Vector)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apache Airflow 3.0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Workflow automation&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Jina AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Embedding generation (Week 4)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Local LLM serving (Week 5)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;High-performance caching (Week 6)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Langfuse&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RAG pipeline observability (Week 6)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Development Tools:&lt;/strong&gt; UV, Ruff, MyPy, Pytest, Docker Compose&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Project Structure&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;arxiv-paper-curator/
‚îú‚îÄ‚îÄ src/                    # Main application code
‚îÇ   ‚îú‚îÄ‚îÄ routers/            # API endpoints (search, ask, papers)
‚îÇ   ‚îú‚îÄ‚îÄ services/           # Business logic (opensearch, ollama, agents, cache)
‚îÇ   ‚îú‚îÄ‚îÄ models/             # Database models (SQLAlchemy)
‚îÇ   ‚îú‚îÄ‚îÄ schemas/            # Pydantic validation schemas
‚îÇ   ‚îî‚îÄ‚îÄ config.py           # Environment configuration
‚îú‚îÄ‚îÄ notebooks/              # Weekly learning materials (week1-7)
‚îú‚îÄ‚îÄ airflow/                # Workflow orchestration (DAGs)
‚îú‚îÄ‚îÄ tests/                  # Test suite
‚îî‚îÄ‚îÄ compose.yml             # Docker service orchestration
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üì° API Endpoints Reference&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Endpoint&lt;/th&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Week&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/health&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Service health check&lt;/td&gt; 
   &lt;td&gt;Week 1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/papers&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;List stored papers&lt;/td&gt; 
   &lt;td&gt;Week 2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/papers/{id}&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Get specific paper&lt;/td&gt; 
   &lt;td&gt;Week 2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/search&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;BM25 keyword search&lt;/td&gt; 
   &lt;td&gt;Week 3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/hybrid-search/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;Hybrid search (BM25 + Vector)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Week 4&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;API Documentation:&lt;/strong&gt; Visit &lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt; for interactive API explorer&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üîß Essential Commands&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;Using the Makefile&lt;/strong&gt; (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# View all available commands
make help

# Quick workflow
make start         # Start all services
make health        # Check all services health
make test          # Run tests
make stop          # Stop services
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;All Available Commands&lt;/strong&gt;&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make start&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Start all services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make stop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Stop all services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make restart&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Restart all services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make status&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show service status&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make logs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show service logs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make health&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Check all services health&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make setup&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Install Python dependencies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make format&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Format code&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make lint&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Lint and type check&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make test&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Run tests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make test-cov&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Run tests with coverage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make clean&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Clean up everything&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;&lt;strong&gt;Direct Commands&lt;/strong&gt; (Alternative)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you prefer using commands directly
docker compose up --build -d    # Start services
docker compose ps               # Check status
docker compose logs            # View logs
uv run pytest                 # Run tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üéì Target Audience&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Who&lt;/th&gt; 
   &lt;th&gt;Why&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI/ML Engineers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Learn production RAG architecture beyond tutorials&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Software Engineers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Build end-to-end AI applications with best practices&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Scientists&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Implement production AI systems using modern tools&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üõ†Ô∏è Troubleshooting&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Common Issues:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Services not starting?&lt;/strong&gt; Wait 2-3 minutes, check &lt;code&gt;docker compose logs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port conflicts?&lt;/strong&gt; Stop other services using ports 8000, 8080, 5432, 9200&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory issues?&lt;/strong&gt; Increase Docker Desktop memory allocation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Get Help:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check the comprehensive Week 1 notebook troubleshooting section&lt;/li&gt; 
 &lt;li&gt;Review service logs: &lt;code&gt;docker compose logs [service-name]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Complete reset: &lt;code&gt;docker compose down --volumes &amp;amp;&amp;amp; docker compose up --build -d&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí∞ Cost Structure&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;This course is completely free!&lt;/strong&gt; You'll only need minimal costs for optional services:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local Development:&lt;/strong&gt; $0 (everything runs locally)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optional Cloud APIs:&lt;/strong&gt; ~$2-5 for external LLM services (if chosen)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üéâ Ready to Start Your AI Engineering Journey?&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;Begin with the Week 1 setup notebook and build your first production RAG system!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;For learners who want to master modern AI engineering&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Built with love by Jam With AI&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;MIT License - see &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>666ghj/BettaFish</title>
      <link>https://github.com/666ghj/BettaFish</link>
      <description>&lt;p&gt;ÂæÆËàÜÔºö‰∫∫‰∫∫ÂèØÁî®ÁöÑÂ§öAgentËàÜÊÉÖÂàÜÊûêÂä©ÊâãÔºåÊâìÁ†¥‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñÔºÅ‰ªé0ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÊ°ÜÊû∂„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_compressed.png" alt="BettaFish Logo" width="100%" /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15286" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15286" alt="666ghj%2FBettaFish | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;‚ÄÇ &lt;a href="https://lioncc.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;‚ÄÇ &lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://open.anspire.cn/?share_code=3E1FUOUH" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_anspire.png" alt="666ghj%2FBettaFish | Trendshift" height="50" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/666ghj/BettaFish?style=flat-square" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/666ghj/BettaFish?style=flat-square" alt="GitHub Watchers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/network"&gt;&lt;img src="https://img.shields.io/github/forks/666ghj/BettaFish?style=flat-square" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;&lt;img src="https://img.shields.io/github/issues/666ghj/BettaFish?style=flat-square" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/666ghj/BettaFish?style=flat-square" alt="GitHub Pull Requests" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/666ghj/BettaFish?style=flat-square" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish"&gt;&lt;img src="https://img.shields.io/badge/version-v1.2.1-green.svg?style=flat-square" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/"&gt;&lt;img src="https://img.shields.io/badge/Docker-Build-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README-EN.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README.md"&gt;‰∏≠ÊñáÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ö° È°πÁõÆÊ¶ÇËø∞&lt;/h2&gt; 
&lt;p&gt;‚Äú&lt;strong&gt;ÂæÆËàÜ&lt;/strong&gt;‚Äù ÊòØ‰∏Ä‰∏™‰ªé0ÂÆûÁé∞ÁöÑÂàõÊñ∞Âûã Â§öÊô∫ËÉΩ‰Ωì ËàÜÊÉÖÂàÜÊûêÁ≥ªÁªüÔºåÂ∏ÆÂä©Â§ßÂÆ∂Á†¥Èô§‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñ„ÄÇÁî®Êà∑Âè™ÈúÄÂÉèËÅäÂ§©‰∏ÄÊ†∑ÊèêÂá∫ÂàÜÊûêÈúÄÊ±ÇÔºåÊô∫ËÉΩ‰ΩìÂºÄÂßãÂÖ®Ëá™Âä®ÂàÜÊûê ÂõΩÂÜÖÂ§ñ30+‰∏ªÊµÅÁ§æÂ™í ‰∏é Êï∞Áôæ‰∏áÊù°Â§ß‰ºóËØÑËÆ∫„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ÄúÂæÆËàÜ‚ÄùË∞êÈü≥‚ÄúÂæÆÈ±º‚ÄùÔºåBettaFishÊòØ‰∏ÄÁßç‰ΩìÂûãÂæàÂ∞è‰ΩÜÈùûÂ∏∏Â•ΩÊñó„ÄÅÊºÇ‰∫ÆÁöÑÈ±ºÔºåÂÆÉË±°ÂæÅÁùÄ‚ÄúÂ∞èËÄåÂº∫Â§ßÔºå‰∏çÁïèÊåëÊàò‚Äù&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Êü•ÁúãÁ≥ªÁªü‰ª•‚ÄúÊ≠¶Ê±âÂ§ßÂ≠¶ËàÜÊÉÖ‚Äù‰∏∫‰æãÔºåÁîüÊàêÁöÑÁ†îÁ©∂Êä•ÂëäÔºö&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/final_reports/final_report__20250827_131630.html"&gt;Ê≠¶Ê±âÂ§ßÂ≠¶ÂìÅÁâåÂ£∞Ë™âÊ∑±Â∫¶ÂàÜÊûêÊä•Âëä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Êü•ÁúãÁ≥ªÁªü‰ª•‚ÄúÊ≠¶Ê±âÂ§ßÂ≠¶ËàÜÊÉÖ‚Äù‰∏∫‰æãÔºå‰∏ÄÊ¨°ÂÆåÊï¥ËøêË°åÁöÑËßÜÈ¢ëÔºö&lt;a href="https://www.bilibili.com/video/BV1TH1WBxEWN/?vd_source=da3512187e242ce17dceee4c537ec7a6#reply279744466833"&gt;ËßÜÈ¢ë-Ê≠¶Ê±âÂ§ßÂ≠¶ÂìÅÁâåÂ£∞Ë™âÊ∑±Â∫¶ÂàÜÊûêÊä•Âëä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‰∏ç‰ªÖ‰ªÖ‰ΩìÁé∞Âú®Êä•ÂëäË¥®Èáè‰∏äÔºåÁõ∏ÊØîÂêåÁ±ª‰∫ßÂìÅÔºåÊàë‰ª¨Êã•ÊúâüöÄÂÖ≠Â§ß‰ºòÂäøÔºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIÈ©±Âä®ÁöÑÂÖ®ÂüüÁõëÊéß&lt;/strong&gt;ÔºöAIÁà¨Ëô´ÈõÜÁæ§7x24Â∞èÊó∂‰∏çÈó¥Êñ≠‰Ωú‰∏öÔºåÂÖ®Èù¢Ë¶ÜÁõñÂæÆÂçö„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÊäñÈü≥„ÄÅÂø´ÊâãÁ≠â10+ÂõΩÂÜÖÂ§ñÂÖ≥ÈîÆÁ§æÂ™í„ÄÇ‰∏ç‰ªÖÂÆûÊó∂ÊçïËé∑ÁÉ≠ÁÇπÂÜÖÂÆπÔºåÊõ¥ËÉΩ‰∏ãÈíªËá≥Êµ∑ÈáèÁî®Êà∑ËØÑËÆ∫ÔºåËÆ©ÊÇ®Âê¨Âà∞ÊúÄÁúüÂÆû„ÄÅÊúÄÂπøÊ≥õÁöÑÂ§ß‰ºóÂ£∞Èü≥„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ë∂ÖË∂äLLMÁöÑÂ§çÂêàÂàÜÊûêÂºïÊìé&lt;/strong&gt;ÔºöÊàë‰ª¨‰∏ç‰ªÖ‰æùËµñËÆæËÆ°ÁöÑ5Á±ª‰∏ì‰∏öAgentÔºåÊõ¥ËûçÂêà‰∫ÜÂæÆË∞ÉÊ®°Âûã„ÄÅÁªüËÆ°Ê®°ÂûãÁ≠â‰∏≠Èó¥‰ª∂„ÄÇÈÄöËøáÂ§öÊ®°ÂûãÂçèÂêåÂ∑•‰ΩúÔºåÁ°Æ‰øù‰∫ÜÂàÜÊûêÁªìÊûúÁöÑÊ∑±Â∫¶„ÄÅÂáÜÂ∫¶‰∏éÂ§öÁª¥ËßÜËßí„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅËÉΩÂäõ&lt;/strong&gt;ÔºöÁ™ÅÁ†¥ÂõæÊñáÈôêÂà∂ÔºåËÉΩÊ∑±Â∫¶Ëß£ÊûêÊäñÈü≥„ÄÅÂø´ÊâãÁ≠âÁü≠ËßÜÈ¢ëÂÜÖÂÆπÔºåÂπ∂Á≤æÂáÜÊèêÂèñÁé∞‰ª£ÊêúÁ¥¢ÂºïÊìé‰∏≠ÁöÑÂ§©Ê∞î„ÄÅÊó•ÂéÜ„ÄÅËÇ°Á•®Á≠âÁªìÊûÑÂåñÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÂç°ÁâáÔºåËÆ©ÊÇ®ÂÖ®Èù¢ÊéåÊè°ËàÜÊÉÖÂä®ÊÄÅ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Agent‚ÄúËÆ∫Âùõ‚ÄùÂçè‰ΩúÊú∫Âà∂&lt;/strong&gt;Ôºö‰∏∫‰∏çÂêåAgentËµã‰∫àÁã¨ÁâπÁöÑÂ∑•ÂÖ∑ÈõÜ‰∏éÊÄùÁª¥Ê®°ÂºèÔºåÂºïÂÖ•Ëæ©ËÆ∫‰∏ªÊåÅ‰∫∫Ê®°ÂûãÔºåÈÄöËøá‚ÄúËÆ∫Âùõ‚ÄùÊú∫Âà∂ËøõË°åÈìæÂºèÊÄùÁª¥Á¢∞Êíû‰∏éËæ©ËÆ∫„ÄÇËøô‰∏ç‰ªÖÈÅøÂÖç‰∫ÜÂçï‰∏ÄÊ®°ÂûãÁöÑÊÄùÁª¥Â±ÄÈôê‰∏é‰∫§ÊµÅÂØºËá¥ÁöÑÂêåË¥®ÂåñÔºåÊõ¥ÂÇ¨ÁîüÂá∫Êõ¥È´òË¥®ÈáèÁöÑÈõÜ‰ΩìÊô∫ËÉΩ‰∏éÂÜ≥Á≠ñÊîØÊåÅ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂÖ¨ÁßÅÂüüÊï∞ÊçÆÊó†ÁºùËûçÂêà&lt;/strong&gt;ÔºöÂπ≥Âè∞‰∏ç‰ªÖÂàÜÊûêÂÖ¨ÂºÄËàÜÊÉÖÔºåËøòÊèê‰æõÈ´òÂÆâÂÖ®ÊÄßÁöÑÊé•Âè£ÔºåÊîØÊåÅÊÇ®Â∞ÜÂÜÖÈÉ®‰∏öÂä°Êï∞ÊçÆÂ∫ì‰∏éËàÜÊÉÖÊï∞ÊçÆÊó†ÁºùÈõÜÊàê„ÄÇÊâìÈÄöÊï∞ÊçÆÂ£ÅÂûíÔºå‰∏∫ÂûÇÁõ¥‰∏öÂä°Êèê‰æõ‚ÄúÂ§ñÈÉ®Ë∂ãÂäø+ÂÜÖÈÉ®Ê¥ûÂØü‚ÄùÁöÑÂº∫Â§ßÂàÜÊûêËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ËΩªÈáèÂåñ‰∏éÈ´òÊâ©Â±ïÊÄßÊ°ÜÊû∂&lt;/strong&gt;ÔºöÂü∫‰∫éÁ∫ØPythonÊ®°ÂùóÂåñËÆæËÆ°ÔºåÂÆûÁé∞ËΩªÈáèÂåñ„ÄÅ‰∏ÄÈîÆÂºèÈÉ®ÁΩ≤„ÄÇ‰ª£Á†ÅÁªìÊûÑÊ∏ÖÊô∞ÔºåÂºÄÂèëËÄÖÂèØËΩªÊùæÈõÜÊàêËá™ÂÆö‰πâÊ®°Âûã‰∏é‰∏öÂä°ÈÄªËæëÔºåÂÆûÁé∞Âπ≥Âè∞ÁöÑÂø´ÈÄüÊâ©Â±ï‰∏éÊ∑±Â∫¶ÂÆöÂà∂„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Âßã‰∫éËàÜÊÉÖÔºåËÄå‰∏çÊ≠¢‰∫éËàÜÊÉÖ&lt;/strong&gt;„ÄÇ‚ÄúÂæÆËàÜ‚ÄùÁöÑÁõÆÊ†áÔºåÊòØÊàê‰∏∫È©±Âä®‰∏ÄÂàá‰∏öÂä°Âú∫ÊôØÁöÑÁÆÄÊ¥ÅÈÄöÁî®ÁöÑÊï∞ÊçÆÂàÜÊûêÂºïÊìé„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏æ‰∏™‰æãÂ≠ê. ‰Ω†Âè™ÈúÄÁÆÄÂçï‰øÆÊîπAgentÂ∑•ÂÖ∑ÈõÜÁöÑapiÂèÇÊï∞‰∏épromptÔºåÂ∞±ÂèØ‰ª•Êää‰ªñÂèòÊàê‰∏Ä‰∏™ÈáëËûçÈ¢ÜÂüüÁöÑÂ∏ÇÂú∫ÂàÜÊûêÁ≥ªÁªü&lt;/p&gt; 
 &lt;p&gt;ÈôÑ‰∏Ä‰∏™ÊØîËæÉÊ¥ªË∑ÉÁöÑLÁ´ôÈ°πÁõÆËÆ®ËÆ∫Â∏ñÔºö&lt;a href="https://linux.do/t/topic/1009280"&gt;https://linux.do/t/topic/1009280&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Êü•ÁúãLÁ´ô‰Ω¨ÂèãÂÅöÁöÑÊµãËØÑ &lt;a href="https://linux.do/t/topic/1148040"&gt;ÂºÄÊ∫êÈ°πÁõÆ(ÂæÆËàÜ)‰∏émanus|minimax|ChatGPTÂØπÊØî&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/system_schematic.png" alt="banner" width="800" /&gt; 
 &lt;p&gt;ÂëäÂà´‰º†ÁªüÁöÑÊï∞ÊçÆÁúãÊùøÔºåÂú®‚ÄúÂæÆËàÜ‚ÄùÔºå‰∏ÄÂàáÁî±‰∏Ä‰∏™ÁÆÄÂçïÁöÑÈóÆÈ¢òÂºÄÂßãÔºåÊÇ®Âè™ÈúÄÂÉèÂØπËØù‰∏ÄÊ†∑ÔºåÊèêÂá∫ÊÇ®ÁöÑÂàÜÊûêÈúÄÊ±Ç&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ü™Ñ ËµûÂä©ÂïÜ&lt;/h2&gt; 
&lt;p&gt;LLMÊ®°ÂûãAPIËµûÂä©Ôºö&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;ÊúâËµûÂä©LLMÁÆóÂäõÁ¶èÂà©ÔºÅÁºñÁ®ãÊãºËΩ¶codecodex.aiÔºõÁºñÁ®ãÁÆóÂäõVibeCodingAPI.aiÔºö&lt;span style="margin-left: 10px"&gt;&lt;a href="https://codecodex.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÊâÄÁΩóÈó®ÂçöÂÆ¢LionCC.aiÂ∑≤Êõ¥Êñ∞„ÄäBettaFish ÂæÆËàÜÁ≥ªÁªü - LionCC API ÈÉ®ÁΩ≤ÈÖçÁΩÆÂÆåÂÖ®ÊåáÂçó„ÄãÊ≠£Âú®‰∫åÂºÄ‰ºòÂåñ‰∏ÄÈîÆÈÉ®ÁΩ≤Âíå‰∫ëÊúçÂä°Âô®Ë∞ÉÁî®ÊñπÊ°à„ÄÇ&lt;/li&gt; 
  &lt;li&gt;VibeCodingapi.aiÁãÆÂ≠êÁÆóÂäõÂπ≥Âè∞Â∑≤ÁªèÈÄÇÈÖç„ÄäBettaFish ÂæÆËàÜÁ≥ªÁªü„ÄãÊâÄÊúâLLMÊ®°ÂûãÂê´claude codeÂíåopenai codexÂíågemini cliÁºñÁ®ãÂºÄÂèë‰∏âÂ∑®Â§¥ÁÆóÂäõ„ÄÇÈ¢ùÂ∫¶‰ª∑Ê†ºÔºåÂè™Ë¶Å‰∏ÄÊØî‰∏ÄÔºà100ÂÖÉÁ≠â‰∫é100ÁæéÂàÄÈ¢ùÂ∫¶Ôºâ&lt;/li&gt; 
  &lt;li&gt;Codecodex.aiÁãÆÂ≠êÁºñÁ®ãÊãºËΩ¶Á≥ªÁªüÔºåÂ∑≤ÂÆûÁé∞Êó†IPÈó®ÊßõÁªïËøáclaude codeÂíåopenai codexÂ∞ÅÈîÅÔºåÊåâÂÆòÊñπÈÉ®ÁΩ≤ÊïôÁ®ãÂêéÂàáÊç¢BASE_URLË∞ÉÁî®Âú∞ÂùÄÂíåToken keyË∞ÉÁî®ÂØÜÈí•Âç≥ÂèØ‰ΩøÁî®ÊúÄÂº∫ÁºñÁ®ãÊ®°Âûã„ÄÇ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;ÊâÄÁΩóÈó®LionCCËµûÂä©BettaFish ÂæÆËàÜÁ¶èÂà©ÔºöÊâìÂºÄcodecodex.aiÁãÆÂ≠êÁºñÁ®ãÈ¢ëÈÅìÊâ´Á†ÅÂä†ÂÖ•ÂæÆ‰ø°Á§æÁæ§ÔºåÊ≥®ÂÜåVibeCodingapi.aiÁãÆÂ≠êÁÆóÂäõÔºåÁªü‰∏ÄÈÄÅ20ÂàÄAPIÈ¢ùÂ∫¶Ôºà‰ªÖÈôêÂâç‰∏ÄÂçÉÂêçÔºâ&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ÊåâÁî®Èáè‰ªòË¥πÁöÑ‰ºÅ‰∏öÁ∫ßAIËµÑÊ∫êÂπ≥Âè∞ÔºåÊèê‰æõÂ∏ÇÂú∫‰∏äÂÖ®Èù¢ÁöÑAIÊ®°ÂûãÂíåAPIÔºå‰ª•ÂèäÂ§öÁßçÂú®Á∫øAIÂ∫îÁî®Ôºö&lt;span style="margin-left: 10px"&gt;&lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_302ai_ch.jpg" alt="banner" /&gt;302.AIÊòØ‰∏Ä‰∏™ÊåâÁî®Èáè‰ªòË¥πÁöÑ‰ºÅ‰∏öÁ∫ßAIËµÑÊ∫êÂπ≥Âè∞ÔºåÊèê‰æõÂ∏ÇÂú∫‰∏äÊúÄÊñ∞„ÄÅÊúÄÂÖ®Èù¢ÁöÑAIÊ®°ÂûãÂíåAPIÔºå‰ª•ÂèäÂ§öÁßçÂºÄÁÆ±Âç≥Áî®ÁöÑÂú®Á∫øAIÂ∫îÁî®„ÄÇ 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;AIËÅîÁΩëÊêúÁ¥¢„ÄÅÊñá‰ª∂Ëß£ÊûêÂèäÁΩëÈ°µÂÜÖÂÆπÊäìÂèñÁ≠âÊô∫ËÉΩ‰ΩìÊ†∏ÂøÉËÉΩÂäõÊèê‰æõÂïÜÔºö&lt;span style="margin-left: 10px"&gt;&lt;a href="https://open.anspire.cn/?share_code=3E1FUOUH" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_anspire.png" alt="666ghj%2FBettaFish | Trendshift" height="50" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; ÂÆâÊÄùÊ¥æÂºÄÊîæÂπ≥Âè∞(Anspire Open)ÊòØÈù¢ÂêëÊô∫ËÉΩ‰ΩìÊó∂‰ª£ÁöÑÈ¢ÜÂÖàÁöÑÂü∫Á°ÄËÆæÊñΩÊèê‰æõÂïÜ„ÄÇÊàë‰ª¨‰∏∫ÂºÄÂèëËÄÖÊèê‰æõÊûÑÂª∫Âº∫Â§ßÊô∫ËÉΩ‰ΩìÊâÄÈúÄÁöÑÊ†∏ÂøÉËÉΩÂäõÊ†àÔºåÁé∞Â∑≤‰∏äÁ∫øAIËÅîÁΩëÊêúÁ¥¢„ÄêÂ§öÁâàÊú¨ÔºåÊûÅÂÖ∑Á´û‰∫âÂäõÁöÑ‰ª∑Ê†º„Äë„ÄÅÊñá‰ª∂Ëß£Êûê„ÄêÈôêÂÖç„ÄëÂèäÁΩëÈ°µÂÜÖÂÆπÊäìÂèñ„ÄêÈôêÂÖç„Äë„ÄÅ‰∫ëÁ´ØÊµèËßàÂô®Ëá™Âä®ÂåñÔºàAnspire Browser AgentÔºâ„ÄêÂÜÖÊµã„Äë„ÄÅÂ§öËΩÆÊîπÂÜôÁ≠âÊúçÂä°ÔºåÊåÅÁª≠‰∏∫Êô∫ËÉΩ‰ΩìËøûÊé•Âπ∂Êìç‰ΩúÂ§çÊùÇÁöÑÊï∞Â≠ó‰∏ñÁïåÊèê‰æõÂùöÂÆûÂü∫Á°Ä„ÄÇÂèØÊó†ÁºùÈõÜÊàêËá≥Dify„ÄÅCoze„ÄÅÂÖÉÂô®Á≠â‰∏ªÊµÅÊô∫ËÉΩ‰ΩìÂπ≥Âè∞„ÄÇÈÄöËøáÈÄèÊòéÁÇπÊï∞ËÆ°Ë¥π‰ΩìÁ≥ª‰∏éÊ®°ÂùóÂåñËÆæËÆ°Ôºå‰∏∫‰ºÅ‰∏öÊèê‰æõÈ´òÊïà„ÄÅ‰ΩéÊàêÊú¨ÁöÑÂÆöÂà∂ÂåñÊîØÊåÅÔºåÂä†ÈÄüÊô∫ËÉΩÂåñÂçáÁ∫ßËøõÁ®ã„ÄÇ 
&lt;/details&gt; 
&lt;h2&gt;üèóÔ∏è Á≥ªÁªüÊû∂ÊûÑ&lt;/h2&gt; 
&lt;h3&gt;Êï¥‰ΩìÊû∂ÊûÑÂõæ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Insight Agent&lt;/strong&gt; ÁßÅÊúâÊï∞ÊçÆÂ∫ìÊåñÊéòÔºöÁßÅÊúâËàÜÊÉÖÊï∞ÊçÆÂ∫ìÊ∑±Â∫¶ÂàÜÊûêAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Media Agent&lt;/strong&gt; Â§öÊ®°ÊÄÅÂÜÖÂÆπÂàÜÊûêÔºöÂÖ∑Â§áÂº∫Â§ßÂ§öÊ®°ÊÄÅËÉΩÂäõÁöÑAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Query Agent&lt;/strong&gt; Á≤æÂáÜ‰ø°ÊÅØÊêúÁ¥¢ÔºöÂÖ∑Â§áÂõΩÂÜÖÂ§ñÁΩëÈ°µÊêúÁ¥¢ËÉΩÂäõÁöÑAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Report Agent&lt;/strong&gt; Êô∫ËÉΩÊä•ÂëäÁîüÊàêÔºöÂÜÖÁΩÆÊ®°ÊùøÁöÑÂ§öËΩÆÊä•ÂëäÁîüÊàêAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/framework.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;‰∏ÄÊ¨°ÂÆåÊï¥ÂàÜÊûêÊµÅÁ®ã&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ê≠•È™§&lt;/th&gt; 
   &lt;th&gt;Èò∂ÊÆµÂêçÁß∞&lt;/th&gt; 
   &lt;th&gt;‰∏ªË¶ÅÊìç‰Ωú&lt;/th&gt; 
   &lt;th&gt;ÂèÇ‰∏éÁªÑ‰ª∂&lt;/th&gt; 
   &lt;th&gt;Âæ™ÁéØÁâπÊÄß&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;Áî®Êà∑ÊèêÈóÆ&lt;/td&gt; 
   &lt;td&gt;Flask‰∏ªÂ∫îÁî®Êé•Êî∂Êü•ËØ¢&lt;/td&gt; 
   &lt;td&gt;Flask‰∏ªÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;Âπ∂Ë°åÂêØÂä®&lt;/td&gt; 
   &lt;td&gt;‰∏â‰∏™AgentÂêåÊó∂ÂºÄÂßãÂ∑•‰Ωú&lt;/td&gt; 
   &lt;td&gt;Query Agent„ÄÅMedia Agent„ÄÅInsight Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;ÂàùÊ≠•ÂàÜÊûê&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent‰ΩøÁî®‰∏ìÂ±ûÂ∑•ÂÖ∑ËøõË°åÊ¶ÇËßàÊêúÁ¥¢&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + ‰∏ìÂ±ûÂ∑•ÂÖ∑ÈõÜ&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;Á≠ñÁï•Âà∂ÂÆö&lt;/td&gt; 
   &lt;td&gt;Âü∫‰∫éÂàùÊ≠•ÁªìÊûúÂà∂ÂÆöÂàÜÂùóÁ†îÁ©∂Á≠ñÁï•&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÂÜÖÈÉ®ÂÜ≥Á≠ñÊ®°Âùó&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5-N&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Âæ™ÁéØÈò∂ÊÆµ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ËÆ∫ÂùõÂçè‰Ωú + Ê∑±Â∫¶Á†îÁ©∂&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ForumEngine + ÊâÄÊúâAgent&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Â§öËΩÆÂæ™ÁéØ&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;Ê∑±Â∫¶Á†îÁ©∂&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÂü∫‰∫éËÆ∫Âùõ‰∏ªÊåÅ‰∫∫ÂºïÂØºËøõË°å‰∏ìÈ°πÊêúÁ¥¢&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + ÂèçÊÄùÊú∫Âà∂ + ËÆ∫ÂùõÂºïÂØº&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;ËÆ∫ÂùõÂçè‰Ωú&lt;/td&gt; 
   &lt;td&gt;ForumEngineÁõëÊéßAgentÂèëË®ÄÂπ∂ÁîüÊàê‰∏ªÊåÅ‰∫∫ÂºïÂØº&lt;/td&gt; 
   &lt;td&gt;ForumEngine + LLM‰∏ªÊåÅ‰∫∫&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;‰∫§ÊµÅËûçÂêà&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÊ†πÊçÆËÆ®ËÆ∫Ë∞ÉÊï¥Á†îÁ©∂ÊñπÂêë&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + forum_readerÂ∑•ÂÖ∑&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+1&lt;/td&gt; 
   &lt;td&gt;ÁªìÊûúÊï¥Âêà&lt;/td&gt; 
   &lt;td&gt;Report AgentÊî∂ÈõÜÊâÄÊúâÂàÜÊûêÁªìÊûúÂíåËÆ∫ÂùõÂÜÖÂÆπ&lt;/td&gt; 
   &lt;td&gt;Report Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+2&lt;/td&gt; 
   &lt;td&gt;IR‰∏≠Èó¥Ë°®Á§∫&lt;/td&gt; 
   &lt;td&gt;Âä®ÊÄÅÈÄâÊã©Ê®°ÊùøÂíåÊ†∑ÂºèÔºåÂ§öËΩÆÁîüÊàêÂÖÉÊï∞ÊçÆÔºåË£ÖËÆ¢‰∏∫IR‰∏≠Èó¥Ë°®Á§∫&lt;/td&gt; 
   &lt;td&gt;Report Agent + Ê®°ÊùøÂºïÊìé&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+3&lt;/td&gt; 
   &lt;td&gt;Êä•ÂëäÁîüÊàê&lt;/td&gt; 
   &lt;td&gt;ÂàÜÂùóËøõË°åË¥®ÈáèÊ£ÄÊµãÔºåÂü∫‰∫éIRÊ∏≤ÊüìÊàê‰∫§‰∫íÂºè HTML Êä•Âëä&lt;/td&gt; 
   &lt;td&gt;Report Agent + Ë£ÖËÆ¢ÂºïÊìé&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;È°πÁõÆ‰ª£Á†ÅÁªìÊûÑÊ†ë&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;BettaFish/
‚îú‚îÄ‚îÄ QueryEngine/                            # ÂõΩÂÜÖÂ§ñÊñ∞ÈóªÂπøÂ∫¶ÊêúÁ¥¢Agent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                            # Agent‰∏ªÈÄªËæëÔºåÂçèË∞ÉÊêúÁ¥¢‰∏éÂàÜÊûêÊµÅÁ®ã
‚îÇ   ‚îú‚îÄ‚îÄ llms/                               # LLMÊé•Âè£Â∞ÅË£Ö
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                              # Â§ÑÁêÜËäÇÁÇπÔºöÊêúÁ¥¢„ÄÅÊ†ºÂºèÂåñ„ÄÅÊÄªÁªìÁ≠â
‚îÇ   ‚îú‚îÄ‚îÄ tools/                              # ÂõΩÂÜÖÂ§ñÊñ∞ÈóªÊêúÁ¥¢Â∑•ÂÖ∑ÈõÜ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                              # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îú‚îÄ‚îÄ state/                              # Áä∂ÊÄÅÁÆ°ÁêÜ
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                            # ÊèêÁ§∫ËØçÊ®°Êùø
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ MediaEngine/                            # Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅÁêÜËß£Agent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                            # Agent‰∏ªÈÄªËæëÔºåÂ§ÑÁêÜËßÜÈ¢ë/ÂõæÁâáÁ≠âÂ§öÊ®°ÊÄÅÂÜÖÂÆπ
‚îÇ   ‚îú‚îÄ‚îÄ llms/                               # LLMÊé•Âè£Â∞ÅË£Ö
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                              # Â§ÑÁêÜËäÇÁÇπÔºöÊêúÁ¥¢„ÄÅÊ†ºÂºèÂåñ„ÄÅÊÄªÁªìÁ≠â
‚îÇ   ‚îú‚îÄ‚îÄ tools/                              # Â§öÊ®°ÊÄÅÊêúÁ¥¢Â∑•ÂÖ∑ÈõÜ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                              # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îú‚îÄ‚îÄ state/                              # Áä∂ÊÄÅÁÆ°ÁêÜ
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                            # ÊèêÁ§∫ËØçÊ®°Êùø
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ InsightEngine/                          # ÁßÅÊúâÊï∞ÊçÆÂ∫ìÊåñÊéòAgent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                            # Agent‰∏ªÈÄªËæëÔºåÂçèË∞ÉÊï∞ÊçÆÂ∫ìÊü•ËØ¢‰∏éÂàÜÊûê
‚îÇ   ‚îú‚îÄ‚îÄ llms/                               # LLMÊé•Âè£Â∞ÅË£Ö
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py                         # Áªü‰∏ÄÁöÑOpenAIÂÖºÂÆπÂÆ¢Êà∑Á´Ø
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                              # Â§ÑÁêÜËäÇÁÇπÔºöÊêúÁ¥¢„ÄÅÊ†ºÂºèÂåñ„ÄÅÊÄªÁªìÁ≠â
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_node.py                    # Âü∫Á°ÄËäÇÁÇπÁ±ª
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_node.py                  # ÊêúÁ¥¢ËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ formatting_node.py              # Ê†ºÂºèÂåñËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report_structure_node.py        # Êä•ÂëäÁªìÊûÑËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summary_node.py                 # ÊÄªÁªìËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                              # Êï∞ÊçÆÂ∫ìÊü•ËØ¢ÂíåÂàÜÊûêÂ∑•ÂÖ∑ÈõÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword_optimizer.py            # QwenÂÖ≥ÈîÆËØç‰ºòÂåñ‰∏≠Èó¥‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py                       # Êï∞ÊçÆÂ∫ìÊìç‰ΩúÂ∑•ÂÖ∑ÈõÜÔºàËØùÈ¢òÊêúÁ¥¢„ÄÅËØÑËÆ∫Ëé∑ÂèñÁ≠âÔºâ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sentiment_analyzer.py           # ÊÉÖÊÑüÂàÜÊûêÈõÜÊàêÂ∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ utils/                              # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                       # ÈÖçÁΩÆÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db.py                           # SQLAlchemyÂºÇÊ≠•ÂºïÊìé‰∏éÂè™ËØªÊü•ËØ¢Â∞ÅË£Ö
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_processing.py              # ÊñáÊú¨Â§ÑÁêÜÂ∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ state/                              # Áä∂ÊÄÅÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ state.py                        # AgentÁä∂ÊÄÅÂÆö‰πâ
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                            # ÊèêÁ§∫ËØçÊ®°Êùø
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py                      # ÂêÑÁ±ªÊèêÁ§∫ËØç
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ ReportEngine/                           # Â§öËΩÆÊä•ÂëäÁîüÊàêAgent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                            # ÊÄªË∞ÉÂ∫¶Âô®ÔºöÊ®°ÊùøÈÄâÊã©‚ÜíÂ∏ÉÂ±Ä‚ÜíÁØáÂπÖ‚ÜíÁ´†ËäÇ‚ÜíÊ∏≤Êüì
‚îÇ   ‚îú‚îÄ‚îÄ flask_interface.py                  # Flask/SSEÂÖ•Âè£ÔºåÁÆ°ÁêÜ‰ªªÂä°ÊéíÈòü‰∏éÊµÅÂºè‰∫ã‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ llms/                               # OpenAIÂÖºÂÆπLLMÂ∞ÅË£Ö
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py                         # Áªü‰∏ÄÁöÑÊµÅÂºè/ÈáçËØïÂÆ¢Êà∑Á´Ø
‚îÇ   ‚îú‚îÄ‚îÄ core/                               # Ê†∏ÂøÉÂäüËÉΩÔºöÊ®°ÊùøËß£Êûê„ÄÅÁ´†ËäÇÂ≠òÂÇ®„ÄÅÊñáÊ°£Ë£ÖËÆ¢
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ template_parser.py              # MarkdownÊ®°ÊùøÂàáÁâá‰∏éslugÁîüÊàê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chapter_storage.py              # Á´†ËäÇrunÁõÆÂΩï„ÄÅmanifest‰∏érawÊµÅÂÜôÂÖ•
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stitcher.py                     # Document IRË£ÖËÆ¢Âô®ÔºåË°•ÈΩêÈîöÁÇπ/ÂÖÉÊï∞ÊçÆ
‚îÇ   ‚îú‚îÄ‚îÄ ir/                                 # Êä•Âëä‰∏≠Èó¥Ë°®Á§∫ÔºàIRÔºâÂ•ëÁ∫¶‰∏éÊ†°È™å
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schema.py                       # Âùó/Ê†áËÆ∞SchemaÂ∏∏ÈáèÂÆö‰πâ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validator.py                    # Á´†ËäÇJSONÁªìÊûÑÊ†°È™åÂô®
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                              # ÂÖ®ÊµÅÁ®ãÊé®ÁêÜËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_node.py                    # ËäÇÁÇπÂü∫Á±ª+Êó•Âøó/Áä∂ÊÄÅÈí©Â≠ê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ template_selection_node.py      # Ê®°ÊùøÂÄôÈÄâÊî∂ÈõÜ‰∏éLLMÁ≠õÈÄâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_layout_node.py         # Ê†áÈ¢ò/ÁõÆÂΩï/‰∏ªÈ¢òËÆæËÆ°
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ word_budget_node.py             # ÁØáÂπÖËßÑÂàí‰∏éÁ´†ËäÇÊåá‰ª§ÁîüÊàê
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chapter_generation_node.py      # Á´†ËäÇÁ∫ßJSONÁîüÊàê+Ê†°È™å
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                            # ÊèêÁ§∫ËØçÂ∫ì‰∏éSchemaËØ¥Êòé
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py                      # Ê®°ÊùøÈÄâÊã©/Â∏ÉÂ±Ä/ÁØáÂπÖ/Á´†ËäÇÊèêÁ§∫ËØç
‚îÇ   ‚îú‚îÄ‚îÄ renderers/                          # IRÊ∏≤ÊüìÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ html_renderer.py                # Document IR‚Üí‰∫§‰∫íÂºèHTML
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_renderer.py                 # HTML‚ÜíPDFÂØºÂá∫ÔºàWeasyPrintÔºâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_layout_optimizer.py         # PDFÂ∏ÉÂ±Ä‰ºòÂåñÂô®
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chart_to_svg.py                 # ÂõæË°®ËΩ¨SVGÂ∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ state/                              # ‰ªªÂä°/ÂÖÉÊï∞ÊçÆÁä∂ÊÄÅÊ®°Âûã
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ state.py                        # ReportState‰∏éÂ∫èÂàóÂåñÂ∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ utils/                              # ÈÖçÁΩÆ‰∏éËæÖÂä©Â∑•ÂÖ∑
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                       # Pydantic Settings‰∏éÊâìÂç∞Âä©Êâã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency_check.py             # ‰æùËµñÊ£ÄÊü•Â∑•ÂÖ∑
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ json_parser.py                  # JSONËß£ÊûêÂ∑•ÂÖ∑
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chart_validator.py              # ÂõæË°®Ê†°È™åÂ∑•ÂÖ∑
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chart_repair_api.py             # ÂõæË°®‰øÆÂ§çAPI
‚îÇ   ‚îú‚îÄ‚îÄ report_template/                    # MarkdownÊ®°ÊùøÂ∫ì
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‰ºÅ‰∏öÂìÅÁâåÂ£∞Ë™âÂàÜÊûêÊä•Âëä.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ ForumEngine/                            # ËÆ∫ÂùõÂºïÊìéÔºöAgentÂçè‰ΩúÊú∫Âà∂
‚îÇ   ‚îú‚îÄ‚îÄ monitor.py                          # Êó•ÂøóÁõëÊéßÂíåËÆ∫ÂùõÁÆ°ÁêÜÊ†∏ÂøÉ
‚îÇ   ‚îú‚îÄ‚îÄ llm_host.py                         # ËÆ∫Âùõ‰∏ªÊåÅ‰∫∫LLMÊ®°Âùó
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ MindSpider/                             # Á§æ‰∫§Â™í‰ΩìÁà¨Ëô´Á≥ªÁªü
‚îÇ   ‚îú‚îÄ‚îÄ main.py                             # Áà¨Ëô´‰∏ªÁ®ãÂ∫èÂÖ•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ config.py                           # Áà¨Ëô´ÈÖçÁΩÆÊñá‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ BroadTopicExtraction/               # ËØùÈ¢òÊèêÂèñÊ®°Âùó
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                         # ËØùÈ¢òÊèêÂèñ‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database_manager.py             # Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_today_news.py               # ‰ªäÊó•Êñ∞ÈóªËé∑Âèñ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ topic_extractor.py              # ËØùÈ¢òÊèêÂèñÂô®
‚îÇ   ‚îú‚îÄ‚îÄ DeepSentimentCrawling/              # Ê∑±Â∫¶ËàÜÊÉÖÁà¨ÂèñÊ®°Âùó
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                         # Ê∑±Â∫¶Áà¨Âèñ‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword_manager.py              # ÂÖ≥ÈîÆËØçÁÆ°ÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ platform_crawler.py             # Âπ≥Âè∞Áà¨Ëô´ÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MediaCrawler/                   # Á§æÂ™íÁà¨Ëô´Ê†∏ÂøÉ
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config/                     # ÂêÑÂπ≥Âè∞ÈÖçÁΩÆ
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ media_platform/             # ÂêÑÂπ≥Âè∞Áà¨Ëô´ÂÆûÁé∞
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ schema/                             # Êï∞ÊçÆÂ∫ìÁªìÊûÑÂÆö‰πâ
‚îÇ       ‚îú‚îÄ‚îÄ db_manager.py                   # Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®
‚îÇ       ‚îú‚îÄ‚îÄ init_database.py                # Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñËÑöÊú¨
‚îÇ       ‚îú‚îÄ‚îÄ mindspider_tables.sql           # Êï∞ÊçÆÂ∫ìË°®ÁªìÊûÑSQL
‚îÇ       ‚îú‚îÄ‚îÄ models_bigdata.py               # Â§ßËßÑÊ®°Â™í‰ΩìËàÜÊÉÖË°®ÁöÑSQLAlchemyÊò†Â∞Ñ
‚îÇ       ‚îî‚îÄ‚îÄ models_sa.py                    # DailyTopic/TaskÁ≠âÊâ©Â±ïË°®ORMÊ®°Âûã
‚îú‚îÄ‚îÄ SentimentAnalysisModel/                 # ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÈõÜÂêà
‚îÇ   ‚îú‚îÄ‚îÄ WeiboSentiment_Finetuned/           # ÂæÆË∞ÉBERT/GPT-2Ê®°Âûã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BertChinese-Lora/               # BERT‰∏≠ÊñáLoRAÂæÆË∞É
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ GPT2-Lora/                      # GPT-2 LoRAÂæÆË∞É
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ WeiboMultilingualSentiment/         # Â§öËØ≠Ë®ÄÊÉÖÊÑüÂàÜÊûê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ WeiboSentiment_SmallQwen/           # Â∞èÂèÇÊï∞Qwen3ÂæÆË∞É
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict_universal.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ WeiboSentiment_MachineLearning/     # ‰º†ÁªüÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ï
‚îÇ       ‚îú‚îÄ‚îÄ train.py
‚îÇ       ‚îú‚îÄ‚îÄ predict.py
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ SingleEngineApp/                        # ÂçïÁã¨AgentÁöÑStreamlitÂ∫îÁî®
‚îÇ   ‚îú‚îÄ‚îÄ query_engine_streamlit_app.py       # QueryEngineÁã¨Á´ãÂ∫îÁî®
‚îÇ   ‚îú‚îÄ‚îÄ media_engine_streamlit_app.py       # MediaEngineÁã¨Á´ãÂ∫îÁî®
‚îÇ   ‚îî‚îÄ‚îÄ insight_engine_streamlit_app.py     # InsightEngineÁã¨Á´ãÂ∫îÁî®
‚îú‚îÄ‚îÄ query_engine_streamlit_reports/         # QueryEngineÂçïÂ∫îÁî®ËøêË°åËæìÂá∫
‚îú‚îÄ‚îÄ media_engine_streamlit_reports/         # MediaEngineÂçïÂ∫îÁî®ËøêË°åËæìÂá∫
‚îú‚îÄ‚îÄ insight_engine_streamlit_reports/       # InsightEngineÂçïÂ∫îÁî®ËøêË°åËæìÂá∫
‚îú‚îÄ‚îÄ templates/                              # FlaskÂâçÁ´ØÊ®°Êùø
‚îÇ   ‚îî‚îÄ‚îÄ index.html                          # ‰∏ªÁïåÈù¢HTML
‚îú‚îÄ‚îÄ static/                                 # ÈùôÊÄÅËµÑÊ∫ê
‚îÇ   ‚îî‚îÄ‚îÄ image/                              # ÂõæÁâáËµÑÊ∫ê
‚îÇ       ‚îú‚îÄ‚îÄ logo_compressed.png
‚îÇ       ‚îú‚îÄ‚îÄ framework.png
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ logs/                                   # ËøêË°åÊó•ÂøóÁõÆÂΩï
‚îú‚îÄ‚îÄ final_reports/                          # ÊúÄÁªàÁîüÊàêÁöÑÊä•ÂëäÊñá‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ ir/                                 # Êä•ÂëäIR JSONÊñá‰ª∂
‚îÇ   ‚îî‚îÄ‚îÄ *.html                              # ÊúÄÁªàHTMLÊä•Âëä
‚îú‚îÄ‚îÄ utils/                                  # ÈÄöÁî®Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îú‚îÄ‚îÄ forum_reader.py                     # AgentÈó¥ËÆ∫ÂùõÈÄö‰ø°Â∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ github_issues.py                    # Áªü‰∏ÄÁîüÊàêGitHub IssueÈìæÊé•‰∏éÈîôËØØÊèêÁ§∫
‚îÇ   ‚îî‚îÄ‚îÄ retry_helper.py                     # ÁΩëÁªúËØ∑Ê±ÇÈáçËØïÊú∫Âà∂Â∑•ÂÖ∑
‚îú‚îÄ‚îÄ tests/                                  # ÂçïÂÖÉÊµãËØï‰∏éÈõÜÊàêÊµãËØï
‚îÇ   ‚îú‚îÄ‚îÄ run_tests.py                        # pytestÂÖ•Âè£ËÑöÊú¨
‚îÇ   ‚îú‚îÄ‚îÄ test_monitor.py                     # ForumEngineÁõëÊéßÂçïÂÖÉÊµãËØï
‚îÇ   ‚îú‚îÄ‚îÄ test_report_engine_sanitization.py  # ReportEngineÂÆâÂÖ®ÊÄßÊµãËØï
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ app.py                                  # Flask‰∏ªÂ∫îÁî®ÂÖ•Âè£
‚îú‚îÄ‚îÄ config.py                               # ÂÖ®Â±ÄÈÖçÁΩÆÊñá‰ª∂
‚îú‚îÄ‚îÄ .env.example                            # ÁéØÂ¢ÉÂèòÈáèÁ§∫‰æãÊñá‰ª∂
‚îú‚îÄ‚îÄ docker-compose.yml                      # DockerÂ§öÊúçÂä°ÁºñÊéíÈÖçÁΩÆ
‚îú‚îÄ‚îÄ Dockerfile                              # DockerÈïúÂÉèÊûÑÂª∫Êñá‰ª∂
‚îú‚îÄ‚îÄ requirements.txt                        # Python‰æùËµñÂåÖÊ∏ÖÂçï
‚îú‚îÄ‚îÄ regenerate_latest_pdf.py                # PDFÈáçÊñ∞ÁîüÊàêÂ∑•ÂÖ∑ËÑöÊú¨
‚îú‚îÄ‚îÄ report_engine_only.py                   # Report EngineÂëΩ‰ª§Ë°åÁâàÊú¨
‚îú‚îÄ‚îÄ README.md                               # ‰∏≠ÊñáËØ¥ÊòéÊñáÊ°£
‚îú‚îÄ‚îÄ README-EN.md                            # Ëã±ÊñáËØ¥ÊòéÊñáÊ°£
‚îú‚îÄ‚îÄ CONTRIBUTING.md                         # ‰∏≠ÊñáË¥°ÁåÆÊåáÂçó
‚îú‚îÄ‚îÄ CONTRIBUTING-EN.md                      # Ëã±ÊñáË¥°ÁåÆÊåáÂçó
‚îî‚îÄ‚îÄ LICENSE                                 # GPL-2.0ÂºÄÊ∫êËÆ∏ÂèØËØÅ
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Âø´ÈÄüÂºÄÂßãÔºàDockerÔºâ&lt;/h2&gt; 
&lt;h3&gt;1. ÂêØÂä®È°πÁõÆ&lt;/h3&gt; 
&lt;p&gt;Â§çÂà∂‰∏Ä‰ªΩ &lt;code&gt;.env.example&lt;/code&gt; Êñá‰ª∂ÔºåÂëΩÂêç‰∏∫ &lt;code&gt;.env&lt;/code&gt; ÔºåÂπ∂ÊåâÈúÄÈÖçÁΩÆ &lt;code&gt;.env&lt;/code&gt; Êñá‰ª∂‰∏≠ÁöÑÁéØÂ¢ÉÂèòÈáè&lt;/p&gt; 
&lt;p&gt;ÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Âú®ÂêéÂè∞ÂêØÂä®ÊâÄÊúâÊúçÂä°Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Ê≥®ÔºöÈïúÂÉèÊãâÂèñÈÄüÂ∫¶ÊÖ¢&lt;/strong&gt;ÔºåÂú®Âéü &lt;code&gt;docker-compose.yml&lt;/code&gt; Êñá‰ª∂‰∏≠ÔºåÊàë‰ª¨Â∑≤ÁªèÈÄöËøá&lt;strong&gt;Ê≥®Èáä&lt;/strong&gt;ÁöÑÊñπÂºèÊèê‰æõ‰∫ÜÂ§áÁî®ÈïúÂÉèÂú∞ÂùÄ‰æõÊÇ®ÊõøÊç¢&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;2. ÈÖçÁΩÆËØ¥Êòé&lt;/h3&gt; 
&lt;h4&gt;Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºàPostgreSQLÔºâ&lt;/h4&gt; 
&lt;p&gt;ËØ∑ÊåâÁÖß‰ª•‰∏ãÂèÇÊï∞ÈÖçÁΩÆÊï∞ÊçÆÂ∫ìËøûÊé•‰ø°ÊÅØÔºå‰πüÊîØÊåÅMysqlÂèØËá™Ë°å‰øÆÊîπÔºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;ÈÖçÁΩÆÈ°π&lt;/th&gt; 
   &lt;th align="left"&gt;Â°´ÂÜôÂÄº&lt;/th&gt; 
   &lt;th align="left"&gt;ËØ¥Êòé&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;db&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÊúçÂä°ÂêçÁß∞ (ÂØπÂ∫î &lt;code&gt;docker-compose.yml&lt;/code&gt; ‰∏≠ÁöÑÊúçÂä°Âêç)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;5432&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;ÈªòËÆ§ PostgreSQL Á´ØÂè£&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_USER&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÁî®Êà∑Âêç&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PASSWORD&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÂØÜÁ†Å&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÂêçÁß∞&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;ÂÖ∂‰ªñ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;‰øùÊåÅÈªòËÆ§&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìËøûÊé•Ê±†Á≠âÂÖ∂‰ªñÂèÇÊï∞ËØ∑‰øùÊåÅÈªòËÆ§ËÆæÁΩÆ„ÄÇ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Â§ßÊ®°ÂûãÈÖçÁΩÆ&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êàë‰ª¨ÊâÄÊúâ LLM Ë∞ÉÁî®‰ΩøÁî® OpenAI ÁöÑ API Êé•Âè£Ê†áÂáÜ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Âú®ÂÆåÊàêÊï∞ÊçÆÂ∫ìÈÖçÁΩÆÂêéÔºåËØ∑Ê≠£Â∏∏ÈÖçÁΩÆ&lt;strong&gt;ÊâÄÊúâÂ§ßÊ®°ÂûãÁõ∏ÂÖ≥ÁöÑÂèÇÊï∞&lt;/strong&gt;ÔºåÁ°Æ‰øùÁ≥ªÁªüËÉΩÂ§üËøûÊé•Âà∞ÊÇ®ÈÄâÊã©ÁöÑÂ§ßÊ®°ÂûãÊúçÂä°„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÂÆåÊàê‰∏äËø∞ÊâÄÊúâÈÖçÁΩÆÂπ∂‰øùÂ≠òÂêéÔºåÁ≥ªÁªüÂç≥ÂèØÊ≠£Â∏∏ËøêË°å„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üîß Ê∫êÁ†ÅÂêØÂä®ÊåáÂçó&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Â¶ÇÊûú‰Ω†ÊòØÂàùÊ¨°Â≠¶‰π†‰∏Ä‰∏™AgentÁ≥ªÁªüÁöÑÊê≠Âª∫ÔºåÂèØ‰ª•‰ªé‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÁöÑdemoÂºÄÂßãÔºö&lt;a href="https://github.com/666ghj/DeepSearchAgent-Demo"&gt;Deep Search Agent Demo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ÁéØÂ¢ÉË¶ÅÊ±Ç&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êìç‰ΩúÁ≥ªÁªü&lt;/strong&gt;: Windows„ÄÅLinux„ÄÅMacOS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PythonÁâàÊú¨&lt;/strong&gt;: 3.9+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt;: AnacondaÊàñMiniconda&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êï∞ÊçÆÂ∫ì&lt;/strong&gt;: PostgreSQLÔºàÊé®ËçêÔºâÊàñMySQL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÜÖÂ≠ò&lt;/strong&gt;: Âª∫ËÆÆ2GB‰ª•‰∏ä&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. ÂàõÂª∫ÁéØÂ¢É&lt;/h3&gt; 
&lt;h4&gt;Â¶ÇÊûú‰ΩøÁî®Conda&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫condaÁéØÂ¢É
conda create -n your_conda_name python=3.11
conda activate your_conda_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Â¶ÇÊûú‰ΩøÁî®uv&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫uvÁéØÂ¢É
uv venv --python 3.11 # ÂàõÂª∫3.11ÁéØÂ¢É
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. ÂÆâË£Ö PDF ÂØºÂá∫ÊâÄÈúÄÁ≥ªÁªü‰æùËµñÔºàÂèØÈÄâÔºâ&lt;/h3&gt; 
&lt;p&gt;ËøôÈÉ®ÂàÜÊúâËØ¶ÁªÜÁöÑÈÖçÁΩÆËØ¥ÊòéÔºö&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/Partial%20README%20for%20PDF%20Exporting/README.md"&gt;ÈÖçÁΩÆÊâÄÈúÄ‰æùËµñ&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3. ÂÆâË£Ö‰æùËµñÂåÖ&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Â¶ÇÊûúË∑≥Ëøá‰∫ÜÊ≠•È™§2ÔºåweasyprintÂ∫ìÂèØËÉΩÊó†Ê≥ïÂÆâË£ÖÔºåPDFÂäüËÉΩÂèØËÉΩÊó†Ê≥ïÊ≠£Â∏∏‰ΩøÁî®„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âü∫Á°Ä‰æùËµñÂÆâË£Ö
pip install -r requirements.txt

# uvÁâàÊú¨ÂëΩ‰ª§ÔºàÊõ¥Âø´ÈÄüÂÆâË£ÖÔºâ
uv pip install -r requirements.txt
# Â¶ÇÊûú‰∏çÊÉ≥‰ΩøÁî®Êú¨Âú∞ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÔºàÁÆóÂäõÈúÄÊ±ÇÂæàÂ∞èÔºåÈªòËÆ§ÂÆâË£ÖcpuÁâàÊú¨ÔºâÔºåÂèØ‰ª•Â∞ÜËØ•Êñá‰ª∂‰∏≠ÁöÑ"Êú∫Âô®Â≠¶‰π†"ÈÉ®ÂàÜÊ≥®ÈáäÊéâÂÜçÊâßË°åÊåá‰ª§
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. ÂÆâË£ÖPlaywrightÊµèËßàÂô®È©±Âä®&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂÆâË£ÖÊµèËßàÂô®È©±Âä®ÔºàÁî®‰∫éÁà¨Ëô´ÂäüËÉΩÔºâ
playwright install chromium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;5. ÈÖçÁΩÆLLM‰∏éÊï∞ÊçÆÂ∫ì&lt;/h3&gt; 
&lt;p&gt;Â§çÂà∂‰∏Ä‰ªΩÈ°πÁõÆÊ†πÁõÆÂΩï &lt;code&gt;.env.example&lt;/code&gt; Êñá‰ª∂ÔºåÂëΩÂêç‰∏∫ &lt;code&gt;.env&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;ÁºñËæë &lt;code&gt;.env&lt;/code&gt; Êñá‰ª∂ÔºåÂ°´ÂÖ•ÊÇ®ÁöÑAPIÂØÜÈí•ÔºàÊÇ®‰πüÂèØ‰ª•ÈÄâÊã©Ëá™Â∑±ÁöÑÊ®°Âûã„ÄÅÊêúÁ¥¢‰ª£ÁêÜÔºåËØ¶ÊÉÖËßÅÊ†πÁõÆÂΩï.env.exampleÊñá‰ª∂ÂÜÖÊàñÊ†πÁõÆÂΩïconfig.py‰∏≠ÁöÑËØ¥ÊòéÔºâÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;# ====================== Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ ======================
# Êï∞ÊçÆÂ∫ì‰∏ªÊú∫Ôºå‰æãÂ¶Çlocalhost Êàñ 127.0.0.1
DB_HOST=your_db_host
# Êï∞ÊçÆÂ∫ìÁ´ØÂè£Âè∑ÔºåÈªòËÆ§‰∏∫3306
DB_PORT=3306
# Êï∞ÊçÆÂ∫ìÁî®Êà∑Âêç
DB_USER=your_db_user
# Êï∞ÊçÆÂ∫ìÂØÜÁ†Å
DB_PASSWORD=your_db_password
# Êï∞ÊçÆÂ∫ìÂêçÁß∞
DB_NAME=your_db_name
# Êï∞ÊçÆÂ∫ìÂ≠óÁ¨¶ÈõÜÔºåÊé®Ëçêutf8mb4ÔºåÂÖºÂÆπemoji
DB_CHARSET=utf8mb4
# Êï∞ÊçÆÂ∫ìÁ±ªÂûãpostgresqlÊàñmysql
DB_DIALECT=postgresql
# Êï∞ÊçÆÂ∫ì‰∏çÈúÄË¶ÅÂàùÂßãÂåñÔºåÊâßË°åapp.pyÊó∂‰ºöËá™Âä®Ê£ÄÊµã

# ====================== LLMÈÖçÁΩÆ ======================
# ÊÇ®ÂèØ‰ª•Êõ¥ÊîπÊØè‰∏™ÈÉ®ÂàÜLLM‰ΩøÁî®ÁöÑAPIÔºåÂè™Ë¶ÅÂÖºÂÆπOpenAIËØ∑Ê±ÇÊ†ºÂºèÈÉΩÂèØ‰ª•
# ÈÖçÁΩÆÊñá‰ª∂ÂÜÖÈÉ®Áªô‰∫ÜÊØè‰∏Ä‰∏™AgentÁöÑÊé®ËçêLLMÔºåÂàùÊ¨°ÈÉ®ÁΩ≤ËØ∑ÂÖàÂèÇËÄÉÊé®ËçêËÆæÁΩÆ

# Insight Agent
INSIGHT_ENGINE_API_KEY=
INSIGHT_ENGINE_BASE_URL=
INSIGHT_ENGINE_MODEL_NAME=

# Media Agent
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;6. ÂêØÂä®Á≥ªÁªü&lt;/h3&gt; 
&lt;h4&gt;6.1 ÂÆåÊï¥Á≥ªÁªüÂêØÂä®ÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÔºåÊøÄÊ¥ªcondaÁéØÂ¢É
conda activate your_conda_name

# ÂêØÂä®‰∏ªÂ∫îÁî®Âç≥ÂèØ
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;uv ÁâàÊú¨ÂêØÂä®ÂëΩ‰ª§&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÔºåÊøÄÊ¥ªuvÁéØÂ¢É
.venv\Scripts\activate

# ÂêØÂä®‰∏ªÂ∫îÁî®Âç≥ÂèØ
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®1Ôºö‰∏ÄÊ¨°ËøêË°åÁªàÊ≠¢ÂêéÔºåstreamlit appÂèØËÉΩÁªìÊùüÂºÇÂ∏∏‰ªçÁÑ∂Âç†Áî®Á´ØÂè£ÔºåÊ≠§Êó∂ÊêúÁ¥¢Âç†Áî®Á´ØÂè£ÁöÑËøõÁ®ãkillÊéâÂç≥ÂèØ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®2ÔºöÊï∞ÊçÆÁà¨ÂèñÈúÄË¶ÅÂçïÁã¨Êìç‰ΩúÔºåËßÅ6.3ÊåáÂºï&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ËÆøÈóÆ &lt;a href="http://localhost:5000"&gt;http://localhost:5000&lt;/a&gt; Âç≥ÂèØ‰ΩøÁî®ÂÆåÊï¥Á≥ªÁªü&lt;/p&gt; 
&lt;h4&gt;6.2 ÂçïÁã¨ÂêØÂä®Êüê‰∏™Agent&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂêØÂä®QueryEngine
streamlit run SingleEngineApp/query_engine_streamlit_app.py --server.port 8503

# ÂêØÂä®MediaEngine  
streamlit run SingleEngineApp/media_engine_streamlit_app.py --server.port 8502

# ÂêØÂä®InsightEngine
streamlit run SingleEngineApp/insight_engine_streamlit_app.py --server.port 8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6.3 Áà¨Ëô´Á≥ªÁªüÂçïÁã¨‰ΩøÁî®&lt;/h4&gt; 
&lt;p&gt;ËøôÈÉ®ÂàÜÊúâËØ¶ÁªÜÁöÑÈÖçÁΩÆÊñáÊ°£Ôºö&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/MindSpider/README.md"&gt;MindSpider‰ΩøÁî®ËØ¥Êòé&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="MindSpider\img\example.png" alt="banner" width="600" /&gt; 
 &lt;p&gt;MindSpider ËøêË°åÁ§∫‰æã&lt;/p&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ËøõÂÖ•Áà¨Ëô´ÁõÆÂΩï
cd MindSpider

# È°πÁõÆÂàùÂßãÂåñ
python main.py --setup

# ËøêË°åËØùÈ¢òÊèêÂèñÔºàËé∑ÂèñÁÉ≠ÁÇπÊñ∞ÈóªÂíåÂÖ≥ÈîÆËØçÔºâ
python main.py --broad-topic

# ËøêË°åÂÆåÊï¥Áà¨Ëô´ÊµÅÁ®ã
python main.py --complete --date 2024-01-20

# ‰ªÖËøêË°åËØùÈ¢òÊèêÂèñ
python main.py --broad-topic --date 2024-01-20

# ‰ªÖËøêË°åÊ∑±Â∫¶Áà¨Âèñ
python main.py --deep-sentiment --platforms xhs dy wb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6.4 ÂëΩ‰ª§Ë°åÊä•ÂëäÁîüÊàêÂ∑•ÂÖ∑&lt;/h4&gt; 
&lt;p&gt;ËØ•Â∑•ÂÖ∑‰ºöË∑≥Ëøá‰∏â‰∏™ÂàÜÊûêÂºïÊìéÁöÑËøêË°åÈò∂ÊÆµÔºåÁõ¥Êé•ËØªÂèñÂÆÉ‰ª¨ÁöÑÊúÄÊñ∞Êó•ÂøóÊñá‰ª∂ÔºåÂπ∂Âú®Êó†ÈúÄ Web ÁïåÈù¢ÁöÑÊÉÖÂÜµ‰∏ãÁîüÊàêÁªºÂêàÊä•ÂëäÔºàÂêåÊó∂ÁúÅÁï•Êñá‰ª∂Â¢ûÈáèÊ†°È™åÊ≠•È™§Ôºâ„ÄÇÈÄöÂ∏∏Áî®‰∫éÂØπÊä•ÂëäÁîüÊàêÁªìÊûú‰∏çÊª°ÊÑè„ÄÅÈúÄË¶ÅÂø´ÈÄüÈáçËØïÁöÑÂú∫ÊôØÔºåÊàñÂú®Ë∞ÉËØï Report Engine Êó∂ÂêØÁî®„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âü∫Êú¨‰ΩøÁî®ÔºàËá™Âä®‰ªéÊñá‰ª∂ÂêçÊèêÂèñ‰∏ªÈ¢òÔºâ
python report_engine_only.py

# ÊåáÂÆöÊä•Âëä‰∏ªÈ¢ò
python report_engine_only.py --query "ÂúüÊú®Â∑•Á®ãË°å‰∏öÂàÜÊûê"

# Ë∑≥ËøáPDFÁîüÊàêÔºàÂç≥‰ΩøÁ≥ªÁªüÊîØÊåÅÔºâ
python report_engine_only.py --skip-pdf

# ÊòæÁ§∫ËØ¶ÁªÜÊó•Âøó
python report_engine_only.py --verbose

# Êü•ÁúãÂ∏ÆÂä©‰ø°ÊÅØ
python report_engine_only.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;ÂäüËÉΩËØ¥ÊòéÔºö&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Ëá™Âä®Ê£ÄÊü•‰æùËµñ&lt;/strong&gt;ÔºöÁ®ãÂ∫è‰ºöËá™Âä®Ê£ÄÊü•PDFÁîüÊàêÊâÄÈúÄÁöÑÁ≥ªÁªü‰æùËµñÔºåÂ¶ÇÊûúÁº∫Â§±‰ºöÁªôÂá∫ÂÆâË£ÖÊèêÁ§∫&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ëé∑ÂèñÊúÄÊñ∞Êñá‰ª∂&lt;/strong&gt;ÔºöËá™Âä®‰ªé‰∏â‰∏™ÂºïÊìéÁõÆÂΩïÔºà&lt;code&gt;insight_engine_streamlit_reports&lt;/code&gt;„ÄÅ&lt;code&gt;media_engine_streamlit_reports&lt;/code&gt;„ÄÅ&lt;code&gt;query_engine_streamlit_reports&lt;/code&gt;ÔºâËé∑ÂèñÊúÄÊñ∞ÁöÑÂàÜÊûêÊä•Âëä&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êñá‰ª∂Á°ÆËÆ§&lt;/strong&gt;ÔºöÊòæÁ§∫ÊâÄÊúâÈÄâÊã©ÁöÑÊñá‰ª∂Âêç„ÄÅË∑ØÂæÑÂíå‰øÆÊîπÊó∂Èó¥ÔºåÁ≠âÂæÖÁî®Êà∑Á°ÆËÆ§ÔºàÈªòËÆ§ËæìÂÖ• &lt;code&gt;y&lt;/code&gt; ÁªßÁª≠ÔºåËæìÂÖ• &lt;code&gt;n&lt;/code&gt; ÈÄÄÂá∫Ôºâ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áõ¥Êé•ÁîüÊàêÊä•Âëä&lt;/strong&gt;ÔºöË∑≥ËøáÊñá‰ª∂Â¢ûÂä†ÂÆ°Ê†∏Á®ãÂ∫èÔºåÁõ¥Êé•Ë∞ÉÁî®Report EngineÁîüÊàêÁªºÂêàÊä•Âëä&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ëá™Âä®‰øùÂ≠òÊñá‰ª∂&lt;/strong&gt;Ôºö 
  &lt;ul&gt; 
   &lt;li&gt;HTMLÊä•Âëä‰øùÂ≠òÂà∞ &lt;code&gt;final_reports/&lt;/code&gt; ÁõÆÂΩï&lt;/li&gt; 
   &lt;li&gt;PDFÊä•ÂëäÔºàÂ¶ÇÊûúÊúâ‰æùËµñÔºâ‰øùÂ≠òÂà∞ &lt;code&gt;final_reports/pdf/&lt;/code&gt; ÁõÆÂΩï&lt;/li&gt; 
   &lt;li&gt;Êñá‰ª∂ÂëΩÂêçÊ†ºÂºèÔºö&lt;code&gt;final_report_{‰∏ªÈ¢ò}_{Êó∂Èó¥Êà≥}.html/pdf&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Ê≥®ÊÑè‰∫ãÈ°πÔºö&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Á°Æ‰øù‰∏â‰∏™ÂºïÊìéÁõÆÂΩï‰∏≠Ëá≥Â∞ëÊúâ‰∏Ä‰∏™ÂåÖÂê´&lt;code&gt;.md&lt;/code&gt;Êä•ÂëäÊñá‰ª∂&lt;/li&gt; 
 &lt;li&gt;ÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑‰∏éWebÁïåÈù¢Áõ∏‰∫íÁã¨Á´ãÔºå‰∏ç‰ºöÁõ∏‰∫íÂΩ±Âìç&lt;/li&gt; 
 &lt;li&gt;PDFÁîüÊàêÈúÄË¶ÅÂÆâË£ÖÁ≥ªÁªü‰æùËµñÔºåËØ¶ËßÅ‰∏äÊñá"ÂÆâË£Ö PDF ÂØºÂá∫ÊâÄÈúÄÁ≥ªÁªü‰æùËµñ"ÈÉ®ÂàÜ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚öôÔ∏è È´òÁ∫ßÈÖçÁΩÆÔºàÂ∑≤ËøáÊó∂ÔºåÂ∑≤ÁªèÁªü‰∏Ä‰∏∫È°πÁõÆÊ†πÁõÆÂΩï.envÊñá‰ª∂ÁÆ°ÁêÜÔºåÂÖ∂‰ªñÂ≠êagentËá™Âä®ÁªßÊâøÊ†πÁõÆÂΩïÈÖçÁΩÆÔºâ&lt;/h2&gt; 
&lt;h3&gt;‰øÆÊîπÂÖ≥ÈîÆÂèÇÊï∞&lt;/h3&gt; 
&lt;h4&gt;AgentÈÖçÁΩÆÂèÇÊï∞&lt;/h4&gt; 
&lt;p&gt;ÊØè‰∏™AgentÈÉΩÊúâ‰∏ìÈó®ÁöÑÈÖçÁΩÆÊñá‰ª∂ÔºåÂèØÊ†πÊçÆÈúÄÊ±ÇË∞ÉÊï¥Ôºå‰∏ãÈù¢ÊòØÈÉ®ÂàÜÁ§∫‰æãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# QueryEngine/utils/config.py
class Config:
    max_reflections = 2           # ÂèçÊÄùËΩÆÊ¨°
    max_search_results = 15       # ÊúÄÂ§ßÊêúÁ¥¢ÁªìÊûúÊï∞
    max_content_length = 8000     # ÊúÄÂ§ßÂÜÖÂÆπÈïøÂ∫¶
    
# MediaEngine/utils/config.py  
class Config:
    comprehensive_search_limit = 10  # ÁªºÂêàÊêúÁ¥¢ÈôêÂà∂
    web_search_limit = 15           # ÁΩëÈ°µÊêúÁ¥¢ÈôêÂà∂
    
# InsightEngine/utils/config.py
class Config:
    default_search_topic_globally_limit = 200    # ÂÖ®Â±ÄÊêúÁ¥¢ÈôêÂà∂
    default_get_comments_limit = 500             # ËØÑËÆ∫Ëé∑ÂèñÈôêÂà∂
    max_search_results_for_llm = 50              # ‰º†ÁªôLLMÁöÑÊúÄÂ§ßÁªìÊûúÊï∞
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÈÖçÁΩÆ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/sentiment_analyzer.py
SENTIMENT_CONFIG = {
    'model_type': 'multilingual',     # ÂèØÈÄâ: 'bert', 'multilingual', 'qwen'Á≠â
    'confidence_threshold': 0.8,      # ÁΩÆ‰ø°Â∫¶ÈòàÂÄº
    'batch_size': 32,                 # ÊâπÂ§ÑÁêÜÂ§ßÂ∞è
    'max_sequence_length': 512,       # ÊúÄÂ§ßÂ∫èÂàóÈïøÂ∫¶
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Êé•ÂÖ•‰∏çÂêåÁöÑLLMÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;ÊîØÊåÅ‰ªªÊÑèopenAIË∞ÉÁî®Ê†ºÂºèÁöÑLLMÊèê‰æõÂïÜÔºåÂè™ÈúÄË¶ÅÂú®/config.py‰∏≠Â°´ÂÜôÂØπÂ∫îÁöÑKEY„ÄÅBASE_URL„ÄÅMODEL_NAMEÂç≥ÂèØ„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰ªÄ‰πàÊòØopenAIË∞ÉÁî®Ê†ºÂºèÔºü‰∏ãÈù¢Êèê‰æõ‰∏Ä‰∏™ÁÆÄÂçïÁöÑ‰æãÂ≠êÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(api_key="your_api_key", 
               base_url="https://aihubmix.com/v1")

response = client.chat.completions.create(
   model="gpt-4o-mini",
   messages=[
       {'role': 'user', 
        'content': "Êé®ÁêÜÊ®°Âûã‰ºöÁªôÂ∏ÇÂú∫Â∏¶Êù•Âì™‰∫õÊñ∞ÁöÑÊú∫‰ºö"}
   ],
)

complete_response = response.choices[0].message.content
print(complete_response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Êõ¥ÊîπÊÉÖÊÑüÂàÜÊûêÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;Á≥ªÁªüÈõÜÊàê‰∫ÜÂ§öÁßçÊÉÖÊÑüÂàÜÊûêÊñπÊ≥ïÔºåÂèØÊ†πÊçÆÈúÄÊ±ÇÈÄâÊã©Ôºö&lt;/p&gt; 
&lt;h4&gt;1. Â§öËØ≠Ë®ÄÊÉÖÊÑüÂàÜÊûê&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboMultilingualSentiment
python predict.py --text "This product is amazing!" --lang "en"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Â∞èÂèÇÊï∞Qwen3ÂæÆË∞É&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_SmallQwen
python predict_universal.py --text "ËøôÊ¨°Ê¥ªÂä®ÂäûÂæóÂæàÊàêÂäü"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Âü∫‰∫éBERTÁöÑÂæÆË∞ÉÊ®°Âûã&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ‰ΩøÁî®BERT‰∏≠ÊñáÊ®°Âûã
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/BertChinese-Lora
python predict.py --text "Ëøô‰∏™‰∫ßÂìÅÁúüÁöÑÂæà‰∏çÈîô"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. GPT-2 LoRAÂæÆË∞ÉÊ®°Âûã&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_Finetuned/GPT2-Lora
python predict.py --text "‰ªäÂ§©ÂøÉÊÉÖ‰∏çÂ§™Â•Ω"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. ‰º†ÁªüÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ï&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_MachineLearning
python predict.py --model_type "svm" --text "ÊúçÂä°ÊÄÅÂ∫¶ÈúÄË¶ÅÊîπËøõ"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Êé•ÂÖ•Ëá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÂ∫ì&lt;/h3&gt; 
&lt;h4&gt;1. ‰øÆÊîπÊï∞ÊçÆÂ∫ìËøûÊé•ÈÖçÁΩÆ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# config.py ‰∏≠Ê∑ªÂä†ÊÇ®ÁöÑ‰∏öÂä°Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ
BUSINESS_DB_HOST = "your_business_db_host"
BUSINESS_DB_PORT = 3306
BUSINESS_DB_USER = "your_business_user"
BUSINESS_DB_PASSWORD = "your_business_password"
BUSINESS_DB_NAME = "your_business_database"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. ÂàõÂª∫Ëá™ÂÆö‰πâÊï∞ÊçÆËÆøÈóÆÂ∑•ÂÖ∑&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/custom_db_tool.py
class CustomBusinessDBTool:
    """Ëá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÂ∫ìÊü•ËØ¢Â∑•ÂÖ∑"""
    
    def __init__(self):
        self.connection_config = {
            'host': config.BUSINESS_DB_HOST,
            'port': config.BUSINESS_DB_PORT,
            'user': config.BUSINESS_DB_USER,
            'password': config.BUSINESS_DB_PASSWORD,
            'database': config.BUSINESS_DB_NAME,
        }
    
    def search_business_data(self, query: str, table: str):
        """Êü•ËØ¢‰∏öÂä°Êï∞ÊçÆ"""
        # ÂÆûÁé∞ÊÇ®ÁöÑ‰∏öÂä°ÈÄªËæë
        pass
    
    def get_customer_feedback(self, product_id: str):
        """Ëé∑ÂèñÂÆ¢Êà∑ÂèçÈ¶àÊï∞ÊçÆ"""
        # ÂÆûÁé∞ÂÆ¢Êà∑ÂèçÈ¶àÊü•ËØ¢ÈÄªËæë
        pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. ÈõÜÊàêÂà∞InsightEngine&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/agent.py ‰∏≠ÈõÜÊàêËá™ÂÆö‰πâÂ∑•ÂÖ∑
from .tools.custom_db_tool import CustomBusinessDBTool

class DeepSearchAgent:
    def __init__(self, config=None):
        # ... ÂÖ∂‰ªñÂàùÂßãÂåñ‰ª£Á†Å
        self.custom_db_tool = CustomBusinessDBTool()
    
    def execute_custom_search(self, query: str):
        """ÊâßË°åËá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÊêúÁ¥¢"""
        return self.custom_db_tool.search_business_data(query, "your_table")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ëá™ÂÆö‰πâÊä•ÂëäÊ®°Êùø&lt;/h3&gt; 
&lt;h4&gt;1. Âú®WebÁïåÈù¢‰∏≠‰∏ä‰º†&lt;/h4&gt; 
&lt;p&gt;Á≥ªÁªüÊîØÊåÅ‰∏ä‰º†Ëá™ÂÆö‰πâÊ®°ÊùøÊñá‰ª∂Ôºà.mdÊàñ.txtÊ†ºÂºèÔºâÔºåÂèØÂú®ÁîüÊàêÊä•ÂëäÊó∂ÈÄâÊã©‰ΩøÁî®„ÄÇ&lt;/p&gt; 
&lt;h4&gt;2. ÂàõÂª∫Ê®°ÊùøÊñá‰ª∂&lt;/h4&gt; 
&lt;p&gt;Âú® &lt;code&gt;ReportEngine/report_template/&lt;/code&gt; ÁõÆÂΩï‰∏ãÂàõÂª∫Êñ∞ÁöÑÊ®°ÊùøÔºåÊàë‰ª¨ÁöÑAgent‰ºöËá™Ë°åÈÄâÁî®ÊúÄÂêàÈÄÇÁöÑÊ®°Êùø„ÄÇ&lt;/p&gt; 
&lt;h2&gt;ü§ù Ë¥°ÁåÆÊåáÂçó&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨Ê¨¢ËøéÊâÄÊúâÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ËØ∑ÈòÖËØª‰ª•‰∏ãË¥°ÁåÆÊåáÂçóÔºö&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü¶ñ ‰∏ã‰∏ÄÊ≠•ÂºÄÂèëËÆ°Âàí&lt;/h2&gt; 
&lt;p&gt;Áé∞Âú®Á≥ªÁªüÂè™ÂÆåÊàê‰∫Ü"‰∏âÊùøÊñß"‰∏≠ÁöÑÂâç‰∏§Ê≠•ÔºåÂç≥ÔºöËæìÂÖ•Ë¶ÅÊ±Ç-&amp;gt;ËØ¶ÁªÜÂàÜÊûêÔºåËøòÁº∫Â∞ë‰∏ÄÊ≠•È¢ÑÊµãÔºåÁõ¥Êé•Â∞Ü‰ªñÁªßÁª≠‰∫§ÁªôLLMÊòØ‰∏çÂÖ∑ÊúâËØ¥ÊúçÂäõÁöÑ„ÄÇ&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_compressed.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;p&gt;ÁõÆÂâçÊàë‰ª¨ÁªèËøáÂæàÈïø‰∏ÄÊÆµÊó∂Èó¥ÁöÑÁà¨ÂèñÊî∂ÈõÜÔºåÊã•Êúâ‰∫ÜÂ§ßÈáèÂÖ®ÁΩëËØùÈ¢òÁÉ≠Â∫¶ÈöèÊó∂Èó¥„ÄÅÁàÜÁÇπÁ≠âÁöÑÂèòÂåñË∂ãÂäøÁÉ≠Â∫¶Êï∞ÊçÆÔºåÂ∑≤ÁªèÂÖ∑Â§á‰∫ÜÂèØ‰ª•ÂºÄÂèëÈ¢ÑÊµãÊ®°ÂûãÁöÑÊù°‰ª∂„ÄÇÊàë‰ª¨Âõ¢ÈòüÂ∞ÜËøêÁî®Êó∂Â∫èÊ®°Âûã„ÄÅÂõæÁ•ûÁªèÁΩëÁªú„ÄÅÂ§öÊ®°ÊÄÅËûçÂêàÁ≠âÈ¢ÑÊµãÊ®°ÂûãÊäÄÊúØÂÇ®Â§á‰∫éÊ≠§ÔºåÂÆûÁé∞ÁúüÊ≠£Âü∫‰∫éÊï∞ÊçÆÈ©±Âä®ÁöÑËàÜÊÉÖÈ¢ÑÊµãÂäüËÉΩ„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ÈáçË¶ÅÊèêÈÜíÔºöÊú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†„ÄÅÂ≠¶ÊúØÁ†îÁ©∂ÂíåÊïôËÇ≤ÁõÆÁöÑ‰ΩøÁî®&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêàËßÑÊÄßÂ£∞Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Êú¨È°πÁõÆ‰∏≠ÁöÑÊâÄÊúâ‰ª£Á†Å„ÄÅÂ∑•ÂÖ∑ÂíåÂäüËÉΩÂùá‰ªÖ‰æõÂ≠¶‰π†„ÄÅÂ≠¶ÊúØÁ†îÁ©∂ÂíåÊïôËÇ≤ÁõÆÁöÑ‰ΩøÁî®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÊú¨È°πÁõÆÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÁî®ÈÄîÊàñÁõàÂà©ÊÄßÊ¥ªÂä®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÊú¨È°πÁõÆÁî®‰∫é‰ªª‰ΩïËøùÊ≥ï„ÄÅËøùËßÑÊàñ‰æµÁäØ‰ªñ‰∫∫ÊùÉÁõäÁöÑË°å‰∏∫&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Áà¨Ëô´ÂäüËÉΩÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;È°πÁõÆ‰∏≠ÁöÑÁà¨Ëô´ÂäüËÉΩ‰ªÖÁî®‰∫éÊäÄÊúØÂ≠¶‰π†ÂíåÁ†îÁ©∂ÁõÆÁöÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂøÖÈ°ªÈÅµÂÆàÁõÆÊ†áÁΩëÁ´ôÁöÑrobots.txtÂçèËÆÆÂíå‰ΩøÁî®Êù°Ê¨æ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂøÖÈ°ªÈÅµÂÆàÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÔºå‰∏çÂæóËøõË°åÊÅ∂ÊÑèÁà¨ÂèñÊàñÊï∞ÊçÆÊª•Áî®&lt;/li&gt; 
   &lt;li&gt;Âõ†‰ΩøÁî®Áà¨Ëô´ÂäüËÉΩ‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãÂêéÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊãÖ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êï∞ÊçÆ‰ΩøÁî®ÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;È°πÁõÆÊ∂âÂèäÁöÑÊï∞ÊçÆÂàÜÊûêÂäüËÉΩ‰ªÖ‰æõÂ≠¶ÊúØÁ†îÁ©∂‰ΩøÁî®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÂàÜÊûêÁªìÊûúÁî®‰∫éÂïÜ‰∏öÂÜ≥Á≠ñÊàñÁõàÂà©ÁõÆÁöÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îÁ°Æ‰øùÊâÄÂàÜÊûêÊï∞ÊçÆÁöÑÂêàÊ≥ïÊÄßÂíåÂêàËßÑÊÄß&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÊäÄÊúØÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Êú¨È°πÁõÆÊåâ"Áé∞Áä∂"Êèê‰æõÔºå‰∏çÊèê‰æõ‰ªª‰ΩïÊòéÁ§∫ÊàñÊöóÁ§∫ÁöÑ‰øùËØÅ&lt;/li&gt; 
   &lt;li&gt;‰ΩúËÄÖ‰∏çÂØπ‰ΩøÁî®Êú¨È°πÁõÆÈÄ†ÊàêÁöÑ‰ªª‰ΩïÁõ¥Êé•ÊàñÈó¥Êé•ÊçüÂ§±ÊâøÊãÖË¥£‰ªª&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îËá™Ë°åËØÑ‰º∞È°πÁõÆÁöÑÈÄÇÁî®ÊÄßÂíåÈ£éÈô©&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ë¥£‰ªªÈôêÂà∂&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂú®‰ΩøÁî®Êú¨È°πÁõÆÂâçÂ∫îÂÖÖÂàÜ‰∫ÜËß£Áõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îÁ°Æ‰øùÂÖ∂‰ΩøÁî®Ë°å‰∏∫Á¨¶ÂêàÂΩìÂú∞Ê≥ïÂæãÊ≥ïËßÑË¶ÅÊ±Ç&lt;/li&gt; 
   &lt;li&gt;Âõ†ËøùÂèçÊ≥ïÂæãÊ≥ïËßÑ‰ΩøÁî®Êú¨È°πÁõÆËÄå‰∫ßÁîüÁöÑ‰ªª‰ΩïÂêéÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊãÖ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ËØ∑Âú®‰ΩøÁî®Êú¨È°πÁõÆÂâç‰ªîÁªÜÈòÖËØªÂπ∂ÁêÜËß£‰∏äËø∞ÂÖçË¥£Â£∞Êòé„ÄÇ‰ΩøÁî®Êú¨È°πÁõÆÂç≥Ë°®Á§∫ÊÇ®Â∑≤ÂêåÊÑèÂπ∂Êé•Âèó‰∏äËø∞ÊâÄÊúâÊù°Ê¨æ„ÄÇ&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ ËÆ∏ÂèØËØÅ&lt;/h2&gt; 
&lt;p&gt;Êú¨È°πÁõÆÈááÁî® &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/LICENSE"&gt;GPL-2.0ËÆ∏ÂèØËØÅ&lt;/a&gt;„ÄÇËØ¶ÁªÜ‰ø°ÊÅØËØ∑ÂèÇÈòÖLICENSEÊñá‰ª∂„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üéâ ÊîØÊåÅ‰∏éËÅîÁ≥ª&lt;/h2&gt; 
&lt;h3&gt;Ëé∑ÂèñÂ∏ÆÂä©&lt;/h3&gt; 
&lt;p&gt;Â∏∏ËßÅÈóÆÈ¢òËß£Á≠îÔºö&lt;a href="https://github.com/666ghj/BettaFish/issues/185"&gt;https://github.com/666ghj/BettaFish/issues/185&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;È°πÁõÆ‰∏ªÈ°µ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish"&gt;GitHub‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈóÆÈ¢òÂèçÈ¶à&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;IssuesÈ°µÈù¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂäüËÉΩÂª∫ËÆÆ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish/discussions"&gt;DiscussionsÈ°µÈù¢&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ËÅîÁ≥ªÊñπÂºè&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìß &lt;strong&gt;ÈÇÆÁÆ±&lt;/strong&gt;Ôºö&lt;a href="mailto:hangjiang@bupt.edu.cn"&gt;hangjiang@bupt.edu.cn&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÂïÜÂä°Âêà‰Ωú&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºÅ‰∏öÂÆöÂà∂ÂºÄÂèë&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§ßÊï∞ÊçÆÊúçÂä°&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â≠¶ÊúØÂêà‰Ωú&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊäÄÊúØÂüπËÆ≠&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Ë¥°ÁåÆËÄÖ&lt;/h2&gt; 
&lt;p&gt;ÊÑüË∞¢‰ª•‰∏ã‰ºòÁßÄÁöÑË¥°ÁåÆËÄÖ‰ª¨Ôºö&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=666ghj/BettaFish" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Âä†ÂÖ•ÂÆòÊñπ‰∫§ÊµÅÁæ§&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://capsule-render.vercel.app/api?type=waving&amp;amp;color=gradient&amp;amp;height=200&amp;amp;section=header&amp;amp;text=Ê¨¢ËøéÂä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅQQÁæ§ÔºÅ&amp;amp;fontSize=40&amp;amp;fontAlignY=35&amp;amp;desc=Êâ´Êèè‰∏ãÊñπ‰∫åÁª¥Á†ÅÂä†ÂÖ•Áæ§ËÅä&amp;amp;descAlignY=55" alt="Ê¨¢ËøéÂä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅQQÁæ§ÔºÅ" style="width:60%; max-width:900px; display:block; margin:0 auto;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/QQ_Light_Horizenal.png" alt="BettaFish ÊäÄÊúØ‰∫§ÊµÅÁæ§‰∫åÁª¥Á†Å" style="width:60%; max-width:360px; display:block; margin:20px auto 0;" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìà È°πÁõÆÁªüËÆ°&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e04e3eea4674edc39c148a7845c8d09c1b7b1922.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GoogleCloudPlatform/agent-starter-pack</title>
      <link>https://github.com/GoogleCloudPlatform/agent-starter-pack</link>
      <description>&lt;p&gt;Ship AI Agents to Google Cloud in minutes, not months. Production-ready templates with built-in CI/CD, evaluation, and observability.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üöÄ Agent Starter Pack&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/pypi/v/agent-starter-pack?color=blue" alt="Version" /&gt; &lt;a href="https://youtu.be/jHt-ZVD660g"&gt;&lt;img src="https://img.shields.io/badge/1--Minute%20Overview-gray" alt="1-Minute Video Overview" /&gt;&lt;/a&gt; &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/"&gt;&lt;img src="https://img.shields.io/badge/Documentation-gray" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://studio.firebase.google.com/new?template=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fagent-starter-pack%2Ftree%2Fmain%2Fagent_starter_pack%2Fresources%2Fidx"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://cdn.firebasestudio.dev/btn/try_light_20.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://cdn.firebasestudio.dev/btn/try_dark_20.svg" /&gt; 
   &lt;img height="20" alt="Try in Firebase Studio" src="https://cdn.firebasestudio.dev/btn/try_blue_20.svg?sanitize=true" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;a href="https://shell.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Feliasecchig%2Fasp-open-in-cloud-shell&amp;amp;cloudshell_print=open-in-cs"&gt;&lt;img src="https://img.shields.io/badge/Launch-in_Cloud_Shell-white" alt="Launch in Cloud Shell" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/GoogleCloudPlatform/agent-starter-pack?color=yellow" alt="Stars" /&gt;&lt;/p&gt; 
&lt;p&gt;A Python package that provides &lt;strong&gt;production-ready templates&lt;/strong&gt; for GenAI agents on Google Cloud.&lt;/p&gt; 
&lt;p&gt;Focus on your agent logic‚Äîthe starter pack provides everything else: infrastructure, CI/CD, observability, and security.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;‚ö°Ô∏è Launch&lt;/th&gt; 
   &lt;th&gt;üß™ Experiment&lt;/th&gt; 
   &lt;th&gt;‚úÖ Deploy&lt;/th&gt; 
   &lt;th&gt;üõ†Ô∏è Customize&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/agent_starter_pack/agents/"&gt;Pre-built agent templates&lt;/a&gt; (ReAct, RAG, multi-agent, Live API).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview"&gt;Vertex AI evaluation&lt;/a&gt; and an interactive playground.&lt;/td&gt; 
   &lt;td&gt;Production-ready infra with &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/observability"&gt;monitoring, observability&lt;/a&gt;, and &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/deployment"&gt;CI/CD&lt;/a&gt; on &lt;a href="https://cloud.google.com/run"&gt;Cloud Run&lt;/a&gt; or &lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview"&gt;Agent Engine&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;Extend and customize templates according to your needs. üÜï Now integrating with &lt;a href="https://github.com/google-gemini/gemini-cli"&gt;Gemini CLI&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ö° Get Started in 1 Minute&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;From zero to production-ready agent in 60 seconds using &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx agent-starter-pack create
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt; ‚ú® Alternative: Using pip&lt;/summary&gt; 
 &lt;p&gt;If you don't have &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt; installed, you can use pip:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Create and activate a Python virtual environment
python -m venv .venv &amp;amp;&amp;amp; source .venv/bin/activate

# Install the agent starter pack
pip install --upgrade agent-starter-pack

# Create a new agent project
agent-starter-pack create
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; You now have a fully functional agent project‚Äîcomplete with backend, frontend, and deployment infrastructure‚Äîready for you to explore and customize.&lt;/p&gt; 
&lt;h3&gt;üîß Enhance Existing Agents&lt;/h3&gt; 
&lt;p&gt;Already have an agent? Add production-ready deployment and infrastructure by running this command in your project's root folder:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx agent-starter-pack enhance
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/installation"&gt;Installation Guide&lt;/a&gt; for more options, or try with zero setup in &lt;a href="https://studio.firebase.google.com/new?template=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fagent-starter-pack%2Ftree%2Fmain%2Fsrc%2Fresources%2Fidx"&gt;Firebase Studio&lt;/a&gt; or &lt;a href="https://shell.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Feliasecchig%2Fasp-open-in-cloud-shell&amp;amp;cloudshell_print=open-in-cs"&gt;Cloud Shell&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ñ Agents&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;adk_base&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A base ReAct agent implemented using Google's &lt;a href="https://github.com/google/adk-python"&gt;Agent Development Kit&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;adk_a2a_base&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;An ADK agent with &lt;a href="https://a2a-protocol.org/"&gt;Agent2Agent (A2A) Protocol&lt;/a&gt; support for distributed agent communication and interoperability&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;agentic_rag&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A RAG agent for document retrieval and Q&amp;amp;A. Supporting &lt;a href="https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction"&gt;Vertex AI Search&lt;/a&gt; and &lt;a href="https://cloud.google.com/vertex-ai/docs/vector-search/overview"&gt;Vector Search&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;langgraph_base&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A base ReAct agent implemented using LangChain's &lt;a href="https://github.com/langchain-ai/langgraph"&gt;LangGraph&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;adk_live&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A real-time multimodal RAG agent powered by Gemini, supporting audio/video/text chat&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;More agents are on the way!&lt;/strong&gt; We are continuously expanding our &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/agents/overview"&gt;agent library&lt;/a&gt;. Have a specific agent type in mind? &lt;a href="https://github.com/GoogleCloudPlatform/agent-starter-pack/issues/new?labels=enhancement"&gt;Raise an issue as a feature request!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üîç ADK Samples&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Looking to explore more ADK examples? Check out the &lt;a href="https://github.com/google/adk-samples"&gt;ADK Samples Repository&lt;/a&gt; for additional examples and use cases demonstrating ADK's capabilities.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåü Community Showcase&lt;/h2&gt; 
&lt;p&gt;Explore amazing projects built with the Agent Starter Pack!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/community-showcase"&gt;View Community Showcase ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;agent-starter-pack&lt;/code&gt; offers key features to accelerate and simplify the development of your agent:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/cli/setup_cicd"&gt;CI/CD Automation&lt;/a&gt;&lt;/strong&gt; - A single command to set up a complete CI/CD pipeline for all environments, supporting both &lt;strong&gt;Google Cloud Build&lt;/strong&gt; and &lt;strong&gt;GitHub Actions&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üì• &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/data-ingestion"&gt;Data Pipeline for RAG with Terraform/CI-CD&lt;/a&gt;&lt;/strong&gt; - Seamlessly integrate a data pipeline to process embeddings for RAG into your agent system. Supporting &lt;a href="https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction"&gt;Vertex AI Search&lt;/a&gt; and &lt;a href="https://cloud.google.com/vertex-ai/docs/vector-search/overview"&gt;Vector Search&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/guide/remote-templating.md"&gt;Remote Templates&lt;/a&gt;&lt;/strong&gt;: Create and share your own agent starter packs templates from any Git repository.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Gemini CLI Integration&lt;/strong&gt; - Use the &lt;a href="https://github.com/google-gemini/gemini-cli"&gt;Gemini CLI&lt;/a&gt; and the included &lt;code&gt;GEMINI.md&lt;/code&gt; context file to ask questions about your template, agent architecture, and the path to production. Get instant guidance and code examples directly in your terminal.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;High-Level Architecture&lt;/h2&gt; 
&lt;p&gt;This starter pack covers all aspects of Agent development, from prototyping and evaluation to deployment and monitoring.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/images/ags_high_level_architecture.png" alt="High Level Architecture" title="Architecture" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîß Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10+&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/sdk/docs/install"&gt;Google Cloud SDK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.hashicorp.com/terraform/downloads"&gt;Terraform&lt;/a&gt; (for deployment)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.gnu.org/software/make/"&gt;Make&lt;/a&gt; (for development tasks)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/"&gt;documentation site&lt;/a&gt; for comprehensive guides and references!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/getting-started"&gt;Getting Started Guide&lt;/a&gt; - First steps with agent-starter-pack&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/installation"&gt;Installation Guide&lt;/a&gt; - Setting up your environment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/deployment"&gt;Deployment Guide&lt;/a&gt; - Taking your agent to production&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/agents/overview"&gt;Agent Templates Overview&lt;/a&gt; - Explore available agent patterns&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/cli/"&gt;CLI Reference&lt;/a&gt; - Command-line tool documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Video Walkthrough:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=9zqwym-N3lg"&gt;Exploring the Agent Starter Pack&lt;/a&gt;&lt;/strong&gt;: A comprehensive tutorial demonstrating how to rapidly deploy AI Agents using the Agent Starter Pack, covering architecture, templates, and step-by-step deployment.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/live/eZ-8UQ_t4YM?feature=shared&amp;amp;t=2791"&gt;6-minute introduction&lt;/a&gt;&lt;/strong&gt; (April 2024): Explaining the Agent Starter Pack and demonstrating its key features. Part of the Kaggle GenAI intensive course.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Looking for more examples and resources for Generative AI on Google Cloud? Check out the &lt;a href="https://github.com/GoogleCloudPlatform/generative-ai"&gt;GoogleCloudPlatform/generative-ai&lt;/a&gt; repository for notebooks, code samples, and more!&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! See the &lt;a href="https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;We value your input! Your feedback helps us improve this starter pack and make it more useful for the community.&lt;/p&gt; 
&lt;h3&gt;Getting Help&lt;/h3&gt; 
&lt;p&gt;If you encounter any issues or have specific suggestions, please first consider &lt;a href="https://github.com/GoogleCloudPlatform/generative-ai/issues"&gt;raising an issue&lt;/a&gt; on our GitHub repository.&lt;/p&gt; 
&lt;h3&gt;Share Your Experience&lt;/h3&gt; 
&lt;p&gt;For other types of feedback, or if you'd like to share a positive experience or success story using this starter pack, we'd love to hear from you! You can reach out to us at &lt;a href="mailto:agent-starter-pack@google.com"&gt;&lt;/a&gt;&lt;a href="mailto:agent-starter-pack@google.com"&gt;agent-starter-pack@google.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thank you for your contributions!&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This repository is for demonstrative purposes only and is not an officially supported Google product.&lt;/p&gt; 
&lt;h2&gt;Terms of Service&lt;/h2&gt; 
&lt;p&gt;The agent-starter-pack templating CLI and the templates in this starter pack leverage Google Cloud APIs. When you use this starter pack, you'll be deploying resources in your own Google Cloud project and will be responsible for those resources. Please review the &lt;a href="https://cloud.google.com/terms/service-terms"&gt;Google Cloud Service Terms&lt;/a&gt; for details on the terms of service associated with these APIs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>strands-agents/sdk-python</title>
      <link>https://github.com/strands-agents/sdk-python</link>
      <description>&lt;p&gt;A model-driven approach to building AI agents in just a few lines of code.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div&gt; 
  &lt;a href="https://strandsagents.com"&gt; &lt;img src="https://strandsagents.com/latest/assets/logo-github.svg?sanitize=true" alt="Strands Agents" width="55px" height="105px" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h1&gt; Strands Agents &lt;/h1&gt; 
 &lt;h2&gt; A model-driven approach to building AI agents in just a few lines of code. &lt;/h2&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/graphs/commit-activity"&gt;&lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/issues"&gt;&lt;img alt="GitHub open issues" src="https://img.shields.io/github/issues/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/pulls"&gt;&lt;img alt="GitHub open pull requests" src="https://img.shields.io/github/issues-pr/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/raw/main/LICENSE"&gt;&lt;img alt="License" src="https://img.shields.io/github/license/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://pypi.org/project/strands-agents/"&gt;&lt;img alt="PyPI version" src="https://img.shields.io/pypi/v/strands-agents" /&gt;&lt;/a&gt; 
  &lt;a href="https://python.org"&gt;&lt;img alt="Python versions" src="https://img.shields.io/pypi/pyversions/strands-agents" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;p&gt; &lt;a href="https://strandsagents.com/"&gt;Documentation&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/samples"&gt;Samples&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/sdk-python"&gt;Python SDK&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/tools"&gt;Tools&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/agent-builder"&gt;Agent Builder&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/mcp-server"&gt;MCP Server&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Strands Agents is a simple yet powerful SDK that takes a model-driven approach to building and running AI agents. From simple conversational assistants to complex autonomous workflows, from local development to production deployment, Strands Agents scales with your needs.&lt;/p&gt; 
&lt;h2&gt;Feature Overview&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight &amp;amp; Flexible&lt;/strong&gt;: Simple agent loop that just works and is fully customizable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Agnostic&lt;/strong&gt;: Support for Amazon Bedrock, Anthropic, Gemini, LiteLLM, Llama, Ollama, OpenAI, Writer, and custom providers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Capabilities&lt;/strong&gt;: Multi-agent systems, autonomous agents, and streaming support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in MCP&lt;/strong&gt;: Native support for Model Context Protocol (MCP) servers, enabling access to thousands of pre-built tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Strands Agents
pip install strands-agents strands-agents-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands_tools import calculator
agent = Agent(tools=[calculator])
agent("What is the square root of 1764")
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For the default Amazon Bedrock model provider, you'll need AWS credentials configured and model access enabled for Claude 4 Sonnet in the us-west-2 region. See the &lt;a href="https://strandsagents.com/"&gt;Quickstart Guide&lt;/a&gt; for details on configuring other model providers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Ensure you have Python 3.10+ installed, then:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows use: .venv\Scripts\activate

# Install Strands and tools
pip install strands-agents strands-agents-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features at a Glance&lt;/h2&gt; 
&lt;h3&gt;Python-Based Tools&lt;/h3&gt; 
&lt;p&gt;Easily build tools using Python decorators:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent, tool

@tool
def word_count(text: str) -&amp;gt; int:
    """Count words in text.

    This docstring is used by the LLM to understand the tool's purpose.
    """
    return len(text.split())

agent = Agent(tools=[word_count])
response = agent("How many words are in this sentence?")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Hot Reloading from Directory:&lt;/strong&gt; Enable automatic tool loading and reloading from the &lt;code&gt;./tools/&lt;/code&gt; directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent

# Agent will watch ./tools/ directory for changes
agent = Agent(load_tools_from_directory=True)
response = agent("Use any tools you find in the tools directory")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCP Support&lt;/h3&gt; 
&lt;p&gt;Seamlessly integrate Model Context Protocol (MCP) servers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands.tools.mcp import MCPClient
from mcp import stdio_client, StdioServerParameters

aws_docs_client = MCPClient(
    lambda: stdio_client(StdioServerParameters(command="uvx", args=["awslabs.aws-documentation-mcp-server@latest"]))
)

with aws_docs_client:
   agent = Agent(tools=aws_docs_client.list_tools_sync())
   response = agent("Tell me about Amazon Bedrock and how to use it with Python")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiple Model Providers&lt;/h3&gt; 
&lt;p&gt;Support for various model providers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands.models import BedrockModel
from strands.models.ollama import OllamaModel
from strands.models.llamaapi import LlamaAPIModel
from strands.models.gemini import GeminiModel
from strands.models.llamacpp import LlamaCppModel

# Bedrock
bedrock_model = BedrockModel(
  model_id="us.amazon.nova-pro-v1:0",
  temperature=0.3,
  streaming=True, # Enable/disable streaming
)
agent = Agent(model=bedrock_model)
agent("Tell me about Agentic AI")

# Google Gemini
gemini_model = GeminiModel(
  client_args={
    "api_key": "your_gemini_api_key",
  },
  model_id="gemini-2.5-flash",
  params={"temperature": 0.7}
)
agent = Agent(model=gemini_model)
agent("Tell me about Agentic AI")

# Ollama
ollama_model = OllamaModel(
  host="http://localhost:11434",
  model_id="llama3"
)
agent = Agent(model=ollama_model)
agent("Tell me about Agentic AI")

# Llama API
llama_model = LlamaAPIModel(
    model_id="Llama-4-Maverick-17B-128E-Instruct-FP8",
)
agent = Agent(model=llama_model)
response = agent("Tell me about Agentic AI")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Built-in providers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/amazon-bedrock/"&gt;Amazon Bedrock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/anthropic/"&gt;Anthropic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/gemini/"&gt;Gemini&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/cohere/"&gt;Cohere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/litellm/"&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/llamacpp/"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/llamaapi/"&gt;LlamaAPI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/mistral/"&gt;MistralAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/ollama/"&gt;Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/openai/"&gt;OpenAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/sagemaker/"&gt;SageMaker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/writer/"&gt;Writer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Custom providers can be implemented using &lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/custom_model_provider/"&gt;Custom Providers&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Example tools&lt;/h3&gt; 
&lt;p&gt;Strands offers an optional strands-agents-tools package with pre-built tools for quick experimentation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands_tools import calculator
agent = Agent(tools=[calculator])
agent("What is the square root of 1764")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It's also available on GitHub via &lt;a href="https://github.com/strands-agents/tools"&gt;strands-agents/tools&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Bidirectional Streaming&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Experimental Feature&lt;/strong&gt;: Bidirectional streaming is currently in experimental status. APIs may change in future releases as we refine the feature based on user feedback and evolving model capabilities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Build real-time voice and audio conversations with persistent streaming connections. Unlike traditional request-response patterns, bidirectional streaming maintains long-running conversations where users can interrupt, provide continuous input, and receive real-time audio responses. Get started with your first BidiAgent by following the &lt;a href="https://strandsagents.com/latest/documentation/docs/user-guide/concepts/experimental/bidirectional-streaming/quickstart"&gt;Quickstart&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Supported Model Providers:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Amazon Nova Sonic (&lt;code&gt;amazon.nova-sonic-v1:0&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Google Gemini Live (&lt;code&gt;gemini-2.5-flash-native-audio-preview-09-2025&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;OpenAI Realtime API (&lt;code&gt;gpt-realtime&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from strands.experimental.bidi import BidiAgent
from strands.experimental.bidi.models import BidiNovaSonicModel
from strands.experimental.bidi.io import BidiAudioIO, BidiTextIO
from strands.experimental.bidi.tools import stop_conversation
from strands_tools import calculator

async def main():
    # Create bidirectional agent with audio model
    model = BidiNovaSonicModel()
    agent = BidiAgent(model=model, tools=[calculator, stop_conversation])

    # Setup audio and text I/O
    audio_io = BidiAudioIO()
    text_io = BidiTextIO()

    # Run with real-time audio streaming
    # Say "stop conversation" to gracefully end the conversation
    await agent.run(
        inputs=[audio_io.input()],
        outputs=[audio_io.output(), text_io.output()]
    )

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Configuration Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Configure audio settings
model = BidiNovaSonicModel(
    provider_config={
        "audio": {
            "input_rate": 16000,
            "output_rate": 16000,
            "voice": "matthew"
        },
        "inference": {
            "max_tokens": 2048,
            "temperature": 0.7
        }
    }
)

# Configure I/O devices
audio_io = BidiAudioIO(
    input_device_index=0,  # Specific microphone
    output_device_index=1,  # Specific speaker
    input_buffer_size=10,
    output_buffer_size=10
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed guidance &amp;amp; examples, explore our documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/"&gt;User Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/quickstart/"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/agents/agent-loop/"&gt;Agent Loop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/examples/"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/api-reference/agent/"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/deploy/operating-agents-in-production/"&gt;Production &amp;amp; Deployment Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing ‚ù§Ô∏è&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! See our &lt;a href="https://raw.githubusercontent.com/strands-agents/sdk-python/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reporting bugs &amp;amp; features&lt;/li&gt; 
 &lt;li&gt;Development setup&lt;/li&gt; 
 &lt;li&gt;Contributing via Pull Requests&lt;/li&gt; 
 &lt;li&gt;Code of Conduct&lt;/li&gt; 
 &lt;li&gt;Reporting of security issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/strands-agents/sdk-python/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/strands-agents/sdk-python/main/CONTRIBUTING.md#security-issue-notifications"&gt;CONTRIBUTING&lt;/a&gt; for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>infiniflow/ragflow</title>
      <link>https://github.com/infiniflow/ragflow</link>
      <description>&lt;p&gt;RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://demo.ragflow.io/"&gt; &lt;img src="https://raw.githubusercontent.com/infiniflow/ragflow/main/web/src/assets/logo-with-text.svg?sanitize=true" width="520" alt="ragflow logo" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README.md"&gt;&lt;img alt="README in English" src="https://img.shields.io/badge/English-DBEDFA" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_zh.md"&gt;&lt;img alt="ÁÆÄ‰Ωì‰∏≠ÊñáÁâàËá™Ëø∞Êñá‰ª∂" src="https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_tzh.md"&gt;&lt;img alt="ÁπÅÈ´îÁâà‰∏≠ÊñáËá™Ëø∞Êñá‰ª∂" src="https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_ja.md"&gt;&lt;img alt="Êó•Êú¨Ë™û„ÅÆREADME" src="https://img.shields.io/badge/Êó•Êú¨Ë™û-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_ko.md"&gt;&lt;img alt="ÌïúÍµ≠Ïñ¥" src="https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_id.md"&gt;&lt;img alt="Bahasa Indonesia" src="https://img.shields.io/badge/Bahasa Indonesia-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_pt_br.md"&gt;&lt;img alt="Portugu√™s(Brasil)" src="https://img.shields.io/badge/Portugu√™s(Brasil)-DFE0E5" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://x.com/intent/follow?screen_name=infiniflowai" target="_blank"&gt; &lt;img src="https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;amp;color=%20%23f5f5f5" alt="follow on X(Twitter)" /&gt; &lt;/a&gt; &lt;a href="https://demo.ragflow.io" target="_blank"&gt; &lt;img alt="Static Badge" src="https://img.shields.io/badge/Online-Demo-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/infiniflow/ragflow" target="_blank"&gt; &lt;img src="https://img.shields.io/docker/pulls/infiniflow/ragflow?label=Docker%20Pulls&amp;amp;color=0db7ed&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="docker pull infiniflow/ragflow:v0.22.1" /&gt; &lt;/a&gt; &lt;a href="https://github.com/infiniflow/ragflow/releases/latest"&gt; &lt;img src="https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;amp;label=Latest%20Release" alt="Latest Release" /&gt; &lt;/a&gt; &lt;a href="https://github.com/infiniflow/ragflow/raw/main/LICENSE"&gt; &lt;img height="21" src="https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="license" /&gt; &lt;/a&gt; &lt;a href="https://deepwiki.com/infiniflow/ragflow"&gt; &lt;img alt="Ask DeepWiki" src="https://deepwiki.com/badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://ragflow.io/docs/dev/"&gt;Document&lt;/a&gt; | &lt;a href="https://github.com/infiniflow/ragflow/issues/4214"&gt;Roadmap&lt;/a&gt; | &lt;a href="https://twitter.com/infiniflowai"&gt;Twitter&lt;/a&gt; | &lt;a href="https://discord.gg/NjYzJD3GM3"&gt;Discord&lt;/a&gt; | &lt;a href="https://demo.ragflow.io"&gt;Demo&lt;/a&gt; &lt;/h4&gt; 
&lt;div align="center" style="margin-top:20px;margin-bottom:20px;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/ragflow-octoverse.png" width="1200" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/9064" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/9064" alt="infiniflow%2Fragflow | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;üìï Table of Contents&lt;/b&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üí° &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-what-is-ragflow"&gt;What is RAGFlow?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üéÆ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-demo"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üìå &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-latest-updates"&gt;Latest Updates&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üåü &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üîé &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-system-architecture"&gt;System Architecture&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üé¨ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-get-started"&gt;Get Started&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üîß &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-configurations"&gt;Configurations&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üîß &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-build-a-docker-image"&gt;Build a Docker image&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üî® &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-launch-service-from-source-for-development"&gt;Launch service from source for development&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üìö &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üìú &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-roadmap"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üèÑ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üôå &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üí° What is RAGFlow?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://ragflow.io/"&gt;RAGFlow&lt;/a&gt; is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs. It offers a streamlined RAG workflow adaptable to enterprises of any scale. Powered by a converged context engine and pre-built agent templates, RAGFlow enables developers to transform complex data into high-fidelity, production-ready AI systems with exceptional efficiency and precision.&lt;/p&gt; 
&lt;h2&gt;üéÆ Demo&lt;/h2&gt; 
&lt;p&gt;Try our demo at &lt;a href="https://demo.ragflow.io"&gt;https://demo.ragflow.io&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center" style="margin-top:20px;margin-bottom:20px;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/chunking.gif" width="1200" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/agentic-dark.gif" width="1200" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;üî• Latest Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025-11-19 Supports Gemini 3 Pro.&lt;/li&gt; 
 &lt;li&gt;2025-11-12 Supports data synchronization from Confluence, S3, Notion, Discord, Google Drive.&lt;/li&gt; 
 &lt;li&gt;2025-10-23 Supports MinerU &amp;amp; Docling as document parsing methods.&lt;/li&gt; 
 &lt;li&gt;2025-10-15 Supports orchestrable ingestion pipeline.&lt;/li&gt; 
 &lt;li&gt;2025-08-08 Supports OpenAI's latest GPT-5 series models.&lt;/li&gt; 
 &lt;li&gt;2025-08-01 Supports agentic workflow and MCP.&lt;/li&gt; 
 &lt;li&gt;2025-05-23 Adds a Python/JavaScript code executor component to Agent.&lt;/li&gt; 
 &lt;li&gt;2025-05-05 Supports cross-language query.&lt;/li&gt; 
 &lt;li&gt;2025-03-19 Supports using a multi-modal model to make sense of images within PDF or DOCX files.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéâ Stay Tuned&lt;/h2&gt; 
&lt;p&gt;‚≠êÔ∏è Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new releases! üåü&lt;/p&gt; 
&lt;div align="center" style="margin-top:20px;margin-bottom:20px;"&gt; 
 &lt;img src="https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba" width="1200" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü Key Features&lt;/h2&gt; 
&lt;h3&gt;üç≠ &lt;strong&gt;"Quality in, quality out"&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/deepdoc/README.md"&gt;Deep document understanding&lt;/a&gt;-based knowledge extraction from unstructured data with complicated formats.&lt;/li&gt; 
 &lt;li&gt;Finds "needle in a data haystack" of literally unlimited tokens.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üç± &lt;strong&gt;Template-based chunking&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Intelligent and explainable.&lt;/li&gt; 
 &lt;li&gt;Plenty of template options to choose from.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üå± &lt;strong&gt;Grounded citations with reduced hallucinations&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visualization of text chunking to allow human intervention.&lt;/li&gt; 
 &lt;li&gt;Quick view of the key references and traceable citations to support grounded answers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üçî &lt;strong&gt;Compatibility with heterogeneous data sources&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üõÄ &lt;strong&gt;Automated and effortless RAG workflow&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamlined RAG orchestration catered to both personal and large businesses.&lt;/li&gt; 
 &lt;li&gt;Configurable LLMs as well as embedding models.&lt;/li&gt; 
 &lt;li&gt;Multiple recall paired with fused re-ranking.&lt;/li&gt; 
 &lt;li&gt;Intuitive APIs for seamless integration with business.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîé System Architecture&lt;/h2&gt; 
&lt;div align="center" style="margin-top:20px;margin-bottom:20px;"&gt; 
 &lt;img src="https://github.com/user-attachments/assets/31b0dd6f-ca4f-445a-9457-70cb44a381b2" width="1000" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;üé¨ Get Started&lt;/h2&gt; 
&lt;h3&gt;üìù Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU &amp;gt;= 4 cores&lt;/li&gt; 
 &lt;li&gt;RAM &amp;gt;= 16 GB&lt;/li&gt; 
 &lt;li&gt;Disk &amp;gt;= 50 GB&lt;/li&gt; 
 &lt;li&gt;Docker &amp;gt;= 24.0.0 &amp;amp; Docker Compose &amp;gt;= v2.26.1&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gvisor.dev/docs/user_guide/install/"&gt;gVisor&lt;/a&gt;: Required only if you intend to use the code executor (sandbox) feature of RAGFlow.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you have not installed Docker on your local machine (Windows, Mac, or Linux), see &lt;a href="https://docs.docker.com/engine/install/"&gt;Install Docker Engine&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üöÄ Start up the server&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Ensure &lt;code&gt;vm.max_map_count&lt;/code&gt; &amp;gt;= 262144:&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;To check the value of &lt;code&gt;vm.max_map_count&lt;/code&gt;:&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;$ sysctl vm.max_map_count
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;Reset &lt;code&gt;vm.max_map_count&lt;/code&gt; to a value at least 262144 if it is not.&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;# In this case, we set it to 262144:
$ sudo sysctl -w vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;This change will be reset after a system reboot. To ensure your change remains permanent, add or update the &lt;code&gt;vm.max_map_count&lt;/code&gt; value in &lt;strong&gt;/etc/sysctl.conf&lt;/strong&gt; accordingly:&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repo:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;$ git clone https://github.com/infiniflow/ragflow.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start up the server using the pre-built Docker images:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] All Docker images are built for x86 platforms. We don't currently offer Docker images for ARM64. If you are on an ARM64 platform, follow &lt;a href="https://ragflow.io/docs/dev/build_docker_image"&gt;this guide&lt;/a&gt; to build a Docker image compatible with your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The command below downloads the &lt;code&gt;v0.22.1&lt;/code&gt; edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from &lt;code&gt;v0.22.1&lt;/code&gt;, update the &lt;code&gt;RAGFLOW_IMAGE&lt;/code&gt; variable accordingly in &lt;strong&gt;docker/.env&lt;/strong&gt; before using &lt;code&gt;docker compose&lt;/code&gt; to start the server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;   $ cd ragflow/docker
  
   # git checkout v0.22.1
   # Optional: use a stable tag (see releases: https://github.com/infiniflow/ragflow/releases)
   # This step ensures the **entrypoint.sh** file in the code matches the Docker image version.
   
   # Use CPU for DeepDoc tasks:
   $ docker compose -f docker-compose.yml up -d

   # To use GPU to accelerate DeepDoc tasks:
   # sed -i '1i DEVICE=gpu' .env
   # docker compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Prior to &lt;code&gt;v0.22.0&lt;/code&gt;, we provided both images with embedding models and slim images without embedding models. Details as follows:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;RAGFlow image tag&lt;/th&gt; 
   &lt;th&gt;Image size (GB)&lt;/th&gt; 
   &lt;th&gt;Has embedding models?&lt;/th&gt; 
   &lt;th&gt;Stable?&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;v0.21.1&lt;/td&gt; 
   &lt;td&gt;‚âà9&lt;/td&gt; 
   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; 
   &lt;td&gt;Stable release&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;v0.21.1-slim&lt;/td&gt; 
   &lt;td&gt;‚âà2&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;Stable release&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Starting with &lt;code&gt;v0.22.0&lt;/code&gt;, we ship only the slim edition and no longer append the &lt;strong&gt;-slim&lt;/strong&gt; suffix to the image tag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt; &lt;p&gt;Check the server status after having the server up and running:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;$ docker logs -f docker-ragflow-cpu-1
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;The following output confirms a successful launch of the system:&lt;/em&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;
      ____   ___    ______ ______ __
     / __ \ /   |  / ____// ____// /____  _      __
    / /_/ // /| | / / __ / /_   / // __ \| | /| / /
   / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
  /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

 * Running on all addresses (0.0.0.0)
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a &lt;code&gt;network anormal&lt;/code&gt; error because, at that moment, your RAGFlow may not be fully initialized.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In your web browser, enter the IP address of your server and log in to RAGFlow.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;With the default settings, you only need to enter &lt;code&gt;http://IP_OF_YOUR_MACHINE&lt;/code&gt; (&lt;strong&gt;sans&lt;/strong&gt; port number) as the default HTTP serving port &lt;code&gt;80&lt;/code&gt; can be omitted when using the default configurations.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/service_conf.yaml.template"&gt;service_conf.yaml.template&lt;/a&gt;, select the desired LLM factory in &lt;code&gt;user_default_llm&lt;/code&gt; and update the &lt;code&gt;API_KEY&lt;/code&gt; field with the corresponding API key.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;See &lt;a href="https://ragflow.io/docs/dev/llm_api_key_setup"&gt;llm_api_key_setup&lt;/a&gt; for more information.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;p&gt;&lt;em&gt;The show is on!&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üîß Configurations&lt;/h2&gt; 
&lt;p&gt;When it comes to system configurations, you will need to manage the following files:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/.env"&gt;.env&lt;/a&gt;: Keeps the fundamental setups for the system, such as &lt;code&gt;SVR_HTTP_PORT&lt;/code&gt;, &lt;code&gt;MYSQL_PASSWORD&lt;/code&gt;, and &lt;code&gt;MINIO_PASSWORD&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/service_conf.yaml.template"&gt;service_conf.yaml.template&lt;/a&gt;: Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;: The system relies on &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt; to start up.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/README.md"&gt;./docker/README&lt;/a&gt; file provides a detailed description of the environment settings and service configurations which can be used as &lt;code&gt;${ENV_VARS}&lt;/code&gt; in the &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/service_conf.yaml.template"&gt;service_conf.yaml.template&lt;/a&gt; file.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To update the default HTTP serving port (80), go to &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt; and change &lt;code&gt;80:80&lt;/code&gt; to &lt;code&gt;&amp;lt;YOUR_SERVING_PORT&amp;gt;:80&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Updates to the above configurations require a reboot of all containers to take effect:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;$ docker compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Switch doc engine from Elasticsearch to Infinity&lt;/h3&gt; 
&lt;p&gt;RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to &lt;a href="https://github.com/infiniflow/infinity/"&gt;Infinity&lt;/a&gt;, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Stop all running containers:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;$ docker compose -f docker/docker-compose.yml down -v
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;code&gt;-v&lt;/code&gt; will delete the docker container volumes, and the existing data will be cleared.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;Set &lt;code&gt;DOC_ENGINE&lt;/code&gt; in &lt;strong&gt;docker/.env&lt;/strong&gt; to &lt;code&gt;infinity&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start the containers:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;$ docker compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Switching to Infinity on a Linux/arm64 machine is not yet officially supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üîß Build a Docker image&lt;/h2&gt; 
&lt;p&gt;This image is approximately 2 GB in size and relies on external LLM and embedding services.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 -f Dockerfile -t infiniflow/ragflow:nightly .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üî® Launch service from source for development&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;code&gt;uv&lt;/code&gt; and &lt;code&gt;pre-commit&lt;/code&gt;, or skip this step if they are already installed:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pipx install uv pre-commit
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the source code and install Python dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
uv sync --python 3.12 # install RAGFlow dependent python modules
uv run download_deps.py
pre-commit install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker/docker-compose-base.yml up -d
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add the following line to &lt;code&gt;/etc/hosts&lt;/code&gt; to resolve all hosts specified in &lt;strong&gt;docker/.env&lt;/strong&gt; to &lt;code&gt;127.0.0.1&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;127.0.0.1       es01 infinity mysql minio redis sandbox-executor-manager
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you cannot access HuggingFace, set the &lt;code&gt;HF_ENDPOINT&lt;/code&gt; environment variable to use a mirror site:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export HF_ENDPOINT=https://hf-mirror.com
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If your operating system does not have jemalloc, please install it as follows:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu
sudo apt-get install libjemalloc-dev
# CentOS
sudo yum install jemalloc
# OpenSUSE
sudo zypper install jemalloc
# macOS
sudo brew install jemalloc
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch backend service:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;source .venv/bin/activate
export PYTHONPATH=$(pwd)
bash docker/launch_backend_service.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install frontend dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd web
npm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch frontend service:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm run dev
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;The following output confirms a successful launch of the system:&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187" alt="" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Stop RAGFlow front-end and back-end service after development is complete:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pkill -f "ragflow_server.py|task_executor.py"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/configurations"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/release_notes"&gt;Release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/category/guides"&gt;User guides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/category/developers"&gt;Developer guides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/category/references"&gt;References&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/faq"&gt;FAQs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìú Roadmap&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/infiniflow/ragflow/issues/4214"&gt;RAGFlow Roadmap 2025&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üèÑ Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/NjYzJD3GM3"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/infiniflowai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/infiniflow/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôå Contributing&lt;/h2&gt; 
&lt;p&gt;RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community. If you would like to be a part, review our &lt;a href="https://ragflow.io/docs/dev/contributing"&gt;Contribution Guidelines&lt;/a&gt; first.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>polarsource/polar</title>
      <link>https://github.com/polarsource/polar</link>
      <description>&lt;p&gt;Turn your software into a business.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://polar.sh"&gt; &lt;img src="https://github.com/user-attachments/assets/89a588e5-0c58-429a-8bbe-20f70af41372" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.producthunt.com/posts/polar-5?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-polar-5" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=484271&amp;amp;theme=dark&amp;amp;period=daily" alt="Polar - An open source monetization platform for developers | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;a href="https://www.producthunt.com/posts/polar-5?embed=true&amp;amp;utm_source=badge-top-post-topic-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-polar-5" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=484271&amp;amp;theme=dark&amp;amp;period=monthly&amp;amp;topic_id=267" alt="Polar - An open source monetization platform for developers | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://polar.sh"&gt;Website&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://polar.sh/blog"&gt;Blog&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://polar.sh/docs"&gt;Docs&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://polar.sh/docs/api-reference"&gt;API Reference&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://discord.gg/Pnhfz3UThd"&gt; &lt;img src="https://img.shields.io/badge/chat-on%20discord-7289DA.svg?sanitize=true" alt="Discord Chat" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=polar_sh"&gt; &lt;img src="https://img.shields.io/twitter/follow/polar_sh.svg?label=Follow%20@polar_sh" alt="Follow @polar_sh" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Polar: Open Source payments infrastructure for the 21st century&lt;/h2&gt; 
&lt;p&gt;Focus on building your passion, while we focus on the infrastructure to get you paid.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sell SaaS and digital products in minutes&lt;/li&gt; 
 &lt;li&gt;All-in-one funding &amp;amp; monetization platform for developers.&lt;/li&gt; 
 &lt;li&gt;Sell access to GitHub repositories, Discord Support channels, File Downloads, License Keys &amp;amp; much more with Digital Products &amp;amp; Subscriptions.&lt;/li&gt; 
 &lt;li&gt;We're the merchant of record handling the... 
  &lt;ul&gt; 
   &lt;li&gt;...boilerplate (billing, receipts, customer accounts etc)&lt;/li&gt; 
   &lt;li&gt;...headaches (sales tax, VAT)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Pricing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;4% + 40¬¢&lt;/li&gt; 
 &lt;li&gt;No fixed monthly costs&lt;/li&gt; 
 &lt;li&gt;Additional fees may apply. &lt;a href="https://polar.sh/docs/documentation/polar-as-merchant-of-record/fees"&gt;Read more&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap, Issues &amp;amp; Feature Requests&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;üéØ Upcoming milestones.&lt;/strong&gt; &lt;a href="https://github.com/polarsource/polar/issues/3242"&gt;Check out what we're building towards&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üí¨ Shape the future of Polar with us.&lt;/strong&gt; &lt;a href="https://discord.gg/Pnhfz3UThd"&gt;Join our Discord&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üêõ Found a bug?&lt;/strong&gt; &lt;a href="https://github.com/polarsource/polar/issues"&gt;Submit it here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üîì Found a security vulnerability?&lt;/strong&gt; We greatly appreciate responsible and private disclosures. See &lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/SECURITY.md"&gt;Security&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Polar API &amp;amp; SDK&lt;/h3&gt; 
&lt;p&gt;You can integrate Polar on your docs, sites or services using our &lt;a href="https://polar.sh/docs/api-reference"&gt;Public API&lt;/a&gt; and &lt;a href="https://polar.sh/docs/integrate/webhooks/endpoints"&gt;Webhook API&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We also maintain SDKs for the following languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JavaScript (Node.js and browsers): &lt;a href="https://github.com/polarsource/polar-js"&gt;polarsource/polar-js&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Python: &lt;a href="https://github.com/polarsource/polar-python"&gt;polarsource/polar-python&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Our &lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/DEVELOPMENT.md"&gt;&lt;code&gt;DEVELOPMENT.md&lt;/code&gt;&lt;/a&gt; file contains everything you need to know to configure your development environment.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Want to get started quickly? Use GitHub Codespaces.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://codespaces.new/polarsource/polar?machine=standardLinux32gb"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="Open in GitHub Codespaces" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;a href="https://github.com/polarsource/polar/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=polarsource/polar" /&gt; &lt;/a&gt; 
&lt;h2&gt;Monorepo&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/server/README.md"&gt;server&lt;/a&gt;&lt;/strong&gt; ‚Äì Python / FastAPI / Dramatiq / SQLAlchemy (PostgreSQL) / Redis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/clients/README.md"&gt;clients&lt;/a&gt;&lt;/strong&gt; ‚Äì Turborepo 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/clients/apps/web"&gt;web&lt;/a&gt; (Dashboard) ‚Äì NextJS (TypeScript)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/polarsource/polar/main/clients/packages/polarkit"&gt;polarkit&lt;/a&gt; - Shared React components&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;sub&gt;‚ô•Ô∏èüôè To our &lt;code&gt;pyproject.toml&lt;/code&gt; friends: &lt;a href="https://github.com/tiangolo/fastapi"&gt;FastAPI&lt;/a&gt;, &lt;a href="https://github.com/pydantic/pydantic"&gt;Pydantic&lt;/a&gt;, &lt;a href="https://github.com/Bogdanp/dramatiq"&gt;Dramatiq&lt;/a&gt;, &lt;a href="https://github.com/sqlalchemy/sqlalchemy"&gt;SQLAlchemy&lt;/a&gt;, &lt;a href="https://github.com/yanyongyu/githubkit"&gt;Githubkit&lt;/a&gt;, &lt;a href="https://github.com/sysid/sse-starlette"&gt;sse-starlette&lt;/a&gt;, &lt;a href="https://github.com/encode/uvicorn"&gt;Uvicorn&lt;/a&gt;, &lt;a href="https://github.com/frankie567/httpx-oauth"&gt;httpx-oauth&lt;/a&gt;, &lt;a href="https://github.com/pallets/jinja"&gt;jinja&lt;/a&gt;, &lt;a href="https://github.com/pallets-eco/blinker"&gt;blinker&lt;/a&gt;, &lt;a href="https://github.com/jpadilla/pyjwt"&gt;pyjwt&lt;/a&gt;, &lt;a href="https://github.com/getsentry/sentry"&gt;Sentry&lt;/a&gt; + more&lt;/sub&gt;&lt;br /&gt; &lt;sub&gt;‚ô•Ô∏èüôè To our &lt;code&gt;package.json&lt;/code&gt; friends: &lt;a href="https://github.com/vercel/next.js/"&gt;Next.js&lt;/a&gt;, &lt;a href="https://github.com/TanStack/query"&gt;TanStack Query&lt;/a&gt;, &lt;a href="https://github.com/tailwindlabs/tailwindcss"&gt;tailwindcss&lt;/a&gt;, &lt;a href="https://github.com/ferdikoomen/openapi-typescript-codegen"&gt;openapi-typescript-codegen&lt;/a&gt;, &lt;a href="https://github.com/axios/axios"&gt;axios&lt;/a&gt;, &lt;a href="https://github.com/radix-ui/primitives"&gt;radix-ui&lt;/a&gt;, &lt;a href="https://github.com/pacocoursey/cmdk"&gt;cmdk&lt;/a&gt;, &lt;a href="https://github.com/framer/motion"&gt;framer-motion&lt;/a&gt; + more&lt;/sub&gt;&lt;br /&gt; &lt;sub&gt;‚ô•Ô∏èüôè To &lt;a href="https://ipinfo.io"&gt;IPinfo&lt;/a&gt; that provides IP address data to help us geolocate customers during checkout.&lt;/sub&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;Apache License, Version 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>datawhalechina/hello-agents</title>
      <link>https://github.com/datawhalechina/hello-agents</link>
      <description>&lt;p&gt;üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã&lt;/p&gt;&lt;hr&gt;&lt;div align="right"&gt; 
 &lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/README_EN.md"&gt;English&lt;/a&gt; | ‰∏≠Êñá 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/hello-agents.png" alt="alt text" width="100%" /&gt; 
 &lt;h1&gt;Hello-Agents&lt;/h1&gt; 
 &lt;h3&gt;ü§ñ „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã&lt;/h3&gt; 
 &lt;p&gt;&lt;em&gt;‰ªéÂü∫Á°ÄÁêÜËÆ∫Âà∞ÂÆûÈôÖÂ∫îÁî®ÔºåÂÖ®Èù¢ÊéåÊè°Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂÆûÁé∞&lt;/em&gt;&lt;/p&gt; 
 &lt;img src="https://img.shields.io/github/stars/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub stars" /&gt; 
 &lt;img src="https://img.shields.io/github/forks/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub forks" /&gt; 
 &lt;img src="https://img.shields.io/badge/language-Chinese-brightgreen?style=flat" alt="Language" /&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents"&gt;&lt;img src="https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;amp;logo=github" alt="GitHub Project" /&gt;&lt;/a&gt; 
 &lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;&lt;img src="https://img.shields.io/badge/Âú®Á∫øÈòÖËØª-Online%20Reading-green?style=flat&amp;amp;logo=gitbook" alt="Online Reading" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ È°πÁõÆ‰ªãÁªç&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÂ¶ÇÊûúËØ¥ 2024 Âπ¥ÊòØ"ÁôæÊ®°Â§ßÊàò"ÁöÑÂÖÉÂπ¥ÔºåÈÇ£‰πà 2025 Âπ¥Êó†ÁñëÂºÄÂêØ‰∫Ü"Agent ÂÖÉÂπ¥"„ÄÇÊäÄÊúØÁöÑÁÑ¶ÁÇπÊ≠£‰ªéËÆ≠ÁªÉÊõ¥Â§ßÁöÑÂü∫Á°ÄÊ®°ÂûãÔºåËΩ¨ÂêëÊûÑÂª∫Êõ¥ËÅ™ÊòéÁöÑÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁ≥ªÁªüÊÄß„ÄÅÈáçÂÆûË∑µÁöÑÊïôÁ®ãÂç¥ÊûÅÂ∫¶ÂåÆ‰πè„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂèëËµ∑‰∫Ü Hello-Agents È°πÁõÆÔºåÂ∏åÊúõËÉΩ‰∏∫Á§æÂå∫Êèê‰æõ‰∏ÄÊú¨‰ªéÈõ∂ÂºÄÂßã„ÄÅÁêÜËÆ∫‰∏éÂÆûÊàòÂπ∂ÈáçÁöÑÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÊûÑÂª∫ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉHello-Agents ÊòØ Datawhale Á§æÂå∫ÁöÑ&lt;strong&gt;Á≥ªÁªüÊÄßÊô∫ËÉΩ‰ΩìÂ≠¶‰π†ÊïôÁ®ã&lt;/strong&gt;„ÄÇÂ¶Ç‰ªä Agent ÊûÑÂª∫‰∏ªË¶ÅÂàÜ‰∏∫‰∏§Ê¥æÔºå‰∏ÄÊ¥æÊòØ DifyÔºåCozeÔºån8n ËøôÁ±ªËΩØ‰ª∂Â∑•Á®ãÁ±ª AgentÔºåÂÖ∂Êú¨Ë¥®ÊòØÊµÅÁ®ãÈ©±Âä®ÁöÑËΩØ‰ª∂ÂºÄÂèëÔºåLLM ‰Ωú‰∏∫Êï∞ÊçÆÂ§ÑÁêÜÁöÑÂêéÁ´ØÔºõÂè¶‰∏ÄÊ¥æÂàôÊòØ AI ÂéüÁîüÁöÑ AgentÔºåÂç≥ÁúüÊ≠£‰ª• AI È©±Âä®ÁöÑ Agent„ÄÇÊú¨ÊïôÁ®ãÊó®Âú®Â∏¶È¢ÜÂ§ßÂÆ∂Ê∑±ÂÖ•ÁêÜËß£Âπ∂ÊûÑÂª∫ÂêéËÄÖ‚Äî‚ÄîÁúüÊ≠£ÁöÑ AI Native Agent„ÄÇÊïôÁ®ãÂ∞ÜÂ∏¶È¢Ü‰Ω†Á©øÈÄèÊ°ÜÊû∂Ë°®Ë±°Ôºå‰ªéÊô∫ËÉΩ‰ΩìÁöÑÊ†∏ÂøÉÂéüÁêÜÂá∫ÂèëÔºåÊ∑±ÂÖ•ÂÖ∂Ê†∏ÂøÉÊû∂ÊûÑÔºåÁêÜËß£ÂÖ∂ÁªèÂÖ∏ËåÉÂºèÔºåÂπ∂ÊúÄÁªà‰∫≤ÊâãÊûÑÂª∫Ëµ∑Â±û‰∫éËá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÊàë‰ª¨Áõ∏‰ø°ÔºåÊúÄÂ•ΩÁöÑÂ≠¶‰π†ÊñπÂºèÂ∞±ÊòØÂä®ÊâãÂÆûË∑µ„ÄÇÂ∏åÊúõËøôÊú¨ÊïôÁ®ãËÉΩÊàê‰∏∫‰Ω†Êé¢Á¥¢Êô∫ËÉΩ‰Ωì‰∏ñÁïåÁöÑËµ∑ÁÇπÔºåËÉΩÂ§ü‰ªé‰∏ÄÂêçÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ"‰ΩøÁî®ËÄÖ"ÔºåËúïÂèò‰∏∫‰∏ÄÂêçÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑ"ÊûÑÂª∫ËÄÖ"„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üìö Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;h3&gt;Âú®Á∫øÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;üåê ÁÇπÂáªËøôÈáåÂºÄÂßãÂú®Á∫øÈòÖËØª&lt;/a&gt;&lt;/strong&gt; - Êó†ÈúÄ‰∏ãËΩΩÔºåÈöèÊó∂ÈöèÂú∞Â≠¶‰π†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://book.heterocat.com.cn/"&gt;üìñ Cookbook(ÊµãËØïÁâà)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Êú¨Âú∞ÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®Êú¨Âú∞ÈòÖËØªÊàñË¥°ÁåÆÂÜÖÂÆπÔºåËØ∑ÂèÇËÄÉ‰∏ãÊñπÁöÑÂ≠¶‰π†ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;h3&gt;‚ú® ‰Ω†Â∞ÜÊî∂Ëé∑‰ªÄ‰πàÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Datawhale ÂºÄÊ∫êÂÖçË¥π&lt;/strong&gt; ÂÆåÂÖ®ÂÖçË¥πÂ≠¶‰π†Êú¨È°πÁõÆÊâÄÊúâÂÜÖÂÆπÔºå‰∏éÁ§æÂå∫ÂÖ±ÂêåÊàêÈïø&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;ÁêÜËß£Ê†∏ÂøÉÂéüÁêÜ&lt;/strong&gt; Ê∑±ÂÖ•ÁêÜËß£Êô∫ËÉΩ‰ΩìÁöÑÊ¶ÇÂøµ„ÄÅÂéÜÂè≤‰∏éÁªèÂÖ∏ËåÉÂºè&lt;/li&gt; 
 &lt;li&gt;üèóÔ∏è &lt;strong&gt;‰∫≤ÊâãÂÆûÁé∞&lt;/strong&gt; ÊéåÊè°ÁÉ≠Èó®‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÂíåÊô∫ËÉΩ‰Ωì‰ª£Á†ÅÊ°ÜÊû∂ÁöÑ‰ΩøÁî®&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;strong&gt;Ëá™Á†îÊ°ÜÊû∂&lt;a href="https://github.com/jjyaoao/helloagents"&gt;HelloAgents&lt;/a&gt;&lt;/strong&gt; Âü∫‰∫é Openai ÂéüÁîü API ‰ªéÈõ∂ÊûÑÂª∫‰∏Ä‰∏™Ëá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;ÊéåÊè°È´òÁ∫ßÊäÄËÉΩ&lt;/strong&gt; ‰∏ÄÊ≠•Ê≠•ÂÆûÁé∞‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅMemory„ÄÅÂçèËÆÆ„ÄÅËØÑ‰º∞Á≠âÁ≥ªÁªüÊÄßÊäÄÊúØ&lt;/li&gt; 
 &lt;li&gt;ü§ù &lt;strong&gt;Ê®°ÂûãËÆ≠ÁªÉ&lt;/strong&gt; ÊéåÊè° Agentic RLÔºå‰ªé SFT Âà∞ GRPO ÁöÑÂÖ®ÊµÅÁ®ãÂÆûÊàòËÆ≠ÁªÉ LLM&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;È©±Âä®ÁúüÂÆûÊ°à‰æã&lt;/strong&gt; ÂÆûÊàòÂºÄÂèëÊô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËµõÂçöÂ∞èÈïáÁ≠âÁªºÂêàÈ°πÁõÆ&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Ê±ÇËÅåÈù¢ËØï&lt;/strong&gt; Â≠¶‰π†Êô∫ËÉΩ‰ΩìÊ±ÇËÅåÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ ÂÜÖÂÆπÂØºËà™&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á´†ËäÇ&lt;/th&gt; 
   &lt;th&gt;ÂÖ≥ÈîÆÂÜÖÂÆπ&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/%E5%89%8D%E8%A8%80.md"&gt;ÂâçË®Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;È°πÁõÆÁöÑÁºòËµ∑„ÄÅËÉåÊôØÂèäËØªËÄÖÂª∫ËÆÆ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%88%9D%E8%AF%86%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨‰∏ÄÁ´† ÂàùËØÜÊô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Êô∫ËÉΩ‰ΩìÂÆö‰πâ„ÄÅÁ±ªÂûã„ÄÅËåÉÂºè‰∏éÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter2/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E5%8F%91%E5%B1%95%E5%8F%B2.md"&gt;Á¨¨‰∫åÁ´† Êô∫ËÉΩ‰ΩìÂèëÂ±ïÂè≤&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªéÁ¨¶Âè∑‰∏ª‰πâÂà∞ LLM È©±Âä®ÁöÑÊô∫ËÉΩ‰ΩìÊºîËøõ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter3/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md"&gt;Á¨¨‰∏âÁ´† Â§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Transformer„ÄÅÊèêÁ§∫„ÄÅ‰∏ªÊµÅ LLM ÂèäÂÖ∂Â±ÄÈôê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA.md"&gt;Á¨¨ÂõõÁ´† Êô∫ËÉΩ‰ΩìÁªèÂÖ∏ËåÉÂºèÊûÑÂª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊâãÊääÊâãÂÆûÁé∞ ReAct„ÄÅPlan-and-Solve„ÄÅReflection&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter5/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%9F%BA%E4%BA%8E%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E6%90%AD%E5%BB%BA.md"&gt;Á¨¨‰∫îÁ´† Âü∫‰∫é‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÊê≠Âª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∫ÜËß£ Coze„ÄÅDify„ÄÅn8n Á≠â‰Ωé‰ª£Á†ÅÊô∫ËÉΩ‰ΩìÂπ≥Âè∞‰ΩøÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5.md"&gt;Á¨¨ÂÖ≠Á´† Ê°ÜÊû∂ÂºÄÂèëÂÆûË∑µ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AutoGen„ÄÅAgentScope„ÄÅLangGraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂Â∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter7/%E7%AC%AC%E4%B8%83%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84Agent%E6%A1%86%E6%9E%B6.md"&gt;Á¨¨‰∏ÉÁ´† ÊûÑÂª∫‰Ω†ÁöÑAgentÊ°ÜÊû∂&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé 0 ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter8/%E7%AC%AC%E5%85%AB%E7%AB%A0%20%E8%AE%B0%E5%BF%86%E4%B8%8E%E6%A3%80%E7%B4%A2.md"&gt;Á¨¨ÂÖ´Á´† ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ËÆ∞ÂøÜÁ≥ªÁªüÔºåRAGÔºåÂ≠òÂÇ®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter9/%E7%AC%AC%E4%B9%9D%E7%AB%A0%20%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B.md"&gt;Á¨¨‰πùÁ´† ‰∏ä‰∏ãÊñáÂ∑•Á®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊåÅÁª≠‰∫§‰∫íÁöÑ"ÊÉÖÂ¢ÉÁêÜËß£"&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter10/%E7%AC%AC%E5%8D%81%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE.md"&gt;Á¨¨ÂçÅÁ´† Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP„ÄÅA2A„ÄÅANP Á≠âÂçèËÆÆËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter11/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%20Agentic-RL.md"&gt;Á¨¨ÂçÅ‰∏ÄÁ´† Agentic-RL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé SFT Âà∞ GRPO ÁöÑ LLM ËÆ≠ÁªÉÂÆûÊàò&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter12/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0.md"&gt;Á¨¨ÂçÅ‰∫åÁ´† Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ê†∏ÂøÉÊåáÊ†á„ÄÅÂü∫ÂáÜÊµãËØï‰∏éËØÑ‰º∞Ê°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter13/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%20%E6%99%BA%E8%83%BD%E6%97%85%E8%A1%8C%E5%8A%A9%E6%89%8B.md"&gt;Á¨¨ÂçÅ‰∏âÁ´† Êô∫ËÉΩÊóÖË°åÂä©Êâã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP ‰∏éÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÁöÑÁúüÂÆû‰∏ñÁïåÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter14/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%20%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨ÂçÅÂõõÁ´† Ëá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DeepResearch Agent Â§çÁé∞‰∏éËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter15/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E8%B5%9B%E5%8D%9A%E5%B0%8F%E9%95%87.md"&gt;Á¨¨ÂçÅ‰∫îÁ´† ÊûÑÂª∫ËµõÂçöÂ∞èÈïá&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent ‰∏éÊ∏∏ÊàèÁöÑÁªìÂêàÔºåÊ®°ÊãüÁ§æ‰ºöÂä®ÊÄÅ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter16/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0%20%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1.md"&gt;Á¨¨ÂçÅÂÖ≠Á´† ÊØï‰∏öËÆæËÆ°&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊûÑÂª∫Â±û‰∫é‰Ω†ÁöÑÂÆåÊï¥Â§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ (Community Blog)&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢ËøéÂ§ßÂÆ∂Â∞ÜÂú®Â≠¶‰π† Hello-Agents Êàñ Agent Áõ∏ÂÖ≥ÊäÄÊúØ‰∏≠ÁöÑÁã¨Âà∞ËßÅËß£„ÄÅÂÆûË∑µÊÄªÁªìÔºå‰ª• PR ÁöÑÂΩ¢ÂºèË¥°ÁåÆÂà∞Á§æÂå∫Á≤æÈÄâ„ÄÇÂ¶ÇÊûúÊòØÁã¨Á´ã‰∫éÊ≠£ÊñáÁöÑÂÜÖÂÆπÔºå‰πüÂèØ‰ª•ÊäïÁ®øËá≥ Extra-ChapterÔºÅ&lt;strong&gt;ÊúüÂæÖ‰Ω†ÁöÑÁ¨¨‰∏ÄÊ¨°Ë¥°ÁåÆÔºÅ&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á§æÂå∫Á≤æÈÄâ&lt;/th&gt; 
   &lt;th&gt;ÂÜÖÂÆπÊÄªÁªì&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md"&gt;01-AgentÈù¢ËØïÈ¢òÊÄªÁªì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent Â≤ó‰ΩçÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88.md"&gt;01-AgentÈù¢ËØïÈ¢òÁ≠îÊ°à&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Áõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢òÁ≠îÊ°à&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra02-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86.md"&gt;02-‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπË°•ÂÖÖ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπÊâ©Â±ï&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra03-Dify%E6%99%BA%E8%83%BD%E4%BD%93%E5%88%9B%E5%BB%BA%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B.md"&gt;03-DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra04-DatawhaleFAQ.md"&gt;04-Hello-agentsËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DatawhaleËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;PDF ÁâàÊú¨‰∏ãËΩΩ&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉ&lt;em&gt;&lt;strong&gt;Êú¨ Hello-Agents PDF ÊïôÁ®ãÂÆåÂÖ®ÂºÄÊ∫êÂÖçË¥π„ÄÇ‰∏∫Èò≤Ê≠¢ÂêÑÁ±ªËê•ÈîÄÂè∑Âä†Ê∞¥Âç∞ÂêéË¥©ÂçñÁªôÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÂàùÂ≠¶ËÄÖÔºåÊàë‰ª¨ÁâπÂú∞Âú® PDF Êñá‰ª∂‰∏≠È¢ÑÂÖàÊ∑ªÂä†‰∫Ü‰∏çÂΩ±ÂìçÈòÖËØªÁöÑ Datawhale ÂºÄÊ∫êÊ†áÂøóÊ∞¥Âç∞ÔºåÊï¨ËØ∑Ë∞ÖËß£ÔΩû&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Hello-Agents PDF : &lt;a href="https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0"&gt;https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0&lt;/a&gt;&lt;/em&gt;&lt;br /&gt; &lt;em&gt;Hello-Agents PDF ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄ : &lt;a href="https://www.datawhale.cn/learn/summary/239"&gt;https://www.datawhale.cn/learn/summary/239&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üí° Â¶Ç‰ΩïÂ≠¶‰π†&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢Ëøé‰Ω†ÔºåÊú™Êù•ÁöÑÊô∫ËÉΩÁ≥ªÁªüÊûÑÂª∫ËÄÖÔºÅÂú®ÂºÄÂêØËøôÊÆµÊøÄÂä®‰∫∫ÂøÉÁöÑÊóÖÁ®ã‰πãÂâçÔºåËØ∑ÂÖÅËÆ∏Êàë‰ª¨Áªô‰Ω†‰∏Ä‰∫õÊ∏ÖÊô∞ÁöÑÊåáÂºï„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊú¨È°πÁõÆÂÜÖÂÆπÂÖºÈ°æÁêÜËÆ∫‰∏éÂÆûÊàòÔºåÊó®Âú®Â∏ÆÂä©‰Ω†Á≥ªÁªüÊÄßÂú∞ÊéåÊè°‰ªéÂçï‰∏™Êô∫ËÉΩ‰ΩìÂà∞Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂºÄÂèëÂÖ®ÊµÅÁ®ã„ÄÇÂõ†Ê≠§ÔºåÂ∞§ÂÖ∂ÈÄÇÂêàÊúâ‰∏ÄÂÆöÁºñÁ®ãÂü∫Á°ÄÁöÑ &lt;strong&gt;AI ÂºÄÂèëËÄÖ„ÄÅËΩØ‰ª∂Â∑•Á®ãÂ∏à„ÄÅÂú®Ê†°Â≠¶Áîü&lt;/strong&gt; ‰ª•ÂèäÂØπÂâçÊ≤ø AI ÊäÄÊúØÊä±ÊúâÊµìÂéöÂÖ¥Ë∂£ÁöÑ &lt;strong&gt;Ëá™Â≠¶ËÄÖ&lt;/strong&gt;„ÄÇÂú®Â≠¶‰π†Êú¨È°πÁõÆ‰πãÂâçÔºåÊàë‰ª¨Â∏åÊúõ‰Ω†ÂÖ∑Â§áÂü∫Á°ÄÁöÑ Python ÁºñÁ®ãËÉΩÂäõÔºåÂπ∂ÂØπÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúâÂü∫Êú¨ÁöÑÊ¶ÇÂøµÊÄß‰∫ÜËß£Ôºà‰æãÂ¶ÇÔºåÁü•ÈÅìÂ¶Ç‰ΩïÈÄöËøá API Ë∞ÉÁî®‰∏Ä‰∏™ LLMÔºâ„ÄÇÈ°πÁõÆÁöÑÈáçÁÇπÊòØÂ∫îÁî®‰∏éÊûÑÂª∫ÔºåÂõ†Ê≠§‰Ω†Êó†ÈúÄÂÖ∑Â§áÊ∑±ÂéöÁöÑÁÆóÊ≥ïÊàñÊ®°ÂûãËÆ≠ÁªÉËÉåÊôØ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÈ°πÁõÆÂàÜ‰∏∫‰∫îÂ§ßÈÉ®ÂàÜÔºåÊØè‰∏ÄÈÉ®ÂàÜÈÉΩÊòØÈÄöÂæÄ‰∏ã‰∏ÄÈò∂ÊÆµÁöÑÂùöÂÆûÈò∂Ê¢ØÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;ÔºàÁ¨¨‰∏ÄÁ´†ÔΩûÁ¨¨‰∏âÁ´†ÔºâÔºåÊàë‰ª¨Â∞Ü‰ªéÊô∫ËÉΩ‰ΩìÁöÑÂÆö‰πâ„ÄÅÁ±ªÂûã‰∏éÂèëÂ±ïÂéÜÂè≤ËÆ≤Ëµ∑Ôºå‰∏∫‰Ω†Ê¢≥ÁêÜ"Êô∫ËÉΩ‰Ωì"Ëøô‰∏ÄÊ¶ÇÂøµÁöÑÊù•ÈæôÂéªËÑâ„ÄÇÈöèÂêéÔºåÊàë‰ª¨‰ºöÂø´ÈÄüÂ∑©Âõ∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ†∏ÂøÉÁü•ËØÜÔºå‰∏∫‰Ω†ÁöÑÂÆûË∑µ‰πãÊóÖÊâì‰∏ãÂùöÂÆûÁöÑÁêÜËÆ∫Âú∞Âü∫„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;ÔºàÁ¨¨ÂõõÁ´†ÔΩûÁ¨¨‰∏ÉÁ´†ÔºâÔºåËøôÊòØ‰Ω†Âä®ÊâãÂÆûË∑µÁöÑËµ∑ÁÇπ„ÄÇ‰Ω†Â∞Ü‰∫≤ÊâãÂÆûÁé∞ ReAct Á≠âÁªèÂÖ∏ËåÉÂºèÔºå‰ΩìÈ™å Coze Á≠â‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑ‰æøÊç∑ÔºåÂπ∂ÊéåÊè° Langgraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂ÁöÑÂ∫îÁî®„ÄÇÊúÄÁªàÔºåÊàë‰ª¨Ëøò‰ºöÂ∏¶‰Ω†‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫‰∏Ä‰∏™Â±û‰∫éËá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåËÆ©‰Ω†ÂÖºÂÖ∑‚ÄúÁî®ËΩÆÂ≠ê‚Äù‰∏é‚ÄúÈÄ†ËΩÆÂ≠ê‚ÄùÁöÑËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;ÔºàÁ¨¨ÂÖ´Á´†ÔΩûÁ¨¨ÂçÅ‰∫åÁ´†ÔºâÔºåÂú®Ëøô‰∏ÄÈÉ®ÂàÜÔºå‰Ω†ÁöÑÊô∫ËÉΩ‰ΩìÂ∞Ü‚ÄúÂ≠¶‰ºö‚ÄùÊÄùËÄÉ‰∏éÂçè‰Ωú„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®Á¨¨‰∫åÈÉ®ÂàÜÁöÑËá™Á†îÊ°ÜÊû∂ÔºåÊ∑±ÂÖ•Êé¢Á¥¢ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢„ÄÅ‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅAgent ËÆ≠ÁªÉÁ≠âÊ†∏ÂøÉÊäÄÊúØÔºåÂπ∂Â≠¶‰π†Â§öÊô∫ËÉΩ‰ΩìÈó¥ÁöÑÈÄö‰ø°ÂçèËÆÆ„ÄÇÊúÄÁªàÔºå‰Ω†Â∞ÜÊéåÊè°ËØÑ‰º∞Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÊÄßËÉΩÁöÑ‰∏ì‰∏öÊñπÊ≥ï„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;ÔºàÁ¨¨ÂçÅ‰∏âÁ´†ÔΩûÁ¨¨ÂçÅ‰∫îÁ´†ÔºâÔºåËøôÈáåÊòØÁêÜËÆ∫‰∏éÂÆûË∑µÁöÑ‰∫§Ê±áÁÇπ„ÄÇ‰Ω†Â∞ÜÊääÊâÄÂ≠¶Ëûç‰ºöË¥ØÈÄöÔºå‰∫≤ÊâãÊâìÈÄ†Êô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰ΩìÔºå‰πÉËá≥‰∏Ä‰∏™Ê®°ÊãüÁ§æ‰ºöÂä®ÊÄÅÁöÑËµõÂçöÂ∞èÈïáÔºåÂú®ÁúüÂÆûÊúâË∂£ÁöÑÈ°πÁõÆ‰∏≠Ê∑¨ÁÇº‰Ω†ÁöÑÊûÑÂª∫ËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;ÔºàÁ¨¨ÂçÅÂÖ≠Á´†ÔºâÔºåÂú®ÊóÖÁ®ãÁöÑÁªàÁÇπÔºå‰Ω†Â∞ÜËøéÊù•‰∏Ä‰∏™ÊØï‰∏öËÆæËÆ°ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄÅÂ±û‰∫é‰Ω†Ëá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®ÔºåÂÖ®Èù¢Ê£ÄÈ™å‰Ω†ÁöÑÂ≠¶‰π†ÊàêÊûú„ÄÇÊàë‰ª¨ËøòÂ∞Ü‰∏é‰Ω†‰∏ÄÂêåÂ±ïÊúõÊô∫ËÉΩ‰ΩìÁöÑÊú™Êù•ÔºåÊé¢Á¥¢ÊøÄÂä®‰∫∫ÂøÉÁöÑÂâçÊ≤øÊñπÂêë„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊô∫ËÉΩ‰ΩìÊòØ‰∏Ä‰∏™È£ûÈÄüÂèëÂ±ï‰∏îÊûÅÂ∫¶‰æùËµñÂÆûË∑µÁöÑÈ¢ÜÂüü„ÄÇ‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥ÁöÑÂ≠¶‰π†ÊïàÊûúÔºåÊàë‰ª¨Âú®È°πÁõÆÁöÑ&lt;code&gt;code&lt;/code&gt;Êñá‰ª∂Â§πÂÜÖÊèê‰æõ‰∫ÜÈÖçÂ•óÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºåÂº∫ÁÉàÂª∫ËÆÆ‰Ω†&lt;strong&gt;Â∞ÜÁêÜËÆ∫‰∏éÂÆûË∑µÁõ∏ÁªìÂêà&lt;/strong&gt;„ÄÇËØ∑Âä°ÂøÖ‰∫≤ÊâãËøêË°å„ÄÅË∞ÉËØïÁîöËá≥‰øÆÊîπÈ°πÁõÆÈáåÊèê‰æõÁöÑÊØè‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇÊ¨¢Ëøé‰Ω†ÈöèÊó∂ÂÖ≥Ê≥® Datawhale ‰ª•ÂèäÂÖ∂‰ªñ Agent Áõ∏ÂÖ≥Á§æÂå∫ÔºåÂΩìÈÅáÂà∞ÈóÆÈ¢òÊó∂Ôºå‰Ω†ÂèØ‰ª•ÈöèÊó∂Âú®Êú¨È°πÁõÆÁöÑ issue Âå∫ÊèêÈóÆ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÁé∞Âú®ÔºåÂáÜÂ§áÂ•ΩËøõÂÖ•Êô∫ËÉΩ‰ΩìÁöÑÂ•áÂ¶ô‰∏ñÁïå‰∫ÜÂêóÔºüËÆ©Êàë‰ª¨Âç≥ÂàªÂêØÁ®ãÔºÅ&lt;/p&gt; 
&lt;h2&gt;‰∏ã‰∏ÄÊ≠•ËßÑÂàí&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[]Ëã±ÊñáÁâàÊïôÁ®ã&lt;/li&gt; 
 &lt;li&gt;[]ÂèåËØ≠ËßÜÈ¢ëËØæÁ®ã[Ëã±Êñá+‰∏≠Êñá]ÔºàÂ∞Ü‰ºöÊõ¥Âä†ÁªÜËá¥ÔºåÂÆûË∑µËØæÂ∏¶È¢ÜÂ§ßÂÆ∂‰ªéËÆæËÆ°ÊÄùË∑ØÂà∞ÂÆûÊñΩÔºåÊéà‰∫∫‰ª•È±º‰πüÊéà‰∫∫‰ª•Ê∏îÔºâ&lt;/li&gt; 
 &lt;li&gt;[]ÂÖ±ÂàõÁ¨¨16Á´†ÔºàÊâìÈÄ†ÂêÑÁ±ªAgentÂ∫îÁî®,Êõ¥ÊâìÈÄ†AgentÁîüÊÄÅÔºâ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Â¶Ç‰ΩïË¥°ÁåÆ&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨ÊòØ‰∏Ä‰∏™ÂºÄÊîæÁöÑÂºÄÊ∫êÁ§æÂå∫ÔºåÊ¨¢Ëøé‰ªª‰ΩïÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Êä•Âëä Bug&lt;/strong&gt; - ÂèëÁé∞ÂÜÖÂÆπÊàñ‰ª£Á†ÅÈóÆÈ¢òÔºåËØ∑Êèê‰∫§ Issue&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;ÊèêÂá∫Âª∫ËÆÆ&lt;/strong&gt; - ÂØπÈ°πÁõÆÊúâÂ•ΩÊÉ≥Ê≥ïÔºåÊ¨¢ËøéÂèëËµ∑ËÆ®ËÆ∫&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;ÂÆåÂñÑÂÜÖÂÆπ&lt;/strong&gt; - Â∏ÆÂä©ÊîπËøõÊïôÁ®ãÔºåÊèê‰∫§‰Ω†ÁöÑ Pull Request&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;strong&gt;ÂàÜ‰∫´ÂÆûË∑µ&lt;/strong&gt; - Âú®"Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ"‰∏≠ÂàÜ‰∫´‰Ω†ÁöÑÂ≠¶‰π†Á¨îËÆ∞ÂíåÈ°πÁõÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Ëá¥Ë∞¢&lt;/h2&gt; 
&lt;h3&gt;Ê†∏ÂøÉË¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jjyaoao"&gt;ÈôàÊÄùÂ∑û-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, ÂÖ®ÊñáÂÜô‰ΩúÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fengju0213"&gt;Â≠ôÈü¨-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, Á¨¨‰πùÁ´†ÂÜÖÂÆπÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tsumugii24"&gt;ÂßúËàíÂá°-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt;ÔºàDatawhale ÊàêÂëò, Á´†ËäÇ‰π†È¢òËÆæËÆ°ÂíåÊ†°ÂØπÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HeteroCat"&gt;ÈªÑ‰Ω©Êûó-DatawhaleÊÑèÂêëÊàêÂëò&lt;/a&gt; (Agent ÂºÄÂèëÂ∑•Á®ãÂ∏à, Á¨¨‰∫îÁ´†ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fancyboi999"&gt;ÊõæÈë´Ê∞ë-AgentÂ∑•Á®ãÂ∏à&lt;/a&gt; (ÁâõÂÆ¢ÁßëÊäÄ, Á¨¨ÂçÅÂõõÁ´†Ê°à‰æãÂºÄÂèë)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xinzhongzhu.github.io/"&gt;Êú±‰ø°Âø†-ÊåáÂØº‰∏ìÂÆ∂&lt;/a&gt; (DatawhaleÈ¶ñÂ∏≠ÁßëÂ≠¶ÂÆ∂-ÊµôÊ±üÂ∏àËåÉÂ§ßÂ≠¶Êù≠Â∑û‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Èô¢ÊïôÊéà)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extra-Chapter Ë¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/WHQAQ11"&gt;WH&lt;/a&gt; (ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thunderbolt-fire"&gt;Âë®Â••Êù∞-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ë•øÂÆâ‰∫§ÈÄöÂ§ßÂ≠¶, Extra02 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tasselszcx"&gt;Âº†ÂÆ∏Êó≠-‰∏™‰∫∫ÂºÄÂèëËÄÖ&lt;/a&gt;(Â∏ùÂõΩÁêÜÂ∑•Â≠¶Èô¢, Extra03 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XiaoMa-PM"&gt;ÈªÑÂÆèÊôó-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ê∑±Âú≥Â§ßÂ≠¶, Extra04 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÁâπÂà´ÊÑüË∞¢&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊÑüË∞¢ &lt;a href="https://github.com/Sm1les"&gt;@Sm1les&lt;/a&gt; ÂØπÊú¨È°πÁõÆÁöÑÂ∏ÆÂä©‰∏éÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;ÊÑüË∞¢ÊâÄÊúâ‰∏∫Êú¨È°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖ‰ª¨ ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center" style="margin-top: 30px;"&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=datawhalechina/Hello-Agents" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/star-history-20251211.png" alt="Datawhale" width="90%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‚≠ê Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ÁªôÊàë‰ª¨‰∏Ä‰∏™ StarÔºÅ&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ÂÖ≥‰∫é Datawhale&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/datawhale.png" alt="Datawhale" width="30%" /&gt; 
 &lt;p&gt;Êâ´Êèè‰∫åÁª¥Á†ÅÂÖ≥Ê≥® Datawhale ÂÖ¨‰ºóÂè∑ÔºåËé∑ÂèñÊõ¥Â§ö‰ºòË¥®ÂºÄÊ∫êÂÜÖÂÆπ&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìú ÂºÄÊ∫êÂçèËÆÆ&lt;/h2&gt; 
&lt;p&gt;Êú¨‰ΩúÂìÅÈááÁî®&lt;a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆ&lt;/a&gt;ËøõË°åËÆ∏ÂèØ„ÄÇ&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zai-org/GLM-V</title>
      <link>https://github.com/zai-org/GLM-V</link>
      <description>&lt;p&gt;GLM-4.6V/4.5V/4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GLM-V&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/zai-org/GLM-V/main/README_zh.md"&gt;‰∏≠ÊñáÈòÖËØª.&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/zai-org/GLM-V/main/resources/logo.svg?sanitize=true" width="40%" /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; üëã Join our &lt;a href="https://raw.githubusercontent.com/zai-org/GLM-V/main/resources/WECHAT.md" target="_blank"&gt;WeChat&lt;/a&gt; and &lt;a href="https://t.co/b6zGxJvzzS" target="_blank"&gt;Discord&lt;/a&gt; communities. &lt;br /&gt; üìñ Check out the GLM-4.6V &lt;a href="https://z.ai/blog/glm-4.6v" target="_blank"&gt;blog&lt;/a&gt; and GLM-4.5V &amp;amp; GLM-4.1V &lt;a href="https://arxiv.org/abs/2507.01006" target="_blank"&gt;paper&lt;/a&gt;. &lt;br /&gt; üìç Try &lt;a href="https://chat.z.ai/" target="_blank"&gt;online&lt;/a&gt; or use the &lt;a href="https://docs.z.ai/guides/vlm/glm-4.6v" target="_blank"&gt;API&lt;/a&gt;. &lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Vision-language models (VLMs) have become a key cornerstone of intelligent systems. As real-world AI tasks grow increasingly complex, VLMs urgently need to enhance reasoning capabilities beyond basic multimodal perception ‚Äî improving accuracy, comprehensiveness, and intelligence ‚Äî to enable complex problem solving, long-context understanding, and multimodal agents.&lt;/p&gt; 
&lt;p&gt;Through our open-source work, we aim to explore the technological frontier together with the community while empowering more developers to create exciting and innovative applications.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This open-source repository contains our &lt;code&gt;GLM-4.6V&lt;/code&gt;, &lt;code&gt;GLM-4.5V&lt;/code&gt; and &lt;code&gt;GLM-4.1V&lt;/code&gt; series models.&lt;/strong&gt; For performance and details, see &lt;a href="https://raw.githubusercontent.com/zai-org/GLM-V/main/#model-overview"&gt;Model Overview&lt;/a&gt;. For known issues, see &lt;a href="https://raw.githubusercontent.com/zai-org/GLM-V/main/#fixed-and-remaining-issues"&gt;Fixed and Remaining Issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Project Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üî• &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2025/12/08&lt;/code&gt;: We‚Äôve released &lt;strong&gt;GLM-4.6V&lt;/strong&gt; series model, including GLM-4.6V (106B-A12B) and GLM-4.6V-Flash (9B). GLM-4.6V scales its context window to 128k tokens in training, and we integrate native Function Calling capabilities for the first time. This effectively bridges the gap between "visual perception" and "executable action," providing a unified technical foundation for multimodal agents in real-world business scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2025/11/10&lt;/code&gt;: We released &lt;strong&gt;UI2Code^N&lt;/strong&gt;, a RL-enhanced UI coding model with UI-to-code, UI-polish, and UI-edit capabilities. The model is trained based on &lt;code&gt;GLM-4.1V-Base&lt;/code&gt;. Check it out &lt;a href="https://huggingface.co/zai-org/UI2Code_N"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2025/10/27&lt;/code&gt;: We‚Äôve released &lt;strong&gt;Glyph&lt;/strong&gt;, a framework for scaling the context length through visual-text compression, the glyph model trained based on &lt;code&gt;GLM-4.1V-Base&lt;/code&gt;. Check it out &lt;a href="https://huggingface.co/zai-org/Glyph"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2025/08/11&lt;/code&gt;: We released &lt;strong&gt;GLM-4.5V&lt;/strong&gt; with significant improvements across multiple benchmarks. We also open-sourced our handcrafted &lt;strong&gt;desktop assistant app&lt;/strong&gt; for debugging. Once connected to GLM-4.5V, it can capture visual information from your PC screen via screenshots or screen recordings. Feel free to try it out or customize it into your own multimodal assistant. Click &lt;a href="https://huggingface.co/spaces/zai-org/GLM-4.5V-Demo-App"&gt;here&lt;/a&gt; to download the installer or &lt;a href="https://raw.githubusercontent.com/zai-org/GLM-V/main/examples/vllm-chat-helper/README.md"&gt;build from source&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2025/07/16&lt;/code&gt;: We have open-sourced the &lt;strong&gt;VLM Reward System&lt;/strong&gt; used to train GLM-4.1V-Thinking.View the &lt;a href="https://raw.githubusercontent.com/zai-org/GLM-V/main/glmv_reward"&gt;code repository&lt;/a&gt; and run locally: &lt;code&gt;python examples/reward_system_demo.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2025/07/01&lt;/code&gt;: We released &lt;strong&gt;GLM-4.1V-9B-Thinking&lt;/strong&gt; and its &lt;a href="https://arxiv.org/abs/2507.01006"&gt;technical report&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model Implementation Code&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;GLM-4.5V and GLM-4.6V model algorithm: see the full implementation in &lt;a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/glm4v_moe"&gt;transformers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;GLM-4.1V-9B-Thinking model algorithm: see the full implementation in &lt;a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/glm4v"&gt;transformers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Both models share identical multimodal preprocessing, but use different conversation templates ‚Äî please distinguish carefully.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model Downloads&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Download Links&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GLM-4.6V&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org/GLM-4.6V"&gt;ü§ó Hugging Face&lt;/a&gt;&lt;br /&gt;&lt;a href="https://modelscope.cn/models/ZhipuAI/GLM-4.6V"&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid Reasoning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GLM-4.6V-FP8&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org/GLM-4.6V-FP8"&gt;ü§ó Hugging Face&lt;/a&gt;&lt;br /&gt;&lt;a href="https://modelscope.cn/models/ZhipuAI/GLM-4.6V-FP8"&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid Reasoning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GLM-4.6V-Flash&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org/GLM-4.6V-Flash"&gt;ü§ó Hugging Face&lt;/a&gt;&lt;br /&gt;&lt;a href="https://modelscope.cn/models/ZhipuAI/GLM-4.6V-Flash"&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid Reasoning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GLM-4.5V&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org/GLM-4.5V"&gt;ü§ó Hugging Face&lt;/a&gt;&lt;br /&gt;&lt;a href="https://modelscope.cn/models/ZhipuAI/GLM-4.5V"&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid Reasoning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GLM-4.5V-FP8&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org/GLM-4.5V-FP8"&gt;ü§ó Hugging Face&lt;/a&gt;&lt;br /&gt;&lt;a href="https://modelscope.cn/models/ZhipuAI/GLM-4.5V-FP8"&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid Reasoning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GLM-4.1V-9B-Thinking&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org/GLM-4.1V-9B-Thinking"&gt;ü§ó Hugging Face&lt;/a&gt;&lt;br /&gt;&lt;a href="https://modelscope.cn/models/ZhipuAI/GLM-4.1V-9B-Thinking"&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Reasoning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GLM-4.1V-9B-Base&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org/GLM-4.1V-9B-Base"&gt;ü§ó Hugging Face&lt;/a&gt;&lt;br /&gt;&lt;a href="https://modelscope.cn/models/ZhipuAI/GLM-4.1V-9B-Base"&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Base&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Using Case&lt;/h2&gt; 
&lt;h3&gt;Grounding&lt;/h3&gt; 
&lt;p&gt;GLM-4.5V equips precise grounding capabilities. Given a prompt that requests the location of a specific object, GLM-4.5V is able to reasoning step-by-step and identify the bounding boxes of the target object. The query prompt supports complex descriptions of the target object as well as specified output formats, for example:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Help me to locate 
   &lt;expr&gt;
     in the image and give me its bounding boxes.
   &lt;/expr&gt;&lt;/li&gt; 
  &lt;li&gt;Please pinpoint the bounding box [[x1,y1,x2,y2], ‚Ä¶] in the image as per the given description. 
   &lt;expr&gt;&lt;/expr&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Here, &lt;code&gt;&amp;lt;expr&amp;gt;&lt;/code&gt; is the description of the target object. The output bounding box is a quadruple $$[x_1,y_1,x_2,y_2]$$ composed of the coordinates of the top-left and bottom-right corners, where each value is normalized by the image width (for x) or height (for y) and scaled by 1000.&lt;/p&gt; 
&lt;p&gt;In the response, the special tokens &lt;code&gt;&amp;lt;|begin_of_box|&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;|end_of_box|&amp;gt;&lt;/code&gt; are used to mark the image bounding box in the answer. The bracket style may vary ([], [[]], (), &amp;lt;&amp;gt;, etc.), but the meaning is the same: to enclose the coordinates of the box.&lt;/p&gt; 
&lt;h3&gt;GUI Agent&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;examples/gui-agent&lt;/code&gt;: Demonstrates prompt construction and output handling for GUI Agents, including strategies for mobile, PC, and web. Prompt templates differ between GLM-4.1V and GLM-4.5V.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Demo&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;examples/vlm-helper&lt;/code&gt;: A desktop assistant for GLM multimodal models (mainly GLM-4.5V, compatible with GLM-4.1V), supporting text, images, videos, PDFs, PPTs, and more. Connects to the GLM multimodal API for intelligent services across scenarios. Download the &lt;a href="https://huggingface.co/spaces/zai-org/GLM-4.5V-Demo-App"&gt;installer&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/zai-org/GLM-V/main/examples/vlm-helper/README.md"&gt;build from source&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Environment Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;vLLM and SGLang dependencies may conflict, so it is recommended to install only one of them in each environment.&lt;/li&gt; 
 &lt;li&gt;Please note that after installation, you should verify the version of &lt;code&gt;transformers&lt;/code&gt; and ensure it is upgraded to &lt;code&gt;5.0.0rc0&lt;/code&gt; or above.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;transformers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;trans_infer_cli.py&lt;/code&gt;: CLI for continuous conversations using &lt;code&gt;transformers&lt;/code&gt; backend.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;trans_infer_gradio.py&lt;/code&gt;: Gradio web interface with multimodal input (images, videos, PDFs, PPTs) using &lt;code&gt;transformers&lt;/code&gt; backend.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;trans_infer_bench&lt;/code&gt;: Academic reproduction script for &lt;code&gt;GLM-4.1V-9B-Thinking&lt;/code&gt;. It forces reasoning truncation at length &lt;code&gt;8192&lt;/code&gt; and requests direct answers afterward. Includes a video input example; modify for other cases.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;vLLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vllm serve zai-org/GLM-4.6V \
     --tensor-parallel-size 4 \
     --tool-call-parser glm45 \
     --reasoning-parser glm45 \
     --enable-auto-tool-choice \
     --served-model-name glm-4.6v \
     --allowed-local-media-path / \
     --mm-encoder-tp-mode data \ 
     --mm_processor_cache_type shm \ 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more detail, check &lt;a href="https://github.com/vllm-project/recipes/raw/main/GLM/GLM-V.md"&gt;vLLM Recipes&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SGlang&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python3 -m sglang.launch_server --model-path zai-org/GLM-4.6V \
     --tp-size 4 \
     --tool-call-parser glm \
     --reasoning-parser glm \
     --served-model-name glm-4.6v \
     --mm-enable-dp-encoder \
     --port 8000 \
     --host 0.0.0.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;We recommend increasing &lt;code&gt;SGLANG_VLM_CACHE_SIZE_MB&lt;/code&gt; (e.g., &lt;code&gt;1024&lt;/code&gt;) to provide sufficient cache space for video understanding.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;When using &lt;code&gt;vLLM&lt;/code&gt; and &lt;code&gt;SGLang&lt;/code&gt;, thinking mode is enabled by default. To disable the thinking switch, Add:&lt;br /&gt; &lt;code&gt;extra_body={"chat_template_kwargs": {"enable_thinking": False}}&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can configure a thinking budget to limit the model‚Äôs maximum reasoning span. Add&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from sglang.srt.sampling.custom_logit_processor import Glm4MoeThinkingBudgetLogitProcessor
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;extra_body={
        "custom_logit_processor": Glm4MoeThinkingBudgetLogitProcessor().to_str(),
        "custom_params": {
            "thinking_budget": 8192, # max reasoning length in tokens
        },
    },
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;xLLM&lt;/h3&gt; 
&lt;p&gt;check &lt;a href="https://raw.githubusercontent.com/zai-org/GLM-V/main/examples/Ascend_NPU/README_zh.md"&gt;here&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h2&gt;Model Fine-tuning&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/hiyouga/LLaMA-Factory"&gt;LLaMA-Factory&lt;/a&gt; already supports fine-tuning for GLM-4.5V &amp;amp; GLM-4.1V-9B-Thinking models. Below is an example of dataset construction using two images. You should organize your dataset into &lt;code&gt;finetune.json&lt;/code&gt; in the following format, This is an example for fine-tuning GLM-4.1V-9B.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;[
  {
    "messages": [
      {
        "content": "&amp;lt;image&amp;gt;Who are they?",
        "role": "user"
      },
      {
        "content": "&amp;lt;think&amp;gt;\nUser asked me to observe the image and find the answer. I know they are Kane and Goretzka from Bayern Munich.&amp;lt;/think&amp;gt;\n&amp;lt;answer&amp;gt;They're Kane and Goretzka from Bayern Munich.&amp;lt;/answer&amp;gt;",
        "role": "assistant"
      },
      {
        "content": "&amp;lt;image&amp;gt;What are they doing?",
        "role": "user"
      },
      {
        "content": "&amp;lt;think&amp;gt;\nI need to observe what these people are doing. Oh, they are celebrating on the soccer field.&amp;lt;/think&amp;gt;\n&amp;lt;answer&amp;gt;They are celebrating on the soccer field.&amp;lt;/answer&amp;gt;",
        "role": "assistant"
      }
    ],
    "images": [
      "mllm_demo_data/1.jpg",
      "mllm_demo_data/2.jpg"
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt;The content inside &lt;code&gt;&amp;lt;think&amp;gt; ... &amp;lt;/think&amp;gt;&lt;/code&gt; will &lt;strong&gt;not&lt;/strong&gt; be stored as conversation history or in fine-tuning data.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;&amp;lt;image&amp;gt;&lt;/code&gt; tag will be replaced with the corresponding image information.&lt;/li&gt; 
 &lt;li&gt;For the GLM-4.5V model, the 
  &lt;answer&gt;
    and 
  &lt;/answer&gt; tags should be removed.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Then, you can fine-tune following the standard LLaMA-Factory procedure.&lt;/p&gt; 
&lt;h2&gt;Model Overview&lt;/h2&gt; 
&lt;h2&gt;Model Overview&lt;/h2&gt; 
&lt;h3&gt;GLM-4.6V&lt;/h3&gt; 
&lt;p&gt;GLM-4.6V series model includes two versions: GLM-4.6V (106B), a foundation model designed for cloud and high-performance cluster scenarios, and GLM-4.6V-Flash (9B), a lightweight model optimized for local deployment and low-latency applications. GLM-4.6V scales its context window to 128k tokens in training, and achieves SoTA performance in visual understanding among models of similar parameter scales. Crucially, we integrate native Function Calling capabilities for the first time. This effectively bridges the gap between "visual perception" and "executable action" providing a unified technical foundation for multimodal agents in real-world business scenarios.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/zai-org/GLM-V/main/resources/bench_46v.jpeg" alt="GLM-4.6V Benchmarks" /&gt;&lt;/p&gt; 
&lt;p&gt;Beyond achieves SoTA performance across major multimodal benchmarks at comparable model scales. GLM-4.6V introduces several key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native Multimodal Function Calling&lt;/strong&gt; Enables native vision-driven tool use. Images, screenshots, and document pages can be passed directly as tool inputs without text conversion, while visual outputs (charts, search images, rendered pages) are interpreted and integrated into the reasoning chain. This closes the loop from perception to understanding to execution.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Interleaved Image-Text Content Generation&lt;/strong&gt; Supports high-quality mixed media creation from complex multimodal inputs. GLM-4.6V takes a multimodal context‚Äîspanning documents, user inputs, and tool-retrieved images‚Äîand synthesizes coherent, interleaved image-text content tailored to the task. During generation it can actively call search and retrieval tools to gather and curate additional text and visuals, producing rich, visually grounded content.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multimodal Document Understanding&lt;/strong&gt; GLM-4.6V can process up to 128K tokens of multi-document or long-document input, directly interpreting richly formatted pages as images. It understands text, layout, charts, tables, and figures jointly, enabling accurate comprehension of complex, image-heavy documents without requiring prior conversion to plain text.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Frontend Replication &amp;amp; Visual Editing&lt;/strong&gt; Reconstructs pixel-accurate HTML/CSS from UI screenshots and supports natural-language-driven edits. It detects layout, components, and styles visually, generates clean code, and applies iterative visual modifications through simple user instructions.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;GLM-4.5V&lt;/h3&gt; 
&lt;p&gt;GLM-4.5V is based on ZhipuAI‚Äôs GLM-4.5-Air.&lt;br /&gt; It continues the technical approach of GLM-4.1V-Thinking, achieving SOTA performance among models of the same scale on 42 public vision-language benchmarks.&lt;br /&gt; It covers common tasks such as image, video, and document understanding, as well as GUI agent operations.&lt;/p&gt; 
&lt;p&gt;Beyond benchmark performance, GLM-4.5V focuses on real-world usability. Through efficient hybrid training, it can handle diverse types of visual content, enabling full-spectrum vision reasoning, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Image reasoning&lt;/strong&gt; (scene understanding, complex multi-image analysis, spatial recognition)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Video understanding&lt;/strong&gt; (long video segmentation and event recognition)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GUI tasks&lt;/strong&gt; (screen reading, icon recognition, desktop operation assistance)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complex chart &amp;amp; long document parsing&lt;/strong&gt; (research report analysis, information extraction)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Grounding&lt;/strong&gt; (precise visual element localization)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The model also introduces a &lt;strong&gt;Thinking Mode&lt;/strong&gt; switch, allowing users to balance between quick responses and deep reasoning. This switch works the same as in the &lt;code&gt;GLM-4.5&lt;/code&gt; language model.&lt;/p&gt; 
&lt;h3&gt;GLM-4.1V-9B&lt;/h3&gt; 
&lt;p&gt;Built on the &lt;a href="https://github.com/zai-org/GLM-4"&gt;GLM-4-9B-0414&lt;/a&gt; foundation model, the &lt;strong&gt;GLM-4.1V-9B-Thinking&lt;/strong&gt; model introduces a reasoning paradigm and uses RLCS (Reinforcement Learning with Curriculum Sampling) to comprehensively enhance model capabilities.&lt;br /&gt; It achieves the strongest performance among 10B-level VLMs and matches or surpasses the much larger Qwen-2.5-VL-72B in 18 benchmark tasks.&lt;/p&gt; 
&lt;p&gt;We also open-sourced the base model &lt;strong&gt;GLM-4.1V-9B-Base&lt;/strong&gt; to support researchers in exploring the limits of vision-language model capabilities.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/zai-org/GLM-V/main/resources/rl.jpeg" alt="rl" /&gt;&lt;/p&gt; 
&lt;p&gt;Compared with the previous generation CogVLM2 and GLM-4V series, &lt;strong&gt;GLM-4.1V-Thinking&lt;/strong&gt; brings:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The series‚Äô first reasoning-focused model, excelling in multiple domains beyond mathematics.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;64k&lt;/strong&gt; context length support.&lt;/li&gt; 
 &lt;li&gt;Support for &lt;strong&gt;any aspect ratio&lt;/strong&gt; and up to &lt;strong&gt;4k&lt;/strong&gt; image resolution.&lt;/li&gt; 
 &lt;li&gt;A bilingual (Chinese/English) open-source version.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;GLM-4.1V-9B-Thinking integrates the &lt;strong&gt;Chain-of-Thought&lt;/strong&gt; reasoning mechanism, improving accuracy, richness, and interpretability.&lt;br /&gt; It leads on 23 out of 28 benchmark tasks at the 10B parameter scale, and outperforms Qwen-2.5-VL-72B on 18 tasks despite its smaller size.&lt;/p&gt; 
&lt;h2&gt;Remaining Issues&lt;/h2&gt; 
&lt;p&gt;Since the open-sourcing of GLM-4.1V, we have received extensive feedback from the community and are well aware that the model still has many shortcomings. In subsequent iterations, we attempted to address several common issues ‚Äî such as repetitive thinking outputs and formatting errors ‚Äî which have been mitigated to some extent in this new version.&lt;/p&gt; 
&lt;p&gt;However, the model still has several limitations and issues that we will fix as soon as possible:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pure text QA capabilities still have significant room for improvement. In this development cycle, our primary focus was on visual multimodal scenarios, and we will enhance pure text abilities in upcoming updates.&lt;/li&gt; 
 &lt;li&gt;The model may still overthink or even repeat itself in certain cases, especially when dealing with complex prompts.&lt;/li&gt; 
 &lt;li&gt;In some situations, the model may restate the answer again at the end.&lt;/li&gt; 
 &lt;li&gt;There remain certain perception limitations, such as counting accuracy and identifying specific individuals, which still require improvement.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Thank you for your patience and understanding. We also welcome feedback and suggestions in the issue section ‚Äî we will respond and improve as much as we can!&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use this model, please cite the following paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{vteam2025glm45vglm41vthinkingversatilemultimodal,
      title={GLM-4.5V and GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning},
      author={V Team and Wenyi Hong and Wenmeng Yu and Xiaotao Gu and Guo Wang and Guobing Gan and Haomiao Tang and Jiale Cheng and Ji Qi and Junhui Ji and Lihang Pan and Shuaiqi Duan and Weihan Wang and Yan Wang and Yean Cheng and Zehai He and Zhe Su and Zhen Yang and Ziyang Pan and Aohan Zeng and Baoxu Wang and Bin Chen and Boyan Shi and Changyu Pang and Chenhui Zhang and Da Yin and Fan Yang and Guoqing Chen and Jiazheng Xu and Jiale Zhu and Jiali Chen and Jing Chen and Jinhao Chen and Jinghao Lin and Jinjiang Wang and Junjie Chen and Leqi Lei and Letian Gong and Leyi Pan and Mingdao Liu and Mingde Xu and Mingzhi Zhang and Qinkai Zheng and Sheng Yang and Shi Zhong and Shiyu Huang and Shuyuan Zhao and Siyan Xue and Shangqin Tu and Shengbiao Meng and Tianshu Zhang and Tianwei Luo and Tianxiang Hao and Tianyu Tong and Wenkai Li and Wei Jia and Xiao Liu and Xiaohan Zhang and Xin Lyu and Xinyue Fan and Xuancheng Huang and Yanling Wang and Yadong Xue and Yanfeng Wang and Yanzi Wang and Yifan An and Yifan Du and Yiming Shi and Yiheng Huang and Yilin Niu and Yuan Wang and Yuanchang Yue and Yuchen Li and Yutao Zhang and Yuting Wang and Yu Wang and Yuxuan Zhang and Zhao Xue and Zhenyu Hou and Zhengxiao Du and Zihan Wang and Peng Zhang and Debing Liu and Bin Xu and Juanzi Li and Minlie Huang and Yuxiao Dong and Jie Tang},
      year={2025},
      eprint={2507.01006},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.01006},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>ladaapp/lada</title>
      <link>https://github.com/ladaapp/lada</link>
      <description>&lt;p&gt;Restore videos with pixelated/mosaic regions&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ladaapp/lada/main/packaging/flatpak/share/io.github.ladaapp.lada.png" alt="Lada Icon" style="display: block; width: 64px; height: 64px;" /&gt; &lt;br /&gt; Lada &lt;/h1&gt; 
&lt;p&gt;&lt;em&gt;Lada&lt;/em&gt; is a tool designed to recover pixelated adult videos (JAV). It helps restore the visual quality of such content, making it more enjoyable to watch.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Recover Pixelated Videos&lt;/strong&gt;: Restore pixelated or mosaic scenes in adult videos.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Watch/Export Videos&lt;/strong&gt;: Use either the CLI or GUI to watch or export your restored videos.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;GUI&lt;/h3&gt; 
&lt;p&gt;After opening a file, you can either watch the restored via in realtime or export it to a new file to watch it later:&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="assets/screenshot_gui_1_dark.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="assets/screenshot_gui_1_light.png" /&gt; 
 &lt;img alt="Screenshot showing video preview" src="https://raw.githubusercontent.com/ladaapp/lada/main/assets/screenshot_gui_1_dark.png" width="36%" /&gt; 
&lt;/picture&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="assets/screenshot_gui_2_dark.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="assets/screenshot_gui_2_light.png" /&gt; 
 &lt;img alt="Screenshot showing video export" src="https://raw.githubusercontent.com/ladaapp/lada/main/assets/screenshot_gui_2_dark.png" width="45%" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;Additional settings can be found in the left sidebar.&lt;/p&gt; 
&lt;h3&gt;CLI&lt;/h3&gt; 
&lt;p&gt;You can also use the command-line interface (CLI) to restore video(s):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;lada-cli --input &amp;lt;input video path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;img src="https://raw.githubusercontent.com/ladaapp/lada/main/assets/screenshot_cli_1.png" alt="screenshot showing video export" width="60%" /&gt; 
&lt;p&gt;For more information about additional options, use the &lt;code&gt;--help&lt;/code&gt; argument.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Lada writes the restored video to a temporary file before combining it with the audio stream from the original file and saving it to the selected destination. You can overwrite &lt;a href="https://docs.python.org/3/library/tempfile.html#tempfile.gettempdir"&gt;the default location&lt;/a&gt; by setting the &lt;code&gt;TMPDIR&lt;/code&gt; environment variable to another location of you choice.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Restoration options&lt;/h2&gt; 
&lt;p&gt;Lada utilizes specialized models for the two main steps of the processing pipeline: Detection and Restoration. You can choose different models for each task.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Mosaic Restoration Models:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;basicvsrpp-v1.2 (Default)&lt;/strong&gt; A general-purpose model trained on diverse video scenes. Delivers mostly good results.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;deepmosaics:&lt;/strong&gt; Restoration model from the project &lt;a href="https://github.com/HypoX64/DeepMosaics"&gt;DeepMosaics&lt;/a&gt;. Worse quality than basicvsrpp-v1.2.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The DeepMosaics model should be worse in most/all scenarios. It‚Äôs integrated because the DeepMosaics project is not maintained anymore, and I wanted to provide an easy way to try it out and compare.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Mosaic Detection Models:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;v3.1-fast (Default):&lt;/strong&gt; Fast and efficient.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v3.1-accurate:&lt;/strong&gt; Slightly more accurate than v3.1-fast, but slower. Not always better than v2.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v2:&lt;/strong&gt; Slowest of all but often provides better mosaic detection than v3.1-accurate but YMMV.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can configure the models in the side panel, or when using the CLI by specifying path and type of the model as arguments.&lt;/p&gt; 
&lt;h2&gt;Performance and hardware requirements&lt;/h2&gt; 
&lt;p&gt;Don't expect this to work perfectly, some scenes can be pretty good and close to the real thing. Other scenes can be rather meh and show worse artifacts than the original mosaics.&lt;/p&gt; 
&lt;p&gt;You'll need a GPU and some patience to run the app. If your card has at least 4-6GB of VRAM then it should work out of the box.&lt;/p&gt; 
&lt;p&gt;The CPU is used for encoding the restored video so shouldn't be too slow either. But you can also use GPU encoding and run both the restoration and encoding tasks on the GPU.&lt;/p&gt; 
&lt;p&gt;The app also needs quite a bit of RAM for buffering to increase throughput. For 1080p content you should be fine with 6-8GB RAM, 4K will need a lot more.&lt;/p&gt; 
&lt;p&gt;To watch the restored video in realtime you'll need a pretty beefy machine or you'll see the player pausing and buffering until next restored frames are computed. When viewing the video no encoding is done but it will use more additional RAM for buffering.&lt;/p&gt; 
&lt;p&gt;If your GPU is not fast enough to watch the video in real-time you'll have to export it first and watch it later with your favorite media player (available in GUI and CLI).&lt;/p&gt; 
&lt;p&gt;Technically running the app on your CPU is also supported but it will be so slow that it's not really practical.&lt;/p&gt; 
&lt;p&gt;Here are some speed performance numbers using Lada v0.7.0 on my available hardware to give you an idea what to expect (used libx264/CPU codec with default settings; RTX 3090 results are limited by CPU encoding and could be a lot faster by switching to NVENC/GPU encoder):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Video name&lt;/th&gt; 
   &lt;th&gt;Video description&lt;/th&gt; 
   &lt;th&gt;Video&lt;br /&gt;duration / resolution / FPS&lt;/th&gt; 
   &lt;th&gt;Lada&lt;br /&gt;runtime / FPS&lt;br /&gt;Nvidia RTX 3050&lt;br /&gt;(&lt;em&gt;Laptop GPU&lt;/em&gt;)&lt;/th&gt; 
   &lt;th&gt;Lada&lt;br /&gt;runtime / FPS&lt;br /&gt;Nvidia RTX 3090&lt;br /&gt;(Desktop GPU)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vid1&lt;/td&gt; 
   &lt;td&gt;multiple mosaic regions present on all frames&lt;/td&gt; 
   &lt;td&gt;1m30s / 10920x1080 / 30 FPS&lt;/td&gt; 
   &lt;td&gt;3m36s / 12 FPS&lt;/td&gt; 
   &lt;td&gt;1m33s / 30 FPS&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vid2&lt;/td&gt; 
   &lt;td&gt;single mosaic region present on all frames&lt;/td&gt; 
   &lt;td&gt;3m0s / 1920x1080 / 30 FPS&lt;/td&gt; 
   &lt;td&gt;4m11s / 21 FPS&lt;/td&gt; 
   &lt;td&gt;2m16s / 39 FPS&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vid3&lt;/td&gt; 
   &lt;td&gt;half of the video doesn't have any mosaics present,&lt;br /&gt;the other half mostly single mosaic per frame&lt;/td&gt; 
   &lt;td&gt;41m16s / 852x480 / 30 FPS&lt;/td&gt; 
   &lt;td&gt;26m30s / 46 FPS&lt;/td&gt; 
   &lt;td&gt;10m20s / 119 FPS&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Using Flatpak&lt;/h3&gt; 
&lt;p&gt;The easiest way to install the app (CLI and GUI) on Linux is via Flathub:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://flathub.org/apps/details/io.github.ladaapp.lada"&gt;&lt;img width="200" alt="Download from Flathub" src="https://flathub.org/api/badge?svg&amp;amp;locale=en" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The Flatpak only works with x86_64 CPUs and Nvidia/CUDA GPUs (Turing or newer: RTX 20xx up to including RTX 50xx). Ensure your NVIDIA GPU driver is up-to-date. It can also be used without a GPU but it will be very slow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] After installation you should find Lada in your application launcher to start the GUI. You can also run it via &lt;code&gt;flatpak run io.github.ladaapp.lada&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] When using the CLI via Flatpak we need to make the file/directory available by giving it permission to the file system so it can access the input/output files&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;flatpak run --filesystem=host --command=lada-cli io.github.ladaapp.lada --input &amp;lt;input video path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You may want to set an alias to make it easier to use&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;alias lada-cli="flatpak run --filesystem=host --command=lada-cli io.github.ladaapp.lada"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You could also give the filesystem permission permanently via &lt;a href="https://flathub.org/apps/com.github.tchx84.Flatseal"&gt;Flatseal&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you want to use the Post-export action feature to run a command/script after export has finished you'll need to give the Flatpak additional permissions. Add the &lt;code&gt;--talk-name=org.freedesktop.Flatpak&lt;/code&gt; permission and then run your command via &lt;code&gt;flatpak-spawn&lt;/code&gt;. For example: If the script you want to run is /home/user/myscript.sh then set custom command as &lt;code&gt;flatpak-spawn --host /home/user/myscript.sh&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you installed Lada from Flathub and drag-and-drop doesn't work, your file browser might not support &lt;a href="https://flatpak.github.io/xdg-desktop-portal/docs/doc-org.freedesktop.portal.FileTransfer.html"&gt;File Transfer Portal&lt;/a&gt;. You can fix this by:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Switching or updating your file browser to one that supports it.&lt;/li&gt; 
  &lt;li&gt;Granting the app filesystem permissions (e.g., via &lt;a href="https://flathub.org/apps/com.github.tchx84.Flatseal"&gt;Flatseal&lt;/a&gt; so it can read files directly).&lt;/li&gt; 
  &lt;li&gt;Using the 'Open' button to select the file instead of drag-and-drop.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Using Docker&lt;/h3&gt; 
&lt;p&gt;The app is also available via Docker (CLI only). You can get the image &lt;code&gt;ladaapp/lada&lt;/code&gt; from &lt;a href="https://hub.docker.com/r/ladaapp/lada"&gt;Docker Hub&lt;/a&gt; with this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker pull ladaapp/lada:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The Docker image only works with x86_64 CPUs and Nvidia/CUDA GPUs (Turing or newer: RTX 20xx up to including RTX 50xx). Ensure your NVIDIA GPU driver is up-to-date. It can also be used without a GPU but it will be very slow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Make sure that you have installed the &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html"&gt;NVIDIA Container Toolkit&lt;/a&gt; on your system so Docker can pass through the GPU&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] When using Docker you'll need to make the file/directory available to the container as well as the GPU:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;docker run --rm --gpus all --mount type=bind,src=&amp;lt;input video path&amp;gt;,dst=/mnt ladaapp/lada:latest --input "/mnt/&amp;lt;input video file&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you want to use hardware encoders like &lt;code&gt;hevc_nvenc&lt;/code&gt; you have to provide the container with &lt;code&gt;video&lt;/code&gt; capability.&lt;/p&gt; 
 &lt;p&gt;With docker run you can use &lt;code&gt;--gpus 'all,"capabilities=compute,video"'&lt;/code&gt;. Learn more &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Using Windows&lt;/h3&gt; 
&lt;p&gt;For Windows users, the app (CLI and GUI) is packaged as a standalone .7z archive file. You'll need &lt;a href="https://7-zip.org/"&gt;7-zip&lt;/a&gt; to unpack the files. It is recommended to validate the file after downloading. See the Tip below.&lt;/p&gt; 
&lt;p&gt;Get the latest release from the &lt;a href="https://codeberg.org/ladaapp/lada/releases"&gt;Releases Page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You'll find &lt;code&gt;lada.exe&lt;/code&gt; and &lt;code&gt;lada-cli.exe&lt;/code&gt; after extracting the archive.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The Windows release only works with x86_64 CPUs and Nvidia/CUDA GPUs (Turing or newer: RTX 20xx up to including RTX 50xx). Ensure your NVIDIA GPU driver is up-to-date. It can also be used without a GPU but it will be very slow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Be aware that the first start of lada.exe or lada-cli.exe could take a while before Windows Defender or your AV has scanned it. The next time you open the program it should start fast.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] It is recommended to compare the checksum of the downloaded file against the value you'll find in the release announcement. This makes sure that you got the correct and unaltered file, especially important if you got the file from an unofficial source.&lt;/p&gt; 
 &lt;p&gt;Calculate the checksum of the downloaded file on your computer and compare it against the &lt;code&gt;SHA256&lt;/code&gt; value you'll find in the release announcement. They must be the same!&lt;/p&gt; 
 &lt;p&gt;You can do this with Powershell &lt;code&gt;Get-FileHash /path/to/file.7z&lt;/code&gt; or &lt;a href="https://www.quickhash-gui.org/"&gt;QuickHash-GUI&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Alternative Installation Methods&lt;/h3&gt; 
&lt;p&gt;If the packages above don't work for you then you'll have to follow the &lt;a href="https://raw.githubusercontent.com/ladaapp/lada/main/#build"&gt;Build&lt;/a&gt; steps to set up the project.&lt;/p&gt; 
&lt;p&gt;Note that these instructions are mostly intended for developers to set up their environment to start working on the source code. But you should hopefully be able to follow the instructions even if you aren't a developer.&lt;/p&gt; 
&lt;p&gt;All packages currently only work with Nvidia cards (or CPU) but there have been reports that, following the Build instructions, newer Intel Xe GPUs and AMD ROCm-compatible cards work as well.&lt;/p&gt; 
&lt;p&gt;Reach out if you can support packaging the app for other operating systems or hardware.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;You can find the Lada project &lt;a href="https://github.com/ladaapp/lada"&gt;on GitHub&lt;/a&gt; and &lt;a href="https://codeberg.org/ladaapp/lada"&gt;on Codeberg&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The home of the project is on Codeberg. GitHub is set up only as a mirror so it's code will stay in sync with the main branch on Codeberg.&lt;/p&gt; 
&lt;p&gt;For contributing code, ideas or bug reports use &lt;a href="https://codeberg.org/ladaapp/lada/pulls"&gt;Pull requests&lt;/a&gt; and the &lt;a href="https://codeberg.org/ladaapp/lada/issues"&gt;Issue tracker&lt;/a&gt; on Codeberg.&lt;/p&gt; 
&lt;p&gt;If you want to help translating the app you can contribute to existing translations or set up a new language over at &lt;a href="https://translate.codeberg.org/projects/lada/lada/"&gt;Codeberg Translate&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://translate.codeberg.org/engage/lada/"&gt;&lt;img src="https://translate.codeberg.org/widget/lada/lada/multi-auto.svg?sanitize=true" alt="Translation status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;p&gt;New releases will be published on both &lt;a href="https://github.com/ladaapp/lada/releases"&gt;GitHub Releases&lt;/a&gt; and &lt;a href="https://codeberg.org/ladaapp/lada/releases"&gt;Codeberg Releases&lt;/a&gt;. You should get a notification about new releases if you star the project on either platform.&lt;/p&gt; 
&lt;h2&gt;Build&lt;/h2&gt; 
&lt;p&gt;If you want to start hacking on this project you'll need to install the app from source. Check out the detailed installation guides for &lt;a href="https://raw.githubusercontent.com/ladaapp/lada/main/docs/linux_install.md"&gt;Linux&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/ladaapp/lada/main/docs/windows_install.md"&gt;Windows&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Training and dataset creation&lt;/h2&gt; 
&lt;p&gt;For instructions on training your own models and datasets, refer to &lt;a href="https://raw.githubusercontent.com/ladaapp/lada/main/docs/training_and_dataset_creation.md"&gt;Training and dataset creation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Source code and models are licensed under AGPL-3.0. See the &lt;a href="https://raw.githubusercontent.com/ladaapp/lada/main/LICENSE.md"&gt;LICENSE.md&lt;/a&gt; file for full details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;This project builds upon work done by these fantastic individuals and projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HypoX64/DeepMosaics"&gt;DeepMosaics&lt;/a&gt;: Provided code for mosaic dataset creation. Also inspired me to start this project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ckkelvinchan.github.io/projects/BasicVSR++"&gt;BasicVSR++&lt;/a&gt; / &lt;a href="https://github.com/open-mmlab/mmagic"&gt;MMagic&lt;/a&gt;: Used as the base model for mosaic removal.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ultralytics/ultralytics"&gt;YOLO/Ultralytics&lt;/a&gt;: Used for training mosaic and NSFW detection models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/VQAssessment/DOVER"&gt;DOVER&lt;/a&gt;: Used to assess video quality of created clips during the dataset creation process to filter out low-quality clips.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tgenlis83/dnn-watermark"&gt;DNN Watermark / PITA Dataset&lt;/a&gt;: Used most of its code for creating a watermark detection dataset used to filter out scenes obstructed by text/watermarks/logos.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/notAI-tech/NudeNet/"&gt;NudeNet&lt;/a&gt;: Used as an additional NSFW classifier to filter out false positives by our own NSFW segmentation model&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/twitter/twemoji"&gt;Twitter Emoji&lt;/a&gt;: Provided eggplant emoji as base for the app icon.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xinntao/Real-ESRGAN"&gt;Real-ESRGAN&lt;/a&gt;: Used their image degradation model design for our mosaic detection model degradation pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hnuzhy/BPJDet"&gt;BPJDet&lt;/a&gt;: Model for detecting human body and head. Used for creating SFW mosaics so that mosaic detection model can be trained so skip such material.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Star-Clouds/CenterFace"&gt;CenterFace&lt;/a&gt;: Model for detecting human faces. Used for creating SFW mosaics so that mosaic detection model can be trained so skip such material.&lt;/li&gt; 
 &lt;li&gt;PyTorch, FFmpeg, GStreamer, GTK and &lt;a href="https://xkcd.com/2347/"&gt;all other folks building our ecosystem&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>google/adk-samples</title>
      <link>https://github.com/google/adk-samples</link>
      <description>&lt;p&gt;A collection of sample agents built with Agent Development Kit (ADK)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agent Development Kit (ADK) Samples&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://github.com/google/adk-docs/raw/main/docs/assets/agent-development-kit.png" alt="Agent Development Kit Logo" width="150" /&gt; 
&lt;p&gt;Welcome to the ADK Sample Agents repository! This collection provides ready-to-use agents built on top of the &lt;a href="https://google.github.io/adk-docs/"&gt;Agent Development Kit&lt;/a&gt;, designed to accelerate your development process. These agents cover a range of common use cases and complexities, from simple conversational bots to complex multi-agent workflows.&lt;/p&gt; 
&lt;h2&gt;‚ú® Getting Started&lt;/h2&gt; 
&lt;p&gt;This repo contains ADK sample agents for &lt;strong&gt;Python&lt;/strong&gt;, &lt;strong&gt;Go&lt;/strong&gt; and &lt;strong&gt;Java.&lt;/strong&gt; Navigate to the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/python/"&gt;Python&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/go/"&gt;Go&lt;/a&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/java/"&gt;Java&lt;/a&gt;&lt;/strong&gt; subfolders to see language-specific setup instructions, and learn more about the available sample agents.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The agents in this repository are built using the &lt;strong&gt;Agent Development Kit (ADK)&lt;/strong&gt;. Before you can run any of the samples, you must have the ADK installed. For instructions, please refer to the &lt;a href="https://google.github.io/adk-docs/get-started"&gt;&lt;strong&gt;ADK Installation Guide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To learn more, check out the &lt;a href="https://google.github.io/adk-docs/"&gt;ADK Documentation&lt;/a&gt;, and the GitHub repositories for each language:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/adk-python"&gt;ADK Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/adk-go"&gt;ADK Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/adk-java"&gt;ADK Java&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üå≥ Repository Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;‚îú‚îÄ‚îÄ go
‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ agents
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ llm-auditor
‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ java
‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ agents
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ software-bug-assistant
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ time-series-forecasting
‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ python
‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ agents
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ academic-research
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ antom-payment
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ blog-writer
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ brand-search-optimization
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ camel
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ customer-service
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ data-engineering
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ data-science
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ financial-advisor
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ fomc-research
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini-fullstack
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deep-search
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ google-trends-agent
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ image-scoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm-auditor
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ machine-learning-engineering
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ marketing-agency
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medical-pre-authorization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ personalized-shopping
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ plumber-data-engineering-assistant
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RAG
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ realtime-conversational-agent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ safety-plugins
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ short-movie-agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ software-bug-assistant
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ travel-concierge
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ README.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ÑπÔ∏è Getting help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or if you found any problems with this repository, please report through &lt;a href="https://github.com/google/adk-samples/issues"&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether it's bug reports, feature requests, documentation improvements, or code contributions, please see our &lt;a href="https://github.com/google/adk-samples/raw/main/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing Guidelines&lt;/strong&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://github.com/google/adk-samples/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Disclaimers&lt;/h2&gt; 
&lt;p&gt;This is not an officially supported Google product. This project is not eligible for the &lt;a href="https://bughunters.google.com/open-source-security"&gt;Google Open Source Software Vulnerability Rewards Program&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is intended for demonstration purposes only. It is not intended for use in a production environment.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>