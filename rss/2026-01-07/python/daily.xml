<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Tue, 06 Jan 2026 01:38:50 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>bytedance/Dolphin</title>
      <link>https://github.com/bytedance/Dolphin</link>
      <description>&lt;p&gt;The official repo for ‚ÄúDolphin: Document Image Parsing via Heterogeneous Anchor Prompting‚Äù, ACL, 2025.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/dolphin.png" width="300" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://arxiv.org/abs/2505.14059"&gt; &lt;img src="https://img.shields.io/badge/Paper-arXiv-red" /&gt; &lt;/a&gt; 
 &lt;a href="https://huggingface.co/ByteDance/Dolphin-v2"&gt; &lt;img src="https://img.shields.io/badge/HuggingFace-Dolphin-yellow" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/bytedance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/Code-Github-green" /&gt; &lt;/a&gt; 
 &lt;a href="https://opensource.org/licenses/MIT"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-lightgray" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/demo.gif" width="800" /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting&lt;/h1&gt; 
&lt;p&gt;Dolphin-v2 is an enhanced universal document parsing model that substantially improves upon the original Dolphin. It seamlessly handles any document type‚Äîwhether digital-born or photographed‚Äîthrough a document-type-aware two-stage architecture with scalable anchor prompting.&lt;/p&gt; 
&lt;h2&gt;üìë Overview&lt;/h2&gt; 
&lt;p&gt;Document image parsing is challenging due to diverse document types and complexly intertwined elements such as text paragraphs, figures, formulas, tables, and code blocks. Dolphin-v2 addresses these challenges through a document-type-aware two-stage approach:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Stage 1&lt;/strong&gt;: Document type classification (digital vs. photographed) + layout analysis with reading order prediction&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß© Stage 2&lt;/strong&gt;: Hybrid parsing strategy - holistic parsing for photographed documents, parallel element-wise parsing for digital documents&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/framework.png" width="680" /&gt; 
&lt;/div&gt; 
&lt;p&gt;Dolphin achieves promising performance across diverse page-level and element-level parsing tasks while ensuring superior efficiency through its lightweight architecture and parallel parsing mechanism.&lt;/p&gt; 
&lt;!-- ## üöÄ Demo
Try our demo on [Demo-Dolphin](https://huggingface.co/spaces/ByteDance/Dolphin). --&gt; 
&lt;h2&gt;üìÖ Changelog&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.12.12&lt;/strong&gt; Released &lt;em&gt;Dolphin-v2&lt;/em&gt; model. Upgraded to 3B parameters with 21-element detection, attribute field extraction, dedicated formula/code parsing, and robust photographed document parsing. (Dolphin-1.5 moved to &lt;a href="https://github.com/bytedance/Dolphin/tree/v1.5"&gt;v1.5 branch&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.10.16&lt;/strong&gt; Released &lt;em&gt;Dolphin-1.5&lt;/em&gt; model. While maintaining the lightweight 0.3B architecture, this version achieves significant parsing improvements. (Dolphin 1.0 moved to &lt;a href="https://github.com/bytedance/Dolphin/tree/v1.0"&gt;v1.0 branch&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.07.10&lt;/strong&gt; Released the &lt;em&gt;Fox-Page Benchmark&lt;/em&gt;, a manually refined subset of the original &lt;a href="https://github.com/ucaslcl/Fox"&gt;Fox dataset&lt;/a&gt;. Download via: &lt;a href="https://pan.baidu.com/share/init?surl=t746ULp6iU5bUraVrPlMSw&amp;amp;pwd=fox1"&gt;Baidu Yun&lt;/a&gt; | &lt;a href="https://drive.google.com/file/d/1yZQZqI34QCqvhB4Tmdl3X_XEvYvQyP0q/view?usp=sharing"&gt;Google Drive&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.06.30&lt;/strong&gt; Added &lt;a href="https://github.com/bytedance/Dolphin/raw/master/deployment/tensorrt_llm/ReadMe.md"&gt;TensorRT-LLM support&lt;/a&gt; for accelerated inferenceÔºÅ&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.06.27&lt;/strong&gt; Added &lt;a href="https://github.com/bytedance/Dolphin/raw/master/deployment/vllm/ReadMe.md"&gt;vLLM support&lt;/a&gt; for accelerated inferenceÔºÅ&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.06.13&lt;/strong&gt; Added multi-page PDF document parsing capability.&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.05.21&lt;/strong&gt; Our demo is released at &lt;a href="http://115.190.42.15:8888/dolphin/"&gt;link&lt;/a&gt;. Check it out!&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.05.20&lt;/strong&gt; The pretrained model and inference code of Dolphin are released.&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.05.16&lt;/strong&gt; Our paper has been accepted by ACL 2025. Paper link: &lt;a href="https://arxiv.org/abs/2505.14059"&gt;arXiv&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìà Performance&lt;/h2&gt; 
&lt;table style="width:90%; border-collapse: collapse; text-align: center;"&gt; 
 &lt;caption&gt;
  Comprehensive evaluation of document parsing on OmniDocBench (v1.5)
 &lt;/caption&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="text-align: center !important;"&gt;Model&lt;/th&gt; 
   &lt;th style="text-align: center !important;"&gt;Size&lt;/th&gt; 
   &lt;th style="text-align: center !important;"&gt;Overall‚Üë&lt;/th&gt; 
   &lt;th style="text-align: center !important;"&gt;Text&lt;sup&gt;Edit&lt;/sup&gt;‚Üì&lt;/th&gt; 
   &lt;th style="text-align: center !important;"&gt;Formula&lt;sup&gt;CDM&lt;/sup&gt;‚Üë&lt;/th&gt; 
   &lt;th style="text-align: center !important;"&gt;Table&lt;sup&gt;TEDS&lt;/sup&gt;‚Üë&lt;/th&gt; 
   &lt;th style="text-align: center !important;"&gt;Table&lt;sup&gt;TEDS-S&lt;/sup&gt;‚Üë&lt;/th&gt; 
   &lt;th style="text-align: center !important;"&gt;Read Order&lt;sup&gt;Edit&lt;/sup&gt;‚Üì&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dolphin&lt;/td&gt; 
   &lt;td&gt;0.3B&lt;/td&gt; 
   &lt;td&gt;74.67&lt;/td&gt; 
   &lt;td&gt;0.125&lt;/td&gt; 
   &lt;td&gt;67.85&lt;/td&gt; 
   &lt;td&gt;68.70&lt;/td&gt; 
   &lt;td&gt;77.77&lt;/td&gt; 
   &lt;td&gt;0.124&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dolphin-1.5&lt;/td&gt; 
   &lt;td&gt;0.3B&lt;/td&gt; 
   &lt;td&gt;85.06&lt;/td&gt; 
   &lt;td&gt;0.085&lt;/td&gt; 
   &lt;td&gt;79.44&lt;/td&gt; 
   &lt;td&gt;84.25&lt;/td&gt; 
   &lt;td&gt;88.06&lt;/td&gt; 
   &lt;td&gt;0.071&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dolphin-v2&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;89.78&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.054&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;87.63&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;87.02&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;90.48&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.054&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üõ†Ô∏è Installation&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ByteDance/Dolphin.git
cd Dolphin
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install the dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Download the pre-trained models of &lt;em&gt;Dolphin-v2&lt;/em&gt;:&lt;/p&gt; &lt;p&gt;Visit our Huggingface &lt;a href="https://huggingface.co/ByteDance/Dolphin-v2"&gt;model card&lt;/a&gt;, or download model by:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Download the model from Hugging Face Hub
git lfs install
git clone https://huggingface.co/ByteDance/Dolphin-v2 ./hf_model
# Or use the Hugging Face CLI
pip install huggingface_hub
huggingface-cli download ByteDance/Dolphin-v2 --local-dir ./hf_model
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;‚ö° Inference&lt;/h2&gt; 
&lt;p&gt;Dolphin provides two inference frameworks with support for two parsing granularities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Page-level Parsing&lt;/strong&gt;: Parse the entire document page into a structured JSON and Markdown format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Element-level Parsing&lt;/strong&gt;: Parse individual document elements (text, table, formula)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìÑ Page-level Parsing&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single document image
python demo_page.py --model_path ./hf_model --save_dir ./results \
    --input_path ./demo/page_imgs/page_1.png 

# Process a single document pdf
python demo_page.py --model_path ./hf_model --save_dir ./results \
    --input_path ./demo/page_imgs/page_6.pdf 

# Process all documents in a directory
python demo_page.py --model_path ./hf_model --save_dir ./results \
    --input_path ./demo/page_imgs 

# Process with custom batch size for parallel element decoding
python demo_page.py --model_path ./hf_model --save_dir ./results \
    --input_path ./demo/page_imgs \
    --max_batch_size 8
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üß© Element-level Parsing&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process element images (specify element_type: table, formula, text, or code)
python demo_element.py --model_path ./hf_model --save_dir ./results \
    --input_path  \
    --element_type [table|formula|text|code]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üé® Layout Parsing&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single document image
python demo_layout.py --model_path ./hf_model --save_dir ./results \
    --input_path ./demo/page_imgs/page_1.png \
    
# Process a single PDF document
python demo_layout.py --model_path ./hf_model --save_dir ./results \
    --input_path ./demo/page_imgs/page_6.pdf \

# Process all documents in a directory
python demo_layout.py --model_path ./hf_model --save_dir ./results \
    --input_path ./demo/page_imgs 
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üåü Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîÑ Two-stage analyze-then-parse approach based on a single VLM&lt;/li&gt; 
 &lt;li&gt;üìä Promising performance on document parsing tasks&lt;/li&gt; 
 &lt;li&gt;üîç Natural reading order element sequence generation&lt;/li&gt; 
 &lt;li&gt;üß© Heterogeneous anchor prompting for different document elements&lt;/li&gt; 
 &lt;li&gt;‚è±Ô∏è Efficient parallel parsing mechanism&lt;/li&gt; 
 &lt;li&gt;ü§ó Support for Hugging Face Transformers for easier integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÆ Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Call for Bad Cases:&lt;/strong&gt; If you have encountered any cases where the model performs poorly, we would greatly appreciate it if you could share them in the issue. We are continuously working to optimize and improve the model.&lt;/p&gt; 
&lt;h2&gt;üíñ Acknowledgement&lt;/h2&gt; 
&lt;p&gt;We would like to acknowledge the following open-source projects that provided inspiration and reference for this work:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/OmniDocBench"&gt;OmniDocBench&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/clovaai/donut/"&gt;Donut&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebookresearch/nougat"&gt;Nougat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Ucas-HaoranWei/GOT-OCR2.0"&gt;GOT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/MinerU/tree/master"&gt;MinerU&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Swin-Transformer"&gt;Swin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/transformers"&gt;Hugging Face Transformers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìù Citation&lt;/h2&gt; 
&lt;p&gt;If you find this code useful for your research, please use the following BibTeX entry.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{feng2025dolphin,
  title={Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting},
  author={Feng, Hao and Wei, Shu and Fei, Xiang and Shi, Wei and Han, Yingdong and Liao, Lei and Lu, Jinghui and Wu, Binghong and Liu, Qi and Lin, Chunhui and others},
  journal={arXiv preprint arXiv:2505.14059},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#bytedance/Dolphin&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=bytedance/Dolphin&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Financial data platform for analysts, quants and AI agents.&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/odp-light.svg?raw=true#gh-light-mode-only" alt="Open Data Platform by OpenBB logo" width="600" /&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/odp-dark.svg?raw=true#gh-dark-mode-only" alt="Open Data Platform by OpenBB logo" width="600" /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://x.com/openbb_finance"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/xPHTuHCmuV"&gt;&lt;img src="https://img.shields.io/discord/831165782750789672" alt="Discord Shield" /&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers" /&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/OpenBB-finance/OpenBB"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" height="20" /&gt; &lt;/a&gt; &lt;a target="_blank" href="https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/openbb/"&gt;&lt;img src="https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package" alt="PyPI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Open Data Platform by OpenBB (ODP) is the open-source toolset that helps data engineers integrate proprietary, licensed, and public data sources into downstream applications like AI copilots and research dashboards.&lt;/p&gt; 
&lt;p&gt;ODP operates as the "connect once, consume everywhere" infrastructure layer that consolidates and exposes data to multiple surfaces at once: Python environments for quants, OpenBB Workspace and Excel for analysts, MCP servers for AI agents, and REST APIs for other applications.&lt;/p&gt; 
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/70b971ef-7a7e-486e-b5ae-1cc602f2162c.png" alt="Logo" width="1000" /&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openbb import obb
output = obb.equity.price.historical("AAPL")
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href="https://docs.openbb.co/python/reference"&gt;https://docs.openbb.co/python/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the Open Data Platform provides the open-source data integration foundation, &lt;strong&gt;OpenBB Workspace&lt;/strong&gt; offers the enterprise UI for analysts to visualize datasets and leverage AI agents. The platform's "connect once, consume everywhere" architecture enables seamless integration between the two.&lt;/p&gt; 
&lt;p&gt;You can find OpenBB Workspace at &lt;a href="https://pro.openbb.co"&gt;https://pro.openbb.co&lt;/a&gt;. &lt;a href="https://pro.openbb.co"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png" alt="Logo" width="1000" /&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href="https://docs.openbb.co/workspace"&gt;docs&lt;/a&gt; or &lt;a href="https://github.com/OpenBB-finance/backends-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href="https://github.com/OpenBB-finance/agents-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating Open Data Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run an ODP backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "openbb[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate the ODP Backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href="https://pro.openbb.co/"&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069" alt="CleanShot 2025-05-17 at 09 51 56@2x" /&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the "Apps" tab&lt;/li&gt; 
 &lt;li&gt;Click on "Connect backend"&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: Open Data Platform URL: &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on "Test". You should get a "Test successful" with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on "Add".&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed="closed"&gt; 
 &lt;summary&gt;&lt;h2 style="display: inline-block"&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts"&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The ODP Python Package can be installed from &lt;a href="https://pypi.org/project/openbb/"&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href="https://docs.openbb.co/python/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;ODP CLI installation&lt;/h3&gt; 
&lt;p&gt;The ODP CLI is a command-line interface that allows you to access the ODP directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href="https://docs.openbb.co/cli/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now ‚≠êÔ∏è)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href="https://docs.openbb.co/python/developer"&gt;Developer Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn't exist already &lt;a href="https://github.com/OpenBB-finance/OpenBB/issues"&gt;among the existing issues&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D"&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D"&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href="https://openbb.co/discord"&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href="https://openbb.co/links"&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the Open Data Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href="https://openbb.co/links"&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href="https://openbb.co/open"&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB" width="800" /&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>langgenius/dify</title>
      <link>https://github.com/langgenius/dify</link>
      <description>&lt;p&gt;Production-ready platform for agentic workflow development.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/langgenius/dify/main/images/GitHub_README_if.png" alt="cover-v5-optimized" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; üìå &lt;a href="https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast"&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://cloud.dify.ai"&gt;Dify Cloud&lt;/a&gt; ¬∑ &lt;a href="https://docs.dify.ai/getting-started/install-self-hosted"&gt;Self-hosting&lt;/a&gt; ¬∑ &lt;a href="https://docs.dify.ai"&gt;Documentation&lt;/a&gt; ¬∑ &lt;a href="https://dify.ai/pricing"&gt;Dify edition overview&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://dify.ai" target="_blank"&gt; &lt;img alt="Static Badge" src="https://img.shields.io/badge/Product-F04438" /&gt;&lt;/a&gt; &lt;a href="https://dify.ai/pricing" target="_blank"&gt; &lt;img alt="Static Badge" src="https://img.shields.io/badge/free-pricing?logo=free&amp;amp;color=%20%23155EEF&amp;amp;label=pricing&amp;amp;labelColor=%20%23528bff" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/FngNHpbcY7" target="_blank"&gt; &lt;img src="https://img.shields.io/discord/1082486657678311454?logo=discord&amp;amp;labelColor=%20%235462eb&amp;amp;logoColor=%20%23f5f5f5&amp;amp;color=%20%235462eb" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://reddit.com/r/difyai" target="_blank"&gt; &lt;img src="https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;amp;logo=reddit&amp;amp;label=r%2Fdifyai&amp;amp;labelColor=white" alt="join Reddit" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=dify_ai" target="_blank"&gt; &lt;img src="https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;amp;color=%20%23f5f5f5" alt="follow on X(Twitter)" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/langgenius/" target="_blank"&gt; &lt;img src="https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;amp;logoColor=fff" alt="follow on LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/u/langgenius" target="_blank"&gt; &lt;img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;amp;color=%20%23f79009" /&gt;&lt;/a&gt; &lt;a href="https://github.com/langgenius/dify/graphs/commit-activity" target="_blank"&gt; &lt;img alt="Commits last month" src="https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;amp;color=%20%2312b76a" /&gt;&lt;/a&gt; &lt;a href="https://github.com/langgenius/dify/" target="_blank"&gt; &lt;img alt="Issues closed" src="https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;amp;label=issues%20closed&amp;amp;labelColor=%20%237d89b0&amp;amp;color=%20%235d6b98" /&gt;&lt;/a&gt; &lt;a href="https://github.com/langgenius/dify/discussions/" target="_blank"&gt; &lt;img alt="Discussion posts" src="https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;amp;color=%20%237a5af8" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/langgenius-dify" target="_blank"&gt; &lt;img alt="LFX Health Score" src="https://insights.linuxfoundation.org/api/badge/health-score?project=langgenius-dify" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/langgenius-dify" target="_blank"&gt; &lt;img alt="LFX Contributors" src="https://insights.linuxfoundation.org/api/badge/contributors?project=langgenius-dify" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/langgenius-dify" target="_blank"&gt; &lt;img alt="LFX Active Contributors" src="https://insights.linuxfoundation.org/api/badge/active-contributors?project=langgenius-dify" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/README.md"&gt;&lt;img alt="README in English" src="https://img.shields.io/badge/English-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/zh-TW/README.md"&gt;&lt;img alt="ÁπÅÈ´î‰∏≠ÊñáÊñá‰ª∂" src="https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/zh-CN/README.md"&gt;&lt;img alt="ÁÆÄ‰Ωì‰∏≠ÊñáÊñá‰ª∂" src="https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/ja-JP/README.md"&gt;&lt;img alt="Êó•Êú¨Ë™û„ÅÆREADME" src="https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/es-ES/README.md"&gt;&lt;img alt="README en Espa√±ol" src="https://img.shields.io/badge/Espa√±ol-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/fr-FR/README.md"&gt;&lt;img alt="README en Fran√ßais" src="https://img.shields.io/badge/Fran√ßais-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/tlh/README.md"&gt;&lt;img alt="README tlhIngan Hol" src="https://img.shields.io/badge/Klingon-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/ko-KR/README.md"&gt;&lt;img alt="README in Korean" src="https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/ar-SA/README.md"&gt;&lt;img alt="README ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" src="https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/tr-TR/README.md"&gt;&lt;img alt="T√ºrk√ße README" src="https://img.shields.io/badge/T√ºrk√ße-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/vi-VN/README.md"&gt;&lt;img alt="README Ti·∫øng Vi·ªát" src="https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/de-DE/README.md"&gt;&lt;img alt="README in Deutsch" src="https://img.shields.io/badge/German-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/bn-BD/README.md"&gt;&lt;img alt="README in ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ" src="https://img.shields.io/badge/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ-d9d9d9" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Dify is an open-source platform for developing LLM applications. Its intuitive interface combines agentic AI workflows, RAG pipelines, agent capabilities, model management, observability features, and more‚Äîallowing you to quickly move from prototype to production.&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Before installing Dify, make sure your machine meets the following minimum system requirements:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CPU &amp;gt;= 2 Core&lt;/li&gt; 
  &lt;li&gt;RAM &amp;gt;= 4 GiB&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;p&gt;The easiest way to start the Dify server is through &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docker/docker-compose.yaml"&gt;Docker Compose&lt;/a&gt;. Before running Dify with the following commands, make sure that &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt; and &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt; are installed on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd dify
cd docker
cp .env.example .env
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After running, you can access the Dify dashboard in your browser at &lt;a href="http://localhost/install"&gt;http://localhost/install&lt;/a&gt; and start the initialization process.&lt;/p&gt; 
&lt;h4&gt;Seeking help&lt;/h4&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://docs.dify.ai/getting-started/install-self-hosted/faqs"&gt;FAQ&lt;/a&gt; if you encounter problems setting up Dify. Reach out to &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/#community--contact"&gt;the community and us&lt;/a&gt; if you are still having issues.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you'd like to contribute to Dify or do additional development, refer to our &lt;a href="https://docs.dify.ai/getting-started/install-self-hosted/local-source-code"&gt;guide to deploying from source code&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Key features&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Workflow&lt;/strong&gt;: Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Comprehensive model support&lt;/strong&gt;: Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found &lt;a href="https://docs.dify.ai/getting-started/readme/model-providers"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3" alt="providers-v5" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. Prompt IDE&lt;/strong&gt;: Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. RAG Pipeline&lt;/strong&gt;: Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5. Agent capabilities&lt;/strong&gt;: You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL¬∑E, Stable Diffusion and WolframAlpha.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6. LLMOps&lt;/strong&gt;: Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;7. Backend-as-a-Service&lt;/strong&gt;: All of Dify's offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.&lt;/p&gt; 
&lt;h2&gt;Using Dify&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cloud &lt;br /&gt;&lt;/strong&gt; We host a &lt;a href="https://dify.ai"&gt;Dify Cloud&lt;/a&gt; service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self-hosting Dify Community Edition&lt;br /&gt;&lt;/strong&gt; Quickly get Dify running in your environment with this &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/#quick-start"&gt;starter guide&lt;/a&gt;. Use our &lt;a href="https://docs.dify.ai"&gt;documentation&lt;/a&gt; for further references and more in-depth instructions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dify for enterprise / organizations&lt;br /&gt;&lt;/strong&gt; We provide additional enterprise-centric features. &lt;a href="mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry"&gt;Send us an email&lt;/a&gt; to discuss your enterprise needs. &lt;br /&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;For startups and small businesses using AWS, check out &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6"&gt;Dify Premium on AWS Marketplace&lt;/a&gt; and deploy it to your own AWS VPC with one click. It's an affordable AMI offering with the option to create apps with custom logo and branding.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Staying ahead&lt;/h2&gt; 
&lt;p&gt;Star Dify on GitHub and be instantly notified of new releases.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4" alt="star-us" /&gt;&lt;/p&gt; 
&lt;h2&gt;Advanced Setup&lt;/h2&gt; 
&lt;h3&gt;Custom configurations&lt;/h3&gt; 
&lt;p&gt;If you need to customize the configuration, please refer to the comments in our &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docker/.env.example"&gt;.env.example&lt;/a&gt; file and update the corresponding values in your &lt;code&gt;.env&lt;/code&gt; file. Additionally, you might need to make adjustments to the &lt;code&gt;docker-compose.yaml&lt;/code&gt; file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run &lt;code&gt;docker-compose up -d&lt;/code&gt;. You can find the full list of available environment variables &lt;a href="https://docs.dify.ai/getting-started/install-self-hosted/environments"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Customizing Suggested Questions&lt;/h4&gt; 
&lt;p&gt;You can now customize the "Suggested Questions After Answer" feature to better fit your use case. For example, to generate longer, more technical questions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# In your .env file
SUGGESTED_QUESTIONS_PROMPT='Please help me predict the five most likely technical follow-up questions a developer would ask. Focus on implementation details, best practices, and architecture considerations. Keep each question between 40-60 characters. Output must be JSON array: ["question1","question2","question3","question4","question5"]'
SUGGESTED_QUESTIONS_MAX_TOKENS=512
SUGGESTED_QUESTIONS_TEMPERATURE=0.3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/suggested-questions-configuration.md"&gt;Suggested Questions Configuration Guide&lt;/a&gt; for detailed examples and usage instructions.&lt;/p&gt; 
&lt;h3&gt;Metrics Monitoring with Grafana&lt;/h3&gt; 
&lt;p&gt;Import the dashboard to Grafana, using Dify's PostgreSQL database as data source, to monitor metrics in granularity of apps, tenants, messages, and more.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bowenliang123/dify-grafana-dashboard"&gt;Grafana Dashboard by @bowenliang123&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deployment with Kubernetes&lt;/h3&gt; 
&lt;p&gt;If you'd like to configure a highly-available setup, there are community-contributed &lt;a href="https://helm.sh/"&gt;Helm Charts&lt;/a&gt; and YAML files which allow Dify to be deployed on Kubernetes.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/douban/charts/tree/master/charts/dify"&gt;Helm Chart by @LeoQuote&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BorisPolonsky/dify-helm"&gt;Helm Chart by @BorisPolonsky&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/magicsong/ai-charts"&gt;Helm Chart by @magicsong&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Winson-030/dify-kubernetes"&gt;YAML file by @Winson-030&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wyy-holding/dify-k8s"&gt;YAML file by @wyy-holding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Zhoneym/DifyAI-Kubernetes"&gt;üöÄ NEW! YAML files (Supports Dify v1.6.0) by @Zhoneym&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using Terraform for Deployment&lt;/h4&gt; 
&lt;p&gt;Deploy Dify to Cloud Platform with a single click using &lt;a href="https://www.terraform.io/"&gt;terraform&lt;/a&gt;&lt;/p&gt; 
&lt;h5&gt;Azure Global&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nikawang/dify-azure-terraform"&gt;Azure Terraform by @nikawang&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Google Cloud&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DeNA/dify-google-cloud-terraform"&gt;Google Cloud Terraform by @sotazum&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using AWS CDK for Deployment&lt;/h4&gt; 
&lt;p&gt;Deploy Dify to AWS with &lt;a href="https://aws.amazon.com/cdk/"&gt;CDK&lt;/a&gt;&lt;/p&gt; 
&lt;h5&gt;AWS&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/solution-for-deploying-dify-on-aws"&gt;AWS CDK by @KevinZhao (EKS based)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/dify-self-hosted-on-aws"&gt;AWS CDK by @tmokmss (ECS based)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using Alibaba Cloud Computing Nest&lt;/h4&gt; 
&lt;p&gt;Quickly deploy Dify to Alibaba cloud with &lt;a href="https://computenest.console.aliyun.com/service/instance/create/default?type=user&amp;amp;ServiceName=Dify%E7%A4%BE%E5%8C%BA%E7%89%88"&gt;Alibaba Cloud Computing Nest&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Alibaba Cloud Data Management&lt;/h4&gt; 
&lt;p&gt;One-Click deploy Dify to Alibaba Cloud with &lt;a href="https://www.alibabacloud.com/help/en/dms/dify-in-invitational-preview/"&gt;Alibaba Cloud Data Management&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Deploy to AKS with Azure Devops Pipeline&lt;/h4&gt; 
&lt;p&gt;One-Click deploy Dify to AKS with &lt;a href="https://github.com/Ruiruiz30/Dify-helm-chart-AKS"&gt;Azure Devops Pipeline Helm Chart by @LeoZhang&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;For those who'd like to contribute code, see our &lt;a href="https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;. At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the &lt;a href="https://github.com/langgenius/dify/raw/main/web/i18n-config/README.md"&gt;i18n README&lt;/a&gt; for more information, and leave us a comment in the &lt;code&gt;global-users&lt;/code&gt; channel of our &lt;a href="https://discord.gg/8Tpq4AcN9c"&gt;Discord Community Server&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Community &amp;amp; contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify/discussions"&gt;GitHub Discussion&lt;/a&gt;. Best for: sharing feedback and asking questions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify/issues"&gt;GitHub Issues&lt;/a&gt;. Best for: bugs you encounter using Dify.AI, and feature proposals. See our &lt;a href="https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/FngNHpbcY7"&gt;Discord&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/dify_ai"&gt;X(Twitter)&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Contributors&lt;/strong&gt;&lt;/p&gt; 
&lt;a href="https://github.com/langgenius/dify/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=langgenius/dify" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#langgenius/dify&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=langgenius/dify&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Security disclosure&lt;/h2&gt; 
&lt;p&gt;To protect your privacy, please avoid posting security issues on GitHub. Instead, report issues to &lt;a href="mailto:security@dify.ai"&gt;security@dify.ai&lt;/a&gt;, and our team will respond with detailed answer.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/LICENSE"&gt;Dify Open Source License&lt;/a&gt;, based on Apache 2.0 with additional conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>virattt/ai-hedge-fund</title>
      <link>https://github.com/virattt/ai-hedge-fund</link>
      <description>&lt;p&gt;An AI Hedge Fund Team&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Hedge Fund&lt;/h1&gt; 
&lt;p&gt;This is a proof of concept for an AI-powered hedge fund. The goal of this project is to explore the use of AI to make trading decisions. This project is for &lt;strong&gt;educational&lt;/strong&gt; purposes only and is not intended for real trading or investment.&lt;/p&gt; 
&lt;p&gt;This system employs several agents working together:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation&lt;/li&gt; 
 &lt;li&gt;Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety&lt;/li&gt; 
 &lt;li&gt;Bill Ackman Agent - An activist investor, takes bold positions and pushes for change&lt;/li&gt; 
 &lt;li&gt;Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption&lt;/li&gt; 
 &lt;li&gt;Charlie Munger Agent - Warren Buffett's partner, only buys wonderful businesses at fair prices&lt;/li&gt; 
 &lt;li&gt;Michael Burry Agent - The Big Short contrarian who hunts for deep value&lt;/li&gt; 
 &lt;li&gt;Mohnish Pabrai Agent - The Dhandho investor, who looks for doubles at low risk&lt;/li&gt; 
 &lt;li&gt;Peter Lynch Agent - Practical investor who seeks "ten-baggers" in everyday businesses&lt;/li&gt; 
 &lt;li&gt;Phil Fisher Agent - Meticulous growth investor who uses deep "scuttlebutt" research&lt;/li&gt; 
 &lt;li&gt;Rakesh Jhunjhunwala Agent - The Big Bull of India&lt;/li&gt; 
 &lt;li&gt;Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential&lt;/li&gt; 
 &lt;li&gt;Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price&lt;/li&gt; 
 &lt;li&gt;Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Sentiment Agent - Analyzes market sentiment and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Fundamentals Agent - Analyzes fundamental data and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Technicals Agent - Analyzes technical indicators and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Risk Manager - Calculates risk metrics and sets position limits&lt;/li&gt; 
 &lt;li&gt;Portfolio Manager - Makes final trading decisions and generates orders&lt;/li&gt; 
&lt;/ol&gt; 
&lt;img width="1042" alt="Screenshot 2025-03-22 at 6 19 07 PM" src="https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4" /&gt; 
&lt;p&gt;Note: the system does not actually make any trades.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/virattt"&gt;&lt;img src="https://img.shields.io/twitter/follow/virattt?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for &lt;strong&gt;educational and research purposes only&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not intended for real trading or investment&lt;/li&gt; 
 &lt;li&gt;No investment advice or guarantees provided&lt;/li&gt; 
 &lt;li&gt;Creator assumes no liability for financial losses&lt;/li&gt; 
 &lt;li&gt;Consult a financial advisor for investment decisions&lt;/li&gt; 
 &lt;li&gt;Past performance does not indicate future results&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to use it solely for learning purposes.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-install"&gt;How to Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-run"&gt;How to Run&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-command-line-interface"&gt;‚å®Ô∏è Command Line Interface&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-web-application"&gt;üñ•Ô∏è Web Application&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-contribute"&gt;How to Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#feature-requests"&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;Before you can run the AI Hedge Fund, you'll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.&lt;/p&gt; 
&lt;h3&gt;1. Clone the Repository&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set up API keys&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file for your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create .env file for your API keys (in the root directory)
cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open and edit the &lt;code&gt;.env&lt;/code&gt; file to add your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: You must set at least one LLM API key (e.g. &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;GROQ_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, or &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt;) for the hedge fund to work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Financial Data&lt;/strong&gt;: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the &lt;code&gt;FINANCIAL_DATASETS_API_KEY&lt;/code&gt; in the .env file.&lt;/p&gt; 
&lt;h2&gt;How to Run&lt;/h2&gt; 
&lt;h3&gt;‚å®Ô∏è Command Line Interface&lt;/h3&gt; 
&lt;p&gt;You can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.&lt;/p&gt; 
&lt;img width="992" alt="Screenshot 2025-01-06 at 5 50 17 PM" src="https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b" /&gt; 
&lt;h4&gt;Quick Start&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Poetry (if not already installed):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://install.python-poetry.org | python3 -
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the AI Hedge Fund&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;--ollama&lt;/code&gt; flag to run the AI hedge fund using local LLMs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can optionally specify the start and end dates to make decisions over a specific time period.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the Backtester&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt; &lt;img width="941" alt="Screenshot 2025-01-06 at 5 47 52 PM" src="https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47" /&gt;&lt;/p&gt; 
&lt;p&gt;Note: The &lt;code&gt;--ollama&lt;/code&gt;, &lt;code&gt;--start-date&lt;/code&gt;, and &lt;code&gt;--end-date&lt;/code&gt; flags work for the backtester, as well!&lt;/p&gt; 
&lt;h3&gt;üñ•Ô∏è Web Application&lt;/h3&gt; 
&lt;p&gt;The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. This is recommended for users who prefer visual interfaces over command line tools.&lt;/p&gt; 
&lt;p&gt;Please see detailed instructions on how to install and run the web application &lt;a href="https://github.com/virattt/ai-hedge-fund/tree/main/app"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;img width="1721" alt="Screenshot 2025-06-28 at 6 41 03‚ÄØPM" src="https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b" /&gt; 
&lt;h2&gt;How to Contribute&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Commit your changes&lt;/li&gt; 
 &lt;li&gt;Push to the branch&lt;/li&gt; 
 &lt;li&gt;Create a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Please keep your pull requests small and focused. This will make it easier to review and merge.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;If you have a feature request, please open an &lt;a href="https://github.com/virattt/ai-hedge-fund/issues"&gt;issue&lt;/a&gt; and make sure it is tagged with &lt;code&gt;enhancement&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>python/cpython</title>
      <link>https://github.com/python/cpython</link>
      <description>&lt;p&gt;The Python programming language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;This is Python version 3.15.0 alpha 3&lt;/h1&gt; 
&lt;p&gt;.. image:: &lt;a href="https://github.com/python/cpython/actions/workflows/build.yml/badge.svg?branch=main&amp;amp;event=push"&gt;https://github.com/python/cpython/actions/workflows/build.yml/badge.svg?branch=main&amp;amp;event=push&lt;/a&gt; :alt: CPython build status on GitHub Actions :target: &lt;a href="https://github.com/python/cpython/actions"&gt;https://github.com/python/cpython/actions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://dev.azure.com/python/cpython/_apis/build/status/Azure%20Pipelines%20CI?branchName=main"&gt;https://dev.azure.com/python/cpython/_apis/build/status/Azure%20Pipelines%20CI?branchName=main&lt;/a&gt; :alt: CPython build status on Azure DevOps :target: &lt;a href="https://dev.azure.com/python/cpython/_build/latest?definitionId=4&amp;amp;branchName=main"&gt;https://dev.azure.com/python/cpython/_build/latest?definitionId=4&amp;amp;branchName=main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/badge/discourse-join_chat-brightgreen.svg"&gt;https://img.shields.io/badge/discourse-join_chat-brightgreen.svg&lt;/a&gt; :alt: Python Discourse chat :target: &lt;a href="https://discuss.python.org/"&gt;https://discuss.python.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Copyright ¬© 2001 Python Software Foundation. All rights reserved.&lt;/p&gt; 
&lt;p&gt;See the end of this file for further copyright and license information.&lt;/p&gt; 
&lt;p&gt;.. contents::&lt;/p&gt; 
&lt;h2&gt;General Information&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href="https://www.python.org"&gt;https://www.python.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Source code: &lt;a href="https://github.com/python/cpython"&gt;https://github.com/python/cpython&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Issue tracker: &lt;a href="https://github.com/python/cpython/issues"&gt;https://github.com/python/cpython/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://docs.python.org"&gt;https://docs.python.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Developer's Guide: &lt;a href="https://devguide.python.org/"&gt;https://devguide.python.org/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing to CPython&lt;/h2&gt; 
&lt;p&gt;For more complete instructions on contributing to CPython development, see the &lt;code&gt;Developer Guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. _Developer Guide: &lt;a href="https://devguide.python.org/"&gt;https://devguide.python.org/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Using Python&lt;/h2&gt; 
&lt;p&gt;Installable Python kits, and information about using Python, are available at &lt;code&gt;python.org&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. _python.org: &lt;a href="https://www.python.org/"&gt;https://www.python.org/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Build Instructions&lt;/h2&gt; 
&lt;p&gt;On Unix, Linux, BSD, macOS, and Cygwin::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./configure
make
make test
sudo make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will install Python as &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can pass many options to the configure script; run &lt;code&gt;./configure --help&lt;/code&gt; to find out more. On macOS case-insensitive file systems and on Cygwin, the executable is called &lt;code&gt;python.exe&lt;/code&gt;; elsewhere it's just &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Building a complete Python installation requires the use of various additional third-party libraries, depending on your build platform and configure options. Not all standard library modules are buildable or usable on all platforms. Refer to the &lt;code&gt;Install dependencies &amp;lt;https://devguide.python.org/getting-started/setup-building.html#build-dependencies&amp;gt;&lt;/code&gt;_ section of the &lt;code&gt;Developer Guide&lt;/code&gt;_ for current detailed information on dependencies for various Linux distributions and macOS.&lt;/p&gt; 
&lt;p&gt;On macOS, there are additional configure and build options related to macOS framework and universal builds. Refer to &lt;code&gt;Mac/README.rst &amp;lt;https://github.com/python/cpython/blob/main/Mac/README.rst&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;On Windows, see &lt;code&gt;PCbuild/readme.txt &amp;lt;https://github.com/python/cpython/blob/main/PCbuild/readme.txt&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;To build Windows installer, see &lt;code&gt;Tools/msi/README.txt &amp;lt;https://github.com/python/cpython/blob/main/Tools/msi/README.txt&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;If you wish, you can create a subdirectory and invoke configure from there. For example::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mkdir debug
cd debug
../configure --with-pydebug
make
make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(This will fail if you &lt;em&gt;also&lt;/em&gt; built at the top-level directory. You should do a &lt;code&gt;make clean&lt;/code&gt; at the top-level first.)&lt;/p&gt; 
&lt;p&gt;To get an optimized build of Python, &lt;code&gt;configure --enable-optimizations&lt;/code&gt; before you run &lt;code&gt;make&lt;/code&gt;. This sets the default make targets up to enable Profile Guided Optimization (PGO) and may be used to auto-enable Link Time Optimization (LTO) on some platforms. For more details, see the sections below.&lt;/p&gt; 
&lt;p&gt;Profile Guided Optimization ^^^^^^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;PGO takes advantage of recent versions of the GCC or Clang compilers. If used, either via &lt;code&gt;configure --enable-optimizations&lt;/code&gt; or by manually running &lt;code&gt;make profile-opt&lt;/code&gt; regardless of configure flags, the optimized build process will perform the following steps:&lt;/p&gt; 
&lt;p&gt;The entire Python directory is cleaned of temporary files that may have resulted from a previous compilation.&lt;/p&gt; 
&lt;p&gt;An instrumented version of the interpreter is built, using suitable compiler flags for each flavor. Note that this is just an intermediary step. The binary resulting from this step is not good for real-life workloads as it has profiling instructions embedded inside.&lt;/p&gt; 
&lt;p&gt;After the instrumented interpreter is built, the Makefile will run a training workload. This is necessary in order to profile the interpreter's execution. Note also that any output, both stdout and stderr, that may appear at this step is suppressed.&lt;/p&gt; 
&lt;p&gt;The final step is to build the actual interpreter, using the information collected from the instrumented one. The end result will be a Python binary that is optimized; suitable for distribution or production installation.&lt;/p&gt; 
&lt;p&gt;Link Time Optimization ^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Enabled via configure's &lt;code&gt;--with-lto&lt;/code&gt; flag. LTO takes advantage of the ability of recent compiler toolchains to optimize across the otherwise arbitrary &lt;code&gt;.o&lt;/code&gt; file boundary when building final executables or shared libraries for additional performance gains.&lt;/p&gt; 
&lt;h2&gt;What's New&lt;/h2&gt; 
&lt;p&gt;We have a comprehensive overview of the changes in the &lt;code&gt;What's new in Python 3.15 &amp;lt;https://docs.python.org/3.15/whatsnew/3.15.html&amp;gt;&lt;/code&gt;_ document. For a more detailed change log, read &lt;code&gt;Misc/NEWS &amp;lt;https://github.com/python/cpython/tree/main/Misc/NEWS.d&amp;gt;&lt;/code&gt;&lt;em&gt;, but a full accounting of changes can only be gleaned from the &lt;code&gt;commit history &amp;lt;https://github.com/python/cpython/commits/main&amp;gt;&lt;/code&gt;&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to install multiple versions of Python, see the section below entitled "Installing multiple versions".&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Documentation for Python 3.15 &amp;lt;https://docs.python.org/3.15/&amp;gt;&lt;/code&gt;_ is online, updated daily.&lt;/p&gt; 
&lt;p&gt;It can also be downloaded in many formats for faster access. The documentation is downloadable in HTML, EPUB, and reStructuredText formats; the latter version is primarily for documentation authors, translators, and people with special formatting requirements.&lt;/p&gt; 
&lt;p&gt;For information about building Python's documentation, refer to &lt;code&gt;Doc/README.rst &amp;lt;https://github.com/python/cpython/blob/main/Doc/README.rst&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;p&gt;To test the interpreter, type &lt;code&gt;make test&lt;/code&gt; in the top-level directory. The test set produces some output. You can generally ignore the messages about skipped tests due to optional features which can't be imported. If a message is printed about a failed test or a traceback or core dump is produced, something is wrong.&lt;/p&gt; 
&lt;p&gt;By default, tests are prevented from overusing resources like disk space and memory. To enable these tests, run &lt;code&gt;make buildbottest&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If any tests fail, you can re-run the failing test(s) in verbose mode. For example, if &lt;code&gt;test_os&lt;/code&gt; and &lt;code&gt;test_gdb&lt;/code&gt; failed, you can run::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make test TESTOPTS="-v test_os test_gdb"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the failure persists and appears to be a problem with Python rather than your environment, you can &lt;code&gt;file a bug report &amp;lt;https://github.com/python/cpython/issues&amp;gt;&lt;/code&gt;_ and include relevant output from that command to show the issue.&lt;/p&gt; 
&lt;p&gt;See &lt;code&gt;Running &amp;amp; Writing Tests &amp;lt;https://devguide.python.org/testing/run-write-tests.html&amp;gt;&lt;/code&gt;_ for more on running tests.&lt;/p&gt; 
&lt;h2&gt;Installing multiple versions&lt;/h2&gt; 
&lt;p&gt;On Unix and Mac systems if you intend to install multiple versions of Python using the same installation prefix (&lt;code&gt;--prefix&lt;/code&gt; argument to the configure script) you must take care that your primary python executable is not overwritten by the installation of a different version. All files and directories installed using &lt;code&gt;make altinstall&lt;/code&gt; contain the major and minor version and can thus live side-by-side. &lt;code&gt;make install&lt;/code&gt; also creates &lt;code&gt;${prefix}/bin/python3&lt;/code&gt; which refers to &lt;code&gt;${prefix}/bin/python3.X&lt;/code&gt;. If you intend to install multiple versions using the same prefix you must decide which version (if any) is your "primary" version. Install that version using &lt;code&gt;make install&lt;/code&gt;. Install all other versions using &lt;code&gt;make altinstall&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, if you want to install Python 2.7, 3.6, and 3.15 with 3.15 being the primary version, you would execute &lt;code&gt;make install&lt;/code&gt; in your 3.15 build directory and &lt;code&gt;make altinstall&lt;/code&gt; in the others.&lt;/p&gt; 
&lt;h2&gt;Release Schedule&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;PEP 790 &amp;lt;https://peps.python.org/pep-0790/&amp;gt;&lt;/code&gt;__ for Python 3.15 release details.&lt;/p&gt; 
&lt;h2&gt;Copyright and License Information&lt;/h2&gt; 
&lt;p&gt;Copyright ¬© 2001 Python Software Foundation. All rights reserved.&lt;/p&gt; 
&lt;p&gt;Copyright ¬© 2000 BeOpen.com. All rights reserved.&lt;/p&gt; 
&lt;p&gt;Copyright ¬© 1995-2001 Corporation for National Research Initiatives. All rights reserved.&lt;/p&gt; 
&lt;p&gt;Copyright ¬© 1991-1995 Stichting Mathematisch Centrum. All rights reserved.&lt;/p&gt; 
&lt;p&gt;See the &lt;code&gt;LICENSE &amp;lt;https://github.com/python/cpython/blob/main/LICENSE&amp;gt;&lt;/code&gt;_ for information on the history of this software, terms &amp;amp; conditions for usage, and a DISCLAIMER OF ALL WARRANTIES.&lt;/p&gt; 
&lt;p&gt;This Python distribution contains &lt;em&gt;no&lt;/em&gt; GNU General Public License (GPL) code, so it may be used in proprietary projects. There are interfaces to some GNU code but these are entirely optional.&lt;/p&gt; 
&lt;p&gt;All trademarks referenced herein are property of their respective holders.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>subframe7536/maple-font</title>
      <link>https://github.com/subframe7536/maple-font</link>
      <description>&lt;p&gt;Maple Mono: Open source monospace font with round corner, ligatures and Nerd-Font icons for IDE and terminal, fine-grained customization options. Â∏¶ËøûÂ≠óÂíåÊéßÂà∂Âè∞ÂõæÊ†áÁöÑÂúÜËßíÁ≠âÂÆΩÂ≠ó‰ΩìÔºå‰∏≠Ëã±ÊñáÂÆΩÂ∫¶ÂÆåÁæé2:1ÔºåÁªÜÁ≤íÂ∫¶ÁöÑËá™ÂÆö‰πâÈÄâÈ°π&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/subframe7536/maple-font/variable/resources/header.png" alt="Cover" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/13165" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13165" alt="subframe7536%2Fmaple-font | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;a href="https://hellogithub.com/repository/0601f355bd824d88b58f1af3066c486a" target="_blank"&gt;&lt;img src="https://api.hellogithub.com/v1/widgets/recommend.svg?rid=0601f355bd824d88b58f1af3066c486a&amp;amp;claim_uid=AO0yWRQ48ITGNqK" alt="FeaturedÔΩúHelloGitHub" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="GitHub Repo Stars" src="https://img.shields.io/github/stars/subframe7536/maple-font" /&gt; &lt;img alt="GitHub Repo Forks" src="https://img.shields.io/github/forks/subframe7536/maple-font" /&gt; &lt;img alt="X (formerly Twitter) Follow" src="https://img.shields.io/twitter/follow/subframe7536" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="GitHub Release" src="https://img.shields.io/github/v/release/subframe7536/maple-font" /&gt; &lt;img alt="GitHub Downloads (all assets, all releases)" src="https://img.shields.io/github/downloads/subframe7536/maple-font/total" /&gt; &lt;img alt="GitHub Repo License" src="https://img.shields.io/github/license/subframe7536/maple-font" /&gt; &lt;img alt="GitHub Repo Issues" src="https://img.shields.io/github/issues/subframe7536/maple-font" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/#download"&gt;Download&lt;/a&gt; | &lt;a href="https://font.subf.dev"&gt;Website&lt;/a&gt; | English | &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/README_CN.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/README_JA.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Maple Mono&lt;/h1&gt; 
&lt;p&gt;Maple Mono is an open source monospace font focused on smoothing your coding flow.&lt;/p&gt; 
&lt;p&gt;I create it to enhance my working experience, and hope that it can be useful to others.&lt;/p&gt; 
&lt;p&gt;V7 is a completely remade version, providing variable font format and source files of font project, redesigning more than half of the glyphs and offering smarter ligatures. You can checkout V6 &lt;a href="https://github.com/subframe7536/maple-font/tree/main"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ú® Variable - Infinity font weights with fine-grained italic glyphs.&lt;/li&gt; 
 &lt;li&gt;‚òÅÔ∏è Smooth - Round corner, brand-new glyph of &lt;code&gt;@ $ % &amp;amp; Q -&amp;gt;&lt;/code&gt; and cursive &lt;code&gt;f i j k l x y&lt;/code&gt; in italic style.&lt;/li&gt; 
 &lt;li&gt;üí™ Useful - Large amount of smart ligatures, see in &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/source/features/README.md"&gt;&lt;code&gt;features/&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üé® Icon - First-Class &lt;a href="https://github.com/ryanoasis/nerd-fonts"&gt;Nerd-Font&lt;/a&gt; support, make your terminal more vivid.&lt;/li&gt; 
 &lt;li&gt;üî® Customize - Enable or disable font features as you want, just make your own font.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Simpified Chinese, Traditional Chinese and Japanese&lt;/h3&gt; 
&lt;p&gt;CN version based on &lt;a href="https://github.com/CyanoHao/Resource-Han-Rounded"&gt;Resource Han Rounded&lt;/a&gt; provides complete character set support for Chinese development environments, including Simplified Chinese, Traditional Chinese, and Japanese. Meanwhile, the characteristic of perfect 2:1 alignment between Chinese and English allows this font to achieve a neat, uniform, beautiful, and comfortable appearance in scenarios such as multilingual display and Markdown tables. However, the spacing of Chinese characters is larger compared to other popular Chinese fonts. See details in &lt;a href="https://github.com/subframe7536/maple-font/releases/tag/cn-base"&gt;release notes&lt;/a&gt; and &lt;a href="https://github.com/subframe7536/maple-font/issues/211"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/subframe7536/maple-font/variable/resources/2-1.png" alt="2-1.png" /&gt;&lt;/p&gt; 
&lt;h2&gt;ScreenShots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/subframe7536/maple-font/variable/resources/showcase.png" alt="showcase.png" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pictured by &lt;a href="https://github.com/subframe7536/vscode-codeimg"&gt;CodeImg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Theme: &lt;a href="https://github.com/subframe7536/vscode-theme-maple"&gt;Maple&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Config: font size 16px, line height 1.8, default letter spacing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;p&gt;You can download all the font archives from &lt;a href="https://github.com/subframe7536/maple-font/releases"&gt;Releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Scoop (Windows)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Add bucket
scoop bucket add nerd-fonts
# Maple Mono (ttf format)
scoop install Maple-Mono
# Maple Mono NF
scoop install Maple-Mono-NF
# Maple Mono NF CN
scoop install Maple-Mono-NF-CN
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;All packages (Click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;# Add bucket
scoop bucket add nerd-fonts
# Maple Mono (ttf format)
scoop install Maple-Mono
# Maple Mono (hinted ttf format)
scoop install Maple-Mono-autohint
# Maple Mono (otf format)
scoop install Maple-Mono-otf
# Maple Mono NF
scoop install Maple-Mono-NF
# Maple Mono NF CN
scoop install Maple-Mono-NF-CN
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Homebrew (MacOS, Linux)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Maple Mono
brew install --cask font-maple-mono
# Maple Mono NF
brew install --cask font-maple-mono-nf
# Maple Mono NF CN
brew install --cask font-maple-mono-nf-cn
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;All packages (Click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;# Maple Mono
brew install --cask font-maple-mono
# Maple Mono NF
brew install --cask font-maple-mono-nf
# Maple Mono CN
brew install --cask font-maple-mono-cn
# Maple Mono NF CN
brew install --cask font-maple-mono-nf-cn

# Maple Mono Normal
brew install --cask font-maple-mono-normal
# Maple Mono Normal NF
brew install --cask font-maple-mono-normal-nf
# Maple Mono Normal CN
brew install --cask font-maple-mono-normal-cn
# Maple Mono Normal NF CN
brew install --cask font-maple-mono-normal-nf-cn
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Arch Linux&lt;/h3&gt; 
&lt;p&gt;ArchLinuxCN repository allows downloading a single package zip file without downloading all the package zip files in pkgbase, but AUR does not. (If you have a good solution, please contact Cyberczy(&lt;a href="mailto:czysheep@gmail.com"&gt;czysheep@gmail.com&lt;/a&gt;))&lt;/p&gt; 
&lt;h4&gt;ArchLinuxCN (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Maple Mono (Ligature TTF unhinted)
paru -S ttf-maplemono
# Maple Mono NF (Ligature unhinted)
paru -S ttf-maplemono-nf-unhinted
# Maple Mono NF CN (Ligature unhinted)
paru -S ttf-maplemono-nf-cn-unhinted
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;All packages (Click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;# Maple Mono (Ligature Variable)
paru -S ttf-maplemono-variable
# Maple Mono (Ligature TTF hinted)
paru -S ttf-maplemono-autohint
# Maple Mono (Ligature TTF unhinted)
paru -S ttf-maplemono
# Maple Mono (Ligature OTF)
paru -S otf-maplemono
# Maple Mono (Ligature WOFF2)
paru -S woff2-maplemono
# Maple Mono NF (Ligature hinted)
paru -S ttf-maplemono-nf
# Maple Mono NF (Ligature unhinted)
paru -S ttf-maplemono-nf-unhinted
# Maple Mono CN (Ligature hinted)
paru -S ttf-maplemono-cn
# Maple Mono CN (Ligature unhinted)
paru -S ttf-maplemono-cn-unhinted
# Maple Mono NF CN (Ligature hinted)
paru -S ttf-maplemono-nf-cn
# Maple Mono NF CN (Ligature unhinted)
paru -S ttf-maplemono-nf-cn-unhinted

# Maple Mono (No-Ligature Variable)
paru -S ttf-maplemononl-variable
# Maple Mono (No-Ligature TTF hinted)
paru -S ttf-maplemononl-autohint
# Maple Mono (No-Ligature TTF unhinted)
paru -S ttf-maplemononl
# Maple Mono (No-Ligature OTF)
paru -S otf-maplemononl
# Maple Mono (No-Ligature WOFF2)
paru -S woff2-maplemononl
# Maple Mono NF (No-Ligature hinted)
paru -S ttf-maplemononl-nf
# Maple Mono NF (No-Ligature unhinted)
paru -S ttf-maplemononl-nf-unhinted
# Maple Mono CN (No-Ligature hinted)
paru -S ttf-maplemononl-cn
# Maple Mono CN (No-Ligature unhinted)
paru -S ttf-maplemononl-cn-unhinted
# Maple Mono NF CN (No-Ligature hinted)
paru -S ttf-maplemononl-nf-cn
# Maple Mono NF CN (No-Ligature unhinted)
paru -S ttf-maplemononl-nf-cn-unhinted

# Maple Mono Normal (Ligature Variable)
paru -S ttf-maplemononormal-variable
# Maple Mono Normal (Ligature TTF hinted)
paru -S ttf-maplemononormal-autohint
# Maple Mono Normal (Ligature TTF unhinted)
paru -S ttf-maplemononormal
# Maple Mono Normal (Ligature OTF)
paru -S otf-maplemononormal
# Maple Mono Normal (Ligature WOFF2)
paru -S woff2-maplemononormal
# Maple Mono Normal NF (Ligature hinted)
paru -S ttf-maplemononormal-nf
# Maple Mono Normal NF (Ligature unhinted)
paru -S ttf-maplemononormal-nf-unhinted
# Maple Mono Normal CN (Ligature hinted)
paru -S ttf-maplemononormal-cn
# Maple Mono Normal CN (Ligature unhinted)
paru -S ttf-maplemononormal-cn-unhinted
# Maple Mono Normal NF CN (Ligature hinted)
paru -S ttf-maplemononormal-nf-cn
# Maple Mono Normal NF CN (Ligature unhinted)
paru -S ttf-maplemononormal-nf-cn-unhinted

# Maple Mono Normal (No-Ligature Variable)
paru -S ttf-maplemononormalnl-variable
# Maple Mono Normal (No-Ligature TTF hinted)
paru -S ttf-maplemononormalnl-autohint
# Maple Mono Normal (No-Ligature TTF unhinted)
paru -S ttf-maplemononormalnl
# Maple Mono Normal (No-Ligature OTF)
paru -S otf-maplemononormalnl
# Maple Mono Normal (No-Ligature WOFF2)
paru -S woff2-maplemononormalnl
# Maple Mono Normal NF (No-Ligature hinted)
paru -S ttf-maplemononormalnl-nf
# Maple Mono Normal NF (No-Ligature unhinted)
paru -S ttf-maplemononormalnl-nf-unhinted
# Maple Mono Normal CN (No-Ligature hinted)
paru -S ttf-maplemononormalnl-cn
# Maple Mono Normal CN (No-Ligature unhinted)
paru -S ttf-maplemononormalnl-cn-unhinted
# Maple Mono Normal NF CN (No-Ligature hinted)
paru -S ttf-maplemononormalnl-nf-cn
# Maple Mono Normal NF CN (No-Ligature unhinted)
paru -S ttf-maplemononormalnl-nf-cn-unhinted
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;AUR (Not Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Maple Mono (Ligature TTF unhinted)
paru -S maplemono-ttf
# Maple Mono NF (Ligature unhinted)
paru -S maplemono-nf-unhinted
# Maple Mono NF CN (Ligature unhinted)
paru -S maplemono-nf-cn-unhinted
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;All packages (Click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;# Maple Mono (Ligature Variable)
paru -S maplemono-variable
# Maple Mono (Ligature TTF hinted)
paru -S maplemono-ttf-autohint
# Maple Mono (Ligature TTF unhinted)
paru -S maplemono-ttf
# Maple Mono (Ligature OTF)
paru -S maplemono-otf
# Maple Mono (Ligature WOFF2)
paru -S maplemono-woff2
# Maple Mono NF (Ligature hinted)
paru -S maplemono-nf
# Maple Mono NF (Ligature unhinted)
paru -S maplemono-nf-unhinted
# Maple Mono CN (Ligature hinted)
paru -S maplemono-cn
# Maple Mono CN (Ligature unhinted)
paru -S maplemono-cn-unhinted
# Maple Mono NF CN (Ligature hinted)
paru -S maplemono-nf-cn
# Maple Mono NF CN (Ligature unhinted)
paru -S maplemono-nf-cn-unhinted

# Maple Mono (No-Ligature Variable)
paru -S maplemononl-variable
# Maple Mono (No-Ligature TTF hinted)
paru -S maplemononl-ttf-autohint
# Maple Mono (No-Ligature TTF unhinted)
paru -S maplemononl-ttf
# Maple Mono (No-Ligature OTF)
paru -S maplemononl-otf
# Maple Mono (No-Ligature WOFF2)
paru -S maplemononl-woff2
# Maple Mono NF (No-Ligature hinted)
paru -S maplemononl-nf
# Maple Mono NF (No-Ligature unhinted)
paru -S maplemononl-nf-unhinted
# Maple Mono CN (No-Ligature hinted)
paru -S maplemononl-cn
# Maple Mono CN (No-Ligature unhinted)
paru -S maplemononl-cn-unhinted
# Maple Mono NF CN (No-Ligature hinted)
paru -S maplemononl-nf-cn
# Maple Mono NF CN (No-Ligature unhinted)
paru -S maplemononl-nf-cn-unhinted

# Maple Mono Normal (Ligature Variable)
paru -S maplemononormal-variable
# Maple Mono Normal (Ligature TTF hinted)
paru -S maplemononormal-ttf-autohint
# Maple Mono Normal (Ligature TTF unhinted)
paru -S maplemononormal-ttf
# Maple Mono Normal (Ligature OTF)
paru -S maplemononormal-otf
# Maple Mono Normal (Ligature WOFF2)
paru -S maplemononormal-woff2
# Maple Mono Normal NF (Ligature hinted)
paru -S maplemononormal-nf
# Maple Mono Normal NF (Ligature unhinted)
paru -S maplemononormal-nf-unhinted
# Maple Mono Normal CN (Ligature hinted)
paru -S maplemononormal-cn
# Maple Mono Normal CN (Ligature unhinted)
paru -S maplemononormal-cn-unhinted
# Maple Mono Normal NF CN (Ligature hinted)
paru -S maplemononormal-nf-cn
# Maple Mono Normal NF CN (Ligature unhinted)
paru -S maplemononormal-nf-cn-unhinted

# Maple Mono Normal (No-Ligature Variable)
paru -S maplemononormalnl-variable
# Maple Mono Normal (No-Ligature TTF hinted)
paru -S maplemononormalnl-ttf-autohint
# Maple Mono Normal (No-Ligature TTF unhinted)
paru -S maplemononormalnl-ttf
# Maple Mono Normal (No-Ligature OTF)
paru -S maplemononormalnl-otf
# Maple Mono Normal (No-Ligature WOFF2)
paru -S maplemononormalnl-woff2
# Maple Mono Normal NF (No-Ligature hinted)
paru -S maplemononormalnl-nf
# Maple Mono Normal NF (No-Ligature unhinted)
paru -S maplemononormalnl-nf-unhinted
# Maple Mono Normal CN (No-Ligature hinted)
paru -S maplemononormalnl-cn
# Maple Mono Normal CN (No-Ligature unhinted)
paru -S maplemononormalnl-cn-unhinted
# Maple Mono Normal NF CN (No-Ligature hinted)
paru -S maplemononormalnl-nf-cn
# Maple Mono Normal NF CN (No-Ligature unhinted)
paru -S maplemononormalnl-nf-cn-unhinted
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Nixpkgs (NixOS, Linux, MacOS)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;fonts.packages = with pkgs; [
  # Maple Mono (Ligature TTF unhinted)
  maple-mono.truetype
  # Maple Mono NF (Ligature unhinted)
  maple-mono.NF-unhinted
  # Maple Mono NF CN (Ligature unhinted)
  maple-mono.NF-CN-unhinted
];
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;All packages (Click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;fonts.packages = with pkgs; [
  # Maple Mono (Ligature Variable)
  maple-mono.variable
  # Maple Mono (Ligature TTF hinted)
  maple-mono.truetype-autohint
  # Maple Mono (Ligature TTF unhinted)
  maple-mono.truetype
  # Maple Mono (Ligature OTF)
  maple-mono.opentype
  # Maple Mono (Ligature WOFF2)
  maple-mono.woff2
  # Maple Mono NF (Ligature hinted)
  maple-mono.NF
  # Maple Mono NF (Ligature unhinted)
  maple-mono.NF-unhinted
  # Maple Mono CN (Ligature hinted)
  maple-mono.CN
  # Maple Mono CN (Ligature unhinted)
  maple-mono.CN-unhinted
  # Maple Mono NF CN (Ligature hinted)
  maple-mono.NF-CN
  # Maple Mono NF CN (Ligature unhinted)
  maple-mono.NF-CN-unhinted

  # Maple Mono (No-Ligature Variable)
  maple-mono.NL-Variable
  # Maple Mono (No-Ligature TTF hinted)
  maple-mono.NL-TTF-AutoHint
  # Maple Mono (No-Ligature TTF unhinted)
  maple-mono.NL-TTF
  # Maple Mono (No-Ligature OTF)
  maple-mono.NL-OTF
  # Maple Mono (No-Ligature WOFF2)
  maple-mono.NL-Woff2
  # Maple Mono NF (No-Ligature hinted)
  maple-mono.NL-NF
  # Maple Mono NF (No-Ligature unhinted)
  maple-mono.NL-NF-unhinted
  # Maple Mono CN (No-Ligature hinted)
  maple-mono.NL-CN
  # Maple Mono CN (No-Ligature unhinted)
  maple-mono.NL-CN-unhinted
  # Maple Mono NF CN (No-Ligature hinted)
  maple-mono.NL-NF-CN
  # Maple Mono NF CN (No-Ligature unhinted)
  maple-mono.NL-NF-CN-unhinted

  # Maple Mono Normal (Ligature Variable)
  maple-mono.Normal-Variable
  # Maple Mono Normal (Ligature TTF hinted)
  maple-mono.Normal-TTF-AutoHint
  # Maple Mono Normal (Ligature TTF unhinted)
  maple-mono.Normal-TTF
  # Maple Mono Normal (Ligature OTF)
  maple-mono.Normal-OTF
  # Maple Mono Normal (Ligature WOFF2)
  maple-mono.Normal-Woff2
  # Maple Mono Normal NF (Ligature hinted)
  maple-mono.Normal-NF
  # Maple Mono Normal NF (Ligature unhinted)
  maple-mono.Normal-NF-unhinted
  # Maple Mono Normal CN (Ligature hinted)
  maple-mono.Normal-CN
  # Maple Mono Normal CN (Ligature unhinted)
  maple-mono.Normal-CN-unhinted
  # Maple Mono Normal NF CN (Ligature hinted)
  maple-mono.Normal-NF-CN
  # Maple Mono Normal NF CN (Ligature unhinted)
  maple-mono.Normal-NF-CN-unhinted

  # Maple Mono Normal (No-Ligature Variable)
  maple-mono.NormalNL-Variable
  # Maple Mono Normal (No-Ligature TTF hinted)
  maple-mono.NormalNL-TTF-AutoHint
  # Maple Mono Normal (No-Ligature TTF unhinted)
  maple-mono.NormalNL-TTF
  # Maple Mono Normal (No-Ligature OTF)
  maple-mono.NormalNL-OTF
  # Maple Mono Normal (No-Ligature WOFF2)
  maple-mono.NormalNL-Woff2
  # Maple Mono Normal NF (No-Ligature hinted)
  maple-mono.NormalNL-NF
  # Maple Mono Normal NF (No-Ligature unhinted)
  maple-mono.NormalNL-NF-unhinted
  # Maple Mono Normal CN (No-Ligature hinted)
  maple-mono.NormalNL-CN
  # Maple Mono Normal CN (No-Ligature unhinted)
  maple-mono.NormalNL-CN-unhinted
  # Maple Mono Normal NF CN (No-Ligature hinted)
  maple-mono.NormalNL-NF-CN
  # Maple Mono Normal NF CN (No-Ligature unhinted)
  maple-mono.NormalNL-NF-CN-unhinted
];
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;CDN&lt;/h2&gt; 
&lt;h3&gt;Maple Mono&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://fontsource.org/fonts/maple-mono"&gt;fontsource&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fonts.zeoseven.com/items/443/"&gt;ZeoSeven Fonts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Maple Mono CN&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://chinese-font.netlify.app/zh-cn/fonts/maple-mono-cn/MapleMono-CN-Regular"&gt;The Chinese Web Fonts Plan (‰∏≠ÊñáÁΩëÂ≠óËÆ°Âàí)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fonts.zeoseven.com/items/442/"&gt;ZeoSeven Fonts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage &amp;amp; Feature Configurations&lt;/h2&gt; 
&lt;p&gt;See in &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/source/features/README.md"&gt;document&lt;/a&gt; or try it in &lt;a href="https://font.subf.dev/en/playground"&gt;Playground&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Naming FAQ&lt;/h2&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Ligature&lt;/strong&gt;: Default version with ligatures (&lt;code&gt;Maple Mono&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No-Ligature&lt;/strong&gt;: Default version without ligatures (&lt;code&gt;Maple Mono NL&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Normal-Ligature&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/#preset"&gt;&lt;code&gt;--normal&lt;/code&gt; preset&lt;/a&gt; with ligatures (&lt;code&gt;Maple Mono Normal&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Normal-No-Ligature&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/#preset"&gt;&lt;code&gt;--normal&lt;/code&gt; preset&lt;/a&gt; without ligatures (&lt;code&gt;Maple Mono Normal NL&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Format and Glyph Set&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Variable&lt;/strong&gt;: Minimal version, smoothly change font weight by variable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TTF&lt;/strong&gt;: Minimal version, ttf format [Recommend!]&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OTF&lt;/strong&gt;: Minimal version, otf format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WOFF2&lt;/strong&gt;: Minimal version, woff2 format, for small size on web pages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NF&lt;/strong&gt;: Nerd-Font patched version, add icons for terminal (With &lt;code&gt;-NF&lt;/code&gt; suffix)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CN&lt;/strong&gt;: Chinese version, embed with Chinese and Japanese glyphs (With &lt;code&gt;-CN&lt;/code&gt; suffix)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NF-CN&lt;/strong&gt;: Full version, embed with icons, Chinese and Japanese glyphs (With &lt;code&gt;-NF-CN&lt;/code&gt; suffix)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Font Hint&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hinted font&lt;/strong&gt; is used for low resolution screen to have better render effect. From my experience, if your screen resolution is lower or equal than 1080P, it is recommended to use "hinted font". Using "unhinted font" will lead to misalignment or uneven thickness on your text. 
  &lt;ul&gt; 
   &lt;li&gt;In this case, you can choose &lt;code&gt;MapleMono-TTF-AutoHint&lt;/code&gt; / &lt;code&gt;MapleMono-NF&lt;/code&gt; / &lt;code&gt;MapleMono-NF-CN&lt;/code&gt;, etc.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unhinted font&lt;/strong&gt; is used for high resolution screen (e.g. for MacBook). Using "hinted font" will blur your text or make it looks weird. 
  &lt;ul&gt; 
   &lt;li&gt;In this case, you can choose &lt;code&gt;MapleMono-OTF&lt;/code&gt; / &lt;code&gt;MapleMono-TTF&lt;/code&gt; / &lt;code&gt;MapleMono-NF-unhinted&lt;/code&gt; / &lt;code&gt;MapleMono-NF-CN-unhinted&lt;/code&gt;, etc.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Why there exists &lt;code&gt;-AutoHint&lt;/code&gt; and &lt;code&gt;-unhinted&lt;/code&gt; suffix? 
  &lt;ul&gt; 
   &lt;li&gt;for backward compatibility, I keep the original naming scheme. &lt;code&gt;-AutoHint&lt;/code&gt; is only used for &lt;code&gt;TTF&lt;/code&gt; format.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Custom Build&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/config.json"&gt;&lt;code&gt;config.json&lt;/code&gt;&lt;/a&gt; file is used to configure the build process. Checkout the &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/source/schema.json"&gt;schema&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/source/features/README.md"&gt;document&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;There also have some &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/#build-script-usage"&gt;command line options&lt;/a&gt; for customizing the build process. Cli options have higher priority than options in &lt;code&gt;config.json&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Build Methods&lt;/h3&gt; 
&lt;h4&gt;1. Build In Browser&lt;/h4&gt; 
&lt;p&gt;Go to &lt;a href="https://font.subf.dev/en/playground"&gt;Playground&lt;/a&gt;, and click "Custom Build" button in the bottom left corner&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Only support freezing OpenType features currently.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. Use Github Actions&lt;/h4&gt; 
&lt;p&gt;You can use &lt;a href="https://github.com/subframe7536/maple-font/actions/workflows/custom.yml"&gt;Github Actions&lt;/a&gt; to build the font.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repo&lt;/li&gt; 
 &lt;li&gt;(Optional) Change the content in &lt;code&gt;config.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Go to Actions tab&lt;/li&gt; 
 &lt;li&gt;Click on &lt;code&gt;Custom Build&lt;/code&gt; menu item on the left&lt;/li&gt; 
 &lt;li&gt;Click on &lt;code&gt;Run workflow&lt;/code&gt; button with options setup&lt;/li&gt; 
 &lt;li&gt;Wait for the build to finish&lt;/li&gt; 
 &lt;li&gt;Download the font archives from Releases&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;3. Use Docker&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/subframe7536/maple-font --depth 1 -b variable
docker build -t maple-font .
docker run -v "$(pwd)/fonts:/app/fonts" -e BUILD_ARGS="--normal" maple-font
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Local Build&lt;/h4&gt; 
&lt;p&gt;Clone the repo and run on your local machine. Make sure you have &lt;code&gt;python3&lt;/code&gt; and &lt;code&gt;pip&lt;/code&gt; installed&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/subframe7536/maple-font --depth 1 -b variable
pip install -r requirements.txt
python build.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] For &lt;code&gt;Ubuntu&lt;/code&gt; or &lt;code&gt;Debian&lt;/code&gt;, maybe &lt;code&gt;python-is-python3&lt;/code&gt; is needed as well.&lt;/p&gt; 
 &lt;p&gt;If you have trouble installing the dependencies, just create a new GitHub Codespace and run the commands there.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Narrow Glyph Width&lt;/h3&gt; 
&lt;p&gt;You can setup &lt;code&gt;"width": "narrow"&lt;/code&gt; in &lt;code&gt;config.json&lt;/code&gt; or add &lt;code&gt;--width slim&lt;/code&gt; in cli flag to change glyph width at build time.&lt;/p&gt; 
&lt;p&gt;There are 3 options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;default: 600&lt;/li&gt; 
 &lt;li&gt;narrow: 550&lt;/li&gt; 
 &lt;li&gt;slim: 500&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Preview: &lt;a href="https://github.com/subframe7536/maple-font/issues/131#issuecomment-3678666194"&gt;#131&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Custom Nerd-Font&lt;/h3&gt; 
&lt;p&gt;If you want to get fixed width icons, setup &lt;code&gt;"nerd_font.mono": true&lt;/code&gt; in &lt;code&gt;config.json&lt;/code&gt; or add &lt;code&gt;--nf-mono&lt;/code&gt; flag to build script args.&lt;/p&gt; 
&lt;p&gt;If you want to get variable width icons, setup &lt;code&gt;"nerd_font.propo": true&lt;/code&gt; in &lt;code&gt;config.json&lt;/code&gt; or add &lt;code&gt;--nf-propo&lt;/code&gt; flag to build script args.&lt;/p&gt; 
&lt;p&gt;For custom &lt;code&gt;font-patcher&lt;/code&gt; args, &lt;code&gt;font-forge&lt;/code&gt; (and maybe &lt;code&gt;python3-fontforge&lt;/code&gt; as well) is required.&lt;/p&gt; 
&lt;p&gt;Maybe you should also change &lt;code&gt;"nerd_font.extra_args"&lt;/code&gt; in &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/config.json"&gt;config.json&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Default args: &lt;code&gt;-l --careful --outputdir dir&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if &lt;code&gt;"nerd_font.propo"&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt;, then add &lt;code&gt;--variable-width-glyphs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;else if &lt;code&gt;"nerd_font.mono"&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt;, then add &lt;code&gt;--mono&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Preset&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;build.py&lt;/code&gt; with &lt;code&gt;--normal&lt;/code&gt; flag, make the font looks not such "Opinioned" , just like &lt;code&gt;JetBrains Mono&lt;/code&gt; (with slashed zero).&lt;/p&gt; 
&lt;p&gt;If you are using variable font (NOT recommended), please enable &lt;code&gt;calt&lt;/code&gt; to make all features work.&lt;/p&gt; 
&lt;p&gt;Enabled features:&lt;/p&gt; 
&lt;!-- NORMAL --&gt; 
&lt;pre&gt;&lt;code&gt;cv01, cv02, cv33, cv34, cv35, cv36, cv61, cv62, ss05, ss06, ss07, ss08
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- NORMAL --&gt; 
&lt;p&gt;&lt;a href="https://font.subf.dev/en/playground?normal"&gt;Online Preview&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Freeze OpenType Feature&lt;/h3&gt; 
&lt;p&gt;There are three kinds of options for feature freeze (&lt;a href="https://github.com/subframe7536/maple-font/issues/233#issuecomment-2410170270"&gt;Why&lt;/a&gt;):&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;enable&lt;/code&gt;: Forcely enable the features without setting up &lt;code&gt;cvXX&lt;/code&gt; / &lt;code&gt;ssXX&lt;/code&gt; / &lt;code&gt;zero&lt;/code&gt; in font features config, just as default glyphs / ligatures&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;disable&lt;/code&gt;: Remove the features in &lt;code&gt;cvXX&lt;/code&gt; / &lt;code&gt;ssXX&lt;/code&gt; / &lt;code&gt;zero&lt;/code&gt;, which will no longer effect, even if you enable it manually&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ignore&lt;/code&gt;: Do nothing&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Custom OpenType Feature&lt;/h4&gt; 
&lt;p&gt;OpenType Feature is used to control the font's built-in variants and ligatures. You can remove some ligatures or features you don't want to, change feature's trigger rule or add some new rules by modifying OpenType Feature.&lt;/p&gt; 
&lt;p&gt;By default, the Python module in &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/source/py/feature"&gt;&lt;code&gt;source/py/feature/&lt;/code&gt;&lt;/a&gt; will generate feature rule string and load it at build time. You can modify the features or customize tags there.&lt;/p&gt; 
&lt;p&gt;If you would like to modify the feature file instead, run &lt;code&gt;build.py&lt;/code&gt; with &lt;code&gt;--apply-fea-file&lt;/code&gt; flag, the feature file from &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/source/features"&gt;&lt;code&gt;source/features/{regular,italic}{_cn,}.fea&lt;/code&gt;&lt;/a&gt; will be loaded.&lt;/p&gt; 
&lt;h3&gt;Infinite Arrow Ligatures&lt;/h3&gt; 
&lt;p&gt;Inspired by Fira Code, the font enables infinite arrow ligatures by default from v7.3. For some reason, the ligatures are misaligned when using hinted font, so they are removed in hinted version by default from v7.4.&lt;/p&gt; 
&lt;p&gt;You can setup &lt;code&gt;"infinite_arrow": true&lt;/code&gt; in &lt;code&gt;config.json&lt;/code&gt; or add &lt;code&gt;--infinite-arrow&lt;/code&gt; in cli flag to force enabling the feature. See more details in &lt;a href="https://github.com/subframe7536/maple-font/issues/508"&gt;#508&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Custom Font Weight Mapping&lt;/h3&gt; 
&lt;p&gt;You can modify the static font weight through &lt;code&gt;"weight_mapping"&lt;/code&gt; item in &lt;code&gt;config.json&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, if you want to make regular font weight a little bit lighter, just decrease the number of &lt;code&gt;"weight_mapping.regular"&lt;/code&gt; (from 400 to 350 in this example) :&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "weight_mapping": {
    "thin": 100,
    "extralight": 200,
    "light": 300,
    "regular": 350,
    "semibold": 500,
    "medium": 600,
    "bold": 700,
    "extrabold": 800
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chinese version&lt;/h3&gt; 
&lt;p&gt;CN version is disabled by default. Run &lt;code&gt;python build.py&lt;/code&gt; with &lt;code&gt;--cn&lt;/code&gt; flag, the CN base fonts (about 111 MB) will download from GitHub.&lt;/p&gt; 
&lt;p&gt;If you want to build CN base fonts from variable (about 27 MB), setup &lt;code&gt;"cn.use_static_base_font": false&lt;/code&gt; in &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/config.json"&gt;config.json&lt;/a&gt; and &lt;strong&gt;BE PATIENT&lt;/strong&gt;, instantiation will take about 10-30 minutes.&lt;/p&gt; 
&lt;h4&gt;Narrow spacing in CN glyphs&lt;/h4&gt; 
&lt;p&gt;If you think that &lt;strong&gt;CN glyphs spacing is TOOOOOO large&lt;/strong&gt;, there is a build option &lt;code&gt;cn.narrow&lt;/code&gt; or cli flag &lt;code&gt;--cn-narrow&lt;/code&gt; to narrow spacing in CN glyphs, but this will make the font cannot be recogized as monospaced font. You can see effect in &lt;a href="https://github.com/subframe7536/maple-font/issues/249#issuecomment-2871260476"&gt;#249&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;And if you want to change the Latin letters' width as well, use &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/#narrow-glyph-width"&gt;&lt;code&gt;--width&lt;/code&gt; option&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;GitHub Mirror&lt;/h4&gt; 
&lt;p&gt;The build script will auto download required assets from GitHub. If you have trouble downloading, please setup &lt;code&gt;github_mirror&lt;/code&gt; in &lt;a href="https://raw.githubusercontent.com/subframe7536/maple-font/variable/config.json"&gt;config.json&lt;/a&gt; or &lt;code&gt;$GITHUB&lt;/code&gt; to your environment variable. (Target URL will be &lt;code&gt;https://&amp;lt;github_mirror&amp;gt;/&amp;lt;user&amp;gt;/&amp;lt;repo&amp;gt;/releases/download/&amp;lt;tag&amp;gt;/&amp;lt;file&amp;gt;&lt;/code&gt;), or just download the target &lt;code&gt;.zip&lt;/code&gt; file and put it in the same directory as &lt;code&gt;build.py&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Traditional Chinese Punctuation Support&lt;/h4&gt; 
&lt;p&gt;By enabling &lt;code&gt;cv99&lt;/code&gt;, all Chinese punctuation marks will be centred. See more details in &lt;a href="https://github.com/subframe7536/maple-font/issues/150"&gt;#150&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Build Script Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;usage: build.py [-h] [-v] [-d] [--debug] [-n] [--feat FEAT] [--apply-fea-file]
                [--hinted | --no-hinted] [--liga | --no-liga] [--keep-infinite-arrow]
                [--infinite-arrow] [--remove-tag-liga] [--line-height LINE_HEIGHT]
                [--width {default,narrow,slim}] [--nf-mono] [--nf-propo]
                [--cn-narrow] [--cn-scale-factor CN_SCALE_FACTOR] [--nf | --no-nf]
                [--cn | --no-cn] [--cn-both] [--ttf-only] [--least-styles]
                [--font-patcher] [--cache] [--cn-rebuild] [--archive]

‚ú® Builder and optimizer for Maple Mono

options:
  -h, --help            show this help message and exit
  -v, --version         show program's version number and exit
  -d, --dry             Output config and exit
  --debug               Add `Debug` suffix to family name and faster build

Feature Options:
  -n, --normal          Use normal preset, just like `JetBrains Mono` with slashed
                        zero
  --feat FEAT           Freeze font features, splited by `,` (e.g. `--feat
                        zero,cv01,ss07,ss08`). No effect on variable format
  --apply-fea-file      Load feature file from `source/features/{regular,italic}.fea`
                        to variable font
  --hinted              Use hinted font as base font in NF / CN / NF-CN (default)
  --no-hinted           Use unhinted font as base font in NF / CN / NF-CN
  --liga                Preserve all the ligatures (default)
  --no-liga             Remove all the ligatures
  --infinite-arrow      Enable infinite arrow ligatures (Disabled in hinted font by
                        default)
  --remove-tag-liga     Remove plain text tag ligatures like `[TODO]`
  --line-height LINE_HEIGHT
                        Scale factor for line height (e.g. 1.1)
  --width {default,narrow,slim}
                        Set glyph width: default (600), narrow (550), slim (500)
  --nf-mono             Make Nerd Font icons' width fixed
  --nf-propo            Make Nerd Font icons' width variable, override `--nf-mono`
  --cn-narrow           Make CN / JP characters narrow (And the font cannot be
                        recogized as monospaced font)
  --cn-scale-factor CN_SCALE_FACTOR
                        Scale factor for CN / JP glyphs. Format: &amp;lt;factor&amp;gt; or
                        &amp;lt;width_factor&amp;gt;,&amp;lt;height_factor&amp;gt; (e.g. 1.1 or 1.2,1.1)

Build Options:
  --nf, --nerd-font     Build Nerd-Font version (default)
  --no-nf, --no-nerd-font
                        Do not build Nerd-Font version
  --cn                  Build Chinese version
  --no-cn               Do not build Chinese version (default)
  --cn-both             Build both `Maple Mono CN` and `Maple Mono NF CN`. Nerd-Font
                        version must be enabled
  --ttf-only            Only build TTF format
  --least-styles        Only build Regular / Bold / Italic / BoldItalic style
  --font-patcher        Force the use of Nerd Font Patcher to build NF format
  --cache               Reuse font cache of TTF, OTF and Woff2 formats
  --cn-rebuild          Reinstantiate variable CN base font
  --archive             Build font archives with config and license. If has `--cache`
                        flag, only archive NF and CN formats
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Design&lt;/h3&gt; 
&lt;p&gt;Using &lt;a href="https://www.fontlab.com/"&gt;FontLab&lt;/a&gt; or &lt;a href="https://glyphs.app"&gt;Glyphs&lt;/a&gt;, generate variable TTF into &lt;code&gt;source/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Init project
uv sync
# Dev
uv run build.py --ttf-only --cn --debug
# Update nerd font
uv run task.py nerd-font
# Update fea file
uv run task.py fea
# Update landing page info
uv run task.py page --sync
# Merge two fonts
uv run task.py merge
# Release
uv run task.py release minor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Credit&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JetBrains/JetBrainsMono"&gt;JetBrains Mono&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/googlefonts/RobotoMono"&gt;Roboto Mono&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tonsky/FiraCode"&gt;Fira Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rubjo/victor-mono"&gt;Victor Mono&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/eigilnikolajsen/commit-mono"&gt;Commit Mono&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TheRenegadeCoder/sample-programs-website"&gt;Code Sample&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ryanoasis/nerd-fonts"&gt;Nerd Font&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MuTsunTsai/fontfreeze/"&gt;Font Freeze&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tophix.com/font-tools/font-viewer"&gt;Font Viewer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.monolisa.dev/"&gt;Monolisa&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.recursive.design/"&gt;Recursive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponser&lt;/h2&gt; 
&lt;p&gt;If this font is helpful to you, please feel free to buy me a coffee&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.buymeacoffee.com/subframe753"&gt;&lt;img src="https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&amp;amp;emoji=&amp;amp;slug=subframe753&amp;amp;button_colour=5F7FFF&amp;amp;font_colour=ffffff&amp;amp;font_family=Lato&amp;amp;outline_colour=000000&amp;amp;coffee_colour=FFDD00" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;or sponser me through &lt;a href="https://afdian.com/a/subframe7536"&gt;Afdian&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#subframe7536/maple-font&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=subframe7536/maple-font&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=subframe7536/maple-font&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=subframe7536/maple-font&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;SIL Open Font License 1.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/VibeVoice</title>
      <link>https://github.com/microsoft/VibeVoice</link>
      <description>&lt;p&gt;Open-Source Frontier Voice AI&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h2&gt;üéôÔ∏è VibeVoice: Open-Source Frontier Voice AI&lt;/h2&gt; 
 &lt;p&gt;&lt;a href="https://microsoft.github.io/VibeVoice"&gt;&lt;img src="https://img.shields.io/badge/Project-Page-blue?logo=microsoft" alt="Project Page" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/microsoft/vibevoice-68a2ef24a875c44be47b034f"&gt;&lt;img src="https://img.shields.io/badge/HuggingFace-Collection-orange?logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2508.19205"&gt;&lt;img src="https://img.shields.io/badge/Technical-Report-red?logo=adobeacrobatreader" alt="Technical Report" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="Figures/VibeVoice_logo_white.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/VibeVoice_logo.png" alt="VibeVoice Logo" width="300" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;h3&gt;üì∞ News&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/Status-New-brightgreen?style=flat" alt="New" /&gt; 
 &lt;img src="https://img.shields.io/badge/Feature-Realtime_TTS-blue?style=flat&amp;amp;logo=soundcharts" alt="Realtime TTS" /&gt; 
 &lt;p&gt;&lt;strong&gt;2025-12-16: üì£ We added more experimental speakers for exploration, including multilingual voices and 11 distinct English style voices. &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md#optional-more-experimental-voices"&gt;Try it&lt;/a&gt;. More speaker types will be added over time.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;2025-12-09: üì£ We added experimental speakers in nine languages (DE, FR, IT, JP, KR, NL, PL, PT, ES) for exploration‚Äîwelcome to try them out and share your feedback.&lt;/p&gt; 
 &lt;p&gt;2025-12-03: üì£ We open-sourced &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md"&gt;&lt;strong&gt;VibeVoice‚ÄëRealtime‚Äë0.5B&lt;/strong&gt;&lt;/a&gt;, a real‚Äëtime text‚Äëto‚Äëspeech model that supports streaming text input and robust long-form speech generation. Try it on &lt;a href="https://colab.research.google.com/github/microsoft/VibeVoice/blob/main/demo/vibevoice_realtime_colab.ipynb"&gt;Colab&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;To mitigate deepfake risks and ensure low latency for the first speech chunk, voice prompts are provided in an embedded format. For users requiring voice customization, please reach out to our team. We will also be expanding the range of available speakers. &lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/0901d274-f6ae-46ef-a0fd-3c4fba4f76dc"&gt;https://github.com/user-attachments/assets/0901d274-f6ae-46ef-a0fd-3c4fba4f76dc&lt;/a&gt;&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;(Launch your own realtime demo via the websocket example in &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md#usage-1-launch-real-time-websocket-demo"&gt;Usage&lt;/a&gt;).&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;2025-09-05: VibeVoice is an open-source research framework intended to advance collaboration in the speech synthesis community. After release, we discovered instances where the tool was used in ways inconsistent with the stated intent. Since responsible use of AI is one of Microsoft‚Äôs guiding principles, we have disabled this repo until we are confident that out-of-scope use is no longer possible.&lt;/p&gt; 
&lt;h3&gt;Overview&lt;/h3&gt; 
&lt;p&gt;VibeVoice is a novel framework designed for generating &lt;strong&gt;expressive&lt;/strong&gt;, &lt;strong&gt;long-form&lt;/strong&gt;, &lt;strong&gt;multi-speaker&lt;/strong&gt; conversational audio, such as podcasts, from text. It addresses significant challenges in traditional Text-to-Speech (TTS) systems, particularly in scalability, speaker consistency, and natural turn-taking.&lt;/p&gt; 
&lt;p&gt;VibeVoice currently includes two model variants:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Long-form multi-speaker model&lt;/strong&gt;: Synthesizes conversational/single-speaker speech up to &lt;strong&gt;90 minutes&lt;/strong&gt; with up to &lt;strong&gt;4 distinct speakers&lt;/strong&gt;, surpassing the typical 1‚Äì2 speaker limits of many prior models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md"&gt;Realtime streaming TTS model&lt;/a&gt;&lt;/strong&gt;: Produces initial audible speech in ~&lt;strong&gt;300 ms&lt;/strong&gt; and supports &lt;strong&gt;streaming text input&lt;/strong&gt; for single-speaker &lt;strong&gt;real-time&lt;/strong&gt; speech generation; designed for low-latency generation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;A core innovation of VibeVoice is its use of continuous speech tokenizers (Acoustic and Semantic) operating at an ultra-low frame rate of 7.5 Hz. These tokenizers efficiently preserve audio fidelity while significantly boosting computational efficiency for processing long sequences. VibeVoice employs a &lt;a href="https://arxiv.org/abs/2412.08635"&gt;next-token diffusion&lt;/a&gt; framework, leveraging a Large Language Model (LLM) to understand textual context and dialogue flow, and a diffusion head to generate high-fidelity acoustic details.&lt;/p&gt; 
&lt;p align="left"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/MOS-preference.png" alt="MOS Preference Results" height="260px" /&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/VibeVoice.jpg" alt="VibeVoice Overview" height="250px" style="margin-right: 10px;" /&gt; &lt;/p&gt; 
&lt;h3&gt;üéµ Demo Examples&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Video Demo&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We produced this video with &lt;a href="https://github.com/Wan-Video/Wan2.2"&gt;Wan2.2&lt;/a&gt;. We sincerely appreciate the Wan-Video team for their great work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/0967027c-141e-4909-bec8-091558b1b784"&gt;https://github.com/user-attachments/assets/0967027c-141e-4909-bec8-091558b1b784&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Chinese&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/322280b7-3093-4c67-86e3-10be4746c88f"&gt;https://github.com/user-attachments/assets/322280b7-3093-4c67-86e3-10be4746c88f&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Cross-Lingual&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/838d8ad9-a201-4dde-bb45-8cd3f59ce722"&gt;https://github.com/user-attachments/assets/838d8ad9-a201-4dde-bb45-8cd3f59ce722&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Spontaneous Singing&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/6f27a8a5-0c60-4f57-87f3-7dea2e11c730"&gt;https://github.com/user-attachments/assets/6f27a8a5-0c60-4f57-87f3-7dea2e11c730&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Long Conversation with 4 people&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/a357c4b6-9768-495c-a576-1618f6275727"&gt;https://github.com/user-attachments/assets/a357c4b6-9768-495c-a576-1618f6275727&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;For more examples, see the &lt;a href="https://microsoft.github.io/VibeVoice"&gt;Project Page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Risks and limitations&lt;/h2&gt; 
&lt;p&gt;While efforts have been made to optimize it through various techniques, it may still produce outputs that are unexpected, biased, or inaccurate. VibeVoice inherits any biases, errors, or omissions produced by its base model (specifically, Qwen2.5 1.5b in this release). Potential for Deepfakes and Disinformation: High-quality synthetic speech can be misused to create convincing fake audio content for impersonation, fraud, or spreading disinformation. Users must ensure transcripts are reliable, check content accuracy, and avoid using generated content in misleading ways. Users are expected to use the generated content and to deploy the models in a lawful manner, in full compliance with all applicable laws and regulations in the relevant jurisdictions. It is best practice to disclose the use of AI when sharing AI-generated content.&lt;/p&gt; 
&lt;p&gt;English and Chinese only: Transcripts in languages other than English or Chinese may result in unexpected audio outputs.&lt;/p&gt; 
&lt;p&gt;Non-Speech Audio: The model focuses solely on speech synthesis and does not handle background noise, music, or other sound effects.&lt;/p&gt; 
&lt;p&gt;Overlapping Speech: The current model does not explicitly model or generate overlapping speech segments in conversations.&lt;/p&gt; 
&lt;p&gt;We do not recommend using VibeVoice in commercial or real-world applications without further testing and development. This model is intended for research and development purposes only. Please use responsibly.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://api.star-history.com/svg?repos=Microsoft/vibevoice&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sherlock-project/sherlock</title>
      <link>https://github.com/sherlock-project/sherlock</link>
      <description>&lt;p&gt;Hunt down social media accounts by username across social networks&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;br /&gt; &lt;a href="https://sherlock-project.github.io/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/sherlock-project/sherlock/master/images/sherlock-logo.png" alt="sherlock" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;span&gt;Hunt down social media accounts by username across &lt;a href="https://sherlockproject.xyz/sites"&gt;400+ social networks&lt;/a&gt;&lt;/span&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://sherlockproject.xyz/installation"&gt;Installation&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://sherlockproject.xyz/usage"&gt;Usage&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://sherlockproject.xyz/contribute"&gt;Contributing&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="70%" height="70%" src="https://raw.githubusercontent.com/sherlock-project/sherlock/master/images/demo.png" alt="demo" /&gt; &lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;br /&gt; Packages for ParrotOS and Ubuntu 24.04, maintained by a third party, appear to be &lt;strong&gt;broken&lt;/strong&gt;.&lt;br /&gt; Users of these systems should defer to pipx/pip or Docker.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pipx install sherlock-project&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pip&lt;/code&gt; may be used in place of &lt;code&gt;pipx&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;docker run -it --rm sherlock/sherlock&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dnf install sherlock-project&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Community-maintained packages are available for Debian (&amp;gt;= 13), Ubuntu (&amp;gt;= 22.10), Homebrew, Kali, and BlackArch. These packages are not directly supported or maintained by the Sherlock Project.&lt;/p&gt; 
&lt;p&gt;See all alternative installation methods &lt;a href="https://sherlockproject.xyz/installation"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;General usage&lt;/h2&gt; 
&lt;p&gt;To search for only one user:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sherlock user123
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To search for more than one user:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sherlock user1 user2 user3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Accounts found will be stored in an individual text file with the corresponding username (e.g &lt;code&gt;user123.txt&lt;/code&gt;).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ sherlock --help
usage: sherlock [-h] [--version] [--verbose] [--folderoutput FOLDEROUTPUT]
                [--output OUTPUT] [--tor] [--unique-tor] [--csv] [--xlsx]
                [--site SITE_NAME] [--proxy PROXY_URL] [--json JSON_FILE]
                [--timeout TIMEOUT] [--print-all] [--print-found] [--no-color]
                [--browse] [--local] [--nsfw]
                USERNAMES [USERNAMES ...]

Sherlock: Find Usernames Across Social Networks (Version 0.14.3)

positional arguments:
  USERNAMES             One or more usernames to check with social networks.
                        Check similar usernames using {?} (replace to '_', '-', '.').

optional arguments:
  -h, --help            show this help message and exit
  --version             Display version information and dependencies.
  --verbose, -v, -d, --debug
                        Display extra debugging information and metrics.
  --folderoutput FOLDEROUTPUT, -fo FOLDEROUTPUT
                        If using multiple usernames, the output of the results will be
                        saved to this folder.
  --output OUTPUT, -o OUTPUT
                        If using single username, the output of the result will be saved
                        to this file.
  --tor, -t             Make requests over Tor; increases runtime; requires Tor to be
                        installed and in system path.
  --unique-tor, -u      Make requests over Tor with new Tor circuit after each request;
                        increases runtime; requires Tor to be installed and in system
                        path.
  --csv                 Create Comma-Separated Values (CSV) File.
  --xlsx                Create the standard file for the modern Microsoft Excel
                        spreadsheet (xlsx).
  --site SITE_NAME      Limit analysis to just the listed sites. Add multiple options to
                        specify more than one site.
  --proxy PROXY_URL, -p PROXY_URL
                        Make requests over a proxy. e.g. socks5://127.0.0.1:1080
  --json JSON_FILE, -j JSON_FILE
                        Load data from a JSON file or an online, valid, JSON file.
  --timeout TIMEOUT     Time (in seconds) to wait for response to requests (Default: 60)
  --print-all           Output sites where the username was not found.
  --print-found         Output sites where the username was found.
  --no-color            Don't color terminal output
  --browse, -b          Browse to all results on default browser.
  --local, -l           Force the use of the local data.json file.
  --nsfw                Include checking of NSFW sites from default list.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Apify Actor Usage &lt;a href="https://apify.com/netmilk/sherlock?fpr=sherlock"&gt;&lt;img src="https://apify.com/actor-badge?actor=netmilk/sherlock" alt="Sherlock Actor" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://apify.com/netmilk/sherlock?fpr=sherlock"&gt;&lt;img src="https://apify.com/ext/run-on-apify.png" alt="Run Sherlock Actor on Apify" width="176" height="39" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can run Sherlock in the cloud without installation using the &lt;a href="https://apify.com/netmilk/sherlock?fpr=sherlock"&gt;Sherlock Actor&lt;/a&gt; on &lt;a href="https://apify.com?fpr=sherlock"&gt;Apify&lt;/a&gt; free of charge.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ echo '{"usernames":["user123"]}' | apify call -so netmilk/sherlock
[{
  "username": "user123",
  "links": [
    "https://www.1337x.to/user/user123/",
    ...
  ]
}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about the &lt;a href="https://raw.githubusercontent.com/sherlock-project/sherlock/.actor/README.md"&gt;Sherlock Actor&lt;/a&gt;, including how to use it programmatically via the Apify &lt;a href="https://apify.com/netmilk/sherlock/api?fpr=sherlock"&gt;API&lt;/a&gt;, &lt;a href="https://docs.apify.com/cli/?fpr=sherlock"&gt;CLI&lt;/a&gt; and &lt;a href="https://docs.apify.com/sdk?fpr=sherlock"&gt;JS/TS and Python SDKs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Thank you to everyone who has contributed to Sherlock! ‚ù§Ô∏è&lt;/p&gt; 
&lt;a href="https://github.com/sherlock-project/sherlock/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?&amp;amp;columns=25&amp;amp;max=10000&amp;amp;&amp;amp;repo=sherlock-project/sherlock" alt="contributors" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=sherlock-project/sherlock&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=sherlock-project/sherlock&amp;amp;type=Date" /&gt; 
 &lt;img alt="Sherlock Project Star History Chart" src="https://api.star-history.com/svg?repos=sherlock-project/sherlock&amp;amp;type=Date" /&gt; 
&lt;/picture&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT ¬© Sherlock Project&lt;br /&gt; Original Creator - &lt;a href="https://github.com/sdushantha"&gt;Siddharth Dushantha&lt;/a&gt;&lt;/p&gt; 
&lt;!-- Reference Links --&gt;</description>
    </item>
    
    <item>
      <title>datawhalechina/hello-agents</title>
      <link>https://github.com/datawhalechina/hello-agents</link>
      <description>&lt;p&gt;üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã&lt;/p&gt;&lt;hr&gt;&lt;div align="right"&gt; 
 &lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/README_EN.md"&gt;English&lt;/a&gt; | ‰∏≠Êñá 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/hello-agents.png" alt="alt text" width="100%" /&gt; 
 &lt;h1&gt;Hello-Agents&lt;/h1&gt; 
 &lt;h3&gt;ü§ñ „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/15520" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15520" alt="datawhalechina%2Fhello-agents | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;em&gt;‰ªéÂü∫Á°ÄÁêÜËÆ∫Âà∞ÂÆûÈôÖÂ∫îÁî®ÔºåÂÖ®Èù¢ÊéåÊè°Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂÆûÁé∞&lt;/em&gt;&lt;/p&gt; 
 &lt;img src="https://img.shields.io/github/stars/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub stars" /&gt; 
 &lt;img src="https://img.shields.io/github/forks/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub forks" /&gt; 
 &lt;img src="https://img.shields.io/badge/language-Chinese-brightgreen?style=flat" alt="Language" /&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents"&gt;&lt;img src="https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;amp;logo=github" alt="GitHub Project" /&gt;&lt;/a&gt; 
 &lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;&lt;img src="https://img.shields.io/badge/Âú®Á∫øÈòÖËØª-Online%20Reading-green?style=flat&amp;amp;logo=gitbook" alt="Online Reading" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ È°πÁõÆ‰ªãÁªç&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÂ¶ÇÊûúËØ¥ 2024 Âπ¥ÊòØ"ÁôæÊ®°Â§ßÊàò"ÁöÑÂÖÉÂπ¥ÔºåÈÇ£‰πà 2025 Âπ¥Êó†ÁñëÂºÄÂêØ‰∫Ü"Agent ÂÖÉÂπ¥"„ÄÇÊäÄÊúØÁöÑÁÑ¶ÁÇπÊ≠£‰ªéËÆ≠ÁªÉÊõ¥Â§ßÁöÑÂü∫Á°ÄÊ®°ÂûãÔºåËΩ¨ÂêëÊûÑÂª∫Êõ¥ËÅ™ÊòéÁöÑÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁ≥ªÁªüÊÄß„ÄÅÈáçÂÆûË∑µÁöÑÊïôÁ®ãÂç¥ÊûÅÂ∫¶ÂåÆ‰πè„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂèëËµ∑‰∫Ü Hello-Agents È°πÁõÆÔºåÂ∏åÊúõËÉΩ‰∏∫Á§æÂå∫Êèê‰æõ‰∏ÄÊú¨‰ªéÈõ∂ÂºÄÂßã„ÄÅÁêÜËÆ∫‰∏éÂÆûÊàòÂπ∂ÈáçÁöÑÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÊûÑÂª∫ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉHello-Agents ÊòØ Datawhale Á§æÂå∫ÁöÑ&lt;strong&gt;Á≥ªÁªüÊÄßÊô∫ËÉΩ‰ΩìÂ≠¶‰π†ÊïôÁ®ã&lt;/strong&gt;„ÄÇÂ¶Ç‰ªä Agent ÊûÑÂª∫‰∏ªË¶ÅÂàÜ‰∏∫‰∏§Ê¥æÔºå‰∏ÄÊ¥æÊòØ DifyÔºåCozeÔºån8n ËøôÁ±ªËΩØ‰ª∂Â∑•Á®ãÁ±ª AgentÔºåÂÖ∂Êú¨Ë¥®ÊòØÊµÅÁ®ãÈ©±Âä®ÁöÑËΩØ‰ª∂ÂºÄÂèëÔºåLLM ‰Ωú‰∏∫Êï∞ÊçÆÂ§ÑÁêÜÁöÑÂêéÁ´ØÔºõÂè¶‰∏ÄÊ¥æÂàôÊòØ AI ÂéüÁîüÁöÑ AgentÔºåÂç≥ÁúüÊ≠£‰ª• AI È©±Âä®ÁöÑ Agent„ÄÇÊú¨ÊïôÁ®ãÊó®Âú®Â∏¶È¢ÜÂ§ßÂÆ∂Ê∑±ÂÖ•ÁêÜËß£Âπ∂ÊûÑÂª∫ÂêéËÄÖ‚Äî‚ÄîÁúüÊ≠£ÁöÑ AI Native Agent„ÄÇÊïôÁ®ãÂ∞ÜÂ∏¶È¢Ü‰Ω†Á©øÈÄèÊ°ÜÊû∂Ë°®Ë±°Ôºå‰ªéÊô∫ËÉΩ‰ΩìÁöÑÊ†∏ÂøÉÂéüÁêÜÂá∫ÂèëÔºåÊ∑±ÂÖ•ÂÖ∂Ê†∏ÂøÉÊû∂ÊûÑÔºåÁêÜËß£ÂÖ∂ÁªèÂÖ∏ËåÉÂºèÔºåÂπ∂ÊúÄÁªà‰∫≤ÊâãÊûÑÂª∫Ëµ∑Â±û‰∫éËá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÊàë‰ª¨Áõ∏‰ø°ÔºåÊúÄÂ•ΩÁöÑÂ≠¶‰π†ÊñπÂºèÂ∞±ÊòØÂä®ÊâãÂÆûË∑µ„ÄÇÂ∏åÊúõËøôÊú¨ÊïôÁ®ãËÉΩÊàê‰∏∫‰Ω†Êé¢Á¥¢Êô∫ËÉΩ‰Ωì‰∏ñÁïåÁöÑËµ∑ÁÇπÔºåËÉΩÂ§ü‰ªé‰∏ÄÂêçÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ"‰ΩøÁî®ËÄÖ"ÔºåËúïÂèò‰∏∫‰∏ÄÂêçÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑ"ÊûÑÂª∫ËÄÖ"„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üìö Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;h3&gt;Âú®Á∫øÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;üåê ÁÇπÂáªËøôÈáåÂºÄÂßãÂú®Á∫øÈòÖËØª&lt;/a&gt;&lt;/strong&gt; - Êó†ÈúÄ‰∏ãËΩΩÔºåÈöèÊó∂ÈöèÂú∞Â≠¶‰π†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://book.heterocat.com.cn/"&gt;üìñ Cookbook(ÊµãËØïÁâà)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Êú¨Âú∞ÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®Êú¨Âú∞ÈòÖËØªÊàñË¥°ÁåÆÂÜÖÂÆπÔºåËØ∑ÂèÇËÄÉ‰∏ãÊñπÁöÑÂ≠¶‰π†ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;h3&gt;‚ú® ‰Ω†Â∞ÜÊî∂Ëé∑‰ªÄ‰πàÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Datawhale ÂºÄÊ∫êÂÖçË¥π&lt;/strong&gt; ÂÆåÂÖ®ÂÖçË¥πÂ≠¶‰π†Êú¨È°πÁõÆÊâÄÊúâÂÜÖÂÆπÔºå‰∏éÁ§æÂå∫ÂÖ±ÂêåÊàêÈïø&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;ÁêÜËß£Ê†∏ÂøÉÂéüÁêÜ&lt;/strong&gt; Ê∑±ÂÖ•ÁêÜËß£Êô∫ËÉΩ‰ΩìÁöÑÊ¶ÇÂøµ„ÄÅÂéÜÂè≤‰∏éÁªèÂÖ∏ËåÉÂºè&lt;/li&gt; 
 &lt;li&gt;üèóÔ∏è &lt;strong&gt;‰∫≤ÊâãÂÆûÁé∞&lt;/strong&gt; ÊéåÊè°ÁÉ≠Èó®‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÂíåÊô∫ËÉΩ‰Ωì‰ª£Á†ÅÊ°ÜÊû∂ÁöÑ‰ΩøÁî®&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;strong&gt;Ëá™Á†îÊ°ÜÊû∂&lt;a href="https://github.com/jjyaoao/helloagents"&gt;HelloAgents&lt;/a&gt;&lt;/strong&gt; Âü∫‰∫é Openai ÂéüÁîü API ‰ªéÈõ∂ÊûÑÂª∫‰∏Ä‰∏™Ëá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;ÊéåÊè°È´òÁ∫ßÊäÄËÉΩ&lt;/strong&gt; ‰∏ÄÊ≠•Ê≠•ÂÆûÁé∞‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅMemory„ÄÅÂçèËÆÆ„ÄÅËØÑ‰º∞Á≠âÁ≥ªÁªüÊÄßÊäÄÊúØ&lt;/li&gt; 
 &lt;li&gt;ü§ù &lt;strong&gt;Ê®°ÂûãËÆ≠ÁªÉ&lt;/strong&gt; ÊéåÊè° Agentic RLÔºå‰ªé SFT Âà∞ GRPO ÁöÑÂÖ®ÊµÅÁ®ãÂÆûÊàòËÆ≠ÁªÉ LLM&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;È©±Âä®ÁúüÂÆûÊ°à‰æã&lt;/strong&gt; ÂÆûÊàòÂºÄÂèëÊô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËµõÂçöÂ∞èÈïáÁ≠âÁªºÂêàÈ°πÁõÆ&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Ê±ÇËÅåÈù¢ËØï&lt;/strong&gt; Â≠¶‰π†Êô∫ËÉΩ‰ΩìÊ±ÇËÅåÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ ÂÜÖÂÆπÂØºËà™&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á´†ËäÇ&lt;/th&gt; 
   &lt;th&gt;ÂÖ≥ÈîÆÂÜÖÂÆπ&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/%E5%89%8D%E8%A8%80.md"&gt;ÂâçË®Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;È°πÁõÆÁöÑÁºòËµ∑„ÄÅËÉåÊôØÂèäËØªËÄÖÂª∫ËÆÆ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%88%9D%E8%AF%86%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨‰∏ÄÁ´† ÂàùËØÜÊô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Êô∫ËÉΩ‰ΩìÂÆö‰πâ„ÄÅÁ±ªÂûã„ÄÅËåÉÂºè‰∏éÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter2/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E5%8F%91%E5%B1%95%E5%8F%B2.md"&gt;Á¨¨‰∫åÁ´† Êô∫ËÉΩ‰ΩìÂèëÂ±ïÂè≤&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªéÁ¨¶Âè∑‰∏ª‰πâÂà∞ LLM È©±Âä®ÁöÑÊô∫ËÉΩ‰ΩìÊºîËøõ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter3/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md"&gt;Á¨¨‰∏âÁ´† Â§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Transformer„ÄÅÊèêÁ§∫„ÄÅ‰∏ªÊµÅ LLM ÂèäÂÖ∂Â±ÄÈôê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA.md"&gt;Á¨¨ÂõõÁ´† Êô∫ËÉΩ‰ΩìÁªèÂÖ∏ËåÉÂºèÊûÑÂª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊâãÊääÊâãÂÆûÁé∞ ReAct„ÄÅPlan-and-Solve„ÄÅReflection&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter5/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%9F%BA%E4%BA%8E%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E6%90%AD%E5%BB%BA.md"&gt;Á¨¨‰∫îÁ´† Âü∫‰∫é‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÊê≠Âª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∫ÜËß£ Coze„ÄÅDify„ÄÅn8n Á≠â‰Ωé‰ª£Á†ÅÊô∫ËÉΩ‰ΩìÂπ≥Âè∞‰ΩøÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5.md"&gt;Á¨¨ÂÖ≠Á´† Ê°ÜÊû∂ÂºÄÂèëÂÆûË∑µ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AutoGen„ÄÅAgentScope„ÄÅLangGraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂Â∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter7/%E7%AC%AC%E4%B8%83%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84Agent%E6%A1%86%E6%9E%B6.md"&gt;Á¨¨‰∏ÉÁ´† ÊûÑÂª∫‰Ω†ÁöÑAgentÊ°ÜÊû∂&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé 0 ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter8/%E7%AC%AC%E5%85%AB%E7%AB%A0%20%E8%AE%B0%E5%BF%86%E4%B8%8E%E6%A3%80%E7%B4%A2.md"&gt;Á¨¨ÂÖ´Á´† ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ËÆ∞ÂøÜÁ≥ªÁªüÔºåRAGÔºåÂ≠òÂÇ®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter9/%E7%AC%AC%E4%B9%9D%E7%AB%A0%20%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B.md"&gt;Á¨¨‰πùÁ´† ‰∏ä‰∏ãÊñáÂ∑•Á®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊåÅÁª≠‰∫§‰∫íÁöÑ"ÊÉÖÂ¢ÉÁêÜËß£"&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter10/%E7%AC%AC%E5%8D%81%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE.md"&gt;Á¨¨ÂçÅÁ´† Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP„ÄÅA2A„ÄÅANP Á≠âÂçèËÆÆËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter11/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%20Agentic-RL.md"&gt;Á¨¨ÂçÅ‰∏ÄÁ´† Agentic-RL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé SFT Âà∞ GRPO ÁöÑ LLM ËÆ≠ÁªÉÂÆûÊàò&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter12/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0.md"&gt;Á¨¨ÂçÅ‰∫åÁ´† Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ê†∏ÂøÉÊåáÊ†á„ÄÅÂü∫ÂáÜÊµãËØï‰∏éËØÑ‰º∞Ê°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter13/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%20%E6%99%BA%E8%83%BD%E6%97%85%E8%A1%8C%E5%8A%A9%E6%89%8B.md"&gt;Á¨¨ÂçÅ‰∏âÁ´† Êô∫ËÉΩÊóÖË°åÂä©Êâã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP ‰∏éÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÁöÑÁúüÂÆû‰∏ñÁïåÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter14/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%20%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨ÂçÅÂõõÁ´† Ëá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DeepResearch Agent Â§çÁé∞‰∏éËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter15/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E8%B5%9B%E5%8D%9A%E5%B0%8F%E9%95%87.md"&gt;Á¨¨ÂçÅ‰∫îÁ´† ÊûÑÂª∫ËµõÂçöÂ∞èÈïá&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent ‰∏éÊ∏∏ÊàèÁöÑÁªìÂêàÔºåÊ®°ÊãüÁ§æ‰ºöÂä®ÊÄÅ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter16/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0%20%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1.md"&gt;Á¨¨ÂçÅÂÖ≠Á´† ÊØï‰∏öËÆæËÆ°&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊûÑÂª∫Â±û‰∫é‰Ω†ÁöÑÂÆåÊï¥Â§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ (Community Blog)&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢ËøéÂ§ßÂÆ∂Â∞ÜÂú®Â≠¶‰π† Hello-Agents Êàñ Agent Áõ∏ÂÖ≥ÊäÄÊúØ‰∏≠ÁöÑÁã¨Âà∞ËßÅËß£„ÄÅÂÆûË∑µÊÄªÁªìÔºå‰ª• PR ÁöÑÂΩ¢ÂºèË¥°ÁåÆÂà∞Á§æÂå∫Á≤æÈÄâ„ÄÇÂ¶ÇÊûúÊòØÁã¨Á´ã‰∫éÊ≠£ÊñáÁöÑÂÜÖÂÆπÔºå‰πüÂèØ‰ª•ÊäïÁ®øËá≥ Extra-ChapterÔºÅ&lt;strong&gt;ÊúüÂæÖ‰Ω†ÁöÑÁ¨¨‰∏ÄÊ¨°Ë¥°ÁåÆÔºÅ&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á§æÂå∫Á≤æÈÄâ&lt;/th&gt; 
   &lt;th&gt;ÂÜÖÂÆπÊÄªÁªì&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md"&gt;01-AgentÈù¢ËØïÈ¢òÊÄªÁªì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent Â≤ó‰ΩçÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88.md"&gt;01-AgentÈù¢ËØïÈ¢òÁ≠îÊ°à&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Áõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢òÁ≠îÊ°à&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra02-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86.md"&gt;02-‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπË°•ÂÖÖ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπÊâ©Â±ï&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra03-Dify%E6%99%BA%E8%83%BD%E4%BD%93%E5%88%9B%E5%BB%BA%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B.md"&gt;03-DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra04-DatawhaleFAQ.md"&gt;04-Hello-agentsËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DatawhaleËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra05-AgentSkills%E8%A7%A3%E8%AF%BB.md"&gt;05-Agent Skills‰∏éMCPÂØπÊØîËß£ËØª&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent Skills‰∏éMCPÊäÄÊúØÂØπÊØî&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra06-GUIAgent%E7%A7%91%E6%99%AE%E4%B8%8E%E5%AE%9E%E6%88%98.md"&gt;06-GUI AgentÁßëÊôÆ‰∏éÂÆûÊàò&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GUI AgentÁßëÊôÆ‰∏éÂ§öÂú∫ÊôØÂÆûÊàò&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;PDF ÁâàÊú¨‰∏ãËΩΩ&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉ&lt;em&gt;&lt;strong&gt;Êú¨ Hello-Agents PDF ÊïôÁ®ãÂÆåÂÖ®ÂºÄÊ∫êÂÖçË¥π„ÄÇ‰∏∫Èò≤Ê≠¢ÂêÑÁ±ªËê•ÈîÄÂè∑Âä†Ê∞¥Âç∞ÂêéË¥©ÂçñÁªôÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÂàùÂ≠¶ËÄÖÔºåÊàë‰ª¨ÁâπÂú∞Âú® PDF Êñá‰ª∂‰∏≠È¢ÑÂÖàÊ∑ªÂä†‰∫Ü‰∏çÂΩ±ÂìçÈòÖËØªÁöÑ Datawhale ÂºÄÊ∫êÊ†áÂøóÊ∞¥Âç∞ÔºåÊï¨ËØ∑Ë∞ÖËß£ÔΩû&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Hello-Agents PDF : &lt;a href="https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0"&gt;https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0&lt;/a&gt;&lt;/em&gt;&lt;br /&gt; &lt;em&gt;Hello-Agents PDF ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄ : &lt;a href="https://www.datawhale.cn/learn/summary/239"&gt;https://www.datawhale.cn/learn/summary/239&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üí° Â¶Ç‰ΩïÂ≠¶‰π†&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢Ëøé‰Ω†ÔºåÊú™Êù•ÁöÑÊô∫ËÉΩÁ≥ªÁªüÊûÑÂª∫ËÄÖÔºÅÂú®ÂºÄÂêØËøôÊÆµÊøÄÂä®‰∫∫ÂøÉÁöÑÊóÖÁ®ã‰πãÂâçÔºåËØ∑ÂÖÅËÆ∏Êàë‰ª¨Áªô‰Ω†‰∏Ä‰∫õÊ∏ÖÊô∞ÁöÑÊåáÂºï„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊú¨È°πÁõÆÂÜÖÂÆπÂÖºÈ°æÁêÜËÆ∫‰∏éÂÆûÊàòÔºåÊó®Âú®Â∏ÆÂä©‰Ω†Á≥ªÁªüÊÄßÂú∞ÊéåÊè°‰ªéÂçï‰∏™Êô∫ËÉΩ‰ΩìÂà∞Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂºÄÂèëÂÖ®ÊµÅÁ®ã„ÄÇÂõ†Ê≠§ÔºåÂ∞§ÂÖ∂ÈÄÇÂêàÊúâ‰∏ÄÂÆöÁºñÁ®ãÂü∫Á°ÄÁöÑ &lt;strong&gt;AI ÂºÄÂèëËÄÖ„ÄÅËΩØ‰ª∂Â∑•Á®ãÂ∏à„ÄÅÂú®Ê†°Â≠¶Áîü&lt;/strong&gt; ‰ª•ÂèäÂØπÂâçÊ≤ø AI ÊäÄÊúØÊä±ÊúâÊµìÂéöÂÖ¥Ë∂£ÁöÑ &lt;strong&gt;Ëá™Â≠¶ËÄÖ&lt;/strong&gt;„ÄÇÂú®Â≠¶‰π†Êú¨È°πÁõÆ‰πãÂâçÔºåÊàë‰ª¨Â∏åÊúõ‰Ω†ÂÖ∑Â§áÂü∫Á°ÄÁöÑ Python ÁºñÁ®ãËÉΩÂäõÔºåÂπ∂ÂØπÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúâÂü∫Êú¨ÁöÑÊ¶ÇÂøµÊÄß‰∫ÜËß£Ôºà‰æãÂ¶ÇÔºåÁü•ÈÅìÂ¶Ç‰ΩïÈÄöËøá API Ë∞ÉÁî®‰∏Ä‰∏™ LLMÔºâ„ÄÇÈ°πÁõÆÁöÑÈáçÁÇπÊòØÂ∫îÁî®‰∏éÊûÑÂª∫ÔºåÂõ†Ê≠§‰Ω†Êó†ÈúÄÂÖ∑Â§áÊ∑±ÂéöÁöÑÁÆóÊ≥ïÊàñÊ®°ÂûãËÆ≠ÁªÉËÉåÊôØ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÈ°πÁõÆÂàÜ‰∏∫‰∫îÂ§ßÈÉ®ÂàÜÔºåÊØè‰∏ÄÈÉ®ÂàÜÈÉΩÊòØÈÄöÂæÄ‰∏ã‰∏ÄÈò∂ÊÆµÁöÑÂùöÂÆûÈò∂Ê¢ØÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;ÔºàÁ¨¨‰∏ÄÁ´†ÔΩûÁ¨¨‰∏âÁ´†ÔºâÔºåÊàë‰ª¨Â∞Ü‰ªéÊô∫ËÉΩ‰ΩìÁöÑÂÆö‰πâ„ÄÅÁ±ªÂûã‰∏éÂèëÂ±ïÂéÜÂè≤ËÆ≤Ëµ∑Ôºå‰∏∫‰Ω†Ê¢≥ÁêÜ"Êô∫ËÉΩ‰Ωì"Ëøô‰∏ÄÊ¶ÇÂøµÁöÑÊù•ÈæôÂéªËÑâ„ÄÇÈöèÂêéÔºåÊàë‰ª¨‰ºöÂø´ÈÄüÂ∑©Âõ∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ†∏ÂøÉÁü•ËØÜÔºå‰∏∫‰Ω†ÁöÑÂÆûË∑µ‰πãÊóÖÊâì‰∏ãÂùöÂÆûÁöÑÁêÜËÆ∫Âú∞Âü∫„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;ÔºàÁ¨¨ÂõõÁ´†ÔΩûÁ¨¨‰∏ÉÁ´†ÔºâÔºåËøôÊòØ‰Ω†Âä®ÊâãÂÆûË∑µÁöÑËµ∑ÁÇπ„ÄÇ‰Ω†Â∞Ü‰∫≤ÊâãÂÆûÁé∞ ReAct Á≠âÁªèÂÖ∏ËåÉÂºèÔºå‰ΩìÈ™å Coze Á≠â‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑ‰æøÊç∑ÔºåÂπ∂ÊéåÊè° Langgraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂ÁöÑÂ∫îÁî®„ÄÇÊúÄÁªàÔºåÊàë‰ª¨Ëøò‰ºöÂ∏¶‰Ω†‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫‰∏Ä‰∏™Â±û‰∫éËá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåËÆ©‰Ω†ÂÖºÂÖ∑‚ÄúÁî®ËΩÆÂ≠ê‚Äù‰∏é‚ÄúÈÄ†ËΩÆÂ≠ê‚ÄùÁöÑËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;ÔºàÁ¨¨ÂÖ´Á´†ÔΩûÁ¨¨ÂçÅ‰∫åÁ´†ÔºâÔºåÂú®Ëøô‰∏ÄÈÉ®ÂàÜÔºå‰Ω†ÁöÑÊô∫ËÉΩ‰ΩìÂ∞Ü‚ÄúÂ≠¶‰ºö‚ÄùÊÄùËÄÉ‰∏éÂçè‰Ωú„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®Á¨¨‰∫åÈÉ®ÂàÜÁöÑËá™Á†îÊ°ÜÊû∂ÔºåÊ∑±ÂÖ•Êé¢Á¥¢ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢„ÄÅ‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅAgent ËÆ≠ÁªÉÁ≠âÊ†∏ÂøÉÊäÄÊúØÔºåÂπ∂Â≠¶‰π†Â§öÊô∫ËÉΩ‰ΩìÈó¥ÁöÑÈÄö‰ø°ÂçèËÆÆ„ÄÇÊúÄÁªàÔºå‰Ω†Â∞ÜÊéåÊè°ËØÑ‰º∞Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÊÄßËÉΩÁöÑ‰∏ì‰∏öÊñπÊ≥ï„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;ÔºàÁ¨¨ÂçÅ‰∏âÁ´†ÔΩûÁ¨¨ÂçÅ‰∫îÁ´†ÔºâÔºåËøôÈáåÊòØÁêÜËÆ∫‰∏éÂÆûË∑µÁöÑ‰∫§Ê±áÁÇπ„ÄÇ‰Ω†Â∞ÜÊääÊâÄÂ≠¶Ëûç‰ºöË¥ØÈÄöÔºå‰∫≤ÊâãÊâìÈÄ†Êô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰ΩìÔºå‰πÉËá≥‰∏Ä‰∏™Ê®°ÊãüÁ§æ‰ºöÂä®ÊÄÅÁöÑËµõÂçöÂ∞èÈïáÔºåÂú®ÁúüÂÆûÊúâË∂£ÁöÑÈ°πÁõÆ‰∏≠Ê∑¨ÁÇº‰Ω†ÁöÑÊûÑÂª∫ËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;ÔºàÁ¨¨ÂçÅÂÖ≠Á´†ÔºâÔºåÂú®ÊóÖÁ®ãÁöÑÁªàÁÇπÔºå‰Ω†Â∞ÜËøéÊù•‰∏Ä‰∏™ÊØï‰∏öËÆæËÆ°ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄÅÂ±û‰∫é‰Ω†Ëá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®ÔºåÂÖ®Èù¢Ê£ÄÈ™å‰Ω†ÁöÑÂ≠¶‰π†ÊàêÊûú„ÄÇÊàë‰ª¨ËøòÂ∞Ü‰∏é‰Ω†‰∏ÄÂêåÂ±ïÊúõÊô∫ËÉΩ‰ΩìÁöÑÊú™Êù•ÔºåÊé¢Á¥¢ÊøÄÂä®‰∫∫ÂøÉÁöÑÂâçÊ≤øÊñπÂêë„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊô∫ËÉΩ‰ΩìÊòØ‰∏Ä‰∏™È£ûÈÄüÂèëÂ±ï‰∏îÊûÅÂ∫¶‰æùËµñÂÆûË∑µÁöÑÈ¢ÜÂüü„ÄÇ‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥ÁöÑÂ≠¶‰π†ÊïàÊûúÔºåÊàë‰ª¨Âú®È°πÁõÆÁöÑ&lt;code&gt;code&lt;/code&gt;Êñá‰ª∂Â§πÂÜÖÊèê‰æõ‰∫ÜÈÖçÂ•óÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºåÂº∫ÁÉàÂª∫ËÆÆ‰Ω†&lt;strong&gt;Â∞ÜÁêÜËÆ∫‰∏éÂÆûË∑µÁõ∏ÁªìÂêà&lt;/strong&gt;„ÄÇËØ∑Âä°ÂøÖ‰∫≤ÊâãËøêË°å„ÄÅË∞ÉËØïÁîöËá≥‰øÆÊîπÈ°πÁõÆÈáåÊèê‰æõÁöÑÊØè‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇÊ¨¢Ëøé‰Ω†ÈöèÊó∂ÂÖ≥Ê≥® Datawhale ‰ª•ÂèäÂÖ∂‰ªñ Agent Áõ∏ÂÖ≥Á§æÂå∫ÔºåÂΩìÈÅáÂà∞ÈóÆÈ¢òÊó∂Ôºå‰Ω†ÂèØ‰ª•ÈöèÊó∂Âú®Êú¨È°πÁõÆÁöÑ issue Âå∫ÊèêÈóÆ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÁé∞Âú®ÔºåÂáÜÂ§áÂ•ΩËøõÂÖ•Êô∫ËÉΩ‰ΩìÁöÑÂ•áÂ¶ô‰∏ñÁïå‰∫ÜÂêóÔºüËÆ©Êàë‰ª¨Âç≥ÂàªÂêØÁ®ãÔºÅ&lt;/p&gt; 
&lt;h2&gt;‰∏ã‰∏ÄÊ≠•ËßÑÂàí&lt;/h2&gt; 
&lt;p&gt;ÂèåËØ≠ËßÜÈ¢ëËØæÁ®ã[Ëã±Êñá+‰∏≠Êñá]ÔºàÂ∞Ü‰ºöÊõ¥Âä†ÁªÜËá¥ÔºåÂÆûË∑µËØæÂ∏¶È¢ÜÂ§ßÂÆ∂‰ªéËÆæËÆ°ÊÄùË∑ØÂà∞ÂÆûÊñΩÔºåÊéà‰∫∫‰ª•È±º‰πüÊéà‰∫∫‰ª•Ê∏îÔºâ&lt;/p&gt; 
&lt;h2&gt;ü§ù Â¶Ç‰ΩïË¥°ÁåÆ&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨ÊòØ‰∏Ä‰∏™ÂºÄÊîæÁöÑÂºÄÊ∫êÁ§æÂå∫ÔºåÊ¨¢Ëøé‰ªª‰ΩïÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Êä•Âëä Bug&lt;/strong&gt; - ÂèëÁé∞ÂÜÖÂÆπÊàñ‰ª£Á†ÅÈóÆÈ¢òÔºåËØ∑Êèê‰∫§ Issue&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;ÊèêÂá∫Âª∫ËÆÆ&lt;/strong&gt; - ÂØπÈ°πÁõÆÊúâÂ•ΩÊÉ≥Ê≥ïÔºåÊ¨¢ËøéÂèëËµ∑ËÆ®ËÆ∫&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;ÂÆåÂñÑÂÜÖÂÆπ&lt;/strong&gt; - Â∏ÆÂä©ÊîπËøõÊïôÁ®ãÔºåÊèê‰∫§‰Ω†ÁöÑ Pull Request&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;strong&gt;ÂàÜ‰∫´ÂÆûË∑µ&lt;/strong&gt; - Âú®"Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ"‰∏≠ÂàÜ‰∫´‰Ω†ÁöÑÂ≠¶‰π†Á¨îËÆ∞ÂíåÈ°πÁõÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Ëá¥Ë∞¢&lt;/h2&gt; 
&lt;h3&gt;Ê†∏ÂøÉË¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jjyaoao"&gt;ÈôàÊÄùÂ∑û-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, ÂÖ®ÊñáÂÜô‰ΩúÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fengju0213"&gt;Â≠ôÈü¨-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, Á¨¨‰πùÁ´†ÂÜÖÂÆπÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tsumugii24"&gt;ÂßúËàíÂá°-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt;ÔºàDatawhale ÊàêÂëò, Á´†ËäÇ‰π†È¢òËÆæËÆ°ÂíåÊ†°ÂØπÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HeteroCat"&gt;ÈªÑ‰Ω©Êûó-DatawhaleÊÑèÂêëÊàêÂëò&lt;/a&gt; (Agent ÂºÄÂèëÂ∑•Á®ãÂ∏à, Á¨¨‰∫îÁ´†ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fancyboi999"&gt;ÊõæÈë´Ê∞ë-AgentÂ∑•Á®ãÂ∏à&lt;/a&gt; (ÁâõÂÆ¢ÁßëÊäÄ, Á¨¨ÂçÅÂõõÁ´†Ê°à‰æãÂºÄÂèë)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xinzhongzhu.github.io/"&gt;Êú±‰ø°Âø†-ÊåáÂØº‰∏ìÂÆ∂&lt;/a&gt; (DatawhaleÈ¶ñÂ∏≠ÁßëÂ≠¶ÂÆ∂-ÊµôÊ±üÂ∏àËåÉÂ§ßÂ≠¶Êù≠Â∑û‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Èô¢ÊïôÊéà)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extra-Chapter Ë¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/WHQAQ11"&gt;WH&lt;/a&gt; (ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thunderbolt-fire"&gt;Âë®Â••Êù∞-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ë•øÂÆâ‰∫§ÈÄöÂ§ßÂ≠¶, Extra02 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tasselszcx"&gt;Âº†ÂÆ∏Êó≠-‰∏™‰∫∫ÂºÄÂèëËÄÖ&lt;/a&gt;(Â∏ùÂõΩÁêÜÂ∑•Â≠¶Èô¢, Extra03 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XiaoMa-PM"&gt;ÈªÑÂÆèÊôó-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ê∑±Âú≥Â§ßÂ≠¶, Extra04 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÁâπÂà´ÊÑüË∞¢&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊÑüË∞¢ &lt;a href="https://github.com/Sm1les"&gt;@Sm1les&lt;/a&gt; ÂØπÊú¨È°πÁõÆÁöÑÂ∏ÆÂä©‰∏éÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;ÊÑüË∞¢ÊâÄÊúâ‰∏∫Êú¨È°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖ‰ª¨ ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center" style="margin-top: 30px;"&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=datawhalechina/Hello-Agents" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/star-history-20251223.png" alt="Datawhale" width="90%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‚≠ê Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ÁªôÊàë‰ª¨‰∏Ä‰∏™ StarÔºÅ&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ÂÖ≥‰∫é Datawhale&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/datawhale.png" alt="Datawhale" width="30%" /&gt; 
 &lt;p&gt;Êâ´Êèè‰∫åÁª¥Á†ÅÂÖ≥Ê≥® Datawhale ÂÖ¨‰ºóÂè∑ÔºåËé∑ÂèñÊõ¥Â§ö‰ºòË¥®ÂºÄÊ∫êÂÜÖÂÆπ&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìú ÂºÄÊ∫êÂçèËÆÆ&lt;/h2&gt; 
&lt;p&gt;Êú¨‰ΩúÂìÅÈááÁî®&lt;a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆ&lt;/a&gt;ËøõË°åËÆ∏ÂèØ„ÄÇ&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kornia/kornia</title>
      <link>https://github.com/kornia/kornia</link>
      <description>&lt;p&gt;üêç Geometric Computer Vision Library for Spatial AI&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img width="55%" src="https://github.com/kornia/data/raw/main/kornia_banner_pixie.png" /&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/README_zh-CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- prettier-ignore --&gt; 
 &lt;p&gt;&lt;a href="https://kornia.readthedocs.io"&gt;Docs&lt;/a&gt; ‚Ä¢ &lt;a href="https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/nbs/hello_world_tutorial.ipynb"&gt;Try it Now&lt;/a&gt; ‚Ä¢ &lt;a href="https://kornia.github.io/tutorials/"&gt;Tutorials&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/kornia/kornia-examples"&gt;Examples&lt;/a&gt; ‚Ä¢ &lt;a href="https://kornia.github.io//kornia-blog"&gt;Blog&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.gg/HfnywwpBnD"&gt;Community&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/kornia"&gt;&lt;img src="https://badge.fury.io/py/kornia.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/kornia"&gt;&lt;img src="https://static.pepy.tech/badge/kornia" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://gitcode.com/kornia/kornia"&gt;&lt;img src="https://gitcode.com/kornia/kornia/star/badge.svg?sanitize=true" alt="star" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/HfnywwpBnD"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/kornia_foss"&gt;&lt;img src="https://img.shields.io/twitter/follow/kornia_foss?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Kornia&lt;/strong&gt; is a differentiable computer vision library that provides a rich set of differentiable image processing and geometric vision algorithms. Built on top of &lt;a href="https://pytorch.org"&gt;PyTorch&lt;/a&gt;, Kornia integrates seamlessly into existing AI workflows, allowing you to leverage powerful &lt;a href=""&gt;batch transformations&lt;/a&gt;, &lt;a href=""&gt;auto-differentiation&lt;/a&gt; and &lt;a href=""&gt;GPU acceleration&lt;/a&gt;. Whether you're working on image transformations, augmentations, or AI-driven image processing, Kornia equips you with the tools you need to bring your ideas to life.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üì¢ Announcement&lt;/strong&gt;: Kornia is shifting towards end-to-end vision models. We are focusing on integrating state-of-the-art Vision Language Models (VLM) and Vision Language Agents (VLA) to provide comprehensive end-to-end vision solutions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Key Components&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Differentiable Image Processing&lt;/strong&gt;&lt;br /&gt; Kornia provides a comprehensive suite of image processing operators, all differentiable and ready to integrate into deep learning pipelines. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Filters&lt;/strong&gt;: Gaussian, Sobel, Median, Box Blur, etc.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Transformations&lt;/strong&gt;: Affine, Homography, Perspective, etc.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Enhancements&lt;/strong&gt;: Histogram Equalization, CLAHE, Gamma Correction, etc.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Edge Detection&lt;/strong&gt;: Canny, Laplacian, Sobel, etc.&lt;/li&gt; 
   &lt;li&gt;... check our &lt;a href="https://kornia.readthedocs.io"&gt;docs&lt;/a&gt; for more.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Augmentations&lt;/strong&gt;&lt;br /&gt; Perform powerful data augmentation with Kornia‚Äôs built-in functions, ideal for training AI models with complex augmentation pipelines. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Augmentation Pipeline&lt;/strong&gt;: AugmentationSequential, PatchSequential, VideoSequential, etc.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Automatic Augmentation&lt;/strong&gt;: AutoAugment, RandAugment, TrivialAugment.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Models&lt;/strong&gt;&lt;br /&gt; Leverage pre-trained AI models optimized for a variety of vision tasks, all within the Kornia ecosystem. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Face Detection&lt;/strong&gt;: YuNet&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Feature Matching&lt;/strong&gt;: LoFTR, LightGlue&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Feature Descriptor&lt;/strong&gt;: DISK, DeDoDe, SOLD2&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Segmentation&lt;/strong&gt;: SAM&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Classification&lt;/strong&gt;: MobileViT, VisionTransformer.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;details&gt; 
 &lt;summary&gt;See here for some of the methods that we support! (&amp;gt;500 ops in total !)&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;strong&gt;Category&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Methods/Models&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Image Processing&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Color conversions (RGB, Grayscale, HSV, etc.)&lt;br /&gt;- Geometric transformations (Affine, Homography, Resizing, etc.)&lt;br /&gt;- Filtering (Gaussian blur, Median blur, etc.)&lt;br /&gt;- Edge detection (Sobel, Canny, etc.)&lt;br /&gt;- Morphological operations (Erosion, Dilation, etc.)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Augmentation&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Random cropping, Erasing&lt;br /&gt; - Random geometric transformations (Affine, flipping, Fish Eye, Perspecive, Thin plate spline, Elastic)&lt;br /&gt;- Random noises (Gaussian, Median, Motion, Box, Rain, Snow, Salt and Pepper)&lt;br /&gt;- Random color jittering (Contrast, Brightness, CLAHE, Equalize, Gamma, Hue, Invert, JPEG, Plasma, Posterize, Saturation, Sharpness, Solarize)&lt;br /&gt; - Random MixUp, CutMix, Mosaic, Transplantation, etc.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Feature Detection&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Detector (Harris, GFTT, Hessian, DoG, KeyNet, DISK and DeDoDe)&lt;br /&gt; - Descriptor (SIFT, HardNet, TFeat, HyNet, SOSNet, and LAFDescriptor)&lt;br /&gt;- Matching (nearest neighbor, mutual nearest neighbor, geometrically aware matching, AdaLAM LightGlue, and LoFTR)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Geometry&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Camera models and calibration&lt;br /&gt;- Stereo vision (epipolar geometry, disparity, etc.)&lt;br /&gt;- Homography estimation&lt;br /&gt;- Depth estimation from disparity&lt;br /&gt;- 3D transformations&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Deep Learning Layers&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Custom convolution layers&lt;br /&gt;- Recurrent layers for vision tasks&lt;br /&gt;- Loss functions (e.g., SSIM, PSNR, etc.)&lt;br /&gt;- Vision-specific optimizers&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Photometric Functions&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Photometric loss functions&lt;br /&gt;- Photometric augmentations&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Filtering&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Bilateral filtering&lt;br /&gt;- DexiNed&lt;br /&gt;- Dissolving&lt;br /&gt;- Guided Blur&lt;br /&gt;- Laplacian&lt;br /&gt;- Gaussian&lt;br /&gt;- Non-local means&lt;br /&gt;- Sobel&lt;br /&gt;- Unsharp masking&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Color&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Color space conversions&lt;br /&gt;- Brightness/contrast adjustment&lt;br /&gt;- Gamma correction&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Stereo Vision&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Disparity estimation&lt;br /&gt;- Depth estimation&lt;br /&gt;- Rectification&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Image Registration&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Affine and homography-based registration&lt;br /&gt;- Image alignment using feature matching&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Pose Estimation&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Essential and Fundamental matrix estimation&lt;br /&gt;- PnP problem solvers&lt;br /&gt;- Pose refinement&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Optical Flow&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Farneback optical flow&lt;br /&gt;- Dense optical flow&lt;br /&gt;- Sparse optical flow&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;3D Vision&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Depth estimation&lt;br /&gt;- Point cloud operations&lt;br /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Image Denoising&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Gaussian noise removal&lt;br /&gt;- Poisson noise removal&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Edge Detection&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Sobel operator&lt;br /&gt;- Canny edge detection&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Transformations&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Rotation&lt;br /&gt;- Translation&lt;br /&gt;- Scaling&lt;br /&gt;- Shearing&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Loss Functions&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- SSIM (Structural Similarity Index Measure)&lt;br /&gt;- PSNR (Peak Signal-to-Noise Ratio)&lt;br /&gt;- Cauchy&lt;br /&gt;- Charbonnier&lt;br /&gt;- Depth Smooth&lt;br /&gt;- Dice&lt;br /&gt;- Hausdorff&lt;br /&gt;- Tversky&lt;br /&gt;- Welsch&lt;br /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Morphological Operations&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;- Dilation&lt;br /&gt;- Erosion&lt;br /&gt;- Opening&lt;br /&gt;- Closing&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;Sponsorship&lt;/h2&gt; 
&lt;p&gt;Kornia is an open-source project that is developed and maintained by volunteers. Whether you're using it for research or commercial purposes, consider sponsoring or collaborating with us. Your support will help ensure Kornia's growth and ongoing innovation. Reach out to us today and be a part of shaping the future of this exciting initiative!&lt;/p&gt; 
&lt;a href="https://opencollective.com/kornia/donate" target="_blank"&gt; &lt;img src="https://opencollective.com/webpack/donate/button@2x.png?color=blue" width="300" /&gt; &lt;/a&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/kornia"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/kornia" alt="PyPI python" /&gt;&lt;/a&gt; &lt;a href="https://pytorch.org/get-started/locally/"&gt;&lt;img src="https://img.shields.io/badge/PyTorch_2.0.0+-ee4c2c?logo=pytorch&amp;amp;logoColor=white" alt="pytorch" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;From pip&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install kornia
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Other installation options&lt;/summary&gt; 
 &lt;h4&gt;From source with editable mode&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;For development with Pixi (Recommended)&lt;/h4&gt; 
 &lt;p&gt;For development, Kornia uses &lt;a href="https://pixi.sh"&gt;pixi&lt;/a&gt; for fast Python package management and environment management. The project includes a &lt;code&gt;pixi.toml&lt;/code&gt; configuration file for reproducible dependency management.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install pixi (if not already installed)
curl -fsSL https://pixi.sh/install.sh | bash

# Install dependencies and set up the development environment
pixi install

# Run tests
pixi run test

# For CUDA development
pixi run -e cuda install
pixi run -e cuda test-cuda
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This will set up a complete development environment with all dependencies. For more details on dependency management and available tasks, see &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
 &lt;h4&gt;From Github url (latest version)&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/kornia/kornia
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Kornia is not just another computer vision library ‚Äî it's your gateway to effortless Computer Vision and AI.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Get started with Kornia image transformation and augmentation!&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import numpy as np
import kornia_rs as kr

from kornia.augmentation import AugmentationSequential, RandomAffine, RandomBrightness
from kornia.filters import StableDiffusionDissolving

# Load and prepare your image
img: np.ndarray = kr.read_image_any("img.jpeg")
img = kr.resize(img, (256, 256), interpolation="bilinear")

# alternatively, load image with PIL
# img = Image.open("img.jpeg").resize((256, 256))
# img = np.array(img)

img = np.stack([img] * 2)  # batch images

# Define an augmentation pipeline
augmentation_pipeline = AugmentationSequential(
    RandomAffine((-45., 45.), p=1.),
    RandomBrightness((0.,1.), p=1.)
)

# Leveraging StableDiffusion models
dslv_op = StableDiffusionDissolving()

img = augmentation_pipeline(img)
dslv_op(img, step_number=500)

dslv_op.save("Kornia-enhanced.jpg")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Find out Kornia ONNX models with ONNXSequential!&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import numpy as np
from kornia.onnx import ONNXSequential
# Chain ONNX models from HuggingFace repo and your own local model together
onnx_seq = ONNXSequential(
    "hf://operators/kornia.geometry.transform.flips.Hflip",
    "hf://models/kornia.models.detection.rtdetr_r18vd_640x640",  # Or you may use "YOUR_OWN_MODEL.onnx"
)
# Prepare some input data
input_data = np.random.randn(1, 3, 384, 512).astype(np.float32)
# Perform inference
outputs = onnx_seq(input_data)
# Print the model outputs
print(outputs)

# Export a new ONNX model that chains up all three models together!
onnx_seq.export("chained_model.onnx")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Multi-framework support&lt;/h2&gt; 
&lt;p&gt;You can now use Kornia with &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt;, &lt;a href="https://jax.readthedocs.io/en/latest/index.html"&gt;JAX&lt;/a&gt;, and &lt;a href="https://numpy.org/"&gt;NumPy&lt;/a&gt;. See &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/docs/source/get-started/multi-framework-support.rst"&gt;Multi-Framework Support&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import kornia
tf_kornia = kornia.to_tensorflow()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; Powered by &lt;a href="https://github.com/ivy-llc/ivy" target="_blank"&gt; &lt;/a&gt;&lt;/p&gt;
&lt;div class="dark-light" style="display: block;" align="center"&gt;
 &lt;a href="https://github.com/ivy-llc/ivy" target="_blank"&gt; &lt;img class="dark-light" width="15%" src="https://raw.githubusercontent.com/ivy-llc/assets/refs/heads/main/assets/logos/ivy-long.svg?sanitize=true" /&gt; &lt;/a&gt;
&lt;/div&gt;
&lt;a href="https://github.com/ivy-llc/ivy" target="_blank"&gt; &lt;/a&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Call For Contributors&lt;/h2&gt; 
&lt;p&gt;Are you passionate about computer vision, AI, and open-source development? Join us in shaping the future of Kornia! We are actively seeking contributors to help expand and enhance our library, making it even more powerful, accessible, and versatile. Whether you're an experienced developer or just starting, there's a place for you in our community.&lt;/p&gt; 
&lt;h3&gt;Accessible AI Models&lt;/h3&gt; 
&lt;p&gt;We are excited to announce our latest advancement: a new initiative designed to seamlessly integrate lightweight AI models into Kornia. We aim to run any models as smooth as big models such as StableDiffusion, to support them well in many perspectives.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Priority Focus: VLM/VLA Models&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our primary focus is on integrating &lt;strong&gt;Vision Language Models (VLM)&lt;/strong&gt; and &lt;strong&gt;Vision Language Agents (VLA)&lt;/strong&gt; to enable end-to-end vision solutions. We're actively seeking contributors to help us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;VLM/VLA Integration (Priority)&lt;/strong&gt;: Implement and integrate state-of-the-art Vision Language Models and Vision Language Agents. This includes models like Qwen2.5-VL, SAM-3, and other cutting-edge VLM/VLA architectures. If you are a researcher working on VLM/VLA models, Kornia is an excellent place for you to promote your model!&lt;/li&gt; 
 &lt;li&gt;Expand the Model Selection: Import decent models into our library. If you are a researcher, Kornia is an excellent place for you to promote your model!&lt;/li&gt; 
 &lt;li&gt;Model Optimization: Work on optimizing models to reduce their computational footprint while maintaining accuracy and performance. You may start from offering ONNX support!&lt;/li&gt; 
 &lt;li&gt;Model Documentation: Create detailed guides and examples to help users get the most out of these models in their projects.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Documentation And Tutorial Optimization&lt;/h3&gt; 
&lt;p&gt;Kornia's foundation lies in its extensive collection of classic computer vision operators, providing robust tools for image processing, feature extraction, and geometric transformations. We continuously seek for contributors to help us improve our documentation and present nice tutorials to our users.&lt;/p&gt; 
&lt;h2&gt;Cite&lt;/h2&gt; 
&lt;p&gt;If you are using kornia in your research-related documents, it is recommended that you cite the paper. See more in &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/CITATION.md"&gt;CITATION&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{eriba2019kornia,
  author    = {E. Riba, D. Mishkin, D. Ponsa, E. Rublee and G. Bradski},
  title     = {Kornia: an Open Source Differentiable Computer Vision Library for PyTorch},
  booktitle = {Winter Conference on Applications of Computer Vision},
  year      = {2020},
  url       = {https://arxiv.org/pdf/1910.02190.pdf}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion. If you plan to contribute new features, utility functions or extensions, please first open an issue and discuss the feature with us. Please, consider reading the &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; notes. The participation in this open source project is subject to &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;AI Policy&lt;/h3&gt; 
&lt;p&gt;Kornia accepts AI-assisted code but strictly rejects AI-generated contributions where the submitter acts as a proxy. All contributors must be the &lt;strong&gt;Sole Responsible Author&lt;/strong&gt; for every line of code. Please review our &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/AI_POLICY.md"&gt;AI Policy&lt;/a&gt; before submitting pull requests. Key requirements include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Proof of Verification&lt;/strong&gt;: PRs must include local test logs proving execution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-Discussion&lt;/strong&gt;: All PRs must be discussed in Discord or via a GitHub issue before implementation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Library References&lt;/strong&gt;: Implementations must be based on existing library references (PyTorch, OpenCV, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Existing Utilities&lt;/strong&gt;: Use existing &lt;code&gt;kornia&lt;/code&gt; utilities instead of reinventing the wheel&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Explain It&lt;/strong&gt;: You must be able to explain any code you submit&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Automated AI reviewers (e.g., GitHub Copilot) will check PRs against these policies. See &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/AI_POLICY.md"&gt;AI_POLICY.md&lt;/a&gt; for complete details.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Discord:&lt;/strong&gt; Join our workspace to keep in touch with our core contributors, get latest updates on the industry and be part of our community. &lt;a href="https://discord.gg/HfnywwpBnD"&gt;JOIN HERE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues:&lt;/strong&gt; bug reports, feature requests, install issues, RFCs, thoughts, etc. &lt;a href="https://github.com/kornia/kornia/issues/new/choose"&gt;OPEN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Forums:&lt;/strong&gt; discuss implementations, research, etc. &lt;a href="https://github.com/kornia/kornia/discussions"&gt;GitHub Forums&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;a href="https://github.com/Kornia/kornia/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=Kornia/kornia" width="60%" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Kornia is released under the Apache 2.0 license. See the &lt;a href="https://raw.githubusercontent.com/kornia/kornia/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>3b1b/manim</title>
      <link>https://github.com/3b1b/manim</link>
      <description>&lt;p&gt;Animation engine for explanatory math videos&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://github.com/3b1b/manim"&gt; &lt;img src="https://raw.githubusercontent.com/3b1b/manim/master/logo/cropped.png" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/manimgl/"&gt;&lt;img src="https://img.shields.io/pypi/v/manimgl?logo=pypi" alt="pypi version" /&gt;&lt;/a&gt; &lt;a href="http://choosealicense.com/licenses/mit/"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?style=flat" alt="MIT License" /&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/manim/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/manim.svg?color=ff4301&amp;amp;label=reddit&amp;amp;logo=reddit" alt="Manim Subreddit" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/bYCyhM9Kz2"&gt;&lt;img src="https://img.shields.io/discord/581738731934056449.svg?label=discord&amp;amp;logo=discord" alt="Manim Discord" /&gt;&lt;/a&gt; &lt;a href="https://3b1b.github.io/manim/"&gt;&lt;img src="https://github.com/3b1b/manim/workflows/docs/badge.svg?sanitize=true" alt="docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Manim is an engine for precise programmatic animations, designed for creating explanatory math videos.&lt;/p&gt; 
&lt;p&gt;Note, there are two versions of manim. This repository began as a personal project by the author of &lt;a href="https://www.3blue1brown.com/"&gt;3Blue1Brown&lt;/a&gt; for the purpose of animating those videos, with video-specific code available &lt;a href="https://github.com/3b1b/videos"&gt;here&lt;/a&gt;. In 2020 a group of developers forked it into what is now the &lt;a href="https://github.com/ManimCommunity/manim/"&gt;community edition&lt;/a&gt;, with a goal of being more stable, better tested, quicker to respond to community contributions, and all around friendlier to get started with. See &lt;a href="https://docs.manim.community/en/stable/faq/installation.html#different-versions"&gt;this page&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Warning] &lt;strong&gt;WARNING:&lt;/strong&gt; These instructions are for ManimGL &lt;em&gt;only&lt;/em&gt;. Trying to use these instructions to install &lt;a href="https://github.com/ManimCommunity/manim"&gt;Manim Community/manim&lt;/a&gt; or instructions there to install this version will cause problems. You should first decide which version you wish to install, then only follow the instructions for your desired version.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] &lt;strong&gt;Note&lt;/strong&gt;: To install manim directly through pip, please pay attention to the name of the installed package. This repository is ManimGL of 3b1b. The package name is &lt;code&gt;manimgl&lt;/code&gt; instead of &lt;code&gt;manim&lt;/code&gt; or &lt;code&gt;manimlib&lt;/code&gt;. Please use &lt;code&gt;pip install manimgl&lt;/code&gt; to install the version in this repository.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Manim runs on Python 3.7 or higher.&lt;/p&gt; 
&lt;p&gt;System requirements are &lt;a href="https://ffmpeg.org/"&gt;FFmpeg&lt;/a&gt;, &lt;a href="https://www.opengl.org/"&gt;OpenGL&lt;/a&gt; and &lt;a href="https://www.latex-project.org"&gt;LaTeX&lt;/a&gt; (optional, if you want to use LaTeX). For Linux, &lt;a href="https://pango.org"&gt;Pango&lt;/a&gt; along with its development headers are required. See instruction &lt;a href="https://github.com/ManimCommunity/ManimPango#building"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Directly&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Install manimgl
pip install manimgl

# Try it out
manimgl
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more options, take a look at the &lt;a href="https://raw.githubusercontent.com/3b1b/manim/master/#using-manim"&gt;Using manim&lt;/a&gt; sections further below.&lt;/p&gt; 
&lt;p&gt;If you want to hack on manimlib itself, clone this repository and in that directory execute:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Install manimgl
pip install -e .

# Try it out
manimgl example_scenes.py OpeningManimExample
# or
manim-render example_scenes.py OpeningManimExample
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Directly (Windows)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://www.wikihow.com/Install-FFmpeg-on-Windows"&gt;Install FFmpeg&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Install a LaTeX distribution. &lt;a href="https://miktex.org/download"&gt;MiKTeX&lt;/a&gt; is recommended.&lt;/li&gt; 
 &lt;li&gt;Install the remaining Python packages. &lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/3b1b/manim.git
cd manim
pip install -e .
manimgl example_scenes.py OpeningManimExample
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Mac OSX&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install FFmpeg, LaTeX in terminal using homebrew.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;brew install ffmpeg mactex
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you are using an ARM-based processor, install Cairo.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;arch -arm64 brew install pkg-config cairo
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install latest version of manim using these command.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/3b1b/manim.git
cd manim
pip install -e .
manimgl example_scenes.py OpeningManimExample (make sure to add manimgl to path first.)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Anaconda Install&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install LaTeX as above.&lt;/li&gt; 
 &lt;li&gt;Create a conda environment using &lt;code&gt;conda create -n manim python=3.8&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Activate the environment using &lt;code&gt;conda activate manim&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Install manimgl using &lt;code&gt;pip install -e .&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Using manim&lt;/h2&gt; 
&lt;p&gt;Try running the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;manimgl example_scenes.py OpeningManimExample
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This should pop up a window playing a simple scene.&lt;/p&gt; 
&lt;p&gt;Look through the &lt;a href="https://3b1b.github.io/manim/getting_started/example_scenes.html"&gt;example scenes&lt;/a&gt; to see examples of the library's syntax, animation types and object types. In the &lt;a href="https://github.com/3b1b/videos"&gt;3b1b/videos&lt;/a&gt; repo, you can see all the code for 3blue1brown videos, though code from older videos may not be compatible with the most recent version of manim. The readme of that repo also outlines some details for how to set up a more interactive workflow, as shown in &lt;a href="https://www.youtube.com/watch?v=rbu7Zu5X1zI"&gt;this manim demo video&lt;/a&gt; for example.&lt;/p&gt; 
&lt;p&gt;When running in the CLI, some useful flags include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-w&lt;/code&gt; to write the scene to a file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-o&lt;/code&gt; to write the scene to a file and open the result&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-s&lt;/code&gt; to skip to the end and just show the final frame. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;-so&lt;/code&gt; will save the final frame to an image and show it&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-n &amp;lt;number&amp;gt;&lt;/code&gt; to skip ahead to the &lt;code&gt;n&lt;/code&gt;'th animation of a scene.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-f&lt;/code&gt; to make the playback window fullscreen&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Take a look at custom_config.yml for further configuration. To add your customization, you can either edit this file, or add another file by the same name "custom_config.yml" to whatever directory you are running manim from. For example &lt;a href="https://github.com/3b1b/videos/raw/master/custom_config.yml"&gt;this is the one&lt;/a&gt; for 3blue1brown videos. There you can specify where videos should be output to, where manim should look for image files and sounds you want to read in, and other defaults regarding style and video quality.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;Documentation is in progress at &lt;a href="https://3b1b.github.io/manim/"&gt;3b1b.github.io/manim&lt;/a&gt;. And there is also a Chinese version maintained by &lt;a href="https://manim.org.cn"&gt;&lt;strong&gt;@manim-kindergarten&lt;/strong&gt;&lt;/a&gt;: &lt;a href="https://docs.manim.org.cn/"&gt;docs.manim.org.cn&lt;/a&gt; (in Chinese).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/manim-kindergarten/"&gt;manim-kindergarten&lt;/a&gt; wrote and collected some useful extra classes and some codes of videos in &lt;a href="https://github.com/manim-kindergarten/manim_sandbox"&gt;manim_sandbox repo&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Is always welcome. As mentioned above, the &lt;a href="https://github.com/ManimCommunity/manim"&gt;community edition&lt;/a&gt; has the most active ecosystem for contributions, with testing and continuous integration, but pull requests are welcome here too. Please explain the motivation for a given change and examples of its effect.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project falls under the MIT license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/TensorRT-LLM</title>
      <link>https://github.com/NVIDIA/TensorRT-LLM</link>
      <description>&lt;p&gt;TensorRT LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and supports state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT LLM also contains components to create Python and C++ runtimes that orchestrate the inference execution in a performant way.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;TensorRT LLM&lt;/h1&gt; 
 &lt;h4&gt;TensorRT LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and supports state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.&lt;/h4&gt; 
 &lt;p&gt;&lt;a href="https://nvidia.github.io/TensorRT-LLM/"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-brightgreen.svg?style=flat" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/release/python-3123/"&gt;&lt;img src="https://img.shields.io/badge/python-3.12-green" alt="python" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/release/python-31012/"&gt;&lt;img src="https://img.shields.io/badge/python-3.10-green" alt="python" /&gt;&lt;/a&gt; &lt;a href="https://developer.nvidia.com/cuda-downloads"&gt;&lt;img src="https://img.shields.io/badge/cuda-13.0.0-green" alt="cuda" /&gt;&lt;/a&gt; &lt;a href="https://pytorch.org"&gt;&lt;img src="https://img.shields.io/badge/torch-2.9.0-green" alt="torch" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/tensorrt_llm/version.py"&gt;&lt;img src="https://img.shields.io/badge/release-1.2.0rc7-green" alt="version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://nvidia.github.io/TensorRT-LLM/developer-guide/overview.html"&gt;Architecture&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://nvidia.github.io/TensorRT-LLM/developer-guide/perf-overview.html"&gt;Performance&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://nvidia.github.io/TensorRT-LLM/quick-start-guide.html"&gt;Examples&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://nvidia.github.io/TensorRT-LLM/"&gt;Documentation&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/NVIDIA/TensorRT-LLM/issues?q=is%3Aissue%20state%3Aopen%20label%3Aroadmap"&gt;Roadmap&lt;/a&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;div align="left"&gt; 
  &lt;h2&gt;Tech Blogs&lt;/h2&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;[10/13] Scaling Expert Parallelism in TensorRT LLM (Part 3: Pushing the Performance Boundary) ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog14_Scaling_Expert_Parallelism_in_TensorRT-LLM_part3.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[09/26] Inference Time Compute Implementation in TensorRT LLM ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog13_Inference_Time_Compute_Implementation_in_TensorRT-LLM.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[09/19] Combining Guided Decoding and Speculative Decoding: Making CPU and GPU Cooperate Seamlessly ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog12_Combining_Guided_Decoding_and_Speculative_Decoding.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[08/29] ADP Balance Strategy ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog10_ADP_Balance_Strategy.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[08/05] Running a High-Performance GPT-OSS-120B Inference Server with TensorRT LLM ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog9_Deploying_GPT_OSS_on_TRTLLM.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[08/01] Scaling Expert Parallelism in TensorRT LLM (Part 2: Performance Status and Optimization) ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog8_Scaling_Expert_Parallelism_in_TensorRT-LLM_part2.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[07/26] N-Gram‚ÄØSpeculative‚ÄØDecoding‚ÄØin TensorRT LLM ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog7_NGram_performance_Analysis_And_Auto_Enablement.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[06/19] Disaggregated Serving in TensorRT LLM ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog5_Disaggregated_Serving_in_TensorRT-LLM.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[06/05] Scaling Expert Parallelism in TensorRT LLM (Part 1: Design and Implementation of Large-scale EP) ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog4_Scaling_Expert_Parallelism_in_TensorRT-LLM.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[05/30] Optimizing DeepSeek R1 Throughput on NVIDIA Blackwell GPUs: A Deep Dive for Developers ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog3_Optimizing_DeepSeek_R1_Throughput_on_NVIDIA_Blackwell_GPUs.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[05/23] DeepSeek R1 MTP Implementation and Optimization ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog2_DeepSeek_R1_MTP_Implementation_and_Optimization.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[05/16] Pushing Latency Boundaries: Optimizing DeepSeek-R1 Performance on NVIDIA B200 GPUs ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/tech_blog/blog1_Pushing_Latency_Boundaries_Optimizing_DeepSeek-R1_Performance_on_NVIDIA_B200_GPUs.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;h2&gt;Latest News&lt;/h2&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;[08/05] üåü TensorRT LLM delivers Day-0 support for OpenAI's latest open-weights models: GPT-OSS-120B &lt;a href="https://huggingface.co/openai/gpt-oss-120b"&gt;‚û°Ô∏è link&lt;/a&gt; and GPT-OSS-20B &lt;a href="https://huggingface.co/openai/gpt-oss-20b"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[07/15] üåü TensorRT LLM delivers Day-0 support for LG AI Research's latest model, EXAONE 4.0 &lt;a href="https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[06/17] Join NVIDIA and DeepInfra for a developer meetup on June 26 ‚ú® &lt;a href="https://events.nvidia.com/scaletheunscalablenextgenai"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[05/22] Blackwell Breaks the 1,000 TPS/User Barrier With Meta‚Äôs Llama 4 Maverick ‚ú® &lt;a href="https://developer.nvidia.com/blog/blackwell-breaks-the-1000-tps-user-barrier-with-metas-llama-4-maverick/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[04/10] TensorRT LLM DeepSeek R1 performance benchmarking best practices now published. ‚ú® &lt;a href="https://nvidia.github.io/TensorRT-LLM/blogs/Best_perf_practice_on_DeepSeek-R1_in_TensorRT-LLM.html"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[04/05] TensorRT LLM can run Llama 4 at over 40,000 tokens per second on B200 GPUs!&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/media/l4_launch_perf.png" alt="L4_perf" /&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;[03/22] TensorRT LLM is now fully open-source, with developments moved to GitHub!&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[03/18] üöÄüöÄ NVIDIA Blackwell Delivers World-Record DeepSeek-R1 Inference Performance with TensorRT LLM &lt;a href="https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/"&gt;‚û°Ô∏è Link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[02/28] üåü NAVER Place Optimizes SLM-Based Vertical Services with TensorRT LLM &lt;a href="https://developer.nvidia.com/blog/spotlight-naver-place-optimizes-slm-based-vertical-services-with-nvidia-tensorrt-llm/"&gt;‚û°Ô∏è Link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[02/25] üåü DeepSeek-R1 performance now optimized for Blackwell &lt;a href="https://huggingface.co/nvidia/DeepSeek-R1-FP4"&gt;‚û°Ô∏è Link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[02/20] Explore the complete guide to achieve great accuracy, high throughput, and low latency at the lowest cost for your business &lt;a href="https://www.nvidia.com/en-us/solutions/ai/inference/balancing-cost-latency-and-performance-ebook/?ncid=so-twit-348956&amp;amp;linkId=100000341423615"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[02/18] Unlock #LLM inference with auto-scaling on @AWS EKS ‚ú® &lt;a href="https://aws.amazon.com/blogs/hpc/scaling-your-llm-inference-workloads-multi-node-deployment-with-tensorrt-llm-and-triton-on-amazon-eks/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[02/12] ü¶∏‚ö° Automating GPU Kernel Generation with DeepSeek-R1 and Inference Time Scaling &lt;a href="https://developer.nvidia.com/blog/automating-gpu-kernel-generation-with-deepseek-r1-and-inference-time-scaling/?ncid=so-twit-997075&amp;amp;linkId=100000338909937"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;[02/12] üåü How Scaling Laws Drive Smarter, More Powerful AI &lt;a href="https://blogs.nvidia.com/blog/ai-scaling-laws/?ncid=so-link-889273&amp;amp;linkId=100000338837832"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;details close&gt; 
   &lt;summary&gt;Previous News&lt;/summary&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;[2025/01/25] Nvidia moves AI focus to inference cost, efficiency &lt;a href="https://www.fierceelectronics.com/ai/nvidia-moves-ai-focus-inference-cost-efficiency?linkId=100000332985606"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2025/01/24] üèéÔ∏è Optimize AI Inference Performance with NVIDIA Full-Stack Solutions &lt;a href="https://developer.nvidia.com/blog/optimize-ai-inference-performance-with-nvidia-full-stack-solutions/?ncid=so-twit-400810&amp;amp;linkId=100000332621049"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2025/01/23] üöÄ Fast, Low-Cost Inference Offers Key to Profitable AI &lt;a href="https://blogs.nvidia.com/blog/ai-inference-platform/?ncid=so-twit-693236-vt04&amp;amp;linkId=100000332307804"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2025/01/16] Introducing New KV Cache Reuse Optimizations in TensorRT LLM &lt;a href="https://developer.nvidia.com/blog/introducing-new-kv-cache-reuse-optimizations-in-nvidia-tensorrt-llm/?ncid=so-twit-363876&amp;amp;linkId=100000330323229"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2025/01/14] üì£ Bing's Transition to LLM/SLM Models: Optimizing Search with TensorRT LLM &lt;a href="https://blogs.bing.com/search-quality-insights/December-2024/Bing-s-Transition-to-LLM-SLM-Models-Optimizing-Search-with-TensorRT-LLM"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2025/01/04] ‚ö°Boost Llama 3.3 70B Inference Throughput 3x with TensorRT LLM Speculative Decoding &lt;a href="https://developer.nvidia.com/blog/boost-llama-3-3-70b-inference-throughput-3x-with-nvidia-tensorrt-llm-speculative-decoding/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/12/10] ‚ö° Llama 3.3 70B from AI at Meta is accelerated by TensorRT-LLM. üåü State-of-the-art model on par with Llama 3.1 405B for reasoning, math, instruction following and tool use. Explore the preview &lt;a href="https://build.nvidia.com/meta/llama-3_3-70b-instruct"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/12/03] üåü Boost your AI inference throughput by up to 3.6x. We now support speculative decoding and tripling token throughput with our NVIDIA TensorRT-LLM. Perfect for your generative AI apps. ‚ö°Learn how in this technical deep dive &lt;a href="https://nvda.ws/3ZCZTzD"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/12/02] Working on deploying ONNX models for performance-critical applications? Try our NVIDIA Nsight Deep Learning Designer ‚ö° A user-friendly GUI and tight integration with NVIDIA TensorRT that offers: ‚úÖ Intuitive visualization of ONNX model graphs ‚úÖ Quick tweaking of model architecture and parameters ‚úÖ Detailed performance profiling with either ORT or TensorRT ‚úÖ Easy building of TensorRT engines &lt;a href="https://developer.nvidia.com/nsight-dl-designer?ncid=so-link-485689&amp;amp;linkId=100000315016072"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/11/26] üì£ Introducing TensorRT LLM for Jetson AGX Orin, making it even easier to deploy on Jetson AGX Orin with initial support in JetPack 6.1 via the v0.12.0-jetson branch of the TensorRT LLM repo. ‚úÖ Pre-compiled TensorRT LLM wheels &amp;amp; containers for easy integration ‚úÖ Comprehensive guides &amp;amp; docs to get you started &lt;a href="https://forums.developer.nvidia.com/t/tensorrt-llm-for-jetson/313227?linkId=100000312718869"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/11/21] NVIDIA TensorRT LLM Multiblock Attention Boosts Throughput by More Than 3x for Long Sequence Lengths on NVIDIA HGX H200 &lt;a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-multiblock-attention-boosts-throughput-by-more-than-3x-for-long-sequence-lengths-on-nvidia-hgx-h200/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/11/19] Llama 3.2 Full-Stack Optimizations Unlock High Performance on NVIDIA GPUs &lt;a href="https://developer.nvidia.com/blog/llama-3-2-full-stack-optimizations-unlock-high-performance-on-nvidia-gpus/?ncid=so-link-721194"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/11/09] üöÄüöÄüöÄ 3x Faster AllReduce with NVSwitch and TensorRT LLM MultiShot &lt;a href="https://developer.nvidia.com/blog/3x-faster-allreduce-with-nvswitch-and-tensorrt-llm-multishot/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/11/09] ‚ú® NVIDIA advances the AI ecosystem with the AI model of LG AI Research üôå &lt;a href="https://blogs.nvidia.co.kr/blog/nvidia-lg-ai-research/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/11/02] üåüüåüüåü NVIDIA and LlamaIndex Developer Contest üôå Enter for a chance to win prizes including an NVIDIA¬Æ GeForce RTX‚Ñ¢ 4080 SUPER GPU, DLI credits, and moreüôå &lt;a href="https://developer.nvidia.com/llamaindex-developer-contest"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/10/28] üèéÔ∏èüèéÔ∏èüèéÔ∏è NVIDIA GH200 Superchip Accelerates Inference by 2x in Multiturn Interactions with Llama Models &lt;a href="https://developer.nvidia.com/blog/nvidia-gh200-superchip-accelerates-inference-by-2x-in-multiturn-interactions-with-llama-models/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/10/22] New üìù Step-by-step instructions on how to ‚úÖ Optimize LLMs with NVIDIA TensorRT-LLM, ‚úÖ Deploy the optimized models with Triton Inference Server, ‚úÖ Autoscale LLMs deployment in a Kubernetes environment. üôå Technical Deep Dive: &lt;a href="https://nvda.ws/3YgI8UT"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/10/07] üöÄüöÄüöÄOptimizing Microsoft Bing Visual Search with NVIDIA Accelerated Libraries &lt;a href="https://developer.nvidia.com/blog/optimizing-microsoft-bing-visual-search-with-nvidia-accelerated-libraries/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/09/29] üåü AI at Meta PyTorch + TensorRT v2.4 üåü ‚ö°TensorRT 10.1 ‚ö°PyTorch 2.4 ‚ö°CUDA 12.4 ‚ö°Python 3.12 &lt;a href="https://github.com/pytorch/TensorRT/releases/tag/v2.4.0"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/09/17] ‚ú® NVIDIA TensorRT LLM Meetup &lt;a href="https://drive.google.com/file/d/1RR8GqC-QbuaKuHj82rZcXb3MS20SWo6F/view?usp=share_link"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/09/17] ‚ú® Accelerating LLM Inference at Databricks with TensorRT-LLM &lt;a href="https://drive.google.com/file/d/1NeSmrLaWRJAY1rxD9lJmzpB9rzr38j8j/view?usp=sharing"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/09/17] ‚ú® TensorRT LLM @ Baseten &lt;a href="https://drive.google.com/file/d/1Y7L2jqW-aRmt31mCdqhwvGMmCSOzBUjG/view?usp=share_link"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/09/04] üèéÔ∏èüèéÔ∏èüèéÔ∏è Best Practices for Tuning TensorRT LLM for Optimal Serving with BentoML &lt;a href="https://www.bentoml.com/blog/tuning-tensor-rt-llm-for-optimal-serving-with-bentoml"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/08/20] üèéÔ∏èSDXL with #Model Optimizer ‚è±Ô∏è‚ö° üèÅ cache diffusion üèÅ quantization aware training üèÅ QLoRA üèÅ #Python 3.12 &lt;a href="https://developer.nvidia.com/blog/nvidia-tensorrt-model-optimizer-v0-15-boosts-inference-performance-and-expands-model-support/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/08/13] üêç DIY Code Completion with #Mamba ‚ö° #TensorRT #LLM for speed ü§ñ NIM for ease ‚òÅÔ∏è deploy anywhere &lt;a href="https://developer.nvidia.com/blog/revolutionizing-code-completion-with-codestral-mamba-the-next-gen-coding-llm/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/08/06] üó´ Multilingual Challenge Accepted üó´ ü§ñ #TensorRT #LLM boosts low-resource languages like Hebrew, Indonesian and Vietnamese ‚ö°&lt;a href="https://developer.nvidia.com/blog/accelerating-hebrew-llm-performance-with-nvidia-tensorrt-llm/?linkId=100000278659647"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/07/30] Introducingüçä @SliceXAI ELM Turbo ü§ñ train ELM once ‚ö° #TensorRT #LLM optimize ‚òÅÔ∏è deploy anywhere &lt;a href="https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/07/23] üëÄ @AIatMeta Llama 3.1 405B trained on 16K NVIDIA H100s - inference is #TensorRT #LLM optimized ‚ö° ü¶ô 400 tok/s - per node ü¶ô 37 tok/s - per user ü¶ô 1 node inference &lt;a href="https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/07/09] Checklist to maximize multi-language performance of @meta #Llama3 with #TensorRT #LLM inference: ‚úÖ MultiLingual ‚úÖ NIM ‚úÖ LoRA tuned adaptors&lt;a href="https://developer.nvidia.com/blog/deploy-multilingual-llms-with-nvidia-nim/"&gt;‚û°Ô∏è Tech blog&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/07/02] Let the @MistralAI MoE tokens fly üìà üöÄ #Mixtral 8x7B with NVIDIA #TensorRT #LLM on #H100. &lt;a href="https://developer.nvidia.com/blog/achieving-high-mixtral-8x7b-performance-with-nvidia-h100-tensor-core-gpus-and-tensorrt-llm?ncid=so-twit-928467"&gt;‚û°Ô∏è Tech blog&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/06/24] Enhanced with NVIDIA #TensorRT #LLM, @upstage.ai‚Äôs solar-10.7B-instruct is ready to power your developer projects through our API catalog üèéÔ∏è. ‚ú®&lt;a href="https://build.nvidia.com/upstage/solar-10_7b-instruct?snippet_tab=Try"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/06/18] CYMI: ü§© Stable Diffusion 3 dropped last week üéä üèéÔ∏è Speed up your SD3 with #TensorRT INT8 Quantization&lt;a href="https://build.nvidia.com/upstage/solar-10_7b-instruct?snippet_tab=Try"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/06/18] üß∞Deploying ComfyUI with TensorRT? Here‚Äôs your setup guide &lt;a href="https://github.com/comfyanonymous/ComfyUI_TensorRT"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/06/11] ‚ú®#TensorRT Weight-Stripped Engines ‚ú® Technical Deep Dive for serious coders ‚úÖ+99% compression ‚úÖ1 set of weights ‚Üí ** GPUs ‚úÖ0 performance loss ‚úÖ** models‚Ä¶LLM, CNN, etc.&lt;a href="https://developer.nvidia.com/blog/maximum-performance-and-minimum-footprint-for-ai-apps-with-nvidia-tensorrt-weight-stripped-engines/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/06/04] ‚ú® #TensorRT and GeForce #RTX unlock ComfyUI SD superhero powers ü¶∏‚ö° üé• Demo: &lt;a href="https://youtu.be/64QEVfbPHyg"&gt;‚û°Ô∏è link&lt;/a&gt; üìó DIY notebook: &lt;a href="https://console.brev.dev/launchable/deploy?userID=2x2sil999&amp;amp;orgID=ktj33l4xj&amp;amp;name=ComfyUI_TensorRT&amp;amp;instance=L4%40g2-standard-4%3Anvidia-l4%3A1&amp;amp;diskStorage=500&amp;amp;cloudID=GCP&amp;amp;baseImage=docker.io%2Fpytorch%2Fpytorch%3A2.2.0-cuda12.1-cudnn8-runtime&amp;amp;ports=ComfUI%3A8188&amp;amp;file=https%3A%2F%2Fgithub.com%2Fbrevdev%2Fnotebooks%2Fblob%2Fmain%2Ftensorrt-comfyui.ipynb&amp;amp;launchableID=env-2hQX3n7ae5mq3NjNZ32DfAG0tJf"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/05/28] ‚ú®#TensorRT weight stripping for ResNet-50 ‚ú® ‚úÖ+99% compression ‚úÖ1 set of weights ‚Üí ** GPUs\ ‚úÖ0 performance loss ‚úÖ** models‚Ä¶LLM, CNN, etc üëÄ üìö DIY &lt;a href="https://console.brev.dev/launchable/deploy?userID=2x2sil999&amp;amp;orgID=ktj33l4xj&amp;amp;launchableID=env-2h6bym7h5GFNho3vpWQQeUYMwTM&amp;amp;instance=L4%40g6.xlarge&amp;amp;diskStorage=500&amp;amp;cloudID=devplane-brev-1&amp;amp;baseImage=nvcr.io%2Fnvidia%2Ftensorrt%3A24.05-py3&amp;amp;file=https%3A%2F%2Fgithub.com%2FNVIDIA%2FTensorRT%2Fblob%2Frelease%2F10.0%2Fsamples%2Fpython%2Fsample_weight_stripping%2Fnotebooks%2Fweight_stripping.ipynb&amp;amp;name=tensorrt_weight_stripping_resnet50"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/05/21] ‚ú®@modal_labs has the codes for serverless @AIatMeta Llama 3 on #TensorRT #LLM ‚ú®üëÄ üìö Marvelous Modal Manual: Serverless TensorRT LLM (LLaMA 3 8B) | Modal Docs &lt;a href="https://modal.com/docs/examples/trtllm_llama"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/05/08] NVIDIA Model Optimizer -- the newest member of the #TensorRT ecosystem is a library of post-training and training-in-the-loop model optimization techniques ‚úÖquantization ‚úÖsparsity ‚úÖQAT &lt;a href="https://developer.nvidia.com/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/"&gt;‚û°Ô∏è blog&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/05/07] ü¶ôü¶ôü¶ô 24,000 tokens per second üõ´Meta Llama 3 takes off with #TensorRT #LLM üìö&lt;a href="https://blogs.nvidia.com/blog/meta-llama3-inference-acceleration/"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/02/06] &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/blogs/quantization-in-TRT-LLM.md"&gt;üöÄ Speed up inference with SOTA quantization techniques in TRT-LLM&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2024/01/30] &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/blogs/XQA-kernel.md"&gt; New XQA-kernel provides 2.4x more Llama-70B throughput within the same latency budget&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2023/12/04] &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/blogs/Falcon180B-H200.md"&gt;Falcon-180B on a single H200 GPU with INT4 AWQ, and 6.7x faster Llama-70B over A100&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2023/11/27] &lt;a href="https://aws.amazon.com/blogs/machine-learning/boost-inference-performance-for-llms-with-new-amazon-sagemaker-containers/"&gt;SageMaker LMI now supports TensorRT LLM - improves throughput by 60%, compared to previous version&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2023/11/13] &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/blogs/H200launch.md"&gt;H200 achieves nearly 12,000 tok/sec on Llama2-13B&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2023/10/22] &lt;a href="https://github.com/NVIDIA/trt-llm-rag-windows#readme"&gt;üöÄ RAG on Windows using TensorRT LLM and LlamaIndex ü¶ô&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2023/10/19] Getting Started Guide - &lt;a href="https://developer.nvidia.com/blog/optimizing-inference-on-llms-with-tensorrt-llm-now-publicly-available/"&gt;Optimizing Inference on Large Language Models with NVIDIA TensorRT-LLM, Now Publicly Available &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;[2023/10/17] &lt;a href="https://blogs.nvidia.com/blog/2023/10/17/tensorrt-llm-windows-stable-diffusion-rtx/"&gt;Large Language Models up to 4x Faster on RTX With TensorRT LLM for Windows &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;h2&gt;TensorRT LLM Overview&lt;/h2&gt; 
  &lt;p&gt;TensorRT LLM is an open-sourced library for optimizing Large Language Model (LLM) inference. It provides state-of-the-art optimizations, including custom attention kernels, inflight batching, paged KV caching, quantization (FP8, &lt;a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/"&gt;FP4&lt;/a&gt;, INT4 &lt;a href="https://arxiv.org/abs/2306.00978"&gt;AWQ&lt;/a&gt;, INT8 &lt;a href="https://arxiv.org/abs/2211.10438"&gt;SmoothQuant&lt;/a&gt;, ...), speculative decoding, and much more, to perform inference efficiently on NVIDIA GPUs.&lt;/p&gt; 
  &lt;p&gt;&lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/release/1.1/docs/source/developer-guide/overview.md"&gt;Architected on PyTorch&lt;/a&gt;, TensorRT LLM provides a high-level Python &lt;a href="https://nvidia.github.io/TensorRT-LLM/quick-start-guide.html#llm-api"&gt;LLM API&lt;/a&gt; that supports a wide range of inference setups - from single-GPU to multi-GPU or multi-node deployments. It includes built-in support for various parallelism strategies and advanced features. The LLM API integrates seamlessly with the broader inference ecosystem, including NVIDIA &lt;a href="https://github.com/ai-dynamo/dynamo"&gt;Dynamo&lt;/a&gt; and the &lt;a href="https://github.com/triton-inference-server/server"&gt;Triton Inference Server&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;TensorRT LLM is designed to be modular and easy to modify. Its PyTorch-native architecture allows developers to experiment with the runtime or extend functionality. Several popular models are also pre-defined and can be customized using &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/tensorrt_llm/_torch/models/modeling_deepseekv3.py"&gt;native PyTorch code&lt;/a&gt;, making it easy to adapt the system to specific needs.&lt;/p&gt; 
  &lt;h2&gt;Getting Started&lt;/h2&gt; 
  &lt;p&gt;To get started with TensorRT-LLM, visit our documentation:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://nvidia.github.io/TensorRT-LLM/quick-start-guide.html"&gt;Quick Start Guide&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/examples/models/core/deepseek_v3"&gt;Running DeepSeek&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://nvidia.github.io/TensorRT-LLM/installation/linux.html"&gt;Installation Guide for Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://nvidia.github.io/TensorRT-LLM/installation/grace-hopper.html"&gt;Installation Guide for Grace Hopper&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://nvidia.github.io/TensorRT-LLM/reference/support-matrix.html"&gt;Supported Hardware, Models, and other Software&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://nvidia.github.io/TensorRT-LLM/performance/performance-tuning-guide/benchmarking-default-performance.html#benchmarking-with-trtllm-bench"&gt;Benchmarking Performance&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://nvidia.github.io/TensorRT-LLM/release-notes.html"&gt;Release Notes&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;h2&gt;Deprecation Policy&lt;/h2&gt; 
  &lt;p&gt;Deprecation is used to inform developers that some APIs and tools are no longer recommended for use. Beginning with version 1.0, TensorRT LLM has the following deprecation policy:&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;Communication of Deprecation&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Deprecation notices are documented in the Release Notes.&lt;/li&gt; 
   &lt;li&gt;Deprecated APIs, methods, classes, or parameters include a statement in the source code indicating when they were deprecated.&lt;/li&gt; 
   &lt;li&gt;If used, deprecated methods, classes, or parameters issue runtime deprecation warnings.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ol start="2"&gt; 
   &lt;li&gt;Migration Period&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;TensorRT LLM provides a 3-month migration period after deprecation.&lt;/li&gt; 
   &lt;li&gt;During this period, deprecated APIs, tools, or parameters continue to work but trigger warnings.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ol start="3"&gt; 
   &lt;li&gt;Scope of Deprecation&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full API/Method/Class Deprecation: The entire API/method/class is marked for removal.&lt;/li&gt; 
   &lt;li&gt;Partial Deprecation: If only specific parameters of an API/method are deprecated (e.g., param1 in LLM.generate(param1, param2)), the method itself remains functional, but the deprecated parameters will be removed in a future release.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ol start="4"&gt; 
   &lt;li&gt;Removal After Migration Period&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;After the 3-month migration period ends, deprecated APIs, tools, or parameters are removed in a manner consistent with semantic versioning (major version changes may include breaking removals).&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;h2&gt;Useful Links&lt;/h2&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://huggingface.co/collections/nvidia/model-optimizer-66aa84f7966b3150262481a4"&gt;Quantized models on Hugging Face&lt;/a&gt;: A growing collection of quantized (e.g., FP8, FP4) and optimized LLMs, including &lt;a href="https://huggingface.co/nvidia/DeepSeek-R1-FP4"&gt;DeepSeek FP4&lt;/a&gt;, ready for fast inference with TensorRT LLM.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ai-dynamo/dynamo"&gt;NVIDIA Dynamo&lt;/a&gt;: A datacenter scale distributed inference serving framework that works seamlessly with TensorRT LLM.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://nvidia.github.io/TensorRT-LLM/torch/auto_deploy/auto-deploy.html"&gt;AutoDeploy&lt;/a&gt;: A prototype backend for TensorRT LLM to simplify and accelerate the deployment of PyTorch models.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/NVIDIA/TensorRT-LLM/issues/5359"&gt;WeChat Discussion Group&lt;/a&gt;: A real-time channel for TensorRT LLM Q&amp;amp;A and news.&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>github/spec-kit</title>
      <link>https://github.com/github/spec-kit</link>
      <description>&lt;p&gt;üí´ Toolkit to help you get started with Spec-Driven Development&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/github/spec-kit/main/media/logo_large.webp" alt="Spec Kit Logo" width="200" height="200" /&gt; 
 &lt;h1&gt;üå± Spec Kit&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Build high-quality software faster.&lt;/em&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt;An open source toolkit that allows you to focus on product scenarios and predictable outcomes instead of vibe coding every piece from scratch.&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/github/spec-kit/actions/workflows/release.yml"&gt;&lt;img src="https://github.com/github/spec-kit/actions/workflows/release.yml/badge.svg?sanitize=true" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/github/spec-kit/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/github/spec-kit?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/github/spec-kit/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/github/spec-kit" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.github.io/spec-kit/"&gt;&lt;img src="https://img.shields.io/badge/docs-GitHub_Pages-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-what-is-spec-driven-development"&gt;ü§î What is Spec-Driven Development?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-get-started"&gt;‚ö° Get Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#%EF%B8%8F-video-overview"&gt;üìΩÔ∏è Video Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-supported-ai-agents"&gt;ü§ñ Supported AI Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-specify-cli-reference"&gt;üîß Specify CLI Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-core-philosophy"&gt;üìö Core Philosophy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-development-phases"&gt;üåü Development Phases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-experimental-goals"&gt;üéØ Experimental Goals&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-prerequisites"&gt;üîß Prerequisites&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-learn-more"&gt;üìñ Learn More&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-detailed-process"&gt;üìã Detailed Process&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-troubleshooting"&gt;üîç Troubleshooting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-maintainers"&gt;üë• Maintainers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-support"&gt;üí¨ Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-acknowledgements"&gt;üôè Acknowledgements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-license"&gt;üìÑ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§î What is Spec-Driven Development?&lt;/h2&gt; 
&lt;p&gt;Spec-Driven Development &lt;strong&gt;flips the script&lt;/strong&gt; on traditional software development. For decades, code has been king ‚Äî specifications were just scaffolding we built and discarded once the "real work" of coding began. Spec-Driven Development changes this: &lt;strong&gt;specifications become executable&lt;/strong&gt;, directly generating working implementations rather than just guiding them.&lt;/p&gt; 
&lt;h2&gt;‚ö° Get Started&lt;/h2&gt; 
&lt;h3&gt;1. Install Specify CLI&lt;/h3&gt; 
&lt;p&gt;Choose your preferred installation method:&lt;/p&gt; 
&lt;h4&gt;Option 1: Persistent Installation (Recommended)&lt;/h4&gt; 
&lt;p&gt;Install once and use everywhere:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv tool install specify-cli --from git+https://github.com/github/spec-kit.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then use the tool directly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create new project
specify init &amp;lt;PROJECT_NAME&amp;gt;

# Or initialize in existing project
specify init . --ai claude
# or
specify init --here --ai claude

# Check installed tools
specify check
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To upgrade Specify, see the &lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/docs/upgrade.md"&gt;Upgrade Guide&lt;/a&gt; for detailed instructions. Quick upgrade:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv tool install specify-cli --force --from git+https://github.com/github/spec-kit.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option 2: One-time Usage&lt;/h4&gt; 
&lt;p&gt;Run directly without installing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx --from git+https://github.com/github/spec-kit.git specify init &amp;lt;PROJECT_NAME&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Benefits of persistent installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tool stays installed and available in PATH&lt;/li&gt; 
 &lt;li&gt;No need to create shell aliases&lt;/li&gt; 
 &lt;li&gt;Better tool management with &lt;code&gt;uv tool list&lt;/code&gt;, &lt;code&gt;uv tool upgrade&lt;/code&gt;, &lt;code&gt;uv tool uninstall&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Cleaner shell configuration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. Establish project principles&lt;/h3&gt; 
&lt;p&gt;Launch your AI assistant in the project directory. The &lt;code&gt;/speckit.*&lt;/code&gt; commands are available in the assistant.&lt;/p&gt; 
&lt;p&gt;Use the &lt;strong&gt;&lt;code&gt;/speckit.constitution&lt;/code&gt;&lt;/strong&gt; command to create your project's governing principles and development guidelines that will guide all subsequent development.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/speckit.constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Create the spec&lt;/h3&gt; 
&lt;p&gt;Use the &lt;strong&gt;&lt;code&gt;/speckit.specify&lt;/code&gt;&lt;/strong&gt; command to describe what you want to build. Focus on the &lt;strong&gt;what&lt;/strong&gt; and &lt;strong&gt;why&lt;/strong&gt;, not the tech stack.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/speckit.specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums are never in other nested albums. Within each album, photos are previewed in a tile-like interface.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. Create a technical implementation plan&lt;/h3&gt; 
&lt;p&gt;Use the &lt;strong&gt;&lt;code&gt;/speckit.plan&lt;/code&gt;&lt;/strong&gt; command to provide your tech stack and architecture choices.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/speckit.plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;5. Break down into tasks&lt;/h3&gt; 
&lt;p&gt;Use &lt;strong&gt;&lt;code&gt;/speckit.tasks&lt;/code&gt;&lt;/strong&gt; to create an actionable task list from your implementation plan.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/speckit.tasks
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;6. Execute implementation&lt;/h3&gt; 
&lt;p&gt;Use &lt;strong&gt;&lt;code&gt;/speckit.implement&lt;/code&gt;&lt;/strong&gt; to execute all tasks and build your feature according to the plan.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/speckit.implement
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed step-by-step instructions, see our &lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/spec-driven.md"&gt;comprehensive guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìΩÔ∏è Video Overview&lt;/h2&gt; 
&lt;p&gt;Want to see Spec Kit in action? Watch our &lt;a href="https://www.youtube.com/watch?v=a9eR1xsfvHg&amp;amp;pp=0gcJCckJAYcqIYzv"&gt;video overview&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=a9eR1xsfvHg&amp;amp;pp=0gcJCckJAYcqIYzv"&gt;&lt;img src="https://raw.githubusercontent.com/github/spec-kit/main/media/spec-kit-video-header.jpg" alt="Spec Kit video header" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ñ Supported AI Agents&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://qoder.com/cli"&gt;Qoder CLI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aws.amazon.com/developer/learning/q-developer-cli/"&gt;Amazon Q Developer CLI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
   &lt;td&gt;Amazon Q Developer CLI &lt;a href="https://github.com/aws/amazon-q-developer-cli/issues/3064"&gt;does not support&lt;/a&gt; custom arguments for slash commands.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://ampcode.com/"&gt;Amp&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.augmentcode.com/cli/overview"&gt;Auggie CLI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.anthropic.com/claude-code"&gt;Claude Code&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.codebuddy.ai/cli"&gt;CodeBuddy CLI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/openai/codex"&gt;Codex CLI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cursor.sh/"&gt;Cursor&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/google-gemini/gemini-cli"&gt;Gemini CLI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://code.visualstudio.com/"&gt;GitHub Copilot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.ibm.com/products/bob"&gt;IBM Bob&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;IDE-based agent with slash command support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://jules.google.com/"&gt;Jules&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Kilo-Org/kilocode"&gt;Kilo Code&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://opencode.ai/"&gt;opencode&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/QwenLM/qwen-code"&gt;Qwen Code&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://roocode.com/"&gt;Roo Code&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ovh/shai"&gt;SHAI (OVHcloud)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://windsurf.com/"&gt;Windsurf&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üîß Specify CLI Reference&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;specify&lt;/code&gt; command supports the following options:&lt;/p&gt; 
&lt;h3&gt;Commands&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;init&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Initialize a new Specify project from the latest template&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;check&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Check for installed tools (&lt;code&gt;git&lt;/code&gt;, &lt;code&gt;claude&lt;/code&gt;, &lt;code&gt;gemini&lt;/code&gt;, &lt;code&gt;code&lt;/code&gt;/&lt;code&gt;code-insiders&lt;/code&gt;, &lt;code&gt;cursor-agent&lt;/code&gt;, &lt;code&gt;windsurf&lt;/code&gt;, &lt;code&gt;qwen&lt;/code&gt;, &lt;code&gt;opencode&lt;/code&gt;, &lt;code&gt;codex&lt;/code&gt;, &lt;code&gt;shai&lt;/code&gt;, &lt;code&gt;qoder&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;code&gt;specify init&lt;/code&gt; Arguments &amp;amp; Options&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Argument/Option&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;project-name&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Argument&lt;/td&gt; 
   &lt;td&gt;Name for your new project directory (optional if using &lt;code&gt;--here&lt;/code&gt;, or use &lt;code&gt;.&lt;/code&gt; for current directory)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--ai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Option&lt;/td&gt; 
   &lt;td&gt;AI assistant to use: &lt;code&gt;claude&lt;/code&gt;, &lt;code&gt;gemini&lt;/code&gt;, &lt;code&gt;copilot&lt;/code&gt;, &lt;code&gt;cursor-agent&lt;/code&gt;, &lt;code&gt;qwen&lt;/code&gt;, &lt;code&gt;opencode&lt;/code&gt;, &lt;code&gt;codex&lt;/code&gt;, &lt;code&gt;windsurf&lt;/code&gt;, &lt;code&gt;kilocode&lt;/code&gt;, &lt;code&gt;auggie&lt;/code&gt;, &lt;code&gt;roo&lt;/code&gt;, &lt;code&gt;codebuddy&lt;/code&gt;, &lt;code&gt;amp&lt;/code&gt;, &lt;code&gt;shai&lt;/code&gt;, &lt;code&gt;q&lt;/code&gt;, &lt;code&gt;bob&lt;/code&gt;, or &lt;code&gt;qoder&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--script&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Option&lt;/td&gt; 
   &lt;td&gt;Script variant to use: &lt;code&gt;sh&lt;/code&gt; (bash/zsh) or &lt;code&gt;ps&lt;/code&gt; (PowerShell)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--ignore-agent-tools&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Flag&lt;/td&gt; 
   &lt;td&gt;Skip checks for AI agent tools like Claude Code&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-git&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Flag&lt;/td&gt; 
   &lt;td&gt;Skip git repository initialization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--here&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Flag&lt;/td&gt; 
   &lt;td&gt;Initialize project in the current directory instead of creating a new one&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--force&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Flag&lt;/td&gt; 
   &lt;td&gt;Force merge/overwrite when initializing in current directory (skip confirmation)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--skip-tls&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Flag&lt;/td&gt; 
   &lt;td&gt;Skip SSL/TLS verification (not recommended)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--debug&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Flag&lt;/td&gt; 
   &lt;td&gt;Enable detailed debug output for troubleshooting&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--github-token&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Option&lt;/td&gt; 
   &lt;td&gt;GitHub token for API requests (or set GH_TOKEN/GITHUB_TOKEN env variable)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic project initialization
specify init my-project

# Initialize with specific AI assistant
specify init my-project --ai claude

# Initialize with Cursor support
specify init my-project --ai cursor-agent

# Initialize with Qoder support
specify init my-project --ai qoder

# Initialize with Windsurf support
specify init my-project --ai windsurf

# Initialize with Amp support
specify init my-project --ai amp

# Initialize with SHAI support
specify init my-project --ai shai

# Initialize with IBM Bob support
specify init my-project --ai bob

# Initialize with PowerShell scripts (Windows/cross-platform)
specify init my-project --ai copilot --script ps

# Initialize in current directory
specify init . --ai copilot
# or use the --here flag
specify init --here --ai copilot

# Force merge into current (non-empty) directory without confirmation
specify init . --force --ai copilot
# or
specify init --here --force --ai copilot

# Skip git initialization
specify init my-project --ai gemini --no-git

# Enable debug output for troubleshooting
specify init my-project --ai claude --debug

# Use GitHub token for API requests (helpful for corporate environments)
specify init my-project --ai claude --github-token ghp_your_token_here

# Check system requirements
specify check
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Available Slash Commands&lt;/h3&gt; 
&lt;p&gt;After running &lt;code&gt;specify init&lt;/code&gt;, your AI coding agent will have access to these slash commands for structured development:&lt;/p&gt; 
&lt;h4&gt;Core Commands&lt;/h4&gt; 
&lt;p&gt;Essential commands for the Spec-Driven Development workflow:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/speckit.constitution&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Create or update project governing principles and development guidelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/speckit.specify&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Define what you want to build (requirements and user stories)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/speckit.plan&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Create technical implementation plans with your chosen tech stack&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/speckit.tasks&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Generate actionable task lists for implementation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/speckit.implement&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Execute all tasks to build the feature according to the plan&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Optional Commands&lt;/h4&gt; 
&lt;p&gt;Additional commands for enhanced quality and validation:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/speckit.clarify&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Clarify underspecified areas (recommended before &lt;code&gt;/speckit.plan&lt;/code&gt;; formerly &lt;code&gt;/quizme&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/speckit.analyze&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cross-artifact consistency &amp;amp; coverage analysis (run after &lt;code&gt;/speckit.tasks&lt;/code&gt;, before &lt;code&gt;/speckit.implement&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/speckit.checklist&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Generate custom quality checklists that validate requirements completeness, clarity, and consistency (like "unit tests for English")&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SPECIFY_FEATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Override feature detection for non-Git repositories. Set to the feature directory name (e.g., &lt;code&gt;001-photo-albums&lt;/code&gt;) to work on a specific feature when not using Git branches.&lt;br /&gt;**Must be set in the context of the agent you're working with prior to using &lt;code&gt;/speckit.plan&lt;/code&gt; or follow-up commands.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üìö Core Philosophy&lt;/h2&gt; 
&lt;p&gt;Spec-Driven Development is a structured process that emphasizes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intent-driven development&lt;/strong&gt; where specifications define the "&lt;em&gt;what&lt;/em&gt;" before the "&lt;em&gt;how&lt;/em&gt;"&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rich specification creation&lt;/strong&gt; using guardrails and organizational principles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-step refinement&lt;/strong&gt; rather than one-shot code generation from prompts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Heavy reliance&lt;/strong&gt; on advanced AI model capabilities for specification interpretation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåü Development Phases&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Phase&lt;/th&gt; 
   &lt;th&gt;Focus&lt;/th&gt; 
   &lt;th&gt;Key Activities&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;0-to-1 Development&lt;/strong&gt; ("Greenfield")&lt;/td&gt; 
   &lt;td&gt;Generate from scratch&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;Start with high-level requirements&lt;/li&gt;
     &lt;li&gt;Generate specifications&lt;/li&gt;
     &lt;li&gt;Plan implementation steps&lt;/li&gt;
     &lt;li&gt;Build production-ready applications&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Creative Exploration&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Parallel implementations&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;Explore diverse solutions&lt;/li&gt;
     &lt;li&gt;Support multiple technology stacks &amp;amp; architectures&lt;/li&gt;
     &lt;li&gt;Experiment with UX patterns&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Iterative Enhancement&lt;/strong&gt; ("Brownfield")&lt;/td&gt; 
   &lt;td&gt;Brownfield modernization&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;Add features iteratively&lt;/li&gt;
     &lt;li&gt;Modernize legacy systems&lt;/li&gt;
     &lt;li&gt;Adapt processes&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üéØ Experimental Goals&lt;/h2&gt; 
&lt;p&gt;Our research and experimentation focus on:&lt;/p&gt; 
&lt;h3&gt;Technology independence&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create applications using diverse technology stacks&lt;/li&gt; 
 &lt;li&gt;Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise constraints&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Demonstrate mission-critical application development&lt;/li&gt; 
 &lt;li&gt;Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)&lt;/li&gt; 
 &lt;li&gt;Support enterprise design systems and compliance requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User-centric development&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Build applications for different user cohorts and preferences&lt;/li&gt; 
 &lt;li&gt;Support various development approaches (from vibe-coding to AI-native development)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Creative &amp;amp; iterative processes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Validate the concept of parallel implementation exploration&lt;/li&gt; 
 &lt;li&gt;Provide robust iterative feature development workflows&lt;/li&gt; 
 &lt;li&gt;Extend processes to handle upgrades and modernization tasks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîß Prerequisites&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux/macOS/Windows&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-supported-ai-agents"&gt;Supported&lt;/a&gt; AI coding agent.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; for package management&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python 3.11+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/downloads"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you encounter issues with an agent, please open an issue so we can refine the integration.&lt;/p&gt; 
&lt;h2&gt;üìñ Learn More&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/spec-driven.md"&gt;Complete Spec-Driven Development Methodology&lt;/a&gt;&lt;/strong&gt; - Deep dive into the full process&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/#-detailed-process"&gt;Detailed Walkthrough&lt;/a&gt;&lt;/strong&gt; - Step-by-step implementation guide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìã Detailed Process&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to expand the detailed step-by-step walkthrough&lt;/summary&gt; 
 &lt;p&gt;You can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;specify init &amp;lt;project_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Or initialize in the current directory:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;specify init .
# or use the --here flag
specify init --here
# Skip confirmation when the directory already has files
specify init . --force
# or
specify init --here --force
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/github/spec-kit/main/media/specify_cli.gif" alt="Specify CLI bootstrapping a new project in the terminal" /&gt;&lt;/p&gt; 
 &lt;p&gt;You will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;specify init &amp;lt;project_name&amp;gt; --ai claude
specify init &amp;lt;project_name&amp;gt; --ai gemini
specify init &amp;lt;project_name&amp;gt; --ai copilot

# Or in current directory:
specify init . --ai claude
specify init . --ai codex

# or use --here flag
specify init --here --ai claude
specify init --here --ai codex

# Force merge into a non-empty current directory
specify init . --force --ai claude

# or
specify init --here --force --ai claude
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The CLI will check if you have Claude Code, Gemini CLI, Cursor CLI, Qwen CLI, opencode, Codex CLI, Qoder CLI, or Amazon Q Developer CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use &lt;code&gt;--ignore-agent-tools&lt;/code&gt; with your command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;specify init &amp;lt;project_name&amp;gt; --ai claude --ignore-agent-tools
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;&lt;strong&gt;STEP 1:&lt;/strong&gt; Establish project principles&lt;/h3&gt; 
 &lt;p&gt;Go to the project folder and run your AI agent. In our example, we're using &lt;code&gt;claude&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/github/spec-kit/main/media/bootstrap-claude-code.gif" alt="Bootstrapping Claude Code environment" /&gt;&lt;/p&gt; 
 &lt;p&gt;You will know that things are configured correctly if you see the &lt;code&gt;/speckit.constitution&lt;/code&gt;, &lt;code&gt;/speckit.specify&lt;/code&gt;, &lt;code&gt;/speckit.plan&lt;/code&gt;, &lt;code&gt;/speckit.tasks&lt;/code&gt;, and &lt;code&gt;/speckit.implement&lt;/code&gt; commands available.&lt;/p&gt; 
 &lt;p&gt;The first step should be establishing your project's governing principles using the &lt;code&gt;/speckit.constitution&lt;/code&gt; command. This helps ensure consistent decision-making throughout all subsequent development phases:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;/speckit.constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements. Include governance for how these principles should guide technical decisions and implementation choices.
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This step creates or updates the &lt;code&gt;.specify/memory/constitution.md&lt;/code&gt; file with your project's foundational guidelines that the AI agent will reference during specification, planning, and implementation phases.&lt;/p&gt; 
 &lt;h3&gt;&lt;strong&gt;STEP 2:&lt;/strong&gt; Create project specifications&lt;/h3&gt; 
 &lt;p&gt;With your project principles established, you can now create the functional specifications. Use the &lt;code&gt;/speckit.specify&lt;/code&gt; command and then provide the concrete requirements for the project you want to develop.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!IMPORTANT] Be as explicit as possible about &lt;em&gt;what&lt;/em&gt; you are trying to build and &lt;em&gt;why&lt;/em&gt;. &lt;strong&gt;Do not focus on the tech stack at this point&lt;/strong&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;An example prompt:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;Develop Taskify, a team productivity platform. It should allow users to create projects, add team members,
assign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,
let's call it "Create Taskify," let's have multiple users but the users will be declared ahead of time, predefined.
I want five users in two different categories, one product manager and four engineers. Let's create three
different sample projects. Let's have the standard Kanban columns for the status of each task, such as "To Do,"
"In Progress," "In Review," and "Done." There will be no login for this application as this is just the very
first testing thing to ensure that our basic features are set up. For each task in the UI for a task card,
you should be able to change the current status of the task between the different columns in the Kanban work board.
You should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task
card, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick
from. There will be no password required. When you click on a user, you go into the main view, which displays the list of
projects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.
You'll be able to drag and drop cards back and forth between different columns. You will see any cards that are
assigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly
see yours. You can edit any comments that you make, but you can't edit comments that other people made. You can
delete any comments that you made, but you can't delete comments anybody else made.
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;After this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.&lt;/p&gt; 
 &lt;p&gt;Once this step is completed, you should have a new branch created (e.g., &lt;code&gt;001-create-taskify&lt;/code&gt;), as well as a new specification in the &lt;code&gt;specs/001-create-taskify&lt;/code&gt; directory.&lt;/p&gt; 
 &lt;p&gt;The produced specification should contain a set of user stories and functional requirements, as defined in the template.&lt;/p&gt; 
 &lt;p&gt;At this stage, your project folder contents should resemble the following:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;‚îî‚îÄ‚îÄ .specify
    ‚îú‚îÄ‚îÄ memory
    ‚îÇ  ‚îî‚îÄ‚îÄ constitution.md
    ‚îú‚îÄ‚îÄ scripts
    ‚îÇ  ‚îú‚îÄ‚îÄ check-prerequisites.sh
    ‚îÇ  ‚îú‚îÄ‚îÄ common.sh
    ‚îÇ  ‚îú‚îÄ‚îÄ create-new-feature.sh
    ‚îÇ  ‚îú‚îÄ‚îÄ setup-plan.sh
    ‚îÇ  ‚îî‚îÄ‚îÄ update-claude-md.sh
    ‚îú‚îÄ‚îÄ specs
    ‚îÇ  ‚îî‚îÄ‚îÄ 001-create-taskify
    ‚îÇ      ‚îî‚îÄ‚îÄ spec.md
    ‚îî‚îÄ‚îÄ templates
        ‚îú‚îÄ‚îÄ plan-template.md
        ‚îú‚îÄ‚îÄ spec-template.md
        ‚îî‚îÄ‚îÄ tasks-template.md
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;&lt;strong&gt;STEP 3:&lt;/strong&gt; Functional specification clarification (required before planning)&lt;/h3&gt; 
 &lt;p&gt;With the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt.&lt;/p&gt; 
 &lt;p&gt;You should run the structured clarification workflow &lt;strong&gt;before&lt;/strong&gt; creating a technical plan to reduce rework downstream.&lt;/p&gt; 
 &lt;p&gt;Preferred order:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Use &lt;code&gt;/speckit.clarify&lt;/code&gt; (structured) ‚Äì sequential, coverage-based questioning that records answers in a Clarifications section.&lt;/li&gt; 
  &lt;li&gt;Optionally follow up with ad-hoc free-form refinement if something still feels vague.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;If you intentionally want to skip clarification (e.g., spike or exploratory prototype), explicitly state that so the agent doesn't block on missing clarifications.&lt;/p&gt; 
 &lt;p&gt;Example free-form refinement prompt (after &lt;code&gt;/speckit.clarify&lt;/code&gt; if still needed):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;For each sample project or project that you create there should be a variable number of tasks between 5 and 15
tasks for each one randomly distributed into different states of completion. Make sure that there's at least
one task in each stage of completion.
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You should also ask Claude Code to validate the &lt;strong&gt;Review &amp;amp; Acceptance Checklist&lt;/strong&gt;, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;Read the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;It's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - &lt;strong&gt;do not treat its first attempt as final&lt;/strong&gt;.&lt;/p&gt; 
 &lt;h3&gt;&lt;strong&gt;STEP 4:&lt;/strong&gt; Generate a plan&lt;/h3&gt; 
 &lt;p&gt;You can now be specific about the tech stack and other technical requirements. You can use the &lt;code&gt;/speckit.plan&lt;/code&gt; command that is built into the project template with a prompt like this:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;We are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use
Blazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,
tasks API, and a notifications API.
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The output of this step will include a number of implementation detail documents, with your directory tree resembling this:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;.
‚îú‚îÄ‚îÄ CLAUDE.md
‚îú‚îÄ‚îÄ memory
‚îÇ  ‚îî‚îÄ‚îÄ constitution.md
‚îú‚îÄ‚îÄ scripts
‚îÇ  ‚îú‚îÄ‚îÄ check-prerequisites.sh
‚îÇ  ‚îú‚îÄ‚îÄ common.sh
‚îÇ  ‚îú‚îÄ‚îÄ create-new-feature.sh
‚îÇ  ‚îú‚îÄ‚îÄ setup-plan.sh
‚îÇ  ‚îî‚îÄ‚îÄ update-claude-md.sh
‚îú‚îÄ‚îÄ specs
‚îÇ  ‚îî‚îÄ‚îÄ 001-create-taskify
‚îÇ      ‚îú‚îÄ‚îÄ contracts
‚îÇ      ‚îÇ  ‚îú‚îÄ‚îÄ api-spec.json
‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ signalr-spec.md
‚îÇ      ‚îú‚îÄ‚îÄ data-model.md
‚îÇ      ‚îú‚îÄ‚îÄ plan.md
‚îÇ      ‚îú‚îÄ‚îÄ quickstart.md
‚îÇ      ‚îú‚îÄ‚îÄ research.md
‚îÇ      ‚îî‚îÄ‚îÄ spec.md
‚îî‚îÄ‚îÄ templates
    ‚îú‚îÄ‚îÄ CLAUDE-template.md
    ‚îú‚îÄ‚îÄ plan-template.md
    ‚îú‚îÄ‚îÄ spec-template.md
    ‚îî‚îÄ‚îÄ tasks-template.md
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Check the &lt;code&gt;research.md&lt;/code&gt; document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).&lt;/p&gt; 
 &lt;p&gt;Additionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;I want you to go through the implementation plan and implementation details, looking for areas that could
benefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that
require further research, I want you to update the research document with additional details about the specific
versions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify
any details using research from the web.
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;During this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;I think we need to break this down into a series of steps. First, identify a list of tasks
that you would need to do during implementation that you're not sure of or would benefit
from further research. Write down a list of those tasks. And then for each one of these tasks,
I want you to spin up a separate research task so that the net results is we are researching
all of those very specific tasks in parallel. What I saw you doing was it looks like you were
researching .NET Aspire in general and I don't think that's gonna do much for us in this case.
That's way too untargeted research. The research needs to help you solve a specific targeted question.
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!NOTE] Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;&lt;strong&gt;STEP 5:&lt;/strong&gt; Have Claude Code validate the plan&lt;/h3&gt; 
 &lt;p&gt;With the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;Now I want you to go and audit the implementation plan and the implementation detail files.
Read through it with an eye on determining whether or not there is a sequence of tasks that you need
to be doing that are obvious from reading this. Because I don't know if there's enough here. For example,
when I look at the core implementation, it would be useful to reference the appropriate places in the implementation
details where it can find the information as it walks through each step in the core implementation or in the refinement.
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.&lt;/p&gt; 
 &lt;p&gt;You can also ask Claude Code (if you have the &lt;a href="https://docs.github.com/en/github-cli/github-cli"&gt;GitHub CLI&lt;/a&gt; installed) to go ahead and create a pull request from your current branch to &lt;code&gt;main&lt;/code&gt; with a detailed description, to make sure that the effort is properly tracked.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!NOTE] Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the &lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/base/memory/constitution.md"&gt;constitution&lt;/a&gt; as the foundational piece that it must adhere to when establishing the plan.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;&lt;strong&gt;STEP 6:&lt;/strong&gt; Generate task breakdown with /speckit.tasks&lt;/h3&gt; 
 &lt;p&gt;With the implementation plan validated, you can now break down the plan into specific, actionable tasks that can be executed in the correct order. Use the &lt;code&gt;/speckit.tasks&lt;/code&gt; command to automatically generate a detailed task breakdown from your implementation plan:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;/speckit.tasks
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This step creates a &lt;code&gt;tasks.md&lt;/code&gt; file in your feature specification directory that contains:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Task breakdown organized by user story&lt;/strong&gt; - Each user story becomes a separate implementation phase with its own set of tasks&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Dependency management&lt;/strong&gt; - Tasks are ordered to respect dependencies between components (e.g., models before services, services before endpoints)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Parallel execution markers&lt;/strong&gt; - Tasks that can run in parallel are marked with &lt;code&gt;[P]&lt;/code&gt; to optimize development workflow&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;File path specifications&lt;/strong&gt; - Each task includes the exact file paths where implementation should occur&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Test-driven development structure&lt;/strong&gt; - If tests are requested, test tasks are included and ordered to be written before implementation&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Checkpoint validation&lt;/strong&gt; - Each user story phase includes checkpoints to validate independent functionality&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;The generated tasks.md provides a clear roadmap for the &lt;code&gt;/speckit.implement&lt;/code&gt; command, ensuring systematic implementation that maintains code quality and allows for incremental delivery of user stories.&lt;/p&gt; 
 &lt;h3&gt;&lt;strong&gt;STEP 7:&lt;/strong&gt; Implementation&lt;/h3&gt; 
 &lt;p&gt;Once ready, use the &lt;code&gt;/speckit.implement&lt;/code&gt; command to execute your implementation plan:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;/speckit.implement
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;/speckit.implement&lt;/code&gt; command will:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Validate that all prerequisites are in place (constitution, spec, plan, and tasks)&lt;/li&gt; 
  &lt;li&gt;Parse the task breakdown from &lt;code&gt;tasks.md&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Execute tasks in the correct order, respecting dependencies and parallel execution markers&lt;/li&gt; 
  &lt;li&gt;Follow the TDD approach defined in your task plan&lt;/li&gt; 
  &lt;li&gt;Provide progress updates and handle errors appropriately&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!IMPORTANT] The AI agent will execute local CLI commands (such as &lt;code&gt;dotnet&lt;/code&gt;, &lt;code&gt;npm&lt;/code&gt;, etc.) - make sure you have the required tools installed on your machine.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;Once the implementation is complete, test the application and resolve any runtime errors that may not be visible in CLI logs (e.g., browser console errors). You can copy and paste such errors back to your AI agent for resolution.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîç Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Git Credential Manager on Linux&lt;/h3&gt; 
&lt;p&gt;If you're having issues with Git authentication on Linux, you can install Git Credential Manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;#!/usr/bin/env bash
set -e
echo "Downloading Git Credential Manager v2.6.1..."
wget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb
echo "Installing Git Credential Manager..."
sudo dpkg -i gcm-linux_amd64.2.6.1.deb
echo "Configuring Git to use GCM..."
git config --global credential.helper manager
echo "Cleaning up..."
rm gcm-linux_amd64.2.6.1.deb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Maintainers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Den Delimarsky (&lt;a href="https://github.com/localden"&gt;@localden&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;John Lam (&lt;a href="https://github.com/jflam"&gt;@jflam&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí¨ Support&lt;/h2&gt; 
&lt;p&gt;For support, please open a &lt;a href="https://github.com/github/spec-kit/issues/new"&gt;GitHub issue&lt;/a&gt;. We welcome bug reports, feature requests, and questions about using Spec-Driven Development.&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is heavily influenced by and based on the work and research of &lt;a href="https://github.com/jflam"&gt;John Lam&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the terms of the MIT open source license. Please refer to the &lt;a href="https://raw.githubusercontent.com/github/spec-kit/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for the full terms.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Asabeneh/30-Days-Of-Python</title>
      <link>https://github.com/Asabeneh/30-Days-Of-Python</link>
      <description>&lt;p&gt;The 30 Days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than 100 days. Follow your own pace. These videos may help too: https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üêç 30 Days Of Python&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;# Day&lt;/th&gt; 
   &lt;th align="center"&gt;Topics&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/readme.md"&gt;Introduction&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md"&gt;Variables, Built-in Functions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/03_Day_Operators/03_operators.md"&gt;Operators&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/04_Day_Strings/04_strings.md"&gt;Strings&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/05_Day_Lists/05_lists.md"&gt;Lists&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/06_Day_Tuples/06_tuples.md"&gt;Tuples&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/07_Day_Sets/07_sets.md"&gt;Sets&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/08_Day_Dictionaries/08_dictionaries.md"&gt;Dictionaries&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/09_Day_Conditionals/09_conditionals.md"&gt;Conditionals&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/10_Day_Loops/10_loops.md"&gt;Loops&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/11_Day_Functions/11_functions.md"&gt;Functions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/12_Day_Modules/12_modules.md"&gt;Modules&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/13_Day_List_comprehension/13_list_comprehension.md"&gt;List Comprehension&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/14_Day_Higher_order_functions/14_higher_order_functions.md"&gt;Higher Order Functions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/15_Day_Python_type_errors/15_python_type_errors.md"&gt;Python Type Errors&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/16_Day_Python_date_time/16_python_datetime.md"&gt;Python Date time&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/17_Day_Exception_handling/17_exception_handling.md"&gt;Exception Handling&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/18_Day_Regular_expressions/18_regular_expressions.md"&gt;Regular Expressions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/19_Day_File_handling/19_file_handling.md"&gt;File Handling&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/20_Day_Python_package_manager/20_python_package_manager.md"&gt;Python Package Manager&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/21_Day_Classes_and_objects/21_classes_and_objects.md"&gt;Classes and Objects&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/22_Day_Web_scraping/22_web_scraping.md"&gt;Web Scraping&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/23_Day_Virtual_environment/23_virtual_environment.md"&gt;Virtual Environment&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/24_Day_Statistics/24_statistics.md"&gt;Statistics&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/25_Day_Pandas/25_pandas.md"&gt;Pandas&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/26_Day_Python_web/26_python_web.md"&gt;Python web&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/27_Day_Python_with_mongodb/27_python_with_mongodb.md"&gt;Python with MongoDB&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/28_Day_API/28_API.md"&gt;API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/29_Day_Building_API/29_building_API.md"&gt;Building API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;30&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/30_Day_Conclusions/30_conclusions.md"&gt;Conclusions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;small&gt;üß°üß°üß° HAPPY CODING üß°üß°üß°&lt;/small&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div&gt; 
 &lt;h2&gt;üíñ Sponsors&lt;/h2&gt; 
 &lt;p&gt;Our amazing sponsors for supporting my open-source contribution and the &lt;strong&gt;30 Days of Challenge&lt;/strong&gt; series!&lt;/p&gt; 
 &lt;h3&gt;Current Sponsors&lt;/h3&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://ref.wisprflow.ai/MPMzRGE" target="_blank" rel="noopener noreferrer"&gt; 
   &lt;picture&gt; 
    &lt;!-- Dark mode --&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/Asabeneh/asabeneh/master/images/Wispr_Flow-Logo-white.png" /&gt; 
    &lt;!-- Light mode (fallback) --&gt; 
    &lt;img src="https://raw.githubusercontent.com/Asabeneh/asabeneh/master/images/Wispr_Flow-logo.png" width="400px" alt="Wispr Flow Logo" title="Wispr Flow" /&gt; 
   &lt;/picture&gt; &lt;/a&gt; 
  &lt;h1&gt; &lt;a href="https://ref.wisprflow.ai/MPMzRGE" target="_blank" rel="noopener noreferrer"&gt; Talk to code, stay in the Flow. &lt;/a&gt; &lt;/h1&gt; 
  &lt;h2&gt; &lt;a href="https://ref.wisprflow.ai/MPMzRGE" target="_blank" rel="noopener noreferrer"&gt; Flow is built for devs who live in their tools. Speak and give more context, get better results. &lt;/a&gt; &lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://client.petrosky.io/aff.php?aff=402" target="_blank" rel="noopener noreferrer"&gt; 
   &lt;picture&gt; 
    &lt;!-- Dark mode --&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/Asabeneh/asabeneh/master/images/petrosky-logo-white.png" /&gt; 
    &lt;!-- Light mode (fallback) --&gt; 
    &lt;img src="https://raw.githubusercontent.com/Asabeneh/asabeneh/master/images/petrosky-logo-black.png" width="400px" alt="Petrosky Logo" title="Petrosky" /&gt; 
   &lt;/picture&gt; &lt;/a&gt; 
  &lt;h1&gt; &lt;a href="https://client.petrosky.io/aff.php?aff=402" target="_blank" rel="noopener noreferrer"&gt; A hosting for your entire journey! &lt;/a&gt; &lt;/h1&gt; 
  &lt;h2&gt; &lt;a href="https://client.petrosky.io/aff.php?aff=402" target="_blank" rel="noopener noreferrer"&gt; Affordable VPS Hosting Services For All Your Needs &lt;/a&gt; &lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;üôå Become a Sponsor&lt;/h3&gt; 
 &lt;p&gt;You can support this project by becoming a sponsor on &lt;strong&gt;&lt;a href="https://github.com/sponsors/asabeneh"&gt;GitHub Sponsors&lt;/a&gt;&lt;/strong&gt; or through &lt;a href="https://www.paypal.me/asabeneh"&gt;PayPal&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;Every contribution, big or small, makes a huge difference. Thank you for your support! üåü&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h1&gt; 30 Days Of Python: Day 1 - Introduction&lt;/h1&gt; 
  &lt;a class="header-badge" target="_blank" href="https://www.linkedin.com/in/asabeneh/"&gt; &lt;img src="https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&amp;amp;logo=linkedin&amp;amp;style=social" /&gt; &lt;/a&gt; 
  &lt;a class="header-badge" target="_blank" href="https://twitter.com/Asabeneh"&gt; &lt;img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/asabeneh?style=social" /&gt; &lt;/a&gt; 
  &lt;p&gt;&lt;sub&gt;Author: &lt;a href="https://www.linkedin.com/in/asabeneh/" target="_blank"&gt;Asabeneh Yetayeh&lt;/a&gt;&lt;br /&gt; &lt;small&gt; Second Edition: July, 2021&lt;/small&gt; &lt;/sub&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;üáßüá∑ &lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/Portuguese/README.md"&gt;Portuguese&lt;/a&gt; üá®üá≥ &lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/Chinese/README.md"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md"&gt;Day 2 &amp;gt;&amp;gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/30DaysOfPython_banner3@2x.png" alt="30DaysOfPython" /&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-30-days-of-python"&gt;üêç 30 Days Of Python&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-become-a-sponsor"&gt;üôå Become a Sponsor&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-day-1"&gt;üìò Day 1&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#welcome"&gt;Welcome&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#why-python-"&gt;Why Python ?&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#environment-setup"&gt;Environment Setup&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#installing-python"&gt;Installing Python&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-shell"&gt;Python Shell&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#installing-visual-studio-code"&gt;Installing Visual Studio Code&lt;/a&gt; 
       &lt;ul&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#how-to-use-visual-studio-code"&gt;How to use visual studio code&lt;/a&gt;&lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#basic-python"&gt;Basic Python&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-syntax"&gt;Python Syntax&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-indentation"&gt;Python Indentation&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#comments"&gt;Comments&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#data-types"&gt;Data types&lt;/a&gt; 
       &lt;ul&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#number"&gt;Number&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#string"&gt;String&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#booleans"&gt;Booleans&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#list"&gt;List&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#dictionary"&gt;Dictionary&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#tuple"&gt;Tuple&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#set"&gt;Set&lt;/a&gt;&lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#checking-data-types"&gt;Checking Data types&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-file"&gt;Python File&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-exercises---day-1"&gt;üíª Exercises - Day 1&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-1"&gt;Exercise: Level 1&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-2"&gt;Exercise: Level 2&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-3"&gt;Exercise: Level 3&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h1&gt;üìò Day 1&lt;/h1&gt; 
 &lt;h2&gt;Welcome&lt;/h2&gt; 
 &lt;p&gt;&lt;strong&gt;Congratulations&lt;/strong&gt; for deciding to participate in a &lt;em&gt;30 days of Python&lt;/em&gt; programming challenge. In this challenge, you will learn everything you need to be a python programmer and the whole concept of programming. At the end of the challenge, you will get a &lt;em&gt;30DaysOfPython&lt;/em&gt; programming challenge certificate.&lt;/p&gt; 
 &lt;p&gt;If you would like to actively engage in the challenge, you may join the &lt;a href="https://t.me/ThirtyDaysOfPython"&gt;30DaysOfPython challenge&lt;/a&gt; telegram group.&lt;/p&gt; 
 &lt;h2&gt;Introduction&lt;/h2&gt; 
 &lt;p&gt;Python is a high-level programming language for general-purpose programming. It is an open source, interpreted, objected-oriented programming language. Python was created by a Dutch programmer, Guido van Rossum. The name of the Python programming language was derived from a British sketch comedy series, &lt;em&gt;Monty Python's Flying Circus&lt;/em&gt;. The first version was released on February 20, 1991. This 30 days of Python challenge will help you learn the latest version of Python, Python 3 step by step. The topics are broken down into 30 days, where each day contains several topics with easy-to-understand explanations, real-world examples, and many hands on exercises and projects.&lt;/p&gt; 
 &lt;p&gt;This challenge is designed for beginners and professionals who want to learn python programming language. It may take 30 to 100 days to complete the challenge. People who actively participate in the telegram group have a high probability of completing the challenge.&lt;/p&gt; 
 &lt;p&gt;This challenge is easy to read, written in conversational English, engaging, motivating and at the same time, it is very demanding. You need to allocate much time to finish this challenge. If you are a visual learner, you may get the video lesson on &lt;a href="https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw"&gt; Washera&lt;/a&gt; YouTube channel. You may start from &lt;a href="https://youtu.be/OCCWZheOesI"&gt;Python for Absolute Beginners video&lt;/a&gt;. Subscribe the channel, comment and ask questions on YouTube vidoes and be proactive, the author will eventually notice you.&lt;/p&gt; 
 &lt;p&gt;The author likes to hear your opinion about the challenge, share the author by expressing your thoughts about the 30DaysOfPython challenge. You can leave your testimonial on this &lt;a href="https://www.asabeneh.com/testimonials"&gt;link&lt;/a&gt;&lt;/p&gt; 
 &lt;h2&gt;Why Python ?&lt;/h2&gt; 
 &lt;p&gt;It is a programming language which is very close to human language and because of that, it is easy to learn and use. Python is used by various industries and companies (including Google). It has been used to develop web applications, desktop applications, system administration, and machine learning libraries. Python is a highly embraced language in the data science and machine learning community. I hope this is enough to convince you to start learning Python. Python is eating the world and you are killing it before it eats you.&lt;/p&gt; 
 &lt;h2&gt;Environment Setup&lt;/h2&gt; 
 &lt;h3&gt;Installing Python&lt;/h3&gt; 
 &lt;p&gt;To run a python script you need to install python. Let's &lt;a href="https://www.python.org/"&gt;download&lt;/a&gt; python. If your are a windows user. Click the button encircled in red.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/installing_on_windows.png" alt="installing on Windows" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;If you are a macOS user. Click the button encircled in red.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/installing_on_macOS.png" alt="installing on Windows" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;To check if python is installed write the following command on your device terminal.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;python --version
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/python_versio.png" alt="Python Version" /&gt;&lt;/p&gt; 
 &lt;p&gt;As you can see from the terminal, I am using &lt;em&gt;Python 3.7.5&lt;/em&gt; version at the moment. Your version of Python might be different from mine by but it should be 3.6 or above. If you mange to see the python version, well done. Python has been installed on your machine. Continue to the next section.&lt;/p&gt; 
 &lt;h3&gt;Python Shell&lt;/h3&gt; 
 &lt;p&gt;Python is an interpreted scripting language, so it does not need to be compiled. It means it executes the code line by line. Python comes with a &lt;em&gt;Python Shell (Python Interactive Shell)&lt;/em&gt;. It is used to execute a single python command and get the result.&lt;/p&gt; 
 &lt;p&gt;Python Shell waits for the Python code from the user. When you enter the code, it interprets the code and shows the result in the next line. Open your terminal or command prompt(cmd) and write:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;python
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_python_shell.png" alt="Python Scripting Shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;The Python interactive shell is opened and it is waiting for you to write Python code(Python script). You will write your Python script next to this symbol &amp;gt;&amp;gt;&amp;gt; and then click Enter. Let us write our very first script on the Python scripting shell.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/adding_on_python_shell.png" alt="Python script on Python shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;Well done, you wrote your first Python script on Python interactive shell. How do we close the Python interactive shell ? To close the shell, next to this symbol &amp;gt;&amp;gt; write &lt;strong&gt;exit()&lt;/strong&gt; command and press Enter.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/exit_from_shell.png" alt="Exit from python shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;Now, you know how to open the Python interactive shell and how to exit from it.&lt;/p&gt; 
 &lt;p&gt;Python will give you results if you write scripts that Python understands, if not it returns errors. Let's make a deliberate mistake and see what Python will return.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/invalid_syntax_error.png" alt="Invalid Syntax Error" /&gt;&lt;/p&gt; 
 &lt;p&gt;As you can see from the returned error, Python is so clever that it knows the mistake we made and which was &lt;em&gt;Syntax Error: invalid syntax&lt;/em&gt;. Using x as multiplication in Python is a syntax error because (x) is not a valid syntax in Python. Instead of (&lt;strong&gt;x&lt;/strong&gt;) we use asterisk (*) for multiplication. The returned error clearly shows what to fix.&lt;/p&gt; 
 &lt;p&gt;The process of identifying and removing errors from a program is called &lt;em&gt;debugging&lt;/em&gt;. Let us debug it by putting * in place of &lt;strong&gt;x&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/fixing_syntax_error.png" alt="Fixing Syntax Error" /&gt;&lt;/p&gt; 
 &lt;p&gt;Our bug was fixed, the code ran and we got a result we were expecting. As a programmer you will see such kind of errors on daily basis. It is good to know how to debug. To be good at debugging you should understand what kind of errors you are facing. Some of the Python errors you may encounter are &lt;em&gt;SyntaxError&lt;/em&gt;, &lt;em&gt;IndexError&lt;/em&gt;, &lt;em&gt;NameError&lt;/em&gt;, &lt;em&gt;ModuleNotFoundError&lt;/em&gt;, &lt;em&gt;KeyError&lt;/em&gt;, &lt;em&gt;ImportError&lt;/em&gt;, &lt;em&gt;AttributeError&lt;/em&gt;, &lt;em&gt;TypeError&lt;/em&gt;, &lt;em&gt;ValueError&lt;/em&gt;, &lt;em&gt;ZeroDivisionError&lt;/em&gt; etc. We will see more about different Python &lt;strong&gt;&lt;em&gt;error types&lt;/em&gt;&lt;/strong&gt; in later sections.&lt;/p&gt; 
 &lt;p&gt;Let us practice more how to use Python interactive shell. Go to your terminal or command prompt and write the word &lt;strong&gt;python&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_python_shell.png" alt="Python Scripting Shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;The Python interactive shell is opened. Let us do some basic mathematical operations (addition, subtraction, multiplication, division, modulus, exponential).&lt;/p&gt; 
 &lt;p&gt;Let us do some maths first before we write any Python code:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;2 + 3 is 5&lt;/li&gt; 
  &lt;li&gt;3 - 2 is 1&lt;/li&gt; 
  &lt;li&gt;3 * 2 is 6&lt;/li&gt; 
  &lt;li&gt;3 / 2 is 1.5&lt;/li&gt; 
  &lt;li&gt;3 ** 2 is the same as 3 * 3&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;In python we have the following additional operations:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;3 % 2 = 1 =&amp;gt; which means finding the remainder&lt;/li&gt; 
  &lt;li&gt;3 // 2 = 1 =&amp;gt; which means removing the remainder&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Let us change the above mathematical expressions to Python code. The Python shell has been opened and let us write a comment at the very beginning of the shell.&lt;/p&gt; 
 &lt;p&gt;A &lt;em&gt;comment&lt;/em&gt; is a part of the code which is not executed by python. So we can leave some text in our code to make our code more readable. Python does not run the comment part. A comment in python starts with hash(#) symbol. This is how you write a comment in python&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt; # comment starts with hash
 # this is a python comment, because it starts with a (#) symbol
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/maths_on_python_shell.png" alt="Maths on python shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;Before we move on to the next section, let us practice more on the Python interactive shell. Close the opened shell by writing &lt;em&gt;exit()&lt;/em&gt; on the shell and open it again and let us practice how to write text on the Python shell.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/writing_string_on_shell.png" alt="Writing String on python shell" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Installing Visual Studio Code&lt;/h3&gt; 
 &lt;p&gt;The Python interactive shell is good to try and test small script codes but it will not be for a big project. In real work environment, developers use different code editors to write codes. In this 30 days of Python programming challenge we will use visual studio code. Visual studio code is a very popular open source text editor. I am a fan of vscode and I would recommend to &lt;a href="https://code.visualstudio.com/"&gt;download&lt;/a&gt; visual studio code, but if you are in favor of other editors, feel free to follow with what you have.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://code.visualstudio.com/"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/vscode.png" alt="Visual Studio Code" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;If you installed visual studio code, let us see how to use it. If you prefer a video, you can follow this Visual Studio Code for Python &lt;a href="https://www.youtube.com/watch?v=bn7Cx4z-vSo"&gt;Video tutorial&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;How to use visual studio code&lt;/h4&gt; 
 &lt;p&gt;Open the visual studio code by double clicking the visual studio icon. When you open it you will get this kind of interface. Try to interact with the labeled icons.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/vscode_ui.png" alt="Visual studio Code" /&gt;&lt;/p&gt; 
 &lt;p&gt;Create a folder named 30DaysOfPython on your desktop. Then open it using visual studio code.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/how_to_open_project_on_vscode.png" alt="Opening Project on Visual studio" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_project.png" alt="Opening a project" /&gt;&lt;/p&gt; 
 &lt;p&gt;After opening it you will see shortcuts for creating files and folders inside of 30DaysOfPython project's directory. As you can see below, I have created the very first file, helloworld.py. You can do the same.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/helloworld.png" alt="Creating a python file" /&gt;&lt;/p&gt; 
 &lt;p&gt;After a long day of coding, you want to close your code editor, right? This is how you will close the opened project.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/closing_opened_project.png" alt="Closing project" /&gt;&lt;/p&gt; 
 &lt;p&gt;Congratulations, you have finished setting up the development environment. Let us start coding.&lt;/p&gt; 
 &lt;h2&gt;Basic Python&lt;/h2&gt; 
 &lt;h3&gt;Python Syntax&lt;/h3&gt; 
 &lt;p&gt;A Python script can be written in Python interactive shell or in the code editor. A Python file has an extension .py.&lt;/p&gt; 
 &lt;h3&gt;Python Indentation&lt;/h3&gt; 
 &lt;p&gt;An indentation is a white space in a text. Indentation in many languages is used to increase code readability; however, Python uses indentation to create blocks of code. In other programming languages, curly brackets are used to create code blocks instead of indentation. One of the common bugs when writing Python code is incorrect indentation.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/indentation.png" alt="Indentation Error" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Comments&lt;/h3&gt; 
 &lt;p&gt;Comments play a crucial role in enhancing code readability and allowing developers to leave notes within their code. In Python, any text preceded by a hash (#) symbol is considered a comment and is not executed when the code runs.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example: Single Line Comment&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;    # This is the first comment
    # This is the second comment
    # Python is eating the world
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Example: Multiline Comment&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Triple quote can be used for multiline comment if it is not assigned to a variable&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;"""This is multiline comment
multiline comment takes multiple lines.
python is eating the world
"""
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Data types&lt;/h3&gt; 
 &lt;p&gt;In Python there are several types of data types. Let us get started with the most common ones. Different data types will be covered in detail in other sections. For the time being, let us just go through the different data types and get familiar with them. You do not have to have a clear understanding now.&lt;/p&gt; 
 &lt;h4&gt;Number&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Integer: Integer(negative, zero and positive) numbers Example: ... -3, -2, -1, 0, 1, 2, 3 ...&lt;/li&gt; 
  &lt;li&gt;Float: Decimal number Example ... -3.5, -2.25, -1.0, 0.0, 1.1, 2.2, 3.5 ...&lt;/li&gt; 
  &lt;li&gt;Complex Example 1 + j, 2 + 4j&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;String&lt;/h4&gt; 
 &lt;p&gt;A collection of one or more characters under a single or double quote. If a string is more than one sentence then we use a triple quote.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;'Asabeneh'
'Finland'
'Python'
'I love teaching'
'I hope you are enjoying the first day of 30DaysOfPython Challenge'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Booleans&lt;/h4&gt; 
 &lt;p&gt;A boolean data type is either a True or False value. T and F should be always uppercase.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;    True  #  Is the light on? If it is on, then the value is True
    False # Is the light on? If it is off, then the value is False
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;List&lt;/h4&gt; 
 &lt;p&gt;Python list is an ordered collection which allows to store different data type items. A list is similar to an array in JavaScript.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;[0, 1, 2, 3, 4, 5]  # all are the same data types - a list of numbers
['Banana', 'Orange', 'Mango', 'Avocado'] # all the same data types - a list of strings (fruits)
['Finland','Estonia', 'Sweden','Norway'] # all the same data types - a list of strings (countries)
['Banana', 10, False, 9.81] # different data types in the list - string, integer, boolean and float
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Dictionary&lt;/h4&gt; 
 &lt;p&gt;A Python dictionary object is an unordered collection of data in a key value pair format.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;{
'first_name':'Asabeneh',
'last_name':'Yetayeh',
'country':'Finland', 
'age':250, 
'is_married':True,
'skills':['JS', 'React', 'Node', 'Python']
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Tuple&lt;/h4&gt; 
 &lt;p&gt;A tuple is an ordered collection of different data types like list but tuples can not be modified once they are created. They are immutable.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;('Asabeneh', 'Pawel', 'Brook', 'Abraham', 'Lidiya') # Names
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;('Earth', 'Jupiter', 'Neptune', 'Mars', 'Venus', 'Saturn', 'Uranus', 'Mercury') # planets
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Set&lt;/h4&gt; 
 &lt;p&gt;A set is a collection of data types similar to list and tuple. Unlike list and tuple, set is not an ordered collection of items. Like in Mathematics, set in Python stores only unique items.&lt;/p&gt; 
 &lt;p&gt;In later sections, we will go in detail about each and every Python data type.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;{2, 4, 3, 5}
{3.14, 9.81, 2.7} # order is not important in set
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Checking Data types&lt;/h3&gt; 
 &lt;p&gt;To check the data type of certain data/variable we use the &lt;strong&gt;type&lt;/strong&gt; function. In the following terminal you will see different python data types:&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/checking_data_types.png" alt="Checking Data types" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Python File&lt;/h3&gt; 
 &lt;p&gt;First open your project folder, 30DaysOfPython. If you don't have this folder, create a folder name called 30DaysOfPython. Inside this folder, create a file called helloworld.py. Now, let's do what we did on python interactive shell using visual studio code.&lt;/p&gt; 
 &lt;p&gt;The Python interactive shell was printing without using &lt;strong&gt;print&lt;/strong&gt; but on visual studio code to see our result we should use a built in function _print(). The &lt;em&gt;print()&lt;/em&gt; built-in function takes one or more arguments as follows &lt;em&gt;print('arument1', 'argument2', 'argument3')&lt;/em&gt;. See the examples below.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The file name is helloworld.py&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;# Day 1 - 30DaysOfPython Challenge

print(2 + 3)             # addition(+)
print(3 - 1)             # subtraction(-)
print(2 * 3)             # multiplication(*)
print(3 / 2)             # division(/)
print(3 ** 2)            # exponential(**)
print(3 % 2)             # modulus(%)
print(3 // 2)            # Floor division operator(//)

# Checking data types
print(type(10))          # Int
print(type(3.14))        # Float
print(type(1 + 3j))      # Complex number
print(type('Asabeneh'))  # String
print(type([1, 2, 3]))   # List
print(type({'name':'Asabeneh'})) # Dictionary
print(type({9.8, 3.14, 2.7}))    # Set
print(type((9.8, 3.14, 2.7)))    # Tuple
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To run the python file check the image below. You can run the python file either by running the green button on Visual Studio Code or by typing &lt;em&gt;python helloworld.py&lt;/em&gt; in the terminal .&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/running_python_script.png" alt="Running python script" /&gt;&lt;/p&gt; 
 &lt;p&gt;üåï You are amazing. You have just completed day 1 challenge and you are on your way to greatness. Now do some exercises for your brain and muscles.&lt;/p&gt; 
 &lt;h2&gt;üíª Exercises - Day 1&lt;/h2&gt; 
 &lt;h3&gt;Exercise: Level 1&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Check the python version you are using&lt;/li&gt; 
  &lt;li&gt;Open the python interactive shell and do the following operations. The operands are 3 and 4. 
   &lt;ul&gt; 
    &lt;li&gt;addition(+)&lt;/li&gt; 
    &lt;li&gt;subtraction(-)&lt;/li&gt; 
    &lt;li&gt;multiplication(*)&lt;/li&gt; 
    &lt;li&gt;modulus(%)&lt;/li&gt; 
    &lt;li&gt;division(/)&lt;/li&gt; 
    &lt;li&gt;exponential(**)&lt;/li&gt; 
    &lt;li&gt;floor division operator(//)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Write strings on the python interactive shell. The strings are the following: 
   &lt;ul&gt; 
    &lt;li&gt;Your name&lt;/li&gt; 
    &lt;li&gt;Your family name&lt;/li&gt; 
    &lt;li&gt;Your country&lt;/li&gt; 
    &lt;li&gt;I am enjoying 30 days of python&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Check the data types of the following data: 
   &lt;ul&gt; 
    &lt;li&gt;10&lt;/li&gt; 
    &lt;li&gt;9.8&lt;/li&gt; 
    &lt;li&gt;3.14&lt;/li&gt; 
    &lt;li&gt;4 - 4j&lt;/li&gt; 
    &lt;li&gt;['Asabeneh', 'Python', 'Finland']&lt;/li&gt; 
    &lt;li&gt;Your name&lt;/li&gt; 
    &lt;li&gt;Your family name&lt;/li&gt; 
    &lt;li&gt;Your country&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Exercise: Level 2&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Create a folder named day_1 inside 30DaysOfPython folder. Inside day_1 folder, create a python file helloworld.py and repeat questions 1, 2, 3 and 4. Remember to use &lt;em&gt;print()&lt;/em&gt; when you are working on a python file. Navigate to the directory where you have saved your file, and run it.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Exercise: Level 3&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Write an example for different Python data types such as Number(Integer, Float, Complex), String, Boolean, List, Tuple, Set and Dictionary.&lt;/li&gt; 
  &lt;li&gt;Find an &lt;a href="https://en.wikipedia.org/wiki/Euclidean_distance#:~:text=In%20mathematics%2C%20the%20Euclidean%20distance,being%20called%20the%20Pythagorean%20distance."&gt;Euclidian distance&lt;/a&gt; between (2, 3) and (10, 8)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;üéâ CONGRATULATIONS ! üéâ&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md"&gt;Day 2 &amp;gt;&amp;gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>