<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Thu, 21 Aug 2025 01:30:57 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>moeru-ai/airi</title>
      <link>https://github.com/moeru-ai/airi</link>
      <description>&lt;p&gt;üíñüß∏ Self hosted, you owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source width="100%" srcset="./docs/content/public/banner-dark-1280x640.avif" media="(prefers-color-scheme: dark)" /&gt; 
 &lt;source width="100%" srcset="./docs/content/public/banner-light-1280x640.avif" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)" /&gt; 
 &lt;img width="250" src="https://raw.githubusercontent.com/moeru-ai/airi/main/docs/content/public/banner-light-1280x640.avif" /&gt; 
&lt;/picture&gt; 
&lt;h1 align="center"&gt;Project AIRI&lt;/h1&gt; 
&lt;p align="center"&gt;Re-creating Neuro-sama, a container of souls of AI waifu / virtual characters to bring them into our worlds.&lt;/p&gt; 
&lt;p align="center"&gt; [&lt;a href="https://discord.gg/TgQ3Cu2F7A"&gt;Join Discord Server&lt;/a&gt;] [&lt;a href="https:///airi.moeru.ai"&gt;Try it&lt;/a&gt;] [&lt;a href="https://github.com/moeru-ai/airi/raw/main/docs/README.zh-CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;] [&lt;a href="https://github.com/moeru-ai/airi/raw/main/docs/README.ja-JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;] &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://deepwiki.com/moeru-ai/airi"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/moeru-ai/airi/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/moeru-ai/airi.svg?style=flat&amp;amp;colorA=080f12&amp;amp;colorB=1fa669" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/TgQ3Cu2F7A"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2FTgQ3Cu2F7A%3Fwith_counts%3Dtrue&amp;amp;query=%24.approximate_member_count&amp;amp;suffix=%20members&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;label=%20&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" /&gt;&lt;/a&gt; &lt;a href="https://x.com/proj_airi"&gt;&lt;img src="https://img.shields.io/badge/%40proj__airi-black?style=flat&amp;amp;logo=x&amp;amp;labelColor=%23101419&amp;amp;color=%232d2e30" /&gt;&lt;/a&gt; &lt;a href="https://t.me/+7M_ZKO3zUHFlOThh"&gt;&lt;img src="https://img.shields.io/badge/Telegram-%235AA9E6?logo=telegram&amp;amp;labelColor=FFFFFF" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.producthunt.com/products/airi?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-airi" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=993524&amp;amp;theme=neutral&amp;amp;t=1752696535380" alt="AIRI - A container of cyber living souls, re-creation of Neuro-sama | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;a href="https://trendshift.io/repositories/14636" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14636" alt="moeru-ai%2Fairi | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Heavily inspired by &lt;a href="https://www.youtube.com/@Neurosama"&gt;Neuro-sama&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;Attention:&lt;/strong&gt; We &lt;strong&gt;do not&lt;/strong&gt; have any officially minted cryptocurrency or token associated with this project. Please check the information and proceed with caution.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;We got a whole dedicated organization &lt;a href="https://github.com/proj-airi"&gt;@proj-airi&lt;/a&gt; for all the sub-project that born from Project AIRI, check it out!&lt;/p&gt; 
 &lt;p&gt;RAG, memory system, embedded database, icons, Live2D utilities, and more!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Have you dreamed about having a cyber living being (cyber waifu / husbando, digital pet), or digital companion that could play with and talk to you?&lt;/p&gt; 
&lt;p&gt;With the power of modern large language models like &lt;a href="https://chatgpt.com"&gt;ChatGPT&lt;/a&gt;, and famous &lt;a href="https://claude.ai"&gt;Claude&lt;/a&gt;, asking a virtual being able to have role playing and chat with us is already easy enough for everyone. Platforms like &lt;a href="https://character.ai"&gt;Character.ai (a.k.a. c.ai)&lt;/a&gt; and &lt;a href="https://janitorai.com/"&gt;JanitorAI&lt;/a&gt;, and local playgrounds like &lt;a href="https://github.com/SillyTavern/SillyTavern"&gt;SillyTavern&lt;/a&gt; is already a well-enough solution for chat based, or visual adventure game like experience.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;But, what about the abilities to play games? And see what you are coding at? Chatting while playing games, watching videos, and capable of doing many other things.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Perhaps you know &lt;a href="https://www.youtube.com/@Neurosama"&gt;Neuro-sama&lt;/a&gt; already, she is currently the best companion capable of playing games, chatting, and interacting with you and the participants (in VTuber community), some call this kind of being, "digital human" too. &lt;strong&gt;Sadly, it's not open sourced, you cannot interact with her after she went offline from live stream&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Therefore, this project, AIRI, offers another possibility here: &lt;strong&gt;let you own your digital life, cyber living, easily, anywhere, anytime&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;DevLogs we posted &amp;amp; Recent updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://airi.moeru.ai/docs/blog/DevLog-2025.07.18/"&gt;DevLog @ 2025.07.18&lt;/a&gt; on July 18, 2025&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://airi.moeru.ai/docs/blog/dreamlog-0x1/"&gt;DreamLog 0x1&lt;/a&gt; on June 16, 2025&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://airi.moeru.ai/docs/blog/DevLog-2025.06.08/"&gt;DevLog @ 2025.06.08&lt;/a&gt; on June 8, 2025&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://airi.moeru.ai/docs/blog/DevLog-2025.05.16/"&gt;DevLog @ 2025.05.16&lt;/a&gt; on May 16, 2025&lt;/li&gt; 
 &lt;li&gt;...more on &lt;a href="https://airi.moeru.ai/docs"&gt;documentation site&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What's so special for this project?&lt;/h2&gt; 
&lt;p&gt;Unlike the other AI driven VTuber open source projects, „Ç¢„Ç§„É™ VTuber was built with many support of Web technologies such as &lt;a href="https://www.w3.org/TR/webgpu/"&gt;WebGPU&lt;/a&gt;, &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API"&gt;WebAudio&lt;/a&gt;, &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers"&gt;Web Workers&lt;/a&gt;, &lt;a href="https://webassembly.org/"&gt;WebAssembly&lt;/a&gt;, &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/WebSocket"&gt;WebSocket&lt;/a&gt;, etc. from the first day.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Worry about the performance drop since we are using Web related technologies?&lt;/p&gt; 
 &lt;p&gt;Don't worry, while Web browser version meant to give a insight about how much we can push and do inside browsers, and webviews, we will never fully rely on this, the desktop version of AIRI is capable of using native &lt;a href="https://developer.nvidia.com/cuda-toolkit"&gt;NVIDIA CUDA&lt;/a&gt; and &lt;a href="https://developer.apple.com/metal/"&gt;Apple Metal&lt;/a&gt; by default (thanks to HuggingFace &amp;amp; beloved &lt;a href="https://github.com/huggingface/candle"&gt;candle&lt;/a&gt; project), without any complex dependency managements, considering the tradeoff, it was partially powered by Web technologies for graphics, layouts, animations, and the WIP plugin systems for everyone to integrate things.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This means that &lt;strong&gt;„Ç¢„Ç§„É™ VTuber is capable to run on modern browsers and devices&lt;/strong&gt;, and even on mobile devices (already done with PWA support), this brought a lot of possibilities for us (the developers) to build and extend the power of „Ç¢„Ç§„É™ VTuber to the next level, while still left the flexibilities for users to enable features that requires TCP connections or other non-Web technologies such as connect to voice channel to Discord, or playing Minecraft, Factorio with you and your friends.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;We are still in the early stage of development where we are seeking out talented developers to join us and help us to make „Ç¢„Ç§„É™ VTuber a reality.&lt;/p&gt; 
 &lt;p&gt;It's ok if you are not familiar with Vue.js, TypeScript, and devtools that required for this project, you can join us as an artist, designer, or even help us to launch our first live stream.&lt;/p&gt; 
 &lt;p&gt;Even you are a big fan of React or Svelte, even Solid, we welcome you, you can open a sub-directory to add features that you want to see in „Ç¢„Ç§„É™ VTuber, or would like to experiment with.&lt;/p&gt; 
 &lt;p&gt;Fields (and related projects) that we are looking for:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Live2D modeller&lt;/li&gt; 
  &lt;li&gt;VRM modeller&lt;/li&gt; 
  &lt;li&gt;VRChat avatar designer&lt;/li&gt; 
  &lt;li&gt;Computer Vision&lt;/li&gt; 
  &lt;li&gt;Reinforcement Learning&lt;/li&gt; 
  &lt;li&gt;Speech Recognition&lt;/li&gt; 
  &lt;li&gt;Speech Synthesis&lt;/li&gt; 
  &lt;li&gt;ONNX Runtime&lt;/li&gt; 
  &lt;li&gt;Transformers.js&lt;/li&gt; 
  &lt;li&gt;vLLM&lt;/li&gt; 
  &lt;li&gt;WebGPU&lt;/li&gt; 
  &lt;li&gt;Three.js&lt;/li&gt; 
  &lt;li&gt;WebXR (&lt;a href="https://github.com/moeru-ai/chat"&gt;checkout the another project&lt;/a&gt; we have under @moeru-ai organization)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;If you are interested in, why not introduce yourself here? &lt;a href="https://github.com/moeru-ai/airi/discussions/33"&gt;Would like to join part of us to build AIRI?&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Current progress&lt;/h2&gt; 
&lt;img src="https://raw.githubusercontent.com/moeru-ai/airi/main/docs/content/public/readme-image-pc-preview.avif" /&gt; 
&lt;p&gt;Capable of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Brain 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Play &lt;a href="https://www.minecraft.net"&gt;Minecraft&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Play &lt;a href="https://www.factorio.com"&gt;Factorio&lt;/a&gt; (WIP, but &lt;a href="https://github.com/moeru-ai/airi-factorio"&gt;PoC and demo available&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Chat in &lt;a href="https://telegram.org"&gt;Telegram&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Chat in &lt;a href="https://discord.com"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Memory 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Pure in-browser database support (DuckDB WASM | &lt;code&gt;pglite&lt;/code&gt;)&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Memory Alaya (WIP)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Pure in-browser local (WebGPU) inference&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Ears 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Audio input from browser&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Audio input from &lt;a href="https://discord.com"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Client side speech recognition&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Client side talking detection&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Mouth 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://elevenlabs.io/"&gt;ElevenLabs&lt;/a&gt; voice synthesis&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Body 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; VRM support 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Control VRM model&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; VRM model animations 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Auto blink&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Auto look at&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Idle eye movement&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Live2D support 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Control Live2D model&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Live2D model animations 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Auto blink&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Auto look at&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Idle eye movement&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For detailed instructions to develop this project, follow the &lt;a href="https://raw.githubusercontent.com/moeru-ai/airi/main/.github/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] By default, &lt;code&gt;pnpm dev&lt;/code&gt; will start the development server for the Stage Web (browser version), if you would like to try developing the desktop version, please make sure you read &lt;a href="https://raw.githubusercontent.com/moeru-ai/airi/main/.github/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; to setup the environment correctly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm i
pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Stage Web (Browser version for &lt;a href="https://airi.moeru.ai"&gt;airi.moeru.ai&lt;/a&gt;)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Stage Tamagotchi (Desktop version)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm dev:tamagotchi
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Documentation site&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm dev:docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Publish&lt;/h3&gt; 
&lt;p&gt;Please update the version in &lt;code&gt;Cargo.toml&lt;/code&gt; after running the &lt;code&gt;bumpp&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npx bumpp --no-commit --no-tag
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported the following LLM API Providers (powered by &lt;a href="https://github.com/moeru-ai/xsai"&gt;xsai&lt;/a&gt;)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://developers.generativeai.google"&gt;Google Gemini&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/guides/gpt/chat-completions-api"&gt;OpenAI&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/reference"&gt;Azure OpenAI API&lt;/a&gt; (PR welcome)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://anthropic.com"&gt;Anthropic Claude&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://docs.anthropic.com/en/api/claude-on-amazon-bedrock"&gt;AWS Claude&lt;/a&gt; (PR welcome)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.deepseek.com/"&gt;DeepSeek&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://help.aliyun.com/document_detail/2400395.html"&gt;Qwen&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://x.ai/"&gt;xAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://wow.groq.com/"&gt;Groq&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://mistral.ai/"&gt;Mistral&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://developers.cloudflare.com/workers-ai/"&gt;Cloudflare Workers AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.together.ai/"&gt;Together.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.together.ai/"&gt;Fireworks.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.novita.ai/"&gt;Novita&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://bigmodel.cn"&gt;Zhipu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://cloud.siliconflow.cn/i/rKXmRobW"&gt;SiliconFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.stepfun.com/"&gt;Stepfun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.baichuan-ai.com"&gt;Baichuan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://api.minimax.chat/"&gt;Minimax&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.moonshot.cn/"&gt;Moonshot AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://player2.game/"&gt;Player2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://cloud.tencent.com/document/product/1729"&gt;Tencent Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.xfyun.cn/doc/spark/Web.html"&gt;Sparks&lt;/a&gt; (PR welcome)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;amp;ac=DSASUQY5&amp;amp;rc=2QXCA1VI"&gt;Volcano Engine&lt;/a&gt; (PR welcome)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sub-projects born from this project&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/proj-airi/awesome-ai-vtuber"&gt;Awesome AI VTuber&lt;/a&gt;: A curated list of AI VTubers and related projects&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/unspeech"&gt;&lt;code&gt;unspeech&lt;/code&gt;&lt;/a&gt;: Universal endpoint proxy server for &lt;code&gt;/audio/transcriptions&lt;/code&gt; and &lt;code&gt;/audio/speech&lt;/code&gt;, like LiteLLM but for any ASR and TTS&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/hfup"&gt;&lt;code&gt;hfup&lt;/code&gt;&lt;/a&gt;: tools to help on deploying, bundling to HuggingFace Spaces&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/xsai-transformers"&gt;&lt;code&gt;xsai-transformers&lt;/code&gt;&lt;/a&gt;: Experimental &lt;a href="https://github.com/huggingface/transformers.js"&gt;ü§ó Transformers.js&lt;/a&gt; provider for &lt;a href="https://github.com/moeru-ai/xsai"&gt;xsAI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/proj-airi/webai-realtime-voice-chat"&gt;WebAI: Realtime Voice Chat&lt;/a&gt;: Full example of implementing ChatGPT's realtime voice from scratch with VAD + STT + LLM + TTS.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi/tree/main/packages/drizzle-duckdb-wasm/README.md"&gt;&lt;code&gt;@proj-airi/drizzle-duckdb-wasm&lt;/code&gt;&lt;/a&gt;: Drizzle ORM driver for DuckDB WASM&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi/tree/main/packages/duckdb-wasm/README.md"&gt;&lt;code&gt;@proj-airi/duckdb-wasm&lt;/code&gt;&lt;/a&gt;: Easy to use wrapper for &lt;code&gt;@duckdb/duckdb-wasm&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi/raw/main/crates/tauri-plugin-mcp/README.md"&gt;&lt;code&gt;tauri-plugin-mcp&lt;/code&gt;&lt;/a&gt;: A Tauri plugin for interacting with MCP servers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi-factorio"&gt;AIRI Factorio&lt;/a&gt;: Allow AIRI to play Factorio&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nekomeowww/factorio-rcon-api"&gt;Factorio RCON API&lt;/a&gt;: RESTful API wrapper for Factorio headless server console&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi-factorio/tree/main/packages/autorio"&gt;&lt;code&gt;autorio&lt;/code&gt;&lt;/a&gt;: Factorio automation library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi-factorio/tree/main/packages/tstl-plugin-reload-factorio-mod"&gt;&lt;code&gt;tstl-plugin-reload-factorio-mod&lt;/code&gt;&lt;/a&gt;: Reload Factorio mod when developing&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/luoling8192/velin"&gt;Velin&lt;/a&gt;: Use Vue SFC and Markdown to write easy to manage stateful prompts for LLM&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/demodel"&gt;&lt;code&gt;demodel&lt;/code&gt;&lt;/a&gt;: Easily boost the speed of pulling your models and datasets from various of inference runtimes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/inventory"&gt;&lt;code&gt;inventory&lt;/code&gt;&lt;/a&gt;: Centralized model catalog and default provider configurations backend service&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/mcp-launcher"&gt;MCP Launcher&lt;/a&gt;: Easy to use MCP builder &amp;amp; launcher for all possible MCP servers, just like Ollama for models!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/sad"&gt;ü•∫ SAD&lt;/a&gt;: Documentation and notes for self-host and browser running LLMs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;%%{ init: { 'flowchart': { 'curve': 'catmullRom' } } }%%

flowchart TD
  Core("Core")
  Unspeech("unspeech")
  DBDriver("@proj-airi/drizzle-duckdb-wasm")
  MemoryDriver("[WIP] Memory Alaya")
  DB1("@proj-airi/duckdb-wasm")
  SVRT("@proj-airi/server-runtime")
  Memory("Memory")
  STT("STT")
  Stage("Stage")
  StageUI("@proj-airi/stage-ui")
  UI("@proj-airi/ui")

  subgraph AIRI
    DB1 --&amp;gt; DBDriver --&amp;gt; MemoryDriver --&amp;gt; Memory --&amp;gt; Core
    UI --&amp;gt; StageUI --&amp;gt; Stage --&amp;gt; Core
    Core --&amp;gt; STT
    Core --&amp;gt; SVRT
  end

  subgraph UI_Components
    UI --&amp;gt; StageUI
    UITransitions("@proj-airi/ui-transitions") --&amp;gt; StageUI
    UILoadingScreens("@proj-airi/ui-loading-screens") --&amp;gt; StageUI
    FontCJK("@proj-airi/font-cjkfonts-allseto") --&amp;gt; StageUI
    FontXiaolai("@proj-airi/font-xiaolai") --&amp;gt; StageUI
  end

  subgraph Apps
    Stage --&amp;gt; StageWeb("@proj-airi/stage-web")
    Stage --&amp;gt; StageTamagotchi("@proj-airi/stage-tamagotchi")
    Core --&amp;gt; RealtimeAudio("@proj-airi/realtime-audio")
    Core --&amp;gt; PromptEngineering("@proj-airi/playground-prompt-engineering")
  end

  subgraph Server_Components
    Core --&amp;gt; ServerSDK("@proj-airi/server-sdk")
    ServerShared("@proj-airi/server-shared") --&amp;gt; SVRT
    ServerShared --&amp;gt; ServerSDK
  end

  STT --&amp;gt;|Speaking| Unspeech
  SVRT --&amp;gt;|Playing Factorio| F_AGENT
  SVRT --&amp;gt;|Playing Minecraft| MC_AGENT

  subgraph Factorio_Agent
    F_AGENT("Factorio Agent")
    F_API("Factorio RCON API")
    factorio-server("factorio-server")
    F_MOD1("autorio")

    F_AGENT --&amp;gt; F_API -.-&amp;gt; factorio-server
    F_MOD1 -.-&amp;gt; factorio-server
  end

  subgraph Minecraft_Agent
    MC_AGENT("Minecraft Agent")
    Mineflayer("Mineflayer")
    minecraft-server("minecraft-server")

    MC_AGENT --&amp;gt; Mineflayer -.-&amp;gt; minecraft-server
  end

  XSAI("xsAI") --&amp;gt; Core
  XSAI --&amp;gt; F_AGENT
  XSAI --&amp;gt; MC_AGENT

  Core --&amp;gt; TauriMCP("@proj-airi/tauri-plugin-mcp")
  Memory_PGVector("@proj-airi/memory-pgvector") --&amp;gt; Memory

  style Core fill:#f9d4d4,stroke:#333,stroke-width:1px
  style AIRI fill:#fcf7f7,stroke:#333,stroke-width:1px
  style UI fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Stage fill:#d4f9d4,stroke:#333,stroke-width:1px
  style UI_Components fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Server_Components fill:#d4e6f9,stroke:#333,stroke-width:1px
  style Apps fill:#d4d4f9,stroke:#333,stroke-width:1px
  style Factorio_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px
  style Minecraft_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px

  style DBDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style MemoryDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style DB1 fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory_PGVector fill:#f9f9d4,stroke:#333,stroke-width:1px
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Similar Projects&lt;/h2&gt; 
&lt;h3&gt;Open sourced ones&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kimjammer/Neuro"&gt;kimjammer/Neuro: A recreation of Neuro-Sama originally created in 7 days.&lt;/a&gt;: very well completed implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SugarcaneDefender/z-waif"&gt;SugarcaneDefender/z-waif&lt;/a&gt;: Great at gaming, autonomous, and prompt engineering&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/semperai/amica/"&gt;semperai/amica&lt;/a&gt;: Great at VRM, WebXR&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/elizaOS/eliza"&gt;elizaOS/eliza&lt;/a&gt;: Great examples and software engineering on how to integrate agent into various of systems and APIs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ardha27/AI-Waifu-Vtuber"&gt;ardha27/AI-Waifu-Vtuber&lt;/a&gt;: Great about Twitch API integrations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InsanityLabs/AIVTuber"&gt;InsanityLabs/AIVTuber&lt;/a&gt;: Nice UI and UX&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/IRedDragonICY/vixevia"&gt;IRedDragonICY/vixevia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/t41372/Open-LLM-VTuber"&gt;t41372/Open-LLM-VTuber&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PeterH0323/Streamer-Sales"&gt;PeterH0323/Streamer-Sales&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Non-open-sourced ones&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://clips.twitch.tv/WanderingCaringDeerDxCat-Qt55xtiGDSoNmDDr"&gt;https://clips.twitch.tv/WanderingCaringDeerDxCat-Qt55xtiGDSoNmDDr&lt;/a&gt; &lt;a href="https://www.youtube.com/watch?v=8Giv5mupJNE"&gt;https://www.youtube.com/watch?v=8Giv5mupJNE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://clips.twitch.tv/TriangularAthleticBunnySoonerLater-SXpBk1dFso21VcWD"&gt;https://clips.twitch.tv/TriangularAthleticBunnySoonerLater-SXpBk1dFso21VcWD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@NOWA_Mirai"&gt;https://www.youtube.com/@NOWA_Mirai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Project Status&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/a1d6fe2c13ea2bb53a5154435a71e2431f70c2ee.svg?sanitize=true" alt="Repobeats analytics image" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unovue/reka-ui"&gt;Reka UI&lt;/a&gt;: for designing the documentation site, new landing page is based on this, as well as implementing massive amount of UI components. (shadcn-vue is using Reka UI as the headless, do checkout!)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pixiv/ChatVRM"&gt;pixiv/ChatVRM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josephrocca/ChatVRM-js"&gt;josephrocca/ChatVRM-js: A JS conversion/adaptation of parts of the ChatVRM (TypeScript) code for standalone use in OpenCharacters and elsewhere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Design of UI and style was inspired by &lt;a href="https://store.steampowered.com/app/2919650/Cookard/"&gt;Cookard&lt;/a&gt;, &lt;a href="https://store.steampowered.com/app/2240620/UNBEATABLE/"&gt;UNBEATABLE&lt;/a&gt;, and &lt;a href="https://store.steampowered.com/app/2957700/_/"&gt;Sensei! I like you so much!&lt;/a&gt;, and artworks of &lt;a href="https://dribbble.com/shots/22157656-Ayame"&gt;Ayame by Mercedes Bazan&lt;/a&gt; with &lt;a href="https://dribbble.com/shots/24501019-Wish"&gt;Wish by Mercedes Bazan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mallorbc/whisper_mic"&gt;mallorbc/whisper_mic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/xsai"&gt;&lt;code&gt;xsai&lt;/code&gt;&lt;/a&gt;: Implemented a decent amount of packages to interact with LLMs and models, like &lt;a href="https://sdk.vercel.ai/"&gt;Vercel AI SDK&lt;/a&gt; but way small.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#moeru-ai/airi&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=moeru-ai/airi&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MotiaDev/motia</title>
      <link>https://github.com/MotiaDev/motia</link>
      <description>&lt;p&gt;Modern Backend Framework that unifies APIs, background jobs, workflows, and AI Agents into a single core primitive with built-in observability and state management.&lt;/p&gt;&lt;hr&gt;&lt;a href="https://motia.dev"&gt; &lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/github-readme-banner.png" alt="Motia Banner" width="100%" /&gt; &lt;/a&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14032" style="margin-right:8px;"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/14032" alt="Motia" style="width: 250px; height: 55px; margin-right:8px;" width="250" height="55" /&gt; &lt;/a&gt; &lt;a href="https://vercel.com/blog/summer-2025-oss-program#motia" target="_blank" style="margin-left:8px;"&gt; &lt;img alt="Vercel OSS Program" src="https://vercel.com/oss/program-badge.svg?sanitize=true" style="width: 250px; height: 55px; margin-left:8px;" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;üî• The Unified Backend Framework That Eliminates Runtime Fragmentation üî•&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt;APIs, background jobs, workflows, and AI agents in one system. JavaScript, TypeScript, Python, and more in one codebase.&lt;/em&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.npmjs.com/package/motia"&gt; &lt;img src="https://img.shields.io/npm/v/motia?style=flat&amp;amp;logo=npm&amp;amp;logoColor=white&amp;amp;color=CB3837&amp;amp;labelColor=000000" alt="npm version" /&gt; &lt;/a&gt; &lt;a href="https://github.com/MotiaDev/motia/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/license-MIT-green?style=flat&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white&amp;amp;labelColor=000000" alt="license" /&gt; &lt;/a&gt; &lt;a href="https://github.com/MotiaDev/motia"&gt; &lt;img src="https://img.shields.io/github/stars/MotiaDev/motia?style=flat&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;color=yellow&amp;amp;labelColor=000000" alt="GitHub stars" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/motiadev" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/Follow-@motiadev-1DA1F2?style=flat&amp;amp;logo=twitter&amp;amp;logoColor=white&amp;amp;labelColor=000000" alt="Twitter Follow" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/motia" target="_blank"&gt; &lt;img src="https://img.shields.io/discord/1322278831184281721?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;color=5865F2&amp;amp;label=Discord&amp;amp;labelColor=000000" alt="Discord" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.motia.dev/manifesto"&gt;üí° Motia Manifesto&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.motia.dev/docs/getting-started/quick-start"&gt;üöÄ Quick Start&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.motia.dev/docs/concepts/steps/defining-steps"&gt;üìã Defining Steps&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.motia.dev/docs"&gt;üìö Docs&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ What is Motia?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Motia solves backend fragmentation.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Modern software engineering is splintered ‚Äì APIs live in one framework, background jobs in another, queues have their own tooling, and AI agents are springing up in yet more isolated runtimes. &lt;strong&gt;This fragmentation demands a unified system.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Motia unifies APIs, background jobs, workflows, and AI agents into a &lt;strong&gt;single coherent system&lt;/strong&gt; with shared observability and developer experience. Similar to how React simplified frontend development where everything is a component, &lt;strong&gt;Motia simplifies backend development where everything is a Step&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Write &lt;strong&gt;JavaScript, TypeScript, Python, and more&lt;/strong&gt; in the same workflow. &lt;strong&gt;What used to take 5 frameworks to build now comes out of the box with Motia.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://motia.dev"&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/Motia_Github_Repository_GIF.gif" alt="Motia combines APIs, background queues, and AI agents into one system" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Quickstart&lt;/h2&gt; 
&lt;p&gt;Get Motia project up and running in &lt;strong&gt;under 60 seconds&lt;/strong&gt;:&lt;/p&gt; 
&lt;h3&gt;1. Bootstrap a New Motia Project&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx motia@latest create -i   # runs the interactive terminal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the prompts to pick a template, project name, and language. &lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/motia-terminal.gif" alt="motia-terminal" /&gt;&lt;/p&gt; 
&lt;h3&gt;2. Start the Workbench&lt;/h3&gt; 
&lt;p&gt;Inside your new project folder, launch the dev server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx motia dev # ‚ûú http://localhost:3000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; You have:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ REST APIs with validation&lt;/li&gt; 
 &lt;li&gt;‚úÖ Visual debugger &amp;amp; tracing&lt;/li&gt; 
 &lt;li&gt;‚úÖ Multi-language support&lt;/li&gt; 
 &lt;li&gt;‚úÖ Event-driven architecture&lt;/li&gt; 
 &lt;li&gt;‚úÖ Zero configuration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/new-workbench.png" alt="new-workbench" /&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìñ &lt;strong&gt;&lt;a href="https://motia.dev/docs/getting-started/quick-start"&gt;Full tutorial in our docs ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üéØ Step Types&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Trigger&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;api&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HTTP Request&lt;/td&gt; 
   &lt;td&gt;REST endpoints&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;event&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Topic subscription&lt;/td&gt; 
   &lt;td&gt;Background processing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;cron&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Schedule&lt;/td&gt; 
   &lt;td&gt;Recurring jobs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;noop&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Manual&lt;/td&gt; 
   &lt;td&gt;External processes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìñ &lt;strong&gt;&lt;a href="https://motia.dev/docs/concepts/steps"&gt;Learn more about Steps ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ Examples&lt;/h2&gt; 
&lt;h3&gt;üèÜ &lt;strong&gt;&lt;a href="https://chessarena.ai"&gt;ChessArena.ai&lt;/a&gt;&lt;/strong&gt; - Full-Featured Production App&lt;/h3&gt; 
&lt;p&gt;A complete chess platform benchmarking LLM performance with real-time evaluation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://chessarena.ai"&gt;Live Website ‚Üí&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/MotiaDev/chessarena-ai"&gt;Source Code ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://github.com/MotiaDev/chessarena-ai/raw/main/public/images/chessarena.gif?raw=true" alt="ChessArena.ai in action (raw GIF)" /&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Built from scratch to production deployment, featuring:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîê &lt;strong&gt;Authentication &amp;amp; user management&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Multi-agent LLM evaluation&lt;/strong&gt; (OpenAI, Claude, Gemini, Grok)&lt;/li&gt; 
 &lt;li&gt;üêç &lt;strong&gt;Python engine integration&lt;/strong&gt; (Stockfish chess evaluation)&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Real-time streaming&lt;/strong&gt; with live move updates and scoring&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;Modern React UI&lt;/strong&gt; with interactive chess boards&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Event-driven workflows&lt;/strong&gt; connecting TypeScript APIs to Python processors&lt;/li&gt; 
 &lt;li&gt;üìà &lt;strong&gt;Live leaderboards&lt;/strong&gt; with move-by-move quality scoring&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Production deployment&lt;/strong&gt; on Motia Cloud&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìö &lt;strong&gt;More Examples&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/MotiaDev/motia-examples"&gt;View all 20+ examples ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-deep-research-agent"&gt;AI Research Agent&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web research with iterative analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/streaming-ai-chatbot"&gt;Streaming Chatbot&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time AI responses&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/gmail-workflow"&gt;Gmail Automation&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart email processing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow"&gt;GitHub PR Manager&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Automated PR workflows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/finance-agent"&gt;Finance Agent&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time market analysis&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Features demonstrated:&lt;/strong&gt; Multi-language workflows ‚Ä¢ Real-time streaming ‚Ä¢ AI integration ‚Ä¢ Production deployment&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåê Language Support&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Stable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Stable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Stable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ruby&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üöß Beta&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Go&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üîÑ Soon&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üìö Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://motia.dev/docs"&gt;üìñ Documentation&lt;/a&gt;&lt;/strong&gt; - Complete guides and API reference&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://discord.gg/motia"&gt;üí¨ Discord&lt;/a&gt;&lt;/strong&gt; - Community support and discussions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/MotiaDev/motia/issues"&gt;üêõ GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Bug reports and feature requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/orgs/MotiaDev/projects/2"&gt;üó∫Ô∏è Roadmap&lt;/a&gt;&lt;/strong&gt; - Upcoming features and progress&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöß Roadmap&lt;/h2&gt; 
&lt;p&gt;We have a public roadmap for Motia, you can view it &lt;a href="https://github.com/orgs/MotiaDev/projects/2/views/4"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Feel free to add comments to the issues, or create a new issue if you have a feature request.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python Types&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/485"&gt;#485&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Python types&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Streams: RBAC&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/495"&gt;#495&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for RBAC&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Streams: Workbench UI&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/497"&gt;#497&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Workbench UI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Queue Strategies&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/476"&gt;#476&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Queue Strategies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Reactive Steps&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/477"&gt;#477&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Reactive Steps&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Point in time triggers&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/480"&gt;#480&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Point in time triggers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Workbench plugins&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/481"&gt;#481&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Workbench plugins&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Rewrite our Core in either Go or Rust&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/482"&gt;#482&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Rewrite our Core in either Go or Rust&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Decrease deployment time&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/483"&gt;#483&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Decrease deployment time&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Built-in database support&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/484"&gt;#484&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for built-in database&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Check our &lt;strong&gt;&lt;a href="https://github.com/MotiaDev/motia/raw/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;&lt;/strong&gt; to get started.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://motia.dev"&gt;üöÄ Get Started&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://motia.dev/docs"&gt;üìñ Docs&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://discord.gg/motia"&gt;üí¨ Discord&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#motiadev/motia&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=motiadev/motia&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;sub&gt;‚≠ê &lt;strong&gt;Star us if you find Motia useful!&lt;/strong&gt;&lt;/sub&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>puppeteer/puppeteer</title>
      <link>https://github.com/puppeteer/puppeteer</link>
      <description>&lt;p&gt;JavaScript API for Chrome and Firefox&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Puppeteer&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/puppeteer/puppeteer/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/puppeteer/puppeteer/actions/workflows/ci.yml/badge.svg?branch=main" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://npmjs.org/package/puppeteer"&gt;&lt;img src="https://img.shields.io/npm/v/puppeteer.svg?sanitize=true" alt="npm puppeteer package" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://user-images.githubusercontent.com/10379601/29446482-04f7036a-841f-11e7-9872-91d1fc2ea683.png" height="200" align="right" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Puppeteer is a JavaScript library which provides a high-level API to control Chrome or Firefox over the &lt;a href="https://chromedevtools.github.io/devtools-protocol/"&gt;DevTools Protocol&lt;/a&gt; or &lt;a href="https://pptr.dev/webdriver-bidi"&gt;WebDriver BiDi&lt;/a&gt;. Puppeteer runs in the headless (no visible UI) by default&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;a href="https://pptr.dev/docs"&gt;Get started&lt;/a&gt; | &lt;a href="https://pptr.dev/api"&gt;API&lt;/a&gt; | &lt;a href="https://pptr.dev/faq"&gt;FAQ&lt;/a&gt; | &lt;a href="https://pptr.dev/contributing"&gt;Contributing&lt;/a&gt; | &lt;a href="https://pptr.dev/troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm i puppeteer # Downloads compatible Chrome during installation.
npm i puppeteer-core # Alternatively, install as a library, without downloading Chrome.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import puppeteer from 'puppeteer';
// Or import puppeteer from 'puppeteer-core';

// Launch the browser and open a new blank page
const browser = await puppeteer.launch();
const page = await browser.newPage();

// Navigate the page to a URL.
await page.goto('https://developer.chrome.com/');

// Set screen size.
await page.setViewport({width: 1080, height: 1024});

// Type into search box using accessible input name.
await page.locator('aria/Search').fill('automate beyond recorder');

// Wait and click on first result.
await page.locator('.devsite-result-item-link').click();

// Locate the full title with a unique string.
const textSelector = await page
  .locator('text/Customize and automate')
  .waitHandle();
const fullTitle = await textSelector?.evaluate(el =&amp;gt; el.textContent);

// Print the full title.
console.log('The title of this blog post is "%s".', fullTitle);

await browser.close();
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>laude-institute/terminal-bench</title>
      <link>https://github.com/laude-institute/terminal-bench</link>
      <description>&lt;p&gt;A benchmark for LLMs on complicated tasks in the terminal&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;terminal-bench&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;#####################################################################
#  _____                   _             _     ______________       #
# |_   _|__ _ __ _ __ ___ (_)_ __   __ _| |   ||            ||      #
#   | |/ _ \ '__| '_ ` _ \| | '_ \ / _` | |   || &amp;gt;          ||      #
#   | |  __/ |  | | | | | | | | | | (_| | |   ||            ||      #
#   |_|\___|_|  |_| |_| |_|_|_| |_|\__,_|_|   ||____________||      #
#   ____                  _                   |______________|      #
#  | __ )  ___ _ __   ___| |__                 \\############\\     #
#  |  _ \ / _ \ '_ \ / __| '_ \                 \\############\\    # 
#  | |_) |  __/ | | | (__| | | |                 \      ____    \   #
#  |____/ \___|_| |_|\___|_| |_|                  \_____\___\____\  #
#                                                                   #
#####################################################################
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/6xWPKhGDbA"&gt;&lt;img src="https://img.shields.io/badge/Join_our_discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/laude-institute/terminal-bench"&gt;&lt;img src="https://img.shields.io/badge/T--Bench-000000?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=000&amp;amp;logoColor=white" alt="Github" /&gt;&lt;/a&gt; &lt;a href="https://www.tbench.ai/docs"&gt;&lt;img src="https://img.shields.io/badge/Docs-000000?style=for-the-badge&amp;amp;logo=mdbook&amp;amp;color=105864" alt="Docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Terminal-Bench is the benchmark for testing AI agents in real terminal environments. From compiling code to training models and setting up servers, Terminal-Bench evaluates how well agents can handle real-world, end-to-end tasks - autonomously.&lt;/p&gt; 
&lt;p&gt;Whether you're building LLM agents, benchmarking frameworks, or stress-testing system-level reasoning, Terminal-Bench gives you a reproducible task suite and execution harness designed for practical, real-world evaluation.&lt;/p&gt; 
&lt;p&gt;Terminal-Bench consists of two parts: a &lt;strong&gt;dataset of tasks&lt;/strong&gt;, and an &lt;strong&gt;execution harness&lt;/strong&gt; that connects a language model to our terminal sandbox.&lt;/p&gt; 
&lt;p&gt;Terminal-Bench is currently in &lt;strong&gt;beta&lt;/strong&gt; with ~100 tasks. Over the coming months, we are going to expand Terminal-Bench into comprehensive testbed for AI agents in text-based environments. Any contributions are welcome, especially new and challenging tasks!&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Our &lt;a href="https://www.tbench.ai/docs/installation"&gt;Quickstart Guide&lt;/a&gt; will walk you through installing the repo and contributing.&lt;/p&gt; 
&lt;p&gt;Terminal-Bench is distributed as a pip package and can be run using the Terminal-Bench CLI: &lt;code&gt;tb&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv tool install terminal-bench
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install terminal-bench
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Further Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.tbench.ai/tasks"&gt;Task Gallery&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tbench.ai/docs/task-ideas"&gt;Task Ideas&lt;/a&gt; - Browse community-sourced task ideas&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tbench.ai/docs/dashboard"&gt;Dashboard Documentation&lt;/a&gt; - Information about the Terminal-Bench dashboard&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Core Components&lt;/h2&gt; 
&lt;h3&gt;Dataset of Tasks&lt;/h3&gt; 
&lt;p&gt;Each task in Terminal-Bench includes&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a instruction in English,&lt;/li&gt; 
 &lt;li&gt;a test script to verify if the language model / agent completed the task successfully,&lt;/li&gt; 
 &lt;li&gt;a reference ("oracle") solution that solves the task.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Tasks are located in the &lt;a href="https://raw.githubusercontent.com/laude-institute/terminal-bench/main/tasks"&gt;&lt;code&gt;tasks&lt;/code&gt;&lt;/a&gt; folder of the repository, and the aforementioned list of current tasks gives an overview that is easy to browse.&lt;/p&gt; 
&lt;h3&gt;Execution Harness&lt;/h3&gt; 
&lt;p&gt;The harness connects language models to a sandboxed terminal environment. After &lt;a href="https://www.tbench.ai/docs/installation"&gt;installing the terminal-bench package&lt;/a&gt; (along with the dependencies &lt;code&gt;uv&lt;/code&gt; and &lt;code&gt;Docker&lt;/code&gt;) you can view how to run the harness using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;tb run --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed information about running the harness and its options, see the &lt;a href="https://www.tbench.ai/docs/first-steps"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Submit to Our Leaderboard&lt;/h3&gt; 
&lt;p&gt;Terminal-Bench-Core v0.1.1 is the set of tasks for Terminal-Bench's beta release and corresponds to the current leaderboard. To evaluate on it pass &lt;code&gt;--dataset-name terminal-bench-core&lt;/code&gt; and &lt;code&gt;--dataset-version 0.1.1&lt;/code&gt; to the harness. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;tb run \
    --agent terminus \
    --model-name anthropic/claude-3-7-latest \
    --dataset-name terminal-bench-core
    --dataset-version 0.1.1
    --n-concurrent 8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more detailed instructions on submitting to the leaderboard, view our &lt;a href="https://www.tbench.ai/docs/submitting-to-leaderboard"&gt;leaderboard submission guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more information on Terminal-Bench datasets and versioning view our &lt;a href="https://www.tbench.ai/docs/registry"&gt;registry overview&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Creating New Tasks&lt;/h2&gt; 
&lt;p&gt;View our &lt;a href="https://www.tbench.ai/docs/task-quickstart"&gt;task contribution quickstart&lt;/a&gt; to create a new task.&lt;/p&gt; 
&lt;h2&gt;Citing Us&lt;/h2&gt; 
&lt;p&gt;If you found Terminal-Bench useful, please cite us as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{tbench_2025,
      title={Terminal-Bench: A Benchmark for AI Agents in Terminal Environments}, 
      url={https://github.com/laude-institute/terminal-bench}, 
      author={The Terminal-Bench Team}, year={2025}, month={Apr}} 
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>bitwarden/clients</title>
      <link>https://github.com/bitwarden/clients</link>
      <description>&lt;p&gt;Bitwarden client apps (web, browser extension, desktop, and cli).&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/bitwarden/brand/main/screenshots/apps-combo-logo.png" alt="Bitwarden" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/bitwarden/clients/actions/workflows/build-browser.yml?query=branch:main" target="_blank"&gt;&lt;img src="https://github.com/bitwarden/clients/actions/workflows/build-browser.yml/badge.svg?branch=main" alt="GitHub Workflow browser build on main" /&gt;&lt;/a&gt; &lt;a href="https://github.com/bitwarden/clients/actions/workflows/build-cli.yml?query=branch:main" target="_blank"&gt;&lt;img src="https://github.com/bitwarden/clients/actions/workflows/build-cli.yml/badge.svg?branch=main" alt="GitHub Workflow CLI build on main" /&gt;&lt;/a&gt; &lt;a href="https://github.com/bitwarden/clients/actions/workflows/build-desktop.yml?query=branch:main" target="_blank"&gt;&lt;img src="https://github.com/bitwarden/clients/actions/workflows/build-desktop.yml/badge.svg?branch=main" alt="GitHub Workflow desktop build on main" /&gt;&lt;/a&gt; &lt;a href="https://github.com/bitwarden/clients/actions/workflows/build-web.yml?query=branch:main" target="_blank"&gt;&lt;img src="https://github.com/bitwarden/clients/actions/workflows/build-web.yml/badge.svg?branch=main" alt="GitHub Workflow web build on main" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/bitwarden/Lobby" target="_blank"&gt;&lt;img src="https://badges.gitter.im/bitwarden/Lobby.svg?sanitize=true" alt="gitter chat" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Bitwarden Client Applications&lt;/h1&gt; 
&lt;p&gt;This repository houses all Bitwarden client applications except the mobile applications (&lt;a href="https://github.com/bitwarden/ios"&gt;iOS&lt;/a&gt; | &lt;a href="https://github.com/bitwarden/android"&gt;android&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://contributing.bitwarden.com/getting-started/clients/"&gt;Clients section&lt;/a&gt; of the &lt;a href="https://contributing.bitwarden.com/"&gt;Contributing Documentation&lt;/a&gt; for build instructions, recommended tooling, code style tips, and lots of other great information to get you started.&lt;/p&gt; 
&lt;h2&gt;Related projects:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bitwarden/server"&gt;bitwarden/server&lt;/a&gt;: The core infrastructure backend (API, database, Docker, etc).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bitwarden/ios"&gt;bitwarden/ios&lt;/a&gt;: Bitwarden iOS Password Manager &amp;amp; Authenticator apps.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bitwarden/android"&gt;bitwarden/android&lt;/a&gt;: Bitwarden Android Password Manager &amp;amp; Authenticator apps.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bitwarden/directory-connector"&gt;bitwarden/directory-connector&lt;/a&gt;: A tool for syncing a directory (AD, LDAP, Azure, G Suite, Okta) to an organization.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;We're Hiring!&lt;/h1&gt; 
&lt;p&gt;Interested in contributing in a big way? Consider joining our team! We're hiring for many positions. Please take a look at our &lt;a href="https://bitwarden.com/careers/"&gt;Careers page&lt;/a&gt; to see what opportunities are &lt;a href="https://bitwarden.com/careers/#open-positions"&gt;currently open&lt;/a&gt; as well as what it's like to work at Bitwarden.&lt;/p&gt; 
&lt;h1&gt;Contribute&lt;/h1&gt; 
&lt;p&gt;Code contributions are welcome! Please commit any pull requests against the &lt;code&gt;main&lt;/code&gt; branch. Learn more about how to contribute by reading the &lt;a href="https://contributing.bitwarden.com/contributing/"&gt;Contributing Guidelines&lt;/a&gt;. Check out the &lt;a href="https://contributing.bitwarden.com/"&gt;Contributing Documentation&lt;/a&gt; for how to get started with your first contribution.&lt;/p&gt; 
&lt;p&gt;Security audits and feedback are welcome. Please open an issue or email us privately if the report is sensitive in nature. You can read our security policy in the &lt;a href="https://raw.githubusercontent.com/bitwarden/clients/main/SECURITY.md"&gt;&lt;code&gt;SECURITY.md&lt;/code&gt;&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ComposersDesktop/CDP8</title>
      <link>https://github.com/ComposersDesktop/CDP8</link>
      <description>&lt;p&gt;New version of CDP software&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CDP System Software, Release 8.&lt;/h1&gt; 
&lt;h3&gt;Full release as of 24 October 2023&lt;/h3&gt; 
&lt;h4&gt;Copyright (c) 2022 Composers Desktop Project&lt;/h4&gt; 
&lt;p&gt;&lt;img src="http://composersdesktop.com/logo.gif" alt="The CDP logo" /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;The CDP System is free software; you can redistribute them and/or modify them  
under the  terms of the GNU Lesser General Public License as published by   
the Free Software Foundation; either version 2.1 of the License,   
or (at your option) any later version.

The CDP System is distributed in the hope that it will be useful, but WITHOUT  
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
FITNESS FOR A PARTICULAR PURPOSE.  
See the GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License  
along with this software (see the top-level file COPYING); if not, write to  
the Free Software  Foundation, Inc., 51 Franklin St, Fifth Floor,  
Boston, MA 02110-1301 USA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;What's New?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;approximately 80 new programs/processes by Trevor Wishart. See details in the &lt;a href="https://raw.githubusercontent.com/ComposersDesktop/CDP8/main/docs"&gt;docs&lt;/a&gt; folder.&lt;/li&gt; 
 &lt;li&gt;majority already available for use in Soundloom 17.0.4.&lt;/li&gt; 
 &lt;li&gt;includes new programs for multichannel (&amp;lt;= 8 channels) production, waveset distortion, speech/voice processing.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;&lt;strong&gt;PVOCEX&lt;/strong&gt;&lt;/em&gt; (.pvx) analysis file support for all pvoc-related programs. This is the standard phase vocoder analysis file format used in Csound. See also the downloadable utilities (Mac, Win32), with example files, in the companion PVXTOOLS distribution:&lt;/li&gt; 
 &lt;li&gt;play program &lt;strong&gt;pvplay&lt;/strong&gt; will play mono/stereo .pvx files.&lt;/li&gt; 
 &lt;li&gt;classic CDP directory utility &lt;strong&gt;dirsf&lt;/strong&gt; now recognises .pvx files with format details.&lt;/li&gt; 
 &lt;li&gt;See also Tabula Vigilans (TV): some bugs fixed, full MIDI device I/O now working on Linux.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;What's needed?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Developers to get involved (whether CDP8 programs or TV), especially to add new software, create new user interfaces, create libraries, and so many other things we have not thought of. Join the new &lt;strong&gt;cdp-dev&lt;/strong&gt; mailing list (see &lt;em&gt;building.txt&lt;/em&gt; for details); get immediate news of any updates pushed to github.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;[updated 28/12/2023]&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Leantime/leantime</title>
      <link>https://github.com/Leantime/leantime</link>
      <description>&lt;p&gt;Leantime is a goals focused project management system for non-project managers. Building with ADHD, Autism, and dyslexia in mind.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://leantime.io"&gt;&lt;img src="https://leantime.io/wp-content/uploads/2023/03/leantime_logo.png" alt="Leantime Logo" width="300" /&gt;&lt;/a&gt; 
 &lt;h1&gt;Leantime¬Æ&lt;/h1&gt; 
 &lt;p&gt;‚≠ê If you find Leantime useful, please star us on GitHub! ‚≠ê&lt;/p&gt; 
 &lt;p&gt;Leantime is an open source project management system for non-project managers.&lt;br /&gt; We combine strategy, planning and execution while making it easy for everyone on the team to use.&lt;br /&gt; Built with ADHD, dyslexia and autism in mind. üß†&lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;üí™ As simple as Trello but as feature-rich as Jira&lt;br /&gt; üîÑ A perfect alternative to ClickUp, Monday, or Asana&lt;br /&gt; üåê &lt;a href="https://leantime.io"&gt;https://leantime.io&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/2264" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/2264" alt="A screenshot of Leantime's my work dashboard showing a few boxes with large metrics represnting todos complete, goals contributing to, scheduled todos. Also shows a day calendar with one task on it and a list of tasks grouped by Overdue, Due this week and Due Later" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.gnu.org/licenses/agpl-3.0.en.html"&gt;&lt;img src="https://img.shields.io/github/license/leantime/leantime?style=flat-square" alt="License Badge" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/leantime/leantime"&gt;&lt;img src="https://img.shields.io/docker/pulls/leantime/leantime?style=flat-square" alt="Docker Hub Badge" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/leantime/leantime/total" alt="Github Downloads" /&gt; &lt;a href="https://discord.gg/4zMzJtAq9z"&gt;&lt;img src="https://img.shields.io/discord/990001288026677318?label=Discord&amp;amp;style=flat-square" alt="Discord Badge" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/leantime"&gt;&lt;img src="https://badges.crowdin.net/leantime/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/sponsors/leantime" alt="GitHub Sponsors" /&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/mywork-v3.5.png" alt="alt text" title="Home Screen" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;h2&gt;üöÄ Features*&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Task Management&lt;/th&gt; 
   &lt;th&gt;Project Planning&lt;/th&gt; 
   &lt;th&gt;Information/Knowledge Management&lt;/th&gt; 
   &lt;th&gt;Administration&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task management via&lt;br /&gt;kanban boards, gantt, table, list and calendar views&lt;/td&gt; 
   &lt;td&gt;Project Dashboards, reports &amp;amp; status updates&lt;/td&gt; 
   &lt;td&gt;Wikis / Docs&lt;/td&gt; 
   &lt;td&gt;Easy installation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Unlimited subtasks and dependencies&lt;/td&gt; 
   &lt;td&gt;Goal &amp;amp; metrics tracking&lt;/td&gt; 
   &lt;td&gt;Idea Boards&lt;/td&gt; 
   &lt;td&gt;Multiple user roles and per project permissions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Milestone management&lt;/td&gt; 
   &lt;td&gt;Lean &amp;amp; Business Model Canvas&lt;/td&gt; 
   &lt;td&gt;Retrospectives&lt;/td&gt; 
   &lt;td&gt;Two factor authentication&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sprint Management&lt;/td&gt; 
   &lt;td&gt;SWOT Analysis canvas&lt;/td&gt; 
   &lt;td&gt;File Storage via S3 or local filesystem&lt;/td&gt; 
   &lt;td&gt;LDAP, OIDC integration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Timetracking &amp;amp; timesheets&lt;/td&gt; 
   &lt;td&gt;Risk Analysis&lt;/td&gt; 
   &lt;td&gt;Screen &amp;amp; webcam recording&lt;/td&gt; 
   &lt;td&gt;Extendable via plugins and API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;... and more&lt;/td&gt; 
   &lt;td&gt;Comments/discussions on everything&lt;/td&gt; 
   &lt;td&gt;Integrates with Slack, Mattermost, Discord&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;... and more&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Available in over 20 languages&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;*yes, all of these features are included in the OSS version&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üì∏ Screenshots&lt;/h3&gt; 
&lt;table width="100%"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%"&gt;&lt;img alt="Screenshot of Leantime's my work dashboard but with a dark color scheme. All colors are darkened or reverted" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/dark.png" title="My Work" /&gt;&lt;/td&gt; 
   &lt;td width="33%"&gt;&lt;img alt="Screenshot of Leantime's project dashboard showing a project checklist that has the first box checked, the latest tasks (1 right now), a progress donut chart at 0%" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/projectDashboard.png" title="Project Dashboard" /&gt;&lt;/td&gt; 
   &lt;td width="33%"&gt;&lt;img alt="Screenshot of Leantime's todo screen in table format. Tasks are grouped by status where each Status has a different color" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/table.png" title="Grouped To-Dos" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt="alt text" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/kanban.png" title="Kanban Board" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Screenshot of Leantime's timeline or gantt feature showing a timeline with various milestone boxes different in length representing how long these take. Each milestone has a different color and they are connected with an arrow" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/timeline.png" title="Tasks on timeline" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Screenshot of Leantime's personal calendar screen showing a month overview with a few tasks" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/calendar.png" title="Project Calendar" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt="alt text" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/goals.png" title="Goals" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Screenshot of Leantime's wiki page showing one template article of a product requirements document formatted with lists and tables" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/docs.png" title="Documents &amp;amp; Wikis" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Screenshot of Leantime's timesheet feature with a table a one week overview and input boxes for each day. Tasks are organized in rows" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/timesheet.png" title="Timesheets" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;‚ùóSystem Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;PHP 8.2+&lt;/li&gt; 
 &lt;li&gt;MySQL 8.0+ or MariaDB 10.6+&lt;/li&gt; 
 &lt;li&gt;Apache or Nginx (IIS works with some modifications)&lt;/li&gt; 
 &lt;li&gt;PHP Extensions:&lt;/li&gt; 
 &lt;li&gt;BC Math (bcmath)&lt;/li&gt; 
 &lt;li&gt;Ctype&lt;/li&gt; 
 &lt;li&gt;cURL&lt;/li&gt; 
 &lt;li&gt;DOM&lt;/li&gt; 
 &lt;li&gt;Exif&lt;/li&gt; 
 &lt;li&gt;Fileinfo&lt;/li&gt; 
 &lt;li&gt;Filter&lt;/li&gt; 
 &lt;li&gt;GD&lt;/li&gt; 
 &lt;li&gt;Hash&lt;/li&gt; 
 &lt;li&gt;LDAP&lt;/li&gt; 
 &lt;li&gt;Multibyte String (mbstring)&lt;/li&gt; 
 &lt;li&gt;MySQL&lt;/li&gt; 
 &lt;li&gt;OPcache&lt;/li&gt; 
 &lt;li&gt;OpenSSL&lt;/li&gt; 
 &lt;li&gt;PCNTL&lt;/li&gt; 
 &lt;li&gt;PCRE&lt;/li&gt; 
 &lt;li&gt;PDO&lt;/li&gt; 
 &lt;li&gt;Phar&lt;/li&gt; 
 &lt;li&gt;Session&lt;/li&gt; 
 &lt;li&gt;Tokenizer&lt;/li&gt; 
 &lt;li&gt;Zip&lt;/li&gt; 
 &lt;li&gt;SimpleXML &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Ctype PHP Extension cURL PHP Extension DOM PHP Extension Fileinfo PHP Extension Filter PHP Extension Hash PHP Extension Mbstring PHP Extension OpenSSL PHP Extension PCRE PHP Extension PDO PHP Extension Session PHP Extension Tokenizer PHP Extension XML PHP Extension&lt;/p&gt; 
&lt;h3&gt;Ô∏è‚ö°Ô∏è Installation (Production)&lt;/h3&gt; 
&lt;p&gt;There are two main ways to install LeanTime for production. The first of which is to install all needed pieces of the system locally. The second is to use the officially supported Docker image.&lt;/p&gt; 
&lt;h4&gt;Local Production Installation&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download latest release package (file is called: Leantime-vx.x.x.zip) from the &lt;a href="https://github.com/Leantime/leantime/releases"&gt;release page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Create an empty MySQL database&lt;/li&gt; 
 &lt;li&gt;Upload the entire directory to your server&lt;/li&gt; 
 &lt;li&gt;Point your domain root to the &lt;code&gt;public/&lt;/code&gt; directory&lt;/li&gt; 
 &lt;li&gt;Rename &lt;code&gt;config/.env.sample&lt;/code&gt; to &lt;code&gt;config/.env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Fill in your database credentials (username, password, host, dbname) in &lt;code&gt;config/.env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;&amp;lt;yourdomain.com&amp;gt;/install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Follow instructions to install database and set up first user account&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;IIS Installation Notes&lt;/h5&gt; 
&lt;p&gt;Whilst the steps above are applicable to Internet Information Services (IIS), there is an additional configuration change that may be required in IIS to ensure full functionality - you need to allow the PATCH method:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open IIS&lt;/li&gt; 
 &lt;li&gt;Expand the server and sites on the left and select the LeanTime site&lt;/li&gt; 
 &lt;li&gt;Double click on &lt;code&gt;Handler Mappings&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Double click on the PHP handler mapping that is used by the site&lt;/li&gt; 
 &lt;li&gt;Click &lt;code&gt;Request Restrictions‚Ä¶&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Click the &lt;code&gt;Verbs&lt;/code&gt; tab&lt;/li&gt; 
 &lt;li&gt;In the &lt;code&gt;One of the following verbs&lt;/code&gt; text box, add &lt;code&gt;PATCH&lt;/code&gt; - for example: &lt;code&gt;GET,HEAD,POST,PATCH&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;In the &lt;code&gt;Executable (optional)&lt;/code&gt; text box, put a double quote character (&lt;code&gt;‚Äú&lt;/code&gt;) at the start and at the end of the path to the &lt;code&gt;php-cgi.exe&lt;/code&gt; file (&lt;em&gt;this isn't needed if the path doesn't have a space in it&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;Click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;A popup will appear asking if you want to create a FastCGI application - click &lt;code&gt;Yes&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: You may need to repeat this when you upgrade PHP.&lt;/p&gt; 
&lt;h4&gt;Production Installation via Docker&lt;/h4&gt; 
&lt;p&gt;We maintain an official &lt;a href="https://hub.docker.com/r/leantime/leantime"&gt;Docker image on dockerhub&lt;/a&gt;. To run the image enter your MySQL credentials and execute. You can pass in all the configuration variables from .env&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -d --restart unless-stopped -p 8080:8080 --network leantime-net \
-e LEAN_DB_HOST=mysql_leantime \
-e LEAN_DB_USER=admin \
-e LEAN_DB_PASSWORD=321.qwerty \
-e LEAN_DB_DATABASE=leantime \
-e LEAN_EMAIL_RETURN=changeme@local.local \
--name leantime leantime/leantime:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless you have a database defined somewhere else you should use our &lt;a href="https://github.com/Leantime/docker-leantime/raw/master/docker-compose.yml"&gt;docker-compose file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Once started you can go to &lt;code&gt;&amp;lt;yourdomain.com&amp;gt;/install&lt;/code&gt; and run the installation script.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important: If you are planning to use plugins you need to mount the plugin folder &lt;code&gt;plugins:/var/www/html/app/Plugins&lt;/code&gt; and ensure the www-data user has access to it. Otherwise installation may fail or plugins will be removed after a restart&lt;/strong&gt;&lt;/p&gt; 
&lt;h5&gt;Docker Installation Notes&lt;/h5&gt; 
&lt;p&gt;If you intend to place Leantime behind a reverse proxy (nginx, etc.) to handle custom domain name resolution and SSL offloading, you will need to set the following environment variable in docker&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-e LEAN_APP_URL=https://yourdomain.com \
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Update yourdomain.com to your custom domain name. &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ü§ì Installation (Development)&lt;/h3&gt; 
&lt;p&gt;There are two ways to install a development setup of LeanTime. The first (but most technical) is to install all pieces of the system locally. The second (and preferred method) is to use a docker containerized development environment.&lt;/p&gt; 
&lt;h4&gt;Local Development Installation&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Clone repository to your local server&lt;/li&gt; 
 &lt;li&gt;Create MySQL database&lt;/li&gt; 
 &lt;li&gt;Run webpack builder via &lt;code&gt;make build-dev&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Point your local domain to the &lt;code&gt;public/&lt;/code&gt; directory&lt;/li&gt; 
 &lt;li&gt;Rename &lt;code&gt;config/.env.sample&lt;/code&gt; to &lt;code&gt;config/.env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Fill in your database credentials (username, password, host, dbname) in &lt;code&gt;config/.env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;&amp;lt;localdomain&amp;gt;/install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Follow instructions to install database and user account&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Development Installation via Docker&lt;/h4&gt; 
&lt;p&gt;For development, we use a dockerized development environment. You will need to have &lt;code&gt;docker&lt;/code&gt;, &lt;code&gt;docker compose&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt;, &lt;code&gt;composer&lt;/code&gt;, &lt;code&gt;git&lt;/code&gt; and &lt;code&gt;npm&lt;/code&gt; installed.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Notes for Windows Environments: 
  &lt;ul&gt; 
   &lt;li&gt;Run all commands within the git bash terminal in order to utilize unix specific commands&lt;/li&gt; 
   &lt;li&gt;If installing php from a zip file, make sure to configure php.ini It does not exist initially, so copy C:\php\php.ini-development to C:\php\php.ini. You will also need to edit php.ini in a text editor and enable all needed extensions for the build process. You can find these by running the make commands and looking for any extensions that error out as missing. You can enable them by searching php.ini for the extension that will look like: &lt;code&gt;;extension=gd&lt;/code&gt; and removing the semicolon.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In order to build the development docker image, in the root of this repository, run a primer with&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;make clean build&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;afterwards, run&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;make run-dev&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;this will start the development server on port 8090.&lt;/p&gt; 
&lt;p&gt;The dev environment provides a MySQL server, mail server, s3 server, and should be good to go for your needs out of the box. The configuration of the development environment is found in &lt;code&gt;.dev/.env&lt;/code&gt;, and is already seeded with the appropriate values. &lt;strong&gt;You should probably not be modifying this unless you plan to work on a feature for a specific integration&lt;/strong&gt;. the applications you get are as follows&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8090"&gt;http://localhost:8090&lt;/a&gt; : leantime&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8081"&gt;http://localhost:8081&lt;/a&gt; : maildev - to check emails sent&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8082"&gt;http://localhost:8082&lt;/a&gt; : phpMyAdmin(authentication &lt;code&gt;leantime:leantime&lt;/code&gt;) to check the DB schema and data&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8083"&gt;http://localhost:8083&lt;/a&gt; : s3ninja - to check s3 uploads. You need to enable this in the &lt;code&gt;.dev/.env&lt;/code&gt; file by enabling s3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, Xdebug is enabled, but you will have to modify your IDE key in the &lt;code&gt;.dev/xdebug.ini&lt;/code&gt; file(or alternatively, on your IDE). You also need to have port 9003 temporarily open on your firewall so you can utilize it effectively. This is because connections from docker to the host will count as external inbound connections &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Run Tests&lt;/h3&gt; 
&lt;p&gt;Static Analysis &lt;code&gt;make phpstan&lt;/code&gt;&lt;br /&gt; Code Style &lt;code&gt;make test-code-style&lt;/code&gt; (to fix code style automatically use &lt;code&gt;make fix-code-style&lt;/code&gt;)&lt;br /&gt; Unit Tests &lt;code&gt;make unit-test&lt;/code&gt;&lt;br /&gt; Acceptance Tests &lt;code&gt;make acceptance-test&lt;/code&gt;&lt;br /&gt; (requires docker)&lt;/p&gt; 
&lt;p&gt;You can test individual acceptance test groups directly using:&lt;br /&gt; For api: &lt;br /&gt; &lt;code&gt;docker compose --file .dev/docker-compose.yaml --file .dev/docker-compose.tests.yaml exec leantime-dev php vendor/bin/codecept run -g api --steps&lt;/code&gt;&lt;br /&gt; For timesheets: &lt;br /&gt; &lt;code&gt;docker compose --file .dev/docker-compose.yaml --file .dev/docker-compose.tests.yaml exec leantime-dev php vendor/bin/codecept run -g timesheet --steps&lt;/code&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;üèó Update&lt;/h3&gt; 
&lt;h4&gt;Manual&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Make sure to take a backup of your database and files&lt;/li&gt; 
 &lt;li&gt;Replace all files in your directory with the updated version&lt;/li&gt; 
 &lt;li&gt;If there were any database changes, the system will redirect you to &lt;code&gt;&amp;lt;yourdomain.com&amp;gt;/update&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;CLI&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run &lt;code&gt;php bin/leantime system:update&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Before updating, make sure your mysql container was started using a mounted volume, otherwise your content will be deleted&lt;/li&gt; 
 &lt;li&gt;Delete/Stop existing container&lt;/li&gt; 
 &lt;li&gt;Pull the latest docker image and rebuild using your compose file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Common Issues&lt;/h3&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://docs.leantime.io/installation/common-issues"&gt;documentation&lt;/a&gt; about common issues found when installing or updating Leantime&lt;/p&gt; 
&lt;h2&gt;üîå Extend Leantime&lt;/h2&gt; 
&lt;p&gt;You can extend Leantime by&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;building your own plugin: &lt;a href="https://docs.leantime.io/development/plugin-development"&gt;Plugin Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;using our json-rpc API: &lt;a href="https://docs.leantime.io/api/usage"&gt;API Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or by purchasing a plugin from our &lt;a href="https://marketplace.leantime.io"&gt;marketplace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõü Let us install it for you.&lt;/h2&gt; 
&lt;p&gt;Hassle free installation service in your environments. We can do full installations, updates, configurations or plugin installations. See our &lt;a href="https://marketplace.leantime.io/product-category/services/technical/"&gt;Marketplace&lt;/a&gt; for details.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;‚òÅÔ∏è Not interested in hosting yourself? Let us do it for you&lt;/h2&gt; 
&lt;p&gt;We offer &lt;a href="https://leantime.io/managed-hosting/"&gt;managed hosting plans&lt;/a&gt; as well as a &lt;a href="https://leantime.io/pricing/"&gt;SaaS product&lt;/a&gt; so you can get all the benefits of Leantime without the hassle. Head to &lt;a href="https://leantime.io/"&gt;leantime.io&lt;/a&gt; for more information. &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ô Need technical support?&lt;/h2&gt; 
&lt;p&gt;We can help you set up Leantime in your environment and customize it to your needs. Our support plans are &lt;a href="https://leantime.io/priority-support/"&gt;outlined on our website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please note: We currently only support the official Leantime docker compose and standard installations. We only offer support for the most recent version.&lt;/p&gt; 
&lt;p&gt;We do not offer support for Cloudron, Elestio, Turnkey, or other external distribution platforms sharing unofficial versions of Leantime.&lt;/p&gt; 
&lt;h2&gt;ü´¥ Contributing&lt;/h2&gt; 
&lt;p&gt;We're excited you are interested in contributing to Leantime. We want to make sure you have a great experience contributing to Leantime and that the new features you build will make it into core. &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;ü™≤ Bugs&lt;/h3&gt; 
&lt;p&gt;Find an issue on Github (or create a new one) add your name to it or comment that you will be working on it. Once fixed, create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;New Features in Core&lt;/h3&gt; 
&lt;p&gt;If you have an idea about new features please reach out to us on Discord. This is where we coordinate feature development and discuss whether core is the right place to add your new features (Plugins is the alternative).&lt;/p&gt; 
&lt;h3&gt;üåè Translations&lt;/h3&gt; 
&lt;p&gt;Language files and translations are stored in &lt;code&gt;app/Language/* &lt;/code&gt;. Once updates please create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üë• Community Support&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Documentation &lt;a href="https://docs.leantime.io"&gt;https://docs.leantime.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community Chat &lt;a href="https://discord.gg/4zMzJtAq9z"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;File a bug report &lt;a href="https://github.com/Leantime/leantime/issues/new"&gt;https://github.com/Leantime/leantime/issues/new&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Translations &lt;a href="https://crowdin.com/project/leantime"&gt;https://crowdin.com/project/leantime&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚öñÔ∏è LICENSE Exceptions&lt;/h2&gt; 
&lt;p&gt;Leantime is licensed under AGPLv3. This file forms part of the Leantime Software for which the following exception is added: Plugins within the &lt;code&gt;/app/Plugins&lt;/code&gt; directory which may contain plugins licensed under other licenses including our enterprise license.&lt;/p&gt; 
&lt;img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=856e290f-a6e9-4fbd-9b95-a835e39a0492" /&gt;</description>
    </item>
    
    <item>
      <title>DataExpert-io/data-engineer-handbook</title>
      <link>https://github.com/DataExpert-io/data-engineer-handbook</link>
      <description>&lt;p&gt;This is a repo with links to everything you'd ever want to learn about data engineering&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Data Engineering Handbook&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/8755" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/8755" alt="DataExpert-io%2Fdata-engineer-handbook | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repo has all the resources you need to become an amazing data engineer!&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;If you are new to data engineering, start by following this &lt;a href="https://blog.dataengineer.io/p/the-2024-breaking-into-data-engineering"&gt;2024 breaking into data engineering roadmap&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you are here for the &lt;a href="https://learn.dataexpert.io/program/the-absolute-beginner-data-engineering-boot-camp-starting-august-7th-6453/details"&gt;4-week free beginner boot camp&lt;/a&gt; you can check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/beginner-bootcamp/introduction.md"&gt;introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/beginner-bootcamp/software.md"&gt;software needed&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are here for the &lt;a href="https://learn.dataexpert.io/program/free-community-boot-camp/details"&gt;6-week free intermediate boot camp&lt;/a&gt; you can check out&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/intermediate-bootcamp/introduction.md"&gt;introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/intermediate-bootcamp/software.md"&gt;software needed&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more applied learning:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/projects.md"&gt;projects&lt;/a&gt; section for more hands-on examples!&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/interviews.md"&gt;interviews&lt;/a&gt; section for more advice on how to pass data engineering interviews!&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/books.md"&gt;books&lt;/a&gt; section for a list of high quality data engineering books&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/communities.md"&gt;communities&lt;/a&gt; section for a list of high quality data engineering communities to join&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/newsletters.md"&gt;newsletter&lt;/a&gt; section to learn via email&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;h3&gt;Great &lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/books.md"&gt;list of over 25 books&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Top 3 must read books are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302/"&gt;Fundamentals of Data Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321/"&gt;Designing Data-Intensive Applications&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969"&gt;Designing Machine Learning Systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Great &lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/communities.md"&gt;list of over 10 communities to join&lt;/a&gt;:&lt;/h3&gt; 
&lt;p&gt;Top must-join communities for DE:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/JGumAXncAK"&gt;DataExpert.io Community Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://datatalks.club/slack"&gt;Data Talks Club Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.dataengineerthings.org/"&gt;Data Engineer Things Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Top must-join communities for ML:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.com/invite/ezzszrRZvT"&gt;AdalFlow Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/dzh728c5t3"&gt;Chip Huyen MLOps Discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Companies:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Orchestration 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.mage.ai"&gt;Mage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.astronomer.io"&gt;Astronomer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.prefect.io"&gt;Prefect&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.dagster.io"&gt;Dagster&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://airflow.apache.org/"&gt;Airflow&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://kestra.io/"&gt;Kestra&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.shipyardapp.com/"&gt;Shipyard&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/dagworks-inc/hamilton"&gt;Hamilton&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Data Lake / Cloud 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.tabular.io"&gt;Tabular&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.microsoft.com"&gt;Microsoft&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.databricks.com/company/about-us"&gt;Databricks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.onehouse.ai"&gt;Onehouse&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://delta.io/"&gt;Delta Lake&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ilum.cloud/"&gt;Ilum&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ducklake.select/"&gt;DuckLake&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://iceberg.apache.org/"&gt;Apache Iceberg&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://polaris.apache.org/"&gt;Apache Polaris&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://lakekeeper.io/"&gt;Lakekeeper&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Data Warehouse 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.snowflake.com/en/"&gt;Snowflake&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.firebolt.io/"&gt;Firebolt&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.databend.com/"&gt;Databend&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Data Quality 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.getdbt.com/"&gt;dbt&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.metaplane.dev/"&gt;Metaplane&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.gable.ai"&gt;Gable&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.greatexpectations.io"&gt;Great Expectations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://streamdal.com"&gt;Streamdal&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://coalesce.io/"&gt;Coalesce&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.soda.io/"&gt;Soda&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://dqops.com/"&gt;DQOps&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://hedda.io"&gt;HEDDA.IO&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/MigoXLab/dingo"&gt;Dingo&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Education Companies 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.dataexpert.io"&gt;DataExpert.io&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.learndataengineering.com"&gt;LearnDataEngineering.com&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.algoexpert.io"&gt;AlgoExpert&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.bytebytego.com"&gt;ByteByteGo&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Analytics / Visualization 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.preset.io"&gt;Preset&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.starburst.io"&gt;Starburst&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.metabase.com/"&gt;Metabase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://lookerstudio.google.com/overview"&gt;Looker Studio&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.tableau.com/"&gt;Tableau&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://powerbi.microsoft.com/"&gt;Power BI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://hex.ai/"&gt;Hex&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://superset.apache.org/"&gt;Apache Superset&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://evidence.dev"&gt;Evidence&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://redash.io/"&gt;Redash&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://lightdash.com/"&gt;Lightdash&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Data Integration 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://cube.dev"&gt;Cube&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.fivetran.com"&gt;Fivetran&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://airbyte.io"&gt;Airbyte&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://dlthub.com/"&gt;dlt&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://slingdata.io/"&gt;Sling&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://meltano.com/"&gt;Meltano&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://estuary.dev/"&gt;Estuary&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Semantic Layers 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://cube.dev"&gt;Cube&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.getdbt.com/product/semantic-layer"&gt;dbt Semantic Layer&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Modern OLAP 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://druid.apache.org/"&gt;Apache Druid&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://clickhouse.com/"&gt;ClickHouse&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pinot.apache.org/"&gt;Apache Pinot&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://kylin.apache.org/"&gt;Apache Kylin&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://duckdb.org/"&gt;DuckDB&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://questdb.io/"&gt;QuestDB&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.starrocks.io/"&gt;StarRocks&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;LLM application library 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/SylphAI-Inc/AdalFlow"&gt;AdalFlow&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/langchain-ai/langchain"&gt;LangChain&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/run-llama/llama_index"&gt;LlamaIndex&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Real-Time Data 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://aggregations.io"&gt;Aggregations.io&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.responsive.dev/"&gt;Responsive&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://risingwave.com/"&gt;RisingWave&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.striim.com/"&gt;Striim&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Data Lineage 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://openlineage.io/"&gt;OpenLineage&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Data Engineering blogs of companies:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://netflixtechblog.com/tagged/big-data"&gt;Netflix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.uber.com/blog/houston/data/?uclick_id=b2f43229-f3f4-4bae-bd5d-10a05db2f70c"&gt;Uber&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.databricks.com/blog/category/engineering/data-engineering"&gt;Databricks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/airbnb-engineering/data/home"&gt;Airbnb&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/blogs/big-data/"&gt;Amazon AWS Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://techcommunity.microsoft.com/t5/data-architecture-blog/bg-p/DataArchitectureBlog"&gt;Microsoft Data Architecture Blogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.fabric.microsoft.com/"&gt;Microsoft Fabric Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.oracle.com/datawarehousing/"&gt;Oracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.fb.com/category/data-infrastructure/"&gt;Meta&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.onehouse.ai/blog"&gt;Onehouse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://estuary.dev/blog/"&gt;Estuary Blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Data Engineering Whitepapers:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ibimapublishing.com/articles/CIBIMA/2011/695619/695619.pdf"&gt;A Five-Layered Business Intelligence Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf"&gt;Lakehouse:A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://link.springer.com/chapter/10.1007/978-3-030-23381-5_5"&gt;Big Data Quality: A Data Quality Profiling Model&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.08697"&gt;The Data Lakehouse: Data Warehousing and More&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dl.acm.org/doi/10.5555/1863103.1863113"&gt;Spark: Cluster Computing with Working Sets&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://research.google/pubs/the-google-file-system/"&gt;The Google File System&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.onehouse.ai/whitepaper/onehouse-universal-data-lakehouse-whitepaper"&gt;Building a Universal Data Lakehouse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2401.09621"&gt;XTable in Action: Seamless Interoperability in Data Lakes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://research.google/pubs/mapreduce-simplified-data-processing-on-large-clusters/"&gt;MapReduce: Simplified Data Processing on Large Clusters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vita.had.co.nz/papers/tidy-data.pdf"&gt;Tidy Data&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.ssp.sh/brain/data-engineering-whitepapers/"&gt;Data Engineering Whitepapers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Social Media Accounts&lt;/h3&gt; 
&lt;p&gt;Here's the mostly comprehensive list of data engineering creators: &lt;strong&gt;(You have to have at least 5k followers somewhere to be added!)&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;YouTube&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;YouTube Channel&lt;/th&gt; 
   &lt;th align="right"&gt;Follower Count&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ByteByteGo&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/c/ByteByteGo"&gt;ByteByteGo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;1,000,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Zach Wilson&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@eczachly_"&gt;Data with Zach&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;150,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Shashank Mishra&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@shashank_mishra"&gt;E-learning Bridge&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Seattle Data Guy&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/c/SeattleDataGuy"&gt;Seattle Data Guy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TrendyTech&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/c/TrendytechInsights"&gt;TrendyTech&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Darshil Parmar&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@DarshilParmar"&gt;Darshil Parmar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Andreas Kretz&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/c/andreaskayy"&gt;Andreas Kretz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;The Ravit Show&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtube.com/@theravitshow"&gt;The Ravit Show&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Guy in a Cube&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@GuyInACube"&gt;Guy in a Cube&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Adam Marczak&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@AdamMarczakYT"&gt;Adam Marczak&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nullQueries&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@nullQueries"&gt;nullQueries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TECHTFQ by Thoufiq&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@techTFQ"&gt;TECHTFQ by Thoufiq&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SQLBI&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@SQLBI"&gt;SQLBI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alex Freberg&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@AlexTheAnalyst"&gt;Alex The Analyst&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ankur Ranjan&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@TheBigDataShow"&gt;Big Data Show&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Prashanth Kumar Pandey&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@ScholarNest"&gt;ScholarNest&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;77,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ITVersity&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@itversity"&gt;ITVersity&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;67,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Soumil Shah&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@SoumilShah"&gt;Soumil Shah&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;50,000&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ansh Lamba&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@AnshLambaJSR"&gt;Ansh Lamba&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;18,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure Lib&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@azurelib-academy"&gt;Azure Lib&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Advancing Analytics&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@AdvancingAnalytics"&gt;Advancing Analytics&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Kahan Data Solutions&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@KahanDataSolutions"&gt;Kahan Data Solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ankit Bansal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtube.com/@ankitbansal6"&gt;Ankit Bansal&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mr. K Talks Tech&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/channel/UCzdOan4AmF65PmLLks8Lmww"&gt;Mr. K Talks Tech&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Samuel Focht&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@PythonBasics"&gt;Python Basics&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mehdi Ouazza&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@mehdio"&gt;Mehdio DataTV&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;3,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alex Merced&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@alexmerceddata_"&gt;Alex Merced Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;John Kutay&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@striiminc"&gt;John Kutay&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Emil Kaminski&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/@DatabricksPro"&gt;Databricks For Professionals&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;LinkedIn&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;LinkedIn Profile&lt;/th&gt; 
   &lt;th align="right"&gt;Follower Count&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Zach Wilson&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/eczachly"&gt;Zach Wilson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;400,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chip Huyen&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/chiphuyen/"&gt;Chip Huyen&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;250,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Shashank Mishra&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/shashank219/"&gt;Shashank Mishra&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Seattle Data Guy&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/benjaminrogojan"&gt;Ben Rogojan&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TrendyTech&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/bigdatabysumit/"&gt;Sumit Mittal&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Darshil Parmar&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/darshil-parmar/"&gt;Darshil Parmar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Andreas Kretz&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/andreas-kretz"&gt;Andreas Kretz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ByteByteGo (Alex Xu)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/alexxubyte"&gt;Alex Xu&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure Lib (Deepak Goyal)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/deepak-goyal-93805a17/"&gt;Deepak Goyal&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alex Freberg&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/alex-freberg/"&gt;Alex Freberg&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SQLBI (Marco Russo)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/sqlbi"&gt;Marco Russo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;50,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ankit Bansal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/ankitbansal6/"&gt;Ankit Bansal&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;50,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Marc Lamberti&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/marclamberti"&gt;Marc Lamberti&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;50,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ankur Ranjan&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/thebigdatashow/"&gt;Ankur Ranjan&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;48,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ITVersity (Durga Gadiraju)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/durga0gadiraju/"&gt;Durga Gadiraju&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;48,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Prashanth Kumar Pandey&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/prashant-kumar-pandey/"&gt;Prashanth Kumar Pandey&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;37,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alex Merced&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/alexmerced"&gt;Alex Merced&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;30,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ijaz Ali&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/ijaz-ali-6aaa87122/"&gt;Ijaz Ali&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;24,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mehdi Ouazza&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/mehd-io/"&gt;Mehdi Ouazza&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;20,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ananth Packkildurai&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/ananthdurai/"&gt;Ananth Packkildurai&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;18,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ansh Lamba&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/ansh-lamba-793681184/"&gt;Ansh Lamba&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;13,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Manojkumar Vadivel&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/manojvsj/"&gt;Manojkumar Vadivel&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;12,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Advancing Analytics&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/simon-whiteley-uk/"&gt;Simon Whiteley&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Li Yin&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/li-yin-ai/"&gt;Li Yin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Jaco van Gelder&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/jwvangelder/"&gt;Jaco van Gelder&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Joseph Machado&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/josephmachado1991/"&gt;Joseph Machado&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Eric Roby&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/codingwithroby/"&gt;Eric Roby&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Simon Sp√§ti&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/sspaeti/"&gt;Simon Sp√§ti&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Constantin Lungu&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/constantin-lungu-668b8756"&gt;Constantin Lungu&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Lakshmi Sontenam&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/shivaga9esh"&gt;Lakshmi Sontenam&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;9,500+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dani P√°lma&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/danthelion/"&gt;Daniel P√°lma&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;9,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Soumil Shah&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/shah-soumil/"&gt;Soumil Shah&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;8,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arnaud Milleker&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/arnaudmilleker/"&gt;Arnaud Milleker&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;7,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dimitri Visnadi&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/visnadi/"&gt;Dimitri Visnadi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;7,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Lenny&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/lennyardiles/"&gt;Lenny A&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;6,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dipankar Mazumdar&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/dipankar-mazumdar/"&gt;Dipankar Mazumdar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Daniel Ciocirlan&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/danielciocirlan"&gt;Daniel Ciocirlan&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hugo Lu&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/hugo-lu-confirmed/"&gt;Hugo Lu&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tobias Macey&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/tmacey"&gt;Tobias Macey&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Marcos Ortiz&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/mlortiz"&gt;Marcos Ortiz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Julien Hurault&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/julienhuraultanalytics/"&gt;Julien Hurault&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;John Kutay&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/johnkutay/"&gt;John Kutay&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hassaan Akbar&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/ehassaan"&gt;Hassaan Akbar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Subhankar&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/subhankarumass/"&gt;Subhankar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nitin&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/tomernitin29/"&gt;Nitin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hassaan&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/in/shassaan/"&gt;Hassaan&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Javier de la Torre&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/www.linkedin.com/in/javier-de-la-torre-medina"&gt;Javier&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5000+&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;X/Twitter&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;X/Twitter Profile&lt;/th&gt; 
   &lt;th align="right"&gt;Follower Count&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ByteByteGo&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/alexxubyte/"&gt;alexxubyte&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;100,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dan Kornas&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.twitter.com/dankornas"&gt;@dankornas&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;66,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Zach Wilson&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.twitter.com/EcZachly"&gt;EcZachly&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;30,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Seattle Data Guy&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.twitter.com/SeattleDataGuy"&gt;SeattleDataGuy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SQLBI&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/marcorus"&gt;marcorus&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Joseph Machado&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/startdataeng"&gt;startdataeng&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alex Merced&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.twitter.com/amdatalakehouse"&gt;@amdatalakehouse&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;John Kutay&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/JohnKutay"&gt;@JohnKutay&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mehdi Ouazza&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/mehd_io"&gt;mehd_io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Instagram&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Instagram Profile&lt;/th&gt; 
   &lt;th align="right"&gt;Follower Count&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sundas Khalid&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.instagram.com/sundaskhalidd"&gt;sundaskhalidd&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;300,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Zach Wilson&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.instagram.com/eczachly"&gt;eczachly&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;150,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Andreas Kretz&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.instagram.com/learndataengineering"&gt;learndataengineering&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;5,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alex Merced&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.instagram.com/alexmercedcoder"&gt;@alexmercedcoder&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;TikTok&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;TikTok Profile&lt;/th&gt; 
   &lt;th align="right"&gt;Follower Count&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Zach Wilson&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.tiktok.com/@eczachly"&gt;@eczachly&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;70,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alex Freberg&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.tiktok.com/@alex_the_analyst"&gt;@alex_the_analyst&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;10,000+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mehdi Ouazza&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.tiktok.com/@mehdio_datatv"&gt;@mehdio_datatv&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Great Podcasts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.dataengineeringshow.com/"&gt;The Data Engineering Show&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.dataengineeringpodcast.com/"&gt;Data Engineering Podcast&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.datatopics.io/"&gt;DataTopics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://podcasts.apple.com/us/podcast/the-engineering-side-of-data/id1566999533"&gt;The Data Engineering Side Of Data&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.ascend.io/dataaware-podcast/"&gt;DataWare&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.deezer.com/us/show/5293247"&gt;The Data Coffee Break Podcast&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://datastackshow.com/"&gt;The Datastack show&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.intricity.com/learningcenter/podcast"&gt;Intricity101 Data Sharks Podcast&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.rittmananalytics.com/drilltodetail/"&gt;Drill to Detail with Mark Rittman&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://analyticshour.io/"&gt;Analytics Power Hour&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://listen.casted.us/public/127/Catalog-%26-Cocktails-2fcf8728"&gt;Catalog &amp;amp; cocktails&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://datatalks.club/podcast.html"&gt;Datatalks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.databricks.com/discover/data-brew"&gt;Data Brew by Databricks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rise-of-the-data-cloud.simplecast.com/"&gt;The Data Cloud Podcast by Snowflake&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.striim.com/podcast/"&gt;What's New in Data&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.datastax.com/resources/podcast/open-source-data"&gt;Open||Source||Data by Datastax&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.confluent.io/podcast/"&gt;Streaming Audio by confluent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://podcasts.apple.com/us/podcast/the-data-scientist-show/id1584430381"&gt;The Data Scientist Show&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://podcast.mlops.community/"&gt;MLOps.community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://open.spotify.com/show/3Km3lBNzJpc1nOTJUtbtMh"&gt;Monday Morning Data Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.thoughtspot.com/data-chief/podcast"&gt;The Data Chief&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Great &lt;a href="https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/newsletters.md"&gt;list of 20+ newsletters&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Top must follow newsletters for data engineering:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://blog.dataengineer.io"&gt;DataEngineer.io Newsletter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://joereis.substack.com"&gt;Joe Reis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.startdataengineering.com"&gt;Start Data Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.dataengineeringweekly.com"&gt;Data Engineering Weekly&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dataengineerthings.substack.com/"&gt;Data Engineer Things&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Glossaries:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.ssp.sh/brain/data-engineering/"&gt;Data Engineering Vault&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://glossary.airbyte.com/"&gt;Airbyte Data Glossary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dataengineering.wiki/Index"&gt;Data Engineering Wiki by Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.secoda.co/glossary/"&gt;Seconda Glossary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.databricks.com/glossary"&gt;Glossary Databricks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://airtable.com/shrGh8BqZbkfkbrfk/tbluZ3ayLHC3CKsDb"&gt;Airtable Glossary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dagster.io/glossary"&gt;Data Engineering Glossary by Dagster&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Design Patterns&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.github.com/DataExpert-io/cumulative-table-design"&gt;Cumulative Table Design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.github.com/EcZachly/microbatch-hourly-deduped-tutorial"&gt;Microbatch Deduplication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.github.com/EcZachly/little-book-of-pipelines"&gt;The Little Book of Pipelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://datadeveloperplatform.org/architecture/"&gt;Data Developer Platform&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Courses / Academies&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.dataexpert.io"&gt;DataExpert.io course&lt;/a&gt; use code &lt;strong&gt;HANDBOOK10&lt;/strong&gt; for a discount!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.learndataengineering.com"&gt;LearnDataEngineering.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.technicalfreelanceracademy.com/"&gt;Technical Freelancer Academy&lt;/a&gt; Use code &lt;strong&gt;zwtech&lt;/strong&gt; for a discount!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.edx.org/learn/data-engineering/ibm-data-engineering-basics-for-everyone"&gt;IBM Data Engineering for Everyone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.qwiklabs.com/"&gt;Qwiklabs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.datacamp.com/"&gt;DataCamp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.udemy.com/user/shruti-mantri-5/"&gt;Udemy Courses from Shruti Mantri&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rockthejvm.com/"&gt;Rock the JVM&lt;/a&gt; teaches Spark (in Scala), Flink and others&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://datatalks.club/"&gt;Data Engineering Zoomcamp by DataTalksClub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://josephmachado.podia.com/efficient-data-processing-in-spark"&gt;Efficient Data Processing in Spark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.scaler.com/"&gt;Scaler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.datateams.ai/"&gt;DataTeams - Data Engingeer hiring platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://danielblanco.dev/links"&gt;Udemy Courses from Daniel Blanco&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Certifications Courses&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/certification/data-engineer"&gt;Google Cloud Certified - Professional Data Engineer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.databricks.com/learn/certification/apache-spark-developer-associate"&gt;Databricks - Certified Associate Developer for Apache Spark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.databricks.com/learn/certification/data-engineer-associate"&gt;Databricks - Data Engineer Associate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.databricks.com/learn/certification/data-engineer-professional"&gt;Databricks - Data Engineer Professional&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-203/?tab=tab-learning-paths"&gt;Microsoft DP-203: Data Engineering on Microsoft Azure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/credentials/certifications/fabric-analytics-engineer-associate/"&gt;Microsoft DP-600: Fabric Analytics Engineer Associate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/credentials/certifications/fabric-data-engineer-associate/?practice-assessment-type=certification"&gt;Microsoft DP-700: Fabric Data Engineer Associate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/certification/certified-data-engineer-associate/"&gt;AWS Certified Data Engineer - Associate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>microsoft/BitNet</title>
      <link>https://github.com/microsoft/BitNet</link>
      <description>&lt;p&gt;Official inference framework for 1-bit LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitnet.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-1.0-blue" alt="version" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/header_model_release.png" alt="BitNet Model on Hugging Face" width="800" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try it out via this &lt;a href="https://bitnet-demo.azurewebsites.net/"&gt;demo&lt;/a&gt;, or build and run it on your own &lt;a href="https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source"&gt;CPU&lt;/a&gt; or &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;GPU&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support &lt;strong&gt;fast&lt;/strong&gt; and &lt;strong&gt;lossless&lt;/strong&gt; inference of 1.58-bit models on CPU and GPU (NPU support will coming next).&lt;/p&gt; 
&lt;p&gt;The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of &lt;strong&gt;1.37x&lt;/strong&gt; to &lt;strong&gt;5.07x&lt;/strong&gt; on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by &lt;strong&gt;55.4%&lt;/strong&gt; to &lt;strong&gt;70.0%&lt;/strong&gt;, further boosting overall efficiency. On x86 CPUs, speedups range from &lt;strong&gt;2.37x&lt;/strong&gt; to &lt;strong&gt;6.17x&lt;/strong&gt; with energy reductions between &lt;strong&gt;71.9%&lt;/strong&gt; to &lt;strong&gt;82.2%&lt;/strong&gt;. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the &lt;a href="https://arxiv.org/abs/2410.16144"&gt;technical report&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/m2_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/intel_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1"&gt;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What's New:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;05/20/2025 &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;BitNet Official GPU inference kernel&lt;/a&gt; &lt;img src="https://img.shields.io/badge/NEW-red" alt="NEW" /&gt;&lt;/li&gt; 
 &lt;li&gt;04/14/2025 &lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet Official 2B Parameter Model on Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/18/2025 &lt;a href="https://arxiv.org/abs/2502.11880"&gt;Bitnet.cpp: Efficient Edge Inference for Ternary LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;11/08/2024 &lt;a href="https://arxiv.org/abs/2411.04965"&gt;BitNet a4.8: 4-bit Activations for 1-bit LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/21/2024 &lt;a href="https://arxiv.org/abs/2410.16144"&gt;1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2024 bitnet.cpp 1.0 released.&lt;/li&gt; 
 &lt;li&gt;03/21/2024 &lt;a href="https://github.com/microsoft/unilm/raw/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf"&gt;The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/27/2024 &lt;a href="https://arxiv.org/abs/2402.17764"&gt;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2023 &lt;a href="https://arxiv.org/abs/2310.11453"&gt;BitNet: Scaling 1-bit Transformers for Large Language Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is based on the &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in &lt;a href="https://github.com/microsoft/T-MAC/"&gt;T-MAC&lt;/a&gt;. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.&lt;/p&gt; 
&lt;h2&gt;Official Models&lt;/h2&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet-b1.58-2B-4T&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;2.4B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;‚ùóÔ∏è&lt;strong&gt;We use existing 1-bit LLMs available on &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt; to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-large"&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;0.7B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-3B"&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;3.3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens"&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;8.0B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026"&gt;Falcon3 Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-10B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon-edge-series-6804fd13344d6d8a8fa71130"&gt;Falcon-E Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;python&amp;gt;=3.9&lt;/li&gt; 
 &lt;li&gt;cmake&amp;gt;=3.22&lt;/li&gt; 
 &lt;li&gt;clang&amp;gt;=18 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;For Windows users, install &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio 2022&lt;/a&gt;. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Desktop-development with C++&lt;/li&gt; 
     &lt;li&gt;C++-CMake Tools for Windows&lt;/li&gt; 
     &lt;li&gt;Git for Windows&lt;/li&gt; 
     &lt;li&gt;C++-Clang Compiler for Windows&lt;/li&gt; 
     &lt;li&gt;MS-Build Support for LLVM-Toolset (clang)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;For Debian/Ubuntu users, you can download with &lt;a href="https://apt.llvm.org/"&gt;Automatic installation script&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;conda (highly recommend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repo&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install the dependencies&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# (Recommended) Create a new conda environment
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manually download the model and run with local path
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]
                    [--use-pretuned]

Setup the environment for running inference

optional arguments:
  -h, --help            show this help message and exit
  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}
                        Model used for inference
  --model-dir MODEL_DIR, -md MODEL_DIR
                        Directory to save/load the model
  --log-dir LOG_DIR, -ld LOG_DIR
                        Directory to save the logging info
  --quant-type {i2_s,tl1}, -q {i2_s,tl1}
                        Quantization type
  --quant-embd          Quantize the embeddings to f16
  --use-pretuned, -p    Use the pretuned kernel parameters
&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run inference with the quantized model
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You are a helpful assistant" -cnv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]

Run inference

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to model file
  -n N_PREDICT, --n-predict N_PREDICT
                        Number of tokens to predict when generating text
  -p PROMPT, --prompt PROMPT
                        Prompt to generate text from
  -t THREADS, --threads THREADS
                        Number of threads to use
  -c CTX_SIZE, --ctx-size CTX_SIZE
                        Size of the prompt context
  -temp TEMPERATURE, --temperature TEMPERATURE
                        Temperature, a hyperparameter that controls the randomness of the generated text
  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)
                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)
&lt;/pre&gt; 
&lt;h3&gt;Benchmark&lt;/h3&gt; 
&lt;p&gt;We provide scripts to run the inference benchmark providing a model.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  
   
Setup the environment for running the inference  
   
required arguments:  
  -m MODEL, --model MODEL  
                        Path to the model file. 
   
optional arguments:  
  -h, --help  
                        Show this help message and exit. 
  -n N_TOKEN, --n-token N_TOKEN  
                        Number of generated tokens. 
  -p N_PROMPT, --n-prompt N_PROMPT  
                        Prompt to generate text from. 
  -t THREADS, --threads THREADS  
                        Number of threads to use. 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's a brief explanation of each argument:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;: The path to the model file. This is a required argument that must be provided when running the script.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-n&lt;/code&gt;, &lt;code&gt;--n-token&lt;/code&gt;: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--n-prompt&lt;/code&gt;: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-t&lt;/code&gt;, &lt;code&gt;--threads&lt;/code&gt;: The number of threads to use for running the inference. It is an optional argument with a default value of 2.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;: Show the help message and exit. Use this argument to display usage information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command would run the inference benchmark using the model located at &lt;code&gt;/path/to/model&lt;/code&gt;, generating 200 tokens from a 256 token prompt, utilizing 4 threads.&lt;/p&gt; 
&lt;p&gt;For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M

# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Convert from &lt;code&gt;.safetensors&lt;/code&gt; Checkpoints&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prepare the .safetensors model file
huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16

# Convert to gguf model
python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FAQ (Frequently Asked Questions)üìå&lt;/h3&gt; 
&lt;h4&gt;Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This is an issue introduced in recent version of llama.cpp. Please refer to this &lt;a href="https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323"&gt;commit&lt;/a&gt; in the &lt;a href="https://github.com/abetlen/llama-cpp-python/issues/1942"&gt;discussion&lt;/a&gt; to fix this issue.&lt;/p&gt; 
&lt;h4&gt;Q2: How to build with clang in conda environment on windows?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Before building the project, verify your clang installation and access to Visual Studio tools by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;clang -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;'clang' is not recognized as an internal or external command, operable program or batch file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It indicates that your command line window is not properly initialized for Visual Studio tools.&lt;/p&gt; 
&lt;p&gt;‚Ä¢ If you are using Command Prompt, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\VsDevCmd.bat" -startdir=none -arch=x64 -host_arch=x64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Ä¢ If you are using Windows PowerShell, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Import-Module "C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\Microsoft.VisualStudio.DevShell.dll" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments "-arch=x64 -host_arch=x64"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These steps will initialize your environment and allow you to use the correct Visual Studio tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rasbt/LLMs-from-scratch</title>
      <link>https://github.com/rasbt/LLMs-from-scratch</link>
      <description>&lt;p&gt;Implement a ChatGPT-like LLM in PyTorch from scratch, step by step&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Build a Large Language Model (From Scratch)&lt;/h1&gt; 
&lt;p&gt;This repository contains the code for developing, pretraining, and finetuning a GPT-like LLM and is the official code repository for the book &lt;a href="https://amzn.to/4fqvn0D"&gt;Build a Large Language Model (From Scratch)&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://amzn.to/4fqvn0D"&gt;&lt;img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/cover.jpg?123" width="250px" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;In &lt;a href="http://mng.bz/orYv"&gt;&lt;em&gt;Build a Large Language Model (From Scratch)&lt;/em&gt;&lt;/a&gt;, you'll learn and understand how large language models (LLMs) work from the inside out by coding them from the ground up, step by step. In this book, I'll guide you through creating your own LLM, explaining each stage with clear text, diagrams, and examples.&lt;/p&gt; 
&lt;p&gt;The method described in this book for training and developing your own small-but-functional model for educational purposes mirrors the approach used in creating large-scale foundational models such as those behind ChatGPT. In addition, this book includes code for loading the weights of larger pretrained models for finetuning.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Link to the official &lt;a href="https://github.com/rasbt/LLMs-from-scratch"&gt;source code repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mng.bz/orYv"&gt;Link to the book at Manning (the publisher's website)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1633437167"&gt;Link to the book page on Amazon.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ISBN 9781633437166&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="http://mng.bz/orYv#reviews"&gt;&lt;img src="https://sebastianraschka.com//images/LLMs-from-scratch-images/other/reviews.png" width="220px" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;To download a copy of this repository, click on the &lt;a href="https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip"&gt;Download ZIP&lt;/a&gt; button or execute the following command in your terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;p&gt;(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at &lt;a href="https://github.com/rasbt/LLMs-from-scratch"&gt;https://github.com/rasbt/LLMs-from-scratch&lt;/a&gt; for the latest updates.)&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;p&gt;Please note that this &lt;code&gt;README.md&lt;/code&gt; file is a Markdown (&lt;code&gt;.md&lt;/code&gt;) file. If you have downloaded this code bundle from the Manning website and are viewing it on your local computer, I recommend using a Markdown editor or previewer for proper viewing. If you haven't installed a Markdown editor yet, &lt;a href="https://ghostwriter.kde.org"&gt;Ghostwriter&lt;/a&gt; is a good free option.&lt;/p&gt; 
&lt;p&gt;You can alternatively view this and other files on GitHub at &lt;a href="https://github.com/rasbt/LLMs-from-scratch"&gt;https://github.com/rasbt/LLMs-from-scratch&lt;/a&gt; in your browser, which renders Markdown automatically.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tip:&lt;/strong&gt; If you're seeking guidance on installing Python and Python packages and setting up your code environment, I suggest reading the &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/README.md"&gt;README.md&lt;/a&gt; file located in the &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup"&gt;setup&lt;/a&gt; directory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml"&gt;&lt;img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml/badge.svg?sanitize=true" alt="Code tests Linux" /&gt;&lt;/a&gt; &lt;a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml"&gt;&lt;img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml/badge.svg?sanitize=true" alt="Code tests Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml"&gt;&lt;img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml/badge.svg?sanitize=true" alt="Code tests macOS" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chapter Title&lt;/th&gt; 
   &lt;th&gt;Main Code (for Quick Access)&lt;/th&gt; 
   &lt;th&gt;All Code + Supplementary&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup"&gt;Setup recommendations&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 1: Understanding Large Language Models&lt;/td&gt; 
   &lt;td&gt;No code&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 2: Working with Text Data&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/ch02.ipynb"&gt;ch02.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/dataloader.ipynb"&gt;dataloader.ipynb&lt;/a&gt; (summary)&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02"&gt;./ch02&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 3: Coding Attention Mechanisms&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/ch03.ipynb"&gt;ch03.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/multihead-attention.ipynb"&gt;multihead-attention.ipynb&lt;/a&gt; (summary) &lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03"&gt;./ch03&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 4: Implementing a GPT Model from Scratch&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/ch04.ipynb"&gt;ch04.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/gpt.py"&gt;gpt.py&lt;/a&gt; (summary)&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04"&gt;./ch04&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 5: Pretraining on Unlabeled Data&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/ch05.ipynb"&gt;ch05.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_train.py"&gt;gpt_train.py&lt;/a&gt; (summary) &lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_generate.py"&gt;gpt_generate.py&lt;/a&gt; (summary) &lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05"&gt;./ch05&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 6: Finetuning for Text Classification&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/ch06.ipynb"&gt;ch06.ipynb&lt;/a&gt; &lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/gpt_class_finetune.py"&gt;gpt_class_finetune.py&lt;/a&gt; &lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06"&gt;./ch06&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 7: Finetuning to Follow Instructions&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ch07.ipynb"&gt;ch07.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py"&gt;gpt_instruction_finetuning.py&lt;/a&gt; (summary)&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ollama_evaluate.py"&gt;ollama_evaluate.py&lt;/a&gt; (summary)&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07"&gt;./ch07&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix A: Introduction to PyTorch&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part1.ipynb"&gt;code-part1.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part2.ipynb"&gt;code-part2.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/DDP-script.py"&gt;DDP-script.py&lt;/a&gt;&lt;br /&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A"&gt;./appendix-A&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix B: References and Further Reading&lt;/td&gt; 
   &lt;td&gt;No code&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix C: Exercise Solutions&lt;/td&gt; 
   &lt;td&gt;No code&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix D: Adding Bells and Whistles to the Training Loop&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-D/01_main-chapter-code/appendix-D.ipynb"&gt;appendix-D.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-D"&gt;./appendix-D&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix E: Parameter-efficient Finetuning with LoRA&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-E/01_main-chapter-code/appendix-E.ipynb"&gt;appendix-E.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-E"&gt;./appendix-E&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; &amp;nbsp; 
&lt;p&gt;The mental model below summarizes the contents covered in this book.&lt;/p&gt; 
&lt;img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg" width="650px" /&gt; 
&lt;br /&gt; &amp;nbsp; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;The most important prerequisite is a strong foundation in Python programming. With this knowledge, you will be well prepared to explore the fascinating world of LLMs and understand the concepts and code examples presented in this book.&lt;/p&gt; 
&lt;p&gt;If you have some experience with deep neural networks, you may find certain concepts more familiar, as LLMs are built upon these architectures.&lt;/p&gt; 
&lt;p&gt;This book uses PyTorch to implement the code from scratch without using any external LLM libraries. While proficiency in PyTorch is not a prerequisite, familiarity with PyTorch basics is certainly useful. If you are new to PyTorch, Appendix A provides a concise introduction to PyTorch. Alternatively, you may find my book, &lt;a href="https://sebastianraschka.com/teaching/pytorch-1h/"&gt;PyTorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs&lt;/a&gt;, helpful for learning about the essentials.&lt;/p&gt; 
&lt;br /&gt; &amp;nbsp; 
&lt;h2&gt;Hardware Requirements&lt;/h2&gt; 
&lt;p&gt;The code in the main chapters of this book is designed to run on conventional laptops within a reasonable timeframe and does not require specialized hardware. This approach ensures that a wide audience can engage with the material. Additionally, the code automatically utilizes GPUs if they are available. (Please see the &lt;a href="https://github.com/rasbt/LLMs-from-scratch/raw/main/setup/README.md"&gt;setup&lt;/a&gt; doc for additional recommendations.)&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Video Course&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.manning.com/livevideo/master-and-build-large-language-models"&gt;A 17-hour and 15-minute companion video course&lt;/a&gt; where I code through each chapter of the book. The course is organized into chapters and sections that mirror the book's structure so that it can be used as a standalone alternative to the book or complementary code-along resource.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.manning.com/livevideo/master-and-build-large-language-models"&gt;&lt;img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/video-screenshot.webp?123" width="350px" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Exercises&lt;/h2&gt; 
&lt;p&gt;Each chapter of the book includes several exercises. The solutions are summarized in Appendix C, and the corresponding code notebooks are available in the main chapter folders of this repository (for example, &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/exercise-solutions.ipynb"&gt;./ch02/01_main-chapter-code/exercise-solutions.ipynb&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In addition to the code exercises, you can download a free 170-page PDF titled &lt;a href="https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch"&gt;Test Yourself On Build a Large Language Model (From Scratch)&lt;/a&gt; from the Manning website. It contains approximately 30 quiz questions and solutions per chapter to help you test your understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch"&gt;&lt;img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/test-yourself-cover.jpg?123" width="150px" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Bonus Material&lt;/h2&gt; 
&lt;p&gt;Several folders contain optional materials as a bonus for interested readers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Setup&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/01_optional-python-setup-preferences"&gt;Python Setup Tips&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/02_installing-python-libraries"&gt;Installing Python Packages and Libraries Used In This Book&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/03_optional-docker-environment"&gt;Docker Environment Setup Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 2: Working with text data&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/05_bpe-from-scratch/bpe-from-scratch.ipynb"&gt;Byte Pair Encoding (BPE) Tokenizer From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/02_bonus_bytepair-encoder"&gt;Comparing Various Byte Pair Encoding (BPE) Implementations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/03_bonus_embedding-vs-matmul"&gt;Understanding the Difference Between Embedding Layers and Linear Layers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/04_bonus_dataloader-intuition"&gt;Dataloader Intuition with Simple Numbers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 3: Coding attention mechanisms&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb"&gt;Comparing Efficient Multi-Head Attention Implementations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/03_understanding-buffers/understanding-buffers.ipynb"&gt;Understanding PyTorch Buffers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 4: Implementing a GPT model from scratch&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/02_performance-analysis/flops-analysis.ipynb"&gt;FLOPS Analysis&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/03_kv-cache"&gt;KV Cache&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 5: Pretraining on unlabeled data:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/02_alternative_weight_loading/"&gt;Alternative Weight Loading Methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/03_bonus_pretraining_on_gutenberg"&gt;Pretraining GPT on the Project Gutenberg Dataset&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/04_learning_rate_schedulers"&gt;Adding Bells and Whistles to the Training Loop&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/05_bonus_hparam_tuning"&gt;Optimizing Hyperparameters for Pretraining&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/06_user_interface"&gt;Building a User Interface to Interact With the Pretrained LLM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/07_gpt_to_llama"&gt;Converting GPT to Llama&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/07_gpt_to_llama/standalone-llama32.ipynb"&gt;Llama 3.2 From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/11_qwen3/"&gt;Qwen3 Dense and Mixture-of-Experts (MoE) From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/12_gemma3/"&gt;Gemma 3 From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/08_memory_efficient_weight_loading/memory-efficient-state-dict.ipynb"&gt;Memory-efficient Model Weight Loading&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/09_extending-tokenizers/extend-tiktoken.ipynb"&gt;Extending the Tiktoken BPE Tokenizer with New Tokens&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/10_llm-training-speed"&gt;PyTorch Performance Tips for Faster LLM Training&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 6: Finetuning for classification&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/02_bonus_additional-experiments"&gt;Additional experiments finetuning different layers and using larger models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/03_bonus_imdb-classification"&gt;Finetuning different models on 50k IMDB movie review dataset&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/04_user_interface"&gt;Building a User Interface to Interact With the GPT-based Spam Classifier&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 7: Finetuning to follow instructions&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/02_dataset-utilities"&gt;Dataset Utilities for Finding Near Duplicates and Creating Passive Voice Entries&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/03_model-evaluation"&gt;Evaluating Instruction Responses Using the OpenAI API and Ollama&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/llama3-ollama.ipynb"&gt;Generating a Dataset for Instruction Finetuning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/reflection-gpt4.ipynb"&gt;Improving a Dataset for Instruction Finetuning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/create-preference-data-ollama.ipynb"&gt;Generating a Preference Dataset with Llama 3.1 70B and Ollama&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb"&gt;Direct Preference Optimization (DPO) for LLM Alignment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/06_user_interface"&gt;Building a User Interface to Interact With the Instruction Finetuned GPT Model&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; &amp;nbsp; 
&lt;h2&gt;Questions, Feedback, and Contributing to This Repository&lt;/h2&gt; 
&lt;p&gt;I welcome all sorts of feedback, best shared via the &lt;a href="https://livebook.manning.com/forum?product=raschka&amp;amp;page=1"&gt;Manning Forum&lt;/a&gt; or &lt;a href="https://github.com/rasbt/LLMs-from-scratch/discussions"&gt;GitHub Discussions&lt;/a&gt;. Likewise, if you have any questions or just want to bounce ideas off others, please don't hesitate to post these in the forum as well.&lt;/p&gt; 
&lt;p&gt;Please note that since this repository contains the code corresponding to a print book, I currently cannot accept contributions that would extend the contents of the main chapter code, as it would introduce deviations from the physical book. Keeping it consistent helps ensure a smooth experience for everyone.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this book or code useful for your research, please consider citing it.&lt;/p&gt; 
&lt;p&gt;Chicago-style citation:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Raschka, Sebastian. &lt;em&gt;Build A Large Language Model (From Scratch)&lt;/em&gt;. Manning, 2024. ISBN: 978-1633437166.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;BibTeX entry:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@book{build-llms-from-scratch-book,
  author       = {Sebastian Raschka},
  title        = {Build A Large Language Model (From Scratch)},
  publisher    = {Manning},
  year         = {2024},
  isbn         = {978-1633437166},
  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},
  github       = {https://github.com/rasbt/LLMs-from-scratch}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>epicenter-so/epicenter</title>
      <link>https://github.com/epicenter-so/epicenter</link>
      <description>&lt;p&gt;Press shortcut ‚Üí speak ‚Üí get text. Free and open source. More local-first apps soon ‚ù§Ô∏è&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://epicenter.so"&gt; &lt;img width="200" src="https://github.com/user-attachments/assets/9e210c52-2740-43b6-af3f-e6eaf4b5c397" alt="Epicenter" /&gt; &lt;/a&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;Epicenter&lt;/h1&gt; 
&lt;p align="center"&gt;Local-first, open-source apps&lt;/p&gt; 
&lt;p align="center"&gt;Own your data. Use any model you want. Free and open source ‚ù§Ô∏è&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üì¢ Repository Update:&lt;/strong&gt; The &lt;a href="https://github.com/braden-w/whispering/"&gt;Whispering&lt;/a&gt; repository is now part of &lt;strong&gt;Epicenter&lt;/strong&gt;! You can find it &lt;a href="https://github.com/epicenter-so/epicenter/tree/main/apps/whispering"&gt;here&lt;/a&gt;. Everything else remains the same‚Äîsame tools, same philosophy, same team.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; 
 &lt;!-- GitHub Stars Badge --&gt; &lt;a href="https://github.com/epicenter-so/epicenter" target="_blank"&gt; &lt;img alt="GitHub stars" src="https://img.shields.io/github/stars/epicenter-so/epicenter?style=flat-square" /&gt; &lt;/a&gt; 
 &lt;!-- Latest Version Badge --&gt; &lt;img src="https://img.shields.io/github/v/release/epicenter-so/epicenter?style=flat-square&amp;amp;label=Latest%20Version&amp;amp;color=brightgreen" /&gt; 
 &lt;!-- License Badge --&gt; &lt;a href="https://raw.githubusercontent.com/epicenter-so/epicenter/main/LICENSE" target="_blank"&gt; &lt;img alt="MIT License" src="https://img.shields.io/github/license/epicenter-so/epicenter.svg?style=flat-square" /&gt; &lt;/a&gt; 
 &lt;!-- Discord Badge --&gt; &lt;a href="https://go.epicenter.so/discord" target="_blank"&gt; &lt;img alt="Discord" src="https://img.shields.io/badge/Discord-Join%20us-5865F2?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;!-- Platform Support Badges --&gt; &lt;a href="https://github.com/epicenter-so/epicenter/releases" target="_blank"&gt; &lt;img alt="macOS" src="https://img.shields.io/badge/-macOS-black?style=flat-square&amp;amp;logo=apple&amp;amp;logoColor=white" /&gt; &lt;/a&gt; &lt;a href="https://github.com/epicenter-so/epicenter/releases" target="_blank"&gt; &lt;img alt="Windows" src="https://img.shields.io/badge/-Windows-blue?style=flat-square&amp;amp;logo=windows&amp;amp;logoColor=white" /&gt; &lt;/a&gt; &lt;a href="https://github.com/epicenter-so/epicenter/releases" target="_blank"&gt; &lt;img alt="Linux" src="https://img.shields.io/badge/-Linux-yellow?style=flat-square&amp;amp;logo=linux&amp;amp;logoColor=white" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/epicenter-so/epicenter/main/#current-tools"&gt;Tools&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/epicenter-so/epicenter/main/#where-were-headed"&gt;Vision&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/epicenter-so/epicenter/main/#join-us"&gt;Contributing&lt;/a&gt; ‚Ä¢ &lt;a href="https://go.epicenter.so/discord"&gt;Discord&lt;/a&gt; ‚Ä¢ &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;What is Epicenter?&lt;/h2&gt; 
&lt;p&gt;Epicenter is an ecosystem of open-source, local-first apps. Our eventual goal is to store all of your data‚Äînotes, transcripts, chat histories‚Äîin a single folder of plain text and SQLite. Every tool we build shares this memory. It's open, tweakable, and yours. Grep it, open it in Obsidian, host it wherever you like. The choice is yours.&lt;/p&gt; 
&lt;h2&gt;Current Tools&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center" width="50%"&gt; &lt;h3&gt;üéôÔ∏è &lt;a href="https://github.com/epicenter-so/epicenter/tree/main/apps/whispering"&gt;Whispering&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Press shortcut ‚Üí speak ‚Üí get text. Desktop transcription that cuts out the middleman. Bring your own API key.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;‚Üí &lt;a href="https://github.com/epicenter-so/epicenter/tree/main/apps/whispering"&gt;Explore Whispering&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td align="center" width="50%"&gt; &lt;h3&gt;ü§ñ &lt;a href="https://github.com/epicenter-so/epicenter/tree/main/apps/sh"&gt;epicenter.sh&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A local-first assistant you can chat with. It lives in your folder, becoming the access point to everything you've ever written, thought, or built.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;‚Üí &lt;a href="https://github.com/epicenter-so/epicenter/tree/main/apps/sh"&gt;Explore epicenter.sh&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Where We're Headed&lt;/h2&gt; 
&lt;p&gt;Our vision is to build a personal workspace where you own your data, choose your models, and replace siloed apps with open, interoperable alternatives. All while preserving authenticity and being free and open source.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Epicenter will have more apps in the future, but for now, the best way to get started is to run Whispering locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Prerequisites: Install Bun from https://bun.sh (run bun upgrade if there's issues)
git clone https://github.com/epicenter-so/epicenter.git
cd epicenter
bun install  # Will prompt to upgrade if your Bun version is too old
cd apps/whispering
bun dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Join Us&lt;/h2&gt; 
&lt;h2&gt;Discord Community&lt;/h2&gt; 
&lt;p&gt;If you think like a generalist, build like a hacker, and value tools that respect your mind‚Äîyou'll fit right in.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;‚Üí &lt;a href="https://go.epicenter.so/discord"&gt;Join our Discord&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;We're looking for contributors&lt;/h3&gt; 
&lt;p&gt;If you're passionate about open source, local-first software, or are just a cracked Svelte/TypeScript developer‚Äîwe'd love to build with you.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;‚Üí &lt;a href="https://raw.githubusercontent.com/epicenter-so/epicenter/main/CONTRIBUTING.md"&gt;Read our Contributing Guide&lt;/a&gt; to get started&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Contributors coordinate and share ideas in our Discord community.&lt;/p&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img alt="Svelte 5" src="https://img.shields.io/badge/-Svelte%205-orange?style=flat-square&amp;amp;logo=svelte&amp;amp;logoColor=white" /&gt; &lt;img alt="Tauri" src="https://img.shields.io/badge/-Tauri-blue?style=flat-square&amp;amp;logo=tauri&amp;amp;logoColor=white" /&gt; &lt;img alt="TypeScript" src="https://img.shields.io/badge/-TypeScript-blue?style=flat-square&amp;amp;logo=typescript&amp;amp;logoColor=white" /&gt; &lt;img alt="Rust" src="https://img.shields.io/badge/-Rust-orange?style=flat-square&amp;amp;logo=rust&amp;amp;logoColor=white" /&gt; &lt;img alt="TanStack Query" src="https://img.shields.io/badge/-TanStack%20Query-red?style=flat-square&amp;amp;logo=react-query&amp;amp;logoColor=white" /&gt; &lt;img alt="Tailwind CSS" src="https://img.shields.io/badge/-Tailwind%20CSS-38B2AC?style=flat-square&amp;amp;logo=tailwind-css&amp;amp;logoColor=white" /&gt; &lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/epicenter-so/epicenter/main/LICENSE"&gt;MIT&lt;/a&gt;. Build on it. Fork it. Make it yours. Please contribute if you can.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt;Contact:&lt;/strong&gt; &lt;a href="mailto:github@bradenwong.com"&gt;github@bradenwong.com&lt;/a&gt; | &lt;a href="https://go.epicenter.so/discord"&gt;Discord&lt;/a&gt; | &lt;a href="https://twitter.com/braden_wong_"&gt;@braden_wong_&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;sub&gt;Built with ‚ù§Ô∏è for data ownership, local-first, and open-souce&lt;/sub&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>simstudioai/sim</title>
      <link>https://github.com/simstudioai/sim</link>
      <description>&lt;p&gt;Sim is an open-source AI agent workflow builder. Sim Studio's interface is a lightweight, intuitive way to quickly build and deploy LLMs that connect with your favorite tools.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/logo/reverse/text/large.png" alt="Sim Logo" width="500" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Build and deploy AI agent workflows in minutes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA" alt="Sim.ai" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Hr4UWYEcTT" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/simdotai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/simstudioai?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://docs.sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Docs-6F3DFA.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/demo.gif" alt="Sim Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Cloud-hosted: &lt;a href="https://sim.ai"&gt;sim.ai&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&amp;amp;logoColor=white" alt="Sim.ai" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Self-hosted: NPM Package&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx simstudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Note&lt;/h4&gt; 
&lt;p&gt;Docker must be installed and running on your machine.&lt;/p&gt; 
&lt;h4&gt;Options&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-p, --port &amp;lt;port&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port to run Sim on (default &lt;code&gt;3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-pull&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Skip pulling latest Docker images&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Self-hosted: Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the application at &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Local Models with Ollama&lt;/h4&gt; 
&lt;p&gt;Run Sim with local AI models using &lt;a href="https://ollama.ai"&gt;Ollama&lt;/a&gt; - no external APIs required:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the model to download, then visit &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;. Add more models with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Self-hosted: Dev Containers&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open VS Code with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers"&gt;Remote - Containers extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open the project and click "Reopen in Container" when prompted&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;bun run dev:full&lt;/code&gt; in the terminal or use the &lt;code&gt;sim-start&lt;/code&gt; alias 
  &lt;ul&gt; 
   &lt;li&gt;This starts both the main application and the realtime socket server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Self-hosted: Manual Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt; runtime&lt;/li&gt; 
 &lt;li&gt;PostgreSQL 12+ with &lt;a href="https://github.com/pgvector/pgvector"&gt;pgvector extension&lt;/a&gt; (required for AI embeddings)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the &lt;code&gt;pgvector&lt;/code&gt; PostgreSQL extension.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/simstudioai/sim.git
cd sim
bun install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Set up PostgreSQL with pgvector:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You need PostgreSQL with the &lt;code&gt;vector&lt;/code&gt; extension for embedding support. Choose one option:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Using Docker (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Manual Installation&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install PostgreSQL 12+ and the pgvector extension&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/pgvector/pgvector#installation"&gt;pgvector installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Set up the database:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bunx drizzle-kit migrate 
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Start the development servers:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Recommended approach - run both servers together (from project root):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev:full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts both the main Next.js application and the realtime socket server required for full functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Alternative - run servers separately:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Next.js app (from project root):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Realtime socket server (from &lt;code&gt;apps/sim&lt;/code&gt; directory in a separate terminal):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
bun run dev:sockets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Copilot API Keys&lt;/h2&gt; 
&lt;p&gt;Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href="https://sim.ai"&gt;https://sim.ai&lt;/a&gt; ‚Üí Settings ‚Üí Copilot and generate a Copilot API key&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;COPILOT_API_KEY&lt;/code&gt; in your self-hosted environment to that value&lt;/li&gt; 
 &lt;li&gt;Host Sim on a publicly available DNS and set NEXT_PUBLIC_APP_URL and BETTER_AUTH_URL to that value (&lt;a href="https://ngrok.com/"&gt;ngrok&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: &lt;a href="https://nextjs.org/"&gt;Next.js&lt;/a&gt; (App Router)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: PostgreSQL with &lt;a href="https://orm.drizzle.team"&gt;Drizzle ORM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: &lt;a href="https://better-auth.com"&gt;Better Auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: &lt;a href="https://ui.shadcn.com/"&gt;Shadcn&lt;/a&gt;, &lt;a href="https://tailwindcss.com"&gt;Tailwind CSS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;State Management&lt;/strong&gt;: &lt;a href="https://zustand-demo.pmnd.rs/"&gt;Zustand&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flow Editor&lt;/strong&gt;: &lt;a href="https://reactflow.dev/"&gt;ReactFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://fumadocs.vercel.app/"&gt;Fumadocs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monorepo&lt;/strong&gt;: &lt;a href="https://turborepo.org/"&gt;Turborepo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Realtime&lt;/strong&gt;: &lt;a href="https://socket.io/"&gt;Socket.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Jobs&lt;/strong&gt;: &lt;a href="https://trigger.dev/"&gt;Trigger.dev&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p align="center"&gt;Made with ‚ù§Ô∏è by the Sim Team&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>n8n-io/self-hosted-ai-starter-kit</title>
      <link>https://github.com/n8n-io/self-hosted-ai-starter-kit</link>
      <description>&lt;p&gt;The Self-hosted AI Starter Kit is an open-source template that quickly sets up a local AI environment. Curated by n8n, it provides essential tools for creating secure, self-hosted AI workflows.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Self-hosted AI starter kit&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Self-hosted AI Starter Kit&lt;/strong&gt; is an open-source Docker Compose template designed to swiftly initialize a comprehensive local AI and low-code development environment.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/n8n-io/self-hosted-ai-starter-kit/main/assets/n8n-demo.gif" alt="n8n.io - Screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;Curated by &lt;a href="https://github.com/n8n-io"&gt;https://github.com/n8n-io&lt;/a&gt;, it combines the self-hosted n8n platform with a curated list of compatible AI products and components to quickly get started with building self-hosted AI workflows.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;a href="https://blog.n8n.io/self-hosted-ai/"&gt;Read the announcement&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;What‚Äôs included&lt;/h3&gt; 
&lt;p&gt;‚úÖ &lt;a href="https://n8n.io/"&gt;&lt;strong&gt;Self-hosted n8n&lt;/strong&gt;&lt;/a&gt; - Low-code platform with over 400 integrations and advanced AI components&lt;/p&gt; 
&lt;p&gt;‚úÖ &lt;a href="https://ollama.com/"&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/a&gt; - Cross-platform LLM platform to install and run the latest local LLMs&lt;/p&gt; 
&lt;p&gt;‚úÖ &lt;a href="https://qdrant.tech/"&gt;&lt;strong&gt;Qdrant&lt;/strong&gt;&lt;/a&gt; - Open-source, high performance vector store with an comprehensive API&lt;/p&gt; 
&lt;p&gt;‚úÖ &lt;a href="https://www.postgresql.org/"&gt;&lt;strong&gt;PostgreSQL&lt;/strong&gt;&lt;/a&gt; - Workhorse of the Data Engineering world, handles large amounts of data safely.&lt;/p&gt; 
&lt;h3&gt;What you can build&lt;/h3&gt; 
&lt;p&gt;‚≠êÔ∏è &lt;strong&gt;AI Agents&lt;/strong&gt; for scheduling appointments&lt;/p&gt; 
&lt;p&gt;‚≠êÔ∏è &lt;strong&gt;Summarize Company PDFs&lt;/strong&gt; securely without data leaks&lt;/p&gt; 
&lt;p&gt;‚≠êÔ∏è &lt;strong&gt;Smarter Slack Bots&lt;/strong&gt; for enhanced company communications and IT operations&lt;/p&gt; 
&lt;p&gt;‚≠êÔ∏è &lt;strong&gt;Private Financial Document Analysis&lt;/strong&gt; at minimal cost&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Cloning the Repository&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git
cd self-hosted-ai-starter-kit
cp .env.example .env # you should update secrets and passwords inside
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running n8n using Docker Compose&lt;/h3&gt; 
&lt;h4&gt;For Nvidia GPU users&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git
cd self-hosted-ai-starter-kit
cp .env.example .env # you should update secrets and passwords inside
docker compose --profile gpu-nvidia up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you have not used your Nvidia GPU with Docker before, please follow the &lt;a href="https://github.com/ollama/ollama/raw/main/docs/docker.md"&gt;Ollama Docker instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;For AMD GPU users on Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git
cd self-hosted-ai-starter-kit
cp .env.example .env # you should update secrets and passwords inside
docker compose --profile gpu-amd up
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;For Mac / Apple Silicon users&lt;/h4&gt; 
&lt;p&gt;If you‚Äôre using a Mac with an M1 or newer processor, you can't expose your GPU to the Docker instance, unfortunately. There are two options in this case:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run the starter kit fully on CPU, like in the section "For everyone else" below&lt;/li&gt; 
 &lt;li&gt;Run Ollama on your Mac for faster inference, and connect to that from the n8n instance&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If you want to run Ollama on your mac, check the &lt;a href="https://ollama.com/"&gt;Ollama homepage&lt;/a&gt; for installation instructions, and run the starter kit as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git
cd self-hosted-ai-starter-kit
cp .env.example .env # you should update secrets and passwords inside
docker compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;For Mac users running OLLAMA locally&lt;/h5&gt; 
&lt;p&gt;If you're running OLLAMA locally on your Mac (not in Docker), you need to modify the OLLAMA_HOST environment variable&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Set OLLAMA_HOST to &lt;code&gt;host.docker.internal:11434&lt;/code&gt; in your .env file.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Additionally, after you see "Editor is now accessible via: &lt;a href="http://localhost:5678/"&gt;http://localhost:5678/&lt;/a&gt;":&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;Head to &lt;a href="http://localhost:5678/home/credentials"&gt;http://localhost:5678/home/credentials&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Click on "Local Ollama service"&lt;/li&gt; 
   &lt;li&gt;Change the base URL to "&lt;a href="http://host.docker.internal:11434/"&gt;http://host.docker.internal:11434/&lt;/a&gt;"&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;For everyone else&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git
cd self-hosted-ai-starter-kit
cp .env.example .env # you should update secrets and passwords inside
docker compose --profile cpu up
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ö°Ô∏è Quick start and usage&lt;/h2&gt; 
&lt;p&gt;The core of the Self-hosted AI Starter Kit is a Docker Compose file, pre-configured with network and storage settings, minimizing the need for additional installations. After completing the installation steps above, simply follow the steps below to get started.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:5678/"&gt;http://localhost:5678/&lt;/a&gt; in your browser to set up n8n. You‚Äôll only have to do this once.&lt;/li&gt; 
 &lt;li&gt;Open the included workflow: &lt;a href="http://localhost:5678/workflow/srOnR8PAY3u4RSwb"&gt;http://localhost:5678/workflow/srOnR8PAY3u4RSwb&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click the &lt;strong&gt;Chat&lt;/strong&gt; button at the bottom of the canvas, to start running the workflow.&lt;/li&gt; 
 &lt;li&gt;If this is the first time you‚Äôre running the workflow, you may need to wait until Ollama finishes downloading Llama3.2. You can inspect the docker console logs to check on the progress.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To open n8n at any time, visit &lt;a href="http://localhost:5678/"&gt;http://localhost:5678/&lt;/a&gt; in your browser.&lt;/p&gt; 
&lt;p&gt;With your n8n instance, you‚Äôll have access to over 400 integrations and a suite of basic and advanced AI nodes such as &lt;a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"&gt;AI Agent&lt;/a&gt;, &lt;a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.text-classifier/"&gt;Text classifier&lt;/a&gt;, and &lt;a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.information-extractor/"&gt;Information Extractor&lt;/a&gt; nodes. To keep everything local, just remember to use the Ollama node for your language model and Qdrant as your vector store.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This starter kit is designed to help you get started with self-hosted AI workflows. While it‚Äôs not fully optimized for production environments, it combines robust components that work well together for proof-of-concept projects. You can customize it to meet your specific needs&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Upgrading&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;h3&gt;For Nvidia GPU setups:&lt;/h3&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose --profile gpu-nvidia pull
docker compose create &amp;amp;&amp;amp; docker compose --profile gpu-nvidia up
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;h3&gt;For Mac / Apple Silicon users&lt;/h3&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose pull
docker compose create &amp;amp;&amp;amp; docker compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;h3&gt;For Non-GPU setups:&lt;/h3&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose --profile cpu pull
docker compose create &amp;amp;&amp;amp; docker compose --profile cpu up
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üëì Recommended reading&lt;/h2&gt; 
&lt;p&gt;n8n is full of useful content for getting started quickly with its AI concepts and nodes. If you run into an issue, go to &lt;a href="https://raw.githubusercontent.com/n8n-io/self-hosted-ai-starter-kit/main/#support"&gt;support&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://blog.n8n.io/ai-agents/"&gt;AI agents for developers: from theory to practice with n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/advanced-ai/intro-tutorial/"&gt;Tutorial: Build an AI workflow in n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/advanced-ai/langchain/langchain-n8n/"&gt;Langchain Concepts in n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/advanced-ai/examples/agent-chain-comparison/"&gt;Demonstration of key differences between agents and chains&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/advanced-ai/examples/understand-vector-databases/"&gt;What are vector databases?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üé• Video walkthrough&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=xz_X2N-hPg0"&gt;Installing and using Local AI for n8n&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõçÔ∏è More AI templates&lt;/h2&gt; 
&lt;p&gt;For more AI workflow ideas, visit the &lt;a href="https://n8n.io/workflows/categories/ai/"&gt;&lt;strong&gt;official n8n AI template gallery&lt;/strong&gt;&lt;/a&gt;. From each workflow, select the &lt;strong&gt;Use workflow&lt;/strong&gt; button to automatically import the workflow into your local n8n instance.&lt;/p&gt; 
&lt;h3&gt;Learn AI key concepts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/1954-ai-agent-chat/"&gt;AI Agent Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/2026-ai-chat-with-any-data-source-using-the-n8n-workflow-tool/"&gt;AI chat with any data source (using the n8n workflow too)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/2098-chat-with-openai-assistant-by-adding-a-memory/"&gt;Chat with OpenAI Assistant (by adding a memory)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/1980-use-an-open-source-llm-via-huggingface/"&gt;Use an open-source LLM (via Hugging Face)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/2165-chat-with-pdf-docs-using-ai-quoting-sources/"&gt;Chat with PDF docs using AI (quoting sources)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/2006-ai-agent-that-can-scrape-webpages/"&gt;AI agent that can scrape webpages&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local AI templates&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/2341-build-a-tax-code-assistant-with-qdrant-mistralai-and-openai/"&gt;Tax Code Assistant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/2339-breakdown-documents-into-study-notes-using-templating-mistralai-and-qdrant/"&gt;Breakdown Documents into Study Notes with MistralAI and Qdrant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/2335-build-a-financial-documents-assistant-using-qdrant-and-mistralai/"&gt;Financial Documents Assistant using Qdrant and&lt;/a&gt;&amp;nbsp;&lt;a href="http://mistral.ai/"&gt;Mistral.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/2333-recipe-recommendations-with-qdrant-and-mistral/"&gt;Recipe Recommendations with Qdrant and Mistral&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tips &amp;amp; tricks&lt;/h2&gt; 
&lt;h3&gt;Accessing local files&lt;/h3&gt; 
&lt;p&gt;The self-hosted AI starter kit will create a shared folder (by default, located in the same directory) which is mounted to the n8n container and allows n8n to access files on disk. This folder within the n8n container is located at &lt;code&gt;/data/shared&lt;/code&gt; -- this is the path you‚Äôll need to use in nodes that interact with the local filesystem.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Nodes that interact with the local filesystem&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.filesreadwrite/"&gt;Read/Write Files from Disk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger/"&gt;Local File Trigger&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand/"&gt;Execute Command&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìú&amp;nbsp;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/n8n-io/self-hosted-ai-starter-kit/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üí¨&amp;nbsp;Support&lt;/h2&gt; 
&lt;p&gt;Join the conversation in the &lt;a href="https://community.n8n.io/"&gt;n8n Forum&lt;/a&gt;, where you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Share Your Work&lt;/strong&gt;: Show off what you‚Äôve built with n8n and inspire others in the community.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ask Questions&lt;/strong&gt;: Whether you‚Äôre just getting started or you‚Äôre a seasoned pro, the community and our team are ready to support with any challenges.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Propose Ideas&lt;/strong&gt;: Have an idea for a feature or improvement? Let us know! We‚Äôre always eager to hear what you‚Äôd like to see next.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>PixiEditor/PixiEditor</title>
      <link>https://github.com/PixiEditor/PixiEditor</link>
      <description>&lt;p&gt;PixiEditor is a Universal Editor for all your 2D needs&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/flabbet/PixiEditor/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/flabbet/PixiEditor" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/flabbet/PixiEditor/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/PixiEditor/PixiEditor/total" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/qSRMYmq"&gt;&lt;img src="https://badgen.net/badge/discord/join%20chat/7289DA?icon=discord" alt="Discord Server" /&gt;&lt;/a&gt; &lt;a href="https://reddit.com/r/PixiEditor"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/PixiEditor?label=%20r%2FPixiEditor&amp;amp;logoColor=%23e3002d" alt="Subreddit subscribers" /&gt;&lt;/a&gt; &lt;a href="https://forum.pixieditor.net/"&gt;&lt;img src="https://img.shields.io/badge/PixiEditor-Forum-red?link=https%3A%2F%2Fforum.pixieditor.net%2F" alt="Forum" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;img width="50%" align="center" src="https://github.com/user-attachments/assets/bd08c8bd-f610-449d-b1e2-6a990e562518" /&gt; 
 &lt;h2&gt;The only 2D Graphics Editor you'll ever need&lt;/h2&gt; 
 &lt;p&gt;&lt;strong&gt;PixiEditor&lt;/strong&gt; is a universal 2D editor that was made to provide you with tools and features for all your 2D needs. Create beautiful sprites for your games, animations, edit images, create logos. All packed up in an intuitive and familiar interface.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pixieditor.net/download"&gt;&lt;img src="https://github.com/nnakocaj/supreme-train/raw/main/download1.png" width="250" alt="Download" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src="https://github.com/nnakocaj/supreme-train/raw/main/interface.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;Toolsets for any scenario&lt;/h3&gt; 
&lt;p&gt;PixiEditor 2.0 comes by default with 3 toolsets:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pixel art&lt;/strong&gt; - it contains tool suited for pixel-perfect scenarios&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Painting&lt;/strong&gt; - basic painting tools, soft brushes, anti aliased shapes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vector&lt;/strong&gt; - shapes and paths for creating vectors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All &lt;strong&gt;toolsets can be used on one canvas&lt;/strong&gt;. Mix vector with raster. Export to png, jpg, svg, gif, mp4 and more!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/nnakocaj/supreme-train/raw/main/toolsets.gif?raw=true" width="70%" /&gt; &lt;/p&gt; 
&lt;h3&gt;Animations&lt;/h3&gt; 
&lt;p&gt;Version 2.0 comes with a timeline and animation capabilities. You can create frame by frame animations or use nodes to animate your custom shaders. Key frame animations with vectors are on our roadmap.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nnakocaj/supreme-train/raw/main/timeline1.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;Nodes&lt;/h3&gt; 
&lt;p&gt;Node render system is what powers such extensive capabilities. All layers, effects and the layer structure are nodes or a result of its connections. PixiEditor exposes node graph for every document, so you are free to customize your image however you want and create procedural art/animations!&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nnakocaj/supreme-train/raw/main/node.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Building from source&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href="https://pixieditor.net/docs/contribution/compileguide/"&gt;Compile Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;For a seamless collaboration &lt;a href="https://pixieditor.net/docs/contribution/starthere//"&gt;Start Here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Help&lt;/h2&gt; 
&lt;p&gt;Got stuck? We are here to &lt;a href="https://pixieditor.net/help"&gt;Help&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://discord.gg/DwaXAuXVzv" target="_blank"&gt;&lt;img src="https://newsletter.pixieditor.net/uploads/discord.png" alt="discord" width="50/" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
 &lt;a href="https://store.steampowered.com/app/2218560/PixiEditor__Pixel_Art_Editor/" target="_blank"&gt;&lt;img src="https://newsletter.pixieditor.net/uploads/steam.png" alt="steam" width="50/" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
 &lt;a href="https://www.youtube.com/@PixiEditor" target="_blank"&gt;&lt;img src="https://newsletter.pixieditor.net/uploads/youtube.png" alt="youtube" width="50/" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
 &lt;a href="https://twitter.com/PixiEditor" target="_blank"&gt;&lt;img src="https://newsletter.pixieditor.net/uploads/twitter.png" alt="twitter" width="50/" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
 &lt;a href="https://www.reddit.com/r/PixiEditor" target="_blank"&gt;&lt;img src="https://newsletter.pixieditor.net/uploads/reddit.png" alt="reddit" width="50/" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
 &lt;a href="https://www.linkedin.com/company/pixieditor" target="_blank"&gt;&lt;img src="https://newsletter.pixieditor.net/uploads/linkedin.png" alt="linkedin" width="50/" /&gt;&lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>