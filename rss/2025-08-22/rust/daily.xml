<rss version="2.0">
  <channel>
    <title>GitHub Rust Daily Trending</title>
    <description>Daily Trending of Rust in GitHub</description>
    <pubDate>Thu, 21 Aug 2025 01:37:42 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>0xPlaygrounds/rig</title>
      <link>https://github.com/0xPlaygrounds/rig</link>
      <description>&lt;p&gt;‚öôÔ∏èü¶Ä Build modular and scalable LLM Applications in Rust&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="img/rig-playgrounds-dark.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="img/rig-playgrounds-light.svg" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/img/rig-playgrounds-light.svg?sanitize=true" style="width: 40%; height: 40%;" alt="Rig logo" /&gt; 
 &lt;/picture&gt; &lt;br /&gt; &lt;a href="https://docs.rig.rs"&gt;&lt;img src="https://img.shields.io/badge/üìñ docs-rig.rs-dca282.svg" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://docs.rs/rig-core/latest/rig/"&gt;&lt;img src="https://img.shields.io/badge/docs-API Reference-dca282.svg" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://crates.io/crates/rig-core"&gt;&lt;img src="https://img.shields.io/crates/v/rig-core.svg?color=dca282" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://crates.io/crates/rig-core"&gt;&lt;img src="https://img.shields.io/crates/d/rig-core.svg?color=dca282" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://discord.gg/playgrounds"&gt;&lt;img src="https://img.shields.io/discord/511303648119226382?color=%236d82cc&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/0xPlaygrounds/rig"&gt;&lt;img src="https://img.shields.io/github/stars/0xPlaygrounds/rig?style=social" alt="stars - rig" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href=""&gt;&lt;img src="https://img.shields.io/badge/built_with-Rust-dca282.svg?logo=rust" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitter.com/Playgrounds0x"&gt;&lt;img src="https://img.shields.io/twitter/follow/Playgrounds0x" /&gt;&lt;/a&gt; &amp;nbsp; &lt;br /&gt; &lt;/p&gt; &amp;nbsp; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://docs.rig.rs"&gt;üìë Docs&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://rig.rs"&gt;üåê Website&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://github.com/0xPlaygrounds/rig/issues/new"&gt;ü§ù Contribute&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://docs.rig.rs/guides"&gt;‚úçüèΩ Blogs&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;‚ú® If you would like to help spread the word about Rig, please consider starring the repo!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Here be dragons! As we plan to ship a torrent of features in the following months, future updates &lt;strong&gt;will&lt;/strong&gt; contain &lt;strong&gt;breaking changes&lt;/strong&gt;. With Rig evolving, we'll annotate changes and highlight migration paths as we encounter them.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#table-of-contents"&gt;Table of contents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#what-is-rig"&gt;What is Rig?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#high-level-features"&gt;High-level features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#who-is-using-rig-in-production"&gt;Who's using Rig in production?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#get-started"&gt;Get Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#simple-example"&gt;Simple example:&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#integrations"&gt;Integrations&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is Rig?&lt;/h2&gt; 
&lt;p&gt;Rig is a Rust library for building scalable, modular, and ergonomic &lt;strong&gt;LLM-powered&lt;/strong&gt; applications.&lt;/p&gt; 
&lt;p&gt;More information about this crate can be found in the &lt;a href="https://docs.rig.rs"&gt;official&lt;/a&gt; &amp;amp; &lt;a href="https://docs.rs/rig-core/latest/rig/"&gt;crate&lt;/a&gt; (API Reference) documentations.&lt;/p&gt; 
&lt;h2&gt;High-level features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Full support for LLM completion and embedding workflows&lt;/li&gt; 
 &lt;li&gt;Simple but powerful common abstractions over LLM providers (e.g. OpenAI, Cohere) and vector stores (e.g. MongoDB, SQlite, in-memory)&lt;/li&gt; 
 &lt;li&gt;Integrate LLMs in your app with minimal boilerplate&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Who is using Rig in production?&lt;/h2&gt; 
&lt;p&gt;Below is a non-exhaustive list of companies and people who are using Rig in production:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/firstbatchxyz/dkn-compute-node"&gt;Dria Compute Node&lt;/a&gt; - a node that serves computation results within the Dria Knowledge Network&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelcontextprotocol/rust-sdk"&gt;The MCP Rust SDK&lt;/a&gt; - the official Model Context Protocol Rust SDK. Has an example for usage with Rig.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/buger/probe"&gt;Probe&lt;/a&gt; - an AI-friendly, fully local semantic code search tool.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NethermindEth/nine"&gt;NINE&lt;/a&gt; - Neural Interconnected Nodes Engine, by &lt;a href="https://www.nethermind.io/"&gt;Nethermind.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/0xPlaygrounds/rig-onchain-kit"&gt;rig-onchain-kit&lt;/a&gt; - the Rig Onchain Kit. Intended to make interactions between Solana/EVM and Rig much easier to implement.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/linera-io/linera-protocol"&gt;Linera Protocol&lt;/a&gt; - Decentralized blockchain infrastructure designed for highly scalable, secure, low-latency Web3 applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/piotrostr/listen"&gt;Listen&lt;/a&gt; - A framework aiming to become the go-to framework for AI portfolio management agents. Powers &lt;a href="https://app.listen-rs.com/"&gt;the Listen app.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Are you also using Rig in production? &lt;a href="https://www.github.com/0xPlaygrounds/rig/issues"&gt;Open an issue&lt;/a&gt; to have your name added!&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo add rig-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Simple example:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use rig::{completion::Prompt, providers::openai};

#[tokio::main]
async fn main() {
    // Create OpenAI client and model
    // This requires the `OPENAI_API_KEY` environment variable to be set.
    let openai_client = openai::Client::from_env();

    let gpt4 = openai_client.agent("gpt-4").build();

    // Prompt the model and print its response
    let response = gpt4
        .prompt("Who are you?")
        .await
        .expect("Failed to prompt GPT-4");

    println!("GPT-4: {response}");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note using &lt;code&gt;#[tokio::main]&lt;/code&gt; requires you enable tokio's &lt;code&gt;macros&lt;/code&gt; and &lt;code&gt;rt-multi-thread&lt;/code&gt; features or just &lt;code&gt;full&lt;/code&gt; to enable all features (&lt;code&gt;cargo add tokio --features macros,rt-multi-thread&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;You can find more examples each crate's &lt;code&gt;examples&lt;/code&gt; (ie. &lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/rig-core/examples"&gt;&lt;code&gt;rig-core/examples&lt;/code&gt;&lt;/a&gt;) directory. More detailed use cases walkthroughs are regularly published on our &lt;a href="https://dev.to/0thtachi"&gt;Dev.to Blog&lt;/a&gt; and added to Rig's official documentation &lt;a href="http://docs.rig.rs"&gt;(docs.rig.rs)&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Supported Integrations&lt;/h2&gt; 
&lt;p&gt;Vector stores are available as separate companion-crates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MongoDB: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-mongodb"&gt;&lt;code&gt;rig-mongodb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;LanceDB: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-lancedb"&gt;&lt;code&gt;rig-lancedb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Neo4j: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-neo4j"&gt;&lt;code&gt;rig-neo4j&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Qdrant: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-qdrant"&gt;&lt;code&gt;rig-qdrant&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SQLite: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-sqlite"&gt;&lt;code&gt;rig-sqlite&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SurrealDB: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-surrealdb"&gt;&lt;code&gt;rig-surrealdb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Milvus: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-milvus"&gt;&lt;code&gt;rig-milvus&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ScyllaDB: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-scylladb"&gt;&lt;code&gt;rig-scylladb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;AWS S3Vectors: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-s3vectors"&gt;&lt;code&gt;rig-s3vectors&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following providers are available as separate companion-crates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fastembed: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-fastembed"&gt;&lt;code&gt;rig-fastembed&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Eternal AI: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-eternalai"&gt;&lt;code&gt;rig-eternalai&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;br /&gt; &lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/img/built-by-playgrounds.svg?sanitize=true" alt="Build by Playgrounds" width="30%" /&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zama-ai/fhevm</title>
      <link>https://github.com/zama-ai/fhevm</link>
      <description>&lt;p&gt;FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/.gitbook/assets/fhevm-header-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/.gitbook/assets/fhevm-header-light.png" /&gt; 
  &lt;img width="500" alt="fhevm" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/fhevm-whitepaper.pdf"&gt; üìÉ Read white paper&lt;/a&gt; |&lt;a href="https://docs.zama.ai/protocol"&gt; üìí Documentation&lt;/a&gt; | &lt;a href="https://zama.ai/community"&gt; üíõ Community support&lt;/a&gt; | &lt;a href="https://github.com/zama-ai/awesome-zama"&gt; üìö FHE resources by Zama&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/zama-ai/fhevm/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/zama-ai/fhevm?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zama-ai/fhevm/raw/main/LICENSE"&gt; 
  &lt;!-- markdown-link-check-disable-next-line --&gt; &lt;img src="https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zama-ai/bounty-program"&gt; 
  &lt;!-- markdown-link-check-disable-next-line --&gt; &lt;img src="https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img alt="SLSA 3" src="https://slsa.dev/images/gh-badge-level3.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;h3&gt;What is FHEVM?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;FHEVM&lt;/strong&gt; is the core framework of the &lt;em&gt;Zama Confidential Blockchain Protocol&lt;/em&gt;. It enables confidential smart contracts on EVM-compatible blockchains by leveraging Fully Homomorphic Encryption (FHE), allowing encrypted data to be processed directly onchain.&lt;/p&gt; 
&lt;p&gt;FHEVM ensures both confidentiality and composability, with the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end encryption of transactions and state:&lt;/strong&gt; Data included in transactions is encrypted and never visible to anyone.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Composability and data availability on-chain:&lt;/strong&gt; States are updated while remaining encrypted at all times.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No impact on existing dApps and state:&lt;/strong&gt; Encrypted state co-exists alongside public one, and doesn't impact existing dApps. &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Table of contents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt;About&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#what-is-fhevm"&gt;What is FHEVM?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#project-structure"&gt;Project structure&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#main-features"&gt;Main features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#use-cases"&gt;Use cases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#working-with-fhevm"&gt;Working with FHEVM&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#citations"&gt;Citations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#support"&gt;Support&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Project structure&lt;/h3&gt; 
&lt;p&gt;The directories of this repository are organized in the following way:&lt;/p&gt; 
&lt;h6&gt;FHEVM Contracts&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;gateway-contracts/&lt;/code&gt;&lt;/strong&gt;: Smart contracts managing the gateway between on-chain and off-chain components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;host-contracts/&lt;/code&gt;&lt;/strong&gt;: Smart Contracts deployed on the host chain for orchestrating FHE workflows.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;FHEVM Compute Engines&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;coprocessor/&lt;/code&gt;&lt;/strong&gt;: Rust-based coprocessor implementation for FHE operations.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;kms-connector/&lt;/code&gt;&lt;/strong&gt;: Interface for integrating with Key Management Services (KMS) to handle encryption keys securely.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;FHEVM Utilities&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;charts/&lt;/code&gt;&lt;/strong&gt;: Helm charts and deployment configurations for the stack.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;golden-container-images/&lt;/code&gt;&lt;/strong&gt;: Docker golden images for Node.js and Rust environments used as base images by the stack.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;test-suite/&lt;/code&gt;&lt;/strong&gt;: Integration with docker-compose and tests covering end-to-end FHEVM stack behavior.&lt;/p&gt; &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Main features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy by design:&lt;/strong&gt; Building decentralized apps with full privacy and confidentiality on Ethereum, leveraging FHE.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solidity integration:&lt;/strong&gt; Write FHEVM contracts like any standard Solidity contract using Solidity. Compatible with existing toolchains ‚Äî such as Hardhat and Foundry (&lt;em&gt;coming soon&lt;/em&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Programmable privacy:&lt;/strong&gt; Define exactly what data is encrypted and write the access control logic directly in your smart contracts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High precision encrypted integers :&lt;/strong&gt; Up to 256 bits of precision for integers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full range of operators:&lt;/strong&gt; All typical operators are available: &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;, ternary-if, boolean operations‚Ä¶. Consecutive FHE operations are not limited.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security:&lt;/strong&gt; The underlying FHE crypto-scheme of FHEVM is quantum-resistant. Decryption is managed via a key management system (KMS) using multi-party computation (MPC), ensuring security even if some parties are compromised or misbehaving.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Symbolic execution of FHE computations:&lt;/strong&gt; All FHE operations are executed symbolically on the host chain, significantly reducing execution time. The actual computations on encrypted data are offloaded asynchronously to our coprocessor, allowing for faster, efficient, and scalable processing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Learn more about FHEVM features in the &lt;a href="https://docs.zama.ai/protocol"&gt;documentation&lt;/a&gt; and in our &lt;a href="https://github.com/zama-ai/fhevm/raw/main/fhevm-whitepaper.pdf"&gt;whitepaper&lt;/a&gt;.&lt;/em&gt; &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Use cases&lt;/h3&gt; 
&lt;p&gt;FHEVM is built for developers to write confidential smart contracts without the need to learn cryptography. Leveraging FHEVM, you can unlock a myriad of new use cases such as DeFi, gaming, and more. For instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Confidential transfers&lt;/strong&gt;: Keep balances and amounts private, without using mixers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tokenization&lt;/strong&gt;: Swap tokens and RWAs on-chain without others seeing the amounts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Blind auctions&lt;/strong&gt;: Bid on items without revealing the amount or the winner.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-chain games&lt;/strong&gt;: Keep moves, selections, cards, or items hidden until ready to reveal.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Confidential voting&lt;/strong&gt;: Prevents bribery and blackmailing by keeping votes private.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Encrypted DIDs&lt;/strong&gt;: Store identities on-chain and generate attestations without ZK.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Learn more use cases in the &lt;a href="https://docs.zama.ai/protocol/examples"&gt;list of examples&lt;/a&gt;.&lt;/em&gt; &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.zama.ai/protocol"&gt;Documentation&lt;/a&gt; ‚Äî Official documentation of FHEVM.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/fhevm-whitepaper.pdf"&gt;Whitepaper&lt;/a&gt; ‚Äî Technical overview of FHEVM's cryptographic design.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.zama.ai/protocol/examples"&gt;Examples&lt;/a&gt; ‚Äî Examples of building confidential smart contracts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zama-ai/awesome-zama?tab=readme-ov-file#fhevm"&gt;Awesome Zama ‚Äì FHEVM&lt;/a&gt; ‚Äî Curated articles, talks, and ecosystem projects.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt; ‚Üë Back to top &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Working with FHEVM&lt;/h2&gt; 
&lt;h3&gt;Citations&lt;/h3&gt; 
&lt;p&gt;To cite FHEVM or the whitepaper in academic papers, please use the following entries:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;@Misc{FHEVM,
title={{FHEVM: A full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications},
author={Zama},
year={2025},
note={\url{https://github.com/zama-ai/fhevm}},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;There are two ways to contribute to FHEVM:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zama-ai/fhevm/issues/new/choose"&gt;Open issues&lt;/a&gt; to report bugs and typos, or to suggest new ideas&lt;/li&gt; 
 &lt;li&gt;Request to become an official contributor by emailing &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do! &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;This software is distributed under the &lt;strong&gt;BSD-3-Clause-Clear&lt;/strong&gt; license. Read &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/LICENSE"&gt;this&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Is Zama‚Äôs technology free to use?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Zama‚Äôs libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama's open source code, companies must purchase Zama‚Äôs commercial patent license.&lt;/p&gt; 
 &lt;p&gt;Everything we do is open source, and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in &lt;a href="https://www.zama.ai/post/open-source"&gt;this blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;What do I need to do if I want to use Zama‚Äôs technology for commercial purposes?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To commercially use Zama‚Äôs technology you need to be granted Zama‚Äôs patent license. Please contact us at &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Do you file IP on your technology?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Yes, all Zama‚Äôs technologies are patented.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Can you customize a solution for my specific use case?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;a target="_blank" href="https://community.zama.ai"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/.gitbook/assets/support-banner-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/.gitbook/assets/support-banner-light.png" /&gt; 
  &lt;img alt="Support" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;üåü If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development.&lt;/p&gt; 
&lt;p align="right"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt; ‚Üë Back to top &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zed-industries/zed</title>
      <link>https://github.com/zed-industries/zed</link>
      <description>&lt;p&gt;Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Zed&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://zed.dev"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json" alt="Zed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zed-industries/zed/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/zed-industries/zed/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Welcome to Zed, a high-performance, multiplayer code editor from the creators of &lt;a href="https://github.com/atom/atom"&gt;Atom&lt;/a&gt; and &lt;a href="https://github.com/tree-sitter/tree-sitter"&gt;Tree-sitter&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;On macOS and Linux you can &lt;a href="https://zed.dev/download"&gt;download Zed directly&lt;/a&gt; or &lt;a href="https://zed.dev/docs/linux#installing-via-a-package-manager"&gt;install Zed via your local package manager&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Other platforms are not yet available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows (&lt;a href="https://github.com/zed-industries/zed/issues/5394"&gt;tracking issue&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Web (&lt;a href="https://github.com/zed-industries/zed/issues/5396"&gt;tracking issue&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developing Zed&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/macos.md"&gt;Building Zed for macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/linux.md"&gt;Building Zed for Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/windows.md"&gt;Building Zed for Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/local-collaboration.md"&gt;Running Collaboration Locally&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for ways you can contribute to Zed.&lt;/p&gt; 
&lt;p&gt;Also... we're hiring! Check out our &lt;a href="https://zed.dev/jobs"&gt;jobs&lt;/a&gt; page for open roles.&lt;/p&gt; 
&lt;h3&gt;Licensing&lt;/h3&gt; 
&lt;p&gt;License information for third party dependencies must be correctly provided for CI to pass.&lt;/p&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/EmbarkStudios/cargo-about"&gt;&lt;code&gt;cargo-about&lt;/code&gt;&lt;/a&gt; to automatically comply with open source licenses. If CI is failing, check the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Is it showing a &lt;code&gt;no license specified&lt;/code&gt; error for a crate you've created? If so, add &lt;code&gt;publish = false&lt;/code&gt; under &lt;code&gt;[package]&lt;/code&gt; in your crate's Cargo.toml.&lt;/li&gt; 
 &lt;li&gt;Is the error &lt;code&gt;failed to satisfy license requirements&lt;/code&gt; for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license's requirements. If you're unsure, ask a lawyer. Once you've verified that this system is acceptable add the license's SPDX identifier to the &lt;code&gt;accepted&lt;/code&gt; array in &lt;code&gt;script/licenses/zed-licenses.toml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Is &lt;code&gt;cargo-about&lt;/code&gt; unable to find the license for a dependency? If so, add a clarification field at the end of &lt;code&gt;script/licenses/zed-licenses.toml&lt;/code&gt;, as specified in the &lt;a href="https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration"&gt;cargo-about book&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ai-dynamo/dynamo</title>
      <link>https://github.com/ai-dynamo/dynamo</link>
      <description>&lt;p&gt;A Datacenter Scale Distributed Inference Serving Framework&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-banner.png" alt="Dynamo banner" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ai-dynamo/dynamo/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/ai-dynamo/dynamo" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/D92uqZRjCZ"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ai-dynamo/dynamo"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/issues/762"&gt;Roadmap&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://docs.nvidia.com/dynamo/latest/index.html"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/tree/main/examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/enhancements"&gt;Design Proposals&lt;/a&gt;&lt;/strong&gt; |&lt;/p&gt; 
&lt;h1&gt;NVIDIA Dynamo&lt;/h1&gt; 
&lt;p&gt;High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.&lt;/p&gt; 
&lt;h2&gt;Latest News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[08/05] Deploy &lt;code&gt;openai/gpt-oss-120b&lt;/code&gt; with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/trtllm/gpt-oss.md"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;The Era of Multi-GPU, Multi-Node&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-gpu-vertical.png" alt="Multi Node Multi-GPU topology" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs‚Äîand sometimes many servers‚Äîbut it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.&lt;/p&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Disaggregated prefill &amp;amp; decode inference&lt;/strong&gt; ‚Äì Maximizes GPU throughput and facilitates trade off between throughput and latency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic GPU scheduling&lt;/strong&gt; ‚Äì Optimizes performance based on fluctuating demand&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-aware request routing&lt;/strong&gt; ‚Äì Eliminates unnecessary KV cache re-computation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accelerated data transfer&lt;/strong&gt; ‚Äì Reduces inference response time using NIXL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;KV cache offloading&lt;/strong&gt; ‚Äì Leverages multiple memory hierarchies for higher system throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-architecture.png" alt="Dynamo architecture" width="600" /&gt; &lt;/p&gt; 
&lt;h2&gt;Framework Support Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;vLLM&lt;/th&gt; 
   &lt;th&gt;SGLang&lt;/th&gt; 
   &lt;th&gt;TensorRT-LLM&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/disagg_serving.md"&gt;&lt;strong&gt;Disaggregated Serving&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/disagg_serving.md#conditional-disaggregation"&gt;&lt;strong&gt;Conditional Disaggregation&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/kv_cache_routing.md"&gt;&lt;strong&gt;KV-Aware Routing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/load_planner.md"&gt;&lt;strong&gt;Load Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/sla_planner.md"&gt;&lt;strong&gt;SLA-Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/kvbm_architecture.md"&gt;&lt;strong&gt;KVBM&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about each framework and their capabilities, check out each framework's README!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/vllm/README.md"&gt;vLLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/sglang/README.md"&gt;SGLang&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/trtllm/README.md"&gt;TensorRT-LLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;The following examples require a few system level packages. Recommended to use Ubuntu 24.04 with a x86_64 CPU. See &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/support_matrix.md"&gt;docs/support_matrix.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;1. Initial setup&lt;/h2&gt; 
&lt;p&gt;The Dynamo team recommends the &lt;code&gt;uv&lt;/code&gt; Python package manager, although any way works. Install uv:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install etcd and NATS (required)&lt;/h3&gt; 
&lt;p&gt;To coordinate across a data center, Dynamo relies on etcd and NATS. To run Dynamo locally, these need to be available.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; can be run directly as &lt;code&gt;./etcd&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nats.io/"&gt;nats&lt;/a&gt; needs jetstream enabled: &lt;code&gt;nats-server -js&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To quickly setup etcd &amp;amp; NATS, you can also run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# At the root of the repository:
docker compose -f deploy/docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;2. Select an engine&lt;/h2&gt; 
&lt;p&gt;We publish Python wheels specialized for each of our supported engines: vllm, sglang, trtllm, and llama.cpp. The examples that follow use SGLang; continue reading for other engines.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install "ai-dynamo[sglang]"  #replace with [vllm], [trtllm], etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Run Dynamo&lt;/h2&gt; 
&lt;h3&gt;Running an LLM API server&lt;/h3&gt; 
&lt;p&gt;Dynamo provides a simple way to spin up a local set of inference components including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI Compatible Frontend&lt;/strong&gt; ‚Äì High performance OpenAI compatible http api server written in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic and Kv Aware Router&lt;/strong&gt; ‚Äì Route and load balance traffic to a set of workers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt; ‚Äì Set of pre-configured LLM serving engines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
python -m dynamo.frontend --http-port 8080 [--tls-cert-path cert.pem] [--tls-key-path key.pem]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang.worker --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B --skip-tokenizer-init
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send a Request&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl localhost:8080/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "messages": [
    {
        "role": "user",
        "content": "Hello, how are you?"
    }
    ],
    "stream":false,
    "max_tokens": 300
  }' | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Rerun with &lt;code&gt;curl -N&lt;/code&gt; and change &lt;code&gt;stream&lt;/code&gt; in the request to &lt;code&gt;true&lt;/code&gt; to get the responses as soon as the engine issues them.&lt;/p&gt; 
&lt;h3&gt;Deploying Dynamo&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/guides/dynamo_deploy/README.md"&gt;Quickstart Guide&lt;/a&gt; to deploy on Kubernetes.&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends"&gt;Backends&lt;/a&gt; to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)&lt;/li&gt; 
 &lt;li&gt;Run some &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples"&gt;Examples&lt;/a&gt; to learn about building components in Dynamo and exploring various integrations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Engines&lt;/h1&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (&lt;code&gt;python -m dynamo.frontend [--interactive]&lt;/code&gt;).&lt;/p&gt; 
&lt;h2&gt;vLLM&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[vllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.vllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass &lt;code&gt;--context-length &amp;lt;value&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;SGLang&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.sglang.worker --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can pass any sglang flags directly to this worker, see &lt;a href="https://docs.sglang.ai/advanced_features/server_arguments.html"&gt;https://docs.sglang.ai/advanced_features/server_arguments.html&lt;/a&gt; . See there to use multiple GPUs.&lt;/p&gt; 
&lt;h2&gt;TensorRT-LLM&lt;/h2&gt; 
&lt;p&gt;It is recommended to use &lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch"&gt;NGC PyTorch Container&lt;/a&gt; for running the TensorRT-LLM engine.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using. For example, if you are using &lt;code&gt;tensorrt-llm==1.0.0rc4&lt;/code&gt;, use the PyTorch container image version &lt;code&gt;25.05&lt;/code&gt;. To find the correct PyTorch container version for your desired &lt;code&gt;tensorrt-llm&lt;/code&gt; release, visit the &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/docker/Dockerfile.multi"&gt;TensorRT-LLM Dockerfile.multi&lt;/a&gt; on GitHub. Switch to the branch that matches your &lt;code&gt;tensorrt-llm&lt;/code&gt; version, and look for the &lt;code&gt;BASE_TAG&lt;/code&gt; line to identify the recommended PyTorch container tag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] Launch container with the following additional settings &lt;code&gt;--shm-size=1g --ulimit memlock=-1&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Install prerequisites&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install "cuda-python&amp;gt;=12,&amp;lt;13"

sudo apt-get -y install libopenmpi-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Tip] You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation &lt;a href="https://nvidia.github.io/TensorRT-LLM/installation/linux.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;After installing the pre-requisites above, install Dynamo&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[trtllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.trtllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Developing Locally&lt;/h1&gt; 
&lt;h2&gt;1. Install libraries&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Ubuntu:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# if brew is not installed on your system, install it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If Metal is accessible, you should see an error like &lt;code&gt;metal: error: no input files&lt;/code&gt;, which confirms it is installed correctly.&lt;/p&gt; 
&lt;h2&gt;2. Install Rust&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Create a Python virtual env:&lt;/h2&gt; 
&lt;p&gt;Follow the instructions in &lt;a href="https://docs.astral.sh/uv/#installation"&gt;uv installation&lt;/a&gt; guide to install uv if you don't have &lt;code&gt;uv&lt;/code&gt; installed. Once uv is installed, create a virtual environment and activate it.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv dynamo
source dynamo/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Install build tools&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install pip maturin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/PyO3/maturin"&gt;Maturin&lt;/a&gt; is the Rust&amp;lt;-&amp;gt;Python bindings build tool.&lt;/p&gt; 
&lt;h2&gt;5. Build the Rust bindings&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd lib/bindings/python
maturin develop --uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;6. Install the wheel&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd $PROJECT_ROOT
uv pip install .
# For development, use
export PYTHONPATH="${PYTHONPATH}:$(pwd)/components/frontend/src:$(pwd)/components/planner/src:$(pwd)/components/backends/vllm/src:$(pwd)/components/backends/sglang/src:$(pwd)/components/backends/trtllm/src:$(pwd)/components/backends/llama_cpp/src:$(pwd)/components/backends/mocker/src"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Editable (&lt;code&gt;-e&lt;/code&gt;) does not work because the &lt;code&gt;dynamo&lt;/code&gt; package is split over multiple directories, one per backend.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You should now be able to run &lt;code&gt;python -m dynamo.frontend&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Remember that nats and etcd must be running (see earlier).&lt;/p&gt; 
&lt;p&gt;Set the environment variable &lt;code&gt;DYN_LOG&lt;/code&gt; to adjust the logging level; for example, &lt;code&gt;export DYN_LOG=debug&lt;/code&gt;. It has the same syntax as &lt;code&gt;RUST_LOG&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use vscode or cursor, we have a .devcontainer folder built on &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers"&gt;Microsofts Extension&lt;/a&gt;. For instructions see the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/.devcontainer/README.md"&gt;ReadMe&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sharkdp/fd</title>
      <link>https://github.com/sharkdp/fd</link>
      <description>&lt;p&gt;A simple, fast and user-friendly alternative to 'find'&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;fd&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/sharkdp/fd/actions/workflows/CICD.yml"&gt;&lt;img src="https://github.com/sharkdp/fd/actions/workflows/CICD.yml/badge.svg?sanitize=true" alt="CICD" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/fd-find"&gt;&lt;img src="https://img.shields.io/crates/v/fd-find.svg?sanitize=true" alt="Version info" /&gt;&lt;/a&gt; [&lt;a href="https://github.com/cha0ran/fd-zh"&gt;‰∏≠Êñá&lt;/a&gt;] [&lt;a href="https://github.com/spearkkk/fd-kor"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;]&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;fd&lt;/code&gt; is a program to find entries in your filesystem. It is a simple, fast and user-friendly alternative to &lt;a href="https://www.gnu.org/software/findutils/"&gt;&lt;code&gt;find&lt;/code&gt;&lt;/a&gt;. While it does not aim to support all of &lt;code&gt;find&lt;/code&gt;'s powerful functionality, it provides sensible (opinionated) defaults for a majority of use cases.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/sharkdp/fd/master/#installation"&gt;Installation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/sharkdp/fd/master/#how-to-use"&gt;How to use&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/sharkdp/fd/master/#troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Intuitive syntax: &lt;code&gt;fd PATTERN&lt;/code&gt; instead of &lt;code&gt;find -iname '*PATTERN*'&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Regular expression (default) and glob-based patterns.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sharkdp/fd/master/#benchmark"&gt;Very fast&lt;/a&gt; due to parallelized directory traversal.&lt;/li&gt; 
 &lt;li&gt;Uses colors to highlight different file types (same as &lt;code&gt;ls&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Supports &lt;a href="https://raw.githubusercontent.com/sharkdp/fd/master/#command-execution"&gt;parallel command execution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Smart case: the search is case-insensitive by default. It switches to case-sensitive if the pattern contains an uppercase character&lt;a href="http://vimdoc.sourceforge.net/htmldoc/options.html#'smartcase'"&gt;*&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Ignores hidden directories and files, by default.&lt;/li&gt; 
 &lt;li&gt;Ignores patterns from your &lt;code&gt;.gitignore&lt;/code&gt;, by default.&lt;/li&gt; 
 &lt;li&gt;The command name is &lt;em&gt;50%&lt;/em&gt; shorter&lt;a href="https://github.com/ggreer/the_silver_searcher"&gt;*&lt;/a&gt; than &lt;code&gt;find&lt;/code&gt; :-).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sharkdp/fd/master/doc/screencast.svg?sanitize=true" alt="Demo" /&gt;&lt;/p&gt; 
&lt;h2&gt;How to use&lt;/h2&gt; 
&lt;p&gt;First, to get an overview of all available command line options, you can either run &lt;a href="https://raw.githubusercontent.com/sharkdp/fd/master/#command-line-options"&gt;&lt;code&gt;fd -h&lt;/code&gt;&lt;/a&gt; for a concise help message or &lt;code&gt;fd --help&lt;/code&gt; for a more detailed version.&lt;/p&gt; 
&lt;h3&gt;Simple search&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;fd&lt;/em&gt; is designed to find entries in your filesystem. The most basic search you can perform is to run &lt;em&gt;fd&lt;/em&gt; with a single argument: the search pattern. For example, assume that you want to find an old script of yours (the name included &lt;code&gt;netflix&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd netfl
Software/python/imdb-ratings/netflix-details.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If called with just a single argument like this, &lt;em&gt;fd&lt;/em&gt; searches the current directory recursively for any entries that &lt;em&gt;contain&lt;/em&gt; the pattern &lt;code&gt;netfl&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Regular expression search&lt;/h3&gt; 
&lt;p&gt;The search pattern is treated as a regular expression. Here, we search for entries that start with &lt;code&gt;x&lt;/code&gt; and end with &lt;code&gt;rc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; cd /etc
&amp;gt; fd '^x.*rc$'
X11/xinit/xinitrc
X11/xinit/xserverrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The regular expression syntax used by &lt;code&gt;fd&lt;/code&gt; is &lt;a href="https://docs.rs/regex/latest/regex/#syntax"&gt;documented here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Specifying the root directory&lt;/h3&gt; 
&lt;p&gt;If we want to search a specific directory, it can be given as a second argument to &lt;em&gt;fd&lt;/em&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd passwd /etc
/etc/default/passwd
/etc/pam.d/passwd
/etc/passwd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List all files, recursively&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;fd&lt;/em&gt; can be called with no arguments. This is very useful to get a quick overview of all entries in the current directory, recursively (similar to &lt;code&gt;ls -R&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; cd fd/tests
&amp;gt; fd
testenv
testenv/mod.rs
tests.rs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to use this functionality to list all files in a given directory, you have to use a catch-all pattern such as &lt;code&gt;.&lt;/code&gt; or &lt;code&gt;^&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd . fd/tests/
testenv
testenv/mod.rs
tests.rs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Searching for a particular file extension&lt;/h3&gt; 
&lt;p&gt;Often, we are interested in all files of a particular type. This can be done with the &lt;code&gt;-e&lt;/code&gt; (or &lt;code&gt;--extension&lt;/code&gt;) option. Here, we search for all Markdown files in the fd repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; cd fd
&amp;gt; fd -e md
CONTRIBUTING.md
README.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;-e&lt;/code&gt; option can be used in combination with a search pattern:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -e rs mod
src/fshelper/mod.rs
src/lscolors/mod.rs
tests/testenv/mod.rs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Searching for a particular file name&lt;/h3&gt; 
&lt;p&gt;To find files with exactly the provided search pattern, use the &lt;code&gt;-g&lt;/code&gt; (or &lt;code&gt;--glob&lt;/code&gt;) option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -g libc.so /usr
/usr/lib32/libc.so
/usr/lib/libc.so
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hidden and ignored files&lt;/h3&gt; 
&lt;p&gt;By default, &lt;em&gt;fd&lt;/em&gt; does not search hidden directories and does not show hidden files in the search results. To disable this behavior, we can use the &lt;code&gt;-H&lt;/code&gt; (or &lt;code&gt;--hidden&lt;/code&gt;) option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd pre-commit
&amp;gt; fd -H pre-commit
.git/hooks/pre-commit.sample
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If we work in a directory that is a Git repository (or includes Git repositories), &lt;em&gt;fd&lt;/em&gt; does not search folders (and does not show files) that match one of the &lt;code&gt;.gitignore&lt;/code&gt; patterns. To disable this behavior, we can use the &lt;code&gt;-I&lt;/code&gt; (or &lt;code&gt;--no-ignore&lt;/code&gt;) option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd num_cpu
&amp;gt; fd -I num_cpu
target/debug/deps/libnum_cpus-f5ce7ef99006aa05.rlib
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To really search &lt;em&gt;all&lt;/em&gt; files and directories, simply combine the hidden and ignore features to show everything (&lt;code&gt;-HI&lt;/code&gt;) or use &lt;code&gt;-u&lt;/code&gt;/&lt;code&gt;--unrestricted&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Matching the full path&lt;/h3&gt; 
&lt;p&gt;By default, &lt;em&gt;fd&lt;/em&gt; only matches the filename of each file. However, using the &lt;code&gt;--full-path&lt;/code&gt; or &lt;code&gt;-p&lt;/code&gt; option, you can match against the full path.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -p -g '**/.git/config'
&amp;gt; fd -p '.*/lesson-\d+/[a-z]+.(jpg|png)'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Command execution&lt;/h3&gt; 
&lt;p&gt;Instead of just showing the search results, you often want to &lt;em&gt;do something&lt;/em&gt; with them. &lt;code&gt;fd&lt;/code&gt; provides two ways to execute external commands for each of your search results:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;-x&lt;/code&gt;/&lt;code&gt;--exec&lt;/code&gt; option runs an external command &lt;em&gt;for each of the search results&lt;/em&gt; (in parallel).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;-X&lt;/code&gt;/&lt;code&gt;--exec-batch&lt;/code&gt; option launches the external command once, with &lt;em&gt;all search results as arguments&lt;/em&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Examples&lt;/h4&gt; 
&lt;p&gt;Recursively find all zip archives and unpack them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fd -e zip -x unzip
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If there are two such files, &lt;code&gt;file1.zip&lt;/code&gt; and &lt;code&gt;backup/file2.zip&lt;/code&gt;, this would execute &lt;code&gt;unzip file1.zip&lt;/code&gt; and &lt;code&gt;unzip backup/file2.zip&lt;/code&gt;. The two &lt;code&gt;unzip&lt;/code&gt; processes run in parallel (if the files are found fast enough).&lt;/p&gt; 
&lt;p&gt;Find all &lt;code&gt;*.h&lt;/code&gt; and &lt;code&gt;*.cpp&lt;/code&gt; files and auto-format them inplace with &lt;code&gt;clang-format -i&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fd -e h -e cpp -x clang-format -i
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note how the &lt;code&gt;-i&lt;/code&gt; option to &lt;code&gt;clang-format&lt;/code&gt; can be passed as a separate argument. This is why we put the &lt;code&gt;-x&lt;/code&gt; option last.&lt;/p&gt; 
&lt;p&gt;Find all &lt;code&gt;test_*.py&lt;/code&gt; files and open them in your favorite editor:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fd -g 'test_*.py' -X vim
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that we use capital &lt;code&gt;-X&lt;/code&gt; here to open a single &lt;code&gt;vim&lt;/code&gt; instance. If there are two such files, &lt;code&gt;test_basic.py&lt;/code&gt; and &lt;code&gt;lib/test_advanced.py&lt;/code&gt;, this will run &lt;code&gt;vim test_basic.py lib/test_advanced.py&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To see details like file permissions, owners, file sizes etc., you can tell &lt;code&gt;fd&lt;/code&gt; to show them by running &lt;code&gt;ls&lt;/code&gt; for each result:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fd ‚Ä¶ -X ls -lhd --color=always
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This pattern is so useful that &lt;code&gt;fd&lt;/code&gt; provides a shortcut. You can use the &lt;code&gt;-l&lt;/code&gt;/&lt;code&gt;--list-details&lt;/code&gt; option to execute &lt;code&gt;ls&lt;/code&gt; in this way: &lt;code&gt;fd ‚Ä¶ -l&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;-X&lt;/code&gt; option is also useful when combining &lt;code&gt;fd&lt;/code&gt; with &lt;a href="https://github.com/BurntSushi/ripgrep/"&gt;ripgrep&lt;/a&gt; (&lt;code&gt;rg&lt;/code&gt;) in order to search within a certain class of files, like all C++ source files:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fd -e cpp -e cxx -e h -e hpp -X rg 'std::cout'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Convert all &lt;code&gt;*.jpg&lt;/code&gt; files to &lt;code&gt;*.png&lt;/code&gt; files:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fd -e jpg -x convert {} {.}.png
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here, &lt;code&gt;{}&lt;/code&gt; is a placeholder for the search result. &lt;code&gt;{.}&lt;/code&gt; is the same, without the file extension. See below for more details on the placeholder syntax.&lt;/p&gt; 
&lt;p&gt;The terminal output of commands run from parallel threads using &lt;code&gt;-x&lt;/code&gt; will not be interlaced or garbled, so &lt;code&gt;fd -x&lt;/code&gt; can be used to rudimentarily parallelize a task run over many files. An example of this is calculating the checksum of each individual file within a directory.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fd -tf -x md5sum &amp;gt; file_checksums.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Placeholder syntax&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;-x&lt;/code&gt; and &lt;code&gt;-X&lt;/code&gt; options take a &lt;em&gt;command template&lt;/em&gt; as a series of arguments (instead of a single string). If you want to add additional options to &lt;code&gt;fd&lt;/code&gt; after the command template, you can terminate it with a &lt;code&gt;\;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The syntax for generating commands is similar to that of &lt;a href="https://www.gnu.org/software/parallel/"&gt;GNU Parallel&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;{}&lt;/code&gt;: A placeholder token that will be replaced with the path of the search result (&lt;code&gt;documents/images/party.jpg&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;{.}&lt;/code&gt;: Like &lt;code&gt;{}&lt;/code&gt;, but without the file extension (&lt;code&gt;documents/images/party&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;{/}&lt;/code&gt;: A placeholder that will be replaced by the basename of the search result (&lt;code&gt;party.jpg&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;{//}&lt;/code&gt;: The parent of the discovered path (&lt;code&gt;documents/images&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;{/.}&lt;/code&gt;: The basename, with the extension removed (&lt;code&gt;party&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you do not include a placeholder, &lt;em&gt;fd&lt;/em&gt; automatically adds a &lt;code&gt;{}&lt;/code&gt; at the end.&lt;/p&gt; 
&lt;h4&gt;Parallel vs. serial execution&lt;/h4&gt; 
&lt;p&gt;For &lt;code&gt;-x&lt;/code&gt;/&lt;code&gt;--exec&lt;/code&gt;, you can control the number of parallel jobs by using the &lt;code&gt;-j&lt;/code&gt;/&lt;code&gt;--threads&lt;/code&gt; option. Use &lt;code&gt;--threads=1&lt;/code&gt; for serial execution.&lt;/p&gt; 
&lt;h3&gt;Excluding specific files or directories&lt;/h3&gt; 
&lt;p&gt;Sometimes we want to ignore search results from a specific subdirectory. For example, we might want to search all hidden files and directories (&lt;code&gt;-H&lt;/code&gt;) but exclude all matches from &lt;code&gt;.git&lt;/code&gt; directories. We can use the &lt;code&gt;-E&lt;/code&gt; (or &lt;code&gt;--exclude&lt;/code&gt;) option for this. It takes an arbitrary glob pattern as an argument:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -H -E .git ‚Ä¶
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We can also use this to skip mounted directories:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -E /mnt/external-drive ‚Ä¶
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;.. or to skip certain file types:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -E '*.bak' ‚Ä¶
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To make exclude-patterns like these permanent, you can create a &lt;code&gt;.fdignore&lt;/code&gt; file. They work like &lt;code&gt;.gitignore&lt;/code&gt; files, but are specific to &lt;code&gt;fd&lt;/code&gt;. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; cat ~/.fdignore
/mnt/external-drive
*.bak
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] &lt;code&gt;fd&lt;/code&gt; also supports &lt;code&gt;.ignore&lt;/code&gt; files that are used by other programs such as &lt;code&gt;rg&lt;/code&gt; or &lt;code&gt;ag&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you want &lt;code&gt;fd&lt;/code&gt; to ignore these patterns globally, you can put them in &lt;code&gt;fd&lt;/code&gt;'s global ignore file. This is usually located in &lt;code&gt;~/.config/fd/ignore&lt;/code&gt; in macOS or Linux, and &lt;code&gt;%APPDATA%\fd\ignore&lt;/code&gt; in Windows.&lt;/p&gt; 
&lt;p&gt;You may wish to include &lt;code&gt;.git/&lt;/code&gt; in your &lt;code&gt;fd/ignore&lt;/code&gt; file so that &lt;code&gt;.git&lt;/code&gt; directories, and their contents are not included in output if you use the &lt;code&gt;--hidden&lt;/code&gt; option.&lt;/p&gt; 
&lt;h3&gt;Deleting files&lt;/h3&gt; 
&lt;p&gt;You can use &lt;code&gt;fd&lt;/code&gt; to remove all files and directories that are matched by your search pattern. If you only want to remove files, you can use the &lt;code&gt;--exec-batch&lt;/code&gt;/&lt;code&gt;-X&lt;/code&gt; option to call &lt;code&gt;rm&lt;/code&gt;. For example, to recursively remove all &lt;code&gt;.DS_Store&lt;/code&gt; files, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -H '^\.DS_Store$' -tf -X rm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are unsure, always call &lt;code&gt;fd&lt;/code&gt; without &lt;code&gt;-X rm&lt;/code&gt; first. Alternatively, use &lt;code&gt;rm&lt;/code&gt;s "interactive" option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -H '^\.DS_Store$' -tf -X rm -i
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you also want to remove a certain class of directories, you can use the same technique. You will have to use &lt;code&gt;rm&lt;/code&gt;s &lt;code&gt;--recursive&lt;/code&gt;/&lt;code&gt;-r&lt;/code&gt; flag to remove directories.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] There are scenarios where using &lt;code&gt;fd ‚Ä¶ -X rm -r&lt;/code&gt; can cause race conditions: if you have a path like &lt;code&gt;‚Ä¶/foo/bar/foo/‚Ä¶&lt;/code&gt; and want to remove all directories named &lt;code&gt;foo&lt;/code&gt;, you can end up in a situation where the outer &lt;code&gt;foo&lt;/code&gt; directory is removed first, leading to (harmless) &lt;em&gt;"'foo/bar/foo': No such file or directory"&lt;/em&gt; errors in the &lt;code&gt;rm&lt;/code&gt; call.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Command-line options&lt;/h3&gt; 
&lt;p&gt;This is the output of &lt;code&gt;fd -h&lt;/code&gt;. To see the full set of command-line options, use &lt;code&gt;fd --help&lt;/code&gt; which also includes a much more detailed help text.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Usage: fd [OPTIONS] [pattern [path...]]

Arguments:
  [pattern]  the search pattern (a regular expression, unless '--glob' is used; optional)
  [path]...  the root directories for the filesystem search (optional)

Options:
  -H, --hidden                     Search hidden files and directories
  -I, --no-ignore                  Do not respect .(git|fd)ignore files
  -s, --case-sensitive             Case-sensitive search (default: smart case)
  -i, --ignore-case                Case-insensitive search (default: smart case)
  -g, --glob                       Glob-based search (default: regular expression)
  -a, --absolute-path              Show absolute instead of relative paths
  -l, --list-details               Use a long listing format with file metadata
  -L, --follow                     Follow symbolic links
  -p, --full-path                  Search full abs. path (default: filename only)
  -d, --max-depth &amp;lt;depth&amp;gt;          Set maximum search depth (default: none)
  -E, --exclude &amp;lt;pattern&amp;gt;          Exclude entries that match the given glob pattern
  -t, --type &amp;lt;filetype&amp;gt;            Filter by type: file (f), directory (d/dir), symlink (l),
                                   executable (x), empty (e), socket (s), pipe (p), char-device
                                   (c), block-device (b)
  -e, --extension &amp;lt;ext&amp;gt;            Filter by file extension
  -S, --size &amp;lt;size&amp;gt;                Limit results based on the size of files
      --changed-within &amp;lt;date|dur&amp;gt;  Filter by file modification time (newer than)
      --changed-before &amp;lt;date|dur&amp;gt;  Filter by file modification time (older than)
  -o, --owner &amp;lt;user:group&amp;gt;         Filter by owning user and/or group
      --format &amp;lt;fmt&amp;gt;               Print results according to template
  -x, --exec &amp;lt;cmd&amp;gt;...              Execute a command for each search result
  -X, --exec-batch &amp;lt;cmd&amp;gt;...        Execute a command with all search results at once
  -c, --color &amp;lt;when&amp;gt;               When to use colors [default: auto] [possible values: auto,
                                   always, never]
      --hyperlink[=&amp;lt;when&amp;gt;]         Add hyperlinks to output paths [default: never] [possible
                                   values: auto, always, never]
  -h, --help                       Print help (see more with '--help')
  -V, --version                    Print version
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that options can be given after the pattern and/or path as well.&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;Let's search my home folder for files that end in &lt;code&gt;[0-9].jpg&lt;/code&gt;. It contains ~750.000 subdirectories and about a 4 million files. For averaging and statistical analysis, I'm using &lt;a href="https://github.com/sharkdp/hyperfine"&gt;hyperfine&lt;/a&gt;. The following benchmarks are performed with a "warm"/pre-filled disk-cache (results for a "cold" disk-cache show the same trends).&lt;/p&gt; 
&lt;p&gt;Let's start with &lt;code&gt;find&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Benchmark 1: find ~ -iregex '.*[0-9]\.jpg$'
  Time (mean ¬± œÉ):     19.922 s ¬±  0.109 s
  Range (min ‚Ä¶ max):   19.765 s ‚Ä¶ 20.065 s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;find&lt;/code&gt; is much faster if it does not need to perform a regular-expression search:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Benchmark 2: find ~ -iname '*[0-9].jpg'
  Time (mean ¬± œÉ):     11.226 s ¬±  0.104 s
  Range (min ‚Ä¶ max):   11.119 s ‚Ä¶ 11.466 s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now let's try the same for &lt;code&gt;fd&lt;/code&gt;. Note that &lt;code&gt;fd&lt;/code&gt; performs a regular expression search by default. The options &lt;code&gt;-u&lt;/code&gt;/&lt;code&gt;--unrestricted&lt;/code&gt; option is needed here for a fair comparison. Otherwise &lt;code&gt;fd&lt;/code&gt; does not have to traverse hidden folders and ignored paths (see below):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Benchmark 3: fd -u '[0-9]\.jpg$' ~
  Time (mean ¬± œÉ):     854.8 ms ¬±  10.0 ms
  Range (min ‚Ä¶ max):   839.2 ms ‚Ä¶ 868.9 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For this particular example, &lt;code&gt;fd&lt;/code&gt; is approximately &lt;strong&gt;23 times faster&lt;/strong&gt; than &lt;code&gt;find -iregex&lt;/code&gt; and about &lt;strong&gt;13 times faster&lt;/strong&gt; than &lt;code&gt;find -iname&lt;/code&gt;. By the way, both tools found the exact same 546 files &lt;span&gt;üòÑ&lt;/span&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This is &lt;em&gt;one particular&lt;/em&gt; benchmark on &lt;em&gt;one particular&lt;/em&gt; machine. While we have performed a lot of different tests (and found consistent results), things might be different for you! We encourage everyone to try it out on their own. See &lt;a href="https://github.com/sharkdp/fd-benchmarks"&gt;this repository&lt;/a&gt; for all necessary scripts.&lt;/p&gt; 
&lt;p&gt;Concerning &lt;em&gt;fd&lt;/em&gt;'s speed, a lot of credit goes to the &lt;code&gt;regex&lt;/code&gt; and &lt;code&gt;ignore&lt;/code&gt; crates that are also used in &lt;a href="https://github.com/BurntSushi/ripgrep"&gt;ripgrep&lt;/a&gt; (check it out!).&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;&lt;code&gt;fd&lt;/code&gt; does not find my file!&lt;/h3&gt; 
&lt;p&gt;Remember that &lt;code&gt;fd&lt;/code&gt; ignores hidden directories and files by default. It also ignores patterns from &lt;code&gt;.gitignore&lt;/code&gt; files. If you want to make sure to find absolutely every possible file, always use the options &lt;code&gt;-u&lt;/code&gt;/&lt;code&gt;--unrestricted&lt;/code&gt; option (or &lt;code&gt;-HI&lt;/code&gt; to enable hidden and ignored files):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -u ‚Ä¶
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Also remember that by default, &lt;code&gt;fd&lt;/code&gt; only searches based on the filename and doesn't compare the pattern to the full path. If you want to search based on the full path (similar to the &lt;code&gt;-path&lt;/code&gt; option of &lt;code&gt;find&lt;/code&gt;) you need to use the &lt;code&gt;--full-path&lt;/code&gt; (or &lt;code&gt;-p&lt;/code&gt;) option.&lt;/p&gt; 
&lt;h3&gt;Colorized output&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;fd&lt;/code&gt; can colorize files by extension, just like &lt;code&gt;ls&lt;/code&gt;. In order for this to work, the environment variable &lt;a href="https://linux.die.net/man/5/dir_colors"&gt;&lt;code&gt;LS_COLORS&lt;/code&gt;&lt;/a&gt; has to be set. Typically, the value of this variable is set by the &lt;code&gt;dircolors&lt;/code&gt; command which provides a convenient configuration format to define colors for different file formats. On most distributions, &lt;code&gt;LS_COLORS&lt;/code&gt; should be set already. If you are on Windows or if you are looking for alternative, more complete (or more colorful) variants, see &lt;a href="https://github.com/sharkdp/vivid"&gt;here&lt;/a&gt;, &lt;a href="https://github.com/seebi/dircolors-solarized"&gt;here&lt;/a&gt; or &lt;a href="https://github.com/trapd00r/LS_COLORS"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;fd&lt;/code&gt; also honors the &lt;a href="https://no-color.org/"&gt;&lt;code&gt;NO_COLOR&lt;/code&gt;&lt;/a&gt; environment variable.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;fd&lt;/code&gt; doesn't seem to interpret my regex pattern correctly&lt;/h3&gt; 
&lt;p&gt;A lot of special regex characters (like &lt;code&gt;[]&lt;/code&gt;, &lt;code&gt;^&lt;/code&gt;, &lt;code&gt;$&lt;/code&gt;, ..) are also special characters in your shell. If in doubt, always make sure to put single quotes around the regex pattern:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd '^[A-Z][0-9]+$'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your pattern starts with a dash, you have to add &lt;code&gt;--&lt;/code&gt; to signal the end of command line options. Otherwise, the pattern will be interpreted as a command-line option. Alternatively, use a character class with a single hyphen character:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -- '-pattern'
&amp;gt; fd '[-]pattern'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;"Command not found" for &lt;code&gt;alias&lt;/code&gt;es or shell functions&lt;/h3&gt; 
&lt;p&gt;Shell &lt;code&gt;alias&lt;/code&gt;es and shell functions can not be used for command execution via &lt;code&gt;fd -x&lt;/code&gt; or &lt;code&gt;fd -X&lt;/code&gt;. In &lt;code&gt;zsh&lt;/code&gt;, you can make the alias global via &lt;code&gt;alias -g myalias="‚Ä¶"&lt;/code&gt;. In &lt;code&gt;bash&lt;/code&gt;, you can use &lt;code&gt;export -f my_function&lt;/code&gt; to make available to child processes. You would still need to call &lt;code&gt;fd -x bash -c 'my_function "$1"' bash&lt;/code&gt;. For other use cases or shells, use a (temporary) shell script.&lt;/p&gt; 
&lt;h2&gt;Integration with other programs&lt;/h2&gt; 
&lt;h3&gt;Using fd with &lt;code&gt;fzf&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;You can use &lt;em&gt;fd&lt;/em&gt; to generate input for the command-line fuzzy finder &lt;a href="https://github.com/junegunn/fzf"&gt;fzf&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export FZF_DEFAULT_COMMAND='fd --type file'
export FZF_CTRL_T_COMMAND="$FZF_DEFAULT_COMMAND"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, you can type &lt;code&gt;vim &amp;lt;Ctrl-T&amp;gt;&lt;/code&gt; on your terminal to open fzf and search through the fd-results.&lt;/p&gt; 
&lt;p&gt;Alternatively, you might like to follow symbolic links and include hidden files (but exclude &lt;code&gt;.git&lt;/code&gt; folders):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export FZF_DEFAULT_COMMAND='fd --type file --follow --hidden --exclude .git'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can even use fd's colored output inside fzf by setting:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export FZF_DEFAULT_COMMAND="fd --type file --color=always"
export FZF_DEFAULT_OPTS="--ansi"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details, see the &lt;a href="https://github.com/junegunn/fzf#tips"&gt;Tips section&lt;/a&gt; of the fzf README.&lt;/p&gt; 
&lt;h3&gt;Using fd with &lt;code&gt;rofi&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/davatorium/rofi"&gt;&lt;em&gt;rofi&lt;/em&gt;&lt;/a&gt; is a graphical launch menu application that is able to create menus by reading from &lt;em&gt;stdin&lt;/em&gt;. Piping &lt;code&gt;fd&lt;/code&gt; output into &lt;code&gt;rofi&lt;/code&gt;s &lt;code&gt;-dmenu&lt;/code&gt; mode creates fuzzy-searchable lists of files and directories.&lt;/p&gt; 
&lt;h4&gt;Example&lt;/h4&gt; 
&lt;p&gt;Create a case-insensitive searchable multi-select list of &lt;em&gt;PDF&lt;/em&gt; files under your &lt;code&gt;$HOME&lt;/code&gt; directory and open the selection with your configured PDF viewer. To list all file types, drop the &lt;code&gt;-e pdf&lt;/code&gt; argument.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fd --type f -e pdf . $HOME | rofi -keep-right -dmenu -i -p FILES -multi-select | xargs -I {} xdg-open {}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To modify the list that is presented by rofi, add arguments to the &lt;code&gt;fd&lt;/code&gt; command. To modify the search behaviour of rofi, add arguments to the &lt;code&gt;rofi&lt;/code&gt; command.&lt;/p&gt; 
&lt;h3&gt;Using fd with &lt;code&gt;emacs&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;The emacs package &lt;a href="https://github.com/technomancy/find-file-in-project"&gt;find-file-in-project&lt;/a&gt; can use &lt;em&gt;fd&lt;/em&gt; to find files.&lt;/p&gt; 
&lt;p&gt;After installing &lt;code&gt;find-file-in-project&lt;/code&gt;, add the line &lt;code&gt;(setq ffip-use-rust-fd t)&lt;/code&gt; to your &lt;code&gt;~/.emacs&lt;/code&gt; or &lt;code&gt;~/.emacs.d/init.el&lt;/code&gt; file.&lt;/p&gt; 
&lt;p&gt;In emacs, run &lt;code&gt;M-x find-file-in-project-by-selected&lt;/code&gt; to find matching files. Alternatively, run &lt;code&gt;M-x find-file-in-project&lt;/code&gt; to list all available files in the project.&lt;/p&gt; 
&lt;h3&gt;Printing the output as a tree&lt;/h3&gt; 
&lt;p&gt;To format the output of &lt;code&gt;fd&lt;/code&gt; as a file-tree you can use the &lt;code&gt;tree&lt;/code&gt; command with &lt;code&gt;--fromfile&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;‚ùØ fd | tree --fromfile
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This can be more useful than running &lt;code&gt;tree&lt;/code&gt; by itself because &lt;code&gt;tree&lt;/code&gt; does not ignore any files by default, nor does it support as rich a set of options as &lt;code&gt;fd&lt;/code&gt; does to control what to print:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;‚ùØ fd --extension rs | tree --fromfile
.
‚îú‚îÄ‚îÄ build.rs
‚îî‚îÄ‚îÄ src
    ‚îú‚îÄ‚îÄ app.rs
    ‚îî‚îÄ‚îÄ error.rs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On bash and similar you can simply create an alias:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;‚ùØ alias as-tree='tree --fromfile'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using fd with &lt;code&gt;xargs&lt;/code&gt; or &lt;code&gt;parallel&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Note that &lt;code&gt;fd&lt;/code&gt; has a builtin feature for &lt;a href="https://raw.githubusercontent.com/sharkdp/fd/master/#command-execution"&gt;command execution&lt;/a&gt; with its &lt;code&gt;-x&lt;/code&gt;/&lt;code&gt;--exec&lt;/code&gt; and &lt;code&gt;-X&lt;/code&gt;/&lt;code&gt;--exec-batch&lt;/code&gt; options. If you prefer, you can still use it in combination with &lt;code&gt;xargs&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt; fd -0 -e rs | xargs -0 wc -l
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here, the &lt;code&gt;-0&lt;/code&gt; option tells &lt;em&gt;fd&lt;/em&gt; to separate search results by the NULL character (instead of newlines). In the same way, the &lt;code&gt;-0&lt;/code&gt; option of &lt;code&gt;xargs&lt;/code&gt; tells it to read the input in this way.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/fd-find/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/fd-find.svg?sanitize=true" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;On Ubuntu&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;... and other Debian-based Linux distributions.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;If you run Ubuntu 19.04 (Disco Dingo) or newer, you can install the &lt;a href="https://packages.ubuntu.com/fd-find"&gt;officially maintained package&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;apt install fd-find
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the binary is called &lt;code&gt;fdfind&lt;/code&gt; as the binary name &lt;code&gt;fd&lt;/code&gt; is already used by another package. It is recommended that after installation, you add a link to &lt;code&gt;fd&lt;/code&gt; by executing command &lt;code&gt;ln -s $(which fdfind) ~/.local/bin/fd&lt;/code&gt;, in order to use &lt;code&gt;fd&lt;/code&gt; in the same way as in this documentation. Make sure that &lt;code&gt;$HOME/.local/bin&lt;/code&gt; is in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use an older version of Ubuntu, you can download the latest &lt;code&gt;.deb&lt;/code&gt; package from the &lt;a href="https://github.com/sharkdp/fd/releases"&gt;release page&lt;/a&gt; and install it via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;dpkg -i fd_9.0.0_amd64.deb # adapt version number and architecture
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the .deb packages on the release page for this project still name the executable &lt;code&gt;fd&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;On Debian&lt;/h3&gt; 
&lt;p&gt;If you run Debian Buster or newer, you can install the &lt;a href="https://tracker.debian.org/pkg/rust-fd-find"&gt;officially maintained Debian package&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;apt-get install fd-find
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the binary is called &lt;code&gt;fdfind&lt;/code&gt; as the binary name &lt;code&gt;fd&lt;/code&gt; is already used by another package. It is recommended that after installation, you add a link to &lt;code&gt;fd&lt;/code&gt; by executing command &lt;code&gt;ln -s $(which fdfind) ~/.local/bin/fd&lt;/code&gt;, in order to use &lt;code&gt;fd&lt;/code&gt; in the same way as in this documentation. Make sure that &lt;code&gt;$HOME/.local/bin&lt;/code&gt; is in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that the .deb packages on the release page for this project still name the executable &lt;code&gt;fd&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;On Fedora&lt;/h3&gt; 
&lt;p&gt;Starting with Fedora 28, you can install &lt;code&gt;fd&lt;/code&gt; from the official package sources:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;dnf install fd-find
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Alpine Linux&lt;/h3&gt; 
&lt;p&gt;You can install &lt;a href="https://pkgs.alpinelinux.org/packages?name=fd"&gt;the fd package&lt;/a&gt; from the official sources, provided you have the appropriate repository enabled:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;apk add fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Arch Linux&lt;/h3&gt; 
&lt;p&gt;You can install &lt;a href="https://www.archlinux.org/packages/extra/x86_64/fd/"&gt;the fd package&lt;/a&gt; from the official repos:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pacman -S fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also install fd &lt;a href="https://aur.archlinux.org/packages/fd-git"&gt;from the AUR&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;On Gentoo Linux&lt;/h3&gt; 
&lt;p&gt;You can use &lt;a href="https://packages.gentoo.org/packages/sys-apps/fd"&gt;the fd ebuild&lt;/a&gt; from the official repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;emerge -av fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On openSUSE Linux&lt;/h3&gt; 
&lt;p&gt;You can install &lt;a href="https://software.opensuse.org/package/fd"&gt;the fd package&lt;/a&gt; from the official repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;zypper in fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Void Linux&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;fd&lt;/code&gt; via xbps-install:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;xbps-install -S fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On ALT Linux&lt;/h3&gt; 
&lt;p&gt;You can install &lt;a href="https://packages.altlinux.org/en/sisyphus/srpms/fd/"&gt;the fd package&lt;/a&gt; from the official repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;apt-get install fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Solus&lt;/h3&gt; 
&lt;p&gt;You can install &lt;a href="https://github.com/getsolus/packages/tree/main/packages/f/fd"&gt;the fd package&lt;/a&gt; from the official repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;eopkg install fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On RedHat Enterprise Linux (RHEL) 8/9/10, Almalinux 8/9/10, EuroLinux 8/9 or Rocky Linux 8/9/10&lt;/h3&gt; 
&lt;p&gt;You can install &lt;a href="https://copr.fedorainfracloud.org/coprs/tkbcopr/fd/"&gt;the &lt;code&gt;fd&lt;/code&gt; package&lt;/a&gt; from Fedora Copr.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;dnf copr enable tkbcopr/fd
dnf install fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A different version using the &lt;a href="https://github.com/sharkdp/fd/pull/481#issuecomment-534494592"&gt;slower&lt;/a&gt; malloc &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=2216193#c1"&gt;instead of jemalloc&lt;/a&gt; is also available from the EPEL8/9 repo as the package &lt;code&gt;fd-find&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;On macOS&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;fd&lt;/code&gt; with &lt;a href="https://formulae.brew.sh/formula/fd"&gt;Homebrew&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;brew install fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Ä¶ or with MacPorts:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;port install fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Windows&lt;/h3&gt; 
&lt;p&gt;You can download pre-built binaries from the &lt;a href="https://github.com/sharkdp/fd/releases"&gt;release page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Alternatively, you can install &lt;code&gt;fd&lt;/code&gt; via &lt;a href="http://scoop.sh"&gt;Scoop&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;scoop install fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or via &lt;a href="https://chocolatey.org"&gt;Chocolatey&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;choco install fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or via &lt;a href="https://learn.microsoft.com/en-us/windows/package-manager/"&gt;Winget&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;winget install sharkdp.fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On GuixOS&lt;/h3&gt; 
&lt;p&gt;You can install &lt;a href="https://guix.gnu.org/en/packages/fd-8.1.1/"&gt;the fd package&lt;/a&gt; from the official repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;guix install fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On NixOS / via Nix&lt;/h3&gt; 
&lt;p&gt;You can use the &lt;a href="https://nixos.org/nix/"&gt;Nix package manager&lt;/a&gt; to install &lt;code&gt;fd&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;nix-env -i fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Via Flox&lt;/h3&gt; 
&lt;p&gt;You can use &lt;a href="https://flox.dev"&gt;Flox&lt;/a&gt; to install &lt;code&gt;fd&lt;/code&gt; into a Flox environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;flox install fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On FreeBSD&lt;/h3&gt; 
&lt;p&gt;You can install &lt;a href="https://www.freshports.org/sysutils/fd"&gt;the fd-find package&lt;/a&gt; from the official repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pkg install fd-find
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From npm&lt;/h3&gt; 
&lt;p&gt;On Linux and macOS, you can install the &lt;a href="https://npm.im/fd-find"&gt;fd-find&lt;/a&gt; package:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npm install -g fd-find
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;p&gt;With Rust's package manager &lt;a href="https://github.com/rust-lang/cargo"&gt;cargo&lt;/a&gt;, you can install &lt;em&gt;fd&lt;/em&gt; via:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo install fd-find
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that rust version &lt;em&gt;1.77.2&lt;/em&gt; or later is required.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;make&lt;/code&gt; is also needed for the build.&lt;/p&gt; 
&lt;h3&gt;From binaries&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://github.com/sharkdp/fd/releases"&gt;release page&lt;/a&gt; includes precompiled binaries for Linux, macOS and Windows. Statically-linked binaries are also available: look for archives with &lt;code&gt;musl&lt;/code&gt; in the file name.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/sharkdp/fd

# Build
cd fd
cargo build

# Run unit tests and integration tests
cargo test

# Install
cargo install --path .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Maintainers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sharkdp"&gt;sharkdp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tmccombs"&gt;tmccombs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tavianator"&gt;tavianator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;fd&lt;/code&gt; is distributed under the terms of both the MIT License and the Apache License 2.0.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/sharkdp/fd/master/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/sharkdp/fd/master/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; files for license details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ankitects/anki</title>
      <link>https://github.com/ankitects/anki</link>
      <description>&lt;p&gt;Anki is a smart spaced repetition flashcard program&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Anki¬Æ&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://buildkite.com/ankitects/anki-ci"&gt;&lt;img src="https://badge.buildkite.com/c9edf020a4aec976f9835e54751cc5409d843adbb66d043bd3.svg?branch=main" alt="Build status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repo contains the source code for the computer version of &lt;a href="https://apps.ankiweb.net"&gt;Anki&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;About&lt;/h1&gt; 
&lt;p&gt;Anki is a spaced repetition program. Please see the &lt;a href="https://apps.ankiweb.net"&gt;website&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h1&gt;Getting Started&lt;/h1&gt; 
&lt;h3&gt;Anki Betas&lt;/h3&gt; 
&lt;p&gt;If you'd like to try development builds of Anki but don't feel comfortable building the code, please see &lt;a href="https://betas.ankiweb.net/"&gt;Anki betas&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Developing&lt;/h3&gt; 
&lt;p&gt;For more information on building and developing, please see &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/docs/development.md"&gt;Development&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Want to contribute to Anki? Check out the &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/docs/contributing.md"&gt;Contribution Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Anki Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/CONTRIBUTORS"&gt;CONTRIBUTORS&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Anki's license: &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>eythaann/Seelen-UI</title>
      <link>https://github.com/eythaann/Seelen-UI</link>
      <description>&lt;p&gt;The Fully Customizable Desktop Environment for Windows 10/11.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/logo.svg?sanitize=true" width="44" align="top" alt="Seelen UI Logo" /&gt; Seelen UI &lt;/h1&gt; 
&lt;h2 align="center"&gt; Fully Customizable Desktop Environment for Windows &lt;br /&gt; Available in 70+ Languages &lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/eythaann/seelen-ui/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/eythaann/seelen-ui.svg?sanitize=true" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/eythaann/seelen-ui/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/eythaann/seelen-ui.svg?sanitize=true" alt="Last Commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/eythaann/seelen-ui.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/eythaann/seelen-ui/total.svg?sanitize=true" alt="Downloads" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/preview.png" width="100%" alt="Screenshot of Seelen UI desktop showing a customized desktop environment" /&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center" width="33%"&gt; &lt;a href="https://apps.microsoft.com/detail/Seelen%20UI/9p67c2d4t9fb?mode=full" target="_blank" rel="noopener noreferrer" aria-label="Download Seelen UI from Microsoft Store"&gt; &lt;img src="https://get.microsoft.com/images/en-us%20dark.svg?sanitize=true" width="100%" alt="Download Seelen UI from Microsoft Store" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" width="33%"&gt; &lt;a href="https://discord.gg/ABfASx5ZAJ" target="_blank" rel="noopener noreferrer" aria-label="Join the Seelen UI Discord community"&gt; &lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/discord-alt.png" width="100%" alt="Join the Seelen UI Discord community" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" width="33%"&gt; &lt;a href="https://www.digitalocean.com/?refcode=955c7335abf5&amp;amp;utm_campaign=Referral_Invite&amp;amp;utm_medium=Referral_Program&amp;amp;utm_source=badge" target="_blank" rel="noopener noreferrer" aria-label="DigitalOcean Referral Badge"&gt; &lt;img src="https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg?sanitize=true" width="100%" alt="DigitalOcean Referral Badge" /&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://seelen.io/apps/seelen-ui"&gt;Seelen UI&lt;/a&gt; is a tool designed to enhance your Windows desktop experience with a focus on customization and productivity. It integrates smoothly into your system, providing a range of features that allow you to personalize your desktop and optimize your workflow.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Be Creative&lt;/strong&gt;: Seelen UI lets you tailor your desktop to fit your style and needs. You can adjust menus, widgets, icons, and other elements to create a personalized and visually appealing desktop environment.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/theme_preview.png" alt="Seelen UI Custom Theme" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enhance Your Productivity&lt;/strong&gt;: Seelen UI helps you organize your desktop efficiently. With a Tiling Windows Manager, windows automatically arrange themselves to support multitasking, making your work more streamlined.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/twm_preview.png" alt="Seelen UI Tiling Window Manager" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enjoy your music&lt;/strong&gt;: With an integrated media module that's compatible with most music players, Seelen UI allows you to enjoy your music seamlessly. You can pause, resume, and skip tracks at any time without the need to open additional windows.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/media_module_preview.png" alt="Seelen UI Media Module" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Be faster!&lt;/strong&gt;: With an app launcher inspired by Rofi, Seelen UI provides a simple and intuitive way to quickly access your applications and execute commands.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/app_launcher_preview.png" alt="Seelen UI App Launcher" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User-Friendly Configuration&lt;/strong&gt;: Seelen UI offers an intuitive interface for easy customization. Adjust settings such as themes, taskbar layouts, icons, etc. With just a few clicks.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/settings_preview.png" alt="Seelen UI Settings" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] Seelen UI requires the WebView runtime to be installed. On Windows 11, it comes pre-installed with the system. However, on Windows 10, the WebView runtime is included with the &lt;code&gt;setup.exe&lt;/code&gt; installer. Additionally, Microsoft Edge is necessary to function correctly. Some users may have modified their system and removed Edge, so please ensure both Edge and the WebView runtime are installed on your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] On fresh installations of Windows, the app might show a white or dark screen. You only need to update your Windows through Windows Update and restart your PC.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You can choose from different installation options based on your preference:&lt;/p&gt; 
&lt;h3&gt;Microsoft Store &lt;em&gt;(recommended)&lt;/em&gt;&lt;/h3&gt; 
&lt;p&gt;Download the latest version from the &lt;a href="https://www.microsoft.com/store/productId/9P67C2D4T9FB?ocid=pdpshare"&gt;Store&lt;/a&gt; page. This is the recommended option because you will receive updates and a secure version of the program.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/em&gt;: It may take around 1 to 3 business days for changes to be reflected in the Microsoft Store, as updates are approved by real people in the store.&lt;/p&gt; 
&lt;h3&gt;Winget&lt;/h3&gt; 
&lt;p&gt;Install the latest version using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-pwsh"&gt;winget install --id Seelen.SeelenUI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This option also uses the signed &lt;code&gt;.msix&lt;/code&gt; package and ensures you have the latest secure version. Similar to the Microsoft Store, it may take around 1 to 3 business days for changes to be reflected in Winget, as updates are approved by real people in the &lt;code&gt;winget-pkg&lt;/code&gt; project.&lt;/p&gt; 
&lt;h3&gt;.msix Installer&lt;/h3&gt; 
&lt;p&gt;Download the &lt;code&gt;.msix&lt;/code&gt; installer from the &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;Releases&lt;/a&gt; page. This package is signed, ensuring a secure installation. This is the same option as the Microsoft Store but is a portable installer.&lt;/p&gt; 
&lt;h3&gt;.exe Installer&lt;/h3&gt; 
&lt;p&gt;Download the latest version from the &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;Releases&lt;/a&gt; page and run the &lt;code&gt;setup.exe&lt;/code&gt; installer. This option is less recommended as the installer is not signed, which may cause it to be flagged as a potential threat by some antivirus programs. The &lt;code&gt;setup.exe&lt;/code&gt; is updated more quickly than the Microsoft Store or Winget versions and also it receives notifications updates on new release.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Once installed or extracted, simply open the program. The easy-to-use and intuitive GUI will guide you through the configuration process. Customize your desktop environment effortlessly.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For in-depth details on various aspects of Seelen UI, explore the following documents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/languages.md"&gt;Languages&lt;/a&gt; - Information regarding translations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/toolbar.md"&gt;Toolbar&lt;/a&gt; - Details about customizing and using the toolbar.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://seelen.io/blog/seelen-ui-theme-tutorial"&gt;Themes&lt;/a&gt; - Guidance on creating and applying themes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/window_manager.md"&gt;Window Manager&lt;/a&gt; - Instructions on configuring the window manager.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/project.md"&gt;Project&lt;/a&gt; - General information about the project and its structure.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Upcoming Features&lt;/h2&gt; 
&lt;p&gt;I‚Äôm excited to share some upcoming features for Seelen UI! Here‚Äôs a glimpse of what‚Äôs planned for the future:&lt;/p&gt; 
&lt;h3&gt;&lt;del&gt;App Launcher&lt;/del&gt; ‚úÖ&lt;/h3&gt; 
&lt;p&gt;I‚Äôm planning to develop an app launcher inspired by &lt;a href="https://github.com/davatorium/rofi"&gt;Rofi&lt;/a&gt; on Linux. This feature will provide a sleek and highly customizable way to quickly access your applications.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/adi1090x/files/master/rofi/previews/colorful/main.gif" alt="App Launcher Preview" /&gt; &lt;em&gt;Image courtesy of &lt;a href="https://github.com/dctxmei/rofi-themes"&gt;rofi-themes&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Customizable Popup Widgets&lt;/h3&gt; 
&lt;p&gt;I aim to introduce a set of fully customizable popup widgets, similar to the features available in &lt;a href="https://github.com/elkowar/eww"&gt;EWW&lt;/a&gt;. These widgets will be highly configurable and adaptable to your needs, providing an enhanced and interactive way to manage your desktop environment.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/adi1090x/widgets/main/previews/dashboard.png" alt="Customizable Widgets Preview" /&gt; &lt;em&gt;Image courtesy of &lt;a href="https://github.com/adi1090x/widgets"&gt;adi1090x&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Custom Alt + Tab (Task Switching)&lt;/h3&gt; 
&lt;p&gt;An upgraded Alt + Tab system for task switching is on the horizon. This will offer a more visually appealing and functional experience, allowing for smoother transitions between open applications and windows.&lt;/p&gt; 
&lt;h3&gt;Custom Virtual Desktops Viewer and Animations&lt;/h3&gt; 
&lt;p&gt;I‚Äôm also working on a custom virtual desktops viewer and dynamic animations to improve navigation between different workspaces. This will provide a more intuitive and immersive multitasking experience.&lt;/p&gt; 
&lt;p&gt;Stay tuned for more updates as I develop these features. I appreciate your support and enthusiasm!&lt;/p&gt; 
&lt;p&gt;Happy customizing!&lt;/p&gt; 
&lt;p&gt;The Seelen UI Team&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read the &lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/CONTRIBUTING"&gt;Contribution Guidelines&lt;/a&gt; to get started with terms.&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/project.md"&gt;Project Documentation&lt;/a&gt; to understand the project structure and how to use it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;For inquiries and support, please contact me on &lt;a href="https://discord.gg/ABfASx5ZAJ"&gt;Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;See you later&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;                   .      .&amp;amp;     _,x&amp;amp;"``
                    &amp;amp; .   &amp;amp;'  ;.&amp;amp;&amp;amp;'
              &amp;amp;.  . &amp;amp;.&amp;amp;     .0&amp;amp;&amp;amp;&amp;amp;;&amp;amp;""`
         .    '&amp;amp;  &amp;amp;.&amp;amp;&amp;amp;&amp;amp;  .&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;'
       .&amp;amp;         ;&amp;amp;&amp;amp;&amp;amp; &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;'
      &amp;amp;&amp;amp;          &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;     &amp;amp;&amp;amp;&amp;amp;
     0&amp;amp;    .     &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;""
    &amp;amp;&amp;amp;   .0     &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;
   0&amp;amp;&amp;amp; .&amp;amp;'     &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;
  :&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;    . &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp; 
  0&amp;amp;&amp;amp;&amp;amp;&amp;amp;    &amp;amp; &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;
  &amp;amp;&amp;amp;&amp;amp;&amp;amp;'   &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;               .&amp;amp;&amp;amp;&amp;amp;x&amp;amp;
  &amp;amp;&amp;amp;&amp;amp;&amp;amp;   :&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0.&amp;amp;'        , .&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;;.
  &amp;amp;&amp;amp;&amp;amp;&amp;amp;.  &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;        .&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;'               .
  0&amp;amp;&amp;amp;&amp;amp;&amp;amp;  &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;       ,&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;                &amp;amp;
  :&amp;amp;&amp;amp;&amp;amp;&amp;amp;; &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0       ,;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;             ;  .0
   0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0     ,;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;             &amp;amp;  &amp;amp;;
    0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0   :',;".&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;".&amp;amp;             &amp;amp;&amp;amp; &amp;amp;0
     0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0  ',;',&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;" ,&amp;amp;'             &amp;amp;&amp;amp;&amp;amp;&amp;amp;0
      0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0 ,x&amp;amp;&amp;amp;&amp;amp;&amp;amp;" .&amp;amp;&amp;amp;&amp;amp;              &amp;amp;&amp;amp;&amp;amp;&amp;amp;0
        0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp; .&amp;amp;&amp;amp;&amp;amp;&amp;amp;"'''"&amp;amp;&amp;amp;"&amp;amp;&amp;amp;            &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
         0&amp;amp;&amp;amp; .&amp;amp;&amp;amp;;``       `&amp;amp;: :&amp;amp;         &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
            &amp;amp;"' &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;   &amp;amp;"&amp;amp; &amp;amp;"&amp;amp;   &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
              0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
                 0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0         Seelen
                      0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;üìå &lt;strong&gt;Official Website&lt;/strong&gt;: &lt;a href="https://seelen.io"&gt;https://seelen.io&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Seelen Inc ¬© 2025 - All rights reserved&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hyperium/hyper</title>
      <link>https://github.com/hyperium/hyper</link>
      <description>&lt;p&gt;An HTTP library for Rust&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://hyper.rs"&gt;hyper&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/hyper"&gt;&lt;img src="https://img.shields.io/crates/v/hyper.svg?sanitize=true" alt="crates.io" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/hyper"&gt;&lt;img src="https://docs.rs/hyper/badge.svg?sanitize=true" alt="Released API docs" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hyperium/hyper/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hyperium/hyper/actions?query=workflow%3ACI"&gt;&lt;img src="https://github.com/hyperium/hyper/workflows/CI/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/kkwpueZ"&gt;&lt;img src="https://img.shields.io/discord/500028886025895936.svg?logo=discord" alt="Discord chat" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A protective and efficient HTTP library for all.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HTTP/1 and HTTP/2&lt;/li&gt; 
 &lt;li&gt;Asynchronous design&lt;/li&gt; 
 &lt;li&gt;Leading in performance&lt;/li&gt; 
 &lt;li&gt;Tested and &lt;strong&gt;correct&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Extensive production use&lt;/li&gt; 
 &lt;li&gt;Client and Server APIs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Get started&lt;/strong&gt; by looking over the &lt;a href="https://hyper.rs/guides/1/"&gt;guides&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;"Low-level"&lt;/h2&gt; 
&lt;p&gt;hyper is a relatively low-level library, meant to be a building block for libraries and applications.&lt;/p&gt; 
&lt;p&gt;If you are looking for a convenient HTTP client, then you may wish to consider &lt;a href="https://github.com/seanmonstar/reqwest"&gt;reqwest&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are not sure what HTTP server to choose, then you may want to consider &lt;a href="https://github.com/tokio-rs/axum"&gt;axum&lt;/a&gt; or &lt;a href="https://github.com/seanmonstar/warp"&gt;warp&lt;/a&gt;, the latter taking a more functional approach. Both are built on top of this library.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;To get involved, take a look at &lt;a href="https://raw.githubusercontent.com/hyperium/hyper/master/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you prefer chatting, there is an active community in the &lt;a href="https://discord.gg/kkwpueZ"&gt;Discord server&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;hyper is provided under the MIT license. See &lt;a href="https://raw.githubusercontent.com/hyperium/hyper/master/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jj-vcs/jj</title>
      <link>https://github.com/jj-vcs/jj</link>
      <description>&lt;p&gt;A Git-compatible VCS that is both simple and powerful&lt;/p&gt;&lt;hr&gt;&lt;div class="title-block" style="text-align: center;" align="center"&gt; 
 &lt;h1&gt;Jujutsu‚Äîa version control system&lt;/h1&gt; 
 &lt;p&gt;&lt;img title="jj logo" src="https://raw.githubusercontent.com/jj-vcs/jj/main/docs/images/jj-logo.svg?sanitize=true" width="320" height="320" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/jj-vcs/jj/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/martinvonz/jj" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jj-vcs/jj/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/martinvonz/jj" alt="Release date" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/jj-vcs/jj/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/martinvonz/jj" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/dkmfj3aGQN"&gt;&lt;img src="https://img.shields.io/discord/968932220549103686.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://web.libera.chat/?channel=#jujutsu"&gt;&lt;img src="https://img.shields.io/badge/irc-%23jujutsu-blue.svg?sanitize=true" alt="IRC" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj"&gt;Homepage&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj/latest/install-and-setup"&gt;Installation&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj/latest/tutorial"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj/latest/roadmap"&gt;Development Roadmap&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Jujutsu is a powerful &lt;a href="https://en.wikipedia.org/wiki/Version_control"&gt;version control system&lt;/a&gt; for software projects. You use it to get a copy of your code, track changes to the code, and finally publish those changes for others to see and use. It is designed from the ground up to be easy to use‚Äîwhether you're new or experienced, working on brand new projects alone, or large scale software projects with large histories and teams.&lt;/p&gt; 
&lt;p&gt;Jujutsu is unlike most other systems, because internally it abstracts the user interface and version control algorithms from the &lt;em&gt;storage systems&lt;/em&gt; used to serve your content. This allows it to serve as a VCS with many possible physical backends, that may have their own data or networking models‚Äîlike &lt;a href="https://www.mercurial-scm.org/"&gt;Mercurial&lt;/a&gt; or &lt;a href="https://www.breezy-vcs.org/"&gt;Breezy&lt;/a&gt;, or hybrid systems like Google's cloud-based design, &lt;a href="https://youtu.be/W71BTkUbdqE?t=645"&gt;Piper/CitC&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Today, we use Git repositories as a storage layer to serve and track content, making it &lt;strong&gt;compatible with many of your favorite Git-based tools, right now!&lt;/strong&gt; All core developers use Jujutsu to develop Jujutsu, right here on GitHub. But it should hopefully work with your favorite Git forges, too.&lt;/p&gt; 
&lt;p&gt;We combine many distinct design choices and concepts from other version control systems into a single tool. Some of those sources of inspiration include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Git&lt;/strong&gt;: We make an effort to &lt;a href="https://github.com/jj-vcs/jj/discussions/49"&gt;be fast&lt;/a&gt;‚Äîwith a snappy UX, efficient algorithms, correct data structures, and good-old-fashioned attention to detail. The default storage backend uses Git repositories for "physical storage", for wide interoperability and ease of onboarding.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mercurial &amp;amp; Sapling&lt;/strong&gt;: There are many Mercurial-inspired features, such as the &lt;a href="https://jj-vcs.github.io/jj/latest/revsets/"&gt;revset&lt;/a&gt; language to select commits. There is &lt;a href="https://jj-vcs.github.io/jj/latest/git-comparison/#the-index"&gt;no explicit index&lt;/a&gt; or staging area. Branches are "anonymous" like Mercurial, so you don't need to make up a name for each small change. Primitives for rewriting history are powerful and simple. Formatting output is done with a robust template language that can be configured by the user.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Darcs&lt;/strong&gt;: Jujutsu keeps track of conflicts as &lt;a href="https://jj-vcs.github.io/jj/latest/conflicts/"&gt;first-class objects&lt;/a&gt; in its model; they are first-class in the same way commits are, while alternatives like Git simply think of conflicts as textual diffs. While not as rigorous as systems like Darcs (which is based on a formalized theory of patches, as opposed to snapshots), the effect is that many forms of conflict resolution can be performed and propagated automatically.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And it adds several innovative, useful features of its own:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Working-copy-as-a-commit&lt;/strong&gt;: Changes to files are &lt;a href="https://jj-vcs.github.io/jj/latest/working-copy/"&gt;recorded automatically&lt;/a&gt; as normal commits, and amended on every subsequent change. This "snapshot" design simplifies the user-facing data model (commits are the only visible object), simplifies internal algorithms, and completely subsumes features like Git's stashes or the index/staging-area.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Operation log &amp;amp; undo&lt;/strong&gt;: Jujutsu records every operation that is performed on the repository, from commits, to pulls, to pushes. This makes debugging problems like "what just happened?" or "how did I end up here?" easier, &lt;em&gt;especially&lt;/em&gt; when you're helping your coworker answer those questions about their repository! And because everything is recorded, you can undo that mistake you just made with ease. Version control has finally entered &lt;a href="https://en.wikipedia.org/wiki/Undo#History"&gt;the 1960s&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic rebase and conflict resolution&lt;/strong&gt;: When you modify a commit, every descendent is automatically rebased on top of the freshly-modified one. This makes "patch-based" workflows a breeze. If you resolve a conflict in a commit, the &lt;em&gt;resolution&lt;/em&gt; of that conflict is also propagated through descendants as well. In effect, this is a completely transparent version of &lt;code&gt;git rebase --update-refs&lt;/code&gt; combined with &lt;code&gt;git rerere&lt;/code&gt;, supported by design.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] The following features are available for use, but experimental; they may have bugs, backwards incompatible storage changes, and user-interface changes!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Safe, concurrent replication&lt;/strong&gt;: Have you ever wanted to store your version controlled repositories inside a Dropbox folder? Or continuously backup repositories to S3? No? Well, now you can!&lt;/p&gt; &lt;p&gt;The fundamental problem with using filesystems like Dropbox and backup tools like &lt;code&gt;rsync&lt;/code&gt; on your typical Git/Mercurial repositories is that they rely on &lt;em&gt;local filesystem operations&lt;/em&gt; being atomic, serialized, and non-concurrent with respect to other reads and writes‚Äîwhich is &lt;em&gt;not&lt;/em&gt; true when operating on distributed file systems, or when operations like concurrent file copies (for backup) happen while lock files are being held.&lt;/p&gt; &lt;p&gt;Jujutsu is instead designed to be &lt;a href="https://jj-vcs.github.io/jj/latest/technical/concurrency/"&gt;safe under concurrent scenarios&lt;/a&gt;; simply using rsync or Dropbox and then using that resulting repository should never result in a repository in a &lt;em&gt;corrupt state&lt;/em&gt;. The worst that &lt;em&gt;should&lt;/em&gt; happen is that it will expose conflicts between the local and remote state, leaving you to resolve them.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The command-line tool is called &lt;code&gt;jj&lt;/code&gt; for now because it's easy to type and easy to replace (rare in English). The project is called "Jujutsu" because it matches "jj".&lt;/p&gt; 
&lt;p&gt;Jujutsu is relatively young, with lots of work to still be done. If you have any questions, or want to talk about future plans, please join us on Discord &lt;a href="https://discord.gg/dkmfj3aGQN"&gt;&lt;img src="https://img.shields.io/discord/968932220549103686.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" alt="Discord" /&gt;&lt;/a&gt;, start a &lt;a href="https://github.com/jj-vcs/jj/discussions"&gt;GitHub Discussion&lt;/a&gt;, or send an IRC message to &lt;a href="https://web.libera.chat/?channel=#jujutsu"&gt;&lt;code&gt;#jujutsu&lt;/code&gt; on Libera Chat&lt;/a&gt;. The developers monitor all of these channels[^bridge].&lt;/p&gt; 
&lt;p&gt;[^bridge]: To be more precise, the &lt;code&gt;#jujutsu&lt;/code&gt; Libera IRC channel is bridged to one of the channels on jj's Discord. Some of the developers stay on Discord and use the bridge to follow IRC.&lt;/p&gt; 
&lt;h3&gt;News and Updates üì£&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;December 2024&lt;/strong&gt;: The &lt;code&gt;jj&lt;/code&gt; Repository has moved to the &lt;code&gt;jj-vcs&lt;/code&gt; GitHub organisation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;November 2024&lt;/strong&gt;: Version 0.24 is released which adds &lt;code&gt;jj file annotate&lt;/code&gt;, which is equivalent to &lt;code&gt;git blame&lt;/code&gt; or &lt;code&gt;hg annotate&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;September 2024&lt;/strong&gt;: Martin gave a &lt;a href="https://www.youtube.com/watch?v=LV0JzI8IcCY"&gt;presentation about Jujutsu&lt;/a&gt; at Git Merge 2024.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 2024&lt;/strong&gt;: Version 0.14 is released, which deprecates &lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/CHANGELOG.md#0140---2024-02-07"&gt;"jj checkout" and "jj merge"&lt;/a&gt;, as well as &lt;code&gt;jj init --git&lt;/code&gt;, which is now just called &lt;code&gt;jj git init&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 2023&lt;/strong&gt;: Version 0.10.0 is released! Now includes a bundled merge and diff editor for all platforms, "immutable revsets" to avoid accidentally &lt;code&gt;edit&lt;/code&gt;-ing the wrong revisions, and lots of polish.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jan 2023&lt;/strong&gt;: Martin gave a presentation about Google's plans for Jujutsu at Git Merge 2022! See the &lt;a href="https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view"&gt;slides&lt;/a&gt; or the &lt;a href="https://www.youtube.com/watch?v=bx_LGilOuE4"&gt;recording&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Related Media&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 2024&lt;/strong&gt;: Chris Krycho started &lt;a href="https://www.youtube.com/playlist?list=PLelyiwKWHHAq01Pvmpf6x7J0y-yQpmtxp"&gt;a YouTube series about Jujutsu&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 2024&lt;/strong&gt;: Chris Krycho published an article about Jujutsu called &lt;a href="https://v5.chriskrycho.com/essays/jj-init/"&gt;jj init&lt;/a&gt; and Steve Klabnik followed up with the &lt;a href="https://steveklabnik.github.io/jujutsu-tutorial/"&gt;Jujutsu Tutorial&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jan 2024&lt;/strong&gt;: Jujutsu was featured in an LWN.net article called &lt;a href="https://lwn.net/Articles/958468/"&gt;Jujutsu: a new, Git-compatible version control system&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jan 2023&lt;/strong&gt;: Martin's Talk about Jujutsu at Git Merge 2022, &lt;a href="https://www.youtube.com/watch?v=bx_LGilOuE4"&gt;video&lt;/a&gt; and the associated &lt;a href="https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view"&gt;slides&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The wiki also contains a more extensive list of &lt;a href="https://github.com/jj-vcs/jj/wiki/Media"&gt;media references&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Jujutsu is an &lt;strong&gt;experimental version control system&lt;/strong&gt;. While Git compatibility is stable, and most developers use it daily for all their needs, there may still be work-in-progress features, suboptimal UX, and workflow gaps that make it unusable for your particular use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Follow the &lt;a href="https://jj-vcs.github.io/jj/latest/install-and-setup"&gt;installation instructions&lt;/a&gt; to obtain and configure &lt;code&gt;jj&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The best way to get started is probably to go through &lt;a href="https://jj-vcs.github.io/jj/latest/tutorial"&gt;the tutorial&lt;/a&gt;. Also see the &lt;a href="https://jj-vcs.github.io/jj/latest/git-comparison"&gt;Git comparison&lt;/a&gt;, which includes a table of &lt;code&gt;jj&lt;/code&gt; vs. &lt;code&gt;git&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;As you become more familiar with Jujutsu, the following resources may be helpful:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://jj-vcs.github.io/jj/latest/FAQ"&gt;FAQ&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://jj-vcs.github.io/jj/latest/glossary"&gt;Glossary&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;jj help&lt;/code&gt; command (e.g. &lt;code&gt;jj help rebase&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;jj help -k &amp;lt;keyword&amp;gt;&lt;/code&gt; command (e.g. &lt;code&gt;jj help -k config&lt;/code&gt;). Use &lt;code&gt;jj help --help&lt;/code&gt; to see what keywords are available.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are using a &lt;strong&gt;prerelease&lt;/strong&gt; version of &lt;code&gt;jj&lt;/code&gt;, you would want to consult &lt;a href="https://jj-vcs.github.io/jj/prerelease/"&gt;the docs for the prerelease (main branch) version&lt;/a&gt;. You can also get there from the docs for the latest release by using the website's version switcher. The version switcher is visible in the header of the website when you scroll to the top of any page.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Compatible with Git&lt;/h3&gt; 
&lt;p&gt;Jujutsu is designed so that the underlying data and storage model is abstract. Today, only the Git backend is production-ready. The Git backend uses the &lt;a href="https://github.com/Byron/gitoxide"&gt;gitoxide&lt;/a&gt; Rust library.&lt;/p&gt; 
&lt;p&gt;The Git backend is fully featured and maintained, and allows you to use Jujutsu with any Git remote. The commits you create will look like regular Git commits. You can fetch branches from a regular Git remote and push branches to the remote. You can always switch back to Git.&lt;/p&gt; 
&lt;p&gt;Here is how you can explore a GitHub repository with &lt;code&gt;jj&lt;/code&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/git_compat.png" /&gt; 
&lt;p&gt;You can even have a &lt;a href="https://jj-vcs.github.io/jj/latest/git-compatibility#co-located-jujutsugit-repos"&gt;"co-located" local repository&lt;/a&gt; where you can use both &lt;code&gt;jj&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt; commands interchangeably.&lt;/p&gt; 
&lt;h3&gt;The working copy is automatically committed&lt;/h3&gt; 
&lt;p&gt;Jujutsu uses a real commit to represent the working copy. Checking out a commit results a new working-copy commit on top of the target commit. Almost all commands automatically amend the working-copy commit.&lt;/p&gt; 
&lt;p&gt;The working-copy being a commit means that commands never fail because the working copy is dirty (no "error: Your local changes to the following files..."), and there is no need for &lt;code&gt;git stash&lt;/code&gt;. Also, because the working copy is a commit, commands work the same way on the working-copy commit as on any other commit, so you can set the commit message before you're done with the changes.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/working_copy.png" /&gt; 
&lt;h3&gt;The repo is the source of truth&lt;/h3&gt; 
&lt;p&gt;With Jujutsu, the working copy plays a smaller role than with Git. Commands snapshot the working copy before they start, then they update the repo, and then the working copy is updated (if the working-copy commit was modified). Almost all commands (even checkout!) operate on the commits in the repo, leaving the common functionality of snapshotting and updating of the working copy to centralized code. For example, &lt;code&gt;jj restore&lt;/code&gt; (similar to &lt;code&gt;git restore&lt;/code&gt;) can restore from any commit and into any commit, and &lt;code&gt;jj describe&lt;/code&gt; can set the commit message of any commit (defaults to the working-copy commit).&lt;/p&gt; 
&lt;h3&gt;Entire repo is under version control&lt;/h3&gt; 
&lt;p&gt;All operations you perform in the repo are recorded, along with a snapshot of the repo state after the operation. This means that you can easily revert to an earlier repo state, or to simply undo a particular operation (which does not necessarily have to be the most recent operation).&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/operation_log.png" /&gt; 
&lt;h3&gt;Conflicts can be recorded in commits&lt;/h3&gt; 
&lt;p&gt;If an operation results in &lt;a href="https://jj-vcs.github.io/jj/latest/glossary#conflict"&gt;conflicts&lt;/a&gt;, information about those conflicts will be recorded in the commit(s). The operation will succeed. You can then resolve the conflicts later. One consequence of this design is that there's no need to continue interrupted operations. Instead, you get a single workflow for resolving conflicts, regardless of which command caused them. This design also lets Jujutsu rebase merge commits correctly (unlike both Git and Mercurial).&lt;/p&gt; 
&lt;p&gt;Basic conflict resolution:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/resolve_conflicts.png" /&gt; 
&lt;p&gt;Juggling conflicts:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/juggle_conflicts.png" /&gt; 
&lt;h3&gt;Automatic rebase&lt;/h3&gt; 
&lt;p&gt;Whenever you modify a commit, any descendants of the old commit will be rebased onto the new commit. Thanks to the conflict design described above, that can be done even if there are conflicts. Bookmarks pointing to rebased commits will be updated. So will the working copy if it points to a rebased commit.&lt;/p&gt; 
&lt;h3&gt;Comprehensive support for rewriting history&lt;/h3&gt; 
&lt;p&gt;Besides the usual rebase command, there's &lt;code&gt;jj describe&lt;/code&gt; for editing the description (commit message) of an arbitrary commit. There's also &lt;code&gt;jj diffedit&lt;/code&gt;, which lets you edit the changes in a commit without checking it out. To split a commit into two, use &lt;code&gt;jj split&lt;/code&gt;. You can even move part of the changes in a commit to any other commit using &lt;code&gt;jj squash -i --from X --into Y&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;The tool is fairly feature-complete, but some important features like support for Git submodules are not yet completed. There are also several performance bugs. It's likely that workflows and setups different from what the core developers use are not well supported, e.g. there is no native support for email-based workflows.&lt;/p&gt; 
&lt;p&gt;Today, all core developers use &lt;code&gt;jj&lt;/code&gt; to work on &lt;code&gt;jj&lt;/code&gt;. I (Martin von Zweigbergk) have almost exclusively used &lt;code&gt;jj&lt;/code&gt; to develop the project itself since early January 2021. I haven't had to re-clone from source (I don't think I've even had to restore from backup).&lt;/p&gt; 
&lt;p&gt;There &lt;em&gt;will&lt;/em&gt; be changes to workflows and backward-incompatible changes to the on-disk formats before version 1.0.0. For any format changes, we'll try to implement transparent upgrades (as we've done with recent changes), or provide upgrade commands or scripts if requested.&lt;/p&gt; 
&lt;h2&gt;Related work&lt;/h2&gt; 
&lt;p&gt;There are several tools trying to solve similar problems as Jujutsu. See &lt;a href="https://jj-vcs.github.io/jj/latest/related-work"&gt;related work&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome outside contributions, and there's plenty of things to do, so don't be shy. Please ask if you want a pointer on something you can help with, and hopefully we can all figure something out.&lt;/p&gt; 
&lt;p&gt;We do have &lt;a href="https://jj-vcs.github.io/jj/prerelease/contributing/"&gt;a few policies and suggestions&lt;/a&gt; for contributors. The broad TL;DR:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug reports are very welcome!&lt;/li&gt; 
 &lt;li&gt;Every commit that lands in the &lt;code&gt;main&lt;/code&gt; branch is code reviewed.&lt;/li&gt; 
 &lt;li&gt;Please behave yourself, and obey the Community Guidelines.&lt;/li&gt; 
 &lt;li&gt;There &lt;strong&gt;is&lt;/strong&gt; a mandatory CLA you must agree to. Importantly, it &lt;strong&gt;does not&lt;/strong&gt; transfer copyright ownership to Google or anyone else; it simply gives us the right to safely redistribute and use your changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mandatory Google Disclaimer&lt;/h3&gt; 
&lt;p&gt;I (Martin von Zweigbergk, &lt;a href="mailto:martinvonz@google.com"&gt;martinvonz@google.com&lt;/a&gt;) started Jujutsu as a hobby project in late 2019, and it has evolved into my full-time project at Google, with several other Googlers (now) assisting development in various capacities. That said, &lt;strong&gt;this is not a Google product&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Jujutsu is available as Open Source Software, under the Apache 2.0 license. See &lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; for details about copyright and redistribution.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;jj&lt;/code&gt; logo was contributed by J. Jennings and is licensed under a Creative Commons License, see &lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/docs/images/LICENSE"&gt;&lt;code&gt;docs/images/LICENSE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zellij-org/zellij</title>
      <link>https://github.com/zellij-org/zellij</link>
      <description>&lt;p&gt;A terminal workspace with batteries included&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/zellij-org/zellij/main/assets/logo.png" alt="logo" width="200" /&gt; &lt;br /&gt; Zellij &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/CrUAFH3"&gt;&lt;img alt="Discord Chat" src="https://img.shields.io/discord/771367133715628073?color=5865F2&amp;amp;label=discord&amp;amp;style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/#zellij_general:matrix.org"&gt;&lt;img alt="Matrix Chat" src="https://img.shields.io/matrix/zellij_general:matrix.org?color=1d7e64&amp;amp;label=matrix%20chat&amp;amp;style=flat-square&amp;amp;logo=matrix" /&gt;&lt;/a&gt; &lt;a href="https://zellij.dev/documentation/"&gt;&lt;img alt="Zellij documentation" src="https://img.shields.io/badge/zellij-documentation-fc0060?style=flat-square" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/zellij-org/zellij/main/assets/demo.gif" alt="demo" /&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; [&lt;a href="https://zellij.dev/documentation/installation"&gt;Installation&lt;/a&gt;] [&lt;a href="https://zellij.dev/screencasts/"&gt;Screencasts &amp;amp; Tutorials&lt;/a&gt;] [&lt;a href="https://zellij.dev/documentation/configuration"&gt;Configuration&lt;/a&gt;] [&lt;a href="https://zellij.dev/documentation/layouts"&gt;Layouts&lt;/a&gt;] [&lt;a href="https://zellij.dev/documentation/faq"&gt;FAQ&lt;/a&gt;] &lt;/h4&gt; 
&lt;h1&gt;What is this?&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/#origin-of-the-name"&gt;Zellij&lt;/a&gt; is a workspace aimed at developers, ops-oriented people and anyone who loves the terminal. Similar programs are sometimes called "Terminal Multiplexers".&lt;/p&gt; 
&lt;p&gt;Zellij is designed around the philosophy that one must not sacrifice simplicity for power, taking pride in its great experience out of the box as well as the advanced features it places at its users' fingertips.&lt;/p&gt; 
&lt;p&gt;Zellij is geared toward beginner and power users alike - allowing deep customizability, personal automation through &lt;a href="https://zellij.dev/documentation/layouts.html"&gt;layouts&lt;/a&gt;, true multiplayer collaboration, unique UX features such as floating and stacked panes, and a &lt;a href="https://zellij.dev/documentation/plugins.html"&gt;plugin system&lt;/a&gt; allowing one to create plugins in any language that compiles to WebAssembly.&lt;/p&gt; 
&lt;p&gt;Zellij includes a built-in &lt;a href="https://zellij.dev/tutorials/web-client/"&gt;web-client&lt;/a&gt;, making a terminal optional.&lt;/p&gt; 
&lt;p&gt;You can get started by &lt;a href="https://zellij.dev/documentation/installation.html"&gt;installing&lt;/a&gt; Zellij and checking out the &lt;a href="https://zellij.dev/screencasts/"&gt;Screencasts &amp;amp; Tutorials&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more details about our future plans, read about upcoming features in our &lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/#roadmap"&gt;roadmap&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;How do I install it?&lt;/h2&gt; 
&lt;p&gt;The easiest way to install Zellij is through a &lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/docs/THIRD_PARTY_INSTALL.md"&gt;package for your OS&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If one is not available for your OS, you could download a prebuilt binary from the &lt;a href="https://github.com/zellij-org/zellij/releases/latest"&gt;latest release&lt;/a&gt; and place it in your &lt;code&gt;$PATH&lt;/code&gt;. If you'd like, we could &lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/#try-zellij-without-installing"&gt;automatically choose one for you&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also install (compile) with &lt;code&gt;cargo&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo install --locked zellij
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Try Zellij without installing&lt;/h4&gt; 
&lt;p&gt;bash/zsh:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash &amp;lt;(curl -L https://zellij.dev/launch)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;fish/xonsh:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash -c 'bash &amp;lt;(curl -L https://zellij.dev/launch)'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installing from &lt;code&gt;main&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Installing Zellij from the &lt;code&gt;main&lt;/code&gt; branch is not recommended. This branch represents pre-release code, is constantly being worked on and may contain broken or unusable features. In addition, using it may corrupt the cache for future versions, forcing users to clear it before they can use the officially released version.&lt;/p&gt; 
&lt;p&gt;That being said - no-one will stop you from using it (and bug reports involving new features are greatly appreciated), but please consider using the latest release instead as detailed at the top of this section.&lt;/p&gt; 
&lt;h2&gt;How do I start a development environment?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Clone the project&lt;/li&gt; 
 &lt;li&gt;In the project folder, for debug builds run: &lt;code&gt;cargo xtask run&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;To run all tests: &lt;code&gt;cargo xtask test&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more build commands, see &lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;For configuring Zellij, please see the &lt;a href="https://zellij.dev/documentation/configuration.html"&gt;Configuration Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;About issues in this repository&lt;/h2&gt; 
&lt;p&gt;Issues in this repository, whether open or closed, do not necessarily indicate a problem or a bug in the software. They only indicate that the reporter wanted to communicate their experiences or thoughts to the maintainers. The Zellij maintainers do their best to go over and reply to all issue reports, but unfortunately cannot promise these will always be dealt with or even read. Your understanding is appreciated.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Presented here is the project roadmap, divided into three main sections.&lt;/p&gt; 
&lt;p&gt;These are issues that are either being actively worked on or are planned for the near future.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;If you'll click on the image, you'll be led to an SVG version of it on the website where you can directly click on every issue&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://zellij.dev/roadmap"&gt;&lt;img src="https://github.com/user-attachments/assets/bb55d213-4a68-4c84-ae72-7db5c9bf94fb" alt="roadmap" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Origin of the Name&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Zellij"&gt;From Wikipedia, the free encyclopedia&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Zellij (Arabic: ÿßŸÑÿ≤ŸÑŸäÿ¨, romanized: zillƒ´j; also spelled zillij or zellige) is a style of mosaic tilework made from individually hand-chiseled tile pieces. The pieces were typically of different colours and fitted together to form various patterns on the basis of tessellations, most notably elaborate Islamic geometric motifs such as radiating star patterns composed of various polygons. This form of Islamic art is one of the main characteristics of architecture in the western Islamic world. It is found in the architecture of Morocco, the architecture of Algeria, early Islamic sites in Tunisia, and in the historic monuments of al-Andalus (in the Iberian Peninsula).&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt; 
&lt;h2&gt;Sponsored by&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://terminaltrove.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/121595180?s=200&amp;amp;v=4" width="80px" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rustdesk/rustdesk</title>
      <link>https://github.com/rustdesk/rustdesk</link>
      <description>&lt;p&gt;An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/rustdesk/rustdesk/master/res/logo-header.svg?sanitize=true" alt="RustDesk - Your remote desktop" /&gt;&lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#raw-steps-to-build"&gt;Build&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#how-to-build-with-docker"&gt;Docker&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#file-structure"&gt;Structure&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#snapshot"&gt;Snapshot&lt;/a&gt;&lt;br /&gt; [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-UA.md"&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-CS.md"&gt;ƒçesky&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ZH.md"&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-HU.md"&gt;Magyar&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ES.md"&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FA.md"&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FR.md"&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DE.md"&gt;Deutsch&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PL.md"&gt;Polski&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ID.md"&gt;Indonesian&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FI.md"&gt;Suomi&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ML.md"&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NL.md"&gt;Nederlands&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-IT.md"&gt;Italiano&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-RU.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PTBR.md"&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-EO.md"&gt;Esperanto&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-KR.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-AR.md"&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-VN.md"&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DA.md"&gt;Dansk&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-GR.md"&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-TR.md"&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NO.md"&gt;Norsk&lt;/a&gt;]&lt;br /&gt; &lt;b&gt;We need your help to translate this README, &lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/lang"&gt;RustDesk UI&lt;/a&gt; and &lt;a href="https://github.com/rustdesk/doc.rustdesk.com"&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Caution] &lt;strong&gt;Misuse Disclaimer:&lt;/strong&gt; &lt;br /&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Chat with us: &lt;a href="https://discord.gg/nDceKgxnkV"&gt;Discord&lt;/a&gt; | &lt;a href="https://twitter.com/rustdesk"&gt;Twitter&lt;/a&gt; | &lt;a href="https://www.reddit.com/r/rustdesk"&gt;Reddit&lt;/a&gt; | &lt;a href="https://www.youtube.com/@rustdesk"&gt;YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://rustdesk.com/pricing.html"&gt;&lt;img src="https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue" alt="RustDesk Server Pro" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, &lt;a href="https://rustdesk.com/server"&gt;set up your own&lt;/a&gt;, or &lt;a href="https://github.com/rustdesk/rustdesk-server-demo"&gt;write your own rendezvous/relay server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;RustDesk welcomes contribution from everyone. See &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for help getting started.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/wiki/FAQ"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases"&gt;&lt;strong&gt;BINARY DOWNLOAD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases/tag/nightly"&gt;&lt;strong&gt;NIGHTLY BUILD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://f-droid.org/en/packages/com.carriez.flutter_hbb"&gt;&lt;img src="https://f-droid.org/badge/get-it-on.png" alt="Get it on F-Droid" height="80" /&gt;&lt;/a&gt; &lt;a href="https://flathub.org/apps/com.rustdesk.RustDesk"&gt;&lt;img src="https://flathub.org/api/badge?svg&amp;amp;locale=en" alt="Get it on Flathub" height="80" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;p&gt;Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our &lt;a href="https://github.com/rustdesk/rustdesk/raw/master/.github/workflows/flutter-build.yml"&gt;CI&lt;/a&gt; for building Flutter version.&lt;/p&gt; 
&lt;p&gt;Please download Sciter dynamic library yourself.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll"&gt;Windows&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so"&gt;Linux&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib"&gt;macOS&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Raw Steps to build&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Prepare your Rust development env and C++ build env&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://github.com/microsoft/vcpkg"&gt;vcpkg&lt;/a&gt;, and set &lt;code&gt;VCPKG_ROOT&lt;/code&gt; env variable correctly&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static&lt;/li&gt; 
   &lt;li&gt;Linux/macOS: vcpkg install libvpx libyuv opus aom&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;run &lt;code&gt;cargo run&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://rustdesk.com/docs/en/dev/build/"&gt;Build&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;How to Build on Linux&lt;/h2&gt; 
&lt;h3&gt;Ubuntu 18 (Debian 10)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;openSUSE Tumbleweed&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fedora 28 (CentOS 8)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Arch (Manjaro)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install vcpkg&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fix libvpx (For Fedora)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i 's/CFLAGS+=-I/CFLAGS+=-fPIC -I/g' Makefile
sed -i 's/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g' Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How to build with Docker&lt;/h2&gt; 
&lt;p&gt;Begin by cloning the repository and building the Docker container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t "rustdesk-builder" .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, each time you need to build the application, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID="$(id -u)" -e PGID="$(id -g)" rustdesk-builder
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the &lt;code&gt;&amp;lt;OPTIONAL-ARGS&amp;gt;&lt;/code&gt; position. For instance, if you wanted to build an optimized release version, you would run the command above followed by &lt;code&gt;--release&lt;/code&gt;. The resulting executable will be available in the target folder on your system, and can be run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/debug/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you're running a release executable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/release/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as &lt;code&gt;install&lt;/code&gt; or &lt;code&gt;run&lt;/code&gt; are not currently supported via this method as they would install or run the program inside the container instead of the host.&lt;/p&gt; 
&lt;h2&gt;File Structure&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common"&gt;libs/hbb_common&lt;/a&gt;&lt;/strong&gt;: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/scrap"&gt;libs/scrap&lt;/a&gt;&lt;/strong&gt;: screen capture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/enigo"&gt;libs/enigo&lt;/a&gt;&lt;/strong&gt;: platform specific keyboard/mouse control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard"&gt;libs/clipboard&lt;/a&gt;&lt;/strong&gt;: file copy and paste implementation for Windows, Linux, macOS.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/ui"&gt;src/ui&lt;/a&gt;&lt;/strong&gt;: obsolete Sciter UI (deprecated)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/server"&gt;src/server&lt;/a&gt;&lt;/strong&gt;: audio/clipboard/input/video services, and network connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/client.rs"&gt;src/client.rs&lt;/a&gt;&lt;/strong&gt;: start a peer connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs"&gt;src/rendezvous_mediator.rs&lt;/a&gt;&lt;/strong&gt;: Communicate with &lt;a href="https://github.com/rustdesk/rustdesk-server"&gt;rustdesk-server&lt;/a&gt;, wait for remote direct (TCP hole punching) or relayed connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/platform"&gt;src/platform&lt;/a&gt;&lt;/strong&gt;: platform specific code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter"&gt;flutter&lt;/a&gt;&lt;/strong&gt;: Flutter code for desktop and mobile&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js"&gt;flutter/web/js&lt;/a&gt;&lt;/strong&gt;: JavaScript for Flutter web client&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651" alt="Connection Manager" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea" alt="Connected to a Windows PC" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad" alt="File Transfer" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5" alt="TCP Tunneling" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>a2x/cs2-dumper</title>
      <link>https://github.com/a2x/cs2-dumper</link>
      <description>&lt;p&gt;Counter-Strike: 2 Offset Dumper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;cs2-dumper&lt;/h1&gt; 
&lt;p&gt;An external offset/interface dumper for Counter-Strike 2, with support for both Windows &amp;amp; Linux. Powered by &lt;a href="https://github.com/memflow/memflow"&gt;memflow&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The native Linux version is available in the &lt;a href="https://github.com/a2x/cs2-dumper/tree/linux"&gt;linux&lt;/a&gt; branch (currently outdated).&lt;/p&gt; 
&lt;p&gt;For a work-in-progress offline version, check out the &lt;a href="https://github.com/a2x/cs2-analyzer"&gt;cs2-analyzer&lt;/a&gt; repository or view its included web demo &lt;a href="https://a2x.github.io/cs2-analyzer"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;You can download the latest release from &lt;a href="https://github.com/a2x/cs2-dumper/releases"&gt;Releases&lt;/a&gt; or compile it yourself. Note that compiling it yourself requires your Rust compiler version to be at least 1.74.0 or newer.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Ensure the game is running (Being in the main menu should suffice).&lt;/li&gt; 
 &lt;li&gt;Run the &lt;code&gt;cs2-dumper&lt;/code&gt; executable.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; If you run the executable without specifying an optional memflow connector name, it will automatically use the &lt;a href="https://github.com/memflow/memflow-native"&gt;memflow-native&lt;/a&gt; OS layer to read the memory of the game process. If you wish to use an existing memflow connector instead, such as &lt;strong&gt;pcileech&lt;/strong&gt; or &lt;strong&gt;kvm&lt;/strong&gt;, you can pass the &lt;code&gt;connector&lt;/code&gt; and optional &lt;code&gt;connector-args&lt;/code&gt; arguments to the program. These connectors can be installed and managed using the &lt;a href="https://github.com/memflow/memflowup"&gt;memflowup&lt;/a&gt; tool.&lt;/p&gt; 
&lt;p&gt;E.g (for pcileech). &lt;code&gt;cs2-dumper -c pcileech -a :device=FPGA -vv&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Certain connectors, such as the &lt;a href="https://github.com/memflow/memflow-kvm"&gt;kvm&lt;/a&gt; connector on Linux or the &lt;a href="https://github.com/memflow/memflow-pcileech"&gt;pcileech&lt;/a&gt; / &lt;a href="https://github.com/a2x/memflow-winio"&gt;winio&lt;/a&gt; connectors on Windows, require elevated privileges to work. So either run the &lt;code&gt;cs2-dumper&lt;/code&gt; executable with &lt;code&gt;sudo&lt;/code&gt; on Linux or as an administrator on Windows.&lt;/p&gt; 
&lt;h3&gt;Available Arguments&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-c, --connector &amp;lt;connector&amp;gt;&lt;/code&gt;: The name of the memflow connector to use.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-a, --connector-args &amp;lt;connector-args&amp;gt;&lt;/code&gt;: Additional arguments to pass to the memflow connector.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-f, --file-types &amp;lt;file-types&amp;gt;&lt;/code&gt;: The types of files to generate. Default: &lt;code&gt;cs&lt;/code&gt;, &lt;code&gt;hpp&lt;/code&gt;, &lt;code&gt;json&lt;/code&gt;, &lt;code&gt;rs&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-i, --indent-size &amp;lt;indent-size&amp;gt;&lt;/code&gt;: The number of spaces to use per indentation level. Default: &lt;code&gt;4&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-o, --output &amp;lt;output&amp;gt;&lt;/code&gt;: The output directory to write the generated files to. Default: &lt;code&gt;output&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p, --process-name &amp;lt;process-name&amp;gt;&lt;/code&gt;: The name of the game process. Default: &lt;code&gt;cs2.exe&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v...&lt;/code&gt;: Increase logging verbosity. Can be specified multiple times.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h, --help&lt;/code&gt;: Print help.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-V, --version&lt;/code&gt;: Print version.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Running Tests&lt;/h2&gt; 
&lt;p&gt;To run the few basic provided tests, use the following command: &lt;code&gt;cargo test -- --nocapture&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the MIT license (&lt;a href="https://raw.githubusercontent.com/a2x/cs2-dumper/main/LICENSE"&gt;LICENSE&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openobserve/openobserve</title>
      <link>https://github.com/openobserve/openobserve</link>
      <description>&lt;p&gt;üöÄ 10x easier, üöÄ 140x lower storage cost, üöÄ high performance, üöÄ petabyte scale - Elasticsearch/Splunk/Datadog alternative for üöÄ (logs, metrics, traces, RUM, Error tracking, Session replay).&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://openobserve.ai"&gt;&lt;img src="https://openobserve.ai/img/logo/o2-logo-readme.svg?sanitize=true" alt="OpenObserve" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt;üöÄ 10x easier, üöÄ 140x lower storage cost, üöÄ high performance, üöÄ petabyte scale - Elasticsearch/Splunk/Datadog alternative for üöÄ (logs, metrics, traces).&lt;/em&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/openobserve/openobserve" target="_blank"&gt; &lt;img src="https://img.shields.io/github/last-commit/openobserve/openobserve" alt="Last Commit" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/stargazers" target="_blank"&gt; &lt;img src="https://img.shields.io/github/stars/openobserve/openobserve" alt="GitHub Stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/issues" target="_blank"&gt; &lt;img src="https://img.shields.io/github/issues/openobserve/openobserve" alt="GitHub Issues" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/graphs/contributors" target="_blank"&gt; &lt;img src="https://img.shields.io/github/contributors/openobserve/openobserve" alt="Contributors" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/releases" target="_blank"&gt; &lt;img src="https://img.shields.io/github/v/release/openobserve/openobserve" alt="GitHub Release" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;OpenObserve (O2 for short) is a cloud-native observability platform built specifically for logs, metrics, traces, analytics, RUM (Real User Monitoring - Performance, Errors, Session Replay) designed to work at petabyte scale.&lt;/p&gt; 
&lt;p&gt;It is straightforward and easy to operate, in contrast to Elasticsearch, which requires understanding and tuning numerous settings. Get OpenObserve up and running in under 2 minutes.&lt;/p&gt; 
&lt;p&gt;OpenObserve serves as a seamless replacement for Elasticsearch for users who ingest data using APIs and perform searches. OpenObserve comes with its own user interface, eliminating the need for separate installation.&lt;/p&gt; 
&lt;p&gt;You can reduce your log storage costs by ~140x compared to Elasticsearch by using OpenObserve. Below, we present the results from pushing logs from our production Kubernetes cluster to both Elasticsearch and OpenObserve using Fluent Bit.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_vs_es.png" alt="OpenObserve Vs Elasticsearch" /&gt;&lt;/p&gt; 
&lt;h2&gt;üé• Introduction Video&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=4VwuC1tpRP4"&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/o2_intro.webp" alt="OpenObserve Introduction" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Logs, Metrics, Traces&lt;/strong&gt;: Comprehensive support for various data types.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenTelemetry Support&lt;/strong&gt;: Full compatibility with OTLP for logs, metrics, and traces.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real User Monitoring (RUM)&lt;/strong&gt;: Includes performance tracking, error logging, and session replay.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dashboards, Reports, Alerts&lt;/strong&gt;: Features over 18 different chart types for comprehensive data visualization for on-the-fly analysis and reporting along with alerting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pipelines&lt;/strong&gt;: Enrich, redact, reduce, normalize data on the fly. Stream processing for logs to metrics and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Embedded GUI&lt;/strong&gt;: Intuitive and user-friendly interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQL and PromQL Support&lt;/strong&gt;: Query logs and traces with SQL, and metrics with SQL and PromQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single Binary or HA Installation&lt;/strong&gt;: Install using a single binary for small deployments or in HA mode for large deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versatile Storage Options&lt;/strong&gt;: Supports local disk, S3, MinIO, GCS, Azure Blob Storage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Availability and Clustering&lt;/strong&gt;: Ensures reliable and scalable performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Schema&lt;/strong&gt;: Adapts to your data structure seamlessly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in Authentication&lt;/strong&gt;: Secure and ready to use.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ease of Operation&lt;/strong&gt;: Designed for simplicity and efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Upgrades&lt;/strong&gt;: Hassle-free updates.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multilingual UI&lt;/strong&gt;: Supports 11 languages, including English, Spanish, German, French, Chinese, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a full list of features, check the &lt;a href="https://openobserve.ai/docs/#project-status-features-and-roadmap"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ö°Ô∏è Quick start&lt;/h2&gt; 
&lt;h3&gt;üê≥ Docker:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
      --name openobserve \
      -v $PWD/data:/data \
      -p 5080:5080 \
      -e ZO_ROOT_USER_EMAIL="root@example.com" \
      -e ZO_ROOT_USER_PASSWORD="Complexpass#123" \
      public.ecr.aws/zinclabs/openobserve:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üêô Docker Compose:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  openobserve:
    image: public.ecr.aws/zinclabs/openobserve:latest
    restart: unless-stopped
    environment:
      ZO_ROOT_USER_EMAIL: "root@example.com"
      ZO_ROOT_USER_PASSWORD: "Complexpass#123"
    ports:
      - "5080:5080"
    volumes:
      - data:/data
volumes:
  data:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For other ways to quickly install OpenObserve or use OpenObserve cloud, check &lt;a href="https://openobserve.ai/docs/quickstart"&gt;quickstart documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For installing OpenObserve in HA mode, check &lt;a href="https://openobserve.ai/docs/ha_deployment/"&gt;HA deployment documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ## Enterprise Vs Open source Vs Cloud edition

OpenObserve is available in three different editions:


| Feature | Open Source (Self hosted) | Enterprise (Self hosted) | Cloud |
| --- | --- | --- | --- | 
| Logs | ‚úÖ | ‚úÖ | ‚úÖ |
| Metrics | ‚úÖ | ‚úÖ | ‚úÖ |
| Traces | ‚úÖ | ‚úÖ | ‚úÖ |
| RUM | ‚úÖ | ‚úÖ | ‚úÖ |
| Alerts | ‚úÖ | ‚úÖ | ‚úÖ |
| Dashboards | ‚úÖ | ‚úÖ | ‚úÖ |
| Reports | ‚úÖ | ‚úÖ | ‚úÖ |
| VRL functions | ‚úÖ | ‚úÖ | ‚úÖ |
| Pipelines | ‚úÖ | ‚úÖ | ‚úÖ |
| High Availability | ‚úÖ | ‚úÖ | ‚úÖ |
| Multitenancy (Organizations) | ‚úÖ | ‚úÖ | ‚úÖ |
| Dynamic schema and schema evolution | ‚úÖ | ‚úÖ | ‚úÖ |
| Advanced multilingual GUI | ‚úÖ | ‚úÖ | ‚úÖ |
| Single Sign On | ‚ùå | ‚úÖ | ‚úÖ |
| Role Based Access Control (RBAC) | ‚ùå | ‚úÖ | ‚úÖ |
| Federated search / Super cluster | ‚ùå | ‚úÖ | ‚ùå |
| Query management | ‚ùå | ‚úÖ | ‚ùå |
| Workload management (QoS) | ‚ùå | ‚úÖ | ‚ùå |
| Audit trail | ‚ùå | ‚úÖ | ‚ùå |
| Ability to influence roadmap | ‚ùå | ‚úÖ | ‚úÖ on enterprise plan |
| License | AGPL | Enterprise | Cloud |
| Support | Community | Enterprise | Cloud |
| Cost | Free | If self hosted, free for up to 200 GB/Day data ingested &lt;br&gt; Paid thereafter  | Free 200 GB/Month data ingested &lt;br&gt; Paid thereafter | --&gt; 
&lt;h2&gt;üì∑ Screenshots&lt;/h2&gt; 
&lt;h3&gt;Home&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_home.png" alt="Home" /&gt;&lt;/p&gt; 
&lt;h3&gt;Logs&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/logs.png" alt="Logs" /&gt;&lt;/p&gt; 
&lt;h3&gt;Traces (OpenTelemetry)&lt;/h3&gt; 
&lt;p&gt;Trace details page &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces.png" alt="Traces using OpenTelemetry" /&gt;&lt;/p&gt; 
&lt;p&gt;Golden metrics based on traces &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces-overall.png" alt="Traces golden metrics" /&gt;&lt;/p&gt; 
&lt;h3&gt;Visualizations and Dashboards&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard.png" alt="Dashboard" /&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard2.png" alt="Dashboard" /&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/create-panel.png" alt="Create panel" /&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/map.png" alt="Map" /&gt;&lt;/p&gt; 
&lt;h3&gt;Front end monitoring&lt;/h3&gt; 
&lt;p&gt;Performance analytics &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/performance.png" alt="Performance" /&gt;&lt;/p&gt; 
&lt;p&gt;Session replay &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/session-replay.png" alt="Session replay" /&gt;&lt;/p&gt; 
&lt;p&gt;Error tracking &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/error-tracking.png" alt="Error tracking" /&gt;&lt;/p&gt; 
&lt;h3&gt;Alerts&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/alerts.png" alt="Alerts" /&gt;&lt;/p&gt; 
&lt;h3&gt;Streams&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/streams.png" alt="Streams" /&gt;&lt;/p&gt; 
&lt;h3&gt;Ingestion&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/ingestion1.png" alt="Ingestion" /&gt;&lt;/p&gt; 
&lt;h3&gt;Pipeline&lt;/h3&gt; 
&lt;p&gt;Pipeline &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/pipeline.png" alt="Pipeline" /&gt;&lt;/p&gt; 
&lt;p&gt;Function &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/function.png" alt="Function" /&gt;&lt;/p&gt; 
&lt;h3&gt;IAM&lt;/h3&gt; 
&lt;p&gt;SSO (Single Sign On) &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/sso.png" alt="SSO" /&gt;&lt;/p&gt; 
&lt;p&gt;RBAC (Role Based Access Control) &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/iam_rbac.png" alt="RBAC" /&gt;&lt;/p&gt; 
&lt;h3&gt;SBOM&lt;/h3&gt; 
&lt;p&gt;Software Bill of Materials for OpenObserve&lt;/p&gt; 
&lt;h4&gt;Rust&lt;/h4&gt; 
&lt;p&gt;SBOM can be found &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/openobserve.cdx.xml"&gt;here&lt;/a&gt;. You can analyze it using &lt;a href="https://dependencytrack.org/"&gt;dependency track&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In order to generate the SBOM, you can use the following commands:&lt;/p&gt; 
&lt;p&gt;Install cargo-cyclonedx:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-cyclonedx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the SBOM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo-cyclonedx cyclonedx
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;JavaScript&lt;/h4&gt; 
&lt;p&gt;SBOM can be found &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/web/sbom.json"&gt;here&lt;/a&gt;. You can analyze it using &lt;a href="https://dependencytrack.org/"&gt;dependency track&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In order to generate the SBOM, you can use the following commands:&lt;/p&gt; 
&lt;p&gt;Install cyclonedx-npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install --global @cyclonedx/cyclonedx-npm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the SBOM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd web
cyclonedx-npm &amp;gt; sbom.json         
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; 
&lt;p&gt;OpenObserve is licensed under the AGPL-3.0 license. For more details, see the &lt;a href="https://github.com/openobserve/openobserve/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üåç Community&lt;/h2&gt; 
&lt;h3&gt;üîó Join OpenObserve community on Slack&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://short.openobserve.ai/community"&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/slack.png" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Easiest way to get support is to join the &lt;a href="https://short.openobserve.ai/community"&gt;Slack channel&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;üì± Join OpenObserve community on WeChat&lt;/h3&gt; 
&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/wechat_qr.jpg" width="300" /&gt;</description>
    </item>
    
    <item>
      <title>shshemi/tabiew</title>
      <link>https://github.com/shshemi/tabiew</link>
      <description>&lt;p&gt;A lightweight TUI application to view and query tabular data files, such as CSV, TSV, and parquet.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tabiew&lt;/h1&gt; 
&lt;p&gt;Tabiew is a lightweight TUI application that allows users to view and query tabular data files, such as CSV, Parquet, Arrow, and ...&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/shshemi/tabiew/main/images/main.gif" alt="Image Alt text" title="Screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚å®Ô∏è Vim-style keybindings&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è SQL support&lt;/li&gt; 
 &lt;li&gt;üìä Support for CSV, Parquet, JSON, JSONL, Arrow, FWF, Sqlite, and Excel&lt;/li&gt; 
 &lt;li&gt;üîç Fuzzy search&lt;/li&gt; 
 &lt;li&gt;üìù Scripting support&lt;/li&gt; 
 &lt;li&gt;üóÇÔ∏è Multi-table functionality&lt;/li&gt; 
 &lt;li&gt;üìà Plotting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Wiki&lt;/h2&gt; 
&lt;p&gt;Tabiew started as a humble hobby TUI project for viewing CSV data but has evolved to incorporate various features and improvements from valuable community feedbacks. As the project expanded, so did the need for comprehensive documentation, leading to the creation of the &lt;a href="https://github.com/shshemi/tabiew/wiki"&gt;wiki page&lt;/a&gt;. The wiki offers explanations of features and the best practices to get the most out of Tabiew.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;There are various ways to install Tabiew:&lt;/p&gt; 
&lt;h3&gt;Arch Linux&lt;/h3&gt; 
&lt;p&gt;You can install from the &lt;a href="https://archlinux.org/packages/extra/x86_64/tabiew/"&gt;official repositories&lt;/a&gt; using &lt;a href="https://wiki.archlinux.org/title/pacman"&gt;pacman&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pacman -S tabiew
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debian-based&lt;/h3&gt; 
&lt;p&gt;Download the &lt;code&gt;.deb&lt;/code&gt; package from the &lt;a href="https://github.com/shshemi/tabiew/releases"&gt;GitHub releases page&lt;/a&gt; and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo dpkg -i &amp;lt;path_to_package.deb&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;RPM-based&lt;/h3&gt; 
&lt;p&gt;Download the &lt;code&gt;.rpm&lt;/code&gt; package from the &lt;a href="https://github.com/shshemi/tabiew/releases"&gt;GitHub releases page&lt;/a&gt; and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo rpm -i &amp;lt;path_to_package.rpm&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MacOS&lt;/h3&gt; 
&lt;p&gt;Installing Tabiew using &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt; from Homebrew core:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew update
brew install tabiew
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or tap:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install shshemi/tabiew/tabiew
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: Please be aware that installing Tabiew from the tap involves compiling it from the source, which may take some time to complete.&lt;/p&gt; 
&lt;h3&gt;Cargo&lt;/h3&gt; 
&lt;p&gt;Installing Tabiew from &lt;em&gt;Crates.io&lt;/em&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install tabiew
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build from Source&lt;/h3&gt; 
&lt;p&gt;Ensure you have rustc version 1.80 (or higher) installed. Download the desired source version from the &lt;a href="https://github.com/shshemi/tabiew/releases"&gt;release page&lt;/a&gt;. Extract the downloaded file and navigate into the extracted directory. Then run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo build --release
cp ./target/release/tw &amp;lt;system_or_local_bin_path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Start Tabiew with &lt;code&gt;tw&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;tw &amp;lt;path_to_csv(s)&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To open TSV file(s), use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;tw &amp;lt;path_to_tsv(s)&amp;gt; --separator $'\t' --no-header
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To open parquet file(s), use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;tw &amp;lt;path_to_parquet(s)&amp;gt; -f parquet
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To open a URL, use curl to pipe the output directly to Tabiew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -s "https://raw.githubusercontent.com/wiki/shshemi/tabiew/housing.csv" | tw
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Useful KeybindingsÔ∏è&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key Combination&lt;/th&gt; 
   &lt;th&gt;Functionality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Enter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Open sheet&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;h j k l&lt;/code&gt; or &lt;code&gt;‚Üê ‚Üì ‚Üë ‚Üí&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Navigation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;b&lt;/code&gt; / &lt;code&gt;w&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Previous / next column&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;e&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Toggle Auto-Fit&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl + u&lt;/code&gt; / &lt;code&gt;Ctrl + d&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Move half page up/down&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl + b&lt;/code&gt; / &lt;code&gt;Ctrl + f&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Move full page up/down&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Home&lt;/code&gt; or &lt;code&gt;g&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Move to first row&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;End&lt;/code&gt; or &lt;code&gt;G&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Move to last row&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl + r&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Reset data frame&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;q&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Close&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Q&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Quit Application&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Command Palette&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Fuzzy Search&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Useful Commands&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Q&lt;/code&gt; or &lt;code&gt;query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Q SELECT * FROM df&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Query the data in Structured Query Language(SQL). The table name is the file name without extension&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;S&lt;/code&gt; or &lt;code&gt;select&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;S price, area, bedrooms, parking&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Query current data frame for columns/functions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;F&lt;/code&gt; or &lt;code&gt;filter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;F price &amp;lt; 20000 AND bedrooms &amp;gt; 4&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Filter current data frame, keeping rows were the condition(s) match&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;O&lt;/code&gt; or &lt;code&gt;order&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;O area&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sort current data frame by column(s)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tabn&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tabn SELECT * FORM user WHERE balance &amp;gt; 1000&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Create a new tab with the given query&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;q&lt;/code&gt; or &lt;code&gt;quit&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;q&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Return to table from sheet view otherwise quit&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;schema&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;schema&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show loaded data frame(s) alongside their path(s)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;reset&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;reset&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Reset the table to the original data frame&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;help&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;help&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show help menu&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Themes&lt;/h2&gt; 
&lt;h3&gt;Monokai (default):&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/shshemi/tabiew/main/images/theme-monokai.png" alt="Image Alt text" title="Monokai" /&gt;&lt;/p&gt; 
&lt;h3&gt;Argonaut:&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/shshemi/tabiew/main/images/theme-argonaut.png" alt="Image Alt text" title="Argonaut" /&gt;&lt;/p&gt; 
&lt;h3&gt;Nord:&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/shshemi/tabiew/main/images/theme-nord.png" alt="Image Alt text" title="Nord" /&gt;&lt;/p&gt; 
&lt;h3&gt;Catppuccin:&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/shshemi/tabiew/main/images/theme-catppuccin.png" alt="Image Alt text" title="Catppuccin" /&gt;&lt;/p&gt; 
&lt;h3&gt;Tokyo Night:&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/shshemi/tabiew/main/images/theme-tokyo-night.png" alt="Image Alt text" title="Tokyo Night" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please fork the repository and submit pull requests with your features and bug fixes.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>emmett-framework/granian</title>
      <link>https://github.com/emmett-framework/granian</link>
      <description>&lt;p&gt;A Rust HTTP server for Python applications&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="550" src="https://emmett.sh/static/img/granian-logo-xb-fw.png" alt="granian" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt;The Rust HTTP server for Python&lt;/em&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Granian is a Rust HTTP server for Python applications built on top of &lt;a href="https://github.com/hyperium/hyper"&gt;Hyper&lt;/a&gt; and &lt;a href="https://github.com/tokio-rs/tokio"&gt;Tokio&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Rationale&lt;/h2&gt; 
&lt;p&gt;The main reasons behind Granian design are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have a single, correct HTTP implementation, supporting versions 1, 2 (and eventually 3)&lt;/li&gt; 
 &lt;li&gt;Provide a single package for several platforms&lt;/li&gt; 
 &lt;li&gt;Avoid the usual Gunicorn + uvicorn + http-tools dependency composition on unix systems&lt;/li&gt; 
 &lt;li&gt;Provide stable &lt;a href="https://github.com/emmett-framework/granian/raw/master/benchmarks/vs.md"&gt;performance&lt;/a&gt; when compared to existing alternatives&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Adopting Granian would thus be a good choice when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;wanting a modern, single dependency to serve both ASGI and WSGI applications&lt;/li&gt; 
 &lt;li&gt;looking for the most performant way to serve your Python application under HTTP/2&lt;/li&gt; 
 &lt;li&gt;you need great concurrency capabilities, especially with websockets&lt;/li&gt; 
 &lt;li&gt;you care about performance more than everything else&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;On the other hand, Granian won't be the ideal option if:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you want a &lt;em&gt;pure Python&lt;/em&gt; solution&lt;/li&gt; 
 &lt;li&gt;you need advanced debugging features&lt;/li&gt; 
 &lt;li&gt;your application relies on &lt;code&gt;trio&lt;/code&gt; or &lt;code&gt;gevent&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;you're looking for ASGI extensions &lt;a href="https://github.com/emmett-framework/granian/issues/93"&gt;not (yet) implemented&lt;/a&gt; like trailers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports ASGI/3, &lt;a href="https://github.com/emmett-framework/granian/raw/master/docs/spec/RSGI.md"&gt;RSGI&lt;/a&gt; and WSGI interface applications&lt;/li&gt; 
 &lt;li&gt;HTTP/1 and HTTP/2 protocols&lt;/li&gt; 
 &lt;li&gt;HTTPS and mTLS&lt;/li&gt; 
 &lt;li&gt;Websockets&lt;/li&gt; 
 &lt;li&gt;Direct static files serving&lt;/li&gt; 
 &lt;li&gt;ASGI &lt;a href="https://asgi.readthedocs.io/en/latest/extensions.html#path-send"&gt;pathsend&lt;/a&gt; extension&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;You can install Granian using pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install granian
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ASGI&lt;/h3&gt; 
&lt;p&gt;Create an application in your &lt;code&gt;main.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;async def app(scope, receive, send):
    assert scope['type'] == 'http'

    await send({
        'type': 'http.response.start',
        'status': 200,
        'headers': [
            [b'content-type', b'text/plain'],
        ],
    })
    await send({
        'type': 'http.response.body',
        'body': b'Hello, world!',
    })
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and serve it using Granian CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ granian --interface asgi main:app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;RSGI&lt;/h3&gt; 
&lt;p&gt;Create an application your &lt;code&gt;main.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;async def app(scope, proto):
    assert scope.proto == 'http'

    proto.response_str(
        status=200,
        headers=[
            ('content-type', 'text/plain')
        ],
        body="Hello, world!"
    )
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and serve it using Granian CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ granian --interface rsgi main:app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;WSGI&lt;/h3&gt; 
&lt;p&gt;Create an application your &lt;code&gt;main.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def app(environ, start_response):
    start_response('200 OK', [('content-type', 'text/plain')])
    return [b"Hello, world!"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and serve it using Granian CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ granian --interface wsgi main:app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Extra dependencies&lt;/h2&gt; 
&lt;p&gt;Mind that Granian also provides several extra dependencies you might be interested into, in particular:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;dotenv (allows to load environment files)&lt;/li&gt; 
 &lt;li&gt;pname (allows to customize processes' names)&lt;/li&gt; 
 &lt;li&gt;reload (adds reload on changes functionality)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/rloop/"&gt;rloop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/uvloop/"&gt;uvloop&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can combine the above extras to suit your needs, eg:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install granian[pname,uvloop]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For further information, check the options below.&lt;/p&gt; 
&lt;h2&gt;Options&lt;/h2&gt; 
&lt;p&gt;You can check all the options provided by Granian with the &lt;code&gt;--help&lt;/code&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ granian --help
Usage: granian [OPTIONS] APP

  APP  Application target to serve.  [required]

Options:
  --host TEXT                     Host address to bind to  [env var:
                                  GRANIAN_HOST; default: (127.0.0.1)]
  --port INTEGER                  Port to bind to.  [env var: GRANIAN_PORT;
                                  default: 8000]
  --uds PATH                      Unix Domain Socket to bind to.  [env var:
                                  GRANIAN_UDS]
  --interface [asgi|asginl|rsgi|wsgi]
                                  Application interface type  [env var:
                                  GRANIAN_INTERFACE; default: (rsgi)]
  --http [auto|1|2]               HTTP version  [env var: GRANIAN_HTTP;
                                  default: (auto)]
  --ws / --no-ws                  Enable websockets handling  [env var:
                                  GRANIAN_WEBSOCKETS; default: (enabled)]
  --workers INTEGER RANGE         Number of worker processes  [env var:
                                  GRANIAN_WORKERS; default: 1; x&amp;gt;=1]
  --blocking-threads INTEGER RANGE
                                  Number of blocking threads (per worker)
                                  [env var: GRANIAN_BLOCKING_THREADS; x&amp;gt;=1]
  --blocking-threads-idle-timeout DURATION
                                  The maximum amount of time in seconds (or a
                                  human-readable duration) an idle blocking
                                  thread will be kept alive  [env var:
                                  GRANIAN_BLOCKING_THREADS_IDLE_TIMEOUT;
                                  default: 30; 10&amp;lt;=x&amp;lt;=600]
  --runtime-threads INTEGER RANGE
                                  Number of runtime threads (per worker)  [env
                                  var: GRANIAN_RUNTIME_THREADS; default: 1;
                                  x&amp;gt;=1]
  --runtime-blocking-threads INTEGER RANGE
                                  Number of runtime I/O blocking threads (per
                                  worker)  [env var:
                                  GRANIAN_RUNTIME_BLOCKING_THREADS; x&amp;gt;=1]
  --runtime-mode [mt|st]          Runtime mode to use (single/multi threaded)
                                  [env var: GRANIAN_RUNTIME_MODE; default:
                                  (st)]
  --loop [auto|asyncio|rloop|uvloop]
                                  Event loop implementation  [env var:
                                  GRANIAN_LOOP; default: (auto)]
  --task-impl [asyncio|rust]      Async task implementation to use  [env var:
                                  GRANIAN_TASK_IMPL; default: (asyncio)]
  --backlog INTEGER RANGE         Maximum number of connections to hold in
                                  backlog (globally)  [env var:
                                  GRANIAN_BACKLOG; default: 1024; x&amp;gt;=128]
  --backpressure INTEGER RANGE    Maximum number of requests to process
                                  concurrently (per worker)  [env var:
                                  GRANIAN_BACKPRESSURE; default:
                                  (backlog/workers); x&amp;gt;=1]
  --http1-buffer-size INTEGER RANGE
                                  Sets the maximum buffer size for HTTP/1
                                  connections  [env var:
                                  GRANIAN_HTTP1_BUFFER_SIZE; default: 417792;
                                  x&amp;gt;=8192]
  --http1-header-read-timeout INTEGER RANGE
                                  Sets a timeout (in milliseconds) to read
                                  headers  [env var:
                                  GRANIAN_HTTP1_HEADER_READ_TIMEOUT; default:
                                  30000; 1&amp;lt;=x&amp;lt;=60000]
  --http1-keep-alive / --no-http1-keep-alive
                                  Enables or disables HTTP/1 keep-alive  [env
                                  var: GRANIAN_HTTP1_KEEP_ALIVE; default:
                                  (enabled)]
  --http1-pipeline-flush / --no-http1-pipeline-flush
                                  Aggregates HTTP/1 flushes to better support
                                  pipelined responses (experimental)  [env
                                  var: GRANIAN_HTTP1_PIPELINE_FLUSH; default:
                                  (disabled)]
  --http2-adaptive-window / --no-http2-adaptive-window
                                  Sets whether to use an adaptive flow control
                                  for HTTP2  [env var:
                                  GRANIAN_HTTP2_ADAPTIVE_WINDOW; default:
                                  (disabled)]
  --http2-initial-connection-window-size INTEGER RANGE
                                  Sets the max connection-level flow control
                                  for HTTP2  [env var: GRANIAN_HTTP2_INITIAL_C
                                  ONNECTION_WINDOW_SIZE; default: 1048576;
                                  x&amp;gt;=1024]
  --http2-initial-stream-window-size INTEGER RANGE
                                  Sets the `SETTINGS_INITIAL_WINDOW_SIZE`
                                  option for HTTP2 stream-level flow control
                                  [env var:
                                  GRANIAN_HTTP2_INITIAL_STREAM_WINDOW_SIZE;
                                  default: 1048576; x&amp;gt;=1024]
  --http2-keep-alive-interval INTEGER RANGE
                                  Sets an interval (in milliseconds) for HTTP2
                                  Ping frames should be sent to keep a
                                  connection alive  [env var:
                                  GRANIAN_HTTP2_KEEP_ALIVE_INTERVAL;
                                  1&amp;lt;=x&amp;lt;=60000]
  --http2-keep-alive-timeout DURATION
                                  Sets a timeout (in seconds or a human-
                                  readable duration) for receiving an
                                  acknowledgement of the HTTP2 keep-alive ping
                                  [env var: GRANIAN_HTTP2_KEEP_ALIVE_TIMEOUT;
                                  default: 20; x&amp;gt;=1]
  --http2-max-concurrent-streams INTEGER RANGE
                                  Sets the SETTINGS_MAX_CONCURRENT_STREAMS
                                  option for HTTP2 connections  [env var:
                                  GRANIAN_HTTP2_MAX_CONCURRENT_STREAMS;
                                  default: 200; x&amp;gt;=10]
  --http2-max-frame-size INTEGER RANGE
                                  Sets the maximum frame size to use for HTTP2
                                  [env var: GRANIAN_HTTP2_MAX_FRAME_SIZE;
                                  default: 16384; x&amp;gt;=1024]
  --http2-max-headers-size INTEGER RANGE
                                  Sets the max size of received header frames
                                  [env var: GRANIAN_HTTP2_MAX_HEADERS_SIZE;
                                  default: 16777216; x&amp;gt;=1]
  --http2-max-send-buffer-size INTEGER RANGE
                                  Set the maximum write buffer size for each
                                  HTTP/2 stream  [env var:
                                  GRANIAN_HTTP2_MAX_SEND_BUFFER_SIZE; default:
                                  409600; x&amp;gt;=1024]
  --log / --no-log                Enable logging  [env var:
                                  GRANIAN_LOG_ENABLED; default: (enabled)]
  --log-level [critical|error|warning|warn|info|debug|notset]
                                  Log level  [env var: GRANIAN_LOG_LEVEL;
                                  default: (info)]
  --log-config FILE               Logging configuration file (json)  [env var:
                                  GRANIAN_LOG_CONFIG]
  --access-log / --no-access-log  Enable access log  [env var:
                                  GRANIAN_LOG_ACCESS_ENABLED; default:
                                  (disabled)]
  --access-log-fmt TEXT           Access log format  [env var:
                                  GRANIAN_LOG_ACCESS_FMT]
  --ssl-certificate FILE          SSL certificate file  [env var:
                                  GRANIAN_SSL_CERTIFICATE]
  --ssl-keyfile FILE              SSL key file  [env var: GRANIAN_SSL_KEYFILE]
  --ssl-keyfile-password TEXT     SSL key password  [env var:
                                  GRANIAN_SSL_KEYFILE_PASSWORD]
  --ssl-ca FILE                   Root SSL cerificate file for client
                                  verification  [env var: GRANIAN_SSL_CA]
  --ssl-crl FILE                  SSL CRL file(s)  [env var: GRANIAN_SSL_CRL]
  --ssl-client-verify / --no-ssl-client-verify
                                  Verify clients SSL certificates  [env var:
                                  GRANIAN_SSL_CLIENT_VERIFY; default:
                                  (disabled)]
  --url-path-prefix TEXT          URL path prefix the app is mounted on  [env
                                  var: GRANIAN_URL_PATH_PREFIX]
  --respawn-failed-workers / --no-respawn-failed-workers
                                  Enable workers respawn on unexpected exit
                                  [env var: GRANIAN_RESPAWN_FAILED_WORKERS;
                                  default: (disabled)]
  --respawn-interval FLOAT        The number of seconds to sleep between
                                  workers respawn  [env var:
                                  GRANIAN_RESPAWN_INTERVAL; default: 3.5]
  --rss-sample-interval DURATION  The sample rate in seconds (or a human-
                                  readable duration) for the resource monitor
                                  [env var: GRANIAN_RSS_SAMPLE_INTERVAL;
                                  default: 30; 10&amp;lt;=x&amp;lt;=300]
  --workers-lifetime DURATION     The maximum amount of time in seconds (or a
                                  human-readable duration) a worker will be
                                  kept alive before respawn  [env var:
                                  GRANIAN_WORKERS_LIFETIME; x&amp;gt;=60]
  --workers-max-rss INTEGER RANGE
                                  The maximum amount of memory (in MiB) a
                                  worker can consume before respawn  [env var:
                                  GRANIAN_WORKERS_MAX_RSS; x&amp;gt;=1]
  --workers-kill-timeout DURATION
                                  The amount of time in seconds (or a human-
                                  readable duration) to wait for killing
                                  workers that refused to gracefully stop
                                  [env var: GRANIAN_WORKERS_KILL_TIMEOUT;
                                  default: (disabled); 1&amp;lt;=x&amp;lt;=1800]
  --factory / --no-factory        Treat target as a factory function, that
                                  should be invoked to build the actual target
                                  [env var: GRANIAN_FACTORY; default:
                                  (disabled)]
  --working-dir DIRECTORY         Set the working directory  [env var:
                                  GRANIAN_WORKING_DIR]
  --env-files FILE                Environment file(s) to load (requires
                                  granian[dotenv] extra)  [env var:
                                  GRANIAN_ENV_FILES]
  --static-path-route TEXT        Route for static file serving  [env var:
                                  GRANIAN_STATIC_PATH_ROUTE; default:
                                  (/static)]
  --static-path-mount DIRECTORY   Path to mount for static file serving  [env
                                  var: GRANIAN_STATIC_PATH_MOUNT]
  --static-path-expires DURATION  Cache headers expiration (in seconds or a
                                  human-readable duration) for static file
                                  serving. 0 to disable.  [env var:
                                  GRANIAN_STATIC_PATH_EXPIRES; default: 86400;
                                  x&amp;gt;=0]
  --reload / --no-reload          Enable auto reload on application's files
                                  changes (requires granian[reload] extra)
                                  [env var: GRANIAN_RELOAD; default:
                                  (disabled)]
  --reload-paths PATH             Paths to watch for changes  [env var:
                                  GRANIAN_RELOAD_PATHS; default: (Working
                                  directory)]
  --reload-ignore-dirs TEXT       Names of directories to ignore changes for.
                                  Extends the default list of directories to
                                  ignore in watchfiles' default filter  [env
                                  var: GRANIAN_RELOAD_IGNORE_DIRS]
  --reload-ignore-patterns TEXT   File/directory name patterns (regex) to
                                  ignore changes for. Extends the default list
                                  of patterns to ignore in watchfiles' default
                                  filter  [env var:
                                  GRANIAN_RELOAD_IGNORE_PATTERNS]
  --reload-ignore-paths PATH      Absolute paths to ignore changes for  [env
                                  var: GRANIAN_RELOAD_IGNORE_PATHS]
  --reload-tick INTEGER RANGE     The tick frequency (in milliseconds) the
                                  reloader watch for changes  [env var:
                                  GRANIAN_RELOAD_TICK; default: 50;
                                  50&amp;lt;=x&amp;lt;=5000]
  --reload-ignore-worker-failure / --no-reload-ignore-worker-failure
                                  Ignore worker failures when auto reload is
                                  enabled  [env var:
                                  GRANIAN_RELOAD_IGNORE_WORKER_FAILURE;
                                  default: (disabled)]
  --process-name TEXT             Set a custom name for processes (requires
                                  granian[pname] extra)  [env var:
                                  GRANIAN_PROCESS_NAME]
  --pid-file FILE                 A path to write the PID file to  [env var:
                                  GRANIAN_PID_FILE]
  --version                       Show the version and exit.
  --help                          Show this message and exit.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Human-readable durations&lt;/h3&gt; 
&lt;p&gt;Whenever Granian accepts a duration, it can be specified either as sole number, in which case it is interpreted as a number of seconds, or using one of the following suffixes:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;suffix&lt;/th&gt; 
   &lt;th&gt;meaning&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;s&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;seconds (same as no suffix)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;m&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;minutes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;h&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;hours&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;d&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;days&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Logging&lt;/h3&gt; 
&lt;p&gt;Despite being a Rust project, Granian is a good Python citizen and uses the standard library's &lt;a href="https://docs.python.org/3/library/logging.html"&gt;&lt;code&gt;logging&lt;/code&gt;&lt;/a&gt; module to produce logs. This means you can freely configure your logging level and format using the &lt;a href="https://docs.python.org/3/howto/logging.html"&gt;standard idioms&lt;/a&gt; you probably familiar with.&lt;/p&gt; 
&lt;p&gt;As many other web servers, Granian uses two different loggers, specifically:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;code&gt;_granian&lt;/code&gt; logger for runtime messages&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;granian.access&lt;/code&gt; logger for access logs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Access log format&lt;/h3&gt; 
&lt;p&gt;The access log format can be configured by specifying the atoms (see below) to include in a specific format. By default Granian will use &lt;code&gt;[%(time)s] %(addr)s - "%(method)s %(path)s %(protocol)s" %(status)d %(dt_ms).3f&lt;/code&gt; as the format.&lt;/p&gt; 
&lt;h4&gt;Access log atoms&lt;/h4&gt; 
&lt;p&gt;The following atoms are available for use:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;identifier&lt;/th&gt; 
   &lt;th&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;addr&lt;/td&gt; 
   &lt;td&gt;Client remote address&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;time&lt;/td&gt; 
   &lt;td&gt;Datetime of the request&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;dt_ms&lt;/td&gt; 
   &lt;td&gt;Request duration in ms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;status&lt;/td&gt; 
   &lt;td&gt;HTTP response status&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;path&lt;/td&gt; 
   &lt;td&gt;Request path (without query string)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;query_string&lt;/td&gt; 
   &lt;td&gt;Request query string&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;method&lt;/td&gt; 
   &lt;td&gt;Request HTTP method&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;scheme&lt;/td&gt; 
   &lt;td&gt;Request scheme&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;protocol&lt;/td&gt; 
   &lt;td&gt;HTTP protocol version&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Workers and threads&lt;/h3&gt; 
&lt;p&gt;Granian offers different options to configure the number of workers and threads to be run, in particular:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;workers&lt;/strong&gt;: the total number of processes holding a dedicated Python interpreter that will run the application&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;blocking threads&lt;/strong&gt;: the number of threads per worker interacting with the Python interpreter&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;runtime threads&lt;/strong&gt;: the number of Rust threads per worker that will perform network I/O&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;runtime blocking threads&lt;/strong&gt;: the number of Rust threads per worker involved in blocking operations. The main role of these threads is dealing with blocking I/O ‚Äì&amp;nbsp;like file system operations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In general, Granian will try its best to automatically pick proper values for the threading configuration, leaving to you the responsibility to choose the number of workers you need.&lt;br /&gt; There is no &lt;em&gt;golden rule&lt;/em&gt; here, as these numbers will vastly depend both on your application behavior and the deployment target, but we can list some suggestions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;matching the amount of CPU cores for the workers is generally the best starting point; on containerized environments like docker or k8s is best to have 1 worker per container though and scale your containers using the relevant orchestrator;&lt;/li&gt; 
 &lt;li&gt;the default number of &lt;strong&gt;runtime threads&lt;/strong&gt; and &lt;strong&gt;runtime blocking threads&lt;/strong&gt; is fine for the vast majority of applications out there; you might want to increase the first for applications dealing with several concurrently opened websockets or if you primarily use HTTP/2, and lowering the second only if you serve the same few files to a lot of connections;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In regards of blocking threads, the option is irrelevant on asynchronous protocols, as all the interop will happen with the AsyncIO event loop which will also be the one holding the GIL for the vast majority of the time, and thus the value is fixed to a single thread; on synchronous protocols like WSGI instead, it will be the maximum amount of threads interacting ‚Äì and thus trying to acquire the GIL ‚Äì&amp;nbsp;with your application code. All those threads will be spawned on-demand depending on the amount of concurrency, and they'll be shutdown after the amount of inactivity time specified with the relevant setting.&lt;br /&gt; In general, and unless you have a very specific use-case to do so (for example, if your application have an average millisecond response, a very limited amount of blocking threads usually delivers better throughput) you should avoid to tune this threadpool size and configure a backpressure value that suits your needs instead. In that regards, please check the next section.&lt;/p&gt; 
&lt;p&gt;Also, &lt;strong&gt;you should generally avoid to configure workers and threads based on numbers suggested for other servers&lt;/strong&gt;, as Granian architecture is quite different from projects like Gunicorn or Uvicorn.&lt;/p&gt; 
&lt;h3&gt;Backpressure&lt;/h3&gt; 
&lt;p&gt;Since Granian runs a separated Rust runtime aside of your application that will handle I/O and "send work" to the Python interpreter, a mechanism to avoid pushing more work that what the Python interpreter can actually do is provided: backpressure.&lt;/p&gt; 
&lt;p&gt;Backpressure in Granian operates at the single worker's connections accept loop, practically interrupting the loop in case too many requests are waiting to be processed down the line. You can think of it as &lt;em&gt;a secondary backlog&lt;/em&gt;, handled by Granian itself in addition to the network stack one provided by the OS kernel (and configured with apposite parameter).&lt;/p&gt; 
&lt;p&gt;While on asynchronous protocols, the default value for the backpressure should work fine for the vast majority of applications, as &lt;em&gt;work&lt;/em&gt; will be handled and suspended by the AsyncIO event loop, on synchronous protocols there's no way to predict the amount of interrupts (and thus GIL releases) your application would do on a single request, and thus you should configure a value that makes sense in your environment. For example, if your WSGI application never does I/O within a request-reponse flow, then you can't really go beyond serial, and thus any backpressure value above 2 wouldn't probably make any difference, as all the requests will just be waiting to acquire the GIL in order to be processed. On the other hand, if your application makes external network requests within the standard request-response flow, a large backpressure can help, as during the time spent on those code paths you can still process other requests. Another example would be if your application communicate with a database, and you have a limited amount of connections that can be opened to that database: in this case setting the backpressure to that value would definitely be the best option.&lt;/p&gt; 
&lt;p&gt;In general, think of backpressure as the maximum amount of concurrency you want to handle (per worker) in your application, after which Granian will halt and wait before pushing more work.&lt;/p&gt; 
&lt;h3&gt;Runtime mode&lt;/h3&gt; 
&lt;p&gt;Granian offers two different runtime threading paradigms, due to the fact the runtime can be multi-threaded ‚Äì in opposition to what happens in Python event-loop which can only run as a single thread.&lt;/p&gt; 
&lt;p&gt;Given you specify N threads with the relevant option, in &lt;strong&gt;st&lt;/strong&gt; mode Granian will spawn N single-threaded Rust runtimes, while in &lt;strong&gt;mt&lt;/strong&gt; mode Granian will spawn a single multi-threaded runtime with N threads.&lt;/p&gt; 
&lt;p&gt;Benchmarks suggests &lt;strong&gt;st&lt;/strong&gt; mode to be more efficient with a small amount of processes, while &lt;strong&gt;mt&lt;/strong&gt; mode seems to scale more efficiently where you have a large number of CPUs. Real performance will though depend on specific application code, and thus &lt;em&gt;your mileage might vary&lt;/em&gt;.&lt;/p&gt; 
&lt;h3&gt;Proxies and forwarded headers&lt;/h3&gt; 
&lt;p&gt;Since none of the supported applications protocols define a strategy for proxies' &lt;em&gt;forwarded headers&lt;/em&gt;, Granian doesn't provide any option to configure its behaviour around them.&lt;/p&gt; 
&lt;p&gt;What Granian provides instead, for contexts in which is being run behind a reverse proxy, are &lt;em&gt;wrappers&lt;/em&gt; you can use on top of your application, in order to alter the request scope based on the headers forwarded by the proxy itself. You can find such wrappers in the &lt;code&gt;granian.utils.proxies&lt;/code&gt; module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from granian.utils.proxies import wrap_asgi_with_proxy_headers, wrap_wsgi_with_proxy_headers

async def my_asgi_app(scope, receive, send):
    ...

def my_wsgi_app(environ, start_response):
    ...

my_asgi_app = wrap_asgi_with_proxy_headers(my_asgi_app, trusted_hosts="1.2.3.4")
my_wsgi_app = wrap_wsgi_with_proxy_headers(my_wsgi_app, trusted_hosts="1.2.3.4")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Free-threaded Python&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; free-threaded Python support is still experimental and highly discouraged in &lt;em&gt;production environments&lt;/em&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Since version 2.0 Granian supports free-threaded Python. While the installation process remains the same, as wheels for the free-threaded version are published separately, here we list some key differences from the GIL version.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Workers are threads instead of separated processes, so there will always be a single Python interpreter running&lt;/li&gt; 
 &lt;li&gt;The application is thus loaded a single time and shared between workers&lt;/li&gt; 
 &lt;li&gt;In asynchronous protocols like ASGI and RSGI each worker runs its own AsyncIO event loop like the GIL version, but the loop will run in the worker thread instead of the Python main thread&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; if for any reason the GIL gets enabled on the free-threaded build, Granian will refuse to start. This means you can't use the free-threaded build on GIL enabled interpreters.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;While for asynchronous protocols nothing really changes in terms of workers and threads configuration, as the scaling will be still driven by the number of AsyncIO event loops running (so the same rules for GIL workers apply), on synchronous protocols like WSGI every GIL-related limitation is theoretically absent.&lt;br /&gt; While the general rules in terms of I/O-bound vs CPU-bound load still apply, at the time being there's not enough data to make suggestions in terms of workers and threads tuning in the free-threaded Python land, and thus you will need to experiment with those values depending on your specific workload.&lt;/p&gt; 
&lt;h2&gt;Customising Granian&lt;/h2&gt; 
&lt;p&gt;Running Granian directly from Python instead of its CLI gives you access to some customization interfaces that let you alter its standard behaviour.&lt;/p&gt; 
&lt;h3&gt;AsyncIO event loop initialization&lt;/h3&gt; 
&lt;p&gt;As soon as you run Granian directly from Python instead of its CLI, you can customise the default event loop initialisation policy by overwriting the &lt;code&gt;auto&lt;/code&gt; policy. Let's say, for instance, you want to use the selector event loop on Windows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from granian import Granian, loops

@loops.register('auto')
def build_loop():
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return asyncio.new_event_loop()


Granian(...).serve()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hooks&lt;/h3&gt; 
&lt;p&gt;Granian provides hooks registration interfaces to run code during specific phases of its lifecycle. Specifically, you have the following methods available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;on_startup&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;on_shutdown&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;on_reload&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The mentioned methods accept a callable with no arguments that will be invoked during the relevant lifecycle phases. You can register your hooks simply passing them to the relevant method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from granian import Granian

def my_hook():
    print("hello from reload!")

server = Granian(...)
server.on_reload(my_hook)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Embedding Granian in your project&lt;/h3&gt; 
&lt;p&gt;For projects requiring advance lifecycle management, or implementing their own process management strategy, Granian provides an &lt;em&gt;embeddable&lt;/em&gt; server implementation, which provides async interfaces and won't spawn workers as processes or threads, but will run them as AsyncIO tasks.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; the embeddable server is still experimental.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; the embeddable server only supports async protocols, thus WSGI is not supported. It's also limited to a single worker, as it runs over an existing event loop.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To embed Granian in your project, you can import the server from the relevant module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from granian.server.embed import Server

server = Server(my_app, interface="asgi")

async def my_main():
    await server.serve()
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; as you might already figured out, the embed server accepts the application object as its first argument, instead of the import target string of the standard servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Given the &lt;code&gt;serve&lt;/code&gt; method is now async, the embeddable server also provides two methods to manage its lifecycle, specifically:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;stop&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;reload&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The idea is that you can spawn the server as a task, and later on interact with it in your own process loop:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;async def my_main():
    server_task = asyncio.create_task(server.serve())
    await my_logic()
    server.stop()
    await server_task
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Project status&lt;/h2&gt; 
&lt;p&gt;Granian is being actively maintained and is compatible with Python 3.9 and above versions.&lt;/p&gt; 
&lt;p&gt;Granian follows a &lt;em&gt;semantic versioning&lt;/em&gt; scheme for its releases, with a &lt;code&gt;{major}.{minor}.{patch}&lt;/code&gt; scheme for versions numbers, where:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;major&lt;/em&gt; versions might introduce breaking changes&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;minor&lt;/em&gt; versions introduce new features and backward compatible changes&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;patch&lt;/em&gt; versions only introduce bug and security fixes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Mind that bug and security fixes are &lt;strong&gt;usually provided for the latest minor version only&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Granian is used &lt;em&gt;in production&lt;/em&gt; by some popular projects like &lt;a href="https://github.com/paperless-ngx/paperless-ngx/raw/v2.17.1/pyproject.toml#L81"&gt;paperless-ngx&lt;/a&gt; and &lt;a href="https://github.com/reflex-dev/reflex/raw/v0.7.14/pyproject.toml#L25"&gt;reflex&lt;/a&gt;, and by &lt;em&gt;famous companies&lt;/em&gt; like &lt;a href="https://github.com/mozilla/bedrock/raw/2025-06-25/requirements/prod.in#L33"&gt;Mozilla&lt;/a&gt; and &lt;a href="https://github.com/microsoft/call-center-ai/raw/958b3192020ab8a49cabd328a873eaa70e8865bc/pyproject.toml#L26"&gt;Microsoft&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Granian is released under the BSD License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cloudflare/quiche</title>
      <link>https://github.com/cloudflare/quiche</link>
      <description>&lt;p&gt;ü•ß Savoury implementation of the QUIC transport protocol and HTTP/3&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudflare/quiche/master/quiche.svg?sanitize=true" alt="quiche" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/quiche"&gt;&lt;img src="https://img.shields.io/crates/v/quiche.svg?sanitize=true" alt="crates.io" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/quiche"&gt;&lt;img src="https://docs.rs/quiche/badge.svg?sanitize=true" alt="docs.rs" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/BSD-2-Clause"&gt;&lt;img src="https://img.shields.io/github/license/cloudflare/quiche.svg?sanitize=true" alt="license" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/cloudflare/quiche/stable.yml?branch=master" alt="build" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.quic.tech/quiche/"&gt;quiche&lt;/a&gt; is an implementation of the QUIC transport protocol and HTTP/3 as specified by the &lt;a href="https://quicwg.org/"&gt;IETF&lt;/a&gt;. It provides a low level API for processing QUIC packets and handling connection state. The application is responsible for providing I/O (e.g. sockets handling) as well as an event loop with support for timers.&lt;/p&gt; 
&lt;p&gt;For more information on how quiche came about and some insights into its design you can read a &lt;a href="https://blog.cloudflare.com/enjoy-a-slice-of-quic-and-rust/"&gt;post&lt;/a&gt; on Cloudflare's blog that goes into some more detail.&lt;/p&gt; 
&lt;h2&gt;Who uses quiche?&lt;/h2&gt; 
&lt;h3&gt;Cloudflare&lt;/h3&gt; 
&lt;p&gt;quiche powers Cloudflare edge network's &lt;a href="https://blog.cloudflare.com/http3-the-past-present-and-future/"&gt;HTTP/3 support&lt;/a&gt;. The &lt;a href="https://cloudflare-quic.com"&gt;cloudflare-quic.com&lt;/a&gt; website can be used for testing and experimentation.&lt;/p&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;p&gt;Android's DNS resolver uses quiche to &lt;a href="https://security.googleblog.com/2022/07/dns-over-http3-in-android.html"&gt;implement DNS over HTTP/3&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;curl&lt;/h3&gt; 
&lt;p&gt;quiche can be &lt;a href="https://github.com/curl/curl/raw/master/docs/HTTP3.md#quiche-version"&gt;integrated into curl&lt;/a&gt; to provide support for HTTP/3.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Command-line apps&lt;/h3&gt; 
&lt;p&gt;Before diving into the quiche API, here are a few examples on how to use the quiche tools provided as part of the &lt;a href="https://raw.githubusercontent.com/cloudflare/quiche/master/apps/"&gt;quiche-apps&lt;/a&gt; crate.&lt;/p&gt; 
&lt;p&gt;After cloning the project according to the command mentioned in the &lt;a href="https://raw.githubusercontent.com/cloudflare/quiche/master/#building"&gt;building&lt;/a&gt; section, the client can be run as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo run --bin quiche-client -- https://cloudflare-quic.com/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;while the server can be run as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo run --bin quiche-server -- --cert apps/src/bin/cert.crt --key apps/src/bin/cert.key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(note that the certificate provided is self-signed and should not be used in production)&lt;/p&gt; 
&lt;p&gt;Use the &lt;code&gt;--help&lt;/code&gt; command-line flag to get a more detailed description of each tool's options.&lt;/p&gt; 
&lt;h3&gt;Configuring connections&lt;/h3&gt; 
&lt;p&gt;The first step in establishing a QUIC connection using quiche is creating a &lt;a href="https://docs.quic.tech/quiche/struct.Config.html"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; object:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let mut config = quiche::Config::new(quiche::PROTOCOL_VERSION)?;
config.set_application_protos(&amp;amp;[b"example-proto"]);

// Additional configuration specific to application and use case...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;a href="https://docs.quic.tech/quiche/struct.Config.html"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; object controls important aspects of the QUIC connection such as QUIC version, ALPN IDs, flow control, congestion control, idle timeout and other properties or features.&lt;/p&gt; 
&lt;p&gt;QUIC is a general-purpose transport protocol and there are several configuration properties where there is no reasonable default value. For example, the permitted number of concurrent streams of any particular type is dependent on the application running over QUIC, and other use-case specific concerns.&lt;/p&gt; 
&lt;p&gt;quiche defaults several properties to zero, applications most likely need to set these to something else to satisfy their needs using the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_bidi"&gt;&lt;code&gt;set_initial_max_streams_bidi()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_uni"&gt;&lt;code&gt;set_initial_max_streams_uni()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_data"&gt;&lt;code&gt;set_initial_max_data()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_local"&gt;&lt;code&gt;set_initial_max_stream_data_bidi_local()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_remote"&gt;&lt;code&gt;set_initial_max_stream_data_bidi_remote()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_uni"&gt;&lt;code&gt;set_initial_max_stream_data_uni()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://docs.quic.tech/quiche/struct.Config.html"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; also holds TLS configuration. This can be changed by mutators on the an existing object, or by constructing a TLS context manually and creating a configuration using &lt;a href="https://docs.quic.tech/quiche/struct.Config.html#method.with_boring_ssl_ctx_builder"&gt;&lt;code&gt;with_boring_ssl_ctx_builder()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;A configuration object can be shared among multiple connections.&lt;/p&gt; 
&lt;h3&gt;Connection setup&lt;/h3&gt; 
&lt;p&gt;On the client-side the &lt;a href="https://docs.quic.tech/quiche/fn.connect.html"&gt;&lt;code&gt;connect()&lt;/code&gt;&lt;/a&gt; utility function can be used to create a new connection, while &lt;a href="https://docs.quic.tech/quiche/fn.accept.html"&gt;&lt;code&gt;accept()&lt;/code&gt;&lt;/a&gt; is for servers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// Client connection.
let conn = quiche::connect(Some(&amp;amp;server_name), &amp;amp;scid, local, peer, &amp;amp;mut config)?;

// Server connection.
let conn = quiche::accept(&amp;amp;scid, None, local, peer, &amp;amp;mut config)?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Handling incoming packets&lt;/h3&gt; 
&lt;p&gt;Using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.recv"&gt;&lt;code&gt;recv()&lt;/code&gt;&lt;/a&gt; method the application can process incoming packets that belong to that connection from the network:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let to = socket.local_addr().unwrap();

loop {
    let (read, from) = socket.recv_from(&amp;amp;mut buf).unwrap();

    let recv_info = quiche::RecvInfo { from, to };

    let read = match conn.recv(&amp;amp;mut buf[..read], recv_info) {
        Ok(v) =&amp;gt; v,

        Err(e) =&amp;gt; {
            // An error occurred, handle it.
            break;
        },
    };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Generating outgoing packets&lt;/h3&gt; 
&lt;p&gt;Outgoing packet are generated using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.send"&gt;&lt;code&gt;send()&lt;/code&gt;&lt;/a&gt; method instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;loop {
    let (write, send_info) = match conn.send(&amp;amp;mut out) {
        Ok(v) =&amp;gt; v,

        Err(quiche::Error::Done) =&amp;gt; {
            // Done writing.
            break;
        },

        Err(e) =&amp;gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;amp;out[..write], &amp;amp;send_info.to).unwrap();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When packets are sent, the application is responsible for maintaining a timer to react to time-based connection events. The timer expiration can be obtained using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.timeout"&gt;&lt;code&gt;timeout()&lt;/code&gt;&lt;/a&gt; method.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let timeout = conn.timeout();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The application is responsible for providing a timer implementation, which can be specific to the operating system or networking framework used. When a timer expires, the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.on_timeout"&gt;&lt;code&gt;on_timeout()&lt;/code&gt;&lt;/a&gt; method should be called, after which additional packets might need to be sent on the network:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// Timeout expired, handle it.
conn.on_timeout();

// Send more packets as needed after timeout.
loop {
    let (write, send_info) = match conn.send(&amp;amp;mut out) {
        Ok(v) =&amp;gt; v,

        Err(quiche::Error::Done) =&amp;gt; {
            // Done writing.
            break;
        },

        Err(e) =&amp;gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;amp;out[..write], &amp;amp;send_info.to).unwrap();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Pacing&lt;/h4&gt; 
&lt;p&gt;It is recommended that applications &lt;a href="https://datatracker.ietf.org/doc/html/rfc9002#section-7.7"&gt;pace&lt;/a&gt; sending of outgoing packets to avoid creating packet bursts that could cause short-term congestion and losses in the network.&lt;/p&gt; 
&lt;p&gt;quiche exposes pacing hints for outgoing packets through the [&lt;code&gt;at&lt;/code&gt;] field of the [&lt;code&gt;SendInfo&lt;/code&gt;] structure that is returned by the &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.send"&gt;&lt;code&gt;send()&lt;/code&gt;&lt;/a&gt; method. This field represents the time when a specific packet should be sent into the network.&lt;/p&gt; 
&lt;p&gt;Applications can use these hints by artificially delaying the sending of packets through platform-specific mechanisms (such as the &lt;a href="https://man7.org/linux/man-pages/man8/tc-etf.8.html"&gt;&lt;code&gt;SO_TXTIME&lt;/code&gt;&lt;/a&gt; socket option on Linux), or custom methods (for example by using user-space timers).&lt;/p&gt; 
&lt;h3&gt;Sending and receiving stream data&lt;/h3&gt; 
&lt;p&gt;After some back and forth, the connection will complete its handshake and will be ready for sending or receiving application data.&lt;/p&gt; 
&lt;p&gt;Data can be sent on a stream by using the &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.stream_send"&gt;&lt;code&gt;stream_send()&lt;/code&gt;&lt;/a&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;if conn.is_established() {
    // Handshake completed, send some data on stream 0.
    conn.stream_send(0, b"hello", true)?;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The application can check whether there are any readable streams by using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.readable"&gt;&lt;code&gt;readable()&lt;/code&gt;&lt;/a&gt; method, which returns an iterator over all the streams that have outstanding data to read.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.stream_recv"&gt;&lt;code&gt;stream_recv()&lt;/code&gt;&lt;/a&gt; method can then be used to retrieve the application data from the readable stream:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;if conn.is_established() {
    // Iterate over readable streams.
    for stream_id in conn.readable() {
        // Stream is readable, read until there's no more data.
        while let Ok((read, fin)) = conn.stream_recv(stream_id, &amp;amp;mut buf) {
            println!("Got {} bytes on stream {}", read, stream_id);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;HTTP/3&lt;/h3&gt; 
&lt;p&gt;The quiche &lt;a href="https://docs.quic.tech/quiche/h3/index.html"&gt;HTTP/3 module&lt;/a&gt; provides a high level API for sending and receiving HTTP requests and responses on top of the QUIC transport protocol.&lt;/p&gt; 
&lt;p&gt;Have a look at the [quiche/examples/] directory for more complete examples on how to use the quiche API, including examples on how to use quiche in C/C++ applications (see below for more information).&lt;/p&gt; 
&lt;h2&gt;Calling quiche from C/C++&lt;/h2&gt; 
&lt;p&gt;quiche exposes a &lt;a href="https://github.com/cloudflare/quiche/raw/master/quiche/include/quiche.h"&gt;thin C API&lt;/a&gt; on top of the Rust API that can be used to more easily integrate quiche into C/C++ applications (as well as in other languages that allow calling C APIs via some form of FFI). The C API follows the same design of the Rust one, modulo the constraints imposed by the C language itself.&lt;/p&gt; 
&lt;p&gt;When running &lt;code&gt;cargo build&lt;/code&gt;, a static library called &lt;code&gt;libquiche.a&lt;/code&gt; will be built automatically alongside the Rust one. This is fully stand-alone and can be linked directly into C/C++ applications.&lt;/p&gt; 
&lt;p&gt;Note that in order to enable the FFI API, the &lt;code&gt;ffi&lt;/code&gt; feature must be enabled (it is disabled by default), by passing &lt;code&gt;--features ffi&lt;/code&gt; to &lt;code&gt;cargo&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;quiche requires Rust 1.82 or later to build. The latest stable Rust release can be installed using &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Once the Rust build environment is setup, the quiche source code can be fetched using git:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ git clone --recursive https://github.com/cloudflare/quiche
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and then built using cargo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo build --examples
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;cargo can also be used to run the testsuite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;a href="https://boringssl.googlesource.com/boringssl/"&gt;BoringSSL&lt;/a&gt;, which is used to implement QUIC's cryptographic handshake based on TLS, needs to be built and linked to quiche. This is done automatically when building quiche using cargo, but requires the &lt;code&gt;cmake&lt;/code&gt; command to be available during the build process. On Windows you also need &lt;a href="https://www.nasm.us/"&gt;NASM&lt;/a&gt;. The &lt;a href="https://github.com/google/boringssl/raw/master/BUILDING.md"&gt;official BoringSSL documentation&lt;/a&gt; has more details.&lt;/p&gt; 
&lt;p&gt;In alternative you can use your own custom build of BoringSSL by configuring the BoringSSL directory with the &lt;code&gt;QUICHE_BSSL_PATH&lt;/code&gt; environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ QUICHE_BSSL_PATH="/path/to/boringssl" cargo build --examples
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively you can use &lt;a href="https://github.com/quictls/openssl"&gt;OpenSSL/quictls&lt;/a&gt;. To enable quiche to use this vendor the &lt;code&gt;openssl&lt;/code&gt; feature can be added to the &lt;code&gt;--feature&lt;/code&gt; list. Be aware that &lt;code&gt;0-RTT&lt;/code&gt; is not supported if this vendor is used.&lt;/p&gt; 
&lt;h3&gt;Building for Android&lt;/h3&gt; 
&lt;p&gt;Building quiche for Android (NDK version 19 or higher, 21 recommended), can be done using &lt;a href="https://docs.rs/crate/cargo-ndk"&gt;cargo-ndk&lt;/a&gt; (v2.0 or later).&lt;/p&gt; 
&lt;p&gt;First the &lt;a href="https://developer.android.com/ndk"&gt;Android NDK&lt;/a&gt; needs to be installed, either using Android Studio or directly, and the &lt;code&gt;ANDROID_NDK_HOME&lt;/code&gt; environment variable needs to be set to the NDK installation path, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ export ANDROID_NDK_HOME=/usr/local/share/android-ndk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then the Rust toolchain for the Android architectures needed can be installed as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ rustup target add aarch64-linux-android armv7-linux-androideabi i686-linux-android x86_64-linux-android
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the minimum API level is 21 for all target architectures.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.rs/crate/cargo-ndk"&gt;cargo-ndk&lt;/a&gt; (v2.0 or later) also needs to be installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo install cargo-ndk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally the quiche library can be built using the following procedure. Note that the &lt;code&gt;-t &amp;lt;architecture&amp;gt;&lt;/code&gt; and &lt;code&gt;-p &amp;lt;NDK version&amp;gt;&lt;/code&gt; options are mandatory.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo ndk -t arm64-v8a -p 21 -- build --features ffi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://github.com/cloudflare/quiche/raw/master/tools/android/build_android_ndk19.sh"&gt;build_android_ndk19.sh&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Building for iOS&lt;/h3&gt; 
&lt;p&gt;To build quiche for iOS, you need the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install Xcode command-line tools. You can install them with Xcode or with the following command:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ xcode-select --install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the Rust toolchain for iOS architectures:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ rustup target add aarch64-apple-ios x86_64-apple-ios
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;cargo-lipo&lt;/code&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo install cargo-lipo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build libquiche, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo lipo --features ffi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo lipo --features ffi --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;iOS build is tested in Xcode 10.1 and Xcode 11.2.&lt;/p&gt; 
&lt;h3&gt;Building Docker images&lt;/h3&gt; 
&lt;p&gt;In order to build the Docker images, simply run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ make docker-build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find the quiche Docker images on the following Docker Hub repositories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/repository/docker/cloudflare/quiche"&gt;cloudflare/quiche&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/repository/docker/cloudflare/quiche-qns"&gt;cloudflare/quiche-qns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;latest&lt;/code&gt; tag will be updated whenever quiche master branch updates.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;cloudflare/quiche&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Provides a server and client installed in /usr/local/bin.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;cloudflare/quiche-qns&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Provides the script to test quiche within the &lt;a href="https://github.com/marten-seemann/quic-interop-runner"&gt;quic-interop-runner&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Copyright&lt;/h2&gt; 
&lt;p&gt;Copyright (C) 2018-2019, Cloudflare, Inc.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/cloudflare/quiche/tree/master/COPYING"&gt;COPYING&lt;/a&gt; for the license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>paradedb/paradedb</title>
      <link>https://github.com/paradedb/paradedb</link>
      <description>&lt;p&gt;ParadeDB is a modern Elasticsearch alternative built on Postgres. Built for real-time, update-heavy workloads.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://paradedb.com"&gt;&lt;img src="https://raw.githubusercontent.com/paradedb/paradedb/main/docs/logo/readme.svg?sanitize=true" alt="ParadeDB" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;b&gt;Postgres for Search and Analytics&lt;/b&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; &lt;a href="https://paradedb.com"&gt;Website&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.paradedb.com"&gt;Docs&lt;/a&gt; ‚Ä¢ &lt;a href="https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw"&gt;Community&lt;/a&gt; ‚Ä¢ &lt;a href="https://paradedb.com/blog/"&gt;Blog&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.paradedb.com/changelog/"&gt;Changelog&lt;/a&gt; &lt;/h3&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://artifacthub.io/packages/search?repo=paradedb"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/paradedb" alt="Artifact Hub" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/paradedb/paradedb"&gt;&lt;img src="https://img.shields.io/docker/pulls/paradedb/paradedb" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/paradedb/paradedb?tab=AGPL-3.0-1-ov-file#readme"&gt;&lt;img src="https://img.shields.io/github/license/paradedb/paradedb?color=blue" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw"&gt;&lt;img src="https://img.shields.io/badge/Join%20Slack-purple?logo=slack&amp;amp;link=https%3A%2F%2Fjoin.slack.com%2Ft%2Fparadedbcommunity%2Fshared_invite%2Fzt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw" alt="Slack URL" /&gt;&lt;/a&gt; &lt;a href="https://x.com/paradedb"&gt;&lt;img src="https://img.shields.io/twitter/url?url=https%3A%2F%2Ftwitter.com%2Fparadedb&amp;amp;label=Follow%20%40paradedb" alt="X URL" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://paradedb.com"&gt;ParadeDB&lt;/a&gt; is a modern Elasticsearch alternative built on Postgres. Built for real-time, update-heavy workloads.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;Please see our &lt;a href="https://docs.paradedb.com"&gt;documentation&lt;/a&gt; to get started. You'll also find our &lt;a href="https://docs.paradedb.com/welcome/architecture"&gt;architecture&lt;/a&gt; docs and &lt;a href="https://docs.paradedb.com/welcome/roadmap"&gt;public roadmap&lt;/a&gt; there.&lt;/p&gt; 
&lt;h2&gt;Deploying ParadeDB&lt;/h2&gt; 
&lt;p&gt;ParadeDB and its extensions can be deployed in one of two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker image based on &lt;a href="https://hub.docker.com/_/postgres"&gt;Postgres&lt;/a&gt; (&lt;a href="https://docs.paradedb.com/deploy/aws"&gt;see deployment instructions&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Kubernetes Helm chart based on &lt;a href="https://artifacthub.io/packages/helm/cloudnative-pg/cloudnative-pg"&gt;CloudNativePG&lt;/a&gt; (&lt;a href="https://docs.paradedb.com/deploy/helm"&gt;see deployment instructions&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information, including enterprise features and support, please &lt;a href="mailto:sales@paradedb.com"&gt;contact us by email&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Extensions&lt;/h3&gt; 
&lt;p&gt;You can find prebuilt binaries for the ParadeDB Postgres extensions on Debian 11, 12, Ubuntu 22.04 and 24.04, Red Hat Enterprise Linux 8 and 9, and macOS 14 (Sonoma) and 15 (Sequoia) for Postgres 14+ in the &lt;a href="https://github.com/paradedb/paradedb/releases/latest"&gt;GitHub Releases&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;ParadeDB supports all versions supported by the PostgreSQL Global Development Group, which includes PostgreSQL 14+, and you can compile the extensions for other versions of Postgres by following the instructions in the respective extension's README.&lt;/p&gt; 
&lt;h3&gt;Docker Image&lt;/h3&gt; 
&lt;p&gt;To quickly get a ParadeDB instance up and running, simply pull and run the latest Docker image:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --name paradedb -e POSTGRES_PASSWORD=password paradedb/paradedb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start a ParadeDB instance with default user &lt;code&gt;postgres&lt;/code&gt; and password &lt;code&gt;password&lt;/code&gt;. You can then connect to the database using &lt;code&gt;psql&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it paradedb psql -U postgres
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install ParadeDB locally or on-premise, we recommend using our &lt;code&gt;docker-compose.yml&lt;/code&gt; file. Alternatively, you can pass the appropriate environment variables to the &lt;code&gt;docker run&lt;/code&gt; command, replacing the &amp;lt;&amp;gt; with your desired values:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run \
  --name paradedb \
  -e POSTGRES_USER=&amp;lt;user&amp;gt; \
  -e POSTGRES_PASSWORD=&amp;lt;password&amp;gt; \
  -e POSTGRES_DB=&amp;lt;dbname&amp;gt; \
  -v paradedb_data:/var/lib/postgresql/data/ \
  -p 5432:5432 \
  -d \
  paradedb/paradedb:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start a ParadeDB instance with non-root user &lt;code&gt;&amp;lt;user&amp;gt;&lt;/code&gt; and password &lt;code&gt;&amp;lt;password&amp;gt;&lt;/code&gt;. The &lt;code&gt;-v&lt;/code&gt; flag enables your ParadeDB data to persist across restarts in a Docker volume named &lt;code&gt;paradedb_data&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can then connect to the database using &lt;code&gt;psql&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it paradedb psql -U &amp;lt;user&amp;gt; -d &amp;lt;dbname&amp;gt; -p 5432 -W
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Helm Chart&lt;/h3&gt; 
&lt;p&gt;ParadeDB is also available for Kubernetes via our Helm chart. You can find our Helm chart in the &lt;a href="https://github.com/paradedb/charts"&gt;ParadeDB Helm Chart GitHub repository&lt;/a&gt; or download it directly from &lt;a href="https://artifacthub.io/packages/helm/paradedb/paradedb"&gt;Artifact Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;ParadeDB Cloud&lt;/h3&gt; 
&lt;p&gt;At the moment, ParadeDB is not available as a managed cloud service. If you are interested in a ParadeDB Cloud service, please let us know by joining our &lt;a href="https://form.typeform.com/to/jHkLmIzx"&gt;waitlist&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;If you're missing a feature or have found a bug, please open a &lt;a href="https://github.com/paradedb/paradedb/issues/new/choose"&gt;GitHub Issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get community support, you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Post a question in the &lt;a href="https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw"&gt;ParadeDB Slack Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ask for help on our &lt;a href="https://github.com/paradedb/paradedb/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need commercial support, please &lt;a href="mailto:sales@paradedb.com"&gt;contact the ParadeDB team&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions, big or small, and are here to guide you along the way. To get started contributing, check our &lt;a href="https://github.com/paradedb/paradedb/labels/good%20first%20issue"&gt;first timer issues&lt;/a&gt; or message us in the &lt;a href="https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw"&gt;ParadeDB Community Slack&lt;/a&gt;. Once you contribute, ping us in Slack and we'll send you some ParadeDB swag!&lt;/p&gt; 
&lt;p&gt;For more information on how to contribute, please see our &lt;a href="https://raw.githubusercontent.com/paradedb/paradedb/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is released with a &lt;a href="https://raw.githubusercontent.com/paradedb/paradedb/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project, you agree to follow its terms.&lt;/p&gt; 
&lt;p&gt;Thank you for helping us make ParadeDB better for everyone &lt;span&gt;‚ù§Ô∏è&lt;/span&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;ParadeDB is licensed under the &lt;a href="https://raw.githubusercontent.com/paradedb/paradedb/main/LICENSE"&gt;GNU Affero General Public License v3.0&lt;/a&gt; and as commercial software. For commercial licensing, please contact us at &lt;a href="mailto:sales@paradedb.com"&gt;sales@paradedb.com&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tensorzero/tensorzero</title>
      <link>https://github.com/tensorzero/tensorzero</link>
      <description>&lt;p&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" alt="TensorZero Logo" width="128" height="128" /&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;h1&gt;TensorZero&lt;/h1&gt; 
&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://www.tensorzero.com/github-trending-badge.svg?sanitize=true" alt="#1 Repository Of The Day" /&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TensorZero is an open-source stack for &lt;em&gt;industrial-grade LLM applications&lt;/em&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gateway:&lt;/strong&gt; access every LLM provider through a unified API, built for performance (&amp;lt;1ms p99 latency)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability:&lt;/strong&gt; store inferences and feedback in your database, available programmatically or in the UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimization:&lt;/strong&gt; collect metrics and human feedback to optimize prompts, models, and inference strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluation:&lt;/strong&gt; benchmark individual inferences or end-to-end workflows using heuristics, LLM judges, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Experimentation:&lt;/strong&gt; ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Take what you need, adopt incrementally, and complement with other tools.&lt;/p&gt; 
&lt;p&gt;
 &lt;video src="https://github.com/user-attachments/assets/04a8466e-27d8-4189-b305-e7cecb6881ee"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/" target="_blank"&gt;Website&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs" target="_blank"&gt;Docs&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.x.com/tensorzero" target="_blank"&gt;Twitter&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/slack" target="_blank"&gt;Slack&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/discord" target="_blank"&gt;Discord&lt;/a&gt;&lt;/b&gt; &lt;br /&gt; &lt;br /&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart" target="_blank"&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank"&gt;API Reference&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;What is TensorZero?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How is TensorZero different from other LLM frameworks?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt; 1. TensorZero enables you to optimize complex LLM applications based on production metrics and human feedback.&lt;br /&gt; 2. TensorZero supports the needs of industrial-grade LLM applications: low latency, high throughput, type safety, self-hosted, GitOps, customizability, etc.&lt;br /&gt; 3. TensorZero unifies the entire LLMOps stack, creating compounding benefits. For example, LLM evaluations can be used for fine-tuning models alongside AI judges. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Can I use TensorZero with ___?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Yes. Every major programming language is supported. You can use TensorZero with our Python client, any OpenAI SDK or OpenAI-compatible client, or our HTTP API.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Is TensorZero production-ready?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Yes. Here's a case study: &lt;b&gt;&lt;a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms"&gt;Automating Code Changelogs at a Large Bank with LLMs&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How much does TensorZero cost?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Nothing. TensorZero is 100% self-hosted and open-source. There are no paid features.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Who is building TensorZero?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Our technical team includes a former Rust compiler maintainer, machine learning researchers (Stanford, CMU, Oxford, Columbia) with thousands of citations, and the chief product officer of a decacorn startup. We're backed by the same investors as leading open-source projects (e.g. ClickHouse, CockroachDB) and AI labs (e.g. OpenAI, Anthropic).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How do I get started?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;You can adopt TensorZero incrementally. Our &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/b&gt; goes from a vanilla OpenAI wrapper to a production-ready LLM application with observability and fine-tuning in just 5 minutes.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;üåê LLM Gateway&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Integrate with TensorZero once and access every major LLM provider.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Access every major LLM provider (API or self-hosted) through a single unified API&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Infer with streaming, tool use, structured generation (JSON mode), batch, multimodal (VLMs), file inputs, caching, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Define prompt templates and schemas to enforce a consistent, typed interface between your application and the LLMs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Satisfy extreme throughput and latency needs, thanks to ü¶Ä Rust: &amp;lt;1ms p99 latency overhead at 10k+ QPS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Integrate using our Python client, any OpenAI SDK or OpenAI-compatible client, or our HTTP API (use any programming language)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Ensure high availability with routing, retries, fallbacks, load balancing, granular timeouts, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: embeddings; real-time voice&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Model Providers&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="left" valign="top"&gt; &lt;p&gt; The TensorZero Gateway natively supports: &lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic"&gt;Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock"&gt;AWS Bedrock&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker"&gt;AWS SageMaker&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure"&gt;Azure OpenAI Service&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek"&gt;DeepSeek&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks"&gt;Fireworks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic"&gt;GCP Vertex AI Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini"&gt;GCP Vertex AI Gemini&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini"&gt;Google AI Studio (Gemini API)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/groq"&gt;Groq&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic"&gt;Hyperbolic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral"&gt;Mistral&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai"&gt;OpenAI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openrouter"&gt;OpenRouter&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/sglang"&gt;SGLang&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/tgi"&gt;TGI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/together"&gt;Together AI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm"&gt;vLLM&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai"&gt;xAI (Grok)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt; &lt;em&gt; Need something else? Your provider is most likely supported because TensorZero integrates with &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible"&gt;any OpenAI-compatible API (e.g. Ollama)&lt;/a&gt;&lt;/b&gt;. &lt;/em&gt; &lt;/p&gt; &lt;/td&gt; 
   &lt;td width="50%" align="left" valign="top"&gt; &lt;p&gt; The TensorZero Gateway supports advanced features like: &lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks"&gt;Retries &amp;amp; Fallbacks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations"&gt;Inference-Time Optimizations&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas"&gt;Prompt Templates &amp;amp; Schemas&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/experimentation/"&gt;Experimentation (A/B Testing)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/configuration-reference"&gt;Configuration-as-Code (GitOps)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference"&gt;Batch Inference&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference"&gt;Multimodal Inference (VLMs)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching"&gt;Inference Caching&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback"&gt;Metrics &amp;amp; Feedback&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/episodes"&gt;Multi-Step LLM Workflows (Episodes)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;em&gt;&amp;amp; a lot more...&lt;/em&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt; The TensorZero Gateway is written in Rust ü¶Ä with &lt;b&gt;performance&lt;/b&gt; in mind (&amp;lt;1ms p99 latency overhead @ 10k QPS). See &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/benchmarks"&gt;Benchmarks&lt;/a&gt;&lt;/b&gt;.&lt;br /&gt; &lt;/p&gt; &lt;p&gt; You can run inference using the &lt;b&gt;TensorZero client&lt;/b&gt; (recommended), the &lt;b&gt;OpenAI client&lt;/b&gt;, or the &lt;b&gt;HTTP API&lt;/b&gt;. &lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python ‚Äî TensorZero Client (Recommended)&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the TensorZero Python client.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from tensorzero import TensorZeroGateway  # or AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # Try other providers easily: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Write a haiku about artificial intelligence.",
                }
            ]
        },
    )
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python ‚Äî OpenAI Client&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Python client with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI  # or AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()

patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)

response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "Write a haiku about artificial intelligence.",
        }
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: JavaScript / TypeScript (Node) ‚Äî OpenAI Client&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Node client with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-ts"&gt;import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});

const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "Write a haiku about artificial intelligence.",
    },
  ],
});
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Other Languages &amp;amp; Platforms ‚Äî HTTP API&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;TensorZero supports virtually any programming language or platform via its HTTP API.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "Write a haiku about artificial intelligence."
        }
      ]
    }
  }'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;üîç LLM Observability&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Zoom in to debug individual API calls, or zoom out to monitor metrics across models and prompts over time ‚Äî all using the open-source TensorZero UI.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Store inferences and feedback (metrics, human edits, etc.) in your own database&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Dive into individual inferences or high-level aggregate patterns using the TensorZero UI or programmatically&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Build datasets for optimization, evaluation, and other workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Replay historical inferences with new prompts, models, inference strategies, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Export OpenTelemetry (OTLP) traces to your favorite general-purpose observability tool&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: AI-assisted debugging and root cause analysis; AI-assisted data labeling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability ¬ª UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability ¬ª Programmatic&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;
    &lt;video src="https://github.com/user-attachments/assets/a23e4c95-18fa-482c-8423-6078fb4cf285"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td width="50%" align="left" valign="middle"&gt; &lt;pre&gt;&lt;code class="language-python"&gt;t0.experimental_list_inferences(
  function_name="sales_agent",
  variant_name="qwen3-promptv2",
  filters=BooleanMetricFilter(
      metric_name="converted_sale",
      value=True,
  ),
  order_by=[OrderBy(by="timestamp", direction="DESC")],
  limit=100_000,
  # ... and more ...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h3&gt;üìà LLM Optimization&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Send production metrics and human feedback to easily optimize your prompts, models, and inference strategies ‚Äî using the UI or programmatically.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize your models with supervised fine-tuning, RLHF, and other techniques&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize your prompts with automated prompt engineering algorithms like MIPROv2&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize your inference strategy with dynamic in-context learning, chain of thought, best/mixture-of-N sampling, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Enable a feedback loop for your LLMs: a data &amp;amp; learning flywheel turning production data into smarter, faster, and cheaper models&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: programmatic optimization; synthetic data generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Model Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize closed-source and open-source models using supervised fine-tuning (SFT) and preference fine-tuning (DPO).&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Supervised Fine-tuning ‚Äî UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Preference Fine-tuning (DPO) ‚Äî Jupyter Notebook&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;
    &lt;video src="https://github.com/user-attachments/assets/82f76be7-5e02-4ada-b503-69dfa209a442"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Inference-Time Optimization&lt;/h4&gt; 
&lt;p&gt;Boost performance by dynamically updating your prompts with relevant examples, combining responses from multiple inferences, and more.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;Best-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling"&gt;Mixture-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic In-Context Learning (DICL)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot"&gt;Chain-of-Thought (CoT)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h4&gt;Prompt Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize your prompts programmatically using research-driven optimization techniques.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;MIPROv2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;DSPy Integration&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt; TensorZero comes with several optimization recipes, but you can also easily create your own. This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy, a popular library for automated prompt engineering. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;üìä LLM Evaluation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Compare prompts, models, and inference strategies using evaluations powered by heuristics and LLM judges.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Evaluate individual inferences with &lt;em&gt;static evaluations&lt;/em&gt; powered by heuristics or LLM judges (‚âà unit tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Evaluate end-to-end workflows with &lt;em&gt;dynamic evaluations&lt;/em&gt; with complete flexibility (‚âà integration tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize LLM judges just like any other TensorZero function to align them to human preferences&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: more built-in evaluators; headless evaluations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation ¬ª UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation ¬ª CLI&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="left" valign="middle"&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100
exact_match: 0.83 ¬± 0.03
semantic_match: 0.98 ¬± 0.01
item_count: 7.15 ¬± 0.39&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;üß™ LLM Experimentation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Ship with confidence with built-in A/B testing for models, prompts, providers, hyperparameters, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Enforce principled experiments (RCTs) in complex workflows, including multi-turn and compound LLM systems&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: multi-armed bandits; AI-managed experiments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&amp;amp; more!&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Build with an open-source stack well-suited for prototypes but designed from the ground up to support the most complex LLM applications and deployments.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Build simple applications or massive deployments with GitOps-friendly orchestration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Extend TensorZero with built-in escape hatches, programmatic-first usage, direct database access, and more&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Integrate with third-party tools: specialized observability and evaluations, model providers, agent orchestration frameworks, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: UI playground&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Watch LLMs get better at data extraction in real-time with TensorZero!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic in-context learning (DICL)&lt;/a&gt;&lt;/strong&gt; is a powerful inference-time optimization available out of the box with TensorZero. It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb"&gt;https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Start building today.&lt;/strong&gt; The &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; shows it's easy to set up an LLM application with TensorZero.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Questions?&lt;/strong&gt; Ask us on &lt;strong&gt;&lt;a href="https://www.tensorzero.com/slack"&gt;Slack&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href="https://www.tensorzero.com/discord"&gt;Discord&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Using TensorZero at work?&lt;/strong&gt; Email us at &lt;strong&gt;&lt;a href="mailto:hello@tensorzero.com"&gt;hello@tensorzero.com&lt;/a&gt;&lt;/strong&gt; to set up a Slack or Teams channel with your team (free).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Work with us.&lt;/strong&gt; We're &lt;strong&gt;&lt;a href="https://www.tensorzero.com/jobs"&gt;hiring in NYC&lt;/a&gt;&lt;/strong&gt;. We'd also welcome &lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/raw/main/CONTRIBUTING.md"&gt;open-source contributions&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;We are working on a series of &lt;strong&gt;complete runnable examples&lt;/strong&gt; illustrating TensorZero's data &amp;amp; learning flywheel.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner"&gt;Optimizing Data Extraction (NER) with TensorZero&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to use TensorZero to optimize a data extraction pipeline. We demonstrate techniques like fine-tuning and dynamic in-context learning (DICL). In the end, an optimized GPT-4o Mini model outperforms GPT-4o on this task ‚Äî at a fraction of the cost and latency ‚Äî using a small amount of training data.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/"&gt;Agentic RAG ‚Äî Multi-Hop Question Answering with LLMs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to build a multi-hop retrieval agent using TensorZero. The agent iteratively searches Wikipedia to gather information, and decides when it has enough context to answer a complex question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences"&gt;Writing Haikus to Satisfy a Judge with Hidden Preferences&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste. You'll see TensorZero's "data flywheel in a box" in action: better variants leads to better data, and better data leads to better variants. You'll see progress by fine-tuning the LLM multiple times.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/"&gt;Improving LLM Chess Ability with Best-of-N Sampling&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example showcases how best-of-N sampling can significantly enhance an LLM's chess-playing abilities by selecting the most promising moves from multiple generated options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;Improving Math Reasoning with a Custom Recipe for Automated Prompt Engineering (DSPy)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;TensorZero provides a number of pre-built optimization recipes covering common LLM engineering workflows. But you can also easily create your own recipes and workflows! This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&amp;amp; many more on the way!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;OpenAI Codex CLI&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.&lt;br /&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, see &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="50%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Table of contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;!-- Begin ToC --&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#quickstart"&gt;Quickstart&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#installing-and-running-codex-cli"&gt;Installing and running Codex CLI&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#using-codex-with-your-chatgpt-plan"&gt;Using Codex with your ChatGPT plan&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#connecting-on-a-headless-machine"&gt;Connecting on a "Headless" Machine&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#authenticate-locally-and-copy-your-credentials-to-the-headless-machine"&gt;Authenticate locally and copy your credentials to the "headless" machine&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#connecting-through-vps-or-remote"&gt;Connecting through VPS or remote&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#usage-based-billing-alternative-use-an-openai-api-key"&gt;Usage-based billing alternative: Use an OpenAI API key&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#forcing-a-specific-auth-method-advanced"&gt;Forcing a specific auth method (advanced)&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#choosing-codexs-level-of-autonomy"&gt;Choosing Codex's level of autonomy&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#1-readwrite"&gt;&lt;strong&gt;1. Read/write&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#2-read-only"&gt;&lt;strong&gt;2. Read-only&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#3-advanced-configuration"&gt;&lt;strong&gt;3. Advanced configuration&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#can-i-run-without-any-approvals"&gt;Can I run without ANY approvals?&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#fine-tuning-in-configtoml"&gt;Fine-tuning in &lt;code&gt;config.toml&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#using-open-source-models"&gt;Using Open Source Models&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#platform-sandboxing-details"&gt;Platform sandboxing details&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#experimental-technology-disclaimer"&gt;Experimental technology disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#system-requirements"&gt;System requirements&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#cli-reference"&gt;CLI reference&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#memory--project-docs"&gt;Memory &amp;amp; project docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#non-interactive--ci-mode"&gt;Non-interactive / CI mode&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#zero-data-retention-zdr-usage"&gt;Zero data retention (ZDR) usage&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#codex-open-source-fund"&gt;Codex open source fund&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#contributing"&gt;Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#development-workflow"&gt;Development workflow&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#writing-high-impact-code-changes"&gt;Writing high-impact code changes&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#opening-a-pull-request"&gt;Opening a pull request&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#review-process"&gt;Review process&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#community-values"&gt;Community values&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#getting-help"&gt;Getting help&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#contributor-license-agreement-cla"&gt;Contributor license agreement (CLA)&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#quick-fixes"&gt;Quick fixes&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#releasing-codex"&gt;Releasing &lt;code&gt;codex&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#security--responsible-ai"&gt;Security &amp;amp; responsible AI&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- End ToC --&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex  # Alternatively: `brew install codex`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="50%" /&gt; &lt;/p&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. You'll need a Plus, Pro, or Team ChatGPT account, and will get access to our latest models, including &lt;code&gt;gpt-5&lt;/code&gt;, at no extra cost to your plan. (Enterprise is coming soon.)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: If you've used the Codex CLI before, follow these steps to migrate from usage-based billing with your API key:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Update the CLI and ensure &lt;code&gt;codex --version&lt;/code&gt; is &lt;code&gt;0.20.0&lt;/code&gt; or later&lt;/li&gt; 
  &lt;li&gt;Delete &lt;code&gt;~/.codex/auth.json&lt;/code&gt; (this should be &lt;code&gt;C:\Users\USERNAME\.codex\auth.json&lt;/code&gt; on Windows)&lt;/li&gt; 
  &lt;li&gt;Run &lt;code&gt;codex login&lt;/code&gt; again&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you encounter problems with the login flow, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Connecting on a "Headless" Machine&lt;/h3&gt; 
&lt;p&gt;Today, the login process entails running a server on &lt;code&gt;localhost:1455&lt;/code&gt;. If you are on a "headless" server, such as a Docker container or are &lt;code&gt;ssh&lt;/code&gt;'d into a remote machine, loading &lt;code&gt;localhost:1455&lt;/code&gt; in the browser on your local machine will not automatically connect to the webserver running on the &lt;em&gt;headless&lt;/em&gt; machine, so you must use one of the following workarounds:&lt;/p&gt; 
&lt;h4&gt;Authenticate locally and copy your credentials to the "headless" machine&lt;/h4&gt; 
&lt;p&gt;The easiest solution is likely to run through the &lt;code&gt;codex login&lt;/code&gt; process on your local machine such that &lt;code&gt;localhost:1455&lt;/code&gt; &lt;em&gt;is&lt;/em&gt; accessible in your web browser. When you complete the authentication process, an &lt;code&gt;auth.json&lt;/code&gt; file should be available at &lt;code&gt;$CODEX_HOME/auth.json&lt;/code&gt; (on Mac/Linux, &lt;code&gt;$CODEX_HOME&lt;/code&gt; defaults to &lt;code&gt;~/.codex&lt;/code&gt; whereas on Windows, it defaults to &lt;code&gt;%USERPROFILE%\.codex&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;Because the &lt;code&gt;auth.json&lt;/code&gt; file is not tied to a specific host, once you complete the authentication flow locally, you can copy the &lt;code&gt;$CODEX_HOME/auth.json&lt;/code&gt; file to the headless machine and then &lt;code&gt;codex&lt;/code&gt; should "just work" on that machine. Note to copy a file to a Docker container, you can do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# substitute MY_CONTAINER with the name or id of your Docker container:
CONTAINER_HOME=$(docker exec MY_CONTAINER printenv HOME)
docker exec MY_CONTAINER mkdir -p "$CONTAINER_HOME/.codex"
docker cp auth.json MY_CONTAINER:"$CONTAINER_HOME/.codex/auth.json"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;whereas if you are &lt;code&gt;ssh&lt;/code&gt;'d into a remote machine, you likely want to use &lt;a href="https://en.wikipedia.org/wiki/Secure_copy_protocol"&gt;&lt;code&gt;scp&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ssh user@remote 'mkdir -p ~/.codex'
scp ~/.codex/auth.json user@remote:~/.codex/auth.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or try this one-liner:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ssh user@remote 'mkdir -p ~/.codex &amp;amp;&amp;amp; cat &amp;gt; ~/.codex/auth.json' &amp;lt; ~/.codex/auth.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Connecting through VPS or remote&lt;/h4&gt; 
&lt;p&gt;If you run Codex on a remote machine (VPS/server) without a local browser, the login helper starts a server on &lt;code&gt;localhost:1455&lt;/code&gt; on the remote host. To complete login in your local browser, forward that port to your machine before starting the login flow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From your local machine
ssh -L 1455:localhost:1455 &amp;lt;user&amp;gt;@&amp;lt;remote-host&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, in that SSH session, run &lt;code&gt;codex&lt;/code&gt; and select "Sign in with ChatGPT". When prompted, open the printed URL (it will be &lt;code&gt;http://localhost:1455/...&lt;/code&gt;) in your local browser. The traffic will be tunneled to the remote server.&lt;/p&gt; 
&lt;h3&gt;Usage-based billing alternative: Use an OpenAI API key&lt;/h3&gt; 
&lt;p&gt;If you prefer to pay-as-you-go, you can still authenticate with your OpenAI API key by setting it as an environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export OPENAI_API_KEY="your-api-key-here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;This command only sets the key for your current terminal session, which we recommend. To set it for all future sessions, you can also add the &lt;code&gt;export&lt;/code&gt; line to your shell's configuration file (e.g., &lt;code&gt;~/.zshrc&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;If you have signed in with ChatGPT, Codex will default to using your ChatGPT credits. If you wish to use your API key, use the &lt;code&gt;/logout&lt;/code&gt; command to clear your ChatGPT authentication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Forcing a specific auth method (advanced)&lt;/h4&gt; 
&lt;p&gt;You can explicitly choose which authentication Codex should prefer when both are available.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;To always use your API key (even when ChatGPT auth exists), set:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# ~/.codex/config.toml
preferred_auth_method = "apikey"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or override ad-hoc via CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codex --config preferred_auth_method="apikey"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;To prefer ChatGPT auth (default), set:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# ~/.codex/config.toml
preferred_auth_method = "chatgpt"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;When &lt;code&gt;preferred_auth_method = "apikey"&lt;/code&gt; and an API key is available, the login screen is skipped.&lt;/li&gt; 
 &lt;li&gt;When &lt;code&gt;preferred_auth_method = "chatgpt"&lt;/code&gt; (default), Codex prefers ChatGPT auth if present; if only an API key is present, it will use the API key. Certain account types may also require API-key mode.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Choosing Codex's level of autonomy&lt;/h3&gt; 
&lt;p&gt;We always recommend running Codex in its default sandbox that gives you strong guardrails around what the agent can do. The default sandbox prevents it from editing files outside its workspace, or from accessing the network.&lt;/p&gt; 
&lt;p&gt;When you launch Codex in a new folder, it detects whether the folder is version controlled and recommends one of two levels of autonomy:&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;1. Read/write&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Codex can run commands and write files in the workspace without approval.&lt;/li&gt; 
 &lt;li&gt;To write files in other folders, access network, update git or perform other actions protected by the sandbox, Codex will need your permission.&lt;/li&gt; 
 &lt;li&gt;By default, the workspace includes the current directory, as well as temporary directories like &lt;code&gt;/tmp&lt;/code&gt;. You can see what directories are in the workspace with the &lt;code&gt;/status&lt;/code&gt; command. See the docs for how to customize this behavior.&lt;/li&gt; 
 &lt;li&gt;Advanced: You can manually specify this configuration by running &lt;code&gt;codex --sandbox workspace-write --ask-for-approval on-request&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;This is the recommended default for version-controlled folders.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;2. Read-only&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Codex can run read-only commands without approval.&lt;/li&gt; 
 &lt;li&gt;To edit files, access network, or perform other actions protected by the sandbox, Codex will need your permission.&lt;/li&gt; 
 &lt;li&gt;Advanced: You can manually specify this configuration by running &lt;code&gt;codex --sandbox read-only --ask-for-approval on-request&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;This is the recommended default non-version-controlled folders.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;3. Advanced configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Codex gives you fine-grained control over the sandbox with the &lt;code&gt;--sandbox&lt;/code&gt; option, and over when it requests approval with the &lt;code&gt;--ask-for-approval&lt;/code&gt; option. Run &lt;code&gt;codex help&lt;/code&gt; for more on these options.&lt;/p&gt; 
&lt;h4&gt;Can I run without ANY approvals?&lt;/h4&gt; 
&lt;p&gt;Yes, run codex non-interactively with &lt;code&gt;--ask-for-approval never&lt;/code&gt;. This option works with all &lt;code&gt;--sandbox&lt;/code&gt; options, so you still have full control over Codex's level of autonomy. It will make its best attempt with whatever contrainsts you provide. For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;codex --ask-for-approval never --sandbox read-only&lt;/code&gt; when you are running many agents to answer questions in parallel in the same workspace.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;codex --ask-for-approval never --sandbox workspace-write&lt;/code&gt; when you want the agent to non-interactively take time to produce the best outcome, with strong guardrails around its behavior.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;codex --ask-for-approval never --sandbox danger-full-access&lt;/code&gt; to dangerously give the agent full autonomy. Because this disables important safety mechanisms, we recommend against using this unless running Codex in an isolated environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Fine-tuning in &lt;code&gt;config.toml&lt;/code&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# approval mode
approval_policy = "untrusted"
sandbox_mode    = "read-only"

# full-auto mode
approval_policy = "on-request"
sandbox_mode    = "workspace-write"

# Optional: allow network in workspace-write mode
[sandbox_workspace_write]
network_access = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also save presets as &lt;strong&gt;profiles&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[profiles.full_auto]
approval_policy = "on-request"
sandbox_mode    = "workspace-write"

[profiles.readonly_quiet]
approval_policy = "never"
sandbox_mode    = "read-only"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example prompts&lt;/h3&gt; 
&lt;p&gt;Below are a few bite-size examples you can copy-paste. Replace the text in quotes with your own task. See the &lt;a href="https://github.com/openai/codex/raw/main/codex-cli/examples/prompting_guide.md"&gt;prompting guide&lt;/a&gt; for more tips and usage patterns.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;‚ú®&lt;/th&gt; 
   &lt;th&gt;What you type&lt;/th&gt; 
   &lt;th&gt;What happens&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Refactor the Dashboard component to React Hooks"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Codex rewrites the class component, runs &lt;code&gt;npm test&lt;/code&gt;, and shows the diff.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Generate SQL migrations for adding a users table"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Infers your ORM, creates migration files, and runs them in a sandboxed DB.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Write unit tests for utils/date.ts"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Generates tests, executes them, and iterates until they pass.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Bulk-rename *.jpeg -&amp;gt; *.jpg with git mv"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Safely renames files and updates imports/usages.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Explain what this regex does: ^(?=.*[A-Z]).{8,}$"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Outputs a step-by-step human explanation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Carefully review this repo, and propose 3 high impact well-scoped PRs"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Suggests impactful PRs in the current codebase.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Look for vulnerabilities and create a security review report"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Finds and explains security bugs.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Running with a prompt as input&lt;/h2&gt; 
&lt;p&gt;You can also run Codex CLI with a prompt as input:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex "explain this codebase to me"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex --full-auto "create the fanciest todo-list app"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it - Codex will scaffold a file, run it inside a sandbox, install any missing dependencies, and show you the live result. Approve the changes and they'll be committed to your working directory.&lt;/p&gt; 
&lt;h2&gt;Using Open Source Models&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Use &lt;code&gt;--profile&lt;/code&gt; to use other models&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Codex also allows you to use other providers that support the OpenAI Chat Completions (or Responses) API.&lt;/p&gt; 
 &lt;p&gt;To do so, you must first define custom &lt;a href="https://raw.githubusercontent.com/openai/codex/main/config.md#model_providers"&gt;providers&lt;/a&gt; in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For example, the provider for a standard Ollama setup would be defined as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.ollama]
name = "Ollama"
base_url = "http://localhost:11434/v1"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;base_url&lt;/code&gt; will have &lt;code&gt;/chat/completions&lt;/code&gt; appended to it to build the full URL for the request.&lt;/p&gt; 
 &lt;p&gt;For providers that also require an &lt;code&gt;Authorization&lt;/code&gt; header of the form &lt;code&gt;Bearer: SECRET&lt;/code&gt;, an &lt;code&gt;env_key&lt;/code&gt; can be specified, which indicates the environment variable to read to use as the value of &lt;code&gt;SECRET&lt;/code&gt; when making a request:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.openrouter]
name = "OpenRouter"
base_url = "https://openrouter.ai/api/v1"
env_key = "OPENROUTER_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Providers that speak the Responses API are also supported by adding &lt;code&gt;wire_api = "responses"&lt;/code&gt; as part of the definition. Accessing OpenAI models via Azure is an example of such a provider, though it also requires specifying additional &lt;code&gt;query_params&lt;/code&gt; that need to be appended to the request URL:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.azure]
name = "Azure"
# Make sure you set the appropriate subdomain for this URL.
base_url = "https://YOUR_PROJECT_NAME.openai.azure.com/openai"
env_key = "AZURE_OPENAI_API_KEY"  # Or "OPENAI_API_KEY", whichever you use.
# Newer versions appear to support the responses API, see https://github.com/openai/codex/pull/1321
query_params = { api-version = "2025-04-01-preview" }
wire_api = "responses"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Once you have defined a provider you wish to use, you can configure it as your default provider as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;model_provider = "azure"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!TIP] If you find yourself experimenting with a variety of models and providers, then you likely want to invest in defining a &lt;em&gt;profile&lt;/em&gt; for each configuration like so:&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[profiles.o3]
model_provider = "azure"
model = "o3"

[profiles.mistral]
model_provider = "ollama"
model = "mistral"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This way, you can specify one command-line argument (.e.g., &lt;code&gt;--profile o3&lt;/code&gt;, &lt;code&gt;--profile mistral&lt;/code&gt;) to override multiple settings together.&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;Codex can run fully locally against an OpenAI-compatible OSS host (like Ollama) using the &lt;code&gt;--oss&lt;/code&gt; flag:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interactive UI: 
  &lt;ul&gt; 
   &lt;li&gt;codex --oss&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Non-interactive (programmatic) mode: 
  &lt;ul&gt; 
   &lt;li&gt;echo "Refactor utils" | codex exec --oss&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model selection when using &lt;code&gt;--oss&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you omit &lt;code&gt;-m/--model&lt;/code&gt;, Codex defaults to -m gpt-oss:20b and will verify it exists locally (downloading if needed).&lt;/li&gt; 
 &lt;li&gt;To pick a different size, pass one of: 
  &lt;ul&gt; 
   &lt;li&gt;-m "gpt-oss:20b"&lt;/li&gt; 
   &lt;li&gt;-m "gpt-oss:120b"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Point Codex at your own OSS host:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;By default, &lt;code&gt;--oss&lt;/code&gt; talks to &lt;a href="http://localhost:11434/v1"&gt;http://localhost:11434/v1&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;To use a different host, set one of these environment variables before running Codex: 
  &lt;ul&gt; 
   &lt;li&gt;CODEX_OSS_BASE_URL, for example: 
    &lt;ul&gt; 
     &lt;li&gt;CODEX_OSS_BASE_URL="&lt;a href="http://my-ollama.example.com:11434/v1"&gt;http://my-ollama.example.com:11434/v1&lt;/a&gt;" codex --oss -m gpt-oss:20b&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;or CODEX_OSS_PORT (when the host is localhost): 
    &lt;ul&gt; 
     &lt;li&gt;CODEX_OSS_PORT=11434 codex --oss&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Advanced: you can persist this in your config instead of environment variables by overriding the built-in &lt;code&gt;oss&lt;/code&gt; provider in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.oss]
name = "Open Source"
base_url = "http://my-ollama.example.com:11434/v1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Platform sandboxing details&lt;/h3&gt; 
&lt;p&gt;The mechanism Codex uses to implement the sandbox policy depends on your OS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS 12+&lt;/strong&gt; uses &lt;strong&gt;Apple Seatbelt&lt;/strong&gt; and runs commands using &lt;code&gt;sandbox-exec&lt;/code&gt; with a profile (&lt;code&gt;-p&lt;/code&gt;) that corresponds to the &lt;code&gt;--sandbox&lt;/code&gt; that was specified.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; uses a combination of Landlock/seccomp APIs to enforce the &lt;code&gt;sandbox&lt;/code&gt; configuration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that when running Linux in a containerized environment such as Docker, sandboxing may not work if the host/container configuration does not support the necessary Landlock/seccomp APIs. In such cases, we recommend configuring your Docker container so that it provides the sandbox guarantees you are looking for and then running &lt;code&gt;codex&lt;/code&gt; with &lt;code&gt;--sandbox danger-full-access&lt;/code&gt; (or, more simply, the &lt;code&gt;--dangerously-bypass-approvals-and-sandbox&lt;/code&gt; flag) within your container.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Experimental technology disclaimer&lt;/h2&gt; 
&lt;p&gt;Codex CLI is an experimental project under active development. It is not yet stable, may contain bugs, incomplete features, or undergo breaking changes. We're building it in the open with the community and welcome:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug reports&lt;/li&gt; 
 &lt;li&gt;Feature requests&lt;/li&gt; 
 &lt;li&gt;Pull requests&lt;/li&gt; 
 &lt;li&gt;Good vibes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Help us improve by filing issues or submitting PRs (see the section below for how to contribute)!&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;System requirements&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Requirement&lt;/th&gt; 
   &lt;th&gt;Details&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operating systems&lt;/td&gt; 
   &lt;td&gt;macOS 12+, Ubuntu 20.04+/Debian 10+, or Windows 11 &lt;strong&gt;via WSL2&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Git (optional, recommended)&lt;/td&gt; 
   &lt;td&gt;2.23+ for built-in PR helpers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RAM&lt;/td&gt; 
   &lt;td&gt;4-GB minimum (8-GB recommended)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;CLI reference&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Interactive TUI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex "..."&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Initial prompt for interactive TUI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "fix lint errors"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex exec "..."&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Non-interactive "automation mode"&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex exec "explain utils.ts"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Key flags: &lt;code&gt;--model/-m&lt;/code&gt;, &lt;code&gt;--ask-for-approval/-a&lt;/code&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Memory &amp;amp; project docs&lt;/h2&gt; 
&lt;p&gt;You can give Codex extra instructions and guidance using &lt;code&gt;AGENTS.md&lt;/code&gt; files. Codex looks for &lt;code&gt;AGENTS.md&lt;/code&gt; files in the following places, and merges them top-down:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;~/.codex/AGENTS.md&lt;/code&gt; - personal global guidance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; at repo root - shared project notes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; in the current working directory - sub-folder/feature specifics&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Non-interactive / CI mode&lt;/h2&gt; 
&lt;p&gt;Run Codex head-less in pipelines. Example GitHub Action step:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;- name: Update changelog via Codex
  run: |
    npm install -g @openai/codex
    export OPENAI_API_KEY="${{ secrets.OPENAI_KEY }}"
    codex exec --full-auto "update CHANGELOG for next release"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;The Codex CLI can be configured to leverage MCP servers by defining an &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#mcp_servers"&gt;&lt;code&gt;mcp_servers&lt;/code&gt;&lt;/a&gt; section in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. It is intended to mirror how tools such as Claude and Cursor define &lt;code&gt;mcpServers&lt;/code&gt; in their respective JSON config files, though the Codex format is slightly different since it uses TOML rather than JSON, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# IMPORTANT: the top-level key is `mcp_servers` rather than `mcpServers`.
[mcp_servers.server-name]
command = "npx"
args = ["-y", "mcp-server"]
env = { "API_KEY" = "value" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] It is somewhat experimental, but the Codex CLI can also be run as an MCP &lt;em&gt;server&lt;/em&gt; via &lt;code&gt;codex mcp&lt;/code&gt;. If you launch it with an MCP client such as &lt;code&gt;npx @modelcontextprotocol/inspector codex mcp&lt;/code&gt; and send it a &lt;code&gt;tools/list&lt;/code&gt; request, you will see that there is only one tool, &lt;code&gt;codex&lt;/code&gt;, that accepts a grab-bag of inputs, including a catch-all &lt;code&gt;config&lt;/code&gt; map for anything you might want to override. Feel free to play around with it and provide feedback via GitHub issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Tracing / verbose logging&lt;/h2&gt; 
&lt;p&gt;Because Codex is written in Rust, it honors the &lt;code&gt;RUST_LOG&lt;/code&gt; environment variable to configure its logging behavior.&lt;/p&gt; 
&lt;p&gt;The TUI defaults to &lt;code&gt;RUST_LOG=codex_core=info,codex_tui=info&lt;/code&gt; and log messages are written to &lt;code&gt;~/.codex/log/codex-tui.log&lt;/code&gt;, so you can leave the following running in a separate terminal to monitor log messages as they are written:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;tail -F ~/.codex/log/codex-tui.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By comparison, the non-interactive mode (&lt;code&gt;codex exec&lt;/code&gt;) defaults to &lt;code&gt;RUST_LOG=error&lt;/code&gt;, but messages are printed inline, so there is no need to monitor a separate file.&lt;/p&gt; 
&lt;p&gt;See the Rust documentation on &lt;a href="https://docs.rs/env_logger/latest/env_logger/#enabling-logging"&gt;&lt;code&gt;RUST_LOG&lt;/code&gt;&lt;/a&gt; for more information on the configuration options.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;DotSlash&lt;/h3&gt; 
&lt;p&gt;The GitHub Release also contains a &lt;a href="https://dotslash-cli.com/"&gt;DotSlash&lt;/a&gt; file for the Codex CLI named &lt;code&gt;codex&lt;/code&gt;. Using a DotSlash file makes it possible to make a lightweight commit to source control to ensure all contributors use the same version of an executable, regardless of what platform they use for development.&lt;/p&gt;  
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build from source&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository and navigate to the root of the Cargo workspace.
git clone https://github.com/openai/codex.git
cd codex/codex-rs

# Install the Rust toolchain, if necessary.
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
source "$HOME/.cargo/env"
rustup component add rustfmt
rustup component add clippy

# Build Codex.
cargo build

# Launch the TUI with a sample prompt.
cargo run --bin codex -- "explain this codebase to me"

# After making changes, ensure the code is clean.
cargo fmt -- --config imports_granularity=Item
cargo clippy --tests

# Run the tests.
cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Codex supports a rich set of configuration options documented in &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md"&gt;&lt;code&gt;codex-rs/config.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;By default, Codex loads its configuration from &lt;code&gt;~/.codex/config.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Though &lt;code&gt;--config&lt;/code&gt; can be used to set/override ad-hoc config values for individual invocations of &lt;code&gt;codex&lt;/code&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenAI released a model called Codex in 2021 - is this related?&lt;/summary&gt; 
 &lt;p&gt;In 2021, OpenAI released Codex, an AI system designed to generate code from natural language prompts. That original Codex model was deprecated as of March 2023 and is separate from the CLI tool.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which models are supported?&lt;/summary&gt; 
 &lt;p&gt;Any model available with &lt;a href="https://platform.openai.com/docs/api-reference/responses"&gt;Responses API&lt;/a&gt;. The default is &lt;code&gt;o4-mini&lt;/code&gt;, but pass &lt;code&gt;--model gpt-4.1&lt;/code&gt; or set &lt;code&gt;model: gpt-4.1&lt;/code&gt; in your config file to override.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Why does &lt;code&gt;o3&lt;/code&gt; or &lt;code&gt;o4-mini&lt;/code&gt; not work for me?&lt;/summary&gt; 
 &lt;p&gt;It's possible that your &lt;a href="https://help.openai.com/en/articles/10910291-api-organization-verification"&gt;API account needs to be verified&lt;/a&gt; in order to start streaming responses and seeing chain of thought summaries from the API. If you're still running into issues, please let us know!&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do I stop Codex from editing my files?&lt;/summary&gt; 
 &lt;p&gt;Codex runs model-generated commands in a sandbox. If a proposed command or file change doesn't look right, you can simply type &lt;strong&gt;n&lt;/strong&gt; to deny the command or give the model feedback.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Does it work on Windows?&lt;/summary&gt; 
 &lt;p&gt;Not directly. It requires &lt;a href="https://learn.microsoft.com/en-us/windows/wsl/install"&gt;Windows Subsystem for Linux (WSL2)&lt;/a&gt; - Codex has been tested on macOS and Linux with Node 22.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Zero data retention (ZDR) usage&lt;/h2&gt; 
&lt;p&gt;Codex CLI &lt;strong&gt;does&lt;/strong&gt; support OpenAI organizations with &lt;a href="https://platform.openai.com/docs/guides/your-data#zero-data-retention"&gt;Zero Data Retention (ZDR)&lt;/a&gt; enabled. If your OpenAI organization has Zero Data Retention enabled and you still encounter errors such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OpenAI rejected the request. Error details: Status: 400, Code: unsupported_parameter, Type: invalid_request_error, Message: 400 Previous response cannot be used for this organization due to Zero Data Retention.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure you are running &lt;code&gt;codex&lt;/code&gt; with &lt;code&gt;--config disable_response_storage=true&lt;/code&gt; or add this line to &lt;code&gt;~/.codex/config.toml&lt;/code&gt; to avoid specifying the command line option each time:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;disable_response_storage = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#disable_response_storage"&gt;the configuration documentation on &lt;code&gt;disable_response_storage&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Codex open source fund&lt;/h2&gt; 
&lt;p&gt;We're excited to launch a &lt;strong&gt;$1 million initiative&lt;/strong&gt; supporting open source projects that use Codex CLI and other OpenAI models.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Grants are awarded up to &lt;strong&gt;$25,000&lt;/strong&gt; API credits.&lt;/li&gt; 
 &lt;li&gt;Applications are reviewed &lt;strong&gt;on a rolling basis&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Interested? &lt;a href="https://openai.com/form/codex-open-source-fund/"&gt;Apply here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project is under active development and the code will likely change pretty significantly.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;At the moment, we only plan to prioritize reviewing external contributions for bugs or security fixes.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you want to add a new feature or change the behavior of an existing one, please open an issue proposing the feature and get approval from an OpenAI team member before spending time building it.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;New contributions that don't go through this process may be closed&lt;/strong&gt; if they aren't aligned with our current roadmap or conflict with other priorities/upcoming features.&lt;/p&gt; 
&lt;h3&gt;Development workflow&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a &lt;em&gt;topic branch&lt;/em&gt; from &lt;code&gt;main&lt;/code&gt; - e.g. &lt;code&gt;feat/interactive-prompt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Keep your changes focused. Multiple unrelated fixes should be opened as separate PRs.&lt;/li&gt; 
 &lt;li&gt;Following the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/#development-workflow"&gt;development setup&lt;/a&gt; instructions above, ensure your change is free of lint warnings and test failures.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Writing high-impact code changes&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Start with an issue.&lt;/strong&gt; Open a new one or comment on an existing discussion so we can agree on the solution before code is written.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add or update tests.&lt;/strong&gt; Every new feature or bug-fix should come with test coverage that fails before your change and passes afterwards. 100% coverage is not required, but aim for meaningful assertions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document behaviour.&lt;/strong&gt; If your change affects user-facing behaviour, update the README, inline help (&lt;code&gt;codex --help&lt;/code&gt;), or relevant example projects.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Keep commits atomic.&lt;/strong&gt; Each commit should compile and the tests should pass. This makes reviews and potential rollbacks easier.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Opening a pull request&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fill in the PR template (or include similar information) - &lt;strong&gt;What? Why? How?&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;strong&gt;all&lt;/strong&gt; checks locally (&lt;code&gt;cargo test &amp;amp;&amp;amp; cargo clippy --tests &amp;amp;&amp;amp; cargo fmt -- --config imports_granularity=Item&lt;/code&gt;). CI failures that could have been caught locally slow down the process.&lt;/li&gt; 
 &lt;li&gt;Make sure your branch is up-to-date with &lt;code&gt;main&lt;/code&gt; and that you have resolved merge conflicts.&lt;/li&gt; 
 &lt;li&gt;Mark the PR as &lt;strong&gt;Ready for review&lt;/strong&gt; only when you believe it is in a merge-able state.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Review process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;One maintainer will be assigned as a primary reviewer.&lt;/li&gt; 
 &lt;li&gt;If your PR adds a new feature that was not previously discussed and approved, we may choose to close your PR (see &lt;a href="https://raw.githubusercontent.com/openai/codex/main/#contributing"&gt;Contributing&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;We may ask for changes - please do not take this personally. We value the work, but we also value consistency and long-term maintainability.&lt;/li&gt; 
 &lt;li&gt;When there is consensus that the PR meets the bar, a maintainer will squash-and-merge.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Community values&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Be kind and inclusive.&lt;/strong&gt; Treat others with respect; we follow the &lt;a href="https://www.contributor-covenant.org/"&gt;Contributor Covenant&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Assume good intent.&lt;/strong&gt; Written communication is hard - err on the side of generosity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teach &amp;amp; learn.&lt;/strong&gt; If you spot something confusing, open an issue or PR with improvements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting help&lt;/h3&gt; 
&lt;p&gt;If you run into problems setting up the project, would like feedback on an idea, or just want to say &lt;em&gt;hi&lt;/em&gt; - please open a Discussion or jump into the relevant issue. We are happy to help.&lt;/p&gt; 
&lt;p&gt;Together we can make Codex CLI an incredible tool. &lt;strong&gt;Happy hacking!&lt;/strong&gt; &lt;span&gt;üöÄ&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;Contributor license agreement (CLA)&lt;/h3&gt; 
&lt;p&gt;All contributors &lt;strong&gt;must&lt;/strong&gt; accept the CLA. The process is lightweight:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Open your pull request.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Paste the following comment (or reply &lt;code&gt;recheck&lt;/code&gt; if you've signed before):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-text"&gt;I have read the CLA Document and I hereby sign the CLA
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The CLA-Assistant bot records your signature in the repo and marks the status check as passed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;No special Git commands, email attachments, or commit footers required.&lt;/p&gt; 
&lt;h4&gt;Quick fixes&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amend last commit&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;git commit --amend -s --no-edit &amp;amp;&amp;amp; git push -f&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The &lt;strong&gt;DCO check&lt;/strong&gt; blocks merges until every commit in the PR carries the footer (with squash this is just the one).&lt;/p&gt; 
&lt;h3&gt;Releasing &lt;code&gt;codex&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;For admins only.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Make sure you are on &lt;code&gt;main&lt;/code&gt; and have no local changes. Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;VERSION=0.2.0  # Can also be 0.2.0-alpha.1 or any valid Rust version.
./codex-rs/scripts/create_github_release.sh "$VERSION"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will make a local commit on top of &lt;code&gt;main&lt;/code&gt; with &lt;code&gt;version&lt;/code&gt; set to &lt;code&gt;$VERSION&lt;/code&gt; in &lt;code&gt;codex-rs/Cargo.toml&lt;/code&gt; (note that on &lt;code&gt;main&lt;/code&gt;, we leave the version as &lt;code&gt;version = "0.0.0"&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;This will push the commit using the tag &lt;code&gt;rust-v${VERSION}&lt;/code&gt;, which in turn kicks off &lt;a href="https://raw.githubusercontent.com/openai/codex/main/.github/workflows/rust-release.yml"&gt;the release workflow&lt;/a&gt;. This will create a new GitHub Release named &lt;code&gt;$VERSION&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If everything looks good in the generated GitHub Release, uncheck the &lt;strong&gt;pre-release&lt;/strong&gt; box so it is the latest release.&lt;/p&gt; 
&lt;p&gt;Create a PR to update &lt;a href="https://github.com/Homebrew/homebrew-core/raw/main/Formula/c/codex.rb"&gt;&lt;code&gt;Formula/c/codex.rb&lt;/code&gt;&lt;/a&gt; on Homebrew.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Security &amp;amp; responsible AI&lt;/h2&gt; 
&lt;p&gt;Have you discovered a vulnerability or have concerns about model output? Please e-mail &lt;strong&gt;&lt;a href="mailto:security@openai.com"&gt;security@openai.com&lt;/a&gt;&lt;/strong&gt; and we will respond promptly.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aws/amazon-q-developer-cli</title>
      <link>https://github.com/aws/amazon-q-developer-cli</link>
      <description>&lt;p&gt;‚ú® Agentic chat experience in your terminal. Build applications using natural language.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Amazon Q CLI&lt;/h1&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;DMG&lt;/strong&gt;: &lt;a href="https://desktop-release.q.us-east-1.amazonaws.com/latest/Amazon%20Q.dmg"&gt;Download now&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-ubuntu"&gt;Ubuntu/Debian&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-appimage"&gt;AppImage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-alternative-linux"&gt;Alternative Linux builds&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you so much for considering to contribute to Amazon Q.&lt;/p&gt; 
&lt;p&gt;Before getting started, see our &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/CONTRIBUTING.md#security-issue-notifications"&gt;contributing docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;MacOS 
  &lt;ul&gt; 
   &lt;li&gt;Xcode 13 or later&lt;/li&gt; 
   &lt;li&gt;Brew&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1. Clone repo&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/aws/amazon-q-developer-cli.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Install the Rust toolchain using &lt;a href="https://rustup.rs"&gt;Rustup&lt;/a&gt;:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup default stable
rustup toolchain install nightly
cargo install typos-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Develop locally&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;To compile and run: &lt;code&gt;cargo run --bin chat_cli&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To run tests: &lt;code&gt;cargo test&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To run lints: &lt;code&gt;cargo clippy&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To format rust files: &lt;code&gt;cargo +nightly fmt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To run subcommands: &lt;code&gt;cargo run --bin chat_cli -- {subcommand}&lt;/code&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;Login would then be: &lt;code&gt;cargo run --bin chat_cli -- login&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Project Layout&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/crates/chat_cli/"&gt;&lt;code&gt;chat_cli&lt;/code&gt;&lt;/a&gt; - the &lt;code&gt;q&lt;/code&gt; CLI, allows users to interface with Amazon Q Developer from the command line&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/scripts/"&gt;&lt;code&gt;scripts/&lt;/code&gt;&lt;/a&gt; - Contains ops and build related scripts&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/crates/"&gt;&lt;code&gt;crates/&lt;/code&gt;&lt;/a&gt; - Contains all rust crates&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/docs/"&gt;&lt;code&gt;docs/&lt;/code&gt;&lt;/a&gt; - Contains technical documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;For security related concerns, see &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/SECURITY.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;This repo is dual licensed under MIT and Apache 2.0 licenses.&lt;/p&gt; 
&lt;p&gt;Those licenses can be found &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/LICENSE.MIT"&gt;here&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/LICENSE.APACHE"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;‚ÄúAmazon Web Services‚Äù and all related marks, including logos, graphic designs, and service names, are trademarks or trade dress of AWS in the U.S. and other countries. AWS‚Äôs trademarks and trade dress may not be used in connection with any product or service that is not AWS‚Äôs, in any manner that is likely to cause confusion among customers, or in any manner that disparages or discredits AWS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tauri-apps/tauri</title>
      <link>https://github.com/tauri-apps/tauri</link>
      <description>&lt;p&gt;Build smaller, faster, and more secure desktop and mobile applications with a web frontend.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/splash.png" alt="Tauri" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/tauri-apps/tauri/tree/dev"&gt;&lt;img src="https://img.shields.io/badge/status-stable-blue.svg?sanitize=true" alt="status" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/tauri"&gt;&lt;img src="https://img.shields.io/badge/License-MIT%20or%20Apache%202-green.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tauri-apps/tauri/actions/workflows/test-core.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/tauri-apps/tauri/test-core.yml?label=test%20core&amp;amp;logo=github" alt="test core" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/tauri"&gt;&lt;img src="https://img.shields.io/badge/chat-discord-7289da.svg?sanitize=true" alt="Chat Server" /&gt;&lt;/a&gt; &lt;a href="https://tauri.app"&gt;&lt;img src="https://img.shields.io/badge/website-tauri.app-purple.svg?sanitize=true" alt="website" /&gt;&lt;/a&gt; &lt;a href="https://good-labs.github.io/greater-good-affirmation"&gt;&lt;img src="https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg?sanitize=true" alt="https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/tauri"&gt;&lt;img src="https://img.shields.io/badge/sponsor-Open%20Collective-blue.svg?sanitize=true" alt="support" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Tauri is a framework for building tiny, blazingly fast binaries for all major desktop platforms. Developers can integrate any front-end framework that compiles to HTML, JS and CSS for building their user interface. The backend of the application is a rust-sourced binary with an API that the front-end can interact with.&lt;/p&gt; 
&lt;p&gt;The user interface in Tauri apps currently leverages &lt;a href="https://docs.rs/tao"&gt;&lt;code&gt;tao&lt;/code&gt;&lt;/a&gt; as a window handling library on macOS, Windows, Linux, Android and iOS. To render your application, Tauri uses &lt;a href="https://github.com/tauri-apps/wry"&gt;WRY&lt;/a&gt;, a library which provides a unified interface to the system webview, leveraging WKWebView on macOS &amp;amp; iOS, WebView2 on Windows, WebKitGTK on Linux and Android System WebView on Android.&lt;/p&gt; 
&lt;p&gt;To learn more about the details of how all of these pieces fit together, please consult this &lt;a href="https://github.com/tauri-apps/tauri/raw/dev/ARCHITECTURE.md"&gt;ARCHITECTURE.md&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;If you are interested in making a tauri app, please visit the &lt;a href="https://tauri.app"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The quickest way to get started is to install the &lt;a href="https://v2.tauri.app/start/prerequisites/"&gt;prerequisites&lt;/a&gt; for your system and create a new project with &lt;a href="https://github.com/tauri-apps/create-tauri-app/#usage"&gt;&lt;code&gt;create-tauri-app&lt;/code&gt;&lt;/a&gt;. For example with &lt;code&gt;npm&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm create tauri-app@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;The list of Tauri's features includes, but is not limited to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built-in app bundler to create app bundles in formats like &lt;code&gt;.app&lt;/code&gt;, &lt;code&gt;.dmg&lt;/code&gt;, &lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, &lt;code&gt;.AppImage&lt;/code&gt; and Windows installers like &lt;code&gt;.exe&lt;/code&gt; (via NSIS) and &lt;code&gt;.msi&lt;/code&gt; (via WiX).&lt;/li&gt; 
 &lt;li&gt;Built-in self updater (desktop only)&lt;/li&gt; 
 &lt;li&gt;System tray icons&lt;/li&gt; 
 &lt;li&gt;Native notifications&lt;/li&gt; 
 &lt;li&gt;Native WebView Protocol (tauri doesn't create a localhost http(s) server to serve the WebView contents)&lt;/li&gt; 
 &lt;li&gt;GitHub action for streamlined CI&lt;/li&gt; 
 &lt;li&gt;VS Code extension&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Platforms&lt;/h3&gt; 
&lt;p&gt;Tauri currently supports development and distribution on the following platforms:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Versions&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Windows&lt;/td&gt; 
   &lt;td align="left"&gt;7 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;macOS&lt;/td&gt; 
   &lt;td align="left"&gt;10.15 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Linux&lt;/td&gt; 
   &lt;td align="left"&gt;webkit2gtk 4.0 for Tauri v1 (for example Ubuntu 18.04). webkit2gtk 4.1 for Tauri v2 (for example Ubuntu 22.04).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;iOS/iPadOS&lt;/td&gt; 
   &lt;td align="left"&gt;9 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Android&lt;/td&gt; 
   &lt;td align="left"&gt;7 and above (currently 8 and above)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Before you start working on something, it's best to check if there is an existing issue first. It's also a good idea to stop by the Discord server and confirm with the team if it makes sense or if someone else is already working on it.&lt;/p&gt; 
&lt;p&gt;Please make sure to read the &lt;a href="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; before making a pull request.&lt;/p&gt; 
&lt;p&gt;Thank you to everyone contributing to Tauri!&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;Documentation in a polyglot system is a tricky proposition. To this end, we prefer to use inline documentation in the Rust &amp;amp; JS source code as much as possible. Check out the hosting repository for the documentation site for further information: &lt;a href="https://github.com/tauri-apps/tauri-docs"&gt;https://github.com/tauri-apps/tauri-docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://crabnebula.dev" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/sponsors/crabnebula.svg?sanitize=true" alt="CrabNebula" width="283" /&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For the complete list of sponsors please visit our &lt;a href="https://tauri.app#sponsors"&gt;website&lt;/a&gt; and &lt;a href="https://opencollective.com/tauri"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Organization&lt;/h2&gt; 
&lt;p&gt;Tauri aims to be a sustainable collective based on principles that guide &lt;a href="https://sfosc.org"&gt;sustainable free and open software communities&lt;/a&gt;. To this end it has become a Programme within the &lt;a href="https://commonsconservancy.org/"&gt;Commons Conservancy&lt;/a&gt;, and you can contribute financially via &lt;a href="https://opencollective.com/tauri"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;Code: (c) 2015 - Present - The Tauri Programme within The Commons Conservancy.&lt;/p&gt; 
&lt;p&gt;MIT or MIT/Apache 2.0 where applicable.&lt;/p&gt; 
&lt;p&gt;Logo: CC-BY-NC-ND&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Original Tauri Logo Designs by &lt;a href="https://alve.io/"&gt;Alve Larsson&lt;/a&gt;, &lt;a href="https://github.com/nothingismagick"&gt;Daniel Thompson-Yvetot&lt;/a&gt; and &lt;a href="https://github.com/akryum"&gt;Guillaume Chau&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_large"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>