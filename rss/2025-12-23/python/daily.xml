<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Mon, 22 Dec 2025 01:37:35 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>GreyDGL/PentestGPT</title>
      <link>https://github.com/GreyDGL/PentestGPT</link>
      <description>&lt;p&gt;A GPT-empowered penetration testing tool&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- PROJECT SHIELDS --&gt; 
&lt;p&gt;&lt;a href="https://github.com/GreyDGL/PentestGPT/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GreyDGL/PentestGPT/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GreyDGL/PentestGPT/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GreyDGL/PentestGPT/issues"&gt;&lt;img src="https://img.shields.io/github/issues/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GreyDGL/PentestGPT/raw/master/LICENSE.md"&gt;&lt;img src="https://img.shields.io/github/license/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="MIT License" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/eC34CEfEkK"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/eC34CEfEkK" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;h3 align="center"&gt;PentestGPT&lt;/h3&gt; 
 &lt;p align="center"&gt; AI-Powered Autonomous Penetration Testing Agent &lt;br /&gt; &lt;strong&gt;Published at USENIX Security 2024&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://www.usenix.org/conference/usenixsecurity24/presentation/deng"&gt;Research Paper&lt;/a&gt; ¬∑ &lt;a href="https://github.com/GreyDGL/PentestGPT/issues"&gt;Report Bug&lt;/a&gt; ¬∑ &lt;a href="https://github.com/GreyDGL/PentestGPT/issues"&gt;Request Feature&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- ABOUT THE PROJECT --&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/3770" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3770" alt="GreyDGL%2FPentestGPT | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;PentestGPT is a research prototype only&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;PentestGPT is a research prototype that pioneered the use of GenAI in cybersecurity. Please be aware of third-party services claiming to offer paid PentestGPT products - the original project is free and open-source.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://asciinema.org/a/761661"&gt;&lt;img src="https://asciinema.org/a/761661.svg?sanitize=true" alt="Installation Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=RUNmoXqBwVg"&gt;Watch on YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;PentestGPT in Action&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://asciinema.org/a/761663"&gt;&lt;img src="https://asciinema.org/a/761663.svg?sanitize=true" alt="PentestGPT Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=cWi3Yb7RmZA"&gt;Watch on YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;What's New in v1.0 (Agentic Upgrade)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Autonomous Agent&lt;/strong&gt; - Agentic pipeline for intelligent, autonomous penetration testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Persistence&lt;/strong&gt; - Save and resume penetration testing sessions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker-First&lt;/strong&gt; - Isolated, reproducible environment with security tools pre-installed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;In Progress&lt;/strong&gt;: Multi-model support for OpenAI, Gemini, and other LLM providers&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI-Powered Challenge Solver&lt;/strong&gt; - Leverages LLM advanced reasoning to perform penetration testing and CTFs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live Walkthrough&lt;/strong&gt; - Tracks steps in real-time as the agent works through challenges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Category Support&lt;/strong&gt; - Web, Crypto, Reversing, Forensics, PWN, Privilege Escalation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Feedback&lt;/strong&gt; - Watch the AI work with live activity updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible Architecture&lt;/strong&gt; - Clean, modular design ready for future enhancements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt; (required) - &lt;a href="https://docs.docker.com/get-docker/"&gt;Install Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Provider&lt;/strong&gt; (choose one): 
  &lt;ul&gt; 
   &lt;li&gt;Anthropic API Key from &lt;a href="https://console.anthropic.com/"&gt;console.anthropic.com&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Claude OAuth Login (requires Claude subscription)&lt;/li&gt; 
   &lt;li&gt;OpenRouter for alternative models at &lt;a href="https://openrouter.ai/keys"&gt;openrouter.ai&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.google.com/document/d/1ixK7x-wlr5t5TYZJdfm75UME5KnPCpS46boLkUXKg1w/edit?usp=sharing"&gt;Tutorial: Using Local Models with Claude Code&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone and build
git clone --recurse-submodules https://github.com/GreyDGL/PentestGPT.git
cd PentestGPT
make install

# Configure authentication (first time only)
make config

# Connect to container
make connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;--recurse-submodules&lt;/code&gt; flag downloads the benchmark suite. If you already cloned without it, run: &lt;code&gt;git submodule update --init --recursive&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Try a Benchmark&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run pentestgpt-benchmark start XBEN-037-24 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then connect into the container and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pentestgpt --target http://host.docker.internal:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Commands Reference&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make install&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Build the Docker image&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make config&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Configure API key (first-time setup)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make connect&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to container (main entry point)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make stop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Stop container (config persists)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make clean-docker&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Remove everything including config&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Interactive TUI mode (default)
pentestgpt --target 10.10.11.234

# Non-interactive mode
pentestgpt --target 10.10.11.100 --non-interactive

# With challenge context
pentestgpt --target 10.10.11.50 --instruction "WordPress site, focus on plugin vulnerabilities"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Keyboard Shortcuts:&lt;/strong&gt; &lt;code&gt;F1&lt;/code&gt; Help | &lt;code&gt;Ctrl+P&lt;/code&gt; Pause/Resume | &lt;code&gt;Ctrl+Q&lt;/code&gt; Quit&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Using Local LLMs&lt;/h2&gt; 
&lt;p&gt;PentestGPT supports routing requests to local LLM servers (LM Studio, Ollama, text-generation-webui, etc.) running on your host machine.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Local LLM server with an OpenAI-compatible API endpoint 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LM Studio&lt;/strong&gt;: Enable server mode (default port 1234)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: Run &lt;code&gt;ollama serve&lt;/code&gt; (default port 11434)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Configure PentestGPT for local LLM
make config
# Select option 4: Local LLM

# Start your local LLM server on the host machine
# Then connect to the container
make connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customizing Models&lt;/h3&gt; 
&lt;p&gt;Edit &lt;code&gt;scripts/ccr-config-template.json&lt;/code&gt; to customize:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;localLLM.api_base_url&lt;/code&gt;&lt;/strong&gt;: Your LLM server URL (default: &lt;code&gt;host.docker.internal:1234&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;localLLM.models&lt;/code&gt;&lt;/strong&gt;: Available model names on your server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Router section&lt;/strong&gt;: Which models handle which operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Route&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Default Model&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;default&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;General tasks&lt;/td&gt; 
   &lt;td&gt;openai/gpt-oss-20b&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;background&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Background operations&lt;/td&gt; 
   &lt;td&gt;openai/gpt-oss-20b&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;think&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Reasoning-heavy tasks&lt;/td&gt; 
   &lt;td&gt;qwen/qwen3-coder-30b&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;longContext&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Large context handling&lt;/td&gt; 
   &lt;td&gt;qwen/qwen3-coder-30b&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;webSearch&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Web search operations&lt;/td&gt; 
   &lt;td&gt;openai/gpt-oss-20b&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Connection refused&lt;/strong&gt;: Ensure your LLM server is running and listening on the configured port&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker networking&lt;/strong&gt;: Use &lt;code&gt;host.docker.internal&lt;/code&gt; (not &lt;code&gt;localhost&lt;/code&gt;) to access host services from Docker&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check CCR logs&lt;/strong&gt;: Inside the container, run &lt;code&gt;cat /tmp/ccr.log&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;PentestGPT collects anonymous usage data to help improve the tool. This data is sent to our &lt;a href="https://langfuse.com"&gt;Langfuse&lt;/a&gt; project and includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Session metadata (target type, duration, completion status)&lt;/li&gt; 
 &lt;li&gt;Tool execution patterns (which tools are used, not the actual commands)&lt;/li&gt; 
 &lt;li&gt;Flag detection events (that a flag was found, not the flag content)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;No sensitive data is collected&lt;/strong&gt; - command outputs, credentials, or actual flag values are never transmitted.&lt;/p&gt; 
&lt;h3&gt;Opting Out&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Via command line flag
pentestgpt --target 10.10.11.234 --no-telemetry

# Via environment variable
export LANGFUSE_ENABLED=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;PentestGPT includes 100+ vulnerability challenges for testing and development.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pentestgpt-benchmark list                    # List all benchmarks
pentestgpt-benchmark list --levels 1         # Filter by difficulty
pentestgpt-benchmark list --tags sqli        # Filter by vulnerability type
pentestgpt-benchmark start XBEN-037-24       # Start a benchmark
pentestgpt-benchmark status                  # Check running benchmarks
pentestgpt-benchmark stop XBEN-037-24        # Stop a benchmark
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Tags:&lt;/strong&gt; &lt;code&gt;sqli&lt;/code&gt;, &lt;code&gt;xss&lt;/code&gt;, &lt;code&gt;idor&lt;/code&gt;, &lt;code&gt;ssti&lt;/code&gt;, &lt;code&gt;ssrf&lt;/code&gt;, &lt;code&gt;lfi&lt;/code&gt;, &lt;code&gt;rce&lt;/code&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;uv&lt;/strong&gt; (required) - Python package manager: &lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Code CLI&lt;/strong&gt; - Configure with &lt;code&gt;claude login&lt;/code&gt; or &lt;code&gt;export ANTHROPIC_API_KEY='your-key'&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.google.com/document/d/1ixK7x-wlr5t5TYZJdfm75UME5KnPCpS46boLkUXKg1w/edit?usp=sharing"&gt;Tutorial: Using Local Models with Claude Code&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv sync                                      # Install dependencies
uv run pentestgpt --target 10.10.11.234      # Run locally
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Project Commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test          # Run pytest
make lint          # Run ruff linter
make typecheck     # Run mypy
make ci            # Run full CI simulation (lint, format, typecheck, test, build)
make ci-quick      # Quick CI without build step
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Legacy Version&lt;/h2&gt; 
&lt;p&gt;The previous multi-LLM version (v0.15) supporting OpenAI, Gemini, Deepseek, and Ollama is archived in &lt;a href="https://raw.githubusercontent.com/GreyDGL/PentestGPT/main/legacy/"&gt;&lt;code&gt;legacy/&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd legacy &amp;amp;&amp;amp; pip install -e . &amp;amp;&amp;amp; pentestgpt --reasoning gpt-4o
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use PentestGPT in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{299699,
  author = {Gelei Deng and Yi Liu and V√≠ctor Mayoral-Vilches and Peng Liu and Yuekang Li and Yuan Xu and Tianwei Zhang and Yang Liu and Martin Pinzger and Stefan Rass},
  title = {{PentestGPT}: Evaluating and Harnessing Large Language Models for Automated Penetration Testing},
  booktitle = {33rd USENIX Security Symposium (USENIX Security 24)},
  year = {2024},
  isbn = {978-1-939133-44-1},
  address = {Philadelphia, PA},
  pages = {847--864},
  url = {https://www.usenix.org/conference/usenixsecurity24/presentation/deng},
  publisher = {USENIX Association},
  month = aug
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Distributed under the MIT License. See &lt;code&gt;LICENSE.md&lt;/code&gt; for more information.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: This tool is for educational purposes and authorized security testing only. The authors do not condone any illegal use. Use at your own risk.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gelei Deng&lt;/strong&gt; - &lt;a href="https://www.linkedin.com/in/gelei-deng-225a10112/"&gt;&lt;img src="https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;colorB=555" alt="LinkedIn" /&gt;&lt;/a&gt; - &lt;a href="mailto:gelei.deng@ntu.edu.sg"&gt;gelei.deng@ntu.edu.sg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Yi Liu&lt;/strong&gt; - &lt;a href="mailto:yi009@e.ntu.edu.sg"&gt;yi009@e.ntu.edu.sg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Yuekang Li&lt;/strong&gt; - &lt;a href="mailto:yuekang.li@unsw.edu.au"&gt;yuekang.li@unsw.edu.au&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;V√≠ctor Mayoral Vilches&lt;/strong&gt; - &lt;a href="https://www.linkedin.com/in/vmayoral/"&gt;&lt;img src="https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;colorB=555" alt="LinkedIn" /&gt;&lt;/a&gt; - &lt;a href="mailto:v.mayoralv@gmail.com"&gt;v.mayoralv@gmail.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Peng Liu&lt;/strong&gt; - &lt;a href="mailto:liu_peng@i2r.a-star.edu.sg"&gt;liu_peng@i2r.a-star.edu.sg&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Research supported by &lt;a href="https://www.quantstamp.com/"&gt;Quantstamp&lt;/a&gt; and &lt;a href="https://www.ntu.edu.sg/"&gt;NTU Singapore&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/GreyDGL/PentestGPT/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;</description>
    </item>
    
    <item>
      <title>sgl-project/mini-sglang</title>
      <link>https://github.com/sgl-project/mini-sglang</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="400" src="https://raw.githubusercontent.com/sgl-project/mini-sglang/main/assets/logo.png" /&gt; &lt;/p&gt; 
&lt;h1&gt;Mini-SGLang&lt;/h1&gt; 
&lt;p&gt;A &lt;strong&gt;lightweight yet high-performance&lt;/strong&gt; inference framework for Large Language Models.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Mini-SGLang is a compact implementation of &lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt;, designed to demystify the complexities of modern LLM serving systems. With a compact codebase of &lt;strong&gt;~5,000 lines of Python&lt;/strong&gt;, it serves as both a capable inference engine and a transparent reference for researchers and developers.&lt;/p&gt; 
&lt;h2&gt;‚ú® Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Achieves state-of-the-art throughput and latency with advanced optimizations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight &amp;amp; Readable&lt;/strong&gt;: A clean, modular, and fully type-annotated codebase that is easy to understand and modify.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Optimizations&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Radix Cache&lt;/strong&gt;: Reuses KV cache for shared prefixes across requests.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Chunked Prefill&lt;/strong&gt;: Reduces peak memory usage for long-context serving.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Overlap Scheduling&lt;/strong&gt;: Hides CPU scheduling overhead with GPU computation.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;: Scales inference across multiple GPUs.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Optimized Kernels&lt;/strong&gt;: Integrates &lt;strong&gt;FlashAttention&lt;/strong&gt; and &lt;strong&gt;FlashInfer&lt;/strong&gt; for maximum efficiency.&lt;/li&gt; 
   &lt;li&gt;...&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Environment Setup&lt;/h3&gt; 
&lt;p&gt;We recommend using &lt;code&gt;uv&lt;/code&gt; for a fast and reliable installation (note that &lt;code&gt;uv&lt;/code&gt; does not conflict with &lt;code&gt;conda&lt;/code&gt;).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a virtual environment (Python 3.10+ recommended)
uv venv --python=3.12
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: Mini-SGLang relies on CUDA kernels that are JIT-compiled. Ensure you have the &lt;strong&gt;NVIDIA CUDA Toolkit&lt;/strong&gt; installed and that its version matches your driver's version. You can check your driver's CUDA capability with &lt;code&gt;nvidia-smi&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install Mini-SGLang directly from the source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/sgl-project/mini-sglang.git
cd mini-sglang &amp;amp;&amp;amp; uv venv --python=3.12 &amp;amp;&amp;amp; source .venv/bin/activate
uv pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Online Serving&lt;/h3&gt; 
&lt;p&gt;Launch an OpenAI-compatible API server with a single command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Deploy Qwen/Qwen3-0.6B on a single GPU
python -m minisgl --model "Qwen/Qwen3-0.6B"

# Deploy meta-llama/Llama-3.1-70B-Instruct on 4 GPUs with Tensor Parallelism, on port 30000
python -m minisgl --model "meta-llama/Llama-3.1-70B-Instruct" --tp 4 --port 30000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once the server is running, you can send requests using standard tools like &lt;code&gt;curl&lt;/code&gt; or any OpenAI-compatible client.&lt;/p&gt; 
&lt;h3&gt;4. Interactive Shell&lt;/h3&gt; 
&lt;p&gt;Chat with your model directly in the terminal by adding the &lt;code&gt;--shell&lt;/code&gt; flag.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m minisgl --model "Qwen/Qwen3-0.6B" --shell
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://lmsys.org/images/blog/minisgl/shell.png" alt="shell-example" /&gt;&lt;/p&gt; 
&lt;p&gt;You can also use &lt;code&gt;/reset&lt;/code&gt; to clear the chat history.&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;h3&gt;Offline inference&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/sgl-project/mini-sglang/main/benchmark/offline/bench.py"&gt;bench.py&lt;/a&gt; for more details. Set &lt;code&gt;MINISGL_DISABLE_OVERLAP_SCHEDULING=1&lt;/code&gt; for ablation study on overlap scheduling.&lt;/p&gt; 
&lt;p&gt;Test Configuration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hardware: 1xH200 GPU.&lt;/li&gt; 
 &lt;li&gt;Model: Qwen3-0.6B, Qwen3-14B&lt;/li&gt; 
 &lt;li&gt;Total Requests: 256 sequences&lt;/li&gt; 
 &lt;li&gt;Input Length: Randomly sampled between 100-1024 tokens&lt;/li&gt; 
 &lt;li&gt;Output Length: Randomly sampled between 100-1024 tokens&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://lmsys.org/images/blog/minisgl/offline.png" alt="offline" /&gt;&lt;/p&gt; 
&lt;h3&gt;Online inference&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/sgl-project/mini-sglang/main/benchmark/online/bench_qwen.py"&gt;benchmark_qwen.py&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;Test Configuration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hardware: 4xH200 GPU, connected by NVLink.&lt;/li&gt; 
 &lt;li&gt;Model: Qwen3-32B&lt;/li&gt; 
 &lt;li&gt;Dataset: &lt;a href="https://github.com/alibaba-edu/qwen-bailian-usagetraces-anon/raw/main/qwen_traceA_blksz_16.jsonl"&gt;Qwen trace&lt;/a&gt;, replaying first 1000 requests.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Launch command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Mini-SGLang
python -m minisgl --model "Qwen/Qwen3-32B" --tp 4 --cache naive

# SGLang
python3 -m sglang.launch_server --model "Qwen/Qwen3-32B" --tp 4 \
    --disable-radix --port 1919 --decode-attention flashinfer
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://lmsys.org/images/blog/minisgl/online.png" alt="online" /&gt;&lt;/p&gt; 
&lt;h2&gt;üìö Learn More&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sgl-project/mini-sglang/main/docs/features.md"&gt;Detailed Features&lt;/a&gt;&lt;/strong&gt;: Explore all available features and command-line arguments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sgl-project/mini-sglang/main/docs/structures.md"&gt;System Architecture&lt;/a&gt;&lt;/strong&gt;: Dive deep into the design and data flow of Mini-SGLang.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>pollen-robotics/reachy_mini</title>
      <link>https://github.com/pollen-robotics/reachy_mini</link>
      <description>&lt;p&gt;Reachy Mini's SDK&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Reachy Mini ü§ñ&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/chat/?attachments=https%3A%2F%2Fgist.githubusercontent.com%2FFabienDanieau%2F919e1d7468fb16e70dbe984bdc277bba%2Fraw%2Fdoc_reachy_mini_full.md&amp;amp;prompt=Read%20this%20documentation%20about%20Reachy%20Mini%20so%20I%20can%20ask%20questions%20about%20it."&gt;&lt;img src="https://img.shields.io/badge/Ask_on-HuggingChat-yellow?logo=huggingface&amp;amp;logoColor=yellow&amp;amp;style=for-the-badge" alt="Ask on HuggingChat" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Y7FgMqHsub"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join_the_Community-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Reachy Mini is an open-source, expressive robot made for hackers and AI builders.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;üõí &lt;a href="https://www.hf.co/reachy-mini/"&gt;&lt;strong&gt;Buy Reachy Mini&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.pollen-robotics.com/reachy-mini/"&gt;&lt;img src="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/assets/reachy_mini_hello.gif" alt="Reachy Mini Hello" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ö°Ô∏è Build and start your own robot&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Choose your platform to access the specific guide:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;ü§ñ Reachy Mini (Wireless)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;üîå Reachy Mini Lite&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;üíª Simulation&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;The full autonomous experience.&lt;br /&gt;Raspberry Pi 4 + Battery + WiFi.&lt;/td&gt; 
   &lt;td align="center"&gt;The developer version.&lt;br /&gt;USB connection to your computer.&lt;/td&gt; 
   &lt;td align="center"&gt;No hardware required.&lt;br /&gt;Prototype in MuJoCo.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üëâ &lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/platforms/reachy_mini/get_started.md"&gt;&lt;strong&gt;Go to Wireless Guide&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üëâ &lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/platforms/reachy_mini_lite/get_started.md"&gt;&lt;strong&gt;Go to Lite Guide&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üëâ &lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/platforms/simulation/get_started.md"&gt;&lt;strong&gt;Go to Simulation&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö° &lt;strong&gt;Pro tip:&lt;/strong&gt; Install &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; for 10-100x faster app installations (auto-detected, falls back to &lt;code&gt;pip&lt;/code&gt;).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h2&gt;üì± Apps &amp;amp; Ecosystem&lt;/h2&gt; 
&lt;p&gt;Reachy Mini comes with an app store powered by Hugging Face Spaces. You can install these apps directly from your robot's dashboard with one click!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üó£Ô∏è &lt;a href="https://huggingface.co/spaces/pollen-robotics/reachy_mini_conversation_app"&gt;Conversation App&lt;/a&gt;:&lt;/strong&gt; Talk naturally with Reachy Mini (powered by LLMs).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìª &lt;a href="https://huggingface.co/spaces/pollen-robotics/reachy_mini_radio"&gt;Radio&lt;/a&gt;:&lt;/strong&gt; Listen to the radio with Reachy Mini !&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üëã &lt;a href="https://huggingface.co/spaces/pollen-robotics/hand_tracker_v2"&gt;Hand Tracker&lt;/a&gt;:&lt;/strong&gt; The robot follows your hand movements in real-time.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üëâ &lt;a href="https://hf.co/reachy-mini/#/apps"&gt;&lt;strong&gt;Browse all apps on Hugging Face&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;üöÄ Getting Started with Reachy Mini SDK&lt;/h2&gt; 
&lt;h3&gt;Quick Look&lt;/h3&gt; 
&lt;p&gt;Control your robot in just &lt;strong&gt;a few lines of code&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from reachy_mini import ReachyMini
from reachy_mini.utils import create_head_pose

with ReachyMini() as mini:
    # Look up and tilt head
    mini.goto_target(
        head=create_head_pose(z=10, roll=15, degrees=True, mm=True),
        duration=1.0
    )
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;User guides&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/SDK/installation.md"&gt;Installation&lt;/a&gt;&lt;/strong&gt;: 5 minutes to set up your computer&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/SDK/quickstart.md"&gt;Quickstart Guide&lt;/a&gt;&lt;/strong&gt;: Run your first behavior on Reachy Mini&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/SDK/python-sdk.md"&gt;Python SDK&lt;/a&gt;&lt;/strong&gt;: Learn to move, see, speak, and hear.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/SDK/integration.md"&gt;AI Integrations&lt;/a&gt;&lt;/strong&gt;: Connect LLMs, build Apps, and publish to Hugging Face.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/SDK/core-concept.md"&gt;Core Concepts&lt;/a&gt;&lt;/strong&gt;: Architecture, coordinate systems, and safety limits.&lt;/li&gt; 
 &lt;li&gt;ü§ó&lt;a href="https://huggingface.co/blog/pollen-robotics/make-and-publish-your-reachy-mini-apps"&gt;&lt;strong&gt;Share your app with the community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìÇ &lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/examples"&gt;&lt;strong&gt;Browse the Examples Folder&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;üõ† Hardware Overview&lt;/h2&gt; 
&lt;p&gt;Reachy Mini robots are sold as kits and generally take &lt;strong&gt;2 to 3 hours&lt;/strong&gt; to assemble. Detailed step-by-step guides are available in the platform-specific folders linked above.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Reachy Mini (Wireless):&lt;/strong&gt; Runs onboard (RPi 4), autonomous, includes IMU. &lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/platforms/reachy_mini/hardware.md"&gt;See specs&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reachy Mini Lite:&lt;/strong&gt; Runs on your PC, powered via wall outlet. &lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/platforms/reachy_mini_lite/hardware.md"&gt;See specs&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;‚ùì Troubleshooting&lt;/h2&gt; 
&lt;p&gt;Encountering an issue? üëâ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/docs/troubleshooting.md"&gt;Check the Troubleshooting &amp;amp; FAQ Guide&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ü§ù Community &amp;amp; Contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Join the Community:&lt;/strong&gt; Join &lt;a href="https://discord.gg/2bAhWfXme9"&gt;Discord&lt;/a&gt; to share your moments with Reachy, build apps together, and get help.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Found a bug?&lt;/strong&gt; Open an issue on this repository.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License. See the &lt;a href="https://raw.githubusercontent.com/pollen-robotics/reachy_mini/develop/LICENSE"&gt;LICENSE&lt;/a&gt; file for details. Hardware design files are licensed under Creative Commons BY-SA-NC.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TheAlgorithms/Python</title>
      <link>https://github.com/TheAlgorithms/Python</link>
      <description>&lt;p&gt;All Algorithms implemented in Python&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;!-- Title: --&gt; 
 &lt;a href="https://github.com/TheAlgorithms/"&gt; &lt;img src="https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg?sanitize=true" height="100" /&gt; &lt;/a&gt; 
 &lt;h1&gt;&lt;a href="https://github.com/TheAlgorithms/"&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt; 
 &lt;!-- Labels: --&gt; 
 &lt;!-- First row: --&gt; 
 &lt;a href="https://gitpod.io/#https://github.com/TheAlgorithms/Python"&gt; &lt;img src="https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;amp;style=flat-square" height="20" alt="Gitpod Ready-to-Code" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/raw/master/CONTRIBUTING.md"&gt; &lt;img src="https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=0059b3&amp;amp;style=flat-square" height="20" alt="Contributions Welcome" /&gt; &lt;/a&gt; 
 &lt;img src="https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;amp;style=flat-square" height="20" /&gt; 
 &lt;a href="https://the-algorithms.com/discord"&gt; &lt;img src="https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;amp;colorB=7289DA&amp;amp;style=flat-square" height="20" alt="Discord chat" /&gt; &lt;/a&gt; 
 &lt;a href="https://gitter.im/TheAlgorithms/community"&gt; &lt;img src="https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;amp;logo=gitter&amp;amp;style=flat-square" height="20" alt="Gitter chat" /&gt; &lt;/a&gt; 
 &lt;!-- Second row: --&gt; 
 &lt;br /&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/actions"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/TheAlgorithms/Python/build.yml?branch=master&amp;amp;label=CI&amp;amp;logo=github&amp;amp;style=flat-square" height="20" alt="GitHub Workflow Status" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/pre-commit/pre-commit"&gt; &lt;img src="https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;amp;logoColor=white&amp;amp;style=flat-square" height="20" alt="pre-commit" /&gt; &lt;/a&gt; 
 &lt;a href="https://docs.astral.sh/ruff/formatter/"&gt; &lt;img src="https://img.shields.io/static/v1?label=code%20style&amp;amp;message=ruff&amp;amp;color=black&amp;amp;style=flat-square" height="20" alt="code style: black" /&gt; &lt;/a&gt; 
 &lt;!-- Short description: --&gt; 
 &lt;h3&gt;All algorithms implemented in Python - for education üìö&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p&gt;Implementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.&lt;/p&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;p&gt;üìã Read through our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt; 
&lt;h2&gt;üåê Community Channels&lt;/h2&gt; 
&lt;p&gt;We are on &lt;a href="https://the-algorithms.com/discord"&gt;Discord&lt;/a&gt; and &lt;a href="https://gitter.im/TheAlgorithms/community"&gt;Gitter&lt;/a&gt;! Community channels are a great way for you to ask questions and get help. Please join us!&lt;/p&gt; 
&lt;h2&gt;üìú List of Algorithms&lt;/h2&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/DIRECTORY.md"&gt;directory&lt;/a&gt; for easier navigation and a better overview of the project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lllyasviel/stable-diffusion-webui-forge</title>
      <link>https://github.com/lllyasviel/stable-diffusion-webui-forge</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion WebUI Forge&lt;/h1&gt; 
&lt;p&gt;Stable Diffusion WebUI Forge is a platform on top of &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;Stable Diffusion WebUI&lt;/a&gt; (based on &lt;a href="https://www.gradio.app/"&gt;Gradio&lt;/a&gt; &lt;a href="https://github.com/gradio-app/gradio"&gt;&lt;img src="https://img.shields.io/github/stars/gradio-app/gradio" /&gt;&lt;/a&gt;) to make development easier, optimize resource management, speed up inference, and study experimental features.&lt;/p&gt; 
&lt;p&gt;The name "Forge" is inspired from "Minecraft Forge". This project is aimed at becoming SD WebUI's Forge.&lt;/p&gt; 
&lt;p&gt;Forge is currently based on SD-WebUI 1.10.1 at &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/82a973c04367123ae98bd9abdf80d9eda9b910e2"&gt;this commit&lt;/a&gt;. (Because original SD-WebUI is almost static now, Forge will sync with original WebUI every 90 days, or when important fixes.)&lt;/p&gt; 
&lt;p&gt;News are moved to this link: &lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/raw/main/NEWS.md"&gt;Click here to see the News section&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Quick List&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/853"&gt;Gradio 4 UI Must Read (TLDR: You need to use RIGHT MOUSE BUTTON to move canvas!)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/981"&gt;Flux Tutorial (BitsandBytes Models, NF4, "GPU Weight", "Offload Location", "Offload Method", etc)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1050"&gt;Flux Tutorial 2 (Seperated Full Models, GGUF, Technically Correct Comparison between GGUF and NF4, etc)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1754"&gt;Forge Extension List and Extension Replacement List (Temporary)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1038"&gt;How to make LoRAs more precise on low-bit models; How to Skip" Patching LoRAs"; How to only load LoRA one time rather than each generation; How to report LoRAs that do not work&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1181"&gt;Report Flux Performance Problems (TLDR: DO NOT set "GPU Weight" too high! Lower "GPU Weight" solves 99% problems!)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1474"&gt;How to solve "Connection errored out" / "Press anykey to continue ..." / etc&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1224#discussioncomment-10384104"&gt;(Save Flux BitsandBytes UNet/Checkpoint)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/854"&gt;LayerDiffuse Transparent Image Editing&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/932"&gt;Tell us what is missing in ControlNet Integrated&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1286"&gt;(Policy) Soft Advertisement Removal Policy&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;(Flux BNB NF4 / GGUF Q8_0/Q5_0/Q5_1/Q4_0/Q4_1 are all natively supported with GPU weight slider and Quene/Async Swap toggle and swap location toggle. All Flux BNB NF4 / GGUF Q8_0/Q5_0/Q4_0 have LoRA support.)&lt;/p&gt; 
&lt;h1&gt;Installing Forge&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Just use this one-click installation package (with git and python included).&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch231.7z"&gt;&amp;gt;&amp;gt;&amp;gt; Click Here to Download One-Click Package (CUDA 12.1 + Pytorch 2.3.1) &amp;lt;&amp;lt;&amp;lt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Some other CUDA/Torch Versions:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch231.7z"&gt;Forge with CUDA 12.1 + Pytorch 2.3.1&lt;/a&gt; &amp;lt;- &lt;strong&gt;Recommended&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu124_torch24.7z"&gt;Forge with CUDA 12.4 + Pytorch 2.4&lt;/a&gt; &amp;lt;- &lt;strong&gt;Fastest&lt;/strong&gt;, but MSVC may be broken, xformers may not work&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch21.7z"&gt;Forge with CUDA 12.1 + Pytorch 2.1&lt;/a&gt; &amp;lt;- the previously used old environments&lt;/p&gt; 
&lt;p&gt;After you download, you uncompress, use &lt;code&gt;update.bat&lt;/code&gt; to update, and use &lt;code&gt;run.bat&lt;/code&gt; to run.&lt;/p&gt; 
&lt;p&gt;Note that running &lt;code&gt;update.bat&lt;/code&gt; is important, otherwise you may be using a previous version with potential bugs unfixed.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/lllyasviel/stable-diffusion-webui-forge/assets/19834515/c49bd60d-82bd-4086-9859-88d472582b94" alt="image" /&gt;&lt;/p&gt; 
&lt;h3&gt;Advanced Install&lt;/h3&gt; 
&lt;p&gt;If you are proficient in Git and you want to install Forge as another branch of SD-WebUI, please see &lt;a href="https://github.com/continue-revolution/sd-webui-animatediff/raw/forge/master/docs/how-to-use.md#you-have-a1111-and-you-know-git"&gt;here&lt;/a&gt;. In this way, you can reuse all SD checkpoints and all extensions you installed previously in your OG SD-WebUI, but you should know what you are doing.&lt;/p&gt; 
&lt;p&gt;If you know what you are doing, you can also install Forge using same method as SD-WebUI. (Install Git, Python, Git Clone the forge repo &lt;code&gt;https://github.com/lllyasviel/stable-diffusion-webui-forge.git&lt;/code&gt; and then run webui-user.bat).&lt;/p&gt; 
&lt;h3&gt;Previous Versions&lt;/h3&gt; 
&lt;p&gt;You can download previous versions &lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/849"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Forge Status&lt;/h1&gt; 
&lt;p&gt;Based on manual test one-by-one:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Last Test&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Basic Diffusion&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GPU Memory Management System&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LoRAs&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All Preprocessors&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All ControlNets&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All IP-Adapters&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All Instant-IDs&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All Reference-only Methods&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All Integrated Extensions&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Popular Extensions (Adetailer, etc)&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gradio 4 UIs&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gradio 4 Forge Canvas&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LoRA/Checkpoint Selection UI for Gradio 4&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Photopea/OpenposeEditor/etc for ControlNet&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Wacom 128 level touch pressure support for Canvas&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Microsoft Surface touch pressure support for Canvas&lt;/td&gt; 
   &lt;td&gt;Broken, pending fix&lt;/td&gt; 
   &lt;td&gt;2024 July 29&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ControlNets (Union)&lt;/td&gt; 
   &lt;td&gt;Not implemented yet, pending implementation&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ControlNets (Flux)&lt;/td&gt; 
   &lt;td&gt;Not implemented yet, pending implementation&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;API endpoints (txt2img, img2img, etc)&lt;/td&gt; 
   &lt;td&gt;Normal, but pending improved Flux support&lt;/td&gt; 
   &lt;td&gt;2024 Aug 29&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OFT LoRAs&lt;/td&gt; 
   &lt;td&gt;Broken, pending fix&lt;/td&gt; 
   &lt;td&gt;2024 Sep 9&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Feel free to open issue if anything is broken and I will take a look every several days. If I do not update this "Forge Status" then it means I cannot reproduce any problem. In that case, fresh re-install should help most.&lt;/p&gt; 
&lt;h1&gt;UnetPatcher&lt;/h1&gt; 
&lt;p&gt;Below are self-supported &lt;strong&gt;single file&lt;/strong&gt; of all codes to implement FreeU V2.&lt;/p&gt; 
&lt;p&gt;See also &lt;code&gt;extension-builtin/sd_forge_freeu/scripts/forge_freeu.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torch
import gradio as gr

from modules import scripts


def Fourier_filter(x, threshold, scale):
    # FFT
    x_freq = torch.fft.fftn(x.float(), dim=(-2, -1))
    x_freq = torch.fft.fftshift(x_freq, dim=(-2, -1))

    B, C, H, W = x_freq.shape
    mask = torch.ones((B, C, H, W), device=x.device)

    crow, ccol = H // 2, W // 2
    mask[..., crow - threshold:crow + threshold, ccol - threshold:ccol + threshold] = scale
    x_freq = x_freq * mask

    # IFFT
    x_freq = torch.fft.ifftshift(x_freq, dim=(-2, -1))
    x_filtered = torch.fft.ifftn(x_freq, dim=(-2, -1)).real

    return x_filtered.to(x.dtype)


def patch_freeu_v2(unet_patcher, b1, b2, s1, s2):
    model_channels = unet_patcher.model.diffusion_model.config["model_channels"]
    scale_dict = {model_channels * 4: (b1, s1), model_channels * 2: (b2, s2)}
    on_cpu_devices = {}

    def output_block_patch(h, hsp, transformer_options):
        scale = scale_dict.get(h.shape[1], None)
        if scale is not None:
            hidden_mean = h.mean(1).unsqueeze(1)
            B = hidden_mean.shape[0]
            hidden_max, _ = torch.max(hidden_mean.view(B, -1), dim=-1, keepdim=True)
            hidden_min, _ = torch.min(hidden_mean.view(B, -1), dim=-1, keepdim=True)
            hidden_mean = (hidden_mean - hidden_min.unsqueeze(2).unsqueeze(3)) / (hidden_max - hidden_min).unsqueeze(2).unsqueeze(3)

            h[:, :h.shape[1] // 2] = h[:, :h.shape[1] // 2] * ((scale[0] - 1) * hidden_mean + 1)

            if hsp.device not in on_cpu_devices:
                try:
                    hsp = Fourier_filter(hsp, threshold=1, scale=scale[1])
                except:
                    print("Device", hsp.device, "does not support the torch.fft.")
                    on_cpu_devices[hsp.device] = True
                    hsp = Fourier_filter(hsp.cpu(), threshold=1, scale=scale[1]).to(hsp.device)
            else:
                hsp = Fourier_filter(hsp.cpu(), threshold=1, scale=scale[1]).to(hsp.device)

        return h, hsp

    m = unet_patcher.clone()
    m.set_model_output_block_patch(output_block_patch)
    return m


class FreeUForForge(scripts.Script):
    sorting_priority = 12  # It will be the 12th item on UI.

    def title(self):
        return "FreeU Integrated"

    def show(self, is_img2img):
        # make this extension visible in both txt2img and img2img tab.
        return scripts.AlwaysVisible

    def ui(self, *args, **kwargs):
        with gr.Accordion(open=False, label=self.title()):
            freeu_enabled = gr.Checkbox(label='Enabled', value=False)
            freeu_b1 = gr.Slider(label='B1', minimum=0, maximum=2, step=0.01, value=1.01)
            freeu_b2 = gr.Slider(label='B2', minimum=0, maximum=2, step=0.01, value=1.02)
            freeu_s1 = gr.Slider(label='S1', minimum=0, maximum=4, step=0.01, value=0.99)
            freeu_s2 = gr.Slider(label='S2', minimum=0, maximum=4, step=0.01, value=0.95)

        return freeu_enabled, freeu_b1, freeu_b2, freeu_s1, freeu_s2

    def process_before_every_sampling(self, p, *script_args, **kwargs):
        # This will be called before every sampling.
        # If you use highres fix, this will be called twice.

        freeu_enabled, freeu_b1, freeu_b2, freeu_s1, freeu_s2 = script_args

        if not freeu_enabled:
            return

        unet = p.sd_model.forge_objects.unet

        unet = patch_freeu_v2(unet, freeu_b1, freeu_b2, freeu_s1, freeu_s2)

        p.sd_model.forge_objects.unet = unet

        # Below codes will add some logs to the texts below the image outputs on UI.
        # The extra_generation_params does not influence results.
        p.extra_generation_params.update(dict(
            freeu_enabled=freeu_enabled,
            freeu_b1=freeu_b1,
            freeu_b2=freeu_b2,
            freeu_s1=freeu_s1,
            freeu_s2=freeu_s2,
        ))

        return
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See also &lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/raw/main/backend/nn/unet.py"&gt;Forge's Unet Implementation&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Under Construction&lt;/h1&gt; 
&lt;p&gt;WebUI Forge is now under some constructions, and docs / UI / functionality may change with updates.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>numpy/numpy</title>
      <link>https://github.com/numpy/numpy</link>
      <description>&lt;p&gt;The fundamental package for scientific computing with Python.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/numpy/numpy/main/branding/logo/primary/numpylogo.svg?sanitize=true" width="300" /&gt; &lt;/h1&gt;
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://numfocus.org"&gt;&lt;img src="https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&amp;amp;colorA=E1523D&amp;amp;colorB=007D8A" alt="Powered by NumFOCUS" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/numpy/"&gt;&lt;img src="https://img.shields.io/pypi/dm/numpy.svg?label=PyPI%20downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://anaconda.org/conda-forge/numpy"&gt;&lt;img src="https://img.shields.io/conda/dn/conda-forge/numpy.svg?label=Conda%20downloads" alt="Conda Downloads" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/numpy"&gt;&lt;img src="https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg?sanitize=true" alt="Stack Overflow" /&gt;&lt;/a&gt; &lt;a href="https://doi.org/10.1038/s41586-020-2649-2"&gt;&lt;img src="https://img.shields.io/badge/DOI-10.1038%2Fs41586--020--2649--2-blue" alt="Nature Paper" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/numpy"&gt;&lt;img src="https://insights.linuxfoundation.org/api/badge/health-score?project=numpy" alt="LFX Health Score" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/numpy/numpy"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/numpy/numpy/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/numpy/"&gt;&lt;img src="https://img.shields.io/pypi/types/numpy" alt="Typing" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;NumPy is the fundamental package for scientific computing with Python.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://numpy.org"&gt;https://numpy.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation:&lt;/strong&gt; &lt;a href="https://numpy.org/doc"&gt;https://numpy.org/doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mailing list:&lt;/strong&gt; &lt;a href="https://mail.python.org/mailman/listinfo/numpy-discussion"&gt;https://mail.python.org/mailman/listinfo/numpy-discussion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Source code:&lt;/strong&gt; &lt;a href="https://github.com/numpy/numpy"&gt;https://github.com/numpy/numpy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contributing:&lt;/strong&gt; &lt;a href="https://numpy.org/devdocs/dev/index.html"&gt;https://numpy.org/devdocs/dev/index.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug reports:&lt;/strong&gt; &lt;a href="https://github.com/numpy/numpy/issues"&gt;https://github.com/numpy/numpy/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Report a security vulnerability:&lt;/strong&gt; &lt;a href="https://tidelift.com/docs/security"&gt;https://tidelift.com/docs/security&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;It provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a powerful N-dimensional array object&lt;/li&gt; 
 &lt;li&gt;sophisticated (broadcasting) functions&lt;/li&gt; 
 &lt;li&gt;tools for integrating C/C++ and Fortran code&lt;/li&gt; 
 &lt;li&gt;useful linear algebra, Fourier transform, and random number capabilities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Testing:&lt;/p&gt; 
&lt;p&gt;NumPy requires &lt;code&gt;pytest&lt;/code&gt; and &lt;code&gt;hypothesis&lt;/code&gt;. Tests can then be run after installation with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -c "import numpy, sys; sys.exit(numpy.test() is False)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;NumPy is a community-driven open source project developed by a diverse group of &lt;a href="https://numpy.org/teams/"&gt;contributors&lt;/a&gt;. The NumPy leadership has made a strong commitment to creating an open, inclusive, and positive community. Please read the &lt;a href="https://numpy.org/code-of-conduct/"&gt;NumPy Code of Conduct&lt;/a&gt; for guidance on how to interact with others in a way that makes our community thrive.&lt;/p&gt; 
&lt;h2&gt;Call for Contributions&lt;/h2&gt; 
&lt;p&gt;The NumPy project welcomes your expertise and enthusiasm!&lt;/p&gt; 
&lt;p&gt;Small improvements or fixes are always appreciated. If you are considering larger contributions to the source code, please contact us through the &lt;a href="https://mail.python.org/mailman/listinfo/numpy-discussion"&gt;mailing list&lt;/a&gt; first.&lt;/p&gt; 
&lt;p&gt;Writing code isn‚Äôt the only way to contribute to NumPy. You can also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;review pull requests&lt;/li&gt; 
 &lt;li&gt;help us stay on top of new and old issues&lt;/li&gt; 
 &lt;li&gt;develop tutorials, presentations, and other educational materials&lt;/li&gt; 
 &lt;li&gt;maintain and improve &lt;a href="https://github.com/numpy/numpy.org"&gt;our website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;develop graphic design for our brand assets and promotional materials&lt;/li&gt; 
 &lt;li&gt;translate website content&lt;/li&gt; 
 &lt;li&gt;help with outreach and onboard new contributors&lt;/li&gt; 
 &lt;li&gt;write grant proposals and help with other fundraising efforts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the ways you can contribute to NumPy, visit &lt;a href="https://numpy.org/contribute/"&gt;our website&lt;/a&gt;. If you‚Äôre unsure where to start or how your skills fit in, reach out! You can ask on the mailing list or here, on GitHub, by opening a new issue or leaving a comment on a relevant issue that is already open.&lt;/p&gt; 
&lt;p&gt;Our preferred channels of communication are all public, but if you‚Äôd like to speak to us in private first, contact our community coordinators at &lt;a href="mailto:numpy-team@googlegroups.com"&gt;numpy-team@googlegroups.com&lt;/a&gt; or on Slack (write &lt;a href="mailto:numpy-team@googlegroups.com"&gt;numpy-team@googlegroups.com&lt;/a&gt; for an invitation).&lt;/p&gt; 
&lt;p&gt;We also have a biweekly community call, details of which are announced on the mailing list. You are very welcome to join.&lt;/p&gt; 
&lt;p&gt;If you are new to contributing to open source, &lt;a href="https://opensource.guide/how-to-contribute/"&gt;this guide&lt;/a&gt; helps explain why, what, and how to successfully get involved.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>swisskyrepo/PayloadsAllTheThings</title>
      <link>https://github.com/swisskyrepo/PayloadsAllTheThings</link>
      <description>&lt;p&gt;A list of useful payloads and bypass for Web Application Security and Pentest/CTF&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Payloads All The Things&lt;/h1&gt; 
&lt;p&gt;A list of useful payloads and bypasses for Web Application Security. Feel free to improve with your payloads and techniques!&lt;/p&gt; 
&lt;p&gt;You can also contribute with a &lt;span&gt;üçª&lt;/span&gt; IRL, or using the sponsor button.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/swisskyrepo"&gt;&lt;img src="https://img.shields.io/static/v1?label=Sponsor&amp;amp;message=%E2%9D%A4&amp;amp;logo=GitHub&amp;amp;link=https://github.com/sponsors/swisskyrepo" alt="Sponsor" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/tweet?text=Payloads%20All%20The%20Things,%20a%20list%20of%20useful%20payloads%20and%20bypasses%20for%20Web%20Application%20Security%20-%20by%20@pentest_swissky&amp;amp;url=https://github.com/swisskyrepo/PayloadsAllTheThings/"&gt;&lt;img src="https://img.shields.io/twitter/url/http/shields.io.svg?style=social" alt="Tweet" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An alternative display version is available at &lt;a href="https://swisskyrepo.github.io/PayloadsAllTheThings/"&gt;PayloadsAllTheThingsWeb&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/.github/banner.png" alt="banner" /&gt; &lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üìñ&lt;/span&gt; Documentation&lt;/h2&gt; 
&lt;p&gt;Every section contains the following files, you can use the &lt;code&gt;_template_vuln&lt;/code&gt; folder to create a new chapter:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;README.md - vulnerability description and how to exploit it, including several payloads&lt;/li&gt; 
 &lt;li&gt;Intruder - a set of files to give to Burp Intruder&lt;/li&gt; 
 &lt;li&gt;Images - pictures for the README.md&lt;/li&gt; 
 &lt;li&gt;Files - some files referenced in the README.md&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You might also like the other projects from the AllTheThings family :&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://swisskyrepo.github.io/InternalAllTheThings/"&gt;InternalAllTheThings&lt;/a&gt; - Active Directory and Internal Pentest Cheatsheets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swisskyrepo.github.io/HardwareAllTheThings/"&gt;HardwareAllTheThings&lt;/a&gt; - Hardware/IOT Pentesting Wiki&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You want more? Check the &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/raw/master/_LEARNING_AND_SOCIALS/BOOKS.md"&gt;Books&lt;/a&gt; and &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/raw/master/_LEARNING_AND_SOCIALS/YOUTUBE.md"&gt;YouTube channel&lt;/a&gt; selections.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üßëüíª&lt;/span&gt; Contributions&lt;/h2&gt; 
&lt;p&gt;Be sure to read &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/raw/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=swisskyrepo/PayloadsAllTheThings&amp;amp;max=36" alt="sponsors-list" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Thanks again for your contribution! &lt;span&gt;‚ù§Ô∏è&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üçª&lt;/span&gt; Sponsors&lt;/h2&gt; 
&lt;p&gt;This project is proudly sponsored by these companies.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Logo&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://serpapi.com"&gt;&lt;img src="https://avatars.githubusercontent.com/u/34724717?s=40&amp;amp;v=4" alt="sponsor-serpapi" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;SerpApi&lt;/strong&gt; is a real time API to access Google search results. It solves the issues of having to rent proxies, solving captchas, and JSON parsing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://projectdiscovery.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/50994705?s=40&amp;amp;v=4" alt="sponsor-projectdiscovery" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ProjectDiscovery&lt;/strong&gt; - Detect real, exploitable vulnerabilities. Harness the power of Nuclei for fast and accurate findings without false positives.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.vaadata.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/48131541?s=40&amp;amp;v=4" alt="sponsor-vaadata" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;VAADATA&lt;/strong&gt; - Ethical Hacking Services&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>MODSetter/SurfSense</title>
      <link>https://github.com/MODSetter/SurfSense</link>
      <description>&lt;p&gt;Open source alternative to NotebookLM, Perplexity, and Glean. Connects to search engines, Slack, Linear, Jira, ClickUp, Notion, YouTube, GitHub, Discord, and more. Join our Discord: https://discord.gg/ejRNvftDp9&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e236b764-0ddc-42ff-a1f1-8fbb3d2e0e65" alt="new_header" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://discord.gg/ejRNvftDp9"&gt; &lt;img src="https://img.shields.io/discord/1359368468260192417" alt="Discord" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/MODSetter/SurfSense/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/MODSetter/SurfSense/main/README.zh-CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;SurfSense&lt;/h1&gt; 
&lt;p&gt;While tools like NotebookLM and Perplexity are impressive and highly effective for conducting research on any topic/query, SurfSense elevates this capability by integrating with your personal knowledge base. It is a highly customizable AI research agent, connected to external sources such as Search Engines (SearxNG, Tavily, LinkUp), Slack, Linear, Jira, ClickUp, Confluence, BookStack, Gmail, Notion, YouTube, GitHub, Discord, Airtable, Google Calendar, Luma, Elasticsearch and more to come.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13606" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13606" alt="MODSetter%2FSurfSense | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;Video&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/d9221908-e0de-4b2f-ac3a-691cf4b202da"&gt;https://github.com/user-attachments/assets/d9221908-e0de-4b2f-ac3a-691cf4b202da&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Podcast Sample&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/a0a16566-6967-4374-ac51-9b3e07fbecd7"&gt;https://github.com/user-attachments/assets/a0a16566-6967-4374-ac51-9b3e07fbecd7&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;üí° &lt;strong&gt;Idea&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have your own highly customizable private NotebookLM and Perplexity integrated with external sources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìÅ &lt;strong&gt;Multiple File Format Uploading Support&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Save content from your own personal files &lt;em&gt;(Documents, images, videos and supports &lt;strong&gt;50+ file extensions&lt;/strong&gt;)&lt;/em&gt; to your own personal knowledge base .&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîç &lt;strong&gt;Powerful Search&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Quickly research or find anything in your saved content .&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üí¨ &lt;strong&gt;Chat with your Saved Content&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interact in Natural Language and get cited answers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìÑ &lt;strong&gt;Cited Answers&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Get Cited answers just like Perplexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîî &lt;strong&gt;Privacy &amp;amp; Local LLM Support&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Works Flawlessly with Ollama local LLMs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üè† &lt;strong&gt;Self Hostable&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open source and easy to deploy locally.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üë• &lt;strong&gt;Team Collaboration with RBAC&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Role-Based Access Control for Search Spaces&lt;/li&gt; 
 &lt;li&gt;Invite team members with customizable roles (Owner, Admin, Editor, Viewer)&lt;/li&gt; 
 &lt;li&gt;Granular permissions for documents, chats, connectors, and settings&lt;/li&gt; 
 &lt;li&gt;Share knowledge bases securely within your organization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéôÔ∏è Podcasts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blazingly fast podcast generation agent. (Creates a 3-minute podcast in under 20 seconds.)&lt;/li&gt; 
 &lt;li&gt;Convert your chat conversations into engaging audio content&lt;/li&gt; 
 &lt;li&gt;Support for local TTS providers (Kokoro TTS)&lt;/li&gt; 
 &lt;li&gt;Support for multiple TTS providers (OpenAI, Azure, Google Vertex AI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìä &lt;strong&gt;Advanced RAG Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports 100+ LLM's&lt;/li&gt; 
 &lt;li&gt;Supports 6000+ Embedding Models.&lt;/li&gt; 
 &lt;li&gt;Supports all major Rerankers (Pinecode, Cohere, Flashrank etc)&lt;/li&gt; 
 &lt;li&gt;Uses Hierarchical Indices (2 tiered RAG setup).&lt;/li&gt; 
 &lt;li&gt;Utilizes Hybrid Search (Semantic + Full Text Search combined with Reciprocal Rank Fusion).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚ÑπÔ∏è &lt;strong&gt;External Sources&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Search Engines (Tavily, LinkUp)&lt;/li&gt; 
 &lt;li&gt;SearxNG (self-hosted instances)&lt;/li&gt; 
 &lt;li&gt;Slack&lt;/li&gt; 
 &lt;li&gt;Linear&lt;/li&gt; 
 &lt;li&gt;Jira&lt;/li&gt; 
 &lt;li&gt;ClickUp&lt;/li&gt; 
 &lt;li&gt;Confluence&lt;/li&gt; 
 &lt;li&gt;BookStack&lt;/li&gt; 
 &lt;li&gt;Notion&lt;/li&gt; 
 &lt;li&gt;Gmail&lt;/li&gt; 
 &lt;li&gt;Youtube Videos&lt;/li&gt; 
 &lt;li&gt;GitHub&lt;/li&gt; 
 &lt;li&gt;Discord&lt;/li&gt; 
 &lt;li&gt;Airtable&lt;/li&gt; 
 &lt;li&gt;Google Calendar&lt;/li&gt; 
 &lt;li&gt;Luma&lt;/li&gt; 
 &lt;li&gt;Elasticsearch&lt;/li&gt; 
 &lt;li&gt;and more to come.....&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ &lt;strong&gt;Supported File Extensions&lt;/strong&gt;&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ETL Service&lt;/th&gt; 
   &lt;th&gt;Formats&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LlamaCloud&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;50+ formats&lt;/td&gt; 
   &lt;td&gt;Documents, presentations, spreadsheets, images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;34+ formats&lt;/td&gt; 
   &lt;td&gt;Core formats + email support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Docling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Core formats&lt;/td&gt; 
   &lt;td&gt;Local processing, no API key required&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Audio/Video&lt;/strong&gt; (via STT Service): &lt;code&gt;.mp3&lt;/code&gt;, &lt;code&gt;.wav&lt;/code&gt;, &lt;code&gt;.mp4&lt;/code&gt;, &lt;code&gt;.webm&lt;/code&gt;, etc.&lt;/p&gt; 
&lt;h3&gt;üîñ Cross Browser Extension&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The SurfSense extension can be used to save any webpage you like.&lt;/li&gt; 
 &lt;li&gt;Its main usecase is to save any webpages protected beyond authentication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FEATURE REQUESTS AND FUTURE&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;SurfSense is actively being developed.&lt;/strong&gt; While it's not yet production-ready, you can help us speed up the process.&lt;/p&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.gg/ejRNvftDp9"&gt;SurfSense Discord&lt;/a&gt; and help shape the future of SurfSense!&lt;/p&gt; 
&lt;h2&gt;üöÄ Roadmap&lt;/h2&gt; 
&lt;p&gt;Stay up to date with our development progress and upcoming features!&lt;br /&gt; Check out our public roadmap and contribute your ideas or feedback:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üìã Roadmap Discussion:&lt;/strong&gt; &lt;a href="https://github.com/MODSetter/SurfSense/discussions/565"&gt;SurfSense 2025-2026 Roadmap: Deep Agents, Real-Time Collaboration &amp;amp; MCP Servers&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üìä Kanban Board:&lt;/strong&gt; &lt;a href="https://github.com/users/MODSetter/projects/3"&gt;SurfSense Project Board&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;How to get started?&lt;/h2&gt; 
&lt;h3&gt;Quick Start with Docker üê≥&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] For production deployments, use the full &lt;a href="https://www.surfsense.com/docs/docker-installation"&gt;Docker Compose setup&lt;/a&gt; which offers more control and scalability.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Linux/macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 3000:3000 -p 8000:8000 \
  -v surfsense-data:/data \
  --name surfsense \
  --restart unless-stopped \
  ghcr.io/modsetter/surfsense:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows (PowerShell):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker run -d -p 3000:3000 -p 8000:8000 `
  -v surfsense-data:/data `
  --name surfsense `
  --restart unless-stopped `
  ghcr.io/modsetter/surfsense:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;With Custom Configuration (e.g., OpenAI Embeddings):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 3000:3000 -p 8000:8000 \
  -v surfsense-data:/data \
  -e EMBEDDING_MODEL=openai://text-embedding-ada-002 \
  -e OPENAI_API_KEY=your_openai_api_key \
  --name surfsense \
  --restart unless-stopped \
  ghcr.io/modsetter/surfsense:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After starting, access SurfSense at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backend API&lt;/strong&gt;: &lt;a href="http://localhost:8000"&gt;http://localhost:8000&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Docs&lt;/strong&gt;: &lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Useful Commands:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker logs -f surfsense      # View logs
docker stop surfsense         # Stop
docker start surfsense        # Start
docker rm surfsense           # Remove (data preserved in volume)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installation Options&lt;/h3&gt; 
&lt;p&gt;SurfSense provides multiple options to get started:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.surfsense.com/login"&gt;SurfSense Cloud&lt;/a&gt;&lt;/strong&gt; - The easiest way to try SurfSense without any setup.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;No installation required&lt;/li&gt; 
   &lt;li&gt;Instant access to all features&lt;/li&gt; 
   &lt;li&gt;Perfect for getting started quickly&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Quick Start Docker (Above)&lt;/strong&gt; - Single command to get SurfSense running locally.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;All-in-one image with PostgreSQL, Redis, and all services bundled&lt;/li&gt; 
   &lt;li&gt;Perfect for evaluation, development, and small deployments&lt;/li&gt; 
   &lt;li&gt;Data persisted via Docker volume&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.surfsense.com/docs/docker-installation"&gt;Docker Compose (Production)&lt;/a&gt;&lt;/strong&gt; - Full stack deployment with separate services.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Includes pgAdmin for database management through a web UI&lt;/li&gt; 
   &lt;li&gt;Supports environment variable customization via &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
   &lt;li&gt;Flexible deployment options (full stack or core services only)&lt;/li&gt; 
   &lt;li&gt;Better for production with separate scaling of services&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.surfsense.com/docs/manual-installation"&gt;Manual Installation&lt;/a&gt;&lt;/strong&gt; - For users who prefer more control over their setup or need to customize their deployment.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Docker and manual installation guides include detailed OS-specific instructions for Windows, macOS, and Linux.&lt;/p&gt; 
&lt;p&gt;Before self-hosting installation, make sure to complete the &lt;a href="https://www.surfsense.com/docs/"&gt;prerequisite setup steps&lt;/a&gt; including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Auth setup (optional - defaults to LOCAL auth)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Processing ETL Service&lt;/strong&gt; (optional - defaults to Docling): 
  &lt;ul&gt; 
   &lt;li&gt;Docling (default, local processing, no API key required, supports PDF, Office docs, images, HTML, CSV)&lt;/li&gt; 
   &lt;li&gt;Unstructured.io API key (supports 34+ formats)&lt;/li&gt; 
   &lt;li&gt;LlamaIndex API key (enhanced parsing, supports 50+ formats)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Other API keys as needed for your use case&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Research Agent&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e22c5d86-f511-4c72-8c50-feba0c1561b4" alt="updated_researcher" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Search Spaces&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e254c38c-f937-44b6-9e9d-770db583d099" alt="search_spaces" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Manage Documents&lt;/strong&gt; &lt;img src="https://github.com/user-attachments/assets/7001e306-eb06-4009-89c6-8fadfdc3fc4d" alt="documents" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Podcast Agent&lt;/strong&gt; &lt;img src="https://github.com/user-attachments/assets/6cb82ffd-9e14-4172-bc79-67faf34c4c1c" alt="podcasts" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Chat&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/bb352d52-1c6d-4020-926b-722d0b98b491" alt="git_chat" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Browser Extension&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/1f042b7a-6349-422b-94fb-d40d0df16c40" alt="ext1" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/a9b9f1aa-2677-404d-b0a0-c1b2dddf24a7" alt="ext2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;BackEnd&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;: Modern, fast web framework for building APIs with Python&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PostgreSQL with pgvector&lt;/strong&gt;: Database with vector search capabilities for similarity searches&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SQLAlchemy&lt;/strong&gt;: SQL toolkit and ORM (Object-Relational Mapping) for database interactions&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alembic&lt;/strong&gt;: A database migrations tool for SQLAlchemy.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FastAPI Users&lt;/strong&gt;: Authentication and user management with JWT and OAuth support&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LangGraph&lt;/strong&gt;: Framework for developing AI-agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: Framework for developing AI-powered applications.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LLM Integration&lt;/strong&gt;: Integration with LLM models through LiteLLM&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rerankers&lt;/strong&gt;: Advanced result ranking for improved search relevance&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hybrid Search&lt;/strong&gt;: Combines vector similarity and full-text search for optimal results using Reciprocal Rank Fusion (RRF)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vector Embeddings&lt;/strong&gt;: Document and text embeddings for semantic search&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pgvector&lt;/strong&gt;: PostgreSQL extension for efficient vector similarity operations&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Redis&lt;/strong&gt;: In-memory data structure store used as message broker and result backend for Celery&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Celery&lt;/strong&gt;: Distributed task queue for handling asynchronous background jobs (document processing, podcast generation, etc.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flower&lt;/strong&gt;: Real-time monitoring and administration tool for Celery task queues&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Chonkie&lt;/strong&gt;: Advanced document chunking and embedding library&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Uses &lt;code&gt;AutoEmbeddings&lt;/code&gt; for flexible embedding model selection&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;LateChunker&lt;/code&gt; for optimized document chunking based on embedding model's max sequence length&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;strong&gt;FrontEnd&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Next.js 15.2.3&lt;/strong&gt;: React framework featuring App Router, server components, automatic code-splitting, and optimized rendering.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;React 19.0.0&lt;/strong&gt;: JavaScript library for building user interfaces.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;: Static type-checking for JavaScript, enhancing code quality and developer experience.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vercel AI SDK Kit UI Stream Protocol&lt;/strong&gt;: To create scalable chat UI.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tailwind CSS 4.x&lt;/strong&gt;: Utility-first CSS framework for building custom UI designs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Shadcn&lt;/strong&gt;: Headless components library.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Lucide React&lt;/strong&gt;: Icon set implemented as React components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Framer Motion&lt;/strong&gt;: Animation library for React.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Sonner&lt;/strong&gt;: Toast notification library.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Geist&lt;/strong&gt;: Font family from Vercel.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;React Hook Form&lt;/strong&gt;: Form state management and validation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Zod&lt;/strong&gt;: TypeScript-first schema validation with static type inference.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;@hookform/resolvers&lt;/strong&gt;: Resolvers for using validation libraries with React Hook Form.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;@tanstack/react-table&lt;/strong&gt;: Headless UI for building powerful tables &amp;amp; datagrids.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;DevOps&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Container platform for consistent deployment across environments&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;: Tool for defining and running multi-container Docker applications&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pgAdmin&lt;/strong&gt;: Web-based PostgreSQL administration tool included in Docker setup&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Extension&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Manifest v3 on Plasmo&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;Contributions are very welcome! A contribution can be as small as a ‚≠ê or even finding and creating issues. Fine-tuning the Backend is always desired.&lt;/p&gt; 
&lt;p&gt;For detailed contribution guidelines, please see our &lt;a href="https://raw.githubusercontent.com/MODSetter/SurfSense/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#MODSetter/SurfSense&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/329c9bc2-6005-4aed-a629-700b5ae296b4" alt="Catalyst Project" width="200" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;hr /&gt;</description>
    </item>
    
    <item>
      <title>unclecode/crawl4ai</title>
      <link>https://github.com/unclecode/crawl4ai</link>
      <description>&lt;p&gt;üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler &amp;amp; Scraper.&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11716" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11716" alt="unclecode%2Fcrawl4ai | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/unclecode/crawl4ai/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/unclecode/crawl4ai?style=social" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/unclecode/crawl4ai/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/unclecode/crawl4ai?style=social" alt="GitHub Forks" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/crawl4ai"&gt;&lt;img src="https://badge.fury.io/py/crawl4ai.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/crawl4ai/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/crawl4ai" alt="Python Version" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/crawl4ai"&gt;&lt;img src="https://static.pepy.tech/badge/crawl4ai/month" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/unclecode"&gt;&lt;img src="https://img.shields.io/github/sponsors/unclecode?style=flat&amp;amp;logo=GitHub-Sponsors&amp;amp;label=Sponsors&amp;amp;color=pink" alt="GitHub Sponsors" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h4&gt;üöÄ Crawl4AI Cloud API ‚Äî Closed Beta (Launching Soon)&lt;/h4&gt; 
 &lt;p&gt;Reliable, large-scale web extraction, now built to be &lt;em&gt;&lt;strong&gt;drastically more cost-effective&lt;/strong&gt;&lt;/em&gt; than any of the existing solutions.&lt;/p&gt; 
 &lt;p&gt;üëâ &lt;strong&gt;Apply &lt;a href="https://forms.gle/E9MyPaNXACnAMaqG7"&gt;here&lt;/a&gt; for early access&lt;/strong&gt;&lt;br /&gt; &lt;em&gt;We‚Äôll be onboarding in phases and working closely with early users. Limited slots.&lt;/em&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p align="center"&gt; &lt;a href="https://x.com/crawl4ai"&gt; &lt;img src="https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Follow on X" /&gt; &lt;/a&gt; &lt;a href="https://www.linkedin.com/company/crawl4ai"&gt; &lt;img src="https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="Follow on LinkedIn" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/jP8KfhDhyN"&gt; &lt;img src="https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Join our Discord" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Crawl4AI turns the web into clean, LLM ready Markdown for RAG, agents, and data pipelines. Fast, controllable, battle tested by a 50k+ star community.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/unclecode/crawl4ai/main/#-recent-updates"&gt;‚ú® Check out latest update v0.7.8&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‚ú® &lt;strong&gt;New in v0.7.8&lt;/strong&gt;: Stability &amp;amp; Bug Fix Release! 11 bug fixes addressing Docker API issues (ContentRelevanceFilter, ProxyConfig, cache permissions), LLM extraction improvements (configurable backoff, HTML input format), URL handling fixes, and dependency updates (pypdf, Pydantic v2). &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/blog/release-v0.7.8.md"&gt;Release notes ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‚ú® Recent v0.7.7: Complete Self-Hosting Platform with Real-time Monitoring! Enterprise-grade monitoring dashboard, comprehensive REST API, WebSocket streaming, smart browser pool management, and production-ready observability. &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/blog/release-v0.7.7.md"&gt;Release notes ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‚ú® Previous v0.7.6: Complete Webhook Infrastructure for Docker Job Queue API! Real-time notifications for both &lt;code&gt;/crawl/job&lt;/code&gt; and &lt;code&gt;/llm/job&lt;/code&gt; endpoints with exponential backoff retry, custom headers, and flexible delivery modes. &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/blog/release-v0.7.6.md"&gt;Release notes ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;ü§ì &lt;strong&gt;My Personal Story&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;I grew up on an Amstrad, thanks to my dad, and never stopped building. In grad school I specialized in NLP and built crawlers for research. That‚Äôs where I learned how much extraction matters.&lt;/p&gt; 
 &lt;p&gt;In 2023, I needed web-to-Markdown. The ‚Äúopen source‚Äù option wanted an account, API token, and $16, and still under-delivered. I went turbo anger mode, built Crawl4AI in days, and it went viral. Now it‚Äôs the most-starred crawler on GitHub.&lt;/p&gt; 
 &lt;p&gt;I made it open source for &lt;strong&gt;availability&lt;/strong&gt;, anyone can use it without a gate. Now I‚Äôm building the platform for &lt;strong&gt;affordability&lt;/strong&gt;, anyone can run serious crawls without breaking the bank. If that resonates, join in, send feedback, or just crawl something amazing.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Why developers pick Crawl4AI&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;LLM ready output&lt;/strong&gt;, smart Markdown with headings, tables, code, citation hints&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Fast in practice&lt;/strong&gt;, async browser pool, caching, minimal hops&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Full control&lt;/strong&gt;, sessions, proxies, cookies, user scripts, hooks&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Adaptive intelligence&lt;/strong&gt;, learns site patterns, explores only what matters&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Deploy anywhere&lt;/strong&gt;, zero keys, CLI and Docker, cloud friendly&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Crawl4AI:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install the package
pip install -U crawl4ai

# For pre release versions
pip install crawl4ai --pre

# Run post-installation setup
crawl4ai-setup

# Verify your installation
crawl4ai-doctor
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you encounter any browser-related issues, you can install them manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m playwright install --with-deps chromium
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run a simple web crawl with Python:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from crawl4ai import *

async def main():
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://www.nbcnews.com/business",
        )
        print(result.markdown)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Or use the new command-line interface:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic crawl with markdown output
crwl https://www.nbcnews.com/business -o markdown

# Deep crawl with BFS strategy, max 10 pages
crwl https://docs.crawl4ai.com --deep-crawl bfs --max-pages 10

# Use LLM extraction with a specific question
crwl https://www.example.com/products -q "Extract all product prices"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üíñ Support Crawl4AI&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üéâ &lt;strong&gt;Sponsorship Program Now Open!&lt;/strong&gt; After powering 51K+ developers and 1 year of growth, Crawl4AI is launching dedicated support for &lt;strong&gt;startups&lt;/strong&gt; and &lt;strong&gt;enterprises&lt;/strong&gt;. Be among the first 50 &lt;strong&gt;Founding Sponsors&lt;/strong&gt; for permanent recognition in our Hall of Fame.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Crawl4AI is the #1 trending open-source web crawler on GitHub. Your support keeps it independent, innovative, and free for the community ‚Äî while giving you direct access to premium benefits.&lt;/p&gt; 
&lt;div align=""&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sponsors/unclecode"&gt;&lt;img src="https://img.shields.io/badge/Become%20a%20Sponsor-pink?style=for-the-badge&amp;amp;logo=github-sponsors&amp;amp;logoColor=white" alt="Become a Sponsor" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/sponsors/unclecode"&gt;&lt;img src="https://img.shields.io/github/sponsors/unclecode?style=for-the-badge&amp;amp;logo=github&amp;amp;label=Current%20Sponsors&amp;amp;color=green" alt="Current Sponsors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;ü§ù Sponsorship Tiers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üå± Believer ($5/mo)&lt;/strong&gt; ‚Äî Join the movement for data democratization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üöÄ Builder ($50/mo)&lt;/strong&gt; ‚Äî Priority support &amp;amp; early access to features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíº Growing Team ($500/mo)&lt;/strong&gt; ‚Äî Bi-weekly syncs &amp;amp; optimization help&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üè¢ Data Infrastructure Partner ($2000/mo)&lt;/strong&gt; ‚Äî Full partnership with dedicated support&lt;br /&gt; &lt;em&gt;Custom arrangements available - see &lt;a href="https://raw.githubusercontent.com/unclecode/crawl4ai/main/SPONSORS.md"&gt;SPONSORS.md&lt;/a&gt; for details &amp;amp; contact&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Why sponsor?&lt;/strong&gt;&lt;br /&gt; No rate-limited APIs. No lock-in. Build and own your data pipeline with direct guidance from the creator of Crawl4AI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/unclecode"&gt;See All Tiers &amp;amp; Benefits ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìù &lt;strong&gt;Markdown Generation&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üßπ &lt;strong&gt;Clean Markdown&lt;/strong&gt;: Generates clean, structured Markdown with accurate formatting.&lt;/li&gt; 
  &lt;li&gt;üéØ &lt;strong&gt;Fit Markdown&lt;/strong&gt;: Heuristic-based filtering to remove noise and irrelevant parts for AI-friendly processing.&lt;/li&gt; 
  &lt;li&gt;üîó &lt;strong&gt;Citations and References&lt;/strong&gt;: Converts page links into a numbered reference list with clean citations.&lt;/li&gt; 
  &lt;li&gt;üõ†Ô∏è &lt;strong&gt;Custom Strategies&lt;/strong&gt;: Users can create their own Markdown generation strategies tailored to specific needs.&lt;/li&gt; 
  &lt;li&gt;üìö &lt;strong&gt;BM25 Algorithm&lt;/strong&gt;: Employs BM25-based filtering for extracting core information and removing irrelevant content.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìä &lt;strong&gt;Structured Data Extraction&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ü§ñ &lt;strong&gt;LLM-Driven Extraction&lt;/strong&gt;: Supports all LLMs (open-source and proprietary) for structured data extraction.&lt;/li&gt; 
  &lt;li&gt;üß± &lt;strong&gt;Chunking Strategies&lt;/strong&gt;: Implements chunking (topic-based, regex, sentence-level) for targeted content processing.&lt;/li&gt; 
  &lt;li&gt;üåå &lt;strong&gt;Cosine Similarity&lt;/strong&gt;: Find relevant content chunks based on user queries for semantic extraction.&lt;/li&gt; 
  &lt;li&gt;üîé &lt;strong&gt;CSS-Based Extraction&lt;/strong&gt;: Fast schema-based data extraction using XPath and CSS selectors.&lt;/li&gt; 
  &lt;li&gt;üîß &lt;strong&gt;Schema Definition&lt;/strong&gt;: Define custom schemas for extracting structured JSON from repetitive patterns.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üåê &lt;strong&gt;Browser Integration&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üñ•Ô∏è &lt;strong&gt;Managed Browser&lt;/strong&gt;: Use user-owned browsers with full control, avoiding bot detection.&lt;/li&gt; 
  &lt;li&gt;üîÑ &lt;strong&gt;Remote Browser Control&lt;/strong&gt;: Connect to Chrome Developer Tools Protocol for remote, large-scale data extraction.&lt;/li&gt; 
  &lt;li&gt;üë§ &lt;strong&gt;Browser Profiler&lt;/strong&gt;: Create and manage persistent profiles with saved authentication states, cookies, and settings.&lt;/li&gt; 
  &lt;li&gt;üîí &lt;strong&gt;Session Management&lt;/strong&gt;: Preserve browser states and reuse them for multi-step crawling.&lt;/li&gt; 
  &lt;li&gt;üß© &lt;strong&gt;Proxy Support&lt;/strong&gt;: Seamlessly connect to proxies with authentication for secure access.&lt;/li&gt; 
  &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Full Browser Control&lt;/strong&gt;: Modify headers, cookies, user agents, and more for tailored crawling setups.&lt;/li&gt; 
  &lt;li&gt;üåç &lt;strong&gt;Multi-Browser Support&lt;/strong&gt;: Compatible with Chromium, Firefox, and WebKit.&lt;/li&gt; 
  &lt;li&gt;üìê &lt;strong&gt;Dynamic Viewport Adjustment&lt;/strong&gt;: Automatically adjusts the browser viewport to match page content, ensuring complete rendering and capturing of all elements.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîé &lt;strong&gt;Crawling &amp;amp; Scraping&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üñºÔ∏è &lt;strong&gt;Media Support&lt;/strong&gt;: Extract images, audio, videos, and responsive image formats like &lt;code&gt;srcset&lt;/code&gt; and &lt;code&gt;picture&lt;/code&gt;.&lt;/li&gt; 
  &lt;li&gt;üöÄ &lt;strong&gt;Dynamic Crawling&lt;/strong&gt;: Execute JS and wait for async or sync for dynamic content extraction.&lt;/li&gt; 
  &lt;li&gt;üì∏ &lt;strong&gt;Screenshots&lt;/strong&gt;: Capture page screenshots during crawling for debugging or analysis.&lt;/li&gt; 
  &lt;li&gt;üìÇ &lt;strong&gt;Raw Data Crawling&lt;/strong&gt;: Directly process raw HTML (&lt;code&gt;raw:&lt;/code&gt;) or local files (&lt;code&gt;file://&lt;/code&gt;).&lt;/li&gt; 
  &lt;li&gt;üîó &lt;strong&gt;Comprehensive Link Extraction&lt;/strong&gt;: Extracts internal, external links, and embedded iframe content.&lt;/li&gt; 
  &lt;li&gt;üõ†Ô∏è &lt;strong&gt;Customizable Hooks&lt;/strong&gt;: Define hooks at every step to customize crawling behavior (supports both string and function-based APIs).&lt;/li&gt; 
  &lt;li&gt;üíæ &lt;strong&gt;Caching&lt;/strong&gt;: Cache data for improved speed and to avoid redundant fetches.&lt;/li&gt; 
  &lt;li&gt;üìÑ &lt;strong&gt;Metadata Extraction&lt;/strong&gt;: Retrieve structured metadata from web pages.&lt;/li&gt; 
  &lt;li&gt;üì° &lt;strong&gt;IFrame Content Extraction&lt;/strong&gt;: Seamless extraction from embedded iframe content.&lt;/li&gt; 
  &lt;li&gt;üïµÔ∏è &lt;strong&gt;Lazy Load Handling&lt;/strong&gt;: Waits for images to fully load, ensuring no content is missed due to lazy loading.&lt;/li&gt; 
  &lt;li&gt;üîÑ &lt;strong&gt;Full-Page Scanning&lt;/strong&gt;: Simulates scrolling to load and capture all dynamic content, perfect for infinite scroll pages.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üöÄ &lt;strong&gt;Deployment&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üê≥ &lt;strong&gt;Dockerized Setup&lt;/strong&gt;: Optimized Docker image with FastAPI server for easy deployment.&lt;/li&gt; 
  &lt;li&gt;üîë &lt;strong&gt;Secure Authentication&lt;/strong&gt;: Built-in JWT token authentication for API security.&lt;/li&gt; 
  &lt;li&gt;üîÑ &lt;strong&gt;API Gateway&lt;/strong&gt;: One-click deployment with secure token authentication for API-based workflows.&lt;/li&gt; 
  &lt;li&gt;üåê &lt;strong&gt;Scalable Architecture&lt;/strong&gt;: Designed for mass-scale production and optimized server performance.&lt;/li&gt; 
  &lt;li&gt;‚òÅÔ∏è &lt;strong&gt;Cloud Deployment&lt;/strong&gt;: Ready-to-deploy configurations for major cloud platforms.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üéØ &lt;strong&gt;Additional Features&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üï∂Ô∏è &lt;strong&gt;Stealth Mode&lt;/strong&gt;: Avoid bot detection by mimicking real users.&lt;/li&gt; 
  &lt;li&gt;üè∑Ô∏è &lt;strong&gt;Tag-Based Content Extraction&lt;/strong&gt;: Refine crawling based on custom tags, headers, or metadata.&lt;/li&gt; 
  &lt;li&gt;üîó &lt;strong&gt;Link Analysis&lt;/strong&gt;: Extract and analyze all links for detailed data exploration.&lt;/li&gt; 
  &lt;li&gt;üõ°Ô∏è &lt;strong&gt;Error Handling&lt;/strong&gt;: Robust error management for seamless execution.&lt;/li&gt; 
  &lt;li&gt;üîê &lt;strong&gt;CORS &amp;amp; Static Serving&lt;/strong&gt;: Supports filesystem-based caching and cross-origin requests.&lt;/li&gt; 
  &lt;li&gt;üìñ &lt;strong&gt;Clear Documentation&lt;/strong&gt;: Simplified and updated guides for onboarding and advanced usage.&lt;/li&gt; 
  &lt;li&gt;üôå &lt;strong&gt;Community Recognition&lt;/strong&gt;: Acknowledges contributors and pull requests for transparency.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Try it Now!&lt;/h2&gt; 
&lt;p&gt;‚ú® Play around with this &lt;a href="https://colab.research.google.com/drive/1SgRPrByQLzjRfwoRNq1wSGE9nYY_EE8C?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‚ú® Visit our &lt;a href="https://docs.crawl4ai.com/"&gt;Documentation Website&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation üõ†Ô∏è&lt;/h2&gt; 
&lt;p&gt;Crawl4AI offers flexible installation options to suit various use cases. You can install it as a Python package or use Docker.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;üêç &lt;strong&gt;Using pip&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Choose the installation option that best fits your needs:&lt;/p&gt; 
 &lt;h3&gt;Basic Installation&lt;/h3&gt; 
 &lt;p&gt;For basic web crawling and scraping tasks:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install crawl4ai
crawl4ai-setup # Setup the browser
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;By default, this will install the asynchronous version of Crawl4AI, using Playwright for web crawling.&lt;/p&gt; 
 &lt;p&gt;üëâ &lt;strong&gt;Note&lt;/strong&gt;: When you install Crawl4AI, the &lt;code&gt;crawl4ai-setup&lt;/code&gt; should automatically install and set up Playwright. However, if you encounter any Playwright-related errors, you can manually install it using one of these methods:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Through the command line:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;playwright install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;If the above doesn't work, try this more specific command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m playwright install chromium
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;This second method has proven to be more reliable in some cases.&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;Installation with Synchronous Version&lt;/h3&gt; 
 &lt;p&gt;The sync version is deprecated and will be removed in future versions. If you need the synchronous version using Selenium:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install crawl4ai[sync]
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;Development Installation&lt;/h3&gt; 
 &lt;p&gt;For contributors who plan to modify the source code:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/unclecode/crawl4ai.git
cd crawl4ai
pip install -e .                    # Basic installation in editable mode
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Install optional features:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e ".[torch]"           # With PyTorch features
pip install -e ".[transformer]"     # With Transformer features
pip install -e ".[cosine]"          # With cosine similarity features
pip install -e ".[sync]"            # With synchronous crawling (Selenium)
pip install -e ".[all]"             # Install all optional features
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üê≥ &lt;strong&gt;Docker Deployment&lt;/strong&gt;&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;üöÄ &lt;strong&gt;Now Available!&lt;/strong&gt; Our completely redesigned Docker implementation is here! This new solution makes deployment more efficient and seamless than ever.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;New Docker Features&lt;/h3&gt; 
 &lt;p&gt;The new Docker implementation includes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Real-time Monitoring Dashboard&lt;/strong&gt; with live system metrics and browser pool visibility&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Browser pooling&lt;/strong&gt; with page pre-warming for faster response times&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Interactive playground&lt;/strong&gt; to test and generate request code&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;MCP integration&lt;/strong&gt; for direct connection to AI tools like Claude Code&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Comprehensive API endpoints&lt;/strong&gt; including HTML extraction, screenshots, PDF generation, and JavaScript execution&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Multi-architecture support&lt;/strong&gt; with automatic detection (AMD64/ARM64)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Optimized resources&lt;/strong&gt; with improved memory management&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Getting Started&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Pull and run the latest release
docker pull unclecode/crawl4ai:latest
docker run -d -p 11235:11235 --name crawl4ai --shm-size=1g unclecode/crawl4ai:latest

# Visit the monitoring dashboard at http://localhost:11235/dashboard
# Or the playground at http://localhost:11235/playground
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Quick Test&lt;/h3&gt; 
 &lt;p&gt;Run a quick test (works for both Docker options):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import requests

# Submit a crawl job
response = requests.post(
    "http://localhost:11235/crawl",
    json={"urls": ["https://example.com"], "priority": 10}
)
if response.status_code == 200:
    print("Crawl job submitted successfully.")
    
if "results" in response.json():
    results = response.json()["results"]
    print("Crawl job completed. Results:")
    for result in results:
        print(result)
else:
    task_id = response.json()["task_id"]
    print(f"Crawl job submitted. Task ID:: {task_id}")
    result = requests.get(f"http://localhost:11235/task/{task_id}")
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For more examples, see our &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/examples/docker_example.py"&gt;Docker Examples&lt;/a&gt;. For advanced configuration, monitoring features, and production deployment, see our &lt;a href="https://docs.crawl4ai.com/core/self-hosting/"&gt;Self-Hosting Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üî¨ Advanced Usage Examples üî¨&lt;/h2&gt; 
&lt;p&gt;You can check the project structure in the directory &lt;a href="https://github.com/unclecode/crawl4ai/tree/main/docs/examples"&gt;docs/examples&lt;/a&gt;. Over there, you can find a variety of examples; here, some popular examples are shared.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìù &lt;strong&gt;Heuristic Markdown Generation with Clean and Fit Markdown&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai.content_filter_strategy import PruningContentFilter, BM25ContentFilter
from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator

async def main():
    browser_config = BrowserConfig(
        headless=True,  
        verbose=True,
    )
    run_config = CrawlerRunConfig(
        cache_mode=CacheMode.ENABLED,
        markdown_generator=DefaultMarkdownGenerator(
            content_filter=PruningContentFilter(threshold=0.48, threshold_type="fixed", min_word_threshold=0)
        ),
        # markdown_generator=DefaultMarkdownGenerator(
        #     content_filter=BM25ContentFilter(user_query="WHEN_WE_FOCUS_BASED_ON_A_USER_QUERY", bm25_threshold=1.0)
        # ),
    )
    
    async with AsyncWebCrawler(config=browser_config) as crawler:
        result = await crawler.arun(
            url="https://docs.micronaut.io/4.9.9/guide/",
            config=run_config
        )
        print(len(result.markdown.raw_markdown))
        print(len(result.markdown.fit_markdown))

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üñ•Ô∏è &lt;strong&gt;Executing JavaScript &amp;amp; Extract Structured Data without LLMs&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai import JsonCssExtractionStrategy
import json

async def main():
    schema = {
    "name": "KidoCode Courses",
    "baseSelector": "section.charge-methodology .w-tab-content &amp;gt; div",
    "fields": [
        {
            "name": "section_title",
            "selector": "h3.heading-50",
            "type": "text",
        },
        {
            "name": "section_description",
            "selector": ".charge-content",
            "type": "text",
        },
        {
            "name": "course_name",
            "selector": ".text-block-93",
            "type": "text",
        },
        {
            "name": "course_description",
            "selector": ".course-content-text",
            "type": "text",
        },
        {
            "name": "course_icon",
            "selector": ".image-92",
            "type": "attribute",
            "attribute": "src"
        }
    ]
}

    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)

    browser_config = BrowserConfig(
        headless=False,
        verbose=True
    )
    run_config = CrawlerRunConfig(
        extraction_strategy=extraction_strategy,
        js_code=["""(async () =&amp;gt; {const tabs = document.querySelectorAll("section.charge-methodology .tabs-menu-3 &amp;gt; div");for(let tab of tabs) {tab.scrollIntoView();tab.click();await new Promise(r =&amp;gt; setTimeout(r, 500));}})();"""],
        cache_mode=CacheMode.BYPASS
    )
        
    async with AsyncWebCrawler(config=browser_config) as crawler:
        
        result = await crawler.arun(
            url="https://www.kidocode.com/degrees/technology",
            config=run_config
        )

        companies = json.loads(result.extracted_content)
        print(f"Successfully extracted {len(companies)} companies")
        print(json.dumps(companies[0], indent=2))


if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìö &lt;strong&gt;Extracting Structured Data with LLMs&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import os
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode, LLMConfig
from crawl4ai import LLMExtractionStrategy
from pydantic import BaseModel, Field

class OpenAIModelFee(BaseModel):
    model_name: str = Field(..., description="Name of the OpenAI model.")
    input_fee: str = Field(..., description="Fee for input token for the OpenAI model.")
    output_fee: str = Field(..., description="Fee for output token for the OpenAI model.")

async def main():
    browser_config = BrowserConfig(verbose=True)
    run_config = CrawlerRunConfig(
        word_count_threshold=1,
        extraction_strategy=LLMExtractionStrategy(
            # Here you can use any provider that Litellm library supports, for instance: ollama/qwen2
            # provider="ollama/qwen2", api_token="no-token", 
            llm_config = LLMConfig(provider="openai/gpt-4o", api_token=os.getenv('OPENAI_API_KEY')), 
            schema=OpenAIModelFee.schema(),
            extraction_type="schema",
            instruction="""From the crawled content, extract all mentioned model names along with their fees for input and output tokens. 
            Do not miss any models in the entire content. One extracted model JSON format should look like this: 
            {"model_name": "GPT-4", "input_fee": "US$10.00 / 1M tokens", "output_fee": "US$30.00 / 1M tokens"}."""
        ),            
        cache_mode=CacheMode.BYPASS,
    )
    
    async with AsyncWebCrawler(config=browser_config) as crawler:
        result = await crawler.arun(
            url='https://openai.com/api/pricing/',
            config=run_config
        )
        print(result.extracted_content)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ü§ñ &lt;strong&gt;Using Your own Browser with Custom User Profile&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import os, sys
from pathlib import Path
import asyncio, time
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode

async def test_news_crawl():
    # Create a persistent user data directory
    user_data_dir = os.path.join(Path.home(), ".crawl4ai", "browser_profile")
    os.makedirs(user_data_dir, exist_ok=True)

    browser_config = BrowserConfig(
        verbose=True,
        headless=True,
        user_data_dir=user_data_dir,
        use_persistent_context=True,
    )
    run_config = CrawlerRunConfig(
        cache_mode=CacheMode.BYPASS
    )
    
    async with AsyncWebCrawler(config=browser_config) as crawler:
        url = "ADDRESS_OF_A_CHALLENGING_WEBSITE"
        
        result = await crawler.arun(
            url,
            config=run_config,
            magic=True,
        )
        
        print(f"Successfully crawled {url}")
        print(f"Content length: {len(result.markdown)}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Tip:&lt;/strong&gt; Some websites may use &lt;strong&gt;CAPTCHA&lt;/strong&gt; based verification mechanisms to prevent automated access. If your workflow encounters such challenges, you may optionally integrate a third-party CAPTCHA-handling service such as &lt;strong&gt;&lt;a href="https://www.capsolver.com/blog/Partners/crawl4ai-capsolver/?utm_source=crawl4ai&amp;amp;utm_medium=github_pr&amp;amp;utm_campaign=crawl4ai_integration"&gt;CapSolver&lt;/a&gt;&lt;/strong&gt;. They support reCAPTCHA v2/v3, Cloudflare Turnstile, Challenge, AWS WAF, and more. Please ensure that your usage complies with the target website‚Äôs terms of service and applicable laws.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚ú® Recent Updates&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Version 0.7.8 Release Highlights - Stability &amp;amp; Bug Fix Release&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;This release focuses on stability with 11 bug fixes addressing issues reported by the community. No new features, but significant improvements to reliability.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üê≥ Docker API Fixes&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Fixed &lt;code&gt;ContentRelevanceFilter&lt;/code&gt; deserialization in deep crawl requests (#1642)&lt;/li&gt; 
    &lt;li&gt;Fixed &lt;code&gt;ProxyConfig&lt;/code&gt; JSON serialization in &lt;code&gt;BrowserConfig.to_dict()&lt;/code&gt; (#1629)&lt;/li&gt; 
    &lt;li&gt;Fixed &lt;code&gt;.cache&lt;/code&gt; folder permissions in Docker image (#1638)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ü§ñ LLM Extraction Improvements&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Configurable rate limiter backoff with new &lt;code&gt;LLMConfig&lt;/code&gt; parameters (#1269): &lt;pre&gt;&lt;code class="language-python"&gt;from crawl4ai import LLMConfig

config = LLMConfig(
    provider="openai/gpt-4o-mini",
    backoff_base_delay=5,           # Wait 5s on first retry
    backoff_max_attempts=5,          # Try up to 5 times
    backoff_exponential_factor=3     # Multiply delay by 3 each attempt
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt;HTML input format support for &lt;code&gt;LLMExtractionStrategy&lt;/code&gt; (#1178): &lt;pre&gt;&lt;code class="language-python"&gt;from crawl4ai import LLMExtractionStrategy

strategy = LLMExtractionStrategy(
    llm_config=config,
    instruction="Extract table data",
    input_format="html"  # Now supports: "html", "markdown", "fit_markdown"
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt;Fixed raw HTML URL variable - extraction strategies now receive &lt;code&gt;"Raw HTML"&lt;/code&gt; instead of HTML blob (#1116)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó URL Handling&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Fixed relative URL resolution after JavaScript redirects (#1268)&lt;/li&gt; 
    &lt;li&gt;Fixed import statement formatting in extracted code (#1181)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üì¶ Dependency Updates&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Replaced deprecated PyPDF2 with pypdf (#1412)&lt;/li&gt; 
    &lt;li&gt;Pydantic v2 ConfigDict compatibility - no more deprecation warnings (#678)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üß† AdaptiveCrawler&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Fixed query expansion to actually use LLM instead of hardcoded mock data (#1621)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/blog/release-v0.7.8.md"&gt;Full v0.7.8 Release Notes ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Version 0.7.7 Release Highlights - The Self-Hosting &amp;amp; Monitoring Update&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìä Real-time Monitoring Dashboard&lt;/strong&gt;: Interactive web UI with live system metrics and browser pool visibility&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;# Access the monitoring dashboard
# Visit: http://localhost:11235/dashboard

# Real-time metrics include:
# - System health (CPU, memory, network, uptime)
# - Active and completed request tracking
# - Browser pool management (permanent/hot/cold)
# - Janitor cleanup events
# - Error monitoring with full context
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîå Comprehensive Monitor API&lt;/strong&gt;: Complete REST API for programmatic access to all monitoring data&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;import httpx

async with httpx.AsyncClient() as client:
    # System health
    health = await client.get("http://localhost:11235/monitor/health")

    # Request tracking
    requests = await client.get("http://localhost:11235/monitor/requests")

    # Browser pool status
    browsers = await client.get("http://localhost:11235/monitor/browsers")

    # Endpoint statistics
    stats = await client.get("http://localhost:11235/monitor/endpoints/stats")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° WebSocket Streaming&lt;/strong&gt;: Real-time updates every 2 seconds for custom dashboards&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üî• Smart Browser Pool&lt;/strong&gt;: 3-tier architecture (permanent/hot/cold) with automatic promotion and cleanup&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üßπ Janitor System&lt;/strong&gt;: Automatic resource management with event logging&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéÆ Control Actions&lt;/strong&gt;: Manual browser management (kill, restart, cleanup) via API&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìà Production Metrics&lt;/strong&gt;: 6 critical metrics for operational excellence with Prometheus integration&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üêõ Critical Bug Fixes&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Fixed async LLM extraction blocking issue (#1055)&lt;/li&gt; 
    &lt;li&gt;Enhanced DFS deep crawl strategy (#1607)&lt;/li&gt; 
    &lt;li&gt;Fixed sitemap parsing in AsyncUrlSeeder (#1598)&lt;/li&gt; 
    &lt;li&gt;Resolved browser viewport configuration (#1495)&lt;/li&gt; 
    &lt;li&gt;Fixed CDP timing with exponential backoff (#1528)&lt;/li&gt; 
    &lt;li&gt;Security update for pyOpenSSL (&amp;gt;=25.3.0)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/blog/release-v0.7.7.md"&gt;Full v0.7.7 Release Notes ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Version 0.7.5 Release Highlights - The Docker Hooks &amp;amp; Security Update&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîß Docker Hooks System&lt;/strong&gt;: Complete pipeline customization with user-provided Python functions at 8 key points&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ú® Function-Based Hooks API (NEW)&lt;/strong&gt;: Write hooks as regular Python functions with full IDE support:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from crawl4ai import hooks_to_string
from crawl4ai.docker_client import Crawl4aiDockerClient

# Define hooks as regular Python functions
async def on_page_context_created(page, context, **kwargs):
    """Block images to speed up crawling"""
    await context.route("**/*.{png,jpg,jpeg,gif,webp}", lambda route: route.abort())
    await page.set_viewport_size({"width": 1920, "height": 1080})
    return page

async def before_goto(page, context, url, **kwargs):
    """Add custom headers"""
    await page.set_extra_http_headers({'X-Crawl4AI': 'v0.7.5'})
    return page

# Option 1: Use hooks_to_string() utility for REST API
hooks_code = hooks_to_string({
    "on_page_context_created": on_page_context_created,
    "before_goto": before_goto
})

# Option 2: Docker client with automatic conversion (Recommended)
client = Crawl4aiDockerClient(base_url="http://localhost:11235")
results = await client.crawl(
    urls=["https://httpbin.org/html"],
    hooks={
        "on_page_context_created": on_page_context_created,
        "before_goto": before_goto
    }
)
# ‚úì Full IDE support, type checking, and reusability!
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ü§ñ Enhanced LLM Integration&lt;/strong&gt;: Custom providers with temperature control and base_url configuration&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîí HTTPS Preservation&lt;/strong&gt;: Secure internal link handling with &lt;code&gt;preserve_https_for_internal_links=True&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üêç Python 3.10+ Support&lt;/strong&gt;: Modern language features and enhanced performance&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üõ†Ô∏è Bug Fixes&lt;/strong&gt;: Resolved multiple community-reported issues including URL processing, JWT authentication, and proxy configuration&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/blog/release-v0.7.5.md"&gt;Full v0.7.5 Release Notes ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Version 0.7.4 Release Highlights - The Intelligent Table Extraction &amp;amp; Performance Update&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üöÄ LLMTableExtraction&lt;/strong&gt;: Revolutionary table extraction with intelligent chunking for massive tables:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from crawl4ai import LLMTableExtraction, LLMConfig

# Configure intelligent table extraction
table_strategy = LLMTableExtraction(
    llm_config=LLMConfig(provider="openai/gpt-4.1-mini"),
    enable_chunking=True,           # Handle massive tables
    chunk_token_threshold=5000,     # Smart chunking threshold
    overlap_threshold=100,          # Maintain context between chunks
    extraction_type="structured"    # Get structured data output
)

config = CrawlerRunConfig(table_extraction_strategy=table_strategy)
result = await crawler.arun("https://complex-tables-site.com", config=config)

# Tables are automatically chunked, processed, and merged
for table in result.tables:
    print(f"Extracted table: {len(table['data'])} rows")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Dispatcher Bug Fix&lt;/strong&gt;: Fixed sequential processing bottleneck in arun_many for fast-completing tasks&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üßπ Memory Management Refactor&lt;/strong&gt;: Consolidated memory utilities into main utils module for cleaner architecture&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîß Browser Manager Fixes&lt;/strong&gt;: Resolved race conditions in concurrent page creation with thread-safe locking&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Advanced URL Processing&lt;/strong&gt;: Better handling of raw:// URLs and base tag link resolution&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üõ°Ô∏è Enhanced Proxy Support&lt;/strong&gt;: Flexible proxy configuration supporting both dict and string formats&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/blog/release-v0.7.4.md"&gt;Full v0.7.4 Release Notes ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Version 0.7.3 Release Highlights - The Multi-Config Intelligence Update&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üïµÔ∏è Undetected Browser Support&lt;/strong&gt;: Bypass sophisticated bot detection systems:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from crawl4ai import AsyncWebCrawler, BrowserConfig

browser_config = BrowserConfig(
    browser_type="undetected",  # Use undetected Chrome
    headless=True,              # Can run headless with stealth
    extra_args=[
        "--disable-blink-features=AutomationControlled",
        "--disable-web-security"
    ]
)

async with AsyncWebCrawler(config=browser_config) as crawler:
    result = await crawler.arun("https://protected-site.com")
# Successfully bypass Cloudflare, Akamai, and custom bot detection
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üé® Multi-URL Configuration&lt;/strong&gt;: Different strategies for different URL patterns in one batch:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from crawl4ai import CrawlerRunConfig, MatchMode

configs = [
    # Documentation sites - aggressive caching
    CrawlerRunConfig(
        url_matcher=["*docs*", "*documentation*"],
        cache_mode="write",
        markdown_generator_options={"include_links": True}
    ),
    
    # News/blog sites - fresh content
    CrawlerRunConfig(
        url_matcher=lambda url: 'blog' in url or 'news' in url,
        cache_mode="bypass"
    ),
    
    # Fallback for everything else
    CrawlerRunConfig()
]

results = await crawler.arun_many(urls, config=configs)
# Each URL gets the perfect configuration automatically
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üß† Memory Monitoring&lt;/strong&gt;: Track and optimize memory usage during crawling:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from crawl4ai.memory_utils import MemoryMonitor

monitor = MemoryMonitor()
monitor.start_monitoring()

results = await crawler.arun_many(large_url_list)

report = monitor.get_report()
print(f"Peak memory: {report['peak_mb']:.1f} MB")
print(f"Efficiency: {report['efficiency']:.1f}%")
# Get optimization recommendations
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìä Enhanced Table Extraction&lt;/strong&gt;: Direct DataFrame conversion from web tables:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;result = await crawler.arun("https://site-with-tables.com")

# New way - direct table access
if result.tables:
    import pandas as pd
    for table in result.tables:
        df = pd.DataFrame(table['data'])
        print(f"Table: {df.shape[0]} rows √ó {df.shape[1]} columns")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üí∞ GitHub Sponsors&lt;/strong&gt;: 4-tier sponsorship system for project sustainability&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üê≥ Docker LLM Flexibility&lt;/strong&gt;: Configure providers via environment variables&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/blog/release-v0.7.3.md"&gt;Full v0.7.3 Release Notes ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Version 0.7.0 Release Highlights - The Adaptive Intelligence Update&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üß† Adaptive Crawling&lt;/strong&gt;: Your crawler now learns and adapts to website patterns automatically:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;config = AdaptiveConfig(
    confidence_threshold=0.7, # Min confidence to stop crawling
    max_depth=5, # Maximum crawl depth
    max_pages=20, # Maximum number of pages to crawl
    strategy="statistical"
)

async with AsyncWebCrawler() as crawler:
    adaptive_crawler = AdaptiveCrawler(crawler, config)
    state = await adaptive_crawler.digest(
        start_url="https://news.example.com",
        query="latest news content"
    )
# Crawler learns patterns and improves extraction over time
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üåä Virtual Scroll Support&lt;/strong&gt;: Complete content extraction from infinite scroll pages:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;scroll_config = VirtualScrollConfig(
    container_selector="[data-testid='feed']",
    scroll_count=20,
    scroll_by="container_height",
    wait_after_scroll=1.0
)

result = await crawler.arun(url, config=CrawlerRunConfig(
    virtual_scroll_config=scroll_config
))
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Intelligent Link Analysis&lt;/strong&gt;: 3-layer scoring system for smart link prioritization:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;link_config = LinkPreviewConfig(
    query="machine learning tutorials",
    score_threshold=0.3,
    concurrent_requests=10
)

result = await crawler.arun(url, config=CrawlerRunConfig(
    link_preview_config=link_config,
    score_links=True
))
# Links ranked by relevance and quality
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üé£ Async URL Seeder&lt;/strong&gt;: Discover thousands of URLs in seconds:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;seeder = AsyncUrlSeeder(SeedingConfig(
    source="sitemap+cc",
    pattern="*/blog/*",
    query="python tutorials",
    score_threshold=0.4
))

urls = await seeder.discover("https://example.com")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Performance Boost&lt;/strong&gt;: Up to 3x faster with optimized resource handling and memory efficiency&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Read the full details in our &lt;a href="https://docs.crawl4ai.com/blog/release-v0.7.0"&gt;0.7.0 Release Notes&lt;/a&gt; or check the &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Version Numbering in Crawl4AI&lt;/h2&gt; 
&lt;p&gt;Crawl4AI follows standard Python version numbering conventions (PEP 440) to help users understand the stability and features of each release.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìà &lt;strong&gt;Version Numbers Explained&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Our version numbers follow this pattern: &lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt; (e.g., 0.4.3)&lt;/p&gt; 
 &lt;h4&gt;Pre-release Versions&lt;/h4&gt; 
 &lt;p&gt;We use different suffixes to indicate development stages:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;dev&lt;/code&gt; (0.4.3dev1): Development versions, unstable&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;a&lt;/code&gt; (0.4.3a1): Alpha releases, experimental features&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;b&lt;/code&gt; (0.4.3b1): Beta releases, feature complete but needs testing&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;rc&lt;/code&gt; (0.4.3): Release candidates, potential final version&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;Installation&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Regular installation (stable version):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U crawl4ai
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Install pre-release versions:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install crawl4ai --pre
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Install specific version:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install crawl4ai==0.4.3b1
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;Why Pre-releases?&lt;/h4&gt; 
 &lt;p&gt;We use pre-releases to:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Test new features in real-world scenarios&lt;/li&gt; 
  &lt;li&gt;Gather feedback before final releases&lt;/li&gt; 
  &lt;li&gt;Ensure stability for production users&lt;/li&gt; 
  &lt;li&gt;Allow early adopters to try new features&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;For production environments, we recommend using the stable version. For testing new features, you can opt-in to pre-releases using the &lt;code&gt;--pre&lt;/code&gt; flag.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üìñ Documentation &amp;amp; Roadmap&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üö® &lt;strong&gt;Documentation Update Alert&lt;/strong&gt;: We're undertaking a major documentation overhaul next week to reflect recent updates and improvements. Stay tuned for a more comprehensive and up-to-date guide!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For current documentation, including installation instructions, advanced features, and API reference, visit our &lt;a href="https://docs.crawl4ai.com/"&gt;Documentation Website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To check our development plans and upcoming features, visit our &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/ROADMAP.md"&gt;Roadmap&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìà &lt;strong&gt;Development TODOs&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 0. Graph Crawler: Smart website traversal using graph search algorithms for comprehensive nested page extraction&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 1. Question-Based Crawler: Natural language driven web discovery and content extraction&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 2. Knowledge-Optimal Crawler: Smart crawling that maximizes knowledge while minimizing data extraction&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 3. Agentic Crawler: Autonomous system for complex multi-step crawling operations&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 4. Automated Schema Generator: Convert natural language to extraction schemas&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 5. Domain-Specific Scrapers: Pre-configured extractors for common platforms (academic, e-commerce)&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 6. Web Embedding Index: Semantic search infrastructure for crawled content&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 7. Interactive Playground: Web UI for testing, comparing strategies with AI assistance&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 8. Performance Monitor: Real-time insights into crawler operations&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 9. Cloud Integration: One-click deployment solutions across cloud providers&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 10. Sponsorship Program: Structured support system with tiered benefits&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 11. Educational Content: "How to Crawl" video series and interactive tutorials&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the open-source community. Check out our &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/CONTRIBUTORS.md"&gt;contribution guidelines&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;I'll help modify the license section with badges. For the halftone effect, here's a version with it:&lt;/p&gt; 
&lt;p&gt;Here's the updated license section:&lt;/p&gt; 
&lt;h2&gt;üìÑ License &amp;amp; Attribution&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0, attribution is recommended via the badges below. See the &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/LICENSE"&gt;Apache 2.0 License&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h3&gt;Attribution Requirements&lt;/h3&gt; 
&lt;p&gt;When using Crawl4AI, you must include one of the following attribution methods:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìà &lt;strong&gt;1. Badge Attribution (Recommended)&lt;/strong&gt;&lt;/summary&gt; Add one of these badges to your README, documentation, or website: 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Theme&lt;/th&gt; 
    &lt;th&gt;Badge&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Disco Theme (Animated)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/unclecode/crawl4ai"&gt;&lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-disco.svg?sanitize=true" alt="Powered by Crawl4AI" width="200" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Night Theme (Dark with Neon)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/unclecode/crawl4ai"&gt;&lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-night.svg?sanitize=true" alt="Powered by Crawl4AI" width="200" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Dark Theme (Classic)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/unclecode/crawl4ai"&gt;&lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-dark.svg?sanitize=true" alt="Powered by Crawl4AI" width="200" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Light Theme (Classic)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/unclecode/crawl4ai"&gt;&lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-light.svg?sanitize=true" alt="Powered by Crawl4AI" width="200" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;HTML code for adding the badges:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-html"&gt;&amp;lt;!-- Disco Theme (Animated) --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-disco.svg" alt="Powered by Crawl4AI" width="200"/&amp;gt;
&amp;lt;/a&amp;gt;

&amp;lt;!-- Night Theme (Dark with Neon) --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-night.svg" alt="Powered by Crawl4AI" width="200"/&amp;gt;
&amp;lt;/a&amp;gt;

&amp;lt;!-- Dark Theme (Classic) --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-dark.svg" alt="Powered by Crawl4AI" width="200"/&amp;gt;
&amp;lt;/a&amp;gt;

&amp;lt;!-- Light Theme (Classic) --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-light.svg" alt="Powered by Crawl4AI" width="200"/&amp;gt;
&amp;lt;/a&amp;gt;

&amp;lt;!-- Simple Shield Badge --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://img.shields.io/badge/Powered%20by-Crawl4AI-blue?style=flat-square" alt="Powered by Crawl4AI"/&amp;gt;
&amp;lt;/a&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìñ &lt;strong&gt;2. Text Attribution&lt;/strong&gt;&lt;/summary&gt; Add this line to your documentation: ``` This project uses Crawl4AI (https://github.com/unclecode/crawl4ai) for web data extraction. ``` 
&lt;/details&gt; 
&lt;h2&gt;üìö Citation&lt;/h2&gt; 
&lt;p&gt;If you use Crawl4AI in your research or project, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{crawl4ai2024,
  author = {UncleCode},
  title = {Crawl4AI: Open-source LLM Friendly Web Crawler &amp;amp; Scraper},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub Repository},
  howpublished = {\url{https://github.com/unclecode/crawl4ai}},
  commit = {Please use the commit hash you're working with}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Text citation format:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;UncleCode. (2024). Crawl4AI: Open-source LLM Friendly Web Crawler &amp;amp; Scraper [Computer software]. 
GitHub. https://github.com/unclecode/crawl4ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìß Contact&lt;/h2&gt; 
&lt;p&gt;For questions, suggestions, or feedback, feel free to reach out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub: &lt;a href="https://github.com/unclecode"&gt;unclecode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Twitter: &lt;a href="https://twitter.com/unclecode"&gt;@unclecode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Website: &lt;a href="https://crawl4ai.com"&gt;crawl4ai.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Happy Crawling! üï∏Ô∏èüöÄ&lt;/p&gt; 
&lt;h2&gt;üóæ Mission&lt;/h2&gt; 
&lt;p&gt;Our mission is to unlock the value of personal and enterprise data by transforming digital footprints into structured, tradeable assets. Crawl4AI empowers individuals and organizations with open-source tools to extract and structure data, fostering a shared data economy.&lt;/p&gt; 
&lt;p&gt;We envision a future where AI is powered by real human knowledge, ensuring data creators directly benefit from their contributions. By democratizing data and enabling ethical sharing, we are laying the foundation for authentic AI advancement.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîë &lt;strong&gt;Key Opportunities&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Data Capitalization&lt;/strong&gt;: Transform digital footprints into measurable, valuable assets.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Authentic AI Data&lt;/strong&gt;: Provide AI systems with real human insights.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Shared Economy&lt;/strong&gt;: Create a fair data marketplace that benefits data creators.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üöÄ &lt;strong&gt;Development Pathway&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Open-Source Tools&lt;/strong&gt;: Community-driven platforms for transparent data extraction.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Digital Asset Structuring&lt;/strong&gt;: Tools to organize and value digital knowledge.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ethical Data Marketplace&lt;/strong&gt;: A secure, fair platform for exchanging structured data.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;For more details, see our &lt;a href="https://raw.githubusercontent.com/unclecode/crawl4ai/main/MISSION.md"&gt;full mission statement&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üåü Current Sponsors&lt;/h2&gt; 
&lt;h3&gt;üè¢ Enterprise Sponsors &amp;amp; Partners&lt;/h3&gt; 
&lt;p&gt;Our enterprise sponsors and technology partners help scale Crawl4AI to power production-grade data pipelines.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Company&lt;/th&gt; 
   &lt;th&gt;About&lt;/th&gt; 
   &lt;th&gt;Sponsorship Tier&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://app.nstproxy.com/register?i=ecOqW9" target="_blank"&gt;
     &lt;picture&gt;
      &lt;source width="250" media="(prefers-color-scheme: dark)" srcset="https://gist.github.com/aravindkarnam/62f82bd4818d3079d9dd3c31df432cf8/raw/nst-light.svg" /&gt;
      &lt;source width="250" media="(prefers-color-scheme: light)" srcset="https://www.nstproxy.com/logo.svg" /&gt;
      &lt;img alt="nstproxy" src="ttps://www.nstproxy.com/logo.svg?sanitize=true" /&gt;
     &lt;/picture&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;NstProxy is a trusted proxy provider with over 110M+ real residential IPs, city-level targeting, 99.99% uptime, and low pricing at $0.1/GB, it delivers unmatched stability, scale, and cost-efficiency.&lt;/td&gt; 
   &lt;td&gt;ü•à Silver&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://app.scrapeless.com/passport/register?utm_source=official&amp;amp;utm_term=crawl4ai" target="_blank"&gt;
     &lt;picture&gt;
      &lt;source width="250" media="(prefers-color-scheme: dark)" srcset="https://gist.githubusercontent.com/aravindkarnam/0d275b942705604263e5c32d2db27bc1/raw/Scrapeless-light-logo.svg" /&gt;
      &lt;source width="250" media="(prefers-color-scheme: light)" srcset="https://gist.githubusercontent.com/aravindkarnam/22d0525cc0f3021bf19ebf6e11a69ccd/raw/Scrapeless-dark-logo.svg" /&gt;
      &lt;img alt="Scrapeless" src="https://gist.githubusercontent.com/aravindkarnam/22d0525cc0f3021bf19ebf6e11a69ccd/raw/Scrapeless-dark-logo.svg?sanitize=true" /&gt;
     &lt;/picture&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Scrapeless provides production-grade infrastructure for Crawling, Automation, and AI Agents, offering Scraping Browser, 4 Proxy Types and Universal Scraping API.&lt;/td&gt; 
   &lt;td&gt;ü•à Silver&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://dashboard.capsolver.com/passport/register?inviteCode=ESVSECTX5Q23" target="_blank"&gt;
     &lt;picture&gt;
      &lt;source width="120" media="(prefers-color-scheme: dark)" srcset="https://docs.crawl4ai.com/uploads/sponsors/20251013045338_72a71fa4ee4d2f40.png" /&gt;
      &lt;source width="120" media="(prefers-color-scheme: light)" srcset="https://www.capsolver.com/assets/images/logo-text.png" /&gt;
      &lt;img alt="Capsolver" src="https://www.capsolver.com/assets/images/logo-text.png" /&gt;
     &lt;/picture&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AI-powered Captcha solving service. Supports all major Captcha types, including reCAPTCHA, Cloudflare, and more&lt;/td&gt; 
   &lt;td&gt;ü•â Bronze&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://kipo.ai" target="_blank"&gt;&lt;img src="https://docs.crawl4ai.com/uploads/sponsors/20251013045751_2d54f57f117c651e.png" alt="DataSync" width="120" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Helps engineers and buyers find, compare, and source electronic &amp;amp; industrial parts in seconds, with specs, pricing, lead times &amp;amp; alternatives.&lt;/td&gt; 
   &lt;td&gt;ü•á Gold&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.kidocode.com/" target="_blank"&gt;&lt;img src="https://docs.crawl4ai.com/uploads/sponsors/20251013045045_bb8dace3f0440d65.svg?sanitize=true" alt="Kidocode" width="120" /&gt;&lt;p align="center"&gt;KidoCode&lt;/p&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Kidocode is a hybrid technology and entrepreneurship school for kids aged 5‚Äì18, offering both online and on-campus education.&lt;/td&gt; 
   &lt;td&gt;ü•á Gold&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.alephnull.sg/" target="_blank"&gt;&lt;img src="https://docs.crawl4ai.com/uploads/sponsors/20251013050323_a9e8e8c4c3650421.svg?sanitize=true" alt="Aleph null" width="120" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Singapore-based Aleph Null is Asia‚Äôs leading edtech hub, dedicated to student-centric, AI-driven education‚Äîempowering learners with the tools to thrive in a fast-changing world.&lt;/td&gt; 
   &lt;td&gt;ü•á Gold&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üßë‚Äçü§ù Individual Sponsors&lt;/h3&gt; 
&lt;p&gt;A heartfelt thanks to our individual supporters! Every contribution helps us keep our opensource mission alive and thriving!&lt;/p&gt; 
&lt;p align="left"&gt; &lt;a href="https://github.com/hafezparast"&gt;&lt;img src="https://avatars.githubusercontent.com/u/14273305?s=60&amp;amp;v=4" style="border-radius:50%;" width="64px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ntohidi"&gt;&lt;img src="https://avatars.githubusercontent.com/u/17140097?s=60&amp;amp;v=4" style="border-radius:50%;" width="64px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Sjoeborg"&gt;&lt;img src="https://avatars.githubusercontent.com/u/17451310?s=60&amp;amp;v=4" style="border-radius:50%;" width="64px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/romek-rozen"&gt;&lt;img src="https://avatars.githubusercontent.com/u/30595969?s=60&amp;amp;v=4" style="border-radius:50%;" width="64px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Kourosh-Kiyani"&gt;&lt;img src="https://avatars.githubusercontent.com/u/34105600?s=60&amp;amp;v=4" style="border-radius:50%;" width="64px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Etherdrake"&gt;&lt;img src="https://avatars.githubusercontent.com/u/67021215?s=60&amp;amp;v=4" style="border-radius:50%;" width="64px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/shaman247"&gt;&lt;img src="https://avatars.githubusercontent.com/u/211010067?s=60&amp;amp;v=4" style="border-radius:50%;" width="64px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/work-flow-manager"&gt;&lt;img src="https://avatars.githubusercontent.com/u/217665461?s=60&amp;amp;v=4" style="border-radius:50%;" width="64px;" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Want to join them? &lt;a href="https://github.com/sponsors/unclecode"&gt;Sponsor Crawl4AI ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#unclecode/crawl4ai&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=unclecode/crawl4ai&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dortania/OpenCore-Legacy-Patcher</title>
      <link>https://github.com/dortania/OpenCore-Legacy-Patcher</link>
      <description>&lt;p&gt;Experience macOS just like before&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/dortania/OpenCore-Legacy-Patcher/main/docs/images/OC-Patcher.png" alt="OpenCore Patcher Logo" width="256" /&gt; 
 &lt;h1&gt;OpenCore Legacy Patcher&lt;/h1&gt; 
&lt;/div&gt; 
&lt;p&gt;A Python-based project revolving around &lt;a href="https://github.com/acidanthera/OpenCorePkg"&gt;Acidanthera's OpenCorePkg&lt;/a&gt; and &lt;a href="https://github.com/acidanthera/Lilu"&gt;Lilu&lt;/a&gt; for both running and unlocking features in macOS on supported and unsupported Macs.&lt;/p&gt; 
&lt;p&gt;Our project's main goal is to breathe new life into Macs no longer supported by Apple, allowing for the installation and usage of macOS Big Sur and newer on machines as old as 2007.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/downloads/dortania/OpenCore-Legacy-Patcher/total?color=white&amp;amp;style=plastic" alt="GitHub all releases" /&gt; &lt;img src="https://img.shields.io/github/languages/top/dortania/OpenCore-Legacy-Patcher?color=4B8BBE&amp;amp;style=plastic" alt="GitHub top language" /&gt; &lt;img src="https://img.shields.io/discord/417165963327176704?color=7289da&amp;amp;label=discord&amp;amp;style=plastic" alt="Discord" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Noteworthy features of OpenCore Legacy Patcher:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for macOS Big Sur, Monterey, Ventura, Sonoma and Sequoia&lt;/li&gt; 
 &lt;li&gt;Native Over the Air (OTA) System Updates&lt;/li&gt; 
 &lt;li&gt;Supports Penryn and newer Macs&lt;/li&gt; 
 &lt;li&gt;Full support for WPA Wi-Fi and Personal Hotspot on BCM943224 and newer wireless chipsets&lt;/li&gt; 
 &lt;li&gt;System Integrity Protection, FileVault 2, .im4m Secure Boot and Vaulting&lt;/li&gt; 
 &lt;li&gt;Recovery OS, Safe Mode and Single-user Mode booting on non-native OSes&lt;/li&gt; 
 &lt;li&gt;Unlocks features such as Sidecar and AirPlay to Mac even on native Macs&lt;/li&gt; 
 &lt;li&gt;Enables enhanced SATA and NVMe power management on non-Apple storage devices&lt;/li&gt; 
 &lt;li&gt;Zero firmware patching required (ie. APFS ROM patching)&lt;/li&gt; 
 &lt;li&gt;Graphics acceleration for both Metal and non-Metal GPUs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;Note: Only clean-installs and upgrades are supported. macOS Big Sur installs already patched with other patchers, such as &lt;a href="https://github.com/BenSova/Patched-Sur"&gt;Patched Sur&lt;/a&gt; or &lt;a href="https://github.com/StarPlayrX/bigmac"&gt;bigmac&lt;/a&gt;, cannot be used due to broken file integrity with APFS snapshots and SIP.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can, however, reinstall macOS with this patcher and retain your original data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note 2: Currently, OpenCore Legacy Patcher officially supports patching to run macOS Big Sur through Sonoma installs. For older OSes, OpenCore may function; however, support is currently not provided from Dortania.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For macOS Mojave and Catalina support, we recommend the use of &lt;a href="http://dosdude1.com"&gt;dosdude1's patchers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To start using the project, please see our in-depth guide:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dortania.github.io/OpenCore-Legacy-Patcher/"&gt;OpenCore Legacy Patcher Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;This project is offered on an AS-IS basis, we do not guarantee support for any issues that may arise. However, there is a community server with other passionate users and developers that can aid you:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/rqdPgH8xSN"&gt;OpenCore Patcher Paradise Discord Server&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Keep in mind that the Discord server is maintained by the community, so we ask everyone to be respectful.&lt;/li&gt; 
   &lt;li&gt;Please review our docs on &lt;a href="https://dortania.github.io/OpenCore-Legacy-Patcher/DEBUG.html"&gt;how to debug with OpenCore&lt;/a&gt; to gather important information to help others with troubleshooting.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Running from source&lt;/h2&gt; 
&lt;p&gt;To run the project from source, see here: &lt;a href="https://raw.githubusercontent.com/dortania/OpenCore-Legacy-Patcher/main/SOURCE.md"&gt;Build and run from source&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Acidanthera"&gt;Acidanthera&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;OpenCorePkg, as well as many of the core kexts and tools&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DhinakG"&gt;DhinakG&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Main co-author&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Khronokernel"&gt;Khronokernel&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Main co-author&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Ausdauersportler"&gt;Ausdauersportler&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;iMacs Metal GPUs Upgrade Patch set and documentation&lt;/li&gt; 
   &lt;li&gt;Great amounts of help with debugging, and code suggestions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vit9696"&gt;vit9696&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Endless amount of help troubleshooting, determining fixes and writing patches&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/covasedu"&gt;EduCovas&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/non-metal-frameworks"&gt;non-Metal patch set&lt;/a&gt; for nVidia Tesla/Fermi/Maxwell/Pascal, AMD TeraScale 1/2, and Intel Core 1st/2nd Generation GPUs&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/misc-patches/tree/main/3802-Metal-15"&gt;3802 Metal patch set&lt;/a&gt; and &lt;a href="https://github.com/dortania/MetallibSupportPkg"&gt;MetallibSupportPkg&lt;/a&gt; for nVidia Kepler and Intel Core 3rd/4th Generation GPUs&lt;/li&gt; 
   &lt;li&gt;Metal bundle patches and shims for &lt;a href="https://github.com/moraea/misc-patches/tree/main/Kepler%2013%2B"&gt;nVidia Kepler&lt;/a&gt;, &lt;a href="https://github.com/moraea/misc-patches/tree/main/GCN%2013%2B"&gt;AMD GCN 1 - 4&lt;/a&gt;, and &lt;a href="https://github.com/moraea/misc-patches/tree/main/vega%2013%2B"&gt;AMD GCN 5 (Vega)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/misc-patches/tree/main/Sonoma%2014.4%20IOSurface"&gt;IOSurface offset patches&lt;/a&gt; for nVidia Kepler, AMD GCN 1 - 5, and Intel Core 3rd - 6th Generation GPUs&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/unsupported-wifi-patches"&gt;legacy Wi-Fi patch set&lt;/a&gt; restores functionality for Wi-Fi cards in all 2007 - 2017 models&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/misc-patches/tree/main/T1-Patch"&gt;T1 patch set&lt;/a&gt; restores Touch ID, Apple Pay, and other secure functionality in 2016 - 2017 models&lt;/li&gt; 
   &lt;li&gt;AppleGVA downgrade for accelerated video decoding on 2012 - 2016 models&lt;/li&gt; 
   &lt;li&gt;OpenCL and OpenGL downgrade for AMD GCN&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/misc-patches/tree/main/IOUSBHostFamily-14.4"&gt;USB 1 patch&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moosethegoose2213"&gt;ASentientHedgehog&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/non-metal-frameworks"&gt;non-Metal patch set&lt;/a&gt; for nVidia Tesla/Fermi/Maxwell/Pascal, AMD TeraScale 1/2, and Intel Core 1st/2nd Generation GPUs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ASentientBot"&gt;ASentientBot&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/non-metal-frameworks"&gt;non-Metal patch set&lt;/a&gt; for nVidia Tesla/Fermi/Maxwell/Pascal, AMD TeraScale 1/2, and Intel Core 1st/2nd Generation GPUs&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/misc-patches/tree/main/sequoia%2031001%20interposer"&gt;Metal bundle interposer&lt;/a&gt; for AMD GCN 1 - 5 and Intel Core 5th/6th Generation GPUs&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/dsce"&gt;dsce&lt;/a&gt; and &lt;a href="https://github.com/moraea/moraea-common"&gt;shared code&lt;/a&gt; used by some other patches&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cdf"&gt;cdf&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Mac Pro on OpenCore Patch set and documentation&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/cdf/Innie"&gt;Innie&lt;/a&gt; and &lt;a href="https://github.com/cdf/NightShiftEnabler"&gt;NightShiftEnabler&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://forums.macrumors.com/members/syncretic.1173816/"&gt;Syncretic&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://forums.macrumors.com/threads/mp3-1-others-sse-4-2-emulation-to-enable-amd-metal-driver.2206682/"&gt;AAAMouSSE&lt;/a&gt;, &lt;a href="https://forums.macrumors.com/threads/mp3-1-others-sse-4-2-emulation-to-enable-amd-metal-driver.2206682/post-28447707"&gt;telemetrap&lt;/a&gt; and &lt;a href="https://github.com/reenigneorcim/SurPlus"&gt;SurPlus&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dosdude1"&gt;dosdude1&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Main author of the &lt;a href="https://github.com/dortania/OCLP-GUI"&gt;original GUI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Development of previous patchers, laying out much of what needs to be patched&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/parrotgeek1"&gt;parrotgeek1&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/dortania/OpenCore-Legacy-Patcher/raw/4a8f61a01da72b38a4b2250386cc4b497a31a839/payloads/Config/config.plist#L1222-L1281"&gt;VMM Patch Set&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BarryKN"&gt;BarryKN&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Development of previous patchers, laying out much of what needs to be patched&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mariobrostech"&gt;mario_bros_tech&lt;/a&gt; and the rest of the Unsupported Mac Discord 
  &lt;ul&gt; 
   &lt;li&gt;Catalyst that started OpenCore Legacy Patcher&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/arter97/"&gt;arter97&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/arter97/SimpleMSR/"&gt;SimpleMSR&lt;/a&gt; to disable firmware throttling in Nehalem+ MacBooks without batteries&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mrmacintosh.com"&gt;Mr.Macintosh&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Endless hours helping architect and troubleshoot many portions of the project&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flagersgit"&gt;flagers&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Aid with Nvidia Web Driver research and development&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/non-metal-frameworks"&gt;non-Metal patch set&lt;/a&gt; for nVidia Tesla/Fermi/Maxwell/Pascal, AMD TeraScale 1/2, and Intel Core 1st/2nd Generation GPUs&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moraea/misc-patches/tree/main/sequoia%2031001%20interposer"&gt;Metal bundle interposer&lt;/a&gt; for AMD GCN 1 - 5 and Intel Core 5th/6th Generation GPUs&lt;/li&gt; 
   &lt;li&gt;LegacyRVPL, SnapshotIsKill, etc. to aid in rapid testing and development&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/joevt"&gt;joevt&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/joevt/joevtApps"&gt;FixPCIeLinkrate&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jazzzny"&gt;Jazzzny&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Research and various contributions to the project&lt;/li&gt; 
   &lt;li&gt;UEFI Legacy XHCI research and development&lt;/li&gt; 
   &lt;li&gt;NVIDIA OpenCL research and development&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;MacBook5,2&lt;/code&gt; research and development 
    &lt;ul&gt; 
     &lt;li&gt;LegacyKeyboardInjector&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Pre-Ivy Bridge Aquantia Ethernet Patch&lt;/li&gt; 
   &lt;li&gt;Non-Metal Photo Booth Patch for Monterey+&lt;/li&gt; 
   &lt;li&gt;GUI and Backend Development 
    &lt;ul&gt; 
     &lt;li&gt;Updater UI&lt;/li&gt; 
     &lt;li&gt;macOS Downloader UI&lt;/li&gt; 
     &lt;li&gt;Downloader UI&lt;/li&gt; 
     &lt;li&gt;USB Top Case probing&lt;/li&gt; 
     &lt;li&gt;Developer root patching&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Vaulting implementation&lt;/li&gt; 
   &lt;li&gt;macOS 15 3802 Helios Research&lt;/li&gt; 
   &lt;li&gt;UEFI bootx64.efi research&lt;/li&gt; 
   &lt;li&gt;universal2 build research&lt;/li&gt; 
   &lt;li&gt;Various documentation contributions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Amazing users who've graciously donate hardware: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://forums.macrumors.com/members/johnd.53633/"&gt;JohnD&lt;/a&gt; - 2013 Mac Pro&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/SpiGAndromeda"&gt;SpiGAndromeda&lt;/a&gt; - AMD Vega 64&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/turbomacs"&gt;turbomacs&lt;/a&gt; - 2014 5k iMac&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://forums.macrumors.com/members/vinaypundith.1212357/"&gt;vinaypundith&lt;/a&gt; - MacBook7,1&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ThatStella7922"&gt;ThatStella7922&lt;/a&gt; - 2017 13" MacBook Pro (A1708)&lt;/li&gt; 
   &lt;li&gt;zephar - 2008 Mac Pro&lt;/li&gt; 
   &lt;li&gt;jazo97 - 2011 15" MacBook Pro&lt;/li&gt; 
   &lt;li&gt;And others (reach out if we forgot you!)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;MacRumors and Unsupported Mac Communities 
  &lt;ul&gt; 
   &lt;li&gt;Endless testing and reporting issues&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Apple 
  &lt;ul&gt; 
   &lt;li&gt;for macOS and many of the kexts, frameworks and other binaries we reimplemented into newer OSes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>city96/ComfyUI-GGUF</title>
      <link>https://github.com/city96/ComfyUI-GGUF</link>
      <description>&lt;p&gt;GGUF Quantization support for native ComfyUI models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI-GGUF&lt;/h1&gt; 
&lt;p&gt;GGUF Quantization support for native ComfyUI models&lt;/p&gt; 
&lt;p&gt;This is currently very much WIP. These custom nodes provide support for model files stored in the GGUF format popularized by &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;While quantization wasn't feasible for regular UNET models (conv2d), transformer/DiT models such as flux seem less affected by quantization. This allows running it in much lower bits per weight variable bitrate quants on low-end GPUs. For further VRAM savings, a node to load a quantized version of the T5 text encoder is also included.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/70d16d97-c522-4ef4-9435-633f128644c8" alt="Comfy_Flux1_dev_Q4_0_GGUF_1024" /&gt;&lt;/p&gt; 
&lt;p&gt;Note: The "Force/Set CLIP Device" is &lt;strong&gt;NOT&lt;/strong&gt; part of this node pack. Do not install it if you only have one GPU. Do not set it to cuda:0 then complain about OOM errors if you do not undestand what it is for. There is not need to copy the workflow above, just use your own workflow and replace the stock "Load Diffusion Model" with the "Unet Loader (GGUF)" node.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;br /&gt; Make sure your ComfyUI is on a recent-enough version to support custom ops when loading the UNET-only.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To install the custom node normally, git clone this repository into your custom nodes folder (&lt;code&gt;ComfyUI/custom_nodes&lt;/code&gt;) and install the only dependency for inference (&lt;code&gt;pip install --upgrade gguf&lt;/code&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/city96/ComfyUI-GGUF
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install the custom node on a standalone ComfyUI release, open a CMD inside the "ComfyUI_windows_portable" folder (where your &lt;code&gt;run_nvidia_gpu.bat&lt;/code&gt; file is) and use the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/city96/ComfyUI-GGUF ComfyUI/custom_nodes/ComfyUI-GGUF
.\python_embeded\python.exe -s -m pip install -r .\ComfyUI\custom_nodes\ComfyUI-GGUF\requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On MacOS sequoia, torch 2.4.1 seems to be required, as 2.6.X nightly versions cause a "M1 buffer is not large enough" error. See &lt;a href="https://github.com/city96/ComfyUI-GGUF/issues/107"&gt;this issue&lt;/a&gt; for more information/workarounds.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Simply use the GGUF Unet loader found under the &lt;code&gt;bootleg&lt;/code&gt; category. Place the .gguf model files in your &lt;code&gt;ComfyUI/models/unet&lt;/code&gt; folder.&lt;/p&gt; 
&lt;p&gt;LoRA loading is experimental but it should work with just the built-in LoRA loader node(s).&lt;/p&gt; 
&lt;p&gt;Pre-quantized models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/city96/FLUX.1-dev-gguf"&gt;flux1-dev GGUF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/city96/FLUX.1-schnell-gguf"&gt;flux1-schnell GGUF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/city96/stable-diffusion-3.5-large-gguf"&gt;stable-diffusion-3.5-large GGUF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/city96/stable-diffusion-3.5-large-turbo-gguf"&gt;stable-diffusion-3.5-large-turbo GGUF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Initial support for quantizing T5 has also been added recently, these can be used using the various &lt;code&gt;*CLIPLoader (gguf)&lt;/code&gt; nodes which can be used inplace of the regular ones. For the CLIP model, use whatever model you were using before for CLIP. The loader can handle both types of files - &lt;code&gt;gguf&lt;/code&gt; and regular &lt;code&gt;safetensors&lt;/code&gt;/&lt;code&gt;bin&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf"&gt;t5_v1.1-xxl GGUF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the instructions in the &lt;a href="https://github.com/city96/ComfyUI-GGUF/tree/main/tools"&gt;tools&lt;/a&gt; folder for how to create your own quants.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>unslothai/unsloth</title>
      <link>https://github.com/unslothai/unsloth</link>
      <description>&lt;p&gt;Fine-tuning &amp; Reinforcement Learning for LLMs. ü¶• Train OpenAI gpt-oss, DeepSeek-R1, Qwen3, Gemma 3, TTS 2x faster with 70% less VRAM.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://docs.unsloth.ai"&gt;
   &lt;picture&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20white%20text.png" /&gt; 
    &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png" /&gt; 
    &lt;img alt="unsloth logo" src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png" height="110" style="max-width: 100%;" /&gt; 
   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-Fine-tuning.ipynb"&gt;&lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/start free finetune button.png" width="154" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/unsloth"&gt;&lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord button.png" width="165" /&gt;&lt;/a&gt; &lt;a href="https://docs.unsloth.ai"&gt;&lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/refs/heads/main/images/Documentation%20Button.png" width="137" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;Train gpt-oss, DeepSeek, Gemma, Qwen &amp;amp; Llama 2x faster with 70% less VRAM!&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://i.ibb.co/sJ7RhGG/image-41.png" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ú® Train for Free&lt;/h2&gt; 
&lt;p&gt;Notebooks are beginner friendly. Read our &lt;a href="https://docs.unsloth.ai/get-started/fine-tuning-guide"&gt;guide&lt;/a&gt;. Add dataset, run, then export your trained model to GGUF, llama.cpp, Ollama, vLLM, SGLang or Hugging Face.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Free Notebooks&lt;/th&gt; 
   &lt;th&gt;Performance&lt;/th&gt; 
   &lt;th&gt;Memory use&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;gpt-oss (20B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-Fine-tuning.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Mistral Ministral 3 (3B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Ministral_3_VL_(3B)_Vision.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;60% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;gpt-oss (20B): GRPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;80% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Qwen3: Advanced GRPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-GRPO.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;50% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Qwen3-VL (8B): GSPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_VL_(8B)-Vision-GRPO.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;80% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gemma 3 (270M)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_(270M).ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.7x faster&lt;/td&gt; 
   &lt;td&gt;60% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gemma 3n (4B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;50% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;DeepSeek-OCR (3B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Deepseek_OCR_(3B).ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;30% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Llama 3.1 (8B) Alpaca&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Llama 3.2 Conversational&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Orpheus-TTS (3B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Orpheus_(3B)-TTS.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;50% less&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;See all our notebooks for: &lt;a href="https://github.com/unslothai/notebooks?tab=readme-ov-file#-kaggle-notebooks"&gt;Kaggle&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#grpo-reasoning-rl-notebooks"&gt;GRPO&lt;/a&gt;, &lt;strong&gt;&lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#text-to-speech-tts-notebooks"&gt;TTS&lt;/a&gt;&lt;/strong&gt; &amp;amp; &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#vision-multimodal-notebooks"&gt;Vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://docs.unsloth.ai/get-started/all-our-models"&gt;all our models&lt;/a&gt; and &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks"&gt;all our notebooks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See detailed documentation for Unsloth &lt;a href="https://docs.unsloth.ai/"&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Quickstart&lt;/h2&gt; 
&lt;h3&gt;Linux or WSL&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;For Windows, &lt;code&gt;pip install unsloth&lt;/code&gt; works only if you have Pytorch installed. Read our &lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating/windows-installation"&gt;Windows Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Use our official &lt;a href="https://hub.docker.com/r/unsloth/unsloth"&gt;Unsloth Docker image&lt;/a&gt; &lt;code&gt;unsloth/unsloth&lt;/code&gt; container. Read our &lt;a href="https://docs.unsloth.ai/get-started/install-and-update/docker"&gt;Docker Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Blackwell &amp;amp; DGX Spark&lt;/h3&gt; 
&lt;p&gt;For RTX 50x, B200, 6000 GPUs: &lt;code&gt;pip install unsloth&lt;/code&gt;. Read our &lt;a href="https://docs.unsloth.ai/basics/training-llms-with-blackwell-rtx-50-series-and-unsloth"&gt;Blackwell Guide&lt;/a&gt; and &lt;a href="https://docs.unsloth.ai/new/fine-tuning-llms-with-nvidia-dgx-spark-and-unsloth"&gt;DGX Spark Guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;ü¶• Unsloth News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;New RoPE &amp;amp; MLP &lt;strong&gt;Triton Kernels&lt;/strong&gt; &amp;amp; &lt;strong&gt;Padding Free + Packing&lt;/strong&gt;: 3x faster training &amp;amp; 30% less VRAM. &lt;a href="https://docs.unsloth.ai/new/3x-faster-training-packing"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ministral 3&lt;/strong&gt; by Mistral: Run Ministral 3 or fine-tune with vision/RL sodoku notebooks. &lt;a href="https://docs.unsloth.ai/new/ministral-3"&gt;Guide&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.unsloth.ai/new/ministral-3#fine-tuningb"&gt;Notebooks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;500K Context&lt;/strong&gt;: Training a 20B model with &amp;gt;500K context is now possible on an 80GB GPU. &lt;a href="https://docs.unsloth.ai/new/500k-context-length-fine-tuning"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FP8 Reinforcement Learning&lt;/strong&gt;: You can now do FP8 GRPO on consumer GPUs. &lt;a href="https://docs.unsloth.ai/new/fp8-reinforcement-learning"&gt;Blog&lt;/a&gt; ‚Ä¢ &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_8B_FP8_GRPO.ipynb"&gt;Notebook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeek-OCR&lt;/strong&gt;: Fine-tune to improve language understanding by 89%. &lt;a href="https://docs.unsloth.ai/new/deepseek-ocr-run-and-fine-tune"&gt;Guide&lt;/a&gt; ‚Ä¢ &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Deepseek_OCR_(3B).ipynb"&gt;Notebook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Use Unsloth with no setup &amp;amp; environment issues with our new image. &lt;a href="https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker"&gt;Guide&lt;/a&gt; ‚Ä¢ &lt;a href="https://hub.docker.com/r/unsloth/unsloth"&gt;Docker image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;gpt-oss RL&lt;/strong&gt;: Introducing the fastest possible inference for gpt-oss RL! &lt;a href="https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning"&gt;Read blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vision RL&lt;/strong&gt;: You can now train VLMs with GRPO or GSPO in Unsloth! &lt;a href="https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl"&gt;Read guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;gpt-oss&lt;/strong&gt; by OpenAI: Read our &lt;a href="https://docs.unsloth.ai/new/long-context-gpt-oss-training"&gt;Unsloth Flex Attention&lt;/a&gt; blog and &lt;a href="https://docs.unsloth.ai/basics/gpt-oss"&gt;gpt-oss Guide&lt;/a&gt;. 20B works on 14GB VRAM. 120B on 65GB.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click for more news&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Quantization-Aware Training&lt;/strong&gt;: We collabed with Pytorch, recovering ~70% accuracy. &lt;a href="https://docs.unsloth.ai/new/quantization-aware-training-qat"&gt;Read blog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Memory-efficient RL&lt;/strong&gt;: We're introducing even better RL. Our new kernels &amp;amp; algos allows faster RL with 50% less VRAM &amp;amp; 10√ó more context. &lt;a href="https://docs.unsloth.ai/new/memory-efficient-rl"&gt;Read blog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Gemma 3n&lt;/strong&gt; by Google: &lt;a href="https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-tune"&gt;Read Blog&lt;/a&gt;. We &lt;a href="https://huggingface.co/collections/unsloth/gemma-3n-685d3874830e49e1c93f9339"&gt;uploaded GGUFs, 4-bit models&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning"&gt;Text-to-Speech (TTS)&lt;/a&gt;&lt;/strong&gt; is now supported, including &lt;code&gt;sesame/csm-1b&lt;/code&gt; and STT &lt;code&gt;openai/whisper-large-v3&lt;/code&gt;.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune"&gt;Qwen3&lt;/a&gt;&lt;/strong&gt; is now supported. Qwen3-30B-A3B fits on 17.5GB VRAM.&lt;/li&gt; 
  &lt;li&gt;Introducing &lt;strong&gt;&lt;a href="https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs"&gt;Dynamic 2.0&lt;/a&gt;&lt;/strong&gt; quants that set new benchmarks on 5-shot MMLU &amp;amp; Aider Polyglot.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://unsloth.ai/blog/gemma3#everything"&gt;&lt;strong&gt;EVERYTHING&lt;/strong&gt; is now supported&lt;/a&gt; - all models (TTS, BERT, Mamba), FFT, etc. &lt;a href="https://docs.unsloth.ai/basics/multi-gpu-training-with-unsloth"&gt;MultiGPU&lt;/a&gt; coming soon. Enable FFT with &lt;code&gt;full_finetuning = True&lt;/code&gt;, 8-bit with &lt;code&gt;load_in_8bit = True&lt;/code&gt;.&lt;/li&gt; 
  &lt;li&gt;üì£ &lt;a href="https://unsloth.ai/blog/deepseek-r1"&gt;DeepSeek-R1&lt;/a&gt; - run or fine-tune them &lt;a href="https://unsloth.ai/blog/deepseek-r1"&gt;with our guide&lt;/a&gt;. All model uploads: &lt;a href="https://huggingface.co/collections/unsloth/deepseek-r1-all-versions-678e1c48f5d2fce87892ace5"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;üì£ Introducing Long-context &lt;a href="https://unsloth.ai/blog/grpo"&gt;Reasoning (GRPO)&lt;/a&gt; in Unsloth. Train your own reasoning model with just 5GB VRAM. Transform Llama, Phi, Mistral etc. into reasoning LLMs!&lt;/li&gt; 
  &lt;li&gt;üì£ Introducing Unsloth &lt;a href="https://unsloth.ai/blog/dynamic-4bit"&gt;Dynamic 4-bit Quantization&lt;/a&gt;! We dynamically opt not to quantize certain parameters and this greatly increases accuracy while only using &amp;lt;10% more VRAM than BnB 4-bit. See our collection on &lt;a href="https://huggingface.co/collections/unsloth/unsloth-4-bit-dynamic-quants-67503bb873f89e15276c44e7"&gt;Hugging Face here.&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üì£ &lt;strong&gt;&lt;a href="https://unsloth.ai/blog/llama4"&gt;Llama 4&lt;/a&gt;&lt;/strong&gt; by Meta, including Scout &amp;amp; Maverick are now supported.&lt;/li&gt; 
  &lt;li&gt;üì£ &lt;a href="https://unsloth.ai/blog/phi4"&gt;Phi-4&lt;/a&gt; by Microsoft: We also &lt;a href="https://unsloth.ai/blog/phi4"&gt;fixed bugs&lt;/a&gt; in Phi-4 and &lt;a href="https://huggingface.co/collections/unsloth/phi-4-all-versions-677eecf93784e61afe762afa"&gt;uploaded GGUFs, 4-bit&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;üì£ &lt;a href="https://unsloth.ai/blog/vision"&gt;Vision models&lt;/a&gt; now supported! &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb"&gt;Llama 3.2 Vision (11B)&lt;/a&gt;, &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_VL_(7B)-Vision.ipynb"&gt;Qwen 2.5 VL (7B)&lt;/a&gt; and &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Pixtral_(12B)-Vision.ipynb"&gt;Pixtral (12B) 2409&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üì£ &lt;a href="https://huggingface.co/collections/unsloth/llama-33-all-versions-67535d7d994794b9d7cf5e9f"&gt;Llama 3.3 (70B)&lt;/a&gt;, Meta's latest model is supported.&lt;/li&gt; 
  &lt;li&gt;üì£ We worked with Apple to add &lt;a href="https://arxiv.org/abs/2411.09009"&gt;Cut Cross Entropy&lt;/a&gt;. Unsloth now supports 89K context for Meta's Llama 3.3 (70B) on a 80GB GPU - 13x longer than HF+FA2. For Llama 3.1 (8B), Unsloth enables 342K context, surpassing its native 128K support.&lt;/li&gt; 
  &lt;li&gt;üì£ We found and helped fix a &lt;a href="https://unsloth.ai/blog/gradient"&gt;gradient accumulation bug&lt;/a&gt;! Please update Unsloth and transformers.&lt;/li&gt; 
  &lt;li&gt;üì£ We cut memory usage by a &lt;a href="https://unsloth.ai/blog/long-context"&gt;further 30%&lt;/a&gt; and now support &lt;a href="https://unsloth.ai/blog/long-context"&gt;4x longer context windows&lt;/a&gt;!&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üîó Links and Resources&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Links&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img width="15" src="https://redditinc.com/hs-fs/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png" /&gt;&amp;nbsp; &lt;strong&gt;r/unsloth Reddit&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://reddit.com/r/unsloth"&gt;Join Reddit community&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üìö &lt;strong&gt;Documentation &amp;amp; Wiki&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.unsloth.ai"&gt;Read Our Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img width="16" src="https://upload.wikimedia.org/wikipedia/commons/6/6f/Logo_of_Twitter.svg?sanitize=true" /&gt;&amp;nbsp; &lt;strong&gt;Twitter (aka X)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/unslothai"&gt;Follow us on X&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üíæ &lt;strong&gt;Installation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating"&gt;Pip &amp;amp; Docker Install&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîÆ &lt;strong&gt;Our Models&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.unsloth.ai/get-started/all-our-models"&gt;Unsloth Catalog&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚úçÔ∏è &lt;strong&gt;Blog&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://unsloth.ai/blog"&gt;Read our Blogs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚≠ê Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports &lt;strong&gt;full-finetuning&lt;/strong&gt;, pretraining, 4b-bit, 16-bit and &lt;strong&gt;FP8&lt;/strong&gt; training&lt;/li&gt; 
 &lt;li&gt;Supports &lt;strong&gt;all models&lt;/strong&gt; including &lt;a href="https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning"&gt;TTS&lt;/a&gt;, multimodal, &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#other-important-notebooks"&gt;BERT&lt;/a&gt; and more! Any model that works in transformers, works in Unsloth.&lt;/li&gt; 
 &lt;li&gt;The most efficient library for &lt;a href="https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide"&gt;Reinforcement Learning (RL)&lt;/a&gt;, using 80% less VRAM. Supports GRPO, GSPO, DrGRPO, DAPO etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;0% loss in accuracy&lt;/strong&gt; - no approximation methods - all exact.&lt;/li&gt; 
 &lt;li&gt;Supports NVIDIA (since 2018), &lt;a href="https://docs.unsloth.ai/get-started/install-and-update/amd"&gt;AMD&lt;/a&gt; and Intel GPUs. Minimum CUDA Capability 7.0 (V100, T4, Titan V, RTX 20, 30, 40x, A100, H100, L40 etc)&lt;/li&gt; 
 &lt;li&gt;Works on &lt;strong&gt;Linux&lt;/strong&gt;, WSL and &lt;strong&gt;Windows&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;All kernels written in &lt;a href="https://openai.com/index/triton/"&gt;OpenAI's Triton&lt;/a&gt; language. Manual backprop engine.&lt;/li&gt; 
 &lt;li&gt;If you trained a model with ü¶•Unsloth, you can use this cool sticker! &amp;nbsp; &lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/made with unsloth.png" width="200" align="center" /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíæ Install Unsloth&lt;/h2&gt; 
&lt;p&gt;You can also see our docs for more detailed installation and updating instructions &lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unsloth supports Python 3.13 or lower.&lt;/p&gt; 
&lt;h3&gt;Pip Installation&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Install with pip (recommended) for Linux devices:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To update Unsloth:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/unslothai/unsloth/main/#advanced-pip-installation"&gt;here&lt;/a&gt; for advanced pip install instructions.&lt;/p&gt; 
&lt;h3&gt;Windows Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install NVIDIA Video Driver:&lt;/strong&gt; You should install the latest driver for your GPU. Download drivers here: &lt;a href="https://www.nvidia.com/Download/index.aspx"&gt;NVIDIA GPU Driver&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install Visual Studio C++:&lt;/strong&gt; You will need Visual Studio, with C++ installed. By default, C++ is not installed with &lt;a href="https://visualstudio.microsoft.com/vs/community/"&gt;Visual Studio&lt;/a&gt;, so make sure you select all of the C++ options. Also select options for Windows 10/11 SDK. For detailed instructions with options, see &lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install CUDA Toolkit:&lt;/strong&gt; Follow the instructions to install &lt;a href="https://developer.nvidia.com/cuda-toolkit-archive"&gt;CUDA Toolkit&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install PyTorch:&lt;/strong&gt; You will need the correct version of PyTorch that is compatible with your CUDA drivers, so make sure to select them carefully. &lt;a href="https://pytorch.org/get-started/locally/"&gt;Install PyTorch&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install Unsloth:&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Notes&lt;/h4&gt; 
&lt;p&gt;To run Unsloth directly on Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install Triton from this Windows fork and follow the instructions &lt;a href="https://github.com/woct0rdho/triton-windows"&gt;here&lt;/a&gt; (be aware that the Windows fork requires PyTorch &amp;gt;= 2.4 and CUDA 12)&lt;/li&gt; 
 &lt;li&gt;In the &lt;code&gt;SFTConfig&lt;/code&gt;, set &lt;code&gt;dataset_num_proc=1&lt;/code&gt; to avoid a crashing issue:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;SFTConfig(
    dataset_num_proc=1,
    ...
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Advanced/Troubleshooting&lt;/h4&gt; 
&lt;p&gt;For &lt;strong&gt;advanced installation instructions&lt;/strong&gt; or if you see weird errors during installations:&lt;/p&gt; 
&lt;p&gt;First try using an isolated environment via then &lt;code&gt;pip install unsloth&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv unsloth
source unsloth/bin/activate
pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install &lt;code&gt;torch&lt;/code&gt; and &lt;code&gt;triton&lt;/code&gt;. Go to &lt;a href="https://pytorch.org"&gt;https://pytorch.org&lt;/a&gt; to install it. For example &lt;code&gt;pip install torch torchvision torchaudio triton&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Confirm if CUDA is installed correctly. Try &lt;code&gt;nvcc&lt;/code&gt;. If that fails, you need to install &lt;code&gt;cudatoolkit&lt;/code&gt; or CUDA drivers.&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;xformers&lt;/code&gt; manually via:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install ninja
pip install -v --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;Check if `xformers` succeeded with `python -m xformers.info` Go to https://github.com/facebookresearch/xformers. Another option is to install `flash-attn` for Ampere GPUs and ignore `xformers`
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;For GRPO runs, you can try installing &lt;code&gt;vllm&lt;/code&gt; and seeing if &lt;code&gt;pip install vllm&lt;/code&gt; succeeds.&lt;/li&gt; 
 &lt;li&gt;Double check that your versions of Python, CUDA, CUDNN, &lt;code&gt;torch&lt;/code&gt;, &lt;code&gt;triton&lt;/code&gt;, and &lt;code&gt;xformers&lt;/code&gt; are compatible with one another. The &lt;a href="https://github.com/pytorch/pytorch/raw/main/RELEASE.md#release-compatibility-matrix"&gt;PyTorch Compatibility Matrix&lt;/a&gt; may be useful.&lt;/li&gt; 
 &lt;li&gt;Finally, install &lt;code&gt;bitsandbytes&lt;/code&gt; and check it with &lt;code&gt;python -m bitsandbytes&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Conda Installation (Optional)&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;‚ö†Ô∏èOnly use Conda if you have it. If not, use Pip&lt;/code&gt;. Select either &lt;code&gt;pytorch-cuda=11.8,12.1&lt;/code&gt; for CUDA 11.8 or CUDA 12.1. We support &lt;code&gt;python=3.10,3.11,3.12&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create --name unsloth_env \
    python=3.11 \
    pytorch-cuda=12.1 \
    pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers \
    -y
conda activate unsloth_env

pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;If you're looking to install Conda in a Linux environment, &lt;a href="https://docs.anaconda.com/miniconda/"&gt;read here&lt;/a&gt;, or run the below üîΩ&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
~/miniconda3/bin/conda init zsh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Advanced Pip Installation&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;‚ö†Ô∏èDo **NOT** use this if you have Conda.&lt;/code&gt; Pip is a bit more complex since there are dependency issues. The pip command is different for &lt;code&gt;torch 2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9&lt;/code&gt; and CUDA versions.&lt;/p&gt; 
&lt;p&gt;For other torch versions, we support &lt;code&gt;torch211&lt;/code&gt;, &lt;code&gt;torch212&lt;/code&gt;, &lt;code&gt;torch220&lt;/code&gt;, &lt;code&gt;torch230&lt;/code&gt;, &lt;code&gt;torch240&lt;/code&gt;, &lt;code&gt;torch250&lt;/code&gt;, &lt;code&gt;torch260&lt;/code&gt;, &lt;code&gt;torch270&lt;/code&gt;, &lt;code&gt;torch280&lt;/code&gt;, &lt;code&gt;torch290&lt;/code&gt; and for CUDA versions, we support &lt;code&gt;cu118&lt;/code&gt; and &lt;code&gt;cu121&lt;/code&gt; and &lt;code&gt;cu124&lt;/code&gt;. For Ampere devices (A100, H100, RTX3090) and above, use &lt;code&gt;cu118-ampere&lt;/code&gt; or &lt;code&gt;cu121-ampere&lt;/code&gt; or &lt;code&gt;cu124-ampere&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, if you have &lt;code&gt;torch 2.4&lt;/code&gt; and &lt;code&gt;CUDA 12.1&lt;/code&gt;, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade pip
pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Another example, if you have &lt;code&gt;torch 2.9&lt;/code&gt; and &lt;code&gt;CUDA 13.0&lt;/code&gt;, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade pip
pip install "unsloth[cu130-torch290] @ git+https://github.com/unslothai/unsloth.git"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And other examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "unsloth[cu121-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu118-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu118-torch240] @ git+https://github.com/unslothai/unsloth.git"

pip install "unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu121-ampere-torch230] @ git+https://github.com/unslothai/unsloth.git"

pip install "unsloth[cu121-torch250] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu124-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, run the below in a terminal to get the &lt;strong&gt;optimal&lt;/strong&gt; pip installation command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget -qO- https://raw.githubusercontent.com/unslothai/unsloth/main/unsloth/_auto_install.py | python -
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, run the below manually in a Python REPL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;try: import torch
except: raise ImportError('Install torch via `pip install torch`')
from packaging.version import Version as V
import re
v = V(re.match(r"[0-9\.]{3,}", torch.__version__).group(0))
cuda = str(torch.version.cuda)
is_ampere = torch.cuda.get_device_capability()[0] &amp;gt;= 8
USE_ABI = torch._C._GLIBCXX_USE_CXX11_ABI
if cuda not in ("11.8", "12.1", "12.4", "12.6", "12.8", "13.0"): raise RuntimeError(f"CUDA = {cuda} not supported!")
if   v &amp;lt;= V('2.1.0'): raise RuntimeError(f"Torch = {v} too old!")
elif v &amp;lt;= V('2.1.1'): x = 'cu{}{}-torch211'
elif v &amp;lt;= V('2.1.2'): x = 'cu{}{}-torch212'
elif v  &amp;lt; V('2.3.0'): x = 'cu{}{}-torch220'
elif v  &amp;lt; V('2.4.0'): x = 'cu{}{}-torch230'
elif v  &amp;lt; V('2.5.0'): x = 'cu{}{}-torch240'
elif v  &amp;lt; V('2.5.1'): x = 'cu{}{}-torch250'
elif v &amp;lt;= V('2.5.1'): x = 'cu{}{}-torch251'
elif v  &amp;lt; V('2.7.0'): x = 'cu{}{}-torch260'
elif v  &amp;lt; V('2.7.9'): x = 'cu{}{}-torch270'
elif v  &amp;lt; V('2.8.0'): x = 'cu{}{}-torch271'
elif v  &amp;lt; V('2.8.9'): x = 'cu{}{}-torch280'
elif v  &amp;lt; V('2.9.1'): x = 'cu{}{}-torch290'
elif v  &amp;lt; V('2.9.2'): x = 'cu{}{}-torch291'
else: raise RuntimeError(f"Torch = {v} too new!")
if v &amp;gt; V('2.6.9') and cuda not in ("11.8", "12.6", "12.8", "13.0"): raise RuntimeError(f"CUDA = {cuda} not supported!")
x = x.format(cuda.replace(".", ""), "-ampere" if False else "") # is_ampere is broken due to flash-attn
print(f'pip install --upgrade pip &amp;amp;&amp;amp; pip install --no-deps git+https://github.com/unslothai/unsloth-zoo.git &amp;amp;&amp;amp; pip install "unsloth[{x}] @ git+https://github.com/unslothai/unsloth.git" --no-build-isolation')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Installation&lt;/h3&gt; 
&lt;p&gt;You can use our pre-built Docker container with all dependencies to use Unsloth instantly with no setup required. &lt;a href="https://docs.unsloth.ai/get-started/install-and-update/docker"&gt;Read our guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This container requires installing &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html"&gt;NVIDIA's Container Toolkit&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -e JUPYTER_PASSWORD="mypassword" \
  -p 8888:8888 -p 2222:22 \
  -v $(pwd)/work:/workspace/work \
  --gpus all \
  unsloth/unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access Jupyter Lab at &lt;code&gt;http://localhost:8888&lt;/code&gt; and start fine-tuning!&lt;/p&gt; 
&lt;h2&gt;üìú Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to our official &lt;a href="https://docs.unsloth.ai"&gt;Documentation&lt;/a&gt; for &lt;a href="https://docs.unsloth.ai/basics/running-and-saving-models"&gt;running models&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/basics/running-and-saving-models/saving-to-gguf"&gt;saving to GGUF&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/basics/finetuning-from-last-checkpoint"&gt;checkpointing&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/get-started/fine-tuning-llms-guide#evaluation"&gt;evaluation&lt;/a&gt; and more!&lt;/li&gt; 
 &lt;li&gt;Read our Guides for: &lt;a href="https://docs.unsloth.ai/get-started/fine-tuning-llms-guide"&gt;Fine-tuning&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide"&gt;Reinforcement Learning&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning"&gt;Text-to-Speech (TTS)&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/basics/vision-fine-tuning"&gt;Vision&lt;/a&gt; and &lt;a href="https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms"&gt;any model&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We support Huggingface's transformers, TRL, Trainer, Seq2SeqTrainer and Pytorch code.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Unsloth example code to fine-tune gpt-oss-20b:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from unsloth import FastLanguageModel, FastModel
import torch
from trl import SFTTrainer, SFTConfig
from datasets import load_dataset
max_seq_length = 2048 # Supports RoPE Scaling internally, so choose any!
# Get LAION dataset
url = "https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl"
dataset = load_dataset("json", data_files = {"train" : url}, split = "train")

# 4bit pre quantized models we support for 4x faster downloading + no OOMs.
fourbit_models = [
    "unsloth/gpt-oss-20b-unsloth-bnb-4bit", #or choose any model

] # More models at https://huggingface.co/unsloth

model, tokenizer = FastModel.from_pretrained(
    model_name = "unsloth/gpt-oss-20b",
    max_seq_length = 2048, # Choose any for long context!
    load_in_4bit = True,  # 4-bit quantization. False = 16-bit LoRA.
    load_in_8bit = False, # 8-bit quantization
    load_in_16bit = False, # [NEW!] 16-bit LoRA
    full_finetuning = False, # Use for full fine-tuning.
    # token = "hf_...", # use one if using gated models
)

# Do model patching and add fast LoRA weights
model = FastLanguageModel.get_peft_model(
    model,
    r = 16,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 16,
    lora_dropout = 0, # Supports any, but = 0 is optimized
    bias = "none",    # Supports any, but = "none" is optimized
    # [NEW] "unsloth" uses 30% less VRAM, fits 2x larger batch sizes!
    use_gradient_checkpointing = "unsloth", # True or "unsloth" for very long context
    random_state = 3407,
    max_seq_length = max_seq_length,
    use_rslora = False,  # We support rank stabilized LoRA
    loftq_config = None, # And LoftQ
)

trainer = SFTTrainer(
    model = model,
    train_dataset = dataset,
    tokenizer = tokenizer,
    args = SFTConfig(
        max_seq_length = max_seq_length,
        per_device_train_batch_size = 2,
        gradient_accumulation_steps = 4,
        warmup_steps = 10,
        max_steps = 60,
        logging_steps = 1,
        output_dir = "outputs",
        optim = "adamw_8bit",
        seed = 3407,
    ),
)
trainer.train()

# Go to https://docs.unsloth.ai for advanced tips like
# (1) Saving to GGUF / merging to 16bit for vLLM or SGLang
# (2) Continued training from a saved LoRA adapter
# (3) Adding an evaluation loop / OOMs
# (4) Customized chat templates
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a name="RL"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üí° Reinforcement Learning&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide"&gt;RL&lt;/a&gt; including &lt;a href="https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide#training-with-grpo"&gt;GRPO&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide/gspo-reinforcement-learning"&gt;GSPO&lt;/a&gt;, &lt;strong&gt;FP8&lt;/strong&gt; traning, DrGRPO, DAPO, PPO, Reward Modelling, Online DPO all work with Unsloth. Read our &lt;a href="https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide"&gt;Reinforcement Learning Guide&lt;/a&gt; or our &lt;a href="https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide/advanced-rl-documentation"&gt;advanced RL docs&lt;/a&gt; for batching, generation &amp;amp; training parameters.&lt;/p&gt; 
&lt;p&gt;List of RL notebooks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;gpt-oss GSPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Qwen2.5-VL GSPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_5_7B_VL_GRPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Advanced Qwen3 GRPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-GRPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;&lt;strong&gt;FP8&lt;/strong&gt;&lt;/em&gt; Qwen3-8B GRPO notebook (L4): &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_8B_FP8_GRPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ORPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-ORPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DPO Zephyr notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Zephyr_(7B)-DPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;KTO notebook: &lt;a href="https://colab.research.google.com/drive/1MRgGtLWuZX4ypSfGguFgC-IblTvO2ivM?usp=sharing"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SimPO notebook: &lt;a href="https://colab.research.google.com/drive/1Hs5oQDovOay4mFA6Y9lQhVJ8TnbFLFh2?usp=sharing"&gt;Link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü•á Performance Benchmarking&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For our most detailed benchmarks, read our &lt;a href="https://unsloth.ai/blog/llama3-3"&gt;Llama 3.3 Blog&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Benchmarking of Unsloth was also conducted by &lt;a href="https://huggingface.co/blog/unsloth-trl"&gt;ü§óHugging Face&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We tested using the Alpaca Dataset, a batch size of 2, gradient accumulation steps of 4, rank = 32, and applied QLoRA on all linear layers (q, k, v, o, gate, up, down):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;VRAM&lt;/th&gt; 
   &lt;th&gt;ü¶• Unsloth speed&lt;/th&gt; 
   &lt;th&gt;ü¶• VRAM reduction&lt;/th&gt; 
   &lt;th&gt;ü¶• Longer context&lt;/th&gt; 
   &lt;th&gt;üòä Hugging Face + FA2&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.3 (70B)&lt;/td&gt; 
   &lt;td&gt;80GB&lt;/td&gt; 
   &lt;td&gt;2x&lt;/td&gt; 
   &lt;td&gt;&amp;gt;75%&lt;/td&gt; 
   &lt;td&gt;13x longer&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1 (8B)&lt;/td&gt; 
   &lt;td&gt;80GB&lt;/td&gt; 
   &lt;td&gt;2x&lt;/td&gt; 
   &lt;td&gt;&amp;gt;70%&lt;/td&gt; 
   &lt;td&gt;12x longer&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Context length benchmarks&lt;/h3&gt; 
&lt;h4&gt;Llama 3.1 (8B) max. context length&lt;/h4&gt; 
&lt;p&gt;We tested Llama 3.1 (8B) Instruct and did 4bit QLoRA on all linear layers (Q, K, V, O, gate, up and down) with rank = 32 with a batch size of 1. We padded all sequences to a certain maximum sequence length to mimic long context finetuning workloads.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;GPU VRAM&lt;/th&gt; 
   &lt;th&gt;ü¶•Unsloth context length&lt;/th&gt; 
   &lt;th&gt;Hugging Face + FA2&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8 GB&lt;/td&gt; 
   &lt;td&gt;2,972&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12 GB&lt;/td&gt; 
   &lt;td&gt;21,848&lt;/td&gt; 
   &lt;td&gt;932&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16 GB&lt;/td&gt; 
   &lt;td&gt;40,724&lt;/td&gt; 
   &lt;td&gt;2,551&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24 GB&lt;/td&gt; 
   &lt;td&gt;78,475&lt;/td&gt; 
   &lt;td&gt;5,789&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;40 GB&lt;/td&gt; 
   &lt;td&gt;153,977&lt;/td&gt; 
   &lt;td&gt;12,264&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;48 GB&lt;/td&gt; 
   &lt;td&gt;191,728&lt;/td&gt; 
   &lt;td&gt;15,502&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;80 GB&lt;/td&gt; 
   &lt;td&gt;342,733&lt;/td&gt; 
   &lt;td&gt;28,454&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Llama 3.3 (70B) max. context length&lt;/h4&gt; 
&lt;p&gt;We tested Llama 3.3 (70B) Instruct on a 80GB A100 and did 4bit QLoRA on all linear layers (Q, K, V, O, gate, up and down) with rank = 32 with a batch size of 1. We padded all sequences to a certain maximum sequence length to mimic long context finetuning workloads.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;GPU VRAM&lt;/th&gt; 
   &lt;th&gt;ü¶•Unsloth context length&lt;/th&gt; 
   &lt;th&gt;Hugging Face + FA2&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;48 GB&lt;/td&gt; 
   &lt;td&gt;12,106&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;80 GB&lt;/td&gt; 
   &lt;td&gt;89,389&lt;/td&gt; 
   &lt;td&gt;6,916&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://i.ibb.co/sJ7RhGG/image-41.png" alt="" /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Citation&lt;/h3&gt; 
&lt;p&gt;You can cite the Unsloth repo as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{unsloth,
  author = {Daniel Han, Michael Han and Unsloth team},
  title = {Unsloth},
  url = {http://github.com/unslothai/unsloth},
  year = {2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Thank You to&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp library&lt;/a&gt; that lets users save models with Unsloth&lt;/li&gt; 
 &lt;li&gt;The Hugging Face team and their libraries: &lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt; and &lt;a href="https://github.com/huggingface/trl"&gt;TRL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The Pytorch and &lt;a href="https://github.com/unslothai/unsloth/pull/3391"&gt;Torch AO&lt;/a&gt; team for their contributions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/erikwijmans"&gt;Erik&lt;/a&gt; for his help adding &lt;a href="https://github.com/apple/ml-cross-entropy"&gt;Apple's ML Cross Entropy&lt;/a&gt; in Unsloth&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Etherll"&gt;Etherl&lt;/a&gt; for adding support for &lt;a href="https://github.com/unslothai/notebooks/pull/34"&gt;TTS, diffusion and BERT models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;And of course for every single person who has contributed or has used Unsloth!&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>exo-explore/exo</title>
      <link>https://github.com/exo-explore/exo</link>
      <description>&lt;p&gt;Run your own AI cluster at home with everyday devices üì±üíª üñ•Ô∏è‚åö&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/exo-logo-black-bg.jpg" /&gt; 
  &lt;img alt="exo logo" src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/exo-logo-transparent.png" width="50%" height="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;exo: Run your own AI cluster at home with everyday devices. Maintained by &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://discord.gg/72NsF6ux" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/exolabs" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/exolabs?style=social" alt="X" /&gt;&lt;/a&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0.html" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/License-Apache2.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;exo connects all your devices into an AI cluster. Not only does exo enable running models larger than would fit on a single device, but with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt&lt;/a&gt;, makes models run faster as you add more devices.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Device Discovery&lt;/strong&gt;: Devices running exo automatically discover each other - no manual configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RDMA over Thunderbolt&lt;/strong&gt;: exo ships with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt 5&lt;/a&gt;, enabling 99% reduction in latency between devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Topology-Aware Auto Parallel&lt;/strong&gt;: exo figures out the best way to split your model across all available devices based on a realtime view of your device topology. It takes into account device resources and network latency/bandwidth between each link.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;: exo supports sharding models, for up to 1.8x speedup on 2 devices and 3.2x speedup on 4 devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MLX Support&lt;/strong&gt;: exo uses &lt;a href="https://github.com/ml-explore/mlx"&gt;MLX&lt;/a&gt; as an inference backend and &lt;a href="https://ml-explore.github.io/mlx/build/html/usage/distributed.html"&gt;MLX distributed&lt;/a&gt; for distributed communication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qwen3-235B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-1-qwen3-235b.jpeg" alt="Benchmark - Qwen3-235B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;DeepSeek v3.1 671B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-2-deepseek-3.1-671b.jpeg" alt="Benchmark - DeepSeek v3.1 671B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Kimi K2 Thinking (native 4-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-3-kimi-k2-thinking.jpeg" alt="Benchmark - Kimi K2 Thinking (native 4-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Devices running exo automatically discover each other, without needing any manual configuration. Each device provides an API and a dashboard for interacting with your cluster (runs at &lt;code&gt;http://localhost:52415&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;There are two ways to run exo:&lt;/p&gt; 
&lt;h3&gt;Run from Source (Mac &amp;amp; Linux)&lt;/h3&gt; 
&lt;p&gt;Clone the repo, build the dashboard, and run exo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone exo
git clone https://github.com/exo-explore/exo

# Build dashboard
cd exo/dashboard &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; cd ..

# Run exo
uv run exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the exo dashboard and API at &lt;a href="http://localhost:52415/"&gt;http://localhost:52415/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;macOS App&lt;/h3&gt; 
&lt;p&gt;exo ships a macOS app that runs in the background on your Mac.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/macos-app-one-macbook.png" alt="exo macOS App - running on a MacBook" width="35%" /&gt; 
&lt;p&gt;The macOS app requires macOS Tahoe 26.2 or later.&lt;/p&gt; 
&lt;p&gt;Download the latest build here: &lt;a href="https://assets.exolabs.net/EXO-latest.dmg"&gt;EXO-latest.dmg&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The app will ask for permission to modify system settings and install a new Network profile. Improvements to this are being worked on.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Using the API&lt;/h3&gt; 
&lt;p&gt;If you prefer to interact with exo via the API, here is an example creating an instance of a small model (&lt;code&gt;mlx-community/Llama-3.2-1B-Instruct-4bit&lt;/code&gt;), sending a chat completions request and deleting the instance.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;1. Preview instance placements&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;/instance/previews&lt;/code&gt; endpoint will preview all valid placements for your model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "previews": [
    {
      "model_id": "mlx-community/Llama-3.2-1B-Instruct-4bit",
      "sharding": "Pipeline",
      "instance_meta": "MlxRing",
      "instance": {...},
      "memory_delta_by_node": {"local": 729808896},
      "error": null
    }
    // ...possibly more placements...
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will return all valid placements for this model. Pick a placement that you like. To pick the first one, pipe into &lt;code&gt;jq&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b" | jq -c '.previews[] | select(.error == null) | .instance' | head -n1
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;2. Create a model instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Send a POST to &lt;code&gt;/instance&lt;/code&gt; with your desired placement in the &lt;code&gt;instance&lt;/code&gt; field (the full payload must match types as in &lt;code&gt;CreateInstanceParams&lt;/code&gt;), which you can copy from step 1:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:52415/instance \
  -H 'Content-Type: application/json' \
  -d '{
    "instance": {...}
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "message": "Command received.",
  "command_id": "e9d1a8ab-...."
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;3. Send a chat completion&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Now, make a POST to &lt;code&gt;/v1/chat/completions&lt;/code&gt; (the same format as OpenAI's API):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -N -X POST http://localhost:52415/v1/chat/completions \
  -H 'Content-Type: application/json' \
  -d '{
    "model": "mlx-community/Llama-3.2-1B-Instruct-4bit",
    "messages": [
      {"role": "user", "content": "What is Llama 3.2 1B?"}
    ],
    "stream": true
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;4. Delete the instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;When you're done, delete the instance by its ID (find it via &lt;code&gt;/state&lt;/code&gt; or &lt;code&gt;/instance&lt;/code&gt; endpoints):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X DELETE http://localhost:52415/instance/YOUR_INSTANCE_ID
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;&lt;em&gt;Other useful API endpoints&lt;/em&gt;:&lt;/em&gt;*&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;List all models: &lt;code&gt;curl http://localhost:52415/models&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Inspect instance IDs and deployment state: &lt;code&gt;curl http://localhost:52415/state&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For further details, see API types and endpoints in &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/src/exo/master/api.py"&gt;src/exo/master/api.py&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Hardware Accelerator Support&lt;/h2&gt; 
&lt;p&gt;On macOS, exo uses the GPU. On Linux, exo currently runs on CPU. We are working on extending hardware accelerator support. If you'd like support for a new hardware platform, please &lt;a href="https://github.com/exo-explore/exo/issues"&gt;search for an existing feature request&lt;/a&gt; and add a thumbs up so we know what hardware is important to the community.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidelines on how to contribute to exo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>JerBouma/FinanceDatabase</title>
      <link>https://github.com/JerBouma/FinanceDatabase</link>
      <description>&lt;p&gt;This is a database of 300.000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies and Money Markets.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/46355364/220746807-669cdbc1-ac67-404c-b0bb-4a3d67d9931f.jpg" alt="Logo" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/JerBouma"&gt;&lt;img src="https://img.shields.io/badge/Sponsor_this_Project-grey?logo=github" alt="GitHub Sponsors" /&gt;&lt;/a&gt; &lt;a href="https://www.buymeacoffee.com/jerbouma"&gt;&lt;img src="https://img.shields.io/badge/Buy_Me_a_Coffee-grey?logo=buymeacoffee" alt="Buy Me a Coffee" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/in/boumajeroen/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-grey?logo=Linkedin&amp;amp;logoColor=white" alt="LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://www.jeroenbouma.com/projects/financedatabase"&gt;&lt;img src="https://img.shields.io/badge/Documentation-grey?logo=readme" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/financedatabase/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/financedatabase" alt="Supported Python Versions" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/financedatabase/"&gt;&lt;img src="https://img.shields.io/pypi/v/financedatabase" alt="PYPI Version" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/financedatabase"&gt;&lt;img src="https://static.pepy.tech/badge/financedatabase/month" alt="PYPI Downloads" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Call for Contributors to the FinanceDatabase&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;The &lt;strong&gt;FinanceDatabase&lt;/strong&gt; serves the role of providing anyone with any type of financial product categorization entirely for free. To achieve this, the FinanceDatabase relies on community involvement to add, edit, and remove tickers over time. This is made easy enough that anyone, even those with a lack of coding experience, can contribute because of the use of CSV files that can be manually edited with ease.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;I'd like to invite you to go to the &lt;a href="https://github.com/JerBouma/FinanceDatabase/raw/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt; to understand how you can help. Thank you!&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;As a private investor, the sheer amount of information that can be found on the internet is rather daunting. Trying to understand what types of companies or ETFs are available is incredibly challenging, with millions of companies and derivatives available on the market. Sure, the most traded companies and ETFs can quickly be found simply because they are known to the public (for example, Microsoft, Tesla, S&amp;amp;P 500 ETF, or an All-World ETF). However, what else is out there is often unknown.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This database tries to solve that&lt;/strong&gt;. It features 300,000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies, and Money Markets. It therefore allows you to obtain a broad overview of sectors, industries, types of investments, and much more.&lt;/p&gt; 
&lt;p&gt;The aim of this database is explicitly &lt;em&gt;not&lt;/em&gt; to provide up-to-date fundamentals or stock data, as those can be obtained with ease (with the help of this database) by using the &lt;a href="https://github.com/JerBouma/FinanceToolkit"&gt;Finance Toolkit üõ†Ô∏è&lt;/a&gt;. Instead, it gives insights into the products that exist in each country, industry, and sector and provides the most essential information about each product. With this information, you can analyze specific areas of the financial world and/or find a product that is hard to find. For examples of how you can combine this database with the earlier mentioned packages, see the &lt;a href="https://raw.githubusercontent.com/JerBouma/FinanceDatabase/main/#usage"&gt;Usage&lt;/a&gt; section.&lt;/p&gt; 
&lt;p&gt;Some key statistics of the database:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Product&lt;/th&gt; 
   &lt;th&gt;Quantity&lt;/th&gt; 
   &lt;th&gt;Sectors&lt;/th&gt; 
   &lt;th&gt;Industries&lt;/th&gt; 
   &lt;th&gt;Countries&lt;/th&gt; 
   &lt;th&gt;Exchanges&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Equities&lt;/td&gt; 
   &lt;td&gt;158.429&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;63&lt;/td&gt; 
   &lt;td&gt;111&lt;/td&gt; 
   &lt;td&gt;83&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ETFs&lt;/td&gt; 
   &lt;td&gt;36.786&lt;/td&gt; 
   &lt;td&gt;295&lt;/td&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;111&lt;/td&gt; 
   &lt;td&gt;53&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Funds&lt;/td&gt; 
   &lt;td&gt;57.881&lt;/td&gt; 
   &lt;td&gt;1541&lt;/td&gt; 
   &lt;td&gt;52&lt;/td&gt; 
   &lt;td&gt;111&lt;/td&gt; 
   &lt;td&gt;34&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Product&lt;/th&gt; 
   &lt;th&gt;Quantity&lt;/th&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Currencies&lt;/td&gt; 
   &lt;td&gt;2.556&lt;/td&gt; 
   &lt;td&gt;175 Currencies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cryptocurrencies&lt;/td&gt; 
   &lt;td&gt;3.367&lt;/td&gt; 
   &lt;td&gt;352 Cryptocurrencies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Indices&lt;/td&gt; 
   &lt;td&gt;91.183&lt;/td&gt; 
   &lt;td&gt;64 Exchanges&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Money Markets&lt;/td&gt; 
   &lt;td&gt;1.367&lt;/td&gt; 
   &lt;td&gt;3 Exchanges&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The Finance Database is used within or referenced by:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://algotrading101.com/learn/financedatabase-python-guide/"&gt;&lt;img width="200" height="100" alt="AlgoTrading" src="https://github-production-user-asset-6210df.s3.amazonaws.com/46355364/265290727-4c113348-45fc-45fe-afb5-e043b738ee94.png" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/pyquantnews/status/1576185955677077504?lang=en"&gt;&lt;img width="200" height="100" alt="PyQuantNews" src="https://github-production-user-asset-6210df.s3.amazonaws.com/46355364/265290754-8c9025fb-3830-4f41-95fd-e5e6d0f84758.png" /&gt;&lt;/a&gt; &lt;a href="https://alpha2phi.medium.com/investment-analysis-finance-database-61f47ecfe7ca"&gt;&lt;img width="200" height="100" alt="Medium" src="https://github-production-user-asset-6210df.s3.amazonaws.com/46355364/265290765-dfbd0f4c-85eb-4de6-adba-345cb5189f31.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;Before installation, consider starring the project on GitHub, which helps others find the project as well.&lt;/p&gt; 
&lt;img width="1353" alt="image" src="https://github.com/JerBouma/FinanceDatabase/assets/46355364/4132edde-72f9-4e32-adfe-8872207f46ff" /&gt; 
&lt;p&gt;To install the FinanceDatabase, simply use the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install financedatabase -U
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then within Python use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import financedatabase as fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Usage&lt;/h1&gt; 
&lt;p&gt;This section explains in detail how the database can be queried with the related &lt;code&gt;financedatabase&lt;/code&gt; package. Note that examples here are purposely cut off to a maximum of 10 entries due to the sheer size of the database. Furthermore, the summary column is also omitted for readability. For the full detailed results, see the Notebook &lt;a href="https://www.jeroenbouma.com/projects/financedatabase/getting-started"&gt;here&lt;/a&gt;. Let's start by importing the package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import financedatabase as fd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Initialization of each asset class is only required &lt;u&gt;once&lt;/u&gt;. It is therefore important that you save the class to a variable so that you can query the database much more quickly. A simple example is shown below.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;equities = fd.Equities()

equities.select()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A sample of the output is shown below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;symbol&lt;/th&gt; 
   &lt;th align="left"&gt;name&lt;/th&gt; 
   &lt;th align="left"&gt;currency&lt;/th&gt; 
   &lt;th align="left"&gt;sector&lt;/th&gt; 
   &lt;th align="left"&gt;industry_group&lt;/th&gt; 
   &lt;th align="left"&gt;industry&lt;/th&gt; 
   &lt;th align="left"&gt;exchange&lt;/th&gt; 
   &lt;th align="left"&gt;market&lt;/th&gt; 
   &lt;th align="left"&gt;country&lt;/th&gt; 
   &lt;th align="left"&gt;state&lt;/th&gt; 
   &lt;th align="left"&gt;city&lt;/th&gt; 
   &lt;th align="left"&gt;zipcode&lt;/th&gt; 
   &lt;th align="left"&gt;website&lt;/th&gt; 
   &lt;th align="left"&gt;market_cap&lt;/th&gt; 
   &lt;th align="left"&gt;isin&lt;/th&gt; 
   &lt;th align="left"&gt;cusip&lt;/th&gt; 
   &lt;th align="left"&gt;figi&lt;/th&gt; 
   &lt;th align="left"&gt;composite_figi&lt;/th&gt; 
   &lt;th align="left"&gt;shareclass_figi&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;PMTA.DU&lt;/td&gt; 
   &lt;td align="left"&gt;PTC Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Information Technology&lt;/td&gt; 
   &lt;td align="left"&gt;Software &amp;amp; Services&lt;/td&gt; 
   &lt;td align="left"&gt;Software&lt;/td&gt; 
   &lt;td align="left"&gt;DUS&lt;/td&gt; 
   &lt;td align="left"&gt;Dusseldorf Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;MA&lt;/td&gt; 
   &lt;td align="left"&gt;Boston&lt;/td&gt; 
   &lt;td align="left"&gt;2210&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.ptc.com"&gt;http://www.ptc.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US69370C1009&lt;/td&gt; 
   &lt;td align="left"&gt;69370C100&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000FC6SC5&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000FC5PS5&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S6DNK6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;VAW.F&lt;/td&gt; 
   &lt;td align="left"&gt;VAALCO Energy, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Energy&lt;/td&gt; 
   &lt;td align="left"&gt;Energy&lt;/td&gt; 
   &lt;td align="left"&gt;Oil, Gas &amp;amp; Consumable Fuels&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
   &lt;td align="left"&gt;Frankfurt Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;TX&lt;/td&gt; 
   &lt;td align="left"&gt;Houston&lt;/td&gt; 
   &lt;td align="left"&gt;77042&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.vaalco.com"&gt;http://www.vaalco.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Micro Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US91851C2017&lt;/td&gt; 
   &lt;td align="left"&gt;91851C201&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000CN15Y5&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000CN15F6&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S76ZS7&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ORC.DE&lt;/td&gt; 
   &lt;td align="left"&gt;Oracle Corporation&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Information Technology&lt;/td&gt; 
   &lt;td align="left"&gt;Software &amp;amp; Services&lt;/td&gt; 
   &lt;td align="left"&gt;Software&lt;/td&gt; 
   &lt;td align="left"&gt;GER&lt;/td&gt; 
   &lt;td align="left"&gt;XETRA&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;TX&lt;/td&gt; 
   &lt;td align="left"&gt;Austin&lt;/td&gt; 
   &lt;td align="left"&gt;78741&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.oracle.com"&gt;http://www.oracle.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mega Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US68389X1054&lt;/td&gt; 
   &lt;td align="left"&gt;68389X105&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000C0RY38&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000C0RWW0&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S5SJG6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;PAYX&lt;/td&gt; 
   &lt;td align="left"&gt;Paychex, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Industrials&lt;/td&gt; 
   &lt;td align="left"&gt;Commercial &amp;amp; Professional Services&lt;/td&gt; 
   &lt;td align="left"&gt;Professional Services&lt;/td&gt; 
   &lt;td align="left"&gt;NMS&lt;/td&gt; 
   &lt;td align="left"&gt;NASDAQ Global Select&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;NY&lt;/td&gt; 
   &lt;td align="left"&gt;Rochester&lt;/td&gt; 
   &lt;td align="left"&gt;14625-2396&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.paychex.com"&gt;http://www.paychex.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US7043261079&lt;/td&gt; 
   &lt;td align="left"&gt;704326107&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BQT1J5&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BQSQ38&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S5V135&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;RI2A.F&lt;/td&gt; 
   &lt;td align="left"&gt;Rigel Pharmaceuticals, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Health Care&lt;/td&gt; 
   &lt;td align="left"&gt;Pharmaceuticals, Biotechnology &amp;amp; Life Sciences&lt;/td&gt; 
   &lt;td align="left"&gt;Biotechnology&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
   &lt;td align="left"&gt;Frankfurt Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;CA&lt;/td&gt; 
   &lt;td align="left"&gt;South San Francisco&lt;/td&gt; 
   &lt;td align="left"&gt;94080&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.rigel.com"&gt;http://www.rigel.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US7665596034&lt;/td&gt; 
   &lt;td align="left"&gt;766559603&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BKZNR4&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BKZNC0&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001SD33Z0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;PGEN&lt;/td&gt; 
   &lt;td align="left"&gt;Precigen, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Health Care&lt;/td&gt; 
   &lt;td align="left"&gt;Pharmaceuticals, Biotechnology &amp;amp; Life Sciences&lt;/td&gt; 
   &lt;td align="left"&gt;Biotechnology&lt;/td&gt; 
   &lt;td align="left"&gt;NMS&lt;/td&gt; 
   &lt;td align="left"&gt;NASDAQ Global Select&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;MD&lt;/td&gt; 
   &lt;td align="left"&gt;Germantown&lt;/td&gt; 
   &lt;td align="left"&gt;20876&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.precigen.com"&gt;http://www.precigen.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US74017N1054&lt;/td&gt; 
   &lt;td align="left"&gt;74017N105&lt;/td&gt; 
   &lt;td align="left"&gt;BBG004TDDJ32&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000QL8VH9&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001SSB3T5&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;GOGO&lt;/td&gt; 
   &lt;td align="left"&gt;Gogo Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Communication Services&lt;/td&gt; 
   &lt;td align="left"&gt;Telecommunication Services&lt;/td&gt; 
   &lt;td align="left"&gt;Diversified Telecommunication Services&lt;/td&gt; 
   &lt;td align="left"&gt;NMS&lt;/td&gt; 
   &lt;td align="left"&gt;NASDAQ Global Select&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;IL&lt;/td&gt; 
   &lt;td align="left"&gt;Chicago&lt;/td&gt; 
   &lt;td align="left"&gt;60606&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.gogoair.com"&gt;http://www.gogoair.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US38046C1099&lt;/td&gt; 
   &lt;td align="left"&gt;38046C109&lt;/td&gt; 
   &lt;td align="left"&gt;BBG002CN8Y71&lt;/td&gt; 
   &lt;td align="left"&gt;BBG002CN8XN5&lt;/td&gt; 
   &lt;td align="left"&gt;BBG002CN8YD4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;CRK&lt;/td&gt; 
   &lt;td align="left"&gt;Comstock Resources, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Energy&lt;/td&gt; 
   &lt;td align="left"&gt;Energy&lt;/td&gt; 
   &lt;td align="left"&gt;Oil, Gas &amp;amp; Consumable Fuels&lt;/td&gt; 
   &lt;td align="left"&gt;NYQ&lt;/td&gt; 
   &lt;td align="left"&gt;New York Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;TX&lt;/td&gt; 
   &lt;td align="left"&gt;Frisco&lt;/td&gt; 
   &lt;td align="left"&gt;75034&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.comstockresources.com"&gt;http://www.comstockresources.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mid Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US2057683029&lt;/td&gt; 
   &lt;td align="left"&gt;205768302&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000DNBMJ3&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000DNBK89&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S8FX55&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;OIS&lt;/td&gt; 
   &lt;td align="left"&gt;Oil States International, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Energy&lt;/td&gt; 
   &lt;td align="left"&gt;Energy&lt;/td&gt; 
   &lt;td align="left"&gt;Energy Equipment &amp;amp; Services&lt;/td&gt; 
   &lt;td align="left"&gt;NYQ&lt;/td&gt; 
   &lt;td align="left"&gt;New York Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;TX&lt;/td&gt; 
   &lt;td align="left"&gt;Houston&lt;/td&gt; 
   &lt;td align="left"&gt;77002&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.oilstatesintl.com"&gt;http://www.oilstatesintl.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US6780261052&lt;/td&gt; 
   &lt;td align="left"&gt;678026105&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BDDQ06&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BDDN94&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S7WK56&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;CVLC.BE&lt;/td&gt; 
   &lt;td align="left"&gt;Vale S.A.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Materials&lt;/td&gt; 
   &lt;td align="left"&gt;Materials&lt;/td&gt; 
   &lt;td align="left"&gt;Metals &amp;amp; Mining&lt;/td&gt; 
   &lt;td align="left"&gt;BER&lt;/td&gt; 
   &lt;td align="left"&gt;Berlin Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;Brazil&lt;/td&gt; 
   &lt;td align="left"&gt;RJ&lt;/td&gt; 
   &lt;td align="left"&gt;Rio De Janeiro&lt;/td&gt; 
   &lt;td align="left"&gt;22250-145&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.vale.com"&gt;http://www.vale.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US91912E1055&lt;/td&gt; 
   &lt;td align="left"&gt;9.19E+109&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000HCJTN5&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000HCJNQ5&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S7RS91&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;With &lt;code&gt;show_options&lt;/code&gt;, all possible options are given per column. &lt;strong&gt;This is useful as it doesn't require loading the larger data files.&lt;/strong&gt; For example, obtaining all options for equities is done as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;fd.show_options("equities")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This returns all available options for each column.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{'currency': array(['ARS', 'AUD', 'BRL', 'CAD', 'CHF', 'CLP', 'CNY', 'COP', 'CZK',
    'DKK', 'EUR', 'GBP', 'HKD', 'HUF', 'IDR', 'ILA', 'ILS', 'INR',
    'ISK', 'JPY', 'KES', 'KRW', 'LKR', 'MXN', 'MYR', 'NOK', 'NZD',
    'PEN', 'PHP', 'PLN', 'QAR', 'RUB', 'SAR', 'SEK', 'SGD', 'THB',
    'TRY', 'TWD', 'USD', 'ZAC', 'ZAR'], dtype=object),
 'sector': array(['Communication Services', 'Consumer Discretionary',
    'Consumer Staples', 'Energy', 'Financials', 'Health Care',
    'Industrials', 'Information Technology', 'Materials',
    'Real Estate', 'Utilities'], dtype=object),
 'industry_group': array(['Automobiles &amp;amp; Components', 'Banks', 'Capital Goods',
    'Commercial &amp;amp; Professional Services',
    'Consumer Durables &amp;amp; Apparel', 'Consumer Services',
    'Diversified Financials', 'Energy', 'Food &amp;amp; Staples Retailing',
    'Food, Beverage &amp;amp; Tobacco', 'Health Care Equipment &amp;amp; Services',
    'Household &amp;amp; Personal Products', 'Insurance', 'Materials',
    'Media &amp;amp; Entertainment',
    'Pharmaceuticals, Biotechnology &amp;amp; Life Sciences', 'Real Estate',
    'Retailing', 'Semiconductors &amp;amp; Semiconductor Equipment',
    'Software &amp;amp; Services', 'Technology Hardware &amp;amp; Equipment',
    'Telecommunication Services', 'Transportation', 'Utilities'],
       dtype=object)}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since the equities database has already been loaded, it is also possible to use similar functionality from within the class as follows. The main difference is that this functionality allows you to see the options based on specific filtering. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;equities.show_options(country='Netherlands')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This shows a more concise list of parameters given the focus on the Netherlands.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{'currency': array(['ARS', 'AUD', 'BRL', 'CHF', 'CZK', 'EUR', 'GBP', 'ILA', 'MXN',
    'NOK', 'RUB', 'USD', 'ZAC'], dtype=object),
 'sector': array(['Communication Services', 'Consumer Discretionary',
    'Consumer Staples', 'Energy', 'Financials', 'Health Care',
    'Industrials', 'Information Technology', 'Materials',
    'Real Estate', 'Utilities'], dtype=object),
 'industry_group': array(['Automobiles &amp;amp; Components', 'Banks', 'Capital Goods',
    'Commercial &amp;amp; Professional Services',
    'Consumer Durables &amp;amp; Apparel', 'Consumer Services',
    'Diversified Financials', 'Energy', 'Food &amp;amp; Staples Retailing',
    'Food, Beverage &amp;amp; Tobacco', 'Health Care Equipment &amp;amp; Services',
    'Household &amp;amp; Personal Products', 'Insurance', 'Materials',
    'Media &amp;amp; Entertainment',
    'Pharmaceuticals, Biotechnology &amp;amp; Life Sciences', 'Real Estate',
    'Retailing', 'Semiconductors &amp;amp; Semiconductor Equipment',
    'Software &amp;amp; Services', 'Technology Hardware &amp;amp; Equipment',
    'Telecommunication Services', 'Transportation', 'Utilities'],
       dtype=object)}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or only showing one specific parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;equities.show_options(
    selection='industry',
    sector='Financials',
    country='Netherlands')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Which returns:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;array(['Banks', 'Capital Markets', 'Consumer Finance',
       'Diversified Financial Services', 'Insurance'], dtype=object)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Given this information, it then becomes possible to filter the database based on the parameters you are interested in. For example, if you are interested in 'Insurance' companies in the 'Netherlands', you can use the following. Note that I omit the &lt;code&gt;sector&lt;/code&gt; here, given that the selection I make is on a deeper level and therefore it is a given that the sector is 'Financials'.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;equities.select(
    country='Netherlands',
    industry='Insurance',
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This returns a small selection of companies on all exchanges where the companies are listed.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;symbol&lt;/th&gt; 
   &lt;th align="left"&gt;name&lt;/th&gt; 
   &lt;th align="left"&gt;currency&lt;/th&gt; 
   &lt;th align="left"&gt;sector&lt;/th&gt; 
   &lt;th align="left"&gt;industry_group&lt;/th&gt; 
   &lt;th align="left"&gt;industry&lt;/th&gt; 
   &lt;th align="left"&gt;exchange&lt;/th&gt; 
   &lt;th align="left"&gt;market&lt;/th&gt; 
   &lt;th align="left"&gt;country&lt;/th&gt; 
   &lt;th align="right"&gt;state&lt;/th&gt; 
   &lt;th align="left"&gt;city&lt;/th&gt; 
   &lt;th align="left"&gt;zipcode&lt;/th&gt; 
   &lt;th align="left"&gt;website&lt;/th&gt; 
   &lt;th align="left"&gt;market_cap&lt;/th&gt; 
   &lt;th align="left"&gt;isin&lt;/th&gt; 
   &lt;th align="right"&gt;cusip&lt;/th&gt; 
   &lt;th align="left"&gt;figi&lt;/th&gt; 
   &lt;th align="left"&gt;composite_figi&lt;/th&gt; 
   &lt;th align="left"&gt;shareclass_figi&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;A16.F&lt;/td&gt; 
   &lt;td align="left"&gt;ASR Nederland N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
   &lt;td align="left"&gt;Frankfurt Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;Utrecht&lt;/td&gt; 
   &lt;td align="left"&gt;3584 BA&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.asrnl.com"&gt;http://www.asrnl.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mid Cap&lt;/td&gt; 
   &lt;td align="left"&gt;NL0011872643&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;BBG00D2VFV96&lt;/td&gt; 
   &lt;td align="left"&gt;BBG00D2VFV78&lt;/td&gt; 
   &lt;td align="left"&gt;BBG00CWZ0HK0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;A1EG34.SA&lt;/td&gt; 
   &lt;td align="left"&gt;Aegon N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;BRL&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;SAO&lt;/td&gt; 
   &lt;td align="left"&gt;Bovespa Soma&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;The Hague&lt;/td&gt; 
   &lt;td align="left"&gt;2591 TV&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.aegon.com"&gt;http://www.aegon.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mid Cap&lt;/td&gt; 
   &lt;td align="left"&gt;NL0000303709&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AEG&lt;/td&gt; 
   &lt;td align="left"&gt;Aegon N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;NYQ&lt;/td&gt; 
   &lt;td align="left"&gt;New York Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;The Hague&lt;/td&gt; 
   &lt;td align="left"&gt;2591 TV&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.aegon.com"&gt;http://www.aegon.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;NL0000303709&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000CKQTN4&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000CKQSN6&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S6Y6M8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AEGOF&lt;/td&gt; 
   &lt;td align="left"&gt;Aegon N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;PNK&lt;/td&gt; 
   &lt;td align="left"&gt;OTC Bulletin Board&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;The Hague&lt;/td&gt; 
   &lt;td align="left"&gt;2591 TV&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.aegon.com"&gt;http://www.aegon.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mid Cap&lt;/td&gt; 
   &lt;td align="left"&gt;NL0000303709&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AEND.DE&lt;/td&gt; 
   &lt;td align="left"&gt;Aegon N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;GER&lt;/td&gt; 
   &lt;td align="left"&gt;XETRA&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;The Hague&lt;/td&gt; 
   &lt;td align="left"&gt;2591 TV&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.aegon.com"&gt;http://www.aegon.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mid Cap&lt;/td&gt; 
   &lt;td align="left"&gt;NL0000303709&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000DJK260&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000DJHZF1&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S5V8R4&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;You'll see that the same company can appear multiple times. This is because by default all exchanges are shown. There are two methods to focus on one entry:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;code&gt;only_primary_listing&lt;/code&gt; parameter. This will only show the primary listing of each company. This is useful mostly if you are looking at US exchanges.&lt;/li&gt; 
 &lt;li&gt;Use the &lt;code&gt;exchange&lt;/code&gt; or &lt;code&gt;market&lt;/code&gt; parameter. This will allow you to filter on a specific exchange or market. This is useful when you are not necessarily looking at US exchanges and are already filtering on a specific country.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, when filtering on the Netherlands, it makes sense to select a Dutch exchange as well. This could be the exchange "AMS" or the market "Euronext Amsterdam". This will give you a much smaller selection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;equities.select(
    country='Netherlands',
    industry='Insurance',
    market='Euronext Amsterdam',
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This gives the following three companies (not shortened):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;symbol&lt;/th&gt; 
   &lt;th align="left"&gt;name&lt;/th&gt; 
   &lt;th align="left"&gt;currency&lt;/th&gt; 
   &lt;th align="left"&gt;sector&lt;/th&gt; 
   &lt;th align="left"&gt;industry_group&lt;/th&gt; 
   &lt;th align="left"&gt;industry&lt;/th&gt; 
   &lt;th align="left"&gt;exchange&lt;/th&gt; 
   &lt;th align="left"&gt;market&lt;/th&gt; 
   &lt;th align="left"&gt;country&lt;/th&gt; 
   &lt;th align="right"&gt;state&lt;/th&gt; 
   &lt;th align="left"&gt;city&lt;/th&gt; 
   &lt;th align="left"&gt;zipcode&lt;/th&gt; 
   &lt;th align="left"&gt;website&lt;/th&gt; 
   &lt;th align="left"&gt;market_cap&lt;/th&gt; 
   &lt;th align="left"&gt;isin&lt;/th&gt; 
   &lt;th align="right"&gt;cusip&lt;/th&gt; 
   &lt;th align="left"&gt;figi&lt;/th&gt; 
   &lt;th align="left"&gt;composite_figi&lt;/th&gt; 
   &lt;th align="left"&gt;shareclass_figi&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AGN.AS&lt;/td&gt; 
   &lt;td align="left"&gt;Aegon N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;AMS&lt;/td&gt; 
   &lt;td align="left"&gt;Euronext Amsterdam&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;The Hague&lt;/td&gt; 
   &lt;td align="left"&gt;2591 TV&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.aegon.com"&gt;http://www.aegon.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mid Cap&lt;/td&gt; 
   &lt;td align="left"&gt;NL0000303709&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000JN9DM6&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000JN9C93&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S5V8R4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ASRNL.AS&lt;/td&gt; 
   &lt;td align="left"&gt;ASR Nederland N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;AMS&lt;/td&gt; 
   &lt;td align="left"&gt;Euronext Amsterdam&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;Utrecht&lt;/td&gt; 
   &lt;td align="left"&gt;3584 BA&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.asrnl.com"&gt;http://www.asrnl.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mid Cap&lt;/td&gt; 
   &lt;td align="left"&gt;NL0011872643&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;BBG00CWZ0HG5&lt;/td&gt; 
   &lt;td align="left"&gt;BBG00CWZ0HF6&lt;/td&gt; 
   &lt;td align="left"&gt;BBG00CWZ0HK0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;NN.AS&lt;/td&gt; 
   &lt;td align="left"&gt;NN Group N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;AMS&lt;/td&gt; 
   &lt;td align="left"&gt;Euronext Amsterdam&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;The Hague&lt;/td&gt; 
   &lt;td align="left"&gt;2595 AS&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.nn-group.com"&gt;http://www.nn-group.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Given that the Netherlands is a relatively small country, it is not uncommon for the list to become small quickly. For example, the same selection for the United States is already much larger, also utilizing the &lt;code&gt;only_primary_listing&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;equities.select(
    country='United States',
    industry='Insurance',
    only_primary_listing=True
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;While not immediately obvious in this shortened output, it returns about 180 different companies.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;symbol&lt;/th&gt; 
   &lt;th align="left"&gt;name&lt;/th&gt; 
   &lt;th align="left"&gt;currency&lt;/th&gt; 
   &lt;th align="left"&gt;sector&lt;/th&gt; 
   &lt;th align="left"&gt;industry_group&lt;/th&gt; 
   &lt;th align="left"&gt;industry&lt;/th&gt; 
   &lt;th align="left"&gt;exchange&lt;/th&gt; 
   &lt;th align="left"&gt;market&lt;/th&gt; 
   &lt;th align="left"&gt;country&lt;/th&gt; 
   &lt;th align="left"&gt;state&lt;/th&gt; 
   &lt;th align="left"&gt;city&lt;/th&gt; 
   &lt;th align="left"&gt;zipcode&lt;/th&gt; 
   &lt;th align="left"&gt;website&lt;/th&gt; 
   &lt;th align="left"&gt;market_cap&lt;/th&gt; 
   &lt;th align="left"&gt;isin&lt;/th&gt; 
   &lt;th align="left"&gt;cusip&lt;/th&gt; 
   &lt;th align="left"&gt;figi&lt;/th&gt; 
   &lt;th align="left"&gt;composite_figi&lt;/th&gt; 
   &lt;th align="left"&gt;shareclass_figi&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AFL&lt;/td&gt; 
   &lt;td align="left"&gt;Aflac Incorporated&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;NYQ&lt;/td&gt; 
   &lt;td align="left"&gt;New York Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;GA&lt;/td&gt; 
   &lt;td align="left"&gt;Columbus&lt;/td&gt; 
   &lt;td align="left"&gt;31999&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.aflac.com"&gt;http://www.aflac.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US0010551028&lt;/td&gt; 
   &lt;td align="left"&gt;1055102&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BBBRC7&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BBBNC6&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S5NGJ4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AJG&lt;/td&gt; 
   &lt;td align="left"&gt;Arthur J. Gallagher &amp;amp; Co.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;NYQ&lt;/td&gt; 
   &lt;td align="left"&gt;New York Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;IL&lt;/td&gt; 
   &lt;td align="left"&gt;Rolling Meadows&lt;/td&gt; 
   &lt;td align="left"&gt;60008-4050&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.ajg.com"&gt;http://www.ajg.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US3635761097&lt;/td&gt; 
   &lt;td align="left"&gt;363576109&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BBHZK4&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BBHXQ3&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S5NKC2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AMSF&lt;/td&gt; 
   &lt;td align="left"&gt;AMERISAFE, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;NMS&lt;/td&gt; 
   &lt;td align="left"&gt;NASDAQ Global Select&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;LA&lt;/td&gt; 
   &lt;td align="left"&gt;Deridder&lt;/td&gt; 
   &lt;td align="left"&gt;70634&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.amerisafe.com"&gt;http://www.amerisafe.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US03071H1005&lt;/td&gt; 
   &lt;td align="left"&gt;03071H100&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000Q0JWB7&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000Q0JJQ0&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001SDH7B2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;BRO&lt;/td&gt; 
   &lt;td align="left"&gt;Brown &amp;amp; Brown, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;NYQ&lt;/td&gt; 
   &lt;td align="left"&gt;New York Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;FL&lt;/td&gt; 
   &lt;td align="left"&gt;Daytona Beach&lt;/td&gt; 
   &lt;td align="left"&gt;32114&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.bbinsurance.com"&gt;http://www.bbinsurance.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US1152361010&lt;/td&gt; 
   &lt;td align="left"&gt;115236101&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BWSJ77&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BWSGF4&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S5XFN0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;CINF&lt;/td&gt; 
   &lt;td align="left"&gt;Cincinnati Financial Corporation&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;NMS&lt;/td&gt; 
   &lt;td align="left"&gt;NASDAQ Global Select&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;OH&lt;/td&gt; 
   &lt;td align="left"&gt;Fairfield&lt;/td&gt; 
   &lt;td align="left"&gt;45014-5141&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.cinfin.com"&gt;http://www.cinfin.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US1720621010&lt;/td&gt; 
   &lt;td align="left"&gt;172062101&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BFPVV3&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000BFPK65&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S5PTM0&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For any of the variables, it is also possible to provide a list instead, which means that it will return all entries that match any of the variables. As an example, the queries above can be combined into one:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;equities.select(
    country=['Netherlands', 'United States'],
    industry='Insurance',
    market=['Euronext Amsterdam', 'Nordic Growth Market', 'OTC Bulletin Board',
        'New York Stock Exchange', 'NASDAQ Global Select', 'NYSE MKT',
        'NASDAQ Capital Market']
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This returns a larger selection of companies given the increased number of countries and markets.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;symbol&lt;/th&gt; 
   &lt;th align="left"&gt;name&lt;/th&gt; 
   &lt;th align="left"&gt;currency&lt;/th&gt; 
   &lt;th align="left"&gt;sector&lt;/th&gt; 
   &lt;th align="left"&gt;industry_group&lt;/th&gt; 
   &lt;th align="left"&gt;industry&lt;/th&gt; 
   &lt;th align="left"&gt;exchange&lt;/th&gt; 
   &lt;th align="left"&gt;market&lt;/th&gt; 
   &lt;th align="left"&gt;country&lt;/th&gt; 
   &lt;th align="left"&gt;state&lt;/th&gt; 
   &lt;th align="left"&gt;city&lt;/th&gt; 
   &lt;th align="left"&gt;zipcode&lt;/th&gt; 
   &lt;th align="left"&gt;website&lt;/th&gt; 
   &lt;th align="left"&gt;market_cap&lt;/th&gt; 
   &lt;th align="left"&gt;isin&lt;/th&gt; 
   &lt;th align="right"&gt;cusip&lt;/th&gt; 
   &lt;th align="left"&gt;figi&lt;/th&gt; 
   &lt;th align="left"&gt;composite_figi&lt;/th&gt; 
   &lt;th align="left"&gt;shareclass_figi&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AAME&lt;/td&gt; 
   &lt;td align="left"&gt;Atlantic American Corporation&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;NGM&lt;/td&gt; 
   &lt;td align="left"&gt;Nordic Growth Market&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;GA&lt;/td&gt; 
   &lt;td align="left"&gt;Atlanta&lt;/td&gt; 
   &lt;td align="left"&gt;30319-3054&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.atlam.com"&gt;http://www.atlam.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Nano Cap&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ACMT&lt;/td&gt; 
   &lt;td align="left"&gt;ACMAT Corporation&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;PNK&lt;/td&gt; 
   &lt;td align="left"&gt;OTC Bulletin Board&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;CT&lt;/td&gt; 
   &lt;td align="left"&gt;Farmington&lt;/td&gt; 
   &lt;td align="left"&gt;6032&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.acmatcorp.com"&gt;http://www.acmatcorp.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Nano Cap&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ACMTA&lt;/td&gt; 
   &lt;td align="left"&gt;ACMAT Corporation&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;PNK&lt;/td&gt; 
   &lt;td align="left"&gt;OTC Bulletin Board&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;CT&lt;/td&gt; 
   &lt;td align="left"&gt;Farmington&lt;/td&gt; 
   &lt;td align="left"&gt;6032&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.acmatcorp.com"&gt;http://www.acmatcorp.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Nano Cap&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AEG&lt;/td&gt; 
   &lt;td align="left"&gt;Aegon N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;NYQ&lt;/td&gt; 
   &lt;td align="left"&gt;New York Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;The Hague&lt;/td&gt; 
   &lt;td align="left"&gt;2591 TV&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.aegon.com"&gt;http://www.aegon.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;NL0000303709&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000CKQTN4&lt;/td&gt; 
   &lt;td align="left"&gt;BBG000CKQSN6&lt;/td&gt; 
   &lt;td align="left"&gt;BBG001S6Y6M8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AEGOF&lt;/td&gt; 
   &lt;td align="left"&gt;Aegon N.V.&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;Insurance&lt;/td&gt; 
   &lt;td align="left"&gt;PNK&lt;/td&gt; 
   &lt;td align="left"&gt;OTC Bulletin Board&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;The Hague&lt;/td&gt; 
   &lt;td align="left"&gt;2591 TV&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.aegon.com"&gt;http://www.aegon.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mid Cap&lt;/td&gt; 
   &lt;td align="left"&gt;NL0000303709&lt;/td&gt; 
   &lt;td align="right"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;If the current categorization doesn't lead to the results you are looking for, it is possible to use the &lt;code&gt;search&lt;/code&gt; parameter. This allows you to filter on any column in the database via a custom string. This means that if the word or sentence you input is found somewhere in the column you select, it will return the result.&lt;/p&gt; 
&lt;p&gt;By default, the result will not be case sensitive, but you can adjust this by setting &lt;code&gt;case_sensitive=True&lt;/code&gt;. You can also filter the index (&lt;code&gt;symbol&lt;/code&gt; column) by using &lt;code&gt;index&lt;/code&gt; as shown below. Just like the &lt;code&gt;select&lt;/code&gt; function, you can also provide lists here.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;equities.search(
    summary=["Robotics", "Education"],
    industry_group="Equipment",
    market='Frankfurt',
    index=".F"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This returns instruments that are listed on the Frankfurt Stock Exchange, are in an industry group with the word "Equipment," and have either "Robotics" or "Education" in the summary column. The &lt;code&gt;index&lt;/code&gt; parameter is used to filter on the symbol column, which in this case is ".F". The filtering on the index is an alternative way of finding the exchange or market you are looking for.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;symbol&lt;/th&gt; 
   &lt;th align="left"&gt;name&lt;/th&gt; 
   &lt;th align="left"&gt;currency&lt;/th&gt; 
   &lt;th align="left"&gt;sector&lt;/th&gt; 
   &lt;th align="left"&gt;industry_group&lt;/th&gt; 
   &lt;th align="left"&gt;industry&lt;/th&gt; 
   &lt;th align="left"&gt;exchange&lt;/th&gt; 
   &lt;th align="left"&gt;market&lt;/th&gt; 
   &lt;th align="left"&gt;country&lt;/th&gt; 
   &lt;th align="left"&gt;state&lt;/th&gt; 
   &lt;th align="left"&gt;city&lt;/th&gt; 
   &lt;th align="left"&gt;zipcode&lt;/th&gt; 
   &lt;th align="left"&gt;website&lt;/th&gt; 
   &lt;th align="left"&gt;market_cap&lt;/th&gt; 
   &lt;th align="left"&gt;isin&lt;/th&gt; 
   &lt;th align="left"&gt;cusip&lt;/th&gt; 
   &lt;th align="left"&gt;figi&lt;/th&gt; 
   &lt;th align="left"&gt;composite_figi&lt;/th&gt; 
   &lt;th align="left"&gt;shareclass_figi&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;109.F&lt;/td&gt; 
   &lt;td align="left"&gt;Castlight Health, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Health Care&lt;/td&gt; 
   &lt;td align="left"&gt;Health Care Equipment &amp;amp; Services&lt;/td&gt; 
   &lt;td align="left"&gt;Health Care Providers &amp;amp; Services&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
   &lt;td align="left"&gt;Frankfurt Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;CA&lt;/td&gt; 
   &lt;td align="left"&gt;San Francisco&lt;/td&gt; 
   &lt;td align="left"&gt;94105&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.castlighthealth.com"&gt;http://www.castlighthealth.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small Cap&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;1KT.F&lt;/td&gt; 
   &lt;td align="left"&gt;Keysight Technologies, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Information Technology&lt;/td&gt; 
   &lt;td align="left"&gt;Technology Hardware &amp;amp; Equipment&lt;/td&gt; 
   &lt;td align="left"&gt;Electronic Equipment, Instruments &amp;amp; Components&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
   &lt;td align="left"&gt;Frankfurt Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;CA&lt;/td&gt; 
   &lt;td align="left"&gt;Santa Rosa&lt;/td&gt; 
   &lt;td align="left"&gt;95403-1738&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.keysight.com"&gt;http://www.keysight.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US49338L1035&lt;/td&gt; 
   &lt;td align="left"&gt;49338L103&lt;/td&gt; 
   &lt;td align="left"&gt;BBG007DJZFD2&lt;/td&gt; 
   &lt;td align="left"&gt;BBG007DJZFC3&lt;/td&gt; 
   &lt;td align="left"&gt;BBG0059FN820&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;1N1.F&lt;/td&gt; 
   &lt;td align="left"&gt;Nanalysis Scientific Corp.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Information Technology&lt;/td&gt; 
   &lt;td align="left"&gt;Technology Hardware &amp;amp; Equipment&lt;/td&gt; 
   &lt;td align="left"&gt;Electronic Equipment, Instruments &amp;amp; Components&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
   &lt;td align="left"&gt;Frankfurt Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;Canada&lt;/td&gt; 
   &lt;td align="left"&gt;AB&lt;/td&gt; 
   &lt;td align="left"&gt;Calgary&lt;/td&gt; 
   &lt;td align="left"&gt;T2E 7C3&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.nanalysis.com"&gt;http://www.nanalysis.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Nano Cap&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;1YO.F&lt;/td&gt; 
   &lt;td align="left"&gt;Yangtze Optical Fibre And Cable Joint Stock Limited Company&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Information Technology&lt;/td&gt; 
   &lt;td align="left"&gt;Technology Hardware &amp;amp; Equipment&lt;/td&gt; 
   &lt;td align="left"&gt;Communications Equipment&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
   &lt;td align="left"&gt;Frankfurt Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;China&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;Wuhan&lt;/td&gt; 
   &lt;td align="left"&gt;430073&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.yofc.com"&gt;http://www.yofc.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small Cap&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
   &lt;td align="left"&gt;nan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;1ZU.F&lt;/td&gt; 
   &lt;td align="left"&gt;The Pennant Group, Inc.&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Health Care&lt;/td&gt; 
   &lt;td align="left"&gt;Health Care Equipment &amp;amp; Services&lt;/td&gt; 
   &lt;td align="left"&gt;Health Care Equipment &amp;amp; Supplies&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
   &lt;td align="left"&gt;Frankfurt Stock Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;United States&lt;/td&gt; 
   &lt;td align="left"&gt;ID&lt;/td&gt; 
   &lt;td align="left"&gt;Eagle&lt;/td&gt; 
   &lt;td align="left"&gt;83616&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="http://pennantgroup.com"&gt;http://pennantgroup.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small Cap&lt;/td&gt; 
   &lt;td align="left"&gt;US70805E1091&lt;/td&gt; 
   &lt;td align="left"&gt;7.08E+113&lt;/td&gt; 
   &lt;td align="left"&gt;BBG00QJ35K78&lt;/td&gt; 
   &lt;td align="left"&gt;BBG00QJ35K69&lt;/td&gt; 
   &lt;td align="left"&gt;BBG00P33SZ15&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Lastly, the Finance Database has a direct integration with the &lt;a href="https://github.com/JerBouma/FinanceToolkit"&gt;Finance Toolkit&lt;/a&gt;, making it possible to do financial analysis on the companies you've found in the Finance Database. Returning to the earlier example of the 3 insurance companies in the Netherlands, it becomes possible to load these into the Finance Toolkit with the &lt;code&gt;to_toolkit&lt;/code&gt; functionality.&lt;/p&gt; 
&lt;p&gt;To be able to get started, you need to obtain an API Key from FinancialModelingPrep. This is used to gain access to 30+ years of financial statements, both annually and quarterly. Note that the Free plan is limited to 250 requests each day, 5 years of data, and only features companies listed on US exchanges.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;div align="center"&gt;
 &lt;b&gt;Obtain an API Key from FinancialModelingPrep &lt;a href="https://www.jeroenbouma.com/fmp" target="_blank"&gt;here&lt;/a&gt;.&lt;/b&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Then you can go ahead and run the following code, changing the &lt;code&gt;API_KEY&lt;/code&gt; to your own API Key:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;API_KEY = "FINANCIAL_MODELING_PREP_API_KEY"

dutch_insurance_companies = equities.select(
    country='Netherlands',
    industry='Insurance',
    market='Euronext Amsterdam',
)

toolkit = dutch_insurance_companies.to_toolkit(
    api_key=API_KEY
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With this integration, I can now access some of the most important financial metrics for these companies. Let's start simple with historical data:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;toolkit.get_historical_data()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Which returns, selecting only "ASRNL.AS" as an example:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;date&lt;/th&gt; 
   &lt;th align="right"&gt;Open&lt;/th&gt; 
   &lt;th align="right"&gt;High&lt;/th&gt; 
   &lt;th align="right"&gt;Low&lt;/th&gt; 
   &lt;th align="right"&gt;Close&lt;/th&gt; 
   &lt;th align="right"&gt;Adj Close&lt;/th&gt; 
   &lt;th align="right"&gt;Volume&lt;/th&gt; 
   &lt;th align="right"&gt;Dividends&lt;/th&gt; 
   &lt;th align="right"&gt;Return&lt;/th&gt; 
   &lt;th align="right"&gt;Volatility&lt;/th&gt; 
   &lt;th align="right"&gt;Excess Return&lt;/th&gt; 
   &lt;th align="right"&gt;Excess Volatility&lt;/th&gt; 
   &lt;th align="right"&gt;Cumulative Return&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2025-03-31&lt;/td&gt; 
   &lt;td align="right"&gt;52.86&lt;/td&gt; 
   &lt;td align="right"&gt;52.98&lt;/td&gt; 
   &lt;td align="right"&gt;52.56&lt;/td&gt; 
   &lt;td align="right"&gt;52.98&lt;/td&gt; 
   &lt;td align="right"&gt;52.98&lt;/td&gt; 
   &lt;td align="right"&gt;547650&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;-0.0049&lt;/td&gt; 
   &lt;td align="right"&gt;0.0175&lt;/td&gt; 
   &lt;td align="right"&gt;-0.0474&lt;/td&gt; 
   &lt;td align="right"&gt;0.0206&lt;/td&gt; 
   &lt;td align="right"&gt;4.2726&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2025-04-01&lt;/td&gt; 
   &lt;td align="right"&gt;53.22&lt;/td&gt; 
   &lt;td align="right"&gt;53.6&lt;/td&gt; 
   &lt;td align="right"&gt;52.98&lt;/td&gt; 
   &lt;td align="right"&gt;53.44&lt;/td&gt; 
   &lt;td align="right"&gt;53.44&lt;/td&gt; 
   &lt;td align="right"&gt;486098&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;0.0087&lt;/td&gt; 
   &lt;td align="right"&gt;0.0175&lt;/td&gt; 
   &lt;td align="right"&gt;-0.0329&lt;/td&gt; 
   &lt;td align="right"&gt;0.0206&lt;/td&gt; 
   &lt;td align="right"&gt;4.3097&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2025-04-02&lt;/td&gt; 
   &lt;td align="right"&gt;53.18&lt;/td&gt; 
   &lt;td align="right"&gt;53.58&lt;/td&gt; 
   &lt;td align="right"&gt;52.7&lt;/td&gt; 
   &lt;td align="right"&gt;53.3&lt;/td&gt; 
   &lt;td align="right"&gt;53.3&lt;/td&gt; 
   &lt;td align="right"&gt;485768&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;-0.0026&lt;/td&gt; 
   &lt;td align="right"&gt;0.0175&lt;/td&gt; 
   &lt;td align="right"&gt;-0.0446&lt;/td&gt; 
   &lt;td align="right"&gt;0.0206&lt;/td&gt; 
   &lt;td align="right"&gt;4.2984&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2025-04-03&lt;/td&gt; 
   &lt;td align="right"&gt;52.32&lt;/td&gt; 
   &lt;td align="right"&gt;53.22&lt;/td&gt; 
   &lt;td align="right"&gt;52.18&lt;/td&gt; 
   &lt;td align="right"&gt;52.42&lt;/td&gt; 
   &lt;td align="right"&gt;52.42&lt;/td&gt; 
   &lt;td align="right"&gt;567242&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;-0.0165&lt;/td&gt; 
   &lt;td align="right"&gt;0.0175&lt;/td&gt; 
   &lt;td align="right"&gt;-0.057&lt;/td&gt; 
   &lt;td align="right"&gt;0.0206&lt;/td&gt; 
   &lt;td align="right"&gt;4.2274&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2025-04-04&lt;/td&gt; 
   &lt;td align="right"&gt;52&lt;/td&gt; 
   &lt;td align="right"&gt;52.5&lt;/td&gt; 
   &lt;td align="right"&gt;49.45&lt;/td&gt; 
   &lt;td align="right"&gt;50.4&lt;/td&gt; 
   &lt;td align="right"&gt;50.4&lt;/td&gt; 
   &lt;td align="right"&gt;485024&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;-0.0385&lt;/td&gt; 
   &lt;td align="right"&gt;0.0175&lt;/td&gt; 
   &lt;td align="right"&gt;-0.0775&lt;/td&gt; 
   &lt;td align="right"&gt;0.0206&lt;/td&gt; 
   &lt;td align="right"&gt;4.0645&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Now let's make it more advanced by automatically calculating 60+ financial ratios for each company. &lt;strong&gt;This is just a small snippet of what is available within the Finance Toolkit; see the GitHub page of the Finance Toolkit &lt;a href="https://github.com/JerBouma/FinanceToolkit"&gt;here&lt;/a&gt; or the example Notebook &lt;a href="https://www.jeroenbouma.com/projects/financetoolkit/getting-started"&gt;here&lt;/a&gt; for more information.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;toolkit.ratios.collect_all_ratios()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Which returns, selecting only "ASRNL.AS" as an example with a few ratios:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;&lt;/th&gt; 
   &lt;th align="right"&gt;2015&lt;/th&gt; 
   &lt;th align="right"&gt;2016&lt;/th&gt; 
   &lt;th align="right"&gt;2017&lt;/th&gt; 
   &lt;th align="right"&gt;2018&lt;/th&gt; 
   &lt;th align="right"&gt;2019&lt;/th&gt; 
   &lt;th align="right"&gt;2020&lt;/th&gt; 
   &lt;th align="right"&gt;2021&lt;/th&gt; 
   &lt;th align="right"&gt;2022&lt;/th&gt; 
   &lt;th align="right"&gt;2023&lt;/th&gt; 
   &lt;th align="right"&gt;2024&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Interest Coverage Ratio&lt;/td&gt; 
   &lt;td align="right"&gt;4.0535&lt;/td&gt; 
   &lt;td align="right"&gt;4.2287&lt;/td&gt; 
   &lt;td align="right"&gt;6.6142&lt;/td&gt; 
   &lt;td align="right"&gt;5.152&lt;/td&gt; 
   &lt;td align="right"&gt;3.2238&lt;/td&gt; 
   &lt;td align="right"&gt;2.2508&lt;/td&gt; 
   &lt;td align="right"&gt;3.1188&lt;/td&gt; 
   &lt;td align="right"&gt;3.0962&lt;/td&gt; 
   &lt;td align="right"&gt;4.1177&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Income Before Tax Profit Margin&lt;/td&gt; 
   &lt;td align="right"&gt;0.1078&lt;/td&gt; 
   &lt;td align="right"&gt;0.1265&lt;/td&gt; 
   &lt;td align="right"&gt;0.1843&lt;/td&gt; 
   &lt;td align="right"&gt;0.159&lt;/td&gt; 
   &lt;td align="right"&gt;0.1515&lt;/td&gt; 
   &lt;td align="right"&gt;0.1104&lt;/td&gt; 
   &lt;td align="right"&gt;0.1231&lt;/td&gt; 
   &lt;td align="right"&gt;0.1783&lt;/td&gt; 
   &lt;td align="right"&gt;0.1089&lt;/td&gt; 
   &lt;td align="right"&gt;0.0701&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Effective Tax Rate&lt;/td&gt; 
   &lt;td align="right"&gt;0.1923&lt;/td&gt; 
   &lt;td align="right"&gt;0.2351&lt;/td&gt; 
   &lt;td align="right"&gt;0.195&lt;/td&gt; 
   &lt;td align="right"&gt;0.2334&lt;/td&gt; 
   &lt;td align="right"&gt;0.1983&lt;/td&gt; 
   &lt;td align="right"&gt;0.2075&lt;/td&gt; 
   &lt;td align="right"&gt;0.2233&lt;/td&gt; 
   &lt;td align="right"&gt;0.2196&lt;/td&gt; 
   &lt;td align="right"&gt;0.2181&lt;/td&gt; 
   &lt;td align="right"&gt;0.2647&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Return on Capital Employed&lt;/td&gt; 
   &lt;td align="right"&gt;0.0183&lt;/td&gt; 
   &lt;td align="right"&gt;0.0192&lt;/td&gt; 
   &lt;td align="right"&gt;0.0235&lt;/td&gt; 
   &lt;td align="right"&gt;0.0176&lt;/td&gt; 
   &lt;td align="right"&gt;0.0218&lt;/td&gt; 
   &lt;td align="right"&gt;0.0145&lt;/td&gt; 
   &lt;td align="right"&gt;0.0205&lt;/td&gt; 
   &lt;td align="right"&gt;0.0205&lt;/td&gt; 
   &lt;td align="right"&gt;0.0283&lt;/td&gt; 
   &lt;td align="right"&gt;0.0382&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Net Income per EBT&lt;/td&gt; 
   &lt;td align="right"&gt;0.7908&lt;/td&gt; 
   &lt;td align="right"&gt;0.7603&lt;/td&gt; 
   &lt;td align="right"&gt;0.7985&lt;/td&gt; 
   &lt;td align="right"&gt;0.743&lt;/td&gt; 
   &lt;td align="right"&gt;0.7917&lt;/td&gt; 
   &lt;td align="right"&gt;0.7798&lt;/td&gt; 
   &lt;td align="right"&gt;0.768&lt;/td&gt; 
   &lt;td align="right"&gt;0.7705&lt;/td&gt; 
   &lt;td align="right"&gt;0.774&lt;/td&gt; 
   &lt;td align="right"&gt;0.6972&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;EBT to EBIT Ratio&lt;/td&gt; 
   &lt;td align="right"&gt;0.7469&lt;/td&gt; 
   &lt;td align="right"&gt;0.7611&lt;/td&gt; 
   &lt;td align="right"&gt;0.8472&lt;/td&gt; 
   &lt;td align="right"&gt;0.801&lt;/td&gt; 
   &lt;td align="right"&gt;0.7654&lt;/td&gt; 
   &lt;td align="right"&gt;0.7023&lt;/td&gt; 
   &lt;td align="right"&gt;0.7628&lt;/td&gt; 
   &lt;td align="right"&gt;0.6654&lt;/td&gt; 
   &lt;td align="right"&gt;0.3289&lt;/td&gt; 
   &lt;td align="right"&gt;0.2389&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;EBIT to Revenue&lt;/td&gt; 
   &lt;td align="right"&gt;0.1327&lt;/td&gt; 
   &lt;td align="right"&gt;0.163&lt;/td&gt; 
   &lt;td align="right"&gt;0.2107&lt;/td&gt; 
   &lt;td align="right"&gt;0.1803&lt;/td&gt; 
   &lt;td align="right"&gt;0.1885&lt;/td&gt; 
   &lt;td align="right"&gt;0.1481&lt;/td&gt; 
   &lt;td align="right"&gt;0.1553&lt;/td&gt; 
   &lt;td align="right"&gt;0.2564&lt;/td&gt; 
   &lt;td align="right"&gt;0.3196&lt;/td&gt; 
   &lt;td align="right"&gt;0.2567&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Debt-to-Assets Ratio&lt;/td&gt; 
   &lt;td align="right"&gt;0.0442&lt;/td&gt; 
   &lt;td align="right"&gt;0.0605&lt;/td&gt; 
   &lt;td align="right"&gt;0.0504&lt;/td&gt; 
   &lt;td align="right"&gt;0.0546&lt;/td&gt; 
   &lt;td align="right"&gt;0.094&lt;/td&gt; 
   &lt;td align="right"&gt;0.1172&lt;/td&gt; 
   &lt;td align="right"&gt;0.0923&lt;/td&gt; 
   &lt;td align="right"&gt;0.068&lt;/td&gt; 
   &lt;td align="right"&gt;0.0856&lt;/td&gt; 
   &lt;td align="right"&gt;0.0771&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;All of these methods are also available for the other asset classes. The only difference is that the class name changes and the available columns. For example, for ETFs you would use &lt;code&gt;fd.ETFs()&lt;/code&gt; instead of &lt;code&gt;fd.Equities()&lt;/code&gt; and the &lt;code&gt;select&lt;/code&gt; option has parameters such as &lt;code&gt;category_group&lt;/code&gt; and &lt;code&gt;family&lt;/code&gt; instead.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;etfs = fd.ETFs()

etfs.select(
    category_group='Fixed Income'
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This gives you results like the following:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;symbol&lt;/th&gt; 
   &lt;th align="left"&gt;name&lt;/th&gt; 
   &lt;th align="left"&gt;currency&lt;/th&gt; 
   &lt;th align="left"&gt;category_group&lt;/th&gt; 
   &lt;th align="left"&gt;category&lt;/th&gt; 
   &lt;th align="left"&gt;family&lt;/th&gt; 
   &lt;th align="left"&gt;exchange&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;^BND&lt;/td&gt; 
   &lt;td align="left"&gt;VANGUARD BD IDX FD&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Fixed Income&lt;/td&gt; 
   &lt;td align="left"&gt;Investment Grade Bonds&lt;/td&gt; 
   &lt;td align="left"&gt;Vanguard Asset Management&lt;/td&gt; 
   &lt;td align="left"&gt;NIM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;^BNDX&lt;/td&gt; 
   &lt;td align="left"&gt;VANGUARD CHARLOTTE&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Fixed Income&lt;/td&gt; 
   &lt;td align="left"&gt;Investment Grade Bonds&lt;/td&gt; 
   &lt;td align="left"&gt;Vanguard Asset Management&lt;/td&gt; 
   &lt;td align="left"&gt;NIM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;^VCIT&lt;/td&gt; 
   &lt;td align="left"&gt;VANGUARD SCOTTSDAL&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Fixed Income&lt;/td&gt; 
   &lt;td align="left"&gt;Corporate Bonds&lt;/td&gt; 
   &lt;td align="left"&gt;Vanguard Asset Management&lt;/td&gt; 
   &lt;td align="left"&gt;NIM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;^VCLT&lt;/td&gt; 
   &lt;td align="left"&gt;VANGUARD SCOTTSDAL&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Fixed Income&lt;/td&gt; 
   &lt;td align="left"&gt;Corporate Bonds&lt;/td&gt; 
   &lt;td align="left"&gt;Vanguard Asset Management&lt;/td&gt; 
   &lt;td align="left"&gt;NIM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;^VCSH&lt;/td&gt; 
   &lt;td align="left"&gt;VANGUARD SCOTTSDAL&lt;/td&gt; 
   &lt;td align="left"&gt;USD&lt;/td&gt; 
   &lt;td align="left"&gt;Fixed Income&lt;/td&gt; 
   &lt;td align="left"&gt;Corporate Bonds&lt;/td&gt; 
   &lt;td align="left"&gt;Vanguard Asset Management&lt;/td&gt; 
   &lt;td align="left"&gt;NIM&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;This also translates to the available options. For example, let's select &lt;code&gt;fd.Indices()&lt;/code&gt; instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;indices = fd.Indices()

indices.show_options()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A sample of the output is shown below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{'category_group': array(['Alternatives', 'Cash', 'Commodities', 'Communication Services',
    'Consumer Discretionary', 'Consumer Staples', 'Currencies',
    'Derivatives', 'Energy', 'Equities', 'Financials', 'Fixed Income',
    'Health Care', 'Industrials', 'Information Technology',
    'Materials', 'Real Estate', 'Utilities'], dtype=object),
 'category': array(['Alternative', 'Blend', 'Bonds', 'Cash', 'Commercial Real Estate',
    'Commodities Broad Basket', 'Communications',
    'Consumer Discretionary', 'Consumer Staples', 'Corporate Bonds',
    'Currencies', 'Derivatives', 'Developed Markets',
    'Emerging Markets', 'Energy', 'Equities', 'Factors', 'Financials',
    'Frontier Markets', 'Government Bonds', 'Growth', 'Health Care',
    'High Yield Bonds', 'Industrials',
    'Inflation-Protected Securities', 'Investment Grade Bonds',
    'Large Cap', 'Materials', 'Micro Cap', 'Mid Cap',
    'Money Market Instruments', 'Municipal Bonds', 'REITs',
    'Real Estate Development', 'Real Estate Services',
    'Residential Real Estate', 'Small Cap', 'Technology', 'Trading',
    'Treasury Bonds', 'Utilities', 'Value'], dtype=object)}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Lastly, both the &lt;code&gt;search&lt;/code&gt; and &lt;code&gt;to_toolkit&lt;/code&gt; functions also apply to each of the asset classes, using &lt;code&gt;fd.Funds()&lt;/code&gt; and &lt;code&gt;fd.Cryptos()&lt;/code&gt; respectively. For example, let's find the funds that focus on pension plans:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;funds = fd.Funds()

funds.search(summary='Pension')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A sample of the output is shown below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;symbol&lt;/th&gt; 
   &lt;th align="left"&gt;name&lt;/th&gt; 
   &lt;th align="left"&gt;currency&lt;/th&gt; 
   &lt;th align="left"&gt;category_group&lt;/th&gt; 
   &lt;th align="left"&gt;category&lt;/th&gt; 
   &lt;th align="left"&gt;family&lt;/th&gt; 
   &lt;th align="left"&gt;exchange&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;0P000017AH.F&lt;/td&gt; 
   &lt;td align="left"&gt;OpenBank Renta Variable Europa PP&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Equities&lt;/td&gt; 
   &lt;td align="left"&gt;Equities&lt;/td&gt; 
   &lt;td align="left"&gt;Santander Asset Management SGIIC&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;0P000017AJ.F&lt;/td&gt; 
   &lt;td align="left"&gt;Alcal Futuro Uno PP&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Allocation&lt;/td&gt; 
   &lt;td align="left"&gt;Caser Pensiones EGFP&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;0P0000189U.F&lt;/td&gt; 
   &lt;td align="left"&gt;Caser Julio 2021 PP Acc&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Bonds&lt;/td&gt; 
   &lt;td align="left"&gt;Caser Pensiones EGFP&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;0P000018ML.F&lt;/td&gt; 
   &lt;td align="left"&gt;Cajamar Renta Variable PP&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Equities&lt;/td&gt; 
   &lt;td align="left"&gt;Equities&lt;/td&gt; 
   &lt;td align="left"&gt;Cajamar Vida Se. y Re.&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;0P000019H0.F&lt;/td&gt; 
   &lt;td align="left"&gt;Bestinver Global PP&lt;/td&gt; 
   &lt;td align="left"&gt;EUR&lt;/td&gt; 
   &lt;td align="left"&gt;Financials&lt;/td&gt; 
   &lt;td align="left"&gt;Blend&lt;/td&gt; 
   &lt;td align="left"&gt;Bestinver Pensiones&lt;/td&gt; 
   &lt;td align="left"&gt;FRA&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For Cryptos, let's collect the historical data of Ethereum in multiple currencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;cryptos = fd.Cryptos()

eth_cryptos = cryptos.select(
    cryptocurrency='ETH'
)

cryptos_toolkit = eth_cryptos.to_toolkit(
    api_key=API_KEY,
    start_date='2020-01-01'
)

cryptos_toolkit.get_historical_data(period='quarterly')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A sample of the output is shown below, focusing on ETH-BTC:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Date&lt;/th&gt; 
   &lt;th align="right"&gt;Open&lt;/th&gt; 
   &lt;th align="right"&gt;High&lt;/th&gt; 
   &lt;th align="right"&gt;Low&lt;/th&gt; 
   &lt;th align="right"&gt;Close&lt;/th&gt; 
   &lt;th align="right"&gt;Adj Close&lt;/th&gt; 
   &lt;th align="right"&gt;Volume&lt;/th&gt; 
   &lt;th align="right"&gt;Dividends&lt;/th&gt; 
   &lt;th align="right"&gt;Return&lt;/th&gt; 
   &lt;th align="right"&gt;Volatility&lt;/th&gt; 
   &lt;th align="right"&gt;Excess Return&lt;/th&gt; 
   &lt;th align="right"&gt;Excess Volatility&lt;/th&gt; 
   &lt;th align="right"&gt;Cumulative Return&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2024Q2&lt;/td&gt; 
   &lt;td align="right"&gt;0.0559&lt;/td&gt; 
   &lt;td align="right"&gt;0.0558&lt;/td&gt; 
   &lt;td align="right"&gt;0.0554&lt;/td&gt; 
   &lt;td align="right"&gt;0.0554&lt;/td&gt; 
   &lt;td align="right"&gt;0.0554&lt;/td&gt; 
   &lt;td align="right"&gt;108145&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;0.0992&lt;/td&gt; 
   &lt;td align="right"&gt;0.159&lt;/td&gt; 
   &lt;td align="right"&gt;0.0558&lt;/td&gt; 
   &lt;td align="right"&gt;0.144&lt;/td&gt; 
   &lt;td align="right"&gt;2.6763&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2024Q3&lt;/td&gt; 
   &lt;td align="right"&gt;0.0406&lt;/td&gt; 
   &lt;td align="right"&gt;0.0407&lt;/td&gt; 
   &lt;td align="right"&gt;0.0403&lt;/td&gt; 
   &lt;td align="right"&gt;0.0405&lt;/td&gt; 
   &lt;td align="right"&gt;0.0405&lt;/td&gt; 
   &lt;td align="right"&gt;169579&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;-0.269&lt;/td&gt; 
   &lt;td align="right"&gt;0.1433&lt;/td&gt; 
   &lt;td align="right"&gt;-0.307&lt;/td&gt; 
   &lt;td align="right"&gt;0.1445&lt;/td&gt; 
   &lt;td align="right"&gt;1.9565&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2024Q4&lt;/td&gt; 
   &lt;td align="right"&gt;0.0358&lt;/td&gt; 
   &lt;td align="right"&gt;0.0365&lt;/td&gt; 
   &lt;td align="right"&gt;0.036&lt;/td&gt; 
   &lt;td align="right"&gt;0.0362&lt;/td&gt; 
   &lt;td align="right"&gt;0.0362&lt;/td&gt; 
   &lt;td align="right"&gt;291317&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;-0.1062&lt;/td&gt; 
   &lt;td align="right"&gt;0.1857&lt;/td&gt; 
   &lt;td align="right"&gt;-0.1519&lt;/td&gt; 
   &lt;td align="right"&gt;0.1679&lt;/td&gt; 
   &lt;td align="right"&gt;1.7488&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2025Q1&lt;/td&gt; 
   &lt;td align="right"&gt;0.0221&lt;/td&gt; 
   &lt;td align="right"&gt;0.0222&lt;/td&gt; 
   &lt;td align="right"&gt;0.0217&lt;/td&gt; 
   &lt;td align="right"&gt;0.0219&lt;/td&gt; 
   &lt;td align="right"&gt;0.0219&lt;/td&gt; 
   &lt;td align="right"&gt;119665&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;-0.395&lt;/td&gt; 
   &lt;td align="right"&gt;0.1813&lt;/td&gt; 
   &lt;td align="right"&gt;-0.4375&lt;/td&gt; 
   &lt;td align="right"&gt;0.1639&lt;/td&gt; 
   &lt;td align="right"&gt;1.058&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;2025Q2&lt;/td&gt; 
   &lt;td align="right"&gt;0.0218&lt;/td&gt; 
   &lt;td align="right"&gt;0.0217&lt;/td&gt; 
   &lt;td align="right"&gt;0.0216&lt;/td&gt; 
   &lt;td align="right"&gt;0.0216&lt;/td&gt; 
   &lt;td align="right"&gt;0.0216&lt;/td&gt; 
   &lt;td align="right"&gt;195229&lt;/td&gt; 
   &lt;td align="right"&gt;0&lt;/td&gt; 
   &lt;td align="right"&gt;-0.0137&lt;/td&gt; 
   &lt;td align="right"&gt;0.1415&lt;/td&gt; 
   &lt;td align="right"&gt;-0.053&lt;/td&gt; 
   &lt;td align="right"&gt;0.1361&lt;/td&gt; 
   &lt;td align="right"&gt;1.0435&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Questions &amp;amp; Answers&lt;/h1&gt; 
&lt;p&gt;In this section you can find answers to commonly asked questions. In case the answer to your question is not here, consider creating an &lt;a href="https://github.com/JerBouma/FinanceDatabase/issues"&gt;Issue&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;How is the data obtained?&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The data is an aggregation of various publicly available sources. I strictly maintain the rule that all data in this database must be freely accessible to everyone. Data requiring API keys or paid subscriptions is never included. Information that companies charge for is typically owned and maintained by those companies, making public sharing of such data a violation of their Terms of Service (ToS). However, publicly available data can be freely shared (read more about the legality of web scraping &lt;a href="https://techcrunch.com/2022/04/18/web-scraping-legal-court/?guccounter=1&amp;amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;amp;guce_referrer_sig=AQAAAJRZe3F6wCbuO_n8PJ9JtAHpOY4dF2gA_tO0gJF2PhfWUueUcRQataJwNS9FZlp9rH8f8_aiCBfA2v7wlHyXyVLUfMrca4kq0_m6CYSvK7eMk9zuEhnXJOvE0lrHWXSPTtL-lHP8UJD4SyWTpQ2BnCNx-kv3mG7GGn_G_3SGVvhP"&gt;here&lt;/a&gt;). This database will always remain &lt;u&gt;completely free&lt;/u&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;What categorization method is used?&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The categorization for Equities is based on a loose approximation of GICS (Global Industry Classification Standard). This database attempts to reflect sectors and industries as accurately as possible through manual curation, without collecting any actual data from MSCI's proprietary sources. The official GICS datasets curated by MSCI remain the most up-to-date, paid solution and were not used in developing any part of this database. All other categorizations in the database are independently developed and can be freely modified.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;How can I contribute?&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Please see the &lt;a href="https://github.com/JerBouma/FinanceDatabase/raw/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;. Thank you!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;How can I find out which countries, sectors and/or industries exist within the database without needing to check the database manually?&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For this you can use the &lt;code&gt;show_options&lt;/code&gt; function from the package attached to this database within a specific asset class or on a higher level without requiring any data to be loaded beforehand. See &lt;a href="https://raw.githubusercontent.com/JerBouma/FinanceDatabase/main/#usage"&gt;Usage&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;When I try collect data I notice that not all tickers return output, why is that?&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Some tickers are merely holdings of companies and therefore do not really have any data attached to them. Therefore, it makes sense that not all tickers return data. If you are still in doubt, search the ticker on Google to see if there is really no data available. If you can't find anything about the ticker, consider updating the database by visiting the &lt;a href="https://github.com/JerBouma/FinanceDatabase/raw/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;How does the database handle changes to companies over time - like symbol/exchange migration, mergers, bankruptcies, or symbols getting reused?&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For American exchanges, the database automatically updates every Sunday using data from &lt;a href="https://github.com/rreichel3/US-Stock-Symbols"&gt;this repository&lt;/a&gt;. This process includes checks for market cap changes and updates asset classifications accordingly. Delisted tickers are intentionally retained for historical research purposes.&lt;/p&gt; 
&lt;p&gt;While professional financial data services like Bloomberg charge over $25,000 annually for comprehensive market data maintenance, this database relies on community contributions. When companies outside American exchanges undergo changes (migrations, mergers, bankruptcies), we depend on community members to identify and update these entries.&lt;/p&gt; 
&lt;p&gt;Most companies don't change so rapidly that the database becomes obsolete - major changes like Facebook's rebrand to META are quickly incorporated. Even when companies go bankrupt, their ticker information remains valuable for historical analysis.&lt;/p&gt; 
&lt;p&gt;If you notice outdated information, please consider contributing through the &lt;a href="https://github.com/JerBouma/FinanceDatabase/raw/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Contributions&lt;/h1&gt; 
&lt;p&gt;This section is meant to thank those that contributed to the project. Looking to contribute as well? Have a look &lt;a href="https://github.com/JerBouma/FinanceDatabase/raw/main/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;User&lt;/th&gt; 
   &lt;th&gt;Contribution&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/desaijimmy"&gt;desaijimmy&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Made changes to Equities dataset including the Split of Daimler to Mercedes-Benz and Daimler Trucks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/nindogo"&gt;nindogo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Introduced a variety of new equities from the Nairobi Securities Exchange and introduced the country Kenya into the dataset.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/colin99d"&gt;colin99d&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Helped in the conversion of the Finance Database package to Object-Orientated, making the code much more efficient.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Contact&lt;/h1&gt; 
&lt;p&gt;If you have any questions about the FinanceDatabase or would like to share with me what you have been working on, feel free to reach out to me via:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: &lt;a href="https://jeroenbouma.com/"&gt;https://jeroenbouma.com/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LinkedIn:&lt;/strong&gt; &lt;a href="https://www.linkedin.com/in/boumajeroen/"&gt;https://www.linkedin.com/in/boumajeroen/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Email:&lt;/strong&gt; &lt;a href="mailto:jer.bouma@gmail.com"&gt;jer.bouma@gmail.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;f you'd like to support my efforts, either help me out via the &lt;a href="https://github.com/JerBouma/FinanceDatabase/raw/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt; or &lt;a href="https://www.buymeacoffee.com/jerbouma"&gt;Buy me a Coffee&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#JerBouma/FinanceDatabase&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=JerBouma/FinanceDatabase&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>