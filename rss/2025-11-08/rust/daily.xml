<rss version="2.0">
  <channel>
    <title>GitHub Rust Daily Trending</title>
    <description>Daily Trending of Rust in GitHub</description>
    <pubDate>Fri, 07 Nov 2025 01:39:47 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>n0-computer/iroh</title>
      <link>https://github.com/n0-computer/iroh</link>
      <description>&lt;p&gt;peer-2-peer that just works&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;&lt;a href="https://iroh.computer"&gt;&lt;img alt="iroh" src="https://raw.githubusercontent.com/n0-computer/iroh/main/.img/iroh_wordmark.svg?sanitize=true" width="100" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;h3 align="center"&gt; less net work for networks &lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://docs.rs/iroh/"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/iroh"&gt;&lt;img src="https://img.shields.io/crates/v/iroh.svg?style=flat-square" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/iroh"&gt;&lt;img src="https://img.shields.io/crates/d/iroh.svg?style=flat-square" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/DpmJgtU7cW"&gt;&lt;img src="https://img.shields.io/discord/1161119546170687619?logo=discord&amp;amp;style=flat-square" alt="Chat" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/@n0computer"&gt;&lt;img src="https://img.shields.io/badge/YouTube-red?logo=youtube&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Youtube" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/LICENSE-MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/LICENSE-APACHE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=flat-square" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/n0-computer/iroh/actions/workflows/ci.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/n0-computer/iroh/ci.yml?branch=main&amp;amp;style=flat-square&amp;amp;label=CI" alt="CI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt; &lt;a href="https://iroh.computer/docs"&gt; Docs Site &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://docs.rs/iroh"&gt; Rust Docs &lt;/a&gt; &lt;/h3&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;What is iroh?&lt;/h2&gt; 
&lt;p&gt;Iroh gives you an API for dialing by public key. You say ‚Äúconnect to that phone‚Äù, iroh will find &amp;amp; maintain the fastest connection for you, regardless of where it is.&lt;/p&gt; 
&lt;h3&gt;Hole-punching&lt;/h3&gt; 
&lt;p&gt;The fastest route is a direct connection, so if necessary, iroh tries to hole-punch. Should this fail, it can fall back to an open ecosystem of public relay servers. To ensure these connections are as fast as possible, we &lt;a href="https://perf.iroh.computer"&gt;continuously measure iroh&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Built on &lt;a href="https://en.wikipedia.org/wiki/QUIC"&gt;QUIC&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Iroh uses &lt;a href="https://github.com/quinn-rs/quinn"&gt;Quinn&lt;/a&gt; to establish &lt;a href="https://en.wikipedia.org/wiki/QUIC"&gt;QUIC&lt;/a&gt; connections between endpoints. This way you get authenticated encryption, concurrent streams with stream priorities, a datagram transport and avoid head-of-line-blocking out of the box.&lt;/p&gt; 
&lt;h2&gt;Compose Protocols&lt;/h2&gt; 
&lt;p&gt;Use pre-existing protocols built on iroh instead of writing your own:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-blobs"&gt;iroh-blobs&lt;/a&gt; for &lt;a href="https://github.com/BLAKE3-team/BLAKE3"&gt;BLAKE3&lt;/a&gt;-based content-addressed blob transfer scaling from kilobytes to terabytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-gossip"&gt;iroh-gossip&lt;/a&gt; for establishing publish-subscribe overlay networks that scale, requiring only resources that your average phone can handle&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-docs"&gt;iroh-docs&lt;/a&gt; for an eventually-consistent key-value store of &lt;a href="https://github.com/n0-computer/iroh-blobs"&gt;iroh-blobs&lt;/a&gt; blobs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-willow"&gt;iroh-willow&lt;/a&gt; for an (in-construction) implementation of the &lt;a href="https://willowprotocol.org"&gt;willow protocol&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Rust Library&lt;/h3&gt; 
&lt;p&gt;It's easiest to use iroh from rust. Install it using &lt;code&gt;cargo add iroh&lt;/code&gt;, then on the connecting side:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rs"&gt;const ALPN: &amp;amp;[u8] = b"iroh-example/echo/0";

let endpoint = Endpoint::bind().await?;

// Open a connection to the accepting endpoint
let conn = endpoint.connect(addr, ALPN).await?;

// Open a bidirectional QUIC stream
let (mut send, mut recv) = conn.open_bi().await?;

// Send some data to be echoed
send.write_all(b"Hello, world!").await?;
send.finish()?;

// Receive the echo
let response = recv.read_to_end(1000).await?;
assert_eq!(&amp;amp;response, b"Hello, world!");

// As the side receiving the last application data - say goodbye
conn.close(0u32.into(), b"bye!");

// Close the endpoint and all its connections
endpoint.close().await;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And on the accepting side:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rs"&gt;let endpoint = Endpoint::bind().await?;

let router = Router::builder(endpoint)
    .accept(ALPN.to_vec(), Arc::new(Echo))
    .spawn()
    .await?;

// The protocol definition:
#[derive(Debug, Clone)]
struct Echo;

impl ProtocolHandler for Echo {
    async fn accept(&amp;amp;self, connection: Connection) -&amp;gt; Result&amp;lt;()&amp;gt; {
        let (mut send, mut recv) = connection.accept_bi().await?;

        // Echo any bytes received back directly.
        let bytes_sent = tokio::io::copy(&amp;amp;mut recv, &amp;amp;mut send).await?;

        send.finish()?;
        connection.closed().await;

        Ok(())
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The full example code with more comments can be found at &lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/iroh/examples/echo.rs"&gt;&lt;code&gt;echo.rs&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Or use one of the pre-existing protocols, e.g. &lt;a href="https://github.com/n0-computer/iroh-blobs"&gt;iroh-blobs&lt;/a&gt; or &lt;a href="https://github.com/n0-computer/iroh-gossip"&gt;iroh-gossip&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Other Languages&lt;/h3&gt; 
&lt;p&gt;If you want to use iroh from other languages, make sure to check out &lt;a href="https://github.com/n0-computer/iroh-ffi"&gt;iroh-ffi&lt;/a&gt;, the repository for FFI bindings.&lt;/p&gt; 
&lt;h3&gt;Links&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=RwAt36Xe3UI_"&gt;Introducing Iroh (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://iroh.computer/docs"&gt;Iroh Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-examples"&gt;Iroh Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-experiments"&gt;Iroh Experiments&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Repository Structure&lt;/h2&gt; 
&lt;p&gt;This repository contains a workspace of crates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;iroh&lt;/code&gt;: The core library for hole-punching &amp;amp; communicating with relays.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;iroh-relay&lt;/code&gt;: The relay server implementation. This is the code we run in production (and you can, too!).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;iroh-base&lt;/code&gt;: Common types like &lt;code&gt;Hash&lt;/code&gt;, key types or &lt;code&gt;RelayUrl&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;iroh-dns-server&lt;/code&gt;: DNS server implementation powering the &lt;code&gt;n0_discovery&lt;/code&gt; for EndpointIds, running at dns.iroh.link.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;iroh-net-report&lt;/code&gt;: Analyzes your host's networking ability &amp;amp; NAT.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright 2025 N0, INC.&lt;/p&gt; 
&lt;p&gt;This project is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="http://opensource.org/licenses/MIT"&gt;http://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in this project by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>a2x/cs2-dumper</title>
      <link>https://github.com/a2x/cs2-dumper</link>
      <description>&lt;p&gt;Counter-Strike: 2 Offset Dumper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;cs2-dumper&lt;/h1&gt; 
&lt;p&gt;An external offset/interface dumper for Counter-Strike 2, with support for both Windows &amp;amp; Linux. Powered by &lt;a href="https://github.com/memflow/memflow"&gt;memflow&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The native Linux version is available in the &lt;a href="https://github.com/a2x/cs2-dumper/tree/linux"&gt;linux&lt;/a&gt; branch (currently outdated).&lt;/p&gt; 
&lt;p&gt;For a work-in-progress offline version, check out the &lt;a href="https://github.com/a2x/cs2-analyzer"&gt;cs2-analyzer&lt;/a&gt; repository or view its included web demo &lt;a href="https://a2x.github.io/cs2-analyzer"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;You can download the latest release from &lt;a href="https://github.com/a2x/cs2-dumper/releases"&gt;Releases&lt;/a&gt; or compile it yourself. Note that compiling it yourself requires your Rust compiler version to be at least 1.74.0 or newer.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Ensure the game is running (Being in the main menu should suffice).&lt;/li&gt; 
 &lt;li&gt;Run the &lt;code&gt;cs2-dumper&lt;/code&gt; executable.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; If you run the executable without specifying an optional memflow connector name, it will automatically use the &lt;a href="https://github.com/memflow/memflow-native"&gt;memflow-native&lt;/a&gt; OS layer to read the memory of the game process. If you wish to use an existing memflow connector instead, such as &lt;strong&gt;pcileech&lt;/strong&gt; or &lt;strong&gt;kvm&lt;/strong&gt;, you can pass the &lt;code&gt;connector&lt;/code&gt; and optional &lt;code&gt;connector-args&lt;/code&gt; arguments to the program. These connectors can be installed and managed using the &lt;a href="https://github.com/memflow/memflowup"&gt;memflowup&lt;/a&gt; tool.&lt;/p&gt; 
&lt;p&gt;E.g (for pcileech). &lt;code&gt;cs2-dumper -c pcileech -a :device=FPGA -vv&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Certain connectors, such as the &lt;a href="https://github.com/memflow/memflow-kvm"&gt;kvm&lt;/a&gt; connector on Linux or the &lt;a href="https://github.com/memflow/memflow-pcileech"&gt;pcileech&lt;/a&gt; / &lt;a href="https://github.com/a2x/memflow-winio"&gt;winio&lt;/a&gt; connectors on Windows, require elevated privileges to work. So either run the &lt;code&gt;cs2-dumper&lt;/code&gt; executable with &lt;code&gt;sudo&lt;/code&gt; on Linux or as an administrator on Windows.&lt;/p&gt; 
&lt;h3&gt;Available Arguments&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-c, --connector &amp;lt;connector&amp;gt;&lt;/code&gt;: The name of the memflow connector to use.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-a, --connector-args &amp;lt;connector-args&amp;gt;&lt;/code&gt;: Additional arguments to pass to the memflow connector.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-f, --file-types &amp;lt;file-types&amp;gt;&lt;/code&gt;: The types of files to generate. Default: &lt;code&gt;cs&lt;/code&gt;, &lt;code&gt;hpp&lt;/code&gt;, &lt;code&gt;json&lt;/code&gt;, &lt;code&gt;rs&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-i, --indent-size &amp;lt;indent-size&amp;gt;&lt;/code&gt;: The number of spaces to use per indentation level. Default: &lt;code&gt;4&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-o, --output &amp;lt;output&amp;gt;&lt;/code&gt;: The output directory to write the generated files to. Default: &lt;code&gt;output&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p, --process-name &amp;lt;process-name&amp;gt;&lt;/code&gt;: The name of the game process. Default: &lt;code&gt;cs2.exe&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v...&lt;/code&gt;: Increase logging verbosity. Can be specified multiple times.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h, --help&lt;/code&gt;: Print help.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-V, --version&lt;/code&gt;: Print version.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Running Tests&lt;/h2&gt; 
&lt;p&gt;To run the few basic provided tests, use the following command: &lt;code&gt;cargo test -- --nocapture&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the MIT license (&lt;a href="https://raw.githubusercontent.com/a2x/cs2-dumper/main/LICENSE"&gt;LICENSE&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kata-containers/kata-containers</title>
      <link>https://github.com/kata-containers/kata-containers</link>
      <description>&lt;p&gt;Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/&lt;/p&gt;&lt;hr&gt;&lt;img src="https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-images-prod/openstack-logo/kata/SVG/kata-1.svg?sanitize=true" width="900" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml"&gt;&lt;img src="https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml/badge.svg?sanitize=true" alt="CI | Publish Kata Containers payload" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml"&gt;&lt;img src="https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml/badge.svg?sanitize=true" alt="Kata Containers Nightly CI" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/kata-containers/kata-containers"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/kata-containers/kata-containers/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Kata Containers&lt;/h1&gt; 
&lt;p&gt;Welcome to Kata Containers!&lt;/p&gt; 
&lt;p&gt;This repository is the home of the Kata Containers code for the 2.0 and newer releases.&lt;/p&gt; 
&lt;p&gt;If you want to learn about Kata Containers, visit the main &lt;a href="https://katacontainers.io"&gt;Kata Containers website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The code is licensed under the Apache 2.0 license. See &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/LICENSE"&gt;the license file&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;Kata Containers currently runs on 64-bit systems supporting the following technologies:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;Virtualization technology&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x86_64&lt;/code&gt;, &lt;code&gt;amd64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.intel.com"&gt;Intel&lt;/a&gt; VT-x, AMD SVM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;aarch64&lt;/code&gt; ("&lt;code&gt;arm64&lt;/code&gt;")&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.arm.com"&gt;ARM&lt;/a&gt; Hyp&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ppc64le&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.ibm.com"&gt;IBM&lt;/a&gt; Power&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;s390x&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.ibm.com"&gt;IBM&lt;/a&gt; Z &amp;amp; LinuxONE SIE&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware requirements&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;Kata Containers runtime&lt;/a&gt; provides a command to determine if your host system is capable of running and creating a Kata Container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ kata-runtime check
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;This command runs a number of checks including connecting to the network to determine if a newer release of Kata Containers is available on GitHub. If you do not wish this to check to run, add the &lt;code&gt;--no-network-checks&lt;/code&gt; option.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;By default, only a brief success / failure message is printed. If more details are needed, the &lt;code&gt;--verbose&lt;/code&gt; flag can be used to display the list of all the checks performed.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;If the command is run as the &lt;code&gt;root&lt;/code&gt; user additional checks are run (including checking if another incompatible hypervisor is running). When running as &lt;code&gt;root&lt;/code&gt;, network checks are automatically disabled.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install"&gt;installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs"&gt;official documentation&lt;/a&gt; including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install"&gt;Installation guides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/Developer-Guide.md"&gt;Developer guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design"&gt;Design documents&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design/architecture"&gt;Architecture overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design/architecture_3.0/"&gt;Architecture 3.0 overview&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Kata Containers uses a single &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime/README.md#configuration"&gt;configuration file&lt;/a&gt; which contains a number of sections for various parts of the Kata Containers system including the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;runtime&lt;/a&gt;, the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/agent"&gt;agent&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/#hypervisors"&gt;hypervisor&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Hypervisors&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/hypervisors.md"&gt;hypervisors document&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime/README.md#hypervisor-specific-configuration"&gt;Hypervisor specific configuration details&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;To learn more about the project, its community and governance, see the &lt;a href="https://github.com/kata-containers/community"&gt;community repository&lt;/a&gt;. This is the first place to go if you wish to contribute to the project.&lt;/p&gt; 
&lt;h2&gt;Getting help&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/#community"&gt;community&lt;/a&gt; section for ways to contact us.&lt;/p&gt; 
&lt;h3&gt;Raising issues&lt;/h3&gt; 
&lt;p&gt;Please raise an issue &lt;a href="https://github.com/kata-containers/kata-containers/issues"&gt;in this repository&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you are reporting a security issue, please follow the &lt;a href="https://github.com/kata-containers/community#vulnerability-handling"&gt;vulnerability reporting process&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Developers&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/Developer-Guide.md"&gt;developer guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Components&lt;/h3&gt; 
&lt;h3&gt;Main components&lt;/h3&gt; 
&lt;p&gt;The table below lists the core parts of the project:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;runtime&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;Main component run by a container manager and providing a containerd shimv2 runtime implementation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime-rs"&gt;runtime-rs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;The Rust version runtime.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/agent"&gt;agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;Management process running inside the virtual machine / POD that sets up the container environment.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/dragonball"&gt;&lt;code&gt;dragonball&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;An optional built-in VMM brings out-of-the-box Kata Containers experience with optimizations on container workloads&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs"&gt;documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;documentation&lt;/td&gt; 
   &lt;td&gt;Documentation common to all components (such as design and install documentation).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests"&gt;tests&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;tests&lt;/td&gt; 
   &lt;td&gt;Excludes unit tests which live with the main code.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Additional components&lt;/h3&gt; 
&lt;p&gt;The table below lists the remaining parts of the project:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging"&gt;packaging&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Scripts and metadata for producing packaged binaries&lt;br /&gt;(components, hypervisors, kernel and rootfs).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.kernel.org"&gt;kernel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;kernel&lt;/td&gt; 
   &lt;td&gt;Linux kernel used by the hypervisor to boot the guest image. Patches are stored &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kernel"&gt;here&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/osbuilder"&gt;osbuilder&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Tool to create "mini O/S" rootfs and initrd images and kernel for the hypervisor.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-debug/README.md"&gt;kata-debug&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Utility tool to gather Kata Containers debug information from Kubernetes clusters.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/agent-ctl"&gt;&lt;code&gt;agent-ctl&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Tool that provides low-level access for testing the agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/kata-ctl"&gt;&lt;code&gt;kata-ctl&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Tool that provides advanced commands and debug facilities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/trace-forwarder"&gt;&lt;code&gt;trace-forwarder&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Agent tracing helper.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/runk"&gt;&lt;code&gt;runk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Standard OCI container runtime based on the agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/.github/workflows"&gt;&lt;code&gt;ci&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CI&lt;/td&gt; 
   &lt;td&gt;Continuous Integration configuration files and scripts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/ci/openshift-ci/README.md"&gt;&lt;code&gt;ocp-ci&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CI&lt;/td&gt; 
   &lt;td&gt;Continuous Integration configuration for the OpenShift pipelines.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kata-containers/www.katacontainers.io"&gt;&lt;code&gt;katacontainers.io&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Source for the &lt;a href="https://www.katacontainers.io"&gt;&lt;code&gt;katacontainers.io&lt;/code&gt;&lt;/a&gt; site.&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/testing/kata-webhook/README.md"&gt;&lt;code&gt;Webhook&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Example of a simple admission controller webhook to annotate pods with the Kata runtime class&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Packaging and releases&lt;/h3&gt; 
&lt;p&gt;Kata Containers is now &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install/README.md#packaged-installation-methods"&gt;available natively for most distributions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;General tests&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests/README.md"&gt;tests documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Metrics tests&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests/metrics/README.md"&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Glossary of Terms&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/kata-containers/kata-containers/wiki/Glossary"&gt;glossary of terms&lt;/a&gt; related to Kata Containers.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hyperium/tonic</title>
      <link>https://github.com/hyperium/tonic</link>
      <description>&lt;p&gt;A native gRPC client &amp; server implementation with async/await support.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/hyperium/tonic/raw/master/.github/assets/tonic-banner.svg?sanitize=true" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;A rust implementation of &lt;a href="https://grpc.io"&gt;gRPC&lt;/a&gt;, a high performance, open source, general RPC framework that puts mobile and HTTP/2 first.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: tonic's &lt;a href="https://github.com/hyperium/tonic"&gt;master&lt;/a&gt; branch is currently preparing breaking changes. For the most recently &lt;em&gt;released&lt;/em&gt; code, look to the &lt;a href="https://github.com/hyperium/tonic/tree/v0.14.x"&gt;0.14.x branch&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/tonic"&gt;&lt;code&gt;tonic&lt;/code&gt;&lt;/a&gt; is a gRPC over HTTP/2 implementation focused on high performance, interoperability, and flexibility. This library was created to have first class support of async/await and to act as a core building block for production systems written in Rust.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/tonic"&gt;&lt;img src="https://img.shields.io/crates/v/tonic" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/tonic"&gt;&lt;img src="https://docs.rs/tonic/badge.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/LICENSE"&gt;&lt;img src="https://img.shields.io/crates/l/tonic" alt="Crates.io" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hyperium/tonic/tree/master/examples"&gt;Examples&lt;/a&gt; | &lt;a href="https://github.com/hyperium/tonic"&gt;Website&lt;/a&gt; | &lt;a href="https://docs.rs/tonic"&gt;Docs&lt;/a&gt; | &lt;a href="https://discord.gg/6yGkFeN"&gt;Chat&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/tonic"&gt;&lt;code&gt;tonic&lt;/code&gt;&lt;/a&gt; is composed of three main components: the generic gRPC implementation, the high performance HTTP/2 implementation and the codegen powered by &lt;a href="https://github.com/tokio-rs/prost"&gt;&lt;code&gt;prost&lt;/code&gt;&lt;/a&gt;. The generic implementation can support any HTTP/2 implementation and any encoding via a set of generic traits. The HTTP/2 implementation is based on &lt;a href="https://github.com/hyperium/hyper"&gt;&lt;code&gt;hyper&lt;/code&gt;&lt;/a&gt;, a fast HTTP/1.1 and HTTP/2 client and server built on top of the robust &lt;a href="https://github.com/tokio-rs/tokio"&gt;&lt;code&gt;tokio&lt;/code&gt;&lt;/a&gt; stack. The codegen contains the tools to build clients and servers from &lt;a href="https://protobuf.dev/"&gt;&lt;code&gt;protobuf&lt;/code&gt;&lt;/a&gt; definitions.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bi-directional streaming&lt;/li&gt; 
 &lt;li&gt;High performance async io&lt;/li&gt; 
 &lt;li&gt;Interoperability&lt;/li&gt; 
 &lt;li&gt;TLS backed by &lt;a href="https://github.com/rustls/rustls"&gt;&lt;code&gt;rustls&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Load balancing&lt;/li&gt; 
 &lt;li&gt;Custom metadata&lt;/li&gt; 
 &lt;li&gt;Authentication&lt;/li&gt; 
 &lt;li&gt;Health Checking&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://github.com/hyperium/tonic/raw/master/examples/helloworld-tutorial.md"&gt;&lt;code&gt;helloworld&lt;/code&gt;&lt;/a&gt; tutorial provides a basic example of using &lt;code&gt;tonic&lt;/code&gt;, perfect for first time users!&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://github.com/hyperium/tonic/raw/master/examples/routeguide-tutorial.md"&gt;&lt;code&gt;routeguide&lt;/code&gt;&lt;/a&gt; tutorial provides a complete example of using &lt;code&gt;tonic&lt;/code&gt; and all its features.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Examples can be found in &lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/examples"&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; and for more complex scenarios &lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/interop"&gt;&lt;code&gt;interop&lt;/code&gt;&lt;/a&gt; may be a good resource as it shows examples of many of the gRPC features.&lt;/p&gt; 
&lt;h3&gt;Rust Version&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;tonic&lt;/code&gt;'s MSRV is &lt;code&gt;1.75&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Dependencies&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/tonic-build"&gt;&lt;code&gt;tonic-build&lt;/code&gt;&lt;/a&gt; uses &lt;code&gt;protoc&lt;/code&gt; &lt;a href="https://protobuf.dev/downloads/"&gt;Protocol Buffers compiler&lt;/a&gt; in some APIs which compile Protocol Buffers resource files such as &lt;a href="https://docs.rs/tonic-build/latest/tonic_build/fn.compile_protos.html"&gt;&lt;code&gt;tonic_build::compile_protos()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;First, see if the answer to your question can be found in the API documentation. If the answer is not there, there is an active community in the &lt;a href="https://discord.gg/6yGkFeN"&gt;Tonic Discord channel&lt;/a&gt;. We would be happy to try to answer your question. If that doesn't work, try opening an &lt;a href="https://github.com/hyperium/tonic/issues/new/choose"&gt;issue&lt;/a&gt; with the question.&lt;/p&gt; 
&lt;h2&gt;Project Layout&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/tonic"&gt;&lt;code&gt;tonic&lt;/code&gt;&lt;/a&gt;: Generic gRPC and HTTP/2 client/server implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/tonic-build"&gt;&lt;code&gt;tonic-build&lt;/code&gt;&lt;/a&gt;: &lt;a href="https://github.com/tokio-rs/prost"&gt;&lt;code&gt;prost&lt;/code&gt;&lt;/a&gt; based service codegen.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/tonic-types"&gt;&lt;code&gt;tonic-types&lt;/code&gt;&lt;/a&gt;: &lt;a href="https://github.com/tokio-rs/prost"&gt;&lt;code&gt;prost&lt;/code&gt;&lt;/a&gt; based grpc utility types including support for gRPC Well Known Types.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/tonic-health"&gt;&lt;code&gt;tonic-health&lt;/code&gt;&lt;/a&gt;: Implementation of the standard &lt;a href="https://grpc.io/docs/guides/health-checking/"&gt;gRPC health checking service&lt;/a&gt;. Also serves as an example of both unary and response streaming.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/tonic-reflection"&gt;&lt;code&gt;tonic-reflection&lt;/code&gt;&lt;/a&gt;: A tonic based gRPC reflection implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/examples"&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt;: Example gRPC implementations showing off tls, load balancing and bi-directional streaming.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/interop"&gt;&lt;code&gt;interop&lt;/code&gt;&lt;/a&gt;: Interop tests implementation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;üéà&lt;/span&gt; Thanks for your help improving the project! We are so happy to have you! We have a &lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to help you get involved in the Tonic project.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/hyperium/tonic/master/LICENSE"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contribution&lt;/h3&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Tonic by you, shall be licensed as MIT, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aptos-labs/aptos-core</title>
      <link>https://github.com/aptos-labs/aptos-core</link>
      <description>&lt;p&gt;Aptos is a layer 1 blockchain built to support the widespread use of blockchain through better technology and user experience.&lt;/p&gt;&lt;hr&gt;&lt;a href="https://aptos.dev"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/aptos-labs/aptos-core/main/.assets/aptos_banner.png" alt="Aptos Banner" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/aptos-labs/aptos-core/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache-green.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aptos-labs/aptos-core/actions/workflows/lint-test.yaml"&gt;&lt;img src="https://github.com/aptos-labs/aptos-core/actions/workflows/lint-test.yaml/badge.svg?sanitize=true" alt="Lint+Test" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/aptos-labs/aptos-core"&gt;&lt;img src="https://codecov.io/gh/aptos-labs/aptos-core/branch/main/graph/badge.svg?token=X01RKXSGDE" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/aptosnetwork"&gt;&lt;img src="https://img.shields.io/discord/945856774056083548?style=flat-square" alt="Discord chat" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Aptos is a layer 1 blockchain bringing a paradigm shift to Web3 through better technology and user experience. Built with Move to create a home for developers building next-gen applications.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aptosfoundation.org/"&gt;Aptos Foundation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aptos.dev"&gt;Aptos Developer Network&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aptos.dev/guides/system-integrators-guide"&gt;Guide - Integrate with the Aptos Blockchain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aptos.dev/tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://twitter.com/Aptos"&gt;Twitter&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join us on the &lt;a href="https://discord.gg/aptosnetwork"&gt;Aptos Discord&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;You can learn more about contributing to the Aptos project by reading our &lt;a href="https://github.com/aptos-labs/aptos-core/raw/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; and by viewing our &lt;a href="https://github.com/aptos-labs/aptos-core/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Aptos Core is licensed under &lt;a href="https://github.com/aptos-labs/aptos-core/raw/main/LICENSE"&gt;Apache 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>slint-ui/slint</title>
      <link>https://github.com/slint-ui/slint</link>
      <description>&lt;p&gt;Slint is an open-source declarative GUI toolkit to build native user interfaces for Rust, C++, JavaScript, or Python apps.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/slint-ui/slint/master/logo/slint-logo-full-light.svg#gh-light-mode-only" alt="Slint" /&gt; &lt;img src="https://raw.githubusercontent.com/slint-ui/slint/master/logo/slint-logo-full-dark.svg#gh-dark-mode-only" alt="Slint" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/slint-ui/slint/actions"&gt;&lt;img src="https://github.com/slint-ui/slint/workflows/CI/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://api.reuse.software/info/github.com/slint-ui/slint"&gt;&lt;img src="https://api.reuse.software/badge/github.com/slint-ui/slint" alt="REUSE status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/slint-ui/slint/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/slint-ui/slint" alt="Discussions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Slint&lt;/strong&gt; is an open-source declarative GUI toolkit for building native user interfaces for embedded systems, desktops, and mobile platforms.&lt;/p&gt; 
&lt;p&gt;Write your UI once in &lt;code&gt;.slint&lt;/code&gt;, a simple markup language. Connect it to business logic written in Rust, C++, JavaScript, or Python.&lt;/p&gt; 
&lt;h2&gt;Why Slint?&lt;/h2&gt; 
&lt;p&gt;The name &lt;em&gt;Slint&lt;/em&gt; is derived from our design goals:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable&lt;/strong&gt;: Slint should support responsive UI design, allow cross-platform usage across operating systems and processor architectures and support multiple programming languages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: Slint should require minimal resources, in terms of memory and processing power, and yet deliver a smooth, smartphone-like user experience on any device.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intuitive&lt;/strong&gt;: Designers and developers should feel productive while enjoying the GUI design and development process. The design creation tools should be intuitive to use for the designers. Similarly for the developers, the APIs should be consistent and easy to use, no matter which programming language they choose.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native&lt;/strong&gt;: GUI built with Slint should match the end users' expectations of a native application irrespective of the platform - desktop, mobile, web or embedded system. The UI design should be compiled to machine code and provide flexibility that only a native application can offer: Access full operating system APIs, utilize all CPU and GPU cores, connect to any peripheral.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Beyond the design goals, here‚Äôs what makes Slint stand out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Independent UI Design&lt;/strong&gt;: Use a declarative language similar to separate your UI from business logic. Designers can work in parallel with developers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tooling&lt;/strong&gt;: Iterate quickly with our Live Preview &amp;amp; editor integrations. Integrate from Figma with the &lt;a href="https://www.figma.com/community/plugin/1474418299182276871/figma-to-slint"&gt;Figma to Slint plugin&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stable APIs&lt;/strong&gt;: Slint follows a stable 1.x API. We evolve carefully without breaking your code.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See what others have built: &lt;a href="https://madewithslint.com"&gt;#MadeWithSlint&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;h3&gt;Embedded&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;RaspberryPi&lt;/th&gt; 
   &lt;th&gt;STM32&lt;/th&gt; 
   &lt;th&gt;RP2040&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=_BDbNHrjK7g"&gt;Video of Slint on Raspberry Pi&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=NNNOJJsOAis"&gt;Video of Slint on STM32&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=dkBwNocItGs"&gt;Video of Slint on RP2040&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Desktop&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Windows&lt;/th&gt; 
   &lt;th&gt;macOS&lt;/th&gt; 
   &lt;th&gt;Linux&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://slint.dev/resources/gallery_win_screenshot.png" alt="Screenshot of the Gallery on Windows" title="Gallery" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://slint.dev/resources/gallery_mac_screenshot.png" alt="Screenshot of the Gallery on macOS" title="Gallery" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://slint.dev/resources/gallery_linux_screenshot.png" alt="Screenshot of the Gallery on Linux" title="Gallery" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Web using WebAssembly&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Printer Demo&lt;/th&gt; 
   &lt;th&gt;Slide Puzzle&lt;/th&gt; 
   &lt;th&gt;Energy Monitor&lt;/th&gt; 
   &lt;th&gt;Widget Gallery&lt;/th&gt; 
   &lt;th&gt;Weather demo&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/printerdemo/"&gt;&lt;img src="https://slint.dev/resources/printerdemo_screenshot.png" alt="Screenshot of the Printer Demo" title="Printer Demo" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/slide_puzzle/"&gt;&lt;img src="https://slint.dev/resources/puzzle_screenshot.png" alt="Screenshot of the Slide Puzzle" title="Slide Puzzle" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/energy-monitor/"&gt;&lt;img src="https://slint.dev/resources/energy-monitor-screenshot.png" alt="Screenshot of the Energy Monitor Demo" title="Energy Monitor Demo" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/gallery/"&gt;&lt;img src="https://slint.dev/resources/gallery_screenshot.png" alt="Screenshot of the Gallery Demo" title="Gallery Demo" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/weather-demo/"&gt;&lt;img src="https://raw.githubusercontent.com/slint-ui/slint/master/demos/weather-demo/docs/img/desktop-preview.png" alt="Screenshot of the weather Demo" title="Weather Demo" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More examples and demos in the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/examples#examples"&gt;examples folder&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;h3&gt;Hello World&lt;/h3&gt; 
&lt;p&gt;The UI is defined in a Domain Specific Language that is declarative, easy to use, intuitive, and provides a powerful way to describe graphical elements, their placement, their hierarchy, property bindings, and the flow of data through the different states.&lt;/p&gt; 
&lt;p&gt;Here's the obligatory "Hello World":&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-slint"&gt;export component HelloWorld inherits Window {
    width: 400px;
    height: 400px;

    Text {
       y: parent.width / 2;
       x: parent.x + 200px;
       text: "Hello, world";
       color: blue;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;For more details, check out the &lt;a href="https://slint.dev/docs/slint"&gt;Slint Language Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/examples"&gt;examples&lt;/a&gt; folder contains examples and demos, showing how to use the Slint markup language and how to interact with a Slint user interface from supported programming languages.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;docs&lt;/code&gt; folder contains a lot more information, including &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/docs/building.md"&gt;build instructions&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/docs/development.md"&gt;internal developer docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Refer to the README of each language directory in the &lt;code&gt;api&lt;/code&gt; folder:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/api/cpp"&gt;C++&lt;/a&gt; (&lt;a href="https://slint.dev/latest/docs/cpp"&gt;Documentation&lt;/a&gt; | &lt;a href="https://github.com/slint-ui/slint-cpp-template"&gt;Getting Started Template&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/api/rs/slint"&gt;Rust&lt;/a&gt; &lt;a href="https://crates.io/crates/slint"&gt;&lt;img src="https://img.shields.io/crates/v/slint" alt="Crates.io" /&gt;&lt;/a&gt; (&lt;a href="https://slint.dev/latest/docs/rust/slint/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://youtu.be/WBcv4V-whHk"&gt;Tutorial Video&lt;/a&gt; | &lt;a href="https://github.com/slint-ui/slint-rust-template"&gt;Getting Started Template&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/api/node"&gt;JavaScript/NodeJS (Beta)&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/slint-ui"&gt;&lt;img src="https://img.shields.io/npm/v/slint-ui" alt="npm" /&gt;&lt;/a&gt; (&lt;a href="https://slint.dev/latest/docs/node"&gt;Documentation&lt;/a&gt; | &lt;a href="https://github.com/slint-ui/slint-nodejs-template"&gt;Getting Started Template&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/api/python/slint"&gt;Python (Beta)&lt;/a&gt; &lt;a href="https://pypi.org/project/slint/"&gt;&lt;img src="https://img.shields.io/pypi/v/slint" alt="pypi" /&gt;&lt;/a&gt; (&lt;a href="http://snapshots.slint.dev/master/docs/python/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://github.com/slint-ui/slint-python-template"&gt;Getting Started Template&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;An application is composed of the business logic written in Rust, C++, or JavaScript and the &lt;code&gt;.slint&lt;/code&gt; user interface design markup, which is compiled to native code.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://slint.dev/resources/architecture.drawio.svg?sanitize=true" alt="Architecture Overview" /&gt;&lt;/p&gt; 
&lt;h3&gt;Compiler&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;.slint&lt;/code&gt; files are compiled ahead of time. The expressions in the &lt;code&gt;.slint&lt;/code&gt; are pure functions that the compiler can optimize. For example, the compiler could choose to "inline" properties and remove those that are constant or unchanged.&lt;/p&gt; 
&lt;p&gt;The compiler uses the typical compiler phases of lexing, parsing, optimization, and finally code generation. It provides different back-ends for code generation in the target language. The C++ code generator produces a C++ header file, the Rust generator produces Rust code, and so on. An interpreter for dynamic languages is also included.&lt;/p&gt; 
&lt;h3&gt;Runtime&lt;/h3&gt; 
&lt;p&gt;The runtime library consists of an engine that supports properties declared in the &lt;code&gt;.slint&lt;/code&gt; language. Components with their elements, items, and properties are laid out in a single memory region, to reduce memory allocations.&lt;/p&gt; 
&lt;p&gt;Rendering backends and styles are configurable at compile time:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;femtovg&lt;/code&gt; renderer uses OpenGL ES 2.0 for rendering.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;skia&lt;/code&gt; renderer uses &lt;a href="https://skia.org"&gt;Skia&lt;/a&gt; for rendering.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;software&lt;/code&gt; renderer uses the CPU with no additional dependencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;NOTE: When Qt is installed on the system, the &lt;code&gt;qt&lt;/code&gt; style becomes available, using Qt's QStyle to achieve native looking widgets.&lt;/p&gt; 
&lt;h3&gt;Tooling&lt;/h3&gt; 
&lt;p&gt;We have a few tools to help with the development of .slint files:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/tools/lsp"&gt;&lt;strong&gt;LSP Server&lt;/strong&gt;&lt;/a&gt; that adds features like auto-complete and live preview of the .slint files to many editors.&lt;/li&gt; 
 &lt;li&gt;It is bundled in a &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/editors/vscode"&gt;&lt;strong&gt;Visual Studio Code Extension&lt;/strong&gt;&lt;/a&gt; available from the market place.&lt;/li&gt; 
 &lt;li&gt;A &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/tools/viewer"&gt;&lt;strong&gt;slint-viewer&lt;/strong&gt;&lt;/a&gt; tool which displays the .slint files. The &lt;code&gt;--auto-reload&lt;/code&gt; argument makes it easy to preview your UI while you are working on it (when using the LSP preview is not possible).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slintpad.com/"&gt;&lt;strong&gt;SlintPad&lt;/strong&gt;&lt;/a&gt;, an online editor to try out .slint syntax without installing anything (&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/tools/slintpad"&gt;sources&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;A &lt;a href="https://www.figma.com/community/plugin/1474418299182276871/figma-to-slint"&gt;&lt;strong&gt;Figma to Slint&lt;/strong&gt;&lt;/a&gt; plugin.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please check our &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/editors/README.md"&gt;Editors README&lt;/a&gt; for tips on how to configure your favorite editor to work well with Slint.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;You can use Slint under &lt;em&gt;&lt;strong&gt;any&lt;/strong&gt;&lt;/em&gt; of the following licenses, at your choice:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Build proprietary desktop, mobile, or web applications for free with the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/LICENSES/LicenseRef-Slint-Royalty-free-2.0.md"&gt;Royalty-free License&lt;/a&gt;,&lt;/li&gt; 
 &lt;li&gt;Build open source embedded, desktop, mobile, or web applications for free with the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/LICENSES/GPL-3.0-only.txt"&gt;GNU GPLv3&lt;/a&gt;,&lt;/li&gt; 
 &lt;li&gt;Build proprietary embedded, desktop, mobile, or web applications with the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/LICENSES/LicenseRef-Slint-Software-3.0.md"&gt;Paid license&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the &lt;a href="https://slint.dev/pricing.html"&gt;Slint licensing options on the website&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/FAQ.md#licensing"&gt;Licensing FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;We welcome your contributions: in the form of code, bug reports or feedback. For contribution guidelines see &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; 
&lt;p&gt;Please see our separate &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/FAQ.md"&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;About us (SixtyFPS GmbH)&lt;/h2&gt; 
&lt;p&gt;We are passionate about software - API design, cross-platform software development and user interface components. Our aim is to make developing user interfaces fun for everyone: from Python, JavaScript, C++, or Rust developers all the way to UI/UX designers. We believe that software grows organically and keeping it open source is the best way to sustain that growth. Our team members are located remotely in Germany, Finland, and US.&lt;/p&gt; 
&lt;h3&gt;Stay up to date&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://twitter.com/slint_ui"&gt;@slint_ui&lt;/a&gt; on X/Twitter.&lt;/li&gt; 
 &lt;li&gt;Follow &lt;a href="https://mastodon.social/@slint@fosstodon.org"&gt;@slint@fosstodon.org&lt;/a&gt; on Mastodon.&lt;/li&gt; 
 &lt;li&gt;Follow &lt;a href="https://www.linkedin.com/company/slint-ui/"&gt;@slint-ui&lt;/a&gt; on LinkedIn.&lt;/li&gt; 
 &lt;li&gt;Follow &lt;a href="https://bsky.app/profile/slint.dev"&gt;@slint.dev&lt;/a&gt; on Bluesky&lt;/li&gt; 
 &lt;li&gt;Subscribe to our &lt;a href="https://www.youtube.com/@Slint-UI"&gt;YouTube channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contact us&lt;/h3&gt; 
&lt;p&gt;Feel free to join &lt;a href="https://github.com/slint-ui/slint/discussions"&gt;Github discussions&lt;/a&gt; for general chat or questions. Use &lt;a href="https://github.com/slint-ui/slint/issues"&gt;Github issues&lt;/a&gt; to report public suggestions or bugs.&lt;/p&gt; 
&lt;p&gt;We chat in &lt;a href="https://chat.slint.dev"&gt;our Mattermost instance&lt;/a&gt; where you are welcome to listen in or ask your questions.&lt;/p&gt; 
&lt;p&gt;You can of course also contact us privately via email to &lt;a href="mailto://info@slint.dev"&gt;info@slint.dev&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>katanemo/archgw</title>
      <link>https://github.com/katanemo/archgw</link>
      <description>&lt;p&gt;The data plane for agents. Arch is a models-native proxy server that handles the plumbing work in AI: agent routing &amp; hand off, guardrails, zero-code logs and traces, unified access to LLMs from OpenAI, Anthropic, Ollama, etc. Build agents faster, and scale them reliably.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/arch-logo.png" alt="Arch Logo" width="75%" height="auto" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Arch is a models-native (edge and service) proxy server for agents.&lt;/em&gt;&lt;br /&gt;&lt;br /&gt; Arch handles the &lt;em&gt;pesky plumbing work&lt;/em&gt; in building AI agents ‚Äî like applying guardrails, routing prompts to the right agent, generating hyper-rich information traces for RL, and unifying access to any LLM. It‚Äôs a language and framework friendly infrastructure layer designed to help you build and ship agentic apps faster.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Quickstart"&gt;Quickstart&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Demos"&gt;Demos&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#use-arch-as-a-llm-router"&gt;Route LLMs&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Build-Agentic-Apps-with-Arch"&gt;Build agentic apps with Arch&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.archgw.com"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Contact"&gt;Contact&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/katanemo/arch/actions/workflows/pre-commit.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/pre-commit.yml/badge.svg?sanitize=true" alt="pre-commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/katanemo/arch/actions/workflows/rust_tests.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/rust_tests.yml/badge.svg?sanitize=true" alt="rust tests (prompt and llm gateway)" /&gt;&lt;/a&gt; &lt;a href="https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml/badge.svg?sanitize=true" alt="e2e tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/katanemo/arch/actions/workflows/static.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/static.yml/badge.svg?sanitize=true" alt="Build and Deploy Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;About The Latest Release:&lt;/h1&gt; 
&lt;p&gt;[0.3.18] &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/use_cases/claude_code_router/README.md"&gt;Preference-aware multi LLM routing for Claude Code 2.0&lt;/a&gt; &lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/claude_code_router.png" alt="high-level network architecture for ArchGW" width="50%" /&gt;&lt;/p&gt; 
&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.producthunt.com/posts/arch-3?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-arch-3" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=565761&amp;amp;theme=dark&amp;amp;period=daily&amp;amp;t=1742359429995" alt="Arch - Build fast, hyper-personalized agents with intelligent infra | Product Hunt" style="width: 188px; height: 41px;" width="188" height="41" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;AI demos are easy to hack. But once you move past a prototype, you‚Äôre stuck building and maintaining low-level plumbing code that slows down real innovation. For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Routing &amp;amp; orchestration.&lt;/strong&gt; Put routing in code and you‚Äôve got two choices: maintain it yourself or live with a framework‚Äôs baked-in logic. Either way, keeping routing consistent means pushing code changes across all your agents, slowing iteration and turning every policy tweak into a refactor instead of a config flip.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model integration churn.&lt;/strong&gt; Frameworks wire LLM integrations directly into code abstractions, making it hard to add or swap models without touching application code ‚Äî meaning you‚Äôll have to do codewide search/replace every time you want to experiment with a new model or version.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability &amp;amp; governance.&lt;/strong&gt; Logging, tracing, and guardrails are baked in as tightly coupled features, so bringing in best-of-breed solutions is painful and often requires digging through the guts of a framework.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt engineering overhead&lt;/strong&gt;. Input validation, clarifying vague user input, and coercing outputs into the right schema all pile up, turning what should be design work into low-level plumbing work.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Brittle upgrades&lt;/strong&gt;. Every change (new model, new guardrail, new trace format) means patching and redeploying application servers. Contrast that with bouncing a central proxy‚Äîone upgrade, instantly consistent everywhere.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With Arch, you can move faster by focusing on higher-level objectives in a language and framework agnostic way. &lt;strong&gt;Arch&lt;/strong&gt; was built by the contributors of &lt;a href="https://www.envoyproxy.io/"&gt;Envoy Proxy&lt;/a&gt; with the belief that:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Prompts are nuanced and opaque user requests, which require the same capabilities as traditional HTTP requests including secure handling, intelligent routing, robust observability, and integration with backend (API) systems to improve speed and accuracy for common agentic scenarios ‚Äì all outside core application logic.*&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Core Features&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;üö¶ Route to Agents&lt;/code&gt;: Engineered with purpose-built &lt;a href="https://huggingface.co/collections/katanemo/arch-function-66f209a693ea8df14317ad68"&gt;LLMs&lt;/a&gt; for fast (&amp;lt;100ms) agent routing and hand-off&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üîó Route to LLMs&lt;/code&gt;: Unify access to LLMs with support for &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#use-arch-as-a-llm-router"&gt;three routing strategies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;‚õ® Guardrails&lt;/code&gt;: Centrally configure and prevent harmful outcomes and ensure safe user interactions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;‚ö° Tools Use&lt;/code&gt;: For common agentic scenarios let Arch instantly clarify and convert prompts to tools/API calls&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üïµ Observability&lt;/code&gt;: W3C compatible request tracing and LLM metrics that instantly plugin with popular tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üß± Built on Envoy&lt;/code&gt;: Arch runs alongside app servers as a containerized process, and builds on top of &lt;a href="https://envoyproxy.io"&gt;Envoy's&lt;/a&gt; proven HTTP management and scalability features to handle ingress and egress traffic related to prompts and LLMs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;High-Level Sequence Diagram&lt;/strong&gt;: &lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/arch_network_diagram_high_level.png" alt="high-level network architecture for ArchGW" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Jump to our &lt;a href="https://docs.archgw.com"&gt;docs&lt;/a&gt;&lt;/strong&gt; to learn how you can use Arch to improve the speed, security and personalization of your GenAI apps.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Today, the function calling LLM (Arch-Function) designed for the agentic and RAG scenarios is hosted free of charge in the US-central region. To offer consistent latencies and throughput, and to manage our expenses, we will enable access to the hosted version via developers keys soon, and give you the option to run that LLM locally. For more details see this issue &lt;a href="https://github.com/katanemo/archgw/issues/258"&gt;#258&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;To get in touch with us, please join our &lt;a href="https://discord.gg/pGZf2gcwEc"&gt;discord server&lt;/a&gt;. We will be monitoring that actively and offering support there.&lt;/p&gt; 
&lt;h2&gt;Demos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/samples_python/weather_forecast/README.md"&gt;Sample App: Weather Forecast Agent&lt;/a&gt; - A sample agentic weather forecasting app that highlights core function calling capabilities of Arch.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/samples_python/network_switch_operator_agent/README.md"&gt;Sample App: Network Operator Agent&lt;/a&gt; - A simple network device switch operator agent that can retrieve device statistics and reboot them.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/use_cases/spotify_bearer_auth"&gt;Use Case: Connecting to SaaS APIs&lt;/a&gt; - Connect 3rd party SaaS APIs to your agentic chat experience.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Follow this quickstart guide to use Arch as a router for local or hosted LLMs, including dynamic routing. Later in the section we will see how you can Arch to build highly capable agentic applications, and to provide e2e observability.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;Before you begin, ensure you have the following:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/get-started/get-docker/"&gt;Docker System&lt;/a&gt; (v24)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/install/"&gt;Docker compose&lt;/a&gt; (v2.29)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python&lt;/a&gt; (v3.13)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Arch's CLI allows you to manage and interact with the Arch gateway efficiently. To install the CLI, simply run the following command:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] We recommend that developers create a new Python virtual environment to isolate dependencies before installing Arch. This ensures that archgw and its dependencies do not interfere with other packages on your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ python3.12 -m venv venv
$ source venv/bin/activate   # On Windows, use: venv\Scripts\activate
$ pip install archgw==0.3.18
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use Arch as a LLM Router&lt;/h3&gt; 
&lt;p&gt;Arch supports three powerful routing strategies for LLMs: model-based routing, alias-based routing, and preference-based routing. Each strategy offers different levels of abstraction and control for managing your LLM infrastructure.&lt;/p&gt; 
&lt;h4&gt;Model-based Routing&lt;/h4&gt; 
&lt;p&gt;Model-based routing allows you to configure specific models with static routing. This is ideal when you need direct control over which models handle specific requests. Arch supports 11+ LLM providers including OpenAI, Anthropic, DeepSeek, Mistral, Groq, and more.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - model: openai/gpt-4o
    access_key: $OPENAI_API_KEY
    default: true

  - model: anthropic/claude-3-5-sonnet-20241022
    access_key: $ANTHROPIC_API_KEY

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then route to specific models using any OpenAI-compatible client:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(base_url="http://127.0.0.1:12000/v1", api_key="test")

# Route to specific model
response = client.chat.completions.create(
    model="anthropic/claude-3-5-sonnet-20241022",
    messages=[{"role": "user", "content": "Explain quantum computing"}]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Alias-based Routing&lt;/h4&gt; 
&lt;p&gt;Alias-based routing lets you create semantic model names that map to underlying providers. This approach decouples your application code from specific model names, making it easy to experiment with different models or handle provider changes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - model: openai/gpt-4o
    access_key: $OPENAI_API_KEY

  - model: anthropic/claude-3-5-sonnet-20241022
    access_key: $ANTHROPIC_API_KEY

model_aliases:
  # Model aliases - friendly names that map to actual model names
  fast-model:
    target: gpt-4o-mini

  reasoning-model:
    target: gpt-4o

  creative-model:
    target: claude-3-5-sonnet-20241022
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use semantic aliases in your application code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Your code uses semantic names instead of provider-specific ones
response = client.chat.completions.create(
    model="reasoning-model",  # Routes to best available reasoning model
    messages=[{"role": "user", "content": "Solve this complex problem..."}]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Preference-aligned Routing&lt;/h4&gt; 
&lt;p&gt;Preference-aligned routing provides intelligent, dynamic model selection based on natural language descriptions of tasks and preferences. Instead of hardcoded routing logic, you describe what each model is good at using plain English.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - model: openai/gpt-4o
    access_key: $OPENAI_API_KEY
    routing_preferences:
      - name: complex_reasoning
        description: deep analysis, mathematical problem solving, and logical reasoning
      - name: creative_writing
        description: storytelling, creative content, and artistic writing

  - model: deepseek/deepseek-coder
    access_key: $DEEPSEEK_API_KEY
    routing_preferences:
      - name: code_generation
        description: generating new code, writing functions, and creating scripts
      - name: code_review
        description: analyzing existing code for bugs, improvements, and optimization
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Arch uses a lightweight 1.5B autoregressive model to intelligently map user prompts to these preferences, automatically selecting the best model for each request. This approach adapts to intent drift, supports multi-turn conversations, and avoids brittle embedding-based classifiers or manual if/else chains. No retraining required when adding models or updating policies ‚Äî routing is governed entirely by human-readable rules.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn More&lt;/strong&gt;: Check our &lt;a href="https://docs.archgw.com/concepts/llm_providers/llm_providers.html"&gt;documentation&lt;/a&gt; for comprehensive provider setup guides and routing strategies. You can learn more about the design, benchmarks, and methodology behind preference-based routing in our paper:&lt;/p&gt; 
&lt;div align="left"&gt; 
 &lt;a href="https://arxiv.org/abs/2506.16655" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/arch_router_paper_preview.png" alt="Arch Router Paper Preview" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Build Agentic Apps with Arch&lt;/h3&gt; 
&lt;p&gt;In following quickstart we will show you how easy it is to build AI agent with Arch gateway. We will build a currency exchange agent using following simple steps. For this demo we will use &lt;code&gt;https://api.frankfurter.dev/&lt;/code&gt; to fetch latest price for currencies and assume USD as base currency.&lt;/p&gt; 
&lt;h4&gt;Step 1. Create arch config file&lt;/h4&gt; 
&lt;p&gt;Create &lt;code&gt;arch_config.yaml&lt;/code&gt; file with following content,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  ingress_traffic:
    address: 0.0.0.0
    port: 10000
    message_format: openai
    timeout: 30s

llm_providers:
  - access_key: $OPENAI_API_KEY
    model: openai/gpt-4o

system_prompt: |
  You are a helpful assistant.

prompt_guards:
  input_guards:
    jailbreak:
      on_exception:
        message: Looks like you're curious about my abilities, but I can only provide assistance for currency exchange.

prompt_targets:
  - name: currency_exchange
    description: Get currency exchange rate from USD to other currencies
    parameters:
      - name: currency_symbol
        description: the currency that needs conversion
        required: true
        type: str
        in_path: true
    endpoint:
      name: frankfurter_api
      path: /v1/latest?base=USD&amp;amp;symbols={currency_symbol}
    system_prompt: |
      You are a helpful assistant. Show me the currency symbol you want to convert from USD.

  - name: get_supported_currencies
    description: Get list of supported currencies for conversion
    endpoint:
      name: frankfurter_api
      path: /v1/currencies

endpoints:
  frankfurter_api:
    endpoint: api.frankfurter.dev:443
    protocol: https
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 2. Start arch gateway with currency conversion config&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;
$ archgw up arch_config.yaml
2024-12-05 16:56:27,979 - cli.main - INFO - Starting archgw cli version: 0.3.18
2024-12-05 16:56:28,485 - cli.utils - INFO - Schema validation successful!
2024-12-05 16:56:28,485 - cli.main - INFO - Starting arch model server and arch gateway
2024-12-05 16:56:51,647 - cli.core - INFO - Container is healthy!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once the gateway is up you can start interacting with at port 10000 using openai chat completion API.&lt;/p&gt; 
&lt;p&gt;Some of the sample queries you can ask could be &lt;code&gt;what is currency rate for gbp?&lt;/code&gt; or &lt;code&gt;show me list of currencies for conversion&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Step 3. Interacting with gateway using curl command&lt;/h4&gt; 
&lt;p&gt;Here is a sample curl command you can use to interact,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl --header 'Content-Type: application/json' \
  --data '{"messages": [{"role": "user","content": "what is exchange rate for gbp"}], "model": "none"}' \
  http://localhost:10000/v1/chat/completions | jq ".choices[0].message.content"

"As of the date provided in your context, December 5, 2024, the exchange rate for GBP (British Pound) from USD (United States Dollar) is 0.78558. This means that 1 USD is equivalent to 0.78558 GBP."

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And to get list of supported currencies,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl --header 'Content-Type: application/json' \
  --data '{"messages": [{"role": "user","content": "show me list of currencies that are supported for conversion"}], "model": "none"}' \
  http://localhost:10000/v1/chat/completions | jq ".choices[0].message.content"

"Here is a list of the currencies that are supported for conversion from USD, along with their symbols:\n\n1. AUD - Australian Dollar\n2. BGN - Bulgarian Lev\n3. BRL - Brazilian Real\n4. CAD - Canadian Dollar\n5. CHF - Swiss Franc\n6. CNY - Chinese Renminbi Yuan\n7. CZK - Czech Koruna\n8. DKK - Danish Krone\n9. EUR - Euro\n10. GBP - British Pound\n11. HKD - Hong Kong Dollar\n12. HUF - Hungarian Forint\n13. IDR - Indonesian Rupiah\n14. ILS - Israeli New Sheqel\n15. INR - Indian Rupee\n16. ISK - Icelandic Kr√≥na\n17. JPY - Japanese Yen\n18. KRW - South Korean Won\n19. MXN - Mexican Peso\n20. MYR - Malaysian Ringgit\n21. NOK - Norwegian Krone\n22. NZD - New Zealand Dollar\n23. PHP - Philippine Peso\n24. PLN - Polish Z≈Çoty\n25. RON - Romanian Leu\n26. SEK - Swedish Krona\n27. SGD - Singapore Dollar\n28. THB - Thai Baht\n29. TRY - Turkish Lira\n30. USD - United States Dollar\n31. ZAR - South African Rand\n\nIf you want to convert USD to any of these currencies, you can select the one you are interested in."

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;a href="https://docs.archgw.com/guides/observability/observability.html"&gt;Observability&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Arch is designed to support best-in class observability by supporting open standards. Please read our &lt;a href="https://docs.archgw.com/guides/observability/observability.html"&gt;docs&lt;/a&gt; on observability for more details on tracing, metrics, and logs. The screenshot below is from our integration with Signoz (among others)&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/tracing.png" alt="alt text" /&gt;&lt;/p&gt; 
&lt;h2&gt;Debugging&lt;/h2&gt; 
&lt;p&gt;When debugging issues / errors application logs and access logs provide key information to give you more context on whats going on with the system. Arch gateway runs in info log level and following is a typical output you could see in a typical interaction between developer and arch gateway,&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ archgw up --service archgw --foreground
...
[2025-03-26 18:32:01.350][26][info] prompt_gateway: on_http_request_body: sending request to model server
[2025-03-26 18:32:01.851][26][info] prompt_gateway: on_http_call_response: model server response received
[2025-03-26 18:32:01.852][26][info] prompt_gateway: on_http_call_response: dispatching api call to developer endpoint: weather_forecast_service, path: /weather, method: POST
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: developer api call response received: status code: 200
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: sending request to upstream llm
[2025-03-26 18:32:01.883][26][info] llm_gateway: on_http_request_body: provider: gpt-4o-mini, model requested: None, model selected: gpt-4o-mini
[2025-03-26 18:32:02.818][26][info] llm_gateway: on_http_response_body: time to first token: 1468ms
[2025-03-26 18:32:04.532][26][info] llm_gateway: on_http_response_body: request latency: 3183ms
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Log level can be changed to debug to get more details. To enable debug logs edit (supervisord.conf)[arch/supervisord.conf], change the log level &lt;code&gt;--component-log-level wasm:info&lt;/code&gt; to &lt;code&gt;--component-log-level wasm:debug&lt;/code&gt;. And after that you need to rebuild docker image and restart the arch gateway using following set of commands,&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# make sure you are at the root of the repo
$ archgw build
# go to your service that has arch_config.yaml file and issue following command,
$ archgw up --service archgw --foreground
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;We would love feedback on our &lt;a href="https://github.com/orgs/katanemo/projects/1"&gt;Roadmap&lt;/a&gt; and we welcome contributions to &lt;strong&gt;Arch&lt;/strong&gt;! Whether you're fixing bugs, adding new features, improving documentation, or creating tutorials, your help is much appreciated. Please visit our &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; for more details&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ai-dynamo/dynamo</title>
      <link>https://github.com/ai-dynamo/dynamo</link>
      <description>&lt;p&gt;A Datacenter Scale Distributed Inference Serving Framework&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-banner.png" alt="Dynamo banner" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ai-dynamo/dynamo/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/ai-dynamo/dynamo" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/D92uqZRjCZ"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ai-dynamo/dynamo"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/issues/2486"&gt;Roadmap&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/raw/main/docs/reference/support-matrix.md"&gt;Support matrix&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://docs.nvidia.com/dynamo/latest/index.html"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/tree/main/examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo"&gt;Prebuilt containers&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/enhancements"&gt;Design Proposals&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://developer.nvidia.com/blog/tag/nvidia-dynamo"&gt;Blogs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;NVIDIA Dynamo&lt;/h1&gt; 
&lt;p&gt;High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.&lt;/p&gt; 
&lt;h2&gt;Latest News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[08/05] Deploy &lt;code&gt;openai/gpt-oss-120b&lt;/code&gt; with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/trtllm/gpt-oss.md"&gt;‚û°Ô∏è link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;The Era of Multi-GPU, Multi-Node&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-gpu-vertical.png" alt="Multi Node Multi-GPU topology" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs‚Äîand sometimes many servers‚Äîbut it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.&lt;/p&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Disaggregated prefill &amp;amp; decode inference&lt;/strong&gt; ‚Äì Maximizes GPU throughput and facilitates trade off between throughput and latency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic GPU scheduling&lt;/strong&gt; ‚Äì Optimizes performance based on fluctuating demand&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-aware request routing&lt;/strong&gt; ‚Äì Eliminates unnecessary KV cache re-computation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accelerated data transfer&lt;/strong&gt; ‚Äì Reduces inference response time using NIXL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;KV cache offloading&lt;/strong&gt; ‚Äì Leverages multiple memory hierarchies for higher system throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-architecture.png" alt="Dynamo architecture" width="600" /&gt; &lt;/p&gt; 
&lt;h2&gt;Framework Support Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;vLLM&lt;/th&gt; 
   &lt;th&gt;SGLang&lt;/th&gt; 
   &lt;th&gt;TensorRT-LLM&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/design_docs/disagg_serving.md"&gt;&lt;strong&gt;Disaggregated Serving&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/design_docs/disagg_serving.md#conditional-disaggregation"&gt;&lt;strong&gt;Conditional Disaggregation&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/router/kv_cache_routing.md"&gt;&lt;strong&gt;KV-Aware Routing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/planner/load_planner.md"&gt;&lt;strong&gt;Load Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/planner/sla_planner.md"&gt;&lt;strong&gt;SLA-Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/kvbm/kvbm_architecture.md"&gt;&lt;strong&gt;KVBM&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about each framework and their capabilities, check out each framework's README!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/vllm/README.md"&gt;vLLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/sglang/README.md"&gt;SGLang&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/trtllm/README.md"&gt;TensorRT-LLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;The following examples require a few system level packages. Recommended to use Ubuntu 24.04 with a x86_64 CPU. See &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/reference/support-matrix.md"&gt;docs/reference/support-matrix.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;1. Initial setup&lt;/h2&gt; 
&lt;p&gt;The Dynamo team recommends the &lt;code&gt;uv&lt;/code&gt; Python package manager, although any way works. Install uv:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install Python development headers&lt;/h3&gt; 
&lt;p&gt;Backend engines require Python development headers for JIT compilation. Install them with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt install python3-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install etcd and NATS (required)&lt;/h3&gt; 
&lt;p&gt;To coordinate across a data center, Dynamo relies on etcd and NATS. To run Dynamo locally, these need to be available.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; can be run directly as &lt;code&gt;./etcd&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nats.io/"&gt;nats&lt;/a&gt; needs jetstream enabled: &lt;code&gt;nats-server -js&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To quickly setup etcd &amp;amp; NATS, you can also run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# At the root of the repository:
# Edit deploy/docker-compose.yml to comment out "runtime: nvidia" of the dcgm-exporter service if the nvidia container runtime isn't deployed or to be used.
docker compose -f deploy/docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;2. Select an engine&lt;/h2&gt; 
&lt;p&gt;We publish Python wheels specialized for each of our supported engines: vllm, sglang, and trtllm. The examples that follow use SGLang; continue reading for other engines.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install "ai-dynamo[sglang]"  #replace with [vllm], [trtllm], etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Run Dynamo&lt;/h2&gt; 
&lt;h3&gt;Sanity check (optional)&lt;/h3&gt; 
&lt;p&gt;Before trying out Dynamo, you can verify your system configuration and dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./deploy/sanity_check.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is a quick check for system resources, development tools, LLM frameworks, and Dynamo components.&lt;/p&gt; 
&lt;h3&gt;Running an LLM API server&lt;/h3&gt; 
&lt;p&gt;Dynamo provides a simple way to spin up a local set of inference components including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI Compatible Frontend&lt;/strong&gt; ‚Äì High performance OpenAI compatible http api server written in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic and Kv Aware Router&lt;/strong&gt; ‚Äì Route and load balance traffic to a set of workers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt; ‚Äì Set of pre-configured LLM serving engines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send a Request&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl localhost:8000/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "messages": [
    {
        "role": "user",
        "content": "Hello, how are you?"
    }
    ],
    "stream":false,
    "max_tokens": 300
  }' | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Rerun with &lt;code&gt;curl -N&lt;/code&gt; and change &lt;code&gt;stream&lt;/code&gt; in the request to &lt;code&gt;true&lt;/code&gt; to get the responses as soon as the engine issues them.&lt;/p&gt; 
&lt;h3&gt;Deploying Dynamo&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/kubernetes/README.md"&gt;Quickstart Guide&lt;/a&gt; to deploy on Kubernetes.&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples/backends"&gt;Backends&lt;/a&gt; to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)&lt;/li&gt; 
 &lt;li&gt;Run some &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples"&gt;Examples&lt;/a&gt; to learn about building components in Dynamo and exploring various integrations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Benchmarking Dynamo&lt;/h3&gt; 
&lt;p&gt;Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/benchmarks/benchmarking.md"&gt;Benchmarking Guide&lt;/a&gt;&lt;/strong&gt; ‚Äì Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using AIPerf&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/planner/sla_planner_quickstart.md"&gt;SLA-Driven Dynamo Deployments&lt;/a&gt;&lt;/strong&gt; ‚Äì Optimize your deployment to meet SLA requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Engines&lt;/h1&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (&lt;code&gt;python -m dynamo.frontend [--interactive]&lt;/code&gt;).&lt;/p&gt; 
&lt;h2&gt;vLLM&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[vllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.vllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass &lt;code&gt;--context-length &amp;lt;value&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;SGLang&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.sglang --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can pass any sglang flags directly to this worker, see &lt;a href="https://docs.sglang.ai/advanced_features/server_arguments.html"&gt;https://docs.sglang.ai/advanced_features/server_arguments.html&lt;/a&gt; . See there to use multiple GPUs.&lt;/p&gt; 
&lt;h2&gt;TensorRT-LLM&lt;/h2&gt; 
&lt;p&gt;It is recommended to use &lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch"&gt;NGC PyTorch Container&lt;/a&gt; for running the TensorRT-LLM engine.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using. For example, if you are using &lt;code&gt;tensorrt-llm==1.1.0rc5&lt;/code&gt;, use the PyTorch container image version &lt;code&gt;25.06&lt;/code&gt;. To find the correct PyTorch container version for your desired &lt;code&gt;tensorrt-llm&lt;/code&gt; release, visit the &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/docker/Dockerfile.multi"&gt;TensorRT-LLM Dockerfile.multi&lt;/a&gt; on GitHub. Switch to the branch that matches your &lt;code&gt;tensorrt-llm&lt;/code&gt; version, and look for the &lt;code&gt;BASE_TAG&lt;/code&gt; line to identify the recommended PyTorch container tag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] Launch container with the following additional settings &lt;code&gt;--shm-size=1g --ulimit memlock=-1&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Install prerequisites&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install "cuda-python&amp;gt;=12,&amp;lt;13"

sudo apt-get -y install libopenmpi-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Tip] You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation &lt;a href="https://nvidia.github.io/TensorRT-LLM/installation/linux.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;After installing the pre-requisites above, install Dynamo&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[trtllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.trtllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Developing Locally&lt;/h1&gt; 
&lt;h2&gt;1. Install libraries&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Ubuntu:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# if brew is not installed on your system, install it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If Metal is accessible, you should see an error like &lt;code&gt;metal: error: no input files&lt;/code&gt;, which confirms it is installed correctly.&lt;/p&gt; 
&lt;h2&gt;2. Install Rust&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Create a Python virtual env:&lt;/h2&gt; 
&lt;p&gt;Follow the instructions in &lt;a href="https://docs.astral.sh/uv/#installation"&gt;uv installation&lt;/a&gt; guide to install uv if you don't have &lt;code&gt;uv&lt;/code&gt; installed. Once uv is installed, create a virtual environment and activate it.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv dynamo
source dynamo/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Install build tools&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install pip maturin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/PyO3/maturin"&gt;Maturin&lt;/a&gt; is the Rust&amp;lt;-&amp;gt;Python bindings build tool.&lt;/p&gt; 
&lt;h2&gt;5. Build the Rust bindings&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd lib/bindings/python
maturin develop --uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;6. Install the wheel&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd $PROJECT_ROOT
uv pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should now be able to run &lt;code&gt;python -m dynamo.frontend&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Remember that nats and etcd must be running (see earlier).&lt;/p&gt; 
&lt;p&gt;Set the environment variable &lt;code&gt;DYN_LOG&lt;/code&gt; to adjust the logging level; for example, &lt;code&gt;export DYN_LOG=debug&lt;/code&gt;. It has the same syntax as &lt;code&gt;RUST_LOG&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use vscode or cursor, we have a .devcontainer folder built on &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers"&gt;Microsofts Extension&lt;/a&gt;. For instructions see the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/.devcontainer/README.md"&gt;ReadMe&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pythops/impala</title>
      <link>https://github.com/pythops/impala</link>
      <description>&lt;p&gt;üõú TUI for managing wifi on Linux&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h2&gt; TUI for managing wifi &lt;/h2&gt; 
&lt;/div&gt; 
&lt;h2&gt;üì∏ Demo&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/55c800ff-d0aa-4454-aa6b-3990833ce530" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;üí° Prerequisites&lt;/h2&gt; 
&lt;p&gt;A Linux based OS with &lt;a href="https://iwd.wiki.kernel.org/"&gt;iwd&lt;/a&gt; installed.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You might need to install &lt;a href="https://www.nerdfonts.com/"&gt;nerdfonts&lt;/a&gt; for the icons to be displayed correctly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üöÄ Installation&lt;/h2&gt; 
&lt;h3&gt;üì• Binary release&lt;/h3&gt; 
&lt;p&gt;You can download the pre-built binaries from the release page &lt;a href="https://github.com/pythops/impala/releases"&gt;release page&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üì¶ crates.io&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;impala&lt;/code&gt; from &lt;a href="https://crates.io/crates/impala"&gt;crates.io&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install impala
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üêßArch Linux&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;impala&lt;/code&gt; from the &lt;a href="https://archlinux.org/packages/extra/x86_64/impala/"&gt;official repositories&lt;/a&gt; with using &lt;a href="https://wiki.archlinux.org/title/pacman"&gt;pacman&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pacman -S impala
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Nixpkgs&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;nix-env -iA nixpkgs.impala
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚öíÔ∏è Build from source&lt;/h3&gt; 
&lt;p&gt;Run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/pythops/impala
cd impala
cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will produce an executable file at &lt;code&gt;target/release/impala&lt;/code&gt; that you can copy to a directory in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;ü™Ñ Usage&lt;/h2&gt; 
&lt;h3&gt;Global&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Tab&lt;/code&gt; or &lt;code&gt;Shift + Tab&lt;/code&gt;: Switch between different sections.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;j&lt;/code&gt; or &lt;code&gt;Down&lt;/code&gt; : Scroll down.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;k&lt;/code&gt; or &lt;code&gt;Up&lt;/code&gt;: Scroll up.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ctrl+r&lt;/code&gt;: Switch adapter mode.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;?&lt;/code&gt;: Show help.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;esc&lt;/code&gt;: Dismiss the different pop-ups.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;q&lt;/code&gt; or &lt;code&gt;ctrl+c&lt;/code&gt;: Quit the app.&lt;/p&gt; 
&lt;h3&gt;Device&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;i&lt;/code&gt;: Show device information.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;o&lt;/code&gt;: Toggle device power.&lt;/p&gt; 
&lt;h3&gt;Station&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;s&lt;/code&gt;: Start scanning.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Space&lt;/code&gt;: Connect/Disconnect the network.&lt;/p&gt; 
&lt;h3&gt;Known Networks&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;a&lt;/code&gt;: Enable/Disable auto-connect.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;d&lt;/code&gt;: Remove the network from the known networks list.&lt;/p&gt; 
&lt;h3&gt;Access Point&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;n&lt;/code&gt;: Start a new access point.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;x&lt;/code&gt;: Stop the running access point.&lt;/p&gt; 
&lt;h2&gt;Custom keybindings&lt;/h2&gt; 
&lt;p&gt;Keybindings can be customized in the config file &lt;code&gt;$HOME/.config/impala/config.toml&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;
switch = "r"
mode = "station"

[device]
infos = "i"
toggle_power = "o"

[access_point]
start = 'n'
stop = 'x'

[station]
toggle_scanning = "s"
toggle_connect = " "

[station.known_network]
toggle_autoconnect = "a"
remove = "d"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; 
&lt;p&gt;GPLv3&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rust-lang/rustlings</title>
      <link>https://github.com/rust-lang/rustlings</link>
      <description>&lt;p&gt;ü¶Ä Small exercises to get you used to reading and writing Rust code!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://rustlings.rust-lang.org"&gt;Rustlings&lt;/a&gt; ü¶Ä&lt;/h1&gt; 
&lt;p&gt;Small exercises to get you used to reading and writing &lt;a href="https://www.rust-lang.org"&gt;Rust&lt;/a&gt; code - &lt;em&gt;Recommended in parallel to reading &lt;a href="https://doc.rust-lang.org/book"&gt;the official Rust book&lt;/a&gt; üìöÔ∏è&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Visit the &lt;strong&gt;website&lt;/strong&gt; for a demo, info about setup and more:&lt;/p&gt; 
&lt;h2&gt;‚û°Ô∏è &lt;a href="https://rustlings.rust-lang.org"&gt;rustlings.rust-lang.org&lt;/a&gt; ‚¨ÖÔ∏è&lt;/h2&gt;</description>
    </item>
    
    <item>
      <title>cube-js/cube</title>
      <link>https://github.com/cube-js/cube</link>
      <description>&lt;p&gt;üìä Cube Core is open-source semantic layer and LookML alternative for AI, BI and embedded analytics&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="" alt="" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://cube.dev?ref=github-readme"&gt;&lt;img src="https://raw.githubusercontent.com/cube-js/cube/master/docs/content/cube-logo-with-bg.png" alt="Cube ‚Äî Semantic Layer for Data Applications" width="300px" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://cube.dev?ref=github-readme"&gt;Website&lt;/a&gt; ‚Ä¢ &lt;a href="https://cube.dev/docs/getting-started?ref=github-readme"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://cube.dev/docs?ref=github-readme"&gt;Docs&lt;/a&gt; ‚Ä¢ &lt;a href="https://cube.dev/docs/examples?ref=github-readme"&gt;Examples&lt;/a&gt; ‚Ä¢ &lt;a href="https://cube.dev/blog?ref=github-readme"&gt;Blog&lt;/a&gt; ‚Ä¢ &lt;a href="https://slack.cube.dev?ref=github-readme"&gt;Slack&lt;/a&gt; ‚Ä¢ &lt;a href="https://twitter.com/the_cube_dev"&gt;X&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://badge.fury.io/js/%40cubejs-backend%2Fserver"&gt;&lt;img src="https://badge.fury.io/js/%40cubejs-backend%2Fserver.svg?sanitize=true" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cube-js/cube/actions?query=workflow%3ABuild+branch%3Amaster"&gt;&lt;img src="https://github.com/cube-js/cube/workflows/Build/badge.svg?sanitize=true" alt="GitHub Actions" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.io/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js?ref=badge_shield"&gt;&lt;img src="https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Cube Core is an open-source semantic layer and LookML alternative.&lt;/strong&gt; It can be used by data professionals to access data from modern data stores, organize it into consistent definitions, and deliver it to every application. Cube Core is headless and comes with multiple APIs for embedded analytics and BI: REST, GraphQL and SQL. If you are looking for a fully integrated platform, similar to Looker, check out our commercial product - &lt;a href="https://cube.dev"&gt;Cube&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://ucarecdn.com/8d945f29-e9eb-4e7f-9e9e-29ae7074e195/" style="border: none" width="100%" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Learn more about connecting Cube to &lt;a href="https://cube.dev/docs/config/databases?ref=github-readme" target="_blank"&gt;data sources&lt;/a&gt; and &lt;a href="https://cube.dev/docs/config/downstream?ref=github-readme" target="_blank"&gt;analytics &amp;amp; visualization tools&lt;/a&gt;.&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Cube was designed to work with all SQL-enabled data sources, including cloud data warehouses like Snowflake or Google BigQuery, query engines like Presto or Amazon Athena, and application databases like Postgres. Cube has a built-in relational caching engine to provide sub-second latency and high concurrency for API requests.&lt;/p&gt; 
&lt;p&gt;For more details, see the &lt;a href="https://cube.dev/docs/cubejs-introduction?ref=github-readme"&gt;introduction&lt;/a&gt; page in our documentation.&lt;/p&gt; 
&lt;h2&gt;Why Cube?&lt;/h2&gt; 
&lt;p&gt;As data infrastructure evolved from traditional relational databases to cloud data platforms, OLAP capabilities that once lived in specialized servers like SQL Server Analysis Services and Oracle Essbase were left behind. Today's organizations face several challenges:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Analytics Modeling and Multidimensionality.&lt;/strong&gt; Modern cloud data platforms excel at processing large volumes of data but lack native support for multidimensional analysis and modeling. Cube brings OLAP-style analytics to these platforms, enabling consistent metric definitions and multidimensional analysis.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Performance Optimization.&lt;/strong&gt; While cloud data warehouses have improved query performance through column-oriented storage and distributed processing, they still struggle with complex analytical workloads. Cube provides intelligent caching and pre-aggregation strategies that dramatically improve query response times.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Access Control and Governance.&lt;/strong&gt; Securing and governing access to data across all consuming applications remains critical. Cube offers robust access control to ensure consistent security across your entire data ecosystem.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;API Flexibility.&lt;/strong&gt; Legacy OLAP tools were limited in how they exposed data. Cube provides modern REST, GraphQL, and SQL APIs along with support for traditional MDX and DAX interfaces, making it a truly universal semantic layer.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Cube is the missing OLAP engine for the cloud data platform era that provides the necessary infrastructure and features to implement efficient data modeling, access control, and performance optimizations without duplicating analytics modeling, data, or security permissions across different tools.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cube-js/cube.js/master/docs/content/old-was-vs-cubejs-way.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Started üöÄ&lt;/h2&gt; 
&lt;h3&gt;Cube Cloud&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://cube.dev/cloud?ref=github-readme"&gt;Cube Cloud&lt;/a&gt; is the fastest way to get started with Cube. It provides managed infrastructure as well as an instant and free access for development projects and proofs of concept.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cubecloud.dev/auth/signup?ref=github-readme"&gt;&lt;img src="https://cubedev-blog-images.s3.us-east-2.amazonaws.com/f1f1eac0-0b44-4c47-936e-33b5c06eedf0.png" alt="Get started now" width="200px" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For a step-by-step guide on Cube Cloud, &lt;a href="https://cube.dev/docs/getting-started/cloud/overview?ref=github-readme"&gt;see the docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Alternatively, you can get started with Cube locally or self-host it with &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Once Docker is installed, in a new folder for your project, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 4000:4000 \
  -p 15432:15432 \
  -v ${PWD}:/cube/conf \
  -e CUBEJS_DEV_MODE=true \
  cubejs/cube
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, open &lt;a href="http://localhost:4000"&gt;http://localhost:4000&lt;/a&gt; in your browser to continue setup.&lt;/p&gt; 
&lt;p&gt;For a step-by-step guide on Docker, &lt;a href="https://cube.dev/docs/getting-started-docker?ref=github-readme"&gt;see the docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cube.dev/docs?ref=github-readme"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cube.dev/docs/getting-started?ref=github-readme"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cube.dev/docs/examples?ref=github-readme"&gt;Examples &amp;amp; Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cube.dev/docs/product/introduction#four-layers-of-semantic-layer"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;There are many ways you can contribute to Cube! Here are a few possibilities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Star this repo and follow us on &lt;a href="https://twitter.com/the_cube_dev"&gt;X&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add Cube to your stack on &lt;a href="https://stackshare.io/cube-js"&gt;Stackshare&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Upvote issues with üëç reaction so we know what's the demand for particular issue to prioritize it within road map.&lt;/li&gt; 
 &lt;li&gt;Create issues every time you feel something is missing or goes wrong.&lt;/li&gt; 
 &lt;li&gt;Ask questions on &lt;a href="https://stackoverflow.com/questions/tagged/cube.js"&gt;Stack Overflow with cube.js tag&lt;/a&gt; if others can have these questions as well.&lt;/li&gt; 
 &lt;li&gt;Provide pull requests for all open issues and especially for those with &lt;a href="https://github.com/cube-js/cube/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22"&gt;help wanted&lt;/a&gt; and &lt;a href="https://github.com/cube-js/cube/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;good first issue&lt;/a&gt; labels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All sort of contributions are &lt;strong&gt;welcome and extremely helpful&lt;/strong&gt; üôå Please refer to &lt;a href="https://github.com/cube-js/cube/raw/master/CONTRIBUTING.md"&gt;the contribution guide&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Cube Client is &lt;a href="https://raw.githubusercontent.com/cube-js/cube/master/packages/cubejs-client-core/LICENSE"&gt;MIT licensed&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Cube Backend is &lt;a href="https://raw.githubusercontent.com/cube-js/cube/master/packages/cubejs-server/LICENSE"&gt;Apache 2.0 licensed&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.io/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js?ref=badge_large"&gt;&lt;img src="https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gfx-rs/wgpu</title>
      <link>https://github.com/gfx-rs/wgpu</link>
      <description>&lt;p&gt;A cross-platform, safe, pure-Rust graphics API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;wgpu&lt;/h1&gt; 
&lt;img align="right" width="20%" src="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/logo.png" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/gfx-rs/wgpu/actions"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/gfx-rs/wgpu/ci.yml?branch=trunk&amp;amp;logo=github&amp;amp;label=CI" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/gfx-rs/wgpu"&gt;&lt;img src="https://img.shields.io/codecov/c/github/gfx-rs/wgpu?logo=codecov&amp;amp;logoColor=fff&amp;amp;label=codecov&amp;amp;token=84qJTesmeS" alt="codecov.io" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;wgpu&lt;/code&gt; is a cross-platform, safe, pure-Rust graphics API. It runs natively on Vulkan, Metal, D3D12, and OpenGL; and on top of WebGL2 and WebGPU on wasm.&lt;/p&gt; 
&lt;p&gt;The API is based on the &lt;a href="https://gpuweb.github.io/gpuweb/"&gt;WebGPU standard&lt;/a&gt;, but is a fully native Rust library. It serves as the core of the WebGPU integration in Firefox, Servo, and Deno.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;See our examples online at &lt;a href="https://wgpu.rs/examples/"&gt;https://wgpu.rs/examples/&lt;/a&gt;. You can see the Rust sources at &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/examples"&gt;examples&lt;/a&gt; and run them directly with &lt;code&gt;cargo run --bin wgpu-examples &amp;lt;example&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Learning &lt;code&gt;wgpu&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;If you are new to &lt;code&gt;wgpu&lt;/code&gt; and graphics programming, we recommend starting with &lt;a href="https://sotrh.github.io/learn-wgpu/"&gt;Learn Wgpu&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- Note, "Learn Wgpu" is using the capitalization style in their header, NOT our styling --&gt; 
&lt;p&gt;Additionally, &lt;a href="https://webgpufundamentals.org/"&gt;WebGPU Fundamentals&lt;/a&gt; is a tutorial for WebGPU which is very similar to our API, minus differences between Rust and Javascript.&lt;/p&gt; 
&lt;h3&gt;Wiki&lt;/h3&gt; 
&lt;p&gt;We have a &lt;a href="https://github.com/gfx-rs/wgpu/wiki"&gt;wiki&lt;/a&gt; which has information on useful architecture patterns, debugging tips, and more getting started information.&lt;/p&gt; 
&lt;h3&gt;Need Help? Want to Contribute?&lt;/h3&gt; 
&lt;p&gt;The wgpu community uses Matrix to discuss.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://matrix.to/#/#wgpu:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=wgpu-devs&amp;amp;message=%23wgpu&amp;amp;color=blueviolet&amp;amp;logo=matrix" alt="#wgpu:matrix.org" /&gt;&lt;/a&gt; - discussion of wgpu's development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://matrix.to/#/#wgpu-users:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=wgpu-users&amp;amp;message=%23wgpu-users&amp;amp;color=blueviolet&amp;amp;logo=matrix" alt="#wgpu-users:matrix.org" /&gt;&lt;/a&gt; - discussion of using the library and the surrounding ecosystem.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Other Languages&lt;/h3&gt; 
&lt;p&gt;To use wgpu in C or dozens of other languages, look at &lt;a href="https://github.com/gfx-rs/wgpu-native"&gt;wgpu-native&lt;/a&gt;. These are C bindings to wgpu and has an up-to-date list of libraries bringing support to other languages.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://eliemichel.github.io/LearnWebGPU/"&gt;Learn WebGPU (for C++)&lt;/a&gt; is a good resource for learning how to use wgpu-native from C++.&lt;/p&gt; 
&lt;h2&gt;Quick Links&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Docs&lt;/th&gt; 
   &lt;th align="center"&gt;Examples&lt;/th&gt; 
   &lt;th align="center"&gt;Changelog&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.rs/wgpu/"&gt;v27&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/gfx-rs/wgpu/tree/v27/examples#readme"&gt;v27&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/gfx-rs/wgpu/releases"&gt;v27&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://wgpu.rs/doc/wgpu/"&gt;&lt;code&gt;trunk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/gfx-rs/wgpu/tree/trunk/examples#readme"&gt;&lt;code&gt;trunk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/gfx-rs/wgpu/raw/trunk/CHANGELOG.md#unreleased"&gt;&lt;code&gt;trunk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Contributors are welcome! See &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Supported Platforms&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th&gt;Windows&lt;/th&gt; 
   &lt;th&gt;Linux/Android&lt;/th&gt; 
   &lt;th&gt;macOS/iOS&lt;/th&gt; 
   &lt;th&gt;Web (wasm)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vulkan&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;üåã&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Metal&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DX12&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenGL&lt;/td&gt; 
   &lt;td&gt;üÜó (GL 3.3+)&lt;/td&gt; 
   &lt;td&gt;üÜó (GL ES 3.0+)&lt;/td&gt; 
   &lt;td&gt;üìê&lt;/td&gt; 
   &lt;td&gt;üÜó (WebGL2)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WebGPU&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;‚úÖ = First Class Support&lt;br /&gt; üÜó = Downlevel/Best Effort Support&lt;br /&gt; üìê = Requires the &lt;a href="https://github.com/gfx-rs/wgpu/wiki/Running-on-ANGLE"&gt;ANGLE&lt;/a&gt; translation layer (GL ES 3.0 only)&lt;br /&gt; üåã = Requires the &lt;a href="https://vulkan.lunarg.com/sdk/home#mac"&gt;MoltenVK&lt;/a&gt; translation layer&lt;br /&gt; üõ†Ô∏è = Unsupported, though open to contributions&lt;/p&gt; 
&lt;h2&gt;Environment Variables&lt;/h2&gt; 
&lt;p&gt;Testing, examples, and &lt;code&gt;::from_env()&lt;/code&gt; methods use a standardized set of environment variables to control wgpu's behavior.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;WGPU_BACKEND&lt;/code&gt; with a comma-separated list of the backends you want to use (&lt;code&gt;vulkan&lt;/code&gt;, &lt;code&gt;metal&lt;/code&gt;, &lt;code&gt;dx12&lt;/code&gt;, or &lt;code&gt;gl&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;WGPU_ADAPTER_NAME&lt;/code&gt; with a case-insensitive substring of the name of the adapter you want to use (ex. &lt;code&gt;1080&lt;/code&gt; will match &lt;code&gt;NVIDIA GeForce 1080ti&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;WGPU_DX12_COMPILER&lt;/code&gt; with the DX12 shader compiler you wish to use (&lt;code&gt;dxc&lt;/code&gt;, &lt;code&gt;static-dxc&lt;/code&gt;, or &lt;code&gt;fxc&lt;/code&gt;). Note that &lt;code&gt;dxc&lt;/code&gt; requires &lt;code&gt;dxcompiler.dll&lt;/code&gt; (min v1.8.2502) to be in the working directory, and &lt;code&gt;static-dxc&lt;/code&gt; requires the &lt;code&gt;static-dxc&lt;/code&gt; crate feature to be enabled. Otherwise, it will fall back to &lt;code&gt;fxc&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.rs/wgpu/latest/wgpu/index.html?search=env"&gt;documentation&lt;/a&gt; for more environment variables.&lt;/p&gt; 
&lt;p&gt;When running the CTS, use the variables &lt;code&gt;DENO_WEBGPU_ADAPTER_NAME&lt;/code&gt;, &lt;code&gt;DENO_WEBGPU_BACKEND&lt;/code&gt;, &lt;code&gt;DENO_WEBGPU_POWER_PREFERENCE&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Repo Overview&lt;/h2&gt; 
&lt;p&gt;For an overview of all the components in the gfx-rs ecosystem, see &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/docs/big-picture.png"&gt;the big picture&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;MSRV policy&lt;/h2&gt; 
&lt;p&gt;TL;DR: If you're using &lt;code&gt;wgpu&lt;/code&gt;, our MSRV is &lt;strong&gt;1.88&lt;/strong&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Specific Details &lt;/summary&gt; 
 &lt;p&gt;Due to complex dependants, we have two MSRV policies:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;naga&lt;/code&gt;, &lt;code&gt;wgpu-core&lt;/code&gt;, &lt;code&gt;wgpu-hal&lt;/code&gt;, and &lt;code&gt;wgpu-types&lt;/code&gt;'s MSRV is &lt;strong&gt;1.82&lt;/strong&gt;.&lt;/li&gt; 
  &lt;li&gt;The rest of the workspace has an MSRV of &lt;strong&gt;1.88&lt;/strong&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;It is enforced on CI (in "/.github/workflows/ci.yml") with the &lt;code&gt;CORE_MSRV&lt;/code&gt; and &lt;code&gt;REPO_MSRV&lt;/code&gt; variables. This version can only be upgraded in breaking releases, though we release a breaking version every three months.&lt;/p&gt; 
 &lt;p&gt;The &lt;code&gt;naga&lt;/code&gt;, &lt;code&gt;wgpu-core&lt;/code&gt;, &lt;code&gt;wgpu-hal&lt;/code&gt;, and &lt;code&gt;wgpu-types&lt;/code&gt; crates should never require an MSRV ahead of Firefox's MSRV for nightly builds, as determined by the value of &lt;code&gt;MINIMUM_RUST_VERSION&lt;/code&gt; in &lt;a href="https://searchfox.org/mozilla-central/source/python/mozboot/mozboot/util.py"&gt;&lt;code&gt;python/mozboot/mozboot/util.py&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Testing and Environment Variables&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/docs/testing.md"&gt;Information about testing&lt;/a&gt;, including where tests of various kinds live, and how to run the tests.&lt;/p&gt; 
&lt;h2&gt;Tracking the WebGPU and WGSL draft specifications&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;wgpu&lt;/code&gt; crate is meant to be an idiomatic Rust translation of the &lt;a href="https://www.w3.org/TR/webgpu/"&gt;WebGPU API&lt;/a&gt;. That specification, along with its shading language, &lt;a href="https://gpuweb.github.io/gpuweb/wgsl/"&gt;WGSL&lt;/a&gt;, are both still in the "Working Draft" phase, and while the general outlines are stable, details change frequently. Until the specification is stabilized, the &lt;code&gt;wgpu&lt;/code&gt; crate and the version of WGSL it implements will likely differ from what is specified, as the implementation catches up.&lt;/p&gt; 
&lt;p&gt;Exactly which WGSL features &lt;code&gt;wgpu&lt;/code&gt; supports depends on how you are using it:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;When running as native code, &lt;code&gt;wgpu&lt;/code&gt; uses &lt;a href="https://github.com/gfx-rs/wgpu/tree/trunk/naga/"&gt;Naga&lt;/a&gt; to translate WGSL code into the shading language of your platform's native GPU API. Naga is working on catching up to the WGSL specification, with &lt;a href="https://github.com/gfx-rs/wgpu/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22naga%22"&gt;bugs&lt;/a&gt; tracking various issues, but there is no concise summary of differences from the specification.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;When running in a web browser (by compilation to WebAssembly) without the &lt;code&gt;"webgl"&lt;/code&gt; feature enabled, &lt;code&gt;wgpu&lt;/code&gt; relies on the browser's own WebGPU implementation. WGSL shaders are simply passed through to the browser, so that determines which WGSL features you can use.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;When running in a web browser with &lt;code&gt;wgpu&lt;/code&gt;'s &lt;code&gt;"webgl"&lt;/code&gt; feature enabled, &lt;code&gt;wgpu&lt;/code&gt; uses Naga to translate WGSL programs into GLSL. This uses the same version of Naga as if you were running &lt;code&gt;wgpu&lt;/code&gt; as native code.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>openobserve/openobserve</title>
      <link>https://github.com/openobserve/openobserve</link>
      <description>&lt;p&gt;Modern observability platform: 10x easier, 140x lower storage cost, petabyte scale. Open-source alternative to Elasticsearch/Splunk/Datadog for logs, metrics, traces, RUM, and more.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://openobserve.ai"&gt;&lt;img src="https://openobserve.ai/img/logo/o2-logo-readme.svg?sanitize=true" alt="OpenObserve" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt;Modern observability platform: 10x easier, 140x lower storage cost, high performance, petabyte scale - Elasticsearch/Splunk/Datadog alternative for logs, metrics, traces, frontend monitoring and more.&lt;/em&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/openobserve/openobserve" target="_blank"&gt; &lt;img src="https://img.shields.io/github/last-commit/openobserve/openobserve" alt="Last Commit" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/stargazers" target="_blank"&gt; &lt;img src="https://img.shields.io/github/stars/openobserve/openobserve" alt="GitHub Stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/issues" target="_blank"&gt; &lt;img src="https://img.shields.io/github/issues/openobserve/openobserve" alt="GitHub Issues" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/graphs/contributors" target="_blank"&gt; &lt;img src="https://img.shields.io/github/contributors/openobserve/openobserve" alt="Contributors" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/releases" target="_blank"&gt; &lt;img src="https://img.shields.io/github/v/release/openobserve/openobserve" alt="GitHub Release" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;OpenObserve (O2 for short) is a cloud-native observability platform built specifically for logs, metrics, traces, analytics, frontend monitoring and more. Start with a single binary that scales to terabytes, or deploy in High Availability mode for petabyte-scale workloads.&lt;/p&gt; 
&lt;h2&gt;Why OpenObserve?&lt;/h2&gt; 
&lt;h3&gt;1. Simplicity&lt;/h3&gt; 
&lt;p&gt;It is straightforward and easy to operate compared to other observability tools that require understanding and tuning numerous settings. Get OpenObserve up and running on a single node in under 2 minutes. No PhD required.&lt;/p&gt; 
&lt;h3&gt;2. Cost Efficiency&lt;/h3&gt; 
&lt;p&gt;You can reduce your log storage costs by ~140x compared to Elasticsearch. Yes, you read that right - 140x, not a typo. This is achieved through columnar storage format (Parquet), aggressive compression, and S3-native architecture. See the detailed comparison below where we ingested the same amount of data in OpenObserve and Elasticsearch and found OpenObserve storage cost to be ~140x lower. Your CFO will love you.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_vs_es.png" alt="OpenObserve Vs Elasticsearch" /&gt;&lt;/p&gt; 
&lt;h3&gt;3. Performance&lt;/h3&gt; 
&lt;p&gt;OpenObserve delivers better performance than Elasticsearch while using 1/4th the hardware resources. Users report faster search performance and significantly faster analytics queries. The columnar storage format (Parquet) with intelligent partitioning and caching reduces the search space by up to 99% for most queries. Built in Rust for memory safety and high performance, OpenObserve handles thousands of concurrent users querying a single cluster simultaneously.&lt;/p&gt; 
&lt;h3&gt;4. Single Binary Platform&lt;/h3&gt; 
&lt;p&gt;Consolidate metrics, logs, and traces on one single, efficient platform. OpenObserve comes with its own UI, eliminating the need for multiple installations. One binary to rule them all.&lt;/p&gt; 
&lt;h2&gt;üé• Introduction Video&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=4VwuC1tpRP4"&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/o2_intro.webp" alt="OpenObserve Introduction" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;OpenObserve achieves 140x lower storage costs and high performance through its modern architecture:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Parquet columnar storage&lt;/strong&gt;: Efficient compression and query performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3-native design&lt;/strong&gt;: Leverages inexpensive object storage with intelligent caching&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built in Rust&lt;/strong&gt;: Memory-safe, high-performance, single binary deployment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Partitioning, indexing and smart caching&lt;/strong&gt;: Reduces search space by up to 99% for most queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native multi-tenancy&lt;/strong&gt;: Organizations and streams as first-class concepts with complete data isolation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stateless architecture&lt;/strong&gt;: Enables rapid scaling and low RPO/RTO for disaster recovery&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This architecture delivers 140x cost savings while providing better performance than Elasticsearch.&lt;/p&gt; 
&lt;h3&gt;Scale &amp;amp; Deployment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Thousands of concurrent users&lt;/strong&gt; can query a single cluster simultaneously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single binary&lt;/strong&gt; scales to terabytes - unique in the observability space&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Availability mode&lt;/strong&gt; scales to petabytes for the most demanding workloads&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-region deployments&lt;/strong&gt; with cluster federation via Super Cluster architecture (Enterprise feature)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Federated search&lt;/strong&gt; across regions and clusters (Enterprise feature)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Capacity planning tools&lt;/strong&gt; to size deployments for your workload&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;High Availability &amp;amp; Disaster Recovery&lt;/h3&gt; 
&lt;p&gt;Deploy in High Availability mode with clustering for mission-critical workloads requiring maximum uptime and performance.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Low RPO/RTO&lt;/strong&gt;: OpenObserve's stateless architecture with S3-backed storage enables very low Recovery Point Objective (RPO) and Recovery Time Objective (RTO). Stateless nodes can be rapidly restarted, and data durability is guaranteed by S3's 99.999999999% (11 nines) durability. That's a lot of nines.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://openobserve.ai/docs/architecture/"&gt;Read detailed architecture documentation ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://openobserve.ai/docs/ha_deployment/"&gt;Read enterprise deployment guide ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Capabilities&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Logs, Metrics, Traces&lt;/strong&gt;: Full support for all three pillars of observability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenTelemetry Support&lt;/strong&gt;: Native OTLP ingestion for logs, metrics, and traces.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real User Monitoring (RUM)&lt;/strong&gt;: Performance tracking, error logging, and session replay.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dashboards, Reports, Alerts&lt;/strong&gt;: 19+ built-in chart types plus a custom chart capability that enables creating 200+ chart variations including 3D visualizations. Scheduled reports and flexible alerting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pipelines&lt;/strong&gt;: Enrich, redact, reduce, or normalize data on ingest. Stream processing for logs-to-metrics and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in Web UI&lt;/strong&gt;: No separate frontend to install or manage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQL and PromQL Support&lt;/strong&gt;: Query logs and traces with SQL, metrics with SQL or PromQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single Binary or High Availability Mode&lt;/strong&gt;: Start with one binary, scale to full High Availability when you need it.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Storage&lt;/strong&gt;: Local disk, S3, MinIO, GCS, or Azure Blob Storage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Availability and Clustering&lt;/strong&gt;: Production-grade High Availability deployment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Schema&lt;/strong&gt;: No predefined schema required - just start sending data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in Authentication&lt;/strong&gt;: Secure by default.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple Upgrades&lt;/strong&gt;: No complex migration scripts required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multilingual UI&lt;/strong&gt;: Available in 11 languages including English, Spanish, German, French, Chinese, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a full list of features, check the &lt;a href="https://openobserve.ai/docs/#project-status-features-and-roadmap"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ö°Ô∏è Quick start&lt;/h2&gt; 
&lt;h3&gt;üê≥ Docker:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
      --name openobserve \
      -v $PWD/data:/data \
      -p 5080:5080 \
      -e ZO_ROOT_USER_EMAIL="root@example.com" \
      -e ZO_ROOT_USER_PASSWORD="Complexpass#123" \
      public.ecr.aws/zinclabs/openobserve:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For other ways to quickly install OpenObserve or use OpenObserve cloud, check &lt;a href="https://openobserve.ai/docs/quickstart"&gt;quickstart documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For installing OpenObserve in High Availability mode, check &lt;a href="https://openobserve.ai/docs/ha_deployment/"&gt;High Availability deployment documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üèÜ Production Ready&lt;/h2&gt; 
&lt;p&gt;OpenObserve is battle-tested in production environments worldwide (and by "battle-tested", we mean real production traffic, not just our test lab):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Thousands of active deployments&lt;/strong&gt; across diverse industries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Largest deployment processes 2 PB/day&lt;/strong&gt; of data ingestion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single binary scales to terabytes&lt;/strong&gt; - unique in the observability space, no other single-binary solution achieves this scale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Availability mode scales to petabytes&lt;/strong&gt; - for the most demanding workloads&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://openobserve.ai/customer-stories/"&gt;Read customer stories ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∑ Screenshots&lt;/h2&gt; 
&lt;p&gt;OpenObserve includes a powerful web UI for logs, traces, dashboards, alerts, and more.&lt;/p&gt; 
&lt;h3&gt;Logs Search&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/logs.png" alt="Logs" /&gt;&lt;/p&gt; 
&lt;h3&gt;Distributed Tracing&lt;/h3&gt; 
&lt;p&gt;Trace details page with full request flow visualization: &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces.png" alt="Traces using OpenTelemetry" /&gt;&lt;/p&gt; 
&lt;h3&gt;Dashboards&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard.png" alt="Dashboard" /&gt;&lt;/p&gt; 
&lt;h3&gt;Frontend Monitoring&lt;/h3&gt; 
&lt;p&gt;Real user monitoring with session replay: &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/session-replay.png" alt="Session replay" /&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;See more screenshots&lt;/summary&gt; 
 &lt;h3&gt;Home&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_home.png" alt="Home" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Golden Metrics from Traces&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces-overall.png" alt="Traces golden metrics" /&gt;&lt;/p&gt; 
 &lt;h3&gt;More Dashboard Examples&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard2.png" alt="Dashboard" /&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/create-panel.png" alt="Create panel" /&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/map.png" alt="Map" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Performance Analytics&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/performance.png" alt="Performance" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Error Tracking&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/error-tracking.png" alt="Error tracking" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Alerts&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/alerts.png" alt="Alerts" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Streams&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/streams.png" alt="Streams" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Ingestion&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/ingestion1.png" alt="Ingestion" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Pipeline&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/pipeline.png" alt="Pipeline" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Functions&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/function.png" alt="Function" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üîê Security &amp;amp; Compliance&lt;/h2&gt; 
&lt;h3&gt;Security Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Highly secure architecture&lt;/strong&gt; with secure container images&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sensitive Data Redaction (SDR)&lt;/strong&gt;: Automatically redact sensitive data during ingestion and query time (Enterprise feature)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data encryption&lt;/strong&gt;: At rest and in transit&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single Sign-On (SSO)&lt;/strong&gt;: OIDC, OAuth, SAML, LDAP/AD integration (Enterprise feature)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Role-Based Access Control (RBAC)&lt;/strong&gt;: Granular permissions management (Enterprise feature) - &lt;a href="https://openobserve.ai/docs/user-guide/identity-and-access-management/role-based-access-control/"&gt;Learn more ‚Üí&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Compliance Certifications&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;SOC 2 Type II&lt;/strong&gt; certified&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;ISO 27001&lt;/strong&gt; certified&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;GDPR&lt;/strong&gt; compliant&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;HIPAA&lt;/strong&gt; ready (BAA available with Enterprise contracts)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;OpenObserve meets the stringent security and compliance requirements of regulated industries including finance, healthcare, and government.&lt;/p&gt; 
&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Open Source Edition&lt;/strong&gt;: Licensed under AGPL-3.0. We chose AGPL to ensure that improvements to OpenObserve remain open source and benefit the entire community. This license protects the commons while still allowing free commercial use.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Enterprise Edition&lt;/strong&gt;: Licensed under a commercial Enterprise License Agreement, not AGPL. This provides additional flexibility for enterprise deployments and eliminates any concerns about AGPL requirements.&lt;/p&gt; 
&lt;p&gt;For more details:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openobserve/openobserve/raw/main/LICENSE"&gt;Open Source LICENSE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openobserve.ai/blog/what-are-apache-gpl-and-agpl-licenses-and-why-openobserve-moved-from-apache-to-agpl/"&gt;Why AGPL and why it's good for the community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíº Enterprise Support&lt;/h2&gt; 
&lt;p&gt;OpenObserve is built as a true open source project, and we're committed to the community. &lt;strong&gt;The open source version is feature-complete and production-ready&lt;/strong&gt; - it includes logs, metrics, traces, dashboards, alerts, pipelines, and everything you need to run observability at scale. It will always remain actively maintained and free to use without restrictions.&lt;/p&gt; 
&lt;h3&gt;Enterprise Edition&lt;/h3&gt; 
&lt;p&gt;For organizations requiring enterprise-grade features and support, we offer an Enterprise edition with:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Enterprise Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Single Sign-On (SSO)&lt;/strong&gt;: OIDC, OAuth, SAML 2.0, LDAP/AD, and integration with major identity providers (Okta, Azure Entra, Google, GitHub, GitLab, Keycloak)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced RBAC&lt;/strong&gt;: Granular role-based access control with custom roles and permissions - &lt;a href="https://openobserve.ai/docs/user-guide/identity-and-access-management/role-based-access-control/"&gt;Learn more ‚Üí&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Audit trails&lt;/strong&gt;: Comprehensive immutable audit logs with configurable retention&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Federated search&lt;/strong&gt;: Query across multiple clusters and regions with Super Cluster&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sensitive Data Redaction (SDR)&lt;/strong&gt;: Automatically redact PII and sensitive data during ingestion and queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced encryption&lt;/strong&gt;: AES-256 SIV cipher keys with Google Tink KeySet and Akeyless integration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query management&lt;/strong&gt;: Control query resource usage and priorities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workload management (QoS)&lt;/strong&gt;: Quality of Service controls for multi-tenant environments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Enterprise Support &amp;amp; SLAs:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Dedicated support with contractual SLA guarantees&lt;/li&gt; 
 &lt;li&gt;Priority response times for critical issues&lt;/li&gt; 
 &lt;li&gt;Technical account management&lt;/li&gt; 
 &lt;li&gt;Architecture review and deployment assistance&lt;/li&gt; 
 &lt;li&gt;Migration support from existing tools&lt;/li&gt; 
 &lt;li&gt;Training and onboarding programs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Pricing:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Free tier&lt;/strong&gt;: Up to 200 GB/day of ingestion (roughly 6 TB/month), including full commercial use&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Registration required at 100 GB/day&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Volume discounts and multi-year contracts available&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openobserve.ai/downloads/"&gt;View complete feature comparison ‚Üí&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For enterprise inquiries and custom deployments, contact our sales team.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding features, improving documentation, or sharing feedback, your help makes OpenObserve better for everyone.&lt;/p&gt; 
&lt;p&gt;To get started, please read our &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; which covers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;How to set up your development environment&lt;/li&gt; 
 &lt;li&gt;Code standards and best practices&lt;/li&gt; 
 &lt;li&gt;How to submit pull requests&lt;/li&gt; 
 &lt;li&gt;Reporting bugs and requesting features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåç Community&lt;/h2&gt; 
&lt;p&gt;The best way to get help, share ideas, and connect with other OpenObserve users is through our community channels. We're a friendly group of developers, operators, and observability enthusiasts.&lt;/p&gt; 
&lt;h3&gt;üîó Join us on Slack&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://short.openobserve.ai/community"&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/slack.png" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Our Slack community is the most active place for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Getting help with installation and configuration&lt;/li&gt; 
 &lt;li&gt;Sharing best practices and use cases&lt;/li&gt; 
 &lt;li&gt;Discussing feature requests and roadmap&lt;/li&gt; 
 &lt;li&gt;Connecting with the core team and other users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://short.openobserve.ai/community"&gt;Join the conversation ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Other ways to connect&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://github.com/openobserve/openobserve/discussions"&gt;GitHub Discussions&lt;/a&gt; - For longer-form discussions and Q&amp;amp;A&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/openobserve/openobserve/issues"&gt;GitHub Issues&lt;/a&gt; - Report bugs or request features&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://openobserve.ai/docs"&gt;Documentation&lt;/a&gt; - Guides, tutorials, and API references&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ùì FAQ&lt;/h2&gt; 
&lt;h3&gt;How does OpenObserve achieve 140x lower storage costs?&lt;/h3&gt; 
&lt;p&gt;Through a combination of Parquet columnar storage format (efficient compression), S3-native architecture (leveraging inexpensive object storage). See the detailed comparison chart in the "Why OpenObserve?" section above.&lt;/p&gt; 
&lt;h3&gt;What are the limitations?&lt;/h3&gt; 
&lt;p&gt;All data in OpenObserve is &lt;strong&gt;immutable&lt;/strong&gt; - once ingested, it cannot be modified or deleted (only entire retention periods can be dropped). This is by design and is actually a feature for logs and compliance requirements, ensuring data integrity and audit trails.&lt;/p&gt; 
&lt;h3&gt;Is this production-ready?&lt;/h3&gt; 
&lt;p&gt;Yes. OpenObserve is running in production with thousands of deployments worldwide, including environments processing in excess of 2 PB/day. See our &lt;a href="https://openobserve.ai/customer-stories/"&gt;customer stories&lt;/a&gt; for real-world examples.&lt;/p&gt; 
&lt;h3&gt;How does query performance compare to Elasticsearch?&lt;/h3&gt; 
&lt;p&gt;OpenObserve delivers better performance than Elasticsearch for most workloads. Users report faster search performance and significantly faster analytics queries, all while using 1/4th the hardware resources. The columnar storage format (Parquet) is particularly effective for complex aggregations and analytics workloads.&lt;/p&gt; 
&lt;h3&gt;Is there a steep learning curve?&lt;/h3&gt; 
&lt;p&gt;No. OpenObserve is designed to be intuitive from day one:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Familiar query languages&lt;/strong&gt;: Use SQL for logs and traces, PromQL for metrics - no proprietary query language to learn&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy-to-use GUI&lt;/strong&gt;: Intuitive interface with drag-and-drop dashboard builder&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Helpful community&lt;/strong&gt;: Active Slack community and comprehensive documentation to help you get started quickly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No complex tuning&lt;/strong&gt;: Unlike Elasticsearch, you don't need to understand shards, replicas, heap sizes, or other complex configurations. Just install and go.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Most users are productive within hours, not weeks. Some even claim minutes, but we'll let you be the judge.&lt;/p&gt; 
&lt;h2&gt;üîê SBOM&lt;/h2&gt; 
&lt;p&gt;Software Bill of Materials for OpenObserve&lt;/p&gt; 
&lt;h3&gt;Rust&lt;/h3&gt; 
&lt;p&gt;SBOM can be found &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/openobserve.cdx.xml"&gt;here&lt;/a&gt;. You can analyze it using &lt;a href="https://dependencytrack.org/"&gt;dependency track&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In order to generate the SBOM, you can use the following commands:&lt;/p&gt; 
&lt;p&gt;Install cargo-cyclonedx:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-cyclonedx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the SBOM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo-cyclonedx cyclonedx
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;JavaScript&lt;/h3&gt; 
&lt;p&gt;SBOM can be found &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/web/sbom.json"&gt;here&lt;/a&gt;. You can analyze it using &lt;a href="https://dependencytrack.org/"&gt;dependency track&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In order to generate the SBOM, you can use the following commands:&lt;/p&gt; 
&lt;p&gt;Install cyclonedx-npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install --global @cyclonedx/cyclonedx-npm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the SBOM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd web
cyclonedx-npm &amp;gt; sbom.json
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install --cask codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer. &lt;br /&gt; &lt;br /&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href="https://developers.openai.com/codex/ide"&gt;install in your IDE&lt;/a&gt; &lt;br /&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager. If you use npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, if you use Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install --cask codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're running into upgrade issues with Homebrew, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md#brew-upgrade-codex-isnt-upgrading-me"&gt;FAQ entry on brew upgrade codex&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="80%" /&gt; &lt;/p&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. &lt;a href="https://help.openai.com/en/articles/11369540-codex-in-chatgpt"&gt;Learn more about what's included in your ChatGPT plan&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also use Codex with an API key, but this requires &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key"&gt;additional setup&lt;/a&gt;. If you previously used an API key for usage-based billing, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#migrating-from-usage-based-billing-api-key"&gt;migration steps&lt;/a&gt;. If you're having trouble with login, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Model Context Protocol (MCP)&lt;/h3&gt; 
&lt;p&gt;Codex can access MCP servers. To configure them, refer to the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md#mcp_servers"&gt;config docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports a rich set of configuration options, with preferences stored in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For full configuration options, see &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Docs &amp;amp; FAQ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md"&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#cli-usage"&gt;CLI usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/slash_commands.md"&gt;Slash Commands&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/prompts.md"&gt;Custom prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#memory-with-agentsmd"&gt;Memory with AGENTS.md&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;&lt;strong&gt;Configuration&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/example-config.md"&gt;Example config&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/sandbox.md"&gt;&lt;strong&gt;Sandbox &amp;amp; approvals&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md"&gt;&lt;strong&gt;Authentication&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#forcing-a-specific-auth-method-advanced"&gt;Auth methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#connecting-on-a-headless-machine"&gt;Login on a "Headless" machine&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automating Codex&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/openai/codex-action"&gt;GitHub Action&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/sdk/typescript/README.md"&gt;TypeScript SDK&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/exec.md"&gt;Non-interactive mode (&lt;code&gt;codex exec&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md"&gt;&lt;strong&gt;Advanced&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/zdr.md"&gt;&lt;strong&gt;Zero data retention (ZDR)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/contributing.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md"&gt;&lt;strong&gt;Install &amp;amp; build&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#system-requirements"&gt;System Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#build-from-source"&gt;Build from source&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/open-source-fund.md"&gt;&lt;strong&gt;Open source fund&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>embassy-rs/embassy</title>
      <link>https://github.com/embassy-rs/embassy</link>
      <description>&lt;p&gt;Modern embedded framework, using Rust and async.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Embassy&lt;/h1&gt; 
&lt;p&gt;Embassy is the next-generation framework for embedded applications. Write safe, correct, and energy-efficient embedded code faster, using the Rust programming language, its async facilities, and the Embassy libraries.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://embassy.dev/book/index.html"&gt;Documentation&lt;/a&gt; - &lt;a href="https://docs.embassy.dev/"&gt;API reference&lt;/a&gt; - &lt;a href="https://embassy.dev/"&gt;Website&lt;/a&gt; - &lt;a href="https://matrix.to/#/#embassy-rs:matrix.org"&gt;Chat&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Rust + async ‚ù§Ô∏è embedded&lt;/h2&gt; 
&lt;p&gt;The Rust programming language is blazingly fast and memory-efficient, with no runtime, garbage collector, or OS. It catches a wide variety of bugs at compile time, thanks to its full memory- and thread-safety, and expressive type system.&lt;/p&gt; 
&lt;p&gt;Rust's &lt;a href="https://rust-lang.github.io/async-book/"&gt;async/await&lt;/a&gt; allows for unprecedentedly easy and efficient multitasking in embedded systems. Tasks get transformed at compile time into state machines that get run cooperatively. It requires no dynamic memory allocation and runs on a single stack, so no per-task stack size tuning is required. It obsoletes the need for a traditional RTOS with kernel context switching, and is &lt;a href="https://tweedegolf.nl/en/blog/65/async-rust-vs-rtos-showdown"&gt;faster and smaller than one!&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Batteries included&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hardware Abstraction Layers&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;HALs implement safe, idiomatic Rust APIs to use the hardware capabilities, so raw register manipulation is not needed. The Embassy project maintains HALs for select hardware, but you can still use HALs from other projects with Embassy.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.embassy.dev/embassy-stm32/"&gt;embassy-stm32&lt;/a&gt;, for all STM32 microcontroller families.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.embassy.dev/embassy-nrf/"&gt;embassy-nrf&lt;/a&gt;, for the Nordic Semiconductor nRF52, nRF53, nRF54 and nRF91 series.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.embassy.dev/embassy-rp/"&gt;embassy-rp&lt;/a&gt;, for the Raspberry Pi RP2040 and RP23xx microcontrollers.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.embassy.dev/embassy-mspm0/"&gt;embassy-mspm0&lt;/a&gt;, for the Texas Instruments MSPM0 microcontrollers.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/esp-rs"&gt;esp-rs&lt;/a&gt;, for the Espressif Systems ESP32 series of chips. 
    &lt;ul&gt; 
     &lt;li&gt;Embassy HAL support for Espressif chips, as well as Async Wi-Fi, Bluetooth, and ESP-NOW, is being developed in the &lt;a href="https://github.com/esp-rs/esp-hal"&gt;esp-rs/esp-hal&lt;/a&gt; repository.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ch32-rs/ch32-hal"&gt;ch32-hal&lt;/a&gt;, for the WCH 32-bit RISC-V(CH32V) series of chips.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AlexCharlton/mpfs-hal"&gt;mpfs-hal&lt;/a&gt;, for the Microchip PolarFire SoC.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/py32-rs/py32-hal"&gt;py32-hal&lt;/a&gt;, for the Puya Semiconductor PY32 series of microcontrollers.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Time that Just Works&lt;/strong&gt; - No more messing with hardware timers. &lt;a href="https://docs.embassy.dev/embassy-time"&gt;embassy_time&lt;/a&gt; provides Instant, Duration, and Timer types that are globally available and never overflow.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Real-time ready&lt;/strong&gt; - Tasks on the same async executor run cooperatively, but you can create multiple executors with different priorities so that higher priority tasks preempt lower priority ones. See the &lt;a href="https://github.com/embassy-rs/embassy/raw/main/examples/nrf52840/src/bin/multiprio.rs"&gt;example&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Low-power ready&lt;/strong&gt; - Easily build devices with years of battery life. The async executor automatically puts the core to sleep when there's no work to do. Tasks are woken by interrupts, there is no busy-loop polling while waiting.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Networking&lt;/strong&gt; - The &lt;a href="https://docs.embassy.dev/embassy-net/"&gt;embassy-net&lt;/a&gt; network stack implements extensive networking functionality, including Ethernet, IP, TCP, UDP, ICMP, and DHCP. Async drastically simplifies managing timeouts and serving multiple connections concurrently.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bluetooth&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The &lt;a href="https://github.com/embassy-rs/trouble"&gt;trouble&lt;/a&gt; crate provides a Bluetooth Low Energy 4.x and 5.x Host that runs on any microcontroller implementing the &lt;a href="https://github.com/embassy-rs/bt-hci"&gt;bt-hci&lt;/a&gt; traits (currently &lt;code&gt;nRF52&lt;/code&gt;, &lt;code&gt;rp2040&lt;/code&gt;, &lt;code&gt;rp23xx&lt;/code&gt; and &lt;code&gt;esp32&lt;/code&gt; and &lt;code&gt;serial&lt;/code&gt; controllers are supported).&lt;/li&gt; 
   &lt;li&gt;The &lt;a href="https://github.com/embassy-rs/nrf-softdevice"&gt;nrf-softdevice&lt;/a&gt; crate provides Bluetooth Low Energy 4.x and 5.x support for nRF52 microcontrollers.&lt;/li&gt; 
   &lt;li&gt;The &lt;a href="https://github.com/embassy-rs/embassy/tree/main/embassy-stm32-wpan"&gt;embassy-stm32-wpan&lt;/a&gt; crate provides Bluetooth Low Energy 5.x support for stm32wb microcontrollers.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LoRa&lt;/strong&gt; - The &lt;a href="https://github.com/lora-rs/lora-rs"&gt;lora-rs&lt;/a&gt; project provides an async LoRa and LoRaWAN stack that works well on Embassy.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;USB&lt;/strong&gt; - &lt;a href="https://docs.embassy.dev/embassy-usb/"&gt;embassy-usb&lt;/a&gt; implements a device-side USB stack. Implementations for common classes such as USB serial (CDC ACM) and USB HID are available, and a rich builder API allows building your own.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bootloader and DFU&lt;/strong&gt; - &lt;a href="https://github.com/embassy-rs/embassy/tree/main/embassy-boot"&gt;embassy-boot&lt;/a&gt; is a lightweight bootloader supporting firmware application upgrades in a power-fail-safe way, with trial boots and rollbacks.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sneak peek&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-rust,ignore"&gt;use defmt::info;
use embassy_executor::Spawner;
use embassy_time::{Duration, Timer};
use embassy_nrf::gpio::{AnyPin, Input, Level, Output, OutputDrive, Pin, Pull};
use embassy_nrf::{Peri, Peripherals};

// Declare async tasks
#[embassy_executor::task]
async fn blink(pin: Peri&amp;lt;'static, AnyPin&amp;gt;) {
    let mut led = Output::new(pin, Level::Low, OutputDrive::Standard);

    loop {
        // Timekeeping is globally available, no need to mess with hardware timers.
        led.set_high();
        Timer::after_millis(150).await;
        led.set_low();
        Timer::after_millis(150).await;
    }
}

// Main is itself an async task as well.
#[embassy_executor::main]
async fn main(spawner: Spawner) {
    let p = embassy_nrf::init(Default::default());

    // Spawned tasks run in the background, concurrently.
    spawner.spawn(blink(p.P0_13.into()).unwrap());

    let mut button = Input::new(p.P0_11, Pull::Up);
    loop {
        // Asynchronously wait for GPIO events, allowing other tasks
        // to run, or the core to sleep.
        button.wait_for_low().await;
        info!("Button pressed!");
        button.wait_for_high().await;
        info!("Button released!");
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Examples are found in the &lt;code&gt;examples/&lt;/code&gt; folder separated by the chip manufacturer they are designed to run on. For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;examples/nrf52840&lt;/code&gt; run on the &lt;code&gt;nrf52840-dk&lt;/code&gt; board (PCA10056) but should be easily adaptable to other nRF52 chips and boards.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;examples/nrf5340&lt;/code&gt; run on the &lt;code&gt;nrf5340-dk&lt;/code&gt; board (PCA10095).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;examples/stm32xx&lt;/code&gt; for the various STM32 families.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;examples/rp&lt;/code&gt; are for the RP2040 chip.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;examples/std&lt;/code&gt; are designed to run locally on your PC.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Running examples&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;probe-rs&lt;/code&gt; following the instructions at &lt;a href="https://probe.rs"&gt;https://probe.rs&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Change directory to the sample's base directory. For example:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd examples/nrf52840
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ensure &lt;code&gt;Cargo.toml&lt;/code&gt; sets the right feature for the name of the chip you are programming. If this name is incorrect, the example may fail to run or immediately crash after being programmed.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ensure &lt;code&gt;.cargo/config.toml&lt;/code&gt; contains the name of the chip you are programming.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the example&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --release --bin blinky
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more help getting started, see &lt;a href="https://github.com/embassy-rs/embassy/wiki/Getting-Started"&gt;Getting Started&lt;/a&gt; and &lt;a href="https://github.com/embassy-rs/embassy/wiki/Running-the-Examples"&gt;Running the Examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Developing Embassy with Rust Analyzer-based editors&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://rust-analyzer.github.io/"&gt;Rust Analyzer&lt;/a&gt; is used by &lt;a href="https://code.visualstudio.com/"&gt;Visual Studio Code&lt;/a&gt; and others. Given the multiple targets that Embassy serves, there is no Cargo workspace file. Instead, the Rust Analyzer must be told of the target project to work with. In the case of Visual Studio Code, please refer to the &lt;code&gt;.vscode/settings.json&lt;/code&gt; file's &lt;code&gt;rust-analyzer.linkedProjects&lt;/code&gt;setting.&lt;/p&gt; 
&lt;h2&gt;Minimum supported Rust version (MSRV)&lt;/h2&gt; 
&lt;p&gt;Embassy is guaranteed to compile on stable Rust 1.75 and up. It &lt;em&gt;might&lt;/em&gt; compile with older versions, but that may change in any new patch release.&lt;/p&gt; 
&lt;h2&gt;Why the name?&lt;/h2&gt; 
&lt;p&gt;EMBedded ASYnc! :)&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Embassy is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0 (&lt;a href="https://raw.githubusercontent.com/embassy-rs/embassy/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/embassy-rs/embassy/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="http://opensource.org/licenses/MIT"&gt;http://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tursodatabase/turso</title>
      <link>https://github.com/tursodatabase/turso</link>
      <description>&lt;p&gt;Turso is an in-process SQL database, compatible with SQLite.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/turso.png" alt="Turso Database" width="800" /&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;Turso Database&lt;/h1&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; An in-process SQL database, compatible with SQLite. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a title="Build Status" target="_blank" href="https://github.com/tursodatabase/turso/actions/workflows/rust.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/tursodatabase/turso/rust.yml?style=flat-square" /&gt;&lt;/a&gt; &lt;a title="Releases" target="_blank" href="https://github.com/tursodatabase/turso/releases"&gt;&lt;img src="https://img.shields.io/github/release/tursodatabase/turso?style=flat-square&amp;amp;color=9CF" /&gt;&lt;/a&gt; &lt;a title="Rust" target="_blank" href="https://crates.io/crates/turso"&gt;&lt;img alt="Crate" src="https://img.shields.io/crates/v/turso" /&gt;&lt;/a&gt; &lt;a title="JavaScript" target="_blank" href="https://www.npmjs.com/package/@tursodatabase/database"&gt;&lt;img alt="NPM" src="https://img.shields.io/npm/v/@tursodatabase/database" /&gt;&lt;/a&gt; &lt;a title="Python" target="_blank" href="https://pypi.org/project/pyturso/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/pyturso" /&gt;&lt;/a&gt; &lt;a title="Java" target="_blank" href="https://central.sonatype.com/artifact/tech.turso/turso"&gt;&lt;img alt="Maven Central" src="https://img.shields.io/maven-central/v/tech.turso/turso" /&gt;&lt;/a&gt; &lt;a title="MIT" target="_blank" href="https://github.com/tursodatabase/turso/raw/main/LICENSE.md"&gt;&lt;img src="http://img.shields.io/badge/license-MIT-orange.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a title="GitHub Pull Requests" target="_blank" href="https://github.com/tursodatabase/turso/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr-closed/tursodatabase/turso.svg?style=flat-square&amp;amp;color=FF9966" /&gt;&lt;/a&gt; &lt;a title="GitHub Commits" target="_blank" href="https://github.com/tursodatabase/turso/commits/main"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/tursodatabase/turso.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;a title="Last Commit" target="_blank" href="https://github.com/tursodatabase/turso/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/tursodatabase/turso.svg?style=flat-square&amp;amp;color=FF9900" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a title="Developer's Discord" target="_blank" href="https://discord.gg/jgjmyYgHwB"&gt;&lt;img alt="Chat with the Core Developers on Discord" src="https://img.shields.io/discord/1258658826257961020?label=Discord&amp;amp;logo=Discord&amp;amp;style=social&amp;amp;label=Core%20Developers" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a title="Users's Discord" target="_blank" href="https://tur.so/discord"&gt;&lt;img alt="Chat with other users of Turso (and Turso Cloud) on Discord" src="https://img.shields.io/discord/933071162680958986?label=Discord&amp;amp;logo=Discord&amp;amp;style=social&amp;amp;label=Users" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Turso Database is an in-process SQL database written in Rust, compatible with SQLite.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Warning:&lt;/strong&gt; This software is in BETA. It may still contain bugs and unexpected behavior. Use caution with production data and ensure you have backups.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features and Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite compatibility&lt;/strong&gt; for SQL dialect, file formats, and the C API [see &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/COMPAT.md"&gt;document&lt;/a&gt; for details]&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change data capture (CDC)&lt;/strong&gt; for real-time tracking of database changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-language support&lt;/strong&gt; for 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tursodatabase/turso-go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/javascript"&gt;JavaScript&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/java"&gt;Java&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/rust"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/javascript"&gt;WebAssembly&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Asynchronous I/O&lt;/strong&gt; support on Linux with &lt;code&gt;io_uring&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-platform&lt;/strong&gt; support for Linux, macOS, Windows and browsers (through WebAssembly)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vector support&lt;/strong&gt; support including exact search and vector manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Improved schema management&lt;/strong&gt; including extended &lt;code&gt;ALTER&lt;/code&gt; support and faster schema changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The database has the following experimental features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;BEGIN CONCURRENT&lt;/code&gt;&lt;/strong&gt; for improved write throughput using multi-version concurrency control (MVCC).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Encryption at rest&lt;/strong&gt; for protecting the data locally.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incremental computation&lt;/strong&gt; using DBSP for incremental view mainatenance and query subscriptions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following features are on our current roadmap:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Vector indexing&lt;/strong&gt; for fast approximate vector search, similar to &lt;a href="https://turso.tech/vector"&gt;libSQL vector search&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/docs/manual.md"&gt;Turso Database Manual&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;üíª Command Line&lt;/summary&gt; 
 &lt;br /&gt; You can install the latest `turso` release with: 
 &lt;pre&gt;&lt;code class="language-shell"&gt;curl --proto '=https' --tlsv1.2 -LsSf \
  https://github.com/tursodatabase/turso/releases/latest/download/turso_cli-installer.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Then launch the interactive shell:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;$ tursodb
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This will start the Turso interactive shell where you can execute SQL statements:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;Turso
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database
turso&amp;gt; CREATE TABLE users (id INT, username TEXT);
turso&amp;gt; INSERT INTO users VALUES (1, 'alice');
turso&amp;gt; INSERT INTO users VALUES (2, 'bob');
turso&amp;gt; SELECT * FROM users;
1|alice
2|bob
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You can also build and run the latest development version with:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo run
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you like docker, we got you covered. Simply run this in the root folder:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;make docker-cli-build &amp;amp;&amp;amp; \
make docker-cli-run
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ü¶Ä Rust&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;cargo add turso
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-rust"&gt;let db = Builder::new_local("sqlite.db").build().await?;
let conn = db.connect()?;

let res = conn.query("SELECT * FROM users", ()).await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;‚ú® JavaScript&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;npm i @tursodatabase/database
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-js"&gt;import { connect } from '@tursodatabase/database';

const db = await connect('sqlite.db');
const stmt = db.prepare('SELECT * FROM users');
const users = stmt.all();
console.log(users);
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üêç Python&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;uv pip install pyturso
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import turso

con = turso.connect("sqlite.db")
cur = con.cursor()
res = cur.execute("SELECT * FROM users")
print(res.fetchone())
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ü¶´ Go&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;go get github.com/tursodatabase/turso-go
go install github.com/tursodatabase/turso-go
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-go"&gt;import (
    "database/sql"
    _ "github.com/tursodatabase/turso-go"
)

conn, _ = sql.Open("turso", "sqlite.db")
defer conn.Close()

stmt, _ := conn.Prepare("select * from users")
defer stmt.Close()

rows, _ = stmt.Query()
for rows.Next() {
    var id int
    var username string
    _ := rows.Scan(&amp;amp;id, &amp;amp;username)
    fmt.Printf("User: ID: %d, Username: %s\n", id, username)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;‚òïÔ∏è Java&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;We integrated Turso Database into JDBC. For detailed instructions on how to use Turso Database with java, please refer to the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/java/README.md"&gt;README.md under bindings/java&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ü§ñ MCP Server Mode&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;The Turso CLI includes a built-in &lt;a href="https://modelcontextprotocol.io/"&gt;Model Context Protocol (MCP)&lt;/a&gt; server that allows AI assistants to interact with your databases.&lt;/p&gt; 
 &lt;p&gt;Start the MCP server with:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;tursodb your_database.db --mcp
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Configuration&lt;/h3&gt; 
 &lt;p&gt;Add Turso to your MCP client configuration:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "turso": {
      "command": "/path/to/.turso/tursodb",
      "args": ["/path/to/your/database.db", "--mcp"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Available Tools&lt;/h3&gt; 
 &lt;p&gt;The MCP server provides nine tools for database interaction:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;open_database&lt;/code&gt;&lt;/strong&gt; - Open a new database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;current_database&lt;/code&gt;&lt;/strong&gt; - Describe the current database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;list_tables&lt;/code&gt;&lt;/strong&gt; - List all tables in the database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;describe_table&lt;/code&gt;&lt;/strong&gt; - Describe the structure of a specific table&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;execute_query&lt;/code&gt;&lt;/strong&gt; - Execute read-only SELECT queries&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;insert_data&lt;/code&gt;&lt;/strong&gt; - Insert new data into tables&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;update_data&lt;/code&gt;&lt;/strong&gt; - Update existing data in tables&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;delete_data&lt;/code&gt;&lt;/strong&gt; - Delete data from tables&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;schema_change&lt;/code&gt;&lt;/strong&gt; - Execute schema modification statements (CREATE TABLE, ALTER TABLE, DROP TABLE)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Once connected, you can ask your AI assistant:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Show me all tables in the database"&lt;/li&gt; 
  &lt;li&gt;"What's the schema for the users table?"&lt;/li&gt; 
  &lt;li&gt;"Find all posts with more than 100 upvotes"&lt;/li&gt; 
  &lt;li&gt;"Insert a new user with name 'Alice' and email '&lt;a href="mailto:alice@example.com"&gt;alice@example.com&lt;/a&gt;'"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;MCP Clients&lt;/h3&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Claude Code&lt;/summary&gt; 
  &lt;p&gt;If you're using &lt;a href="https://claude.ai/code"&gt;Claude Code&lt;/a&gt;, you can easily connect to your Turso MCP server using the built-in MCP management commands:&lt;/p&gt; 
  &lt;h4&gt;Quick Setup&lt;/h4&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Add the MCP server&lt;/strong&gt; to Claude Code:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add my-database -- tursodb ./path/to/your/database.db --mcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Restart Claude Code&lt;/strong&gt; to activate the connection&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start querying&lt;/strong&gt; your database through natural language!&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;h4&gt;Command Breakdown&lt;/h4&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add my-database -- tursodb ./path/to/your/database.db --mcp
#              ‚Üë            ‚Üë       ‚Üë                           ‚Üë
#              |            |       |                           |
#              Name         |       Database path               MCP flag
#                          Separator
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;my-database&lt;/code&gt;&lt;/strong&gt; - Choose any name for your MCP server&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;--&lt;/code&gt;&lt;/strong&gt; - Required separator between Claude options and your command&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;tursodb&lt;/code&gt;&lt;/strong&gt; - The Turso database CLI&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;./path/to/your/database.db&lt;/code&gt;&lt;/strong&gt; - Path to your SQLite database file&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;--mcp&lt;/code&gt;&lt;/strong&gt; - Enables MCP server mode&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;h4&gt;Example Usage&lt;/h4&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;# For a local project database
cd /your/project
claude mcp add my-project-db -- tursodb ./data/app.db --mcp

# For an absolute path
claude mcp add analytics-db -- tursodb /Users/you/databases/analytics.db --mcp

# For a specific project (local scope)
claude mcp add project-db --local -- tursodb ./database.db --mcp
&lt;/code&gt;&lt;/pre&gt; 
  &lt;h4&gt;Managing MCP Servers&lt;/h4&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;# List all configured MCP servers
claude mcp list

# Get details about a specific server
claude mcp get my-database

# Remove an MCP server
claude mcp remove my-database
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Claude Desktop&lt;/summary&gt; 
  &lt;p&gt;For Claude Desktop, add the configuration to your &lt;code&gt;claude_desktop_config.json&lt;/code&gt; file:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "turso": {
      "command": "/path/to/.turso/tursodb",
      "args": ["./path/to/your/database.db.db", "--mcp"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Cursor&lt;/summary&gt; 
  &lt;p&gt;For Cursor, configure MCP in your settings:&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;Open Cursor settings&lt;/li&gt; 
   &lt;li&gt;Navigate to Extensions ‚Üí MCP&lt;/li&gt; 
   &lt;li&gt;Add a new server with: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Name&lt;/strong&gt;: &lt;code&gt;turso&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Command&lt;/strong&gt;: &lt;code&gt;/path/to/.turso/tursodb&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Args&lt;/strong&gt;: &lt;code&gt;["./path/to/your/database.db.db", "--mcp"]&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;p&gt;Alternatively, you can add it to your Cursor configuration file directly.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;h3&gt;Direct JSON-RPC Usage&lt;/h3&gt; 
 &lt;p&gt;The MCP server runs as a single process that handles multiple JSON-RPC requests over stdin/stdout. Here's how to interact with it directly:&lt;/p&gt; 
 &lt;h4&gt;Example with In-Memory Database&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cat &amp;lt;&amp;lt; 'EOF' | tursodb --mcp
{"jsonrpc": "2.0", "id": 1, "method": "initialize", "params": {"protocolVersion": "2024-11-05", "capabilities": {}, "clientInfo": {"name": "client", "version": "1.0"}}}
{"jsonrpc": "2.0", "id": 2, "method": "tools/call", "params": {"name": "schema_change", "arguments": {"query": "CREATE TABLE users (id INTEGER, name TEXT, email TEXT)"}}}
{"jsonrpc": "2.0", "id": 3, "method": "tools/call", "params": {"name": "list_tables", "arguments": {}}}
{"jsonrpc": "2.0", "id": 4, "method": "tools/call", "params": {"name": "insert_data", "arguments": {"query": "INSERT INTO users VALUES (1, 'Alice', 'alice@example.com')"}}}
{"jsonrpc": "2.0", "id": 5, "method": "tools/call", "params": {"name": "execute_query", "arguments": {"query": "SELECT * FROM users"}}}
EOF
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example with Existing Database&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Working with an existing database file
cat &amp;lt;&amp;lt; 'EOF' | tursodb mydb.db --mcp
{"jsonrpc": "2.0", "id": 1, "method": "initialize", "params": {"protocolVersion": "2024-11-05", "capabilities": {}, "clientInfo": {"name": "client", "version": "1.0"}}}
{"jsonrpc": "2.0", "id": 2, "method": "tools/call", "params": {"name": "list_tables", "arguments": {}}}
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We'd love to have you contribute to Turso Database! Please check out the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Found a data corruption bug? Get up to $1,000.00&lt;/h3&gt; 
&lt;p&gt;SQLite is loved because it is the most reliable database in the world. The next evolution of SQLite has to match or surpass this level of reliability. Turso is built with &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/simulator/"&gt;Deterministic Simulation Testing&lt;/a&gt; from the ground up, and is also tested by &lt;a href="https://antithesis.com"&gt;Antithesis&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Even during Alpha, if you find a bug that leads to a data corruption and demonstrate how our simulator failed to catch it, you can get up to $1,000.00. As the project matures we will increase the size of the prize, and the scope of the bugs.&lt;/p&gt; 
&lt;p&gt;List of rewarded cases:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;B-Tree interior cell replacement issue in btrees with depth &amp;gt;=3 (&lt;a href="https://github.com/tursodatabase/turso/issues/2106"&gt;#2106&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Don't allow autovacuum to be flipped on non-empty databases (&lt;a href="https://github.com/tursodatabase/turso/pull/3830"&gt;#3830&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More details &lt;a href="https://turso.algora.io"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Turso core staff are not eligible.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Is Turso Database ready for production use?&lt;/h3&gt; 
&lt;p&gt;Turso Database is currently under heavy development and is &lt;strong&gt;not&lt;/strong&gt; ready for production use.&lt;/p&gt; 
&lt;h3&gt;How is Turso Database different from Turso's libSQL?&lt;/h3&gt; 
&lt;p&gt;Turso Database is a project to build the next evolution of SQLite in Rust, with a strong open contribution focus and features like native async support, vector search, and more. The libSQL project is also an attempt to evolve SQLite in a similar direction, but through a fork rather than a rewrite.&lt;/p&gt; 
&lt;p&gt;Rewriting SQLite in Rust started as an unassuming experiment, and due to its incredible success, replaces libSQL as our intended direction. At this point, libSQL is production ready, Turso Database is not - although it is evolving rapidly. More details &lt;a href="https://turso.tech/blog/we-will-rewrite-sqlite-and-we-are-going-all-in"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Publications&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pekka Enberg, Sasu Tarkoma, Jon Crowcroft Ashwin Rao (2024). Serverless Runtime / Database Co-Design With Asynchronous I/O. In &lt;em&gt;EdgeSys ‚Äò24&lt;/em&gt;. &lt;a href="https://penberg.org/papers/penberg-edgesys24.pdf"&gt;[PDF]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Pekka Enberg, Sasu Tarkoma, and Ashwin Rao (2023). Towards Database and Serverless Runtime Co-Design. In &lt;em&gt;CoNEXT-SW ‚Äô23&lt;/em&gt;. [&lt;a href="https://penberg.org/papers/penberg-conext-sw-23.pdf"&gt;PDF&lt;/a&gt;] [&lt;a href="https://penberg.org/papers/penberg-conext-sw-23-slides.pdf"&gt;Slides&lt;/a&gt;]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/LICENSE.md"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contribution&lt;/h3&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Turso Database by you, shall be licensed as MIT, without any additional terms or conditions.&lt;/p&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;p&gt;Thanks to all the partners of Turso!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://antithesis.com/"&gt;&lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/antithesis.jpg" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://blacksmith.sh"&gt;&lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/blacksmith.svg?sanitize=true" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://nyrkio.com/"&gt;&lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/turso-nyrkio.png" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to all the contributors to Turso Database!&lt;/p&gt; 
&lt;a href="https://github.com/tursodatabase/turso/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=tursodatabase/turso" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>davidlattimore/wild</title>
      <link>https://github.com/davidlattimore/wild</link>
      <description>&lt;p&gt;A very fast linker for Linux&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Wild linker&lt;/h1&gt; 
&lt;p&gt;Wild is a linker with the goal of being very fast for iterative development.&lt;/p&gt; 
&lt;p&gt;The plan is to eventually make it incremental, however that isn't yet implemented. It is however already pretty fast even without incremental linking.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;From GitHub releases&lt;/h3&gt; 
&lt;p&gt;Download a tarball from the &lt;a href="https://github.com/davidlattimore/wild/releases"&gt;releases page&lt;/a&gt;. Unpack it and copy the &lt;code&gt;wild&lt;/code&gt; binary somewhere on your path.&lt;/p&gt; 
&lt;h3&gt;Cargo binstall&lt;/h3&gt; 
&lt;p&gt;If you have &lt;a href="https://github.com/cargo-bins/cargo-binstall"&gt;cargo-binstall&lt;/a&gt;, you can install wild as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo binstall wild-linker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build latest release from crates.io&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo install --locked wild-linker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build from git head&lt;/h3&gt; 
&lt;p&gt;To build and install the latest, unreleased code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo install --locked --bin wild --git https://github.com/davidlattimore/wild.git wild-linker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Nix&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/davidlattimore/wild/main/nix/nix.md"&gt;nix/nix.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Using as your default linker&lt;/h2&gt; 
&lt;p&gt;If you'd like to use Wild as your default linker for building Rust code, you can put the following in &lt;code&gt;~/.cargo/config.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;On Linux:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[target.x86_64-unknown-linux-gnu]
linker = "clang"
rustflags = ["-C", "link-arg=--ld-path=wild"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Illumos:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[target.x86_64-unknown-illumos]
# Absolute path to clang - on OmniOS this is likely something like /opt/ooce/bin/clang.
linker = "/usr/bin/clang"

rustflags = [
    # Will silently delegate to GNU ld or Sun ld unless the absolute path to Wild is provided.
    "-C", "link-arg=-fuse-ld=/absolute/path/to/wild"
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using wild in CI&lt;/h2&gt; 
&lt;p&gt;If you'd like to use Wild as your linker for Rust code in CI, see &lt;a href="https://github.com/davidlattimore/wild-action"&gt;wild-action&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Q&amp;amp;A&lt;/h2&gt; 
&lt;h3&gt;Why another linker?&lt;/h3&gt; 
&lt;p&gt;Mold is already very fast, however it doesn't do incremental linking and the author has stated that they don't intend to. Wild doesn't do incremental linking yet, but that is the end-goal. By writing Wild in Rust, it's hoped that the complexity of incremental linking will be achievable.&lt;/p&gt; 
&lt;h3&gt;What's working?&lt;/h3&gt; 
&lt;p&gt;The following platforms / architectures are currently supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;x86-64 on Linux&lt;/li&gt; 
 &lt;li&gt;ARM64 on Linux&lt;/li&gt; 
 &lt;li&gt;RISC-V (riscv64gc) on Linux (initial support: &lt;a href="https://github.com/davidlattimore/wild/issues/678"&gt;#678&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following is working with the caveat that there may be bugs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Output to statically linked, non-relocatable binaries&lt;/li&gt; 
 &lt;li&gt;Output to statically linked, position-independent binaries (static-PIE)&lt;/li&gt; 
 &lt;li&gt;Output to dynamically linked binaries&lt;/li&gt; 
 &lt;li&gt;Output to shared objects (.so files)&lt;/li&gt; 
 &lt;li&gt;Rust proc-macros, when linked with Wild work&lt;/li&gt; 
 &lt;li&gt;Most of the top downloaded crates on crates.io have been tested with Wild and pass their tests&lt;/li&gt; 
 &lt;li&gt;Debug info&lt;/li&gt; 
 &lt;li&gt;GNU jobserver support&lt;/li&gt; 
 &lt;li&gt;Very basic linker script support (section mapping, keeping sections, alignment, defining start / stop symbols).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What isn't yet supported?&lt;/h3&gt; 
&lt;p&gt;Lots of stuff. Here are some of the larger things that aren't yet done, roughly sorted by current priority:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Incremental linking&lt;/li&gt; 
 &lt;li&gt;Support for more architectures&lt;/li&gt; 
 &lt;li&gt;Support for a wider range of linker flags&lt;/li&gt; 
 &lt;li&gt;More complex linker scripts&lt;/li&gt; 
 &lt;li&gt;Mac support&lt;/li&gt; 
 &lt;li&gt;Windows support&lt;/li&gt; 
 &lt;li&gt;LTO&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How can I verify that Wild was used to link a binary?&lt;/h3&gt; 
&lt;p&gt;Install &lt;code&gt;readelf&lt;/code&gt;, then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;readelf  -p .comment my-executable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Look for a line like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Linker: Wild version 0.1.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or if you don't want to install readelf, you can probably get away with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;strings my-executable | grep 'Linker:'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Where did the name come from?&lt;/h3&gt; 
&lt;p&gt;It's somewhat of a tradition for linkers to end with the letters "ld". e.g. "GNU ld, "gold", "lld", "mold". Since the end-goal is for the linker to be incremental, an "I" is added. Let's say the "W" stands for "Wild", since recursive acronyms are popular in open-source projects.&lt;/p&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;The goal of Wild is to eventually be very fast via incremental linking. However, we also want to be as fast as we can be for non-incremental linking and for the initial link when incremental linking is enabled.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/davidlattimore/wild/main/BENCHMARKING.md"&gt;BENCHMARKING.md&lt;/a&gt; for more details on running benchmarks.&lt;/p&gt; 
&lt;p&gt;All benchmarks are run with output to a tmpfs.&lt;/p&gt; 
&lt;p&gt;Wild currently doesn't perform great beyond 8 threads. This is something we've been investigating and hope to improve soon.&lt;/p&gt; 
&lt;h3&gt;X86_64&lt;/h3&gt; 
&lt;p&gt;X86_64 benchmarks were run on David Lattimore's laptop (2020 model System76 Lemur pro), which has 4 cores (8 threads) and 42 GB of RAM.&lt;/p&gt; 
&lt;p&gt;Binaries used are official release builds from each project.&lt;/p&gt; 
&lt;p&gt;First a benchmark is linking a smallish binary, the wild linker itself.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/davidlattimore/wild/main/images/benchmarks/wild.svg?sanitize=true" alt="Benchmark of lld, mold and wild linking wild" /&gt;&lt;/p&gt; 
&lt;p&gt;Next, we link librustc-driver, which is a shared object and is where most of the code in the rust compiler ends up.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/davidlattimore/wild/main/images/benchmarks/librustc-driver.svg?sanitize=true" alt="Benchmark of lld, mold and wild linking librustc-driver" /&gt;&lt;/p&gt; 
&lt;p&gt;Finally, for an especially large binary, we link the chromium web browser with debug info.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/davidlattimore/wild/main/images/benchmarks/chromium.svg?sanitize=true" alt="Benchmark of lld, mold and wild linking chromium" /&gt;&lt;/p&gt; 
&lt;h3&gt;Aarch64&lt;/h3&gt; 
&lt;p&gt;Aarch64 benchmarks were run on RaspberryPi5 with 8 GiB of RAM. Binaries used are official release binaries from each project.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/davidlattimore/wild/main/images/benchmarks/rpi-wild-no-debug.svg?sanitize=true" alt="Benchmark of lld, mold and wild linking wild without debug info on a RaspberryPi5" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/davidlattimore/wild/main/images/benchmarks/rpi-wild-debug.svg?sanitize=true" alt="Benchmark of lld, mold and wild linking wild with debug info on a RaspberryPi5" /&gt;&lt;/p&gt; 
&lt;h3&gt;RISC-V 64&lt;/h3&gt; 
&lt;p&gt;RISC-V benchmarks were run on a VisionFive2 with 8 GiB of RAM running Ubuntu 24.04.&lt;/p&gt; 
&lt;p&gt;Neither wild nor lld have official release binaries for RISC-V. For wild, the binary was just a locally built release binary. For lld, the version that comes with Ubuntu was used. Mold does have an official release binary for RISC-V, so that was used.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/davidlattimore/wild/main/images/benchmarks/risc-v-64-wild-debug.svg?sanitize=true" alt="Benchmark of lld, mold and wild linking wild with debug info on a VF2" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/davidlattimore/wild/main/images/benchmarks/risc-v-64-wild-non-debug.svg?sanitize=true" alt="Benchmark of lld, mold and wild linking wild with --strip-debug info on a VF2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Linking Rust code&lt;/h2&gt; 
&lt;p&gt;The following is a &lt;code&gt;cargo test&lt;/code&gt; command-line that can be used to build and test a crate using Wild. This has been run successfully on a few popular crates (e.g. ripgrep, serde, tokio, rand, bitflags). It assumes that the "wild" binary is on your path. It also depends on the Clang compiler being installed, since GCC doesn't allow using an arbitrary linker.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;RUSTFLAGS="-Clinker=clang -Clink-args=--ld-path=wild" cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;For more information on contributing to &lt;code&gt;wild&lt;/code&gt; see &lt;a href="https://raw.githubusercontent.com/davidlattimore/wild/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For a high-level overview of Wild's design, see &lt;a href="https://raw.githubusercontent.com/davidlattimore/wild/main/DESIGN.md"&gt;DESIGN.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Chat server&lt;/h2&gt; 
&lt;p&gt;We have a Zulip server for Wild-related chat. You can join &lt;a href="https://wild.zulipchat.com/join/bbopdeg6howwjpaiyowngyde/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Further reading&lt;/h2&gt; 
&lt;p&gt;Many of the posts on &lt;a href="https://davidlattimore.github.io/"&gt;David's blog&lt;/a&gt; are about various aspects of the Wild linker.&lt;/p&gt; 
&lt;h2&gt;Sponsorship&lt;/h2&gt; 
&lt;p&gt;If you'd like to &lt;a href="https://github.com/sponsors/davidlattimore"&gt;sponsor this work&lt;/a&gt;, that would be very much appreciated. The more sponsorship I get the longer I can continue to work on this project full time.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under either of &lt;a href="https://raw.githubusercontent.com/davidlattimore/wild/main/LICENSE-APACHE"&gt;Apache License, Version 2.0&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/davidlattimore/wild/main/LICENSE-MIT"&gt;MIT license&lt;/a&gt; at your option.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Wild by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pythops/bluetui</title>
      <link>https://github.com/pythops/bluetui</link>
      <description>&lt;p&gt;üõú TUI for managing bluetooth on Linux&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img height="125" src="https://raw.githubusercontent.com/pythops/bluetui/master/assets/bluetui-logo-anim.svg?sanitize=true" /&gt; 
 &lt;h2&gt; TUI for managing bluetooth on Linux &lt;/h2&gt; 
 &lt;img src="https://github.com/user-attachments/assets/f937535d-5675-4427-b347-8086c8830e23" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;üí° Prerequisites&lt;/h2&gt; 
&lt;p&gt;A Linux based OS with &lt;a href="https://www.bluez.org/"&gt;bluez&lt;/a&gt; installed.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You might need to install &lt;a href="https://www.nerdfonts.com/"&gt;nerdfonts&lt;/a&gt; for the icons to be displayed correctly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üöÄ Installation&lt;/h2&gt; 
&lt;h3&gt;üì• Binary release&lt;/h3&gt; 
&lt;p&gt;You can download the pre-built binaries from the release page &lt;a href="https://github.com/pythops/bluetui/releases"&gt;release page&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üì¶ crates.io&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from &lt;a href="https://crates.io/crates/bluetui"&gt;crates.io&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install bluetui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üêß Arch Linux&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the &lt;a href="https://archlinux.org/packages/extra/x86_64/bluetui/"&gt;extra repository&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pacman -S bluetui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üêß Gentoo&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the &lt;a href="https://gpo.zugaina.org/net-wireless/bluetui"&gt;lamdness Gentoo Overlay&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo eselect repository enable lamdness
sudo emaint -r lamdness sync
sudo emerge -av net-wireless/bluetui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üß∞ X-CMD&lt;/h3&gt; 
&lt;p&gt;If you are a user of &lt;a href="https://x-cmd.com"&gt;x-cmd&lt;/a&gt;, you can run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;x install bluetui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚öíÔ∏è Build from source&lt;/h3&gt; 
&lt;p&gt;Run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/pythops/bluetui
cd bluetui
cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will produce an executable file at &lt;code&gt;target/release/bluetui&lt;/code&gt; that you can copy to a directory in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;ü™Ñ Usage&lt;/h2&gt; 
&lt;h3&gt;Global&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Tab&lt;/code&gt; or &lt;code&gt;l&lt;/code&gt;: Scroll down between different sections.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;shift+Tab&lt;/code&gt; or &lt;code&gt;h&lt;/code&gt;: Scroll up between different sections.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;j&lt;/code&gt; or &lt;code&gt;Down&lt;/code&gt; : Scroll down.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;k&lt;/code&gt; or &lt;code&gt;Up&lt;/code&gt;: Scroll up.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;s&lt;/code&gt;: Start/Stop scanning.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ctrl+c&lt;/code&gt; or &lt;code&gt;q&lt;/code&gt;: Quit the app.&lt;/p&gt; 
&lt;h3&gt;Adapters&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;p&lt;/code&gt;: Enable/Disable the pairing.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;o&lt;/code&gt;: Power on/off the adapter.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;d&lt;/code&gt;: Enable/Disable the discovery.&lt;/p&gt; 
&lt;h3&gt;Paired devices&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;u&lt;/code&gt;: Unpair the device.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Connect/Disconnect the device.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;t&lt;/code&gt;: Trust/Untrust the device.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;e&lt;/code&gt;: Rename the device.&lt;/p&gt; 
&lt;h3&gt;New devices&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Pair the device.&lt;/p&gt; 
&lt;h2&gt;Custom keybindings&lt;/h2&gt; 
&lt;p&gt;Keybindings can be customized in the default config file location &lt;code&gt;$HOME/.config/bluetui/config.toml&lt;/code&gt; or from a custom path with &lt;code&gt;-c&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# Possible values: "Legacy", "Start", "End", "Center", "SpaceAround", "SpaceBetween"
layout = "SpaceAround"

# Window width
# Possible values: "auto" or a positive integer
width = "auto"

toggle_scanning = "s"

[adapter]
toggle_pairing = "p"
toggle_power = "o"
toggle_discovery = "d"

[paired_device]
unpair = "u"
toggle_trust = "t"
rename = "e"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üéÅ Note&lt;/h2&gt; 
&lt;p&gt;If you like &lt;code&gt;bluetui&lt;/code&gt; and you are looking for a TUI to manage WiFi, checkout out &lt;a href="https://github.com/pythops/impala"&gt;impala&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; 
&lt;p&gt;GPLv3&lt;/p&gt; 
&lt;h2&gt;‚úçÔ∏è Credits&lt;/h2&gt; 
&lt;p&gt;Bluetui logo: &lt;a href="https://github.com/Bugg4"&gt;Marco Bulgarelli&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>bee-san/RustScan</title>
      <link>https://github.com/bee-san/RustScan</link>
      <description>&lt;p&gt;ü§ñ The Modern Port Scanner ü§ñ&lt;/p&gt;&lt;hr&gt;&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;‚û°Ô∏è &lt;a href="http://discord.skerritt.blog" title="Discord blog"&gt;Discord&lt;/a&gt; | &lt;a href="https://github.com/RustScan/RustScan/wiki/Installation-Guide" title="Installation Guide Wiki"&gt;Installation Guide&lt;/a&gt; | &lt;a href="https://github.com/RustScan/RustScan#-usage"&gt;Usage Guide&lt;/a&gt; ‚¨ÖÔ∏è&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/bee-san/RustScan/master/pictures/rustscan.png" height="400px" width="400px" /&gt; 
 &lt;!--&lt;u&gt;**The Modern Port Scanner.**&lt;/u&gt;--&gt; 
 &lt;p&gt;&lt;strong&gt;Fast, smart, effective.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/archlinux/v/extra/x86_64/rustscan?style=plastic&amp;amp;logo=archlinux&amp;amp;link=https%3A%2F%2Farchlinux.org%2Fpackages%2Fextra%2Fx86_64%2Frustscan%2F" alt="Arch Linux package" /&gt; &lt;img src="https://img.shields.io/badge/Built%20with-Rust-Purple" alt="Built with Rust" /&gt; &lt;img src="https://img.shields.io/github/downloads/rustscan/rustscan/total?label=GitHub%20Downloads" alt="GitHub All Releases" /&gt; &lt;img src="https://img.shields.io/crates/d/rustscan?label=Cargo%20Downloads" alt="Crates.io" /&gt; &lt;img src="https://img.shields.io/discord/754001738184392704" alt="Discord" /&gt; &lt;img src="https://github.com/RustScan/RustScan/actions/workflows/build.yml/badge.svg?branch=master" alt="Actions" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;ü§î What is this?&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/bee-san/RustScan/master/pictures/fast.gif" alt="fast" title="Speed" /&gt;&lt;/p&gt; 
&lt;p&gt;The Modern Port Scanner. &lt;strong&gt;Find ports quickly (3 seconds at its fastest)&lt;/strong&gt;. Run scripts through our scripting engine (Python, Lua, Shell supported).&lt;/p&gt; 
&lt;h1&gt;üõ†Ô∏è Installation&lt;/h1&gt; 
&lt;p&gt;You can install RustScan's binary from our &lt;a href="https://github.com/RustScan/RustScan/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We would prefer you to install with a package manager so it is tested and works for your system.&lt;/p&gt; 
&lt;p&gt;RustScan is in many repositories already. Install it with whatever tools you wish:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/rustscan/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/rustscan.svg?sanitize=true" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;RustScan only officially supports Cargo installations, if you want to use that please install Rust and then &lt;code&gt;cargo install rustscan&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Example installations include:&lt;/p&gt; 
&lt;p&gt;MacOS:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  brew install rustscan
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Arch:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  yay rustscan
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;‚ú® Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scans all 65k ports in &lt;strong&gt;3 seconds&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Full scripting engine support. Automatically pipe results into Nmap, or use our scripts (or write your own) to do whatever you want.&lt;/li&gt; 
 &lt;li&gt;Adaptive learning. RustScan improves the more you use it. No bloated machine learning here, just basic maths.&lt;/li&gt; 
 &lt;li&gt;The usuals you would expect. IPv6, CIDR, file input and more.&lt;/li&gt; 
 &lt;li&gt;Automatically pipes ports into Nmap.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ÄºÔ∏è Important Links&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;!--Installation Guide--&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;!--Documentation--&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;!--Discord--&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://github.com/RustScan/RustScan#-full-installation-guide" title="Full installation guide"&gt;Installation Guide&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;üìö&lt;/span&gt; &lt;a href="https://github.com/bee-san/RustScan/wiki" title="Rustscan"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;ü¶ú&lt;/span&gt; &lt;a href="http://discord.skerritt.blog" title="Discord blog"&gt;Discord&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üôã Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;a href="https://github.com/RustScan/RustScan/wiki/Installation-Guide" title="Installation Guide Wiki"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üêã &lt;a href="https://github.com/RustScan/RustScan/wiki/Installation-Guide#docker-" title="Docker Installation Guide Wiki"&gt;Docker Usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü¶ú &lt;a href="http://discord.skerritt.blog" title="Discord blog"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü§∏ &lt;a href="https://github.com/RustScan/RustScan/wiki/Usage" title="Basic Usage of Rustscan"&gt;Usage&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üî≠ Why RustScan?&lt;/h1&gt; 
&lt;p&gt;RustScan is a modern take on the port scanner. Sleek &amp;amp; fast. All while providing extensive extendability to you.&lt;/p&gt; 
&lt;p&gt;Not to mention RustScan uses Adaptive Learning to improve itself over time, making it the best port scanner for &lt;strong&gt;you&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;üßã Speed&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/bee-san/RustScan/master/pictures/fast.gif" alt="fast" title="Speed" /&gt;&lt;/p&gt; 
&lt;p&gt;Speed is guaranteed via RustScan. However, if you want to run a slow scan due to stealth, that is possible too.&lt;/p&gt; 
&lt;p&gt;Firstly, let's talk code.&lt;/p&gt; 
&lt;p&gt;We have tests that check to see if RustScan is significantly slower than the previous version. If it is, the continuous integration fails, and we can't commit code to master unless we make it faster.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sharkdp/hyperfine" title="Hyperfine"&gt;HyperFine&lt;/a&gt; is used to monitor RustScan's performance over time to answer the question, "Are we getting faster? Are we getting slower?".&lt;/p&gt; 
&lt;p&gt;Every pull request is reviewed by &lt;strong&gt;one&lt;/strong&gt; person, but more often than not, &lt;strong&gt;two&lt;/strong&gt; people review it. We test it manually and ensure the code doesn't negatively affect performance.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/RustScan/RustScan/wiki/Increasing-Speed-&amp;amp;-Accuracy" title="Increasing Speed &amp;amp; Accuracy"&gt;Read more here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è Extensible&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/bee-san/RustScan/master/pictures/scripts.gif" alt="scripts" title="Scripts" /&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;em&gt;RustScan piping results into the custom Python script&lt;/em&gt;&lt;/h3&gt; 
&lt;p&gt;RustScan has a new scripting engine that allows anyone to write scripts in most languages. Python, Lua, and Shell are all supported.&lt;/p&gt; 
&lt;p&gt;Want to take your found ports and pipe them into Nmap for further analysis? That's possible. Want to run &lt;code&gt;smb-enum&lt;/code&gt; if SMB is found open? Possible.&lt;/p&gt; 
&lt;p&gt;The possibilities are endless -- and you can write scripts in whatever language you feel comfortable with.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/RustScan/RustScan/wiki/RustScan-Scripting-Engine" title="Scripting Engine"&gt;Read more here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üåä Adaptive&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/bee-san/RustScan/master/pictures/adaptive.gif" alt="adaptive" title="Adaptive" /&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;em&gt;RustScan automatically fine-tunes itself to match the host OS&lt;/em&gt;&lt;/h3&gt; 
&lt;p&gt;RustScan has a cool set of features called "Adaptive Learning". These features "learn" about the environment you are scanning and how &lt;em&gt;you&lt;/em&gt; use RustScan to &lt;strong&gt;improve itself over time&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;We use this umbrella term for any feature that fits this criterion. The list constantly changes, so &lt;a href="https://github.com/RustScan/RustScan/wiki/Adaptive-Learning" title="Adaptive Learning"&gt;check out our wiki for more information&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üë©‚Äçü¶Ø Accessible&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/bee-san/RustScan/master/pictures/accessible.gif" alt="fast" title="Fast" /&gt;&lt;/p&gt; 
&lt;p&gt;RustScan is one of the first penetration testing tools that aims to be entirely accessible.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://bees.substack.com/p/making-hacking-accessible" title="Making Hacking Accessible"&gt;Most penetration testing tools are not accessible&lt;/a&gt;, which negatively affects the whole industry.&lt;/p&gt; 
&lt;p&gt;RustScan has continuous integration testing that aims to ensure it is accessible, and we are constantly working on ways to improve our accessibility and ensure &lt;em&gt;everyone&lt;/em&gt; can use RustScan.&lt;/p&gt; 
&lt;h1&gt;ü§∏ Usage&lt;/h1&gt; 
&lt;p&gt;We have 2 usage guides. &lt;a href="https://github.com/RustScan/RustScan/wiki/Usage" title="Basic Usage of Rustscan"&gt;Basic Usage&lt;/a&gt; and &lt;a href="https://github.com/RustScan/RustScan/wiki/Things-you-may-want-to-do-with-RustScan-but-don't-understand-how" title="Things you may want to do with rustscan but don't know how"&gt;Things you may want to do&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We also have documentation about our config file &lt;a href="https://github.com/RustScan/RustScan/wiki/Config-File" title="RustScan Configuration File"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;üé™ Community&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/RustScan/RustScan/wiki/Contributing" title="Learn how to contribute"&gt;Contributing&lt;/a&gt; Read this to learn how.&lt;/p&gt; 
&lt;h2&gt;Contributors ‚ú®&lt;/h2&gt; 
&lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#contributors-"&gt;&lt;img src="https://img.shields.io/badge/all_contributors-26-orange.svg?style=flat-square" alt="All Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-BADGE:END --&gt; 
&lt;p&gt;Thanks goes to these wonderful people (&lt;a href="https://allcontributors.org/docs/en/emoji-key"&gt;emoji key&lt;/a&gt;):&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://skerritt.blog"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/10378052?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bee&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#infra-beeskerritt" title="Infrastructure (Hosting, Build-Tools, etc)"&gt;üöá&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/commits?author=beeskerritt" title="Tests"&gt;‚ö†Ô∏è&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/commits?author=beesan" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#design-beeskerritt" title="Design"&gt;üé®&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://sakiir.ovh"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/9950578?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;SakiiR&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=SakiiR" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/issues?q=author%3ASakiiR" title="Bug reports"&gt;üêõ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/smackhack"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/48143394?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;smackhack&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#ideas-smackhack" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#example-smackhack" title="Examples"&gt;üí°&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="http://bernardoamc.github.io/"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/428984?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bernardo Araujo&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=bernardoamc" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/issues?q=author%3Abernardoamc" title="Bug reports"&gt;üêõ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#design-bernardoamc" title="Design"&gt;üé®&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/Isona"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/11759523?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Izzy Whistlecroft&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/issues?q=author%3AIsona" title="Bug reports"&gt;üêõ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://imlonghao.com"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/4951333?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;imlonghao&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/issues?q=author%3Aimlonghao" title="Bug reports"&gt;üêõ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#maintenance-imlonghao" title="Maintenance"&gt;üöß&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/royharoush"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/8113056?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;royharoush&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#ideas-royharoush" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#design-royharoush" title="Design"&gt;üé®&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/Atul9"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/3390330?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Atul Bhosale&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=Atul9" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://tgotwig.dev"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/30773779?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Thomas Gotwig&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#platform-TGotwig" title="Packaging/porting to new platform"&gt;üì¶&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/remigourdon"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/2874133?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;R√©mi Gourdon&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=remigourdon" title="Documentation"&gt;üìñ&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/commits?author=remigourdon" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://cmnatic.co.uk"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/4163116?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ben (CMNatic)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=cmnatic" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/commits?author=cmnatic" title="Documentation"&gt;üìñ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#design-cmnatic" title="Design"&gt;üé®&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/Ferryistaken"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/47927670?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alessandro Ferrari&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#content-Ferryistaken" title="Content"&gt;üñã&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/Phenomite"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/8285537?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Phenomite&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#content-Phenomite" title="Content"&gt;üñã&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://supersandro.de/"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/7258858?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sandro&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#content-SuperSandro2000" title="Content"&gt;üñã&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/issues?q=author%3ASuperSandro2000" title="Bug reports"&gt;üêõ&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/commits?author=SuperSandro2000" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://swag.lgbt"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/25358963?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Cass&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#platform-caass" title="Packaging/porting to new platform"&gt;üì¶&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/commits?author=caass" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/issues?q=author%3Acaass" title="Bug reports"&gt;üêõ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/niklasmohrin"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/47574893?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Niklas Mohrin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=niklasmohrin" title="Documentation"&gt;üìñ&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/commits?author=niklasmohrin" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/issues?q=author%3Aniklasmohrin" title="Bug reports"&gt;üêõ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://liberapay.com/Artem4/"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/5614476?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Artem Polishchuk&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#platform-tim77" title="Packaging/porting to new platform"&gt;üì¶&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/buermarc"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/44375277?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;buermarc&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=buermarc" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/bergabman"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/44554109?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;bergabman&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=bergabman" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/issues?q=author%3Abergabman" title="Bug reports"&gt;üêõ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#design-bergabman" title="Design"&gt;üé®&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/dmitris"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/31205?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dmitry Savintsev&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=dmitris" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/bofh69"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/1444315?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sebastian Andersson&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=bofh69" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/mattcorbin"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/6537765?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matt Corbin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=mattcorbin" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="http://rootsploit.com"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/67270834?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;RootSploit&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/bee-san/RustScan/master/#blog-rootsploit" title="Blogposts"&gt;üìù&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/eiffel-fl"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/12171754?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;eiffel-fl&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=eiffel-fl" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/u5surf"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/14180225?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Y.Horie&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=u5surf" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/okrplay"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/32576280?v=4" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Oskar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/RustScan/RustScan/commits?author=okrplay" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/RustScan/RustScan/commits?author=okrplay" title="Tests"&gt;‚ö†Ô∏è&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;!-- markdownlint-enable --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;p&gt;This project follows the &lt;a href="https://github.com/all-contributors/all-contributors"&gt;all-contributors&lt;/a&gt; specification. Contributions of any kind welcome!&lt;/p&gt; 
&lt;!--Links--&gt; 
&lt;!--Pictures--&gt;</description>
    </item>
    
    <item>
      <title>facebook/pyrefly</title>
      <link>https://github.com/facebook/pyrefly</link>
      <description>&lt;p&gt;A fast type checker and language server for Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pyrefly: A fast type checker and language server for Python with powerful IDE features&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/facebook/pyrefly"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://pyrefly.org/badge.json" alt="pyrefly" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/pyrefly"&gt;&lt;img src="https://img.shields.io/pypi/v/pyrefly.svg?color=blue" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Cf7mFQtW7W"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Pyrefly is a type checker and language server for Python, which provides lightning-fast type checking along with IDE features such as code navigation, semantic highlighting, and code completion. It is available as a &lt;a href="https://pyrefly.org/en/docs/installation/"&gt;command-line tool&lt;/a&gt; and a &lt;a href="https://marketplace.visualstudio.com/items?itemName=meta.pyrefly"&gt;VSCode extension&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://pyrefly.org"&gt;Pyrefly website&lt;/a&gt; for full documentation and how to add Pyrefly to your editor of choice.&lt;/p&gt; 
&lt;p&gt;Currently under active development with known issues. Please open an issue if you find bugs.&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try out pyrefly in your browser: &lt;a href="https://pyrefly.org/sandbox/"&gt;Sandbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Get the command-line tool: &lt;code&gt;pip install pyrefly&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Get the VSCode extension: &lt;a href="https://marketplace.visualstudio.com/items?itemName=meta.pyrefly"&gt;Link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Features:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Type Inference: Pyrefly infers types in most locations, apart from function parameters. It can infer types of variables and return types.&lt;/li&gt; 
 &lt;li&gt;Flow Types: Pyrefly can understand your program's control flow to refine static types.&lt;/li&gt; 
 &lt;li&gt;Incrementality: Pyrefly aims for large-scale incrementality at the module level, with optimized checking and parallelism.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Involved&lt;/h2&gt; 
&lt;p&gt;If you have questions or would like to report a bug, please &lt;a href="https://github.com/facebook/pyrefly/issues"&gt;create an issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See our &lt;a href="https://github.com/facebook/pyrefly/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for information on how to contribute to Pyrefly.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.com/invite/Cf7mFQtW7W"&gt;Discord&lt;/a&gt; to chat about Pyrefly and types. This is also where we hold biweekly office hours.&lt;/p&gt; 
&lt;h2&gt;Choices&lt;/h2&gt; 
&lt;p&gt;There are a number of choices when writing a Python type checker. We are taking inspiration from &lt;a href="https://pyre-check.org/"&gt;Pyre1&lt;/a&gt;, &lt;a href="https://github.com/microsoft/pyright"&gt;Pyright&lt;/a&gt; and &lt;a href="https://mypy.readthedocs.io/en/stable/"&gt;MyPy&lt;/a&gt;. Some notable choices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We infer types in most locations, apart from parameters to functions. We do infer types of variables and return types. As an example, &lt;code&gt;def foo(x): return True&lt;/code&gt; would result in something equivalent to had you written &lt;code&gt;def foo(x: Any) -&amp;gt; bool: ...&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;We attempt to infer the type of &lt;code&gt;[]&lt;/code&gt; to however it is used first, then fix it after. For example &lt;code&gt;xs = []; xs.append(1); xs.append("")&lt;/code&gt; will infer that &lt;code&gt;xs: List[int]&lt;/code&gt; and then error on the final statement.&lt;/li&gt; 
 &lt;li&gt;We use flow types which refine static types, e.g. &lt;code&gt;x: int = 4&lt;/code&gt; will both know that &lt;code&gt;x&lt;/code&gt; has type &lt;code&gt;int&lt;/code&gt;, but also that the immediately next usage of &lt;code&gt;x&lt;/code&gt; will be aware the type is &lt;code&gt;Literal[4]&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;We aim for large-scale incrementality (at the module level) and optimized checking with parallelism, aiming to use the advantages of Rust to keep the code a bit simpler.&lt;/li&gt; 
 &lt;li&gt;We expect large strongly connected components of modules, and do not attempt to take advantage of a DAG-shape in the source code.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Code layout&lt;/h2&gt; 
&lt;p&gt;Pyrefly is split into a number of crates (mostly under &lt;code&gt;crates/&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_util&lt;/code&gt; are general purpose utilities, which have nothing to do with Python or type checking. Examples include IO wrappers, locking, command line helpers etc.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_derive&lt;/code&gt; are proc-macros for deriving traits such as &lt;code&gt;TypeEq&lt;/code&gt; and &lt;code&gt;Visit&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_python&lt;/code&gt; are Python utilities with no type-checking aspects, such as modelling modules or &lt;code&gt;sys.info&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_bundled&lt;/code&gt; are the third-party &lt;a href="https://github.com/python/typeshed"&gt;typeshed stubs&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_config&lt;/code&gt; defines the Pyrefly configuration, along with support for reading Mypy/Pyright configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_types&lt;/code&gt; defines the Pyrefly type along with operations on it.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_wasm&lt;/code&gt; defines the sandbox code that compiles to WASM.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly&lt;/code&gt; itself is the type checker and everything else.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Design&lt;/h2&gt; 
&lt;p&gt;There are many nuances of design that change on a regular basis. But the basic substrate on which the checker is built involves three steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Figure out what each module exports. That requires solving all &lt;code&gt;import *&lt;/code&gt; statements transitively.&lt;/li&gt; 
 &lt;li&gt;For each module in isolation, convert it to bindings, dealing with all statements and scope information (both static and flow).&lt;/li&gt; 
 &lt;li&gt;Solve those bindings, which may require the solutions of bindings in other modules.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If we encounter unknowable information (e.g. recursion) we use &lt;code&gt;Type::Var&lt;/code&gt; to insert placeholders which are filled in later.&lt;/p&gt; 
&lt;p&gt;For each module, we solve the steps sequentially and completely. In particular, we do not try and solve a specific identifier first (like &lt;a href="https://github.com/dotnet/roslyn"&gt;Roslyn&lt;/a&gt; or &lt;a href="https://www.typescriptlang.org/"&gt;TypeScript&lt;/a&gt;), and do not use fine-grained incrementality (like &lt;a href="https://github.com/rust-lang/rust-analyzer"&gt;Rust Analyzer&lt;/a&gt; using &lt;a href="https://github.com/salsa-rs/salsa"&gt;Salsa&lt;/a&gt;). Instead, we aim for raw performance and a simpler module-centric design - there's no need to solve a single binding in isolation if solving all bindings in a module is fast enough.&lt;/p&gt; 
&lt;h3&gt;Example of bindings&lt;/h3&gt; 
&lt;p&gt;Given the program:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;1: x: int = 4
2: print(x)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We might produce the bindings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;define int@0&lt;/code&gt; = &lt;code&gt;from builtins import int&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;define x@1&lt;/code&gt; = &lt;code&gt;4: int@0&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;use x@2&lt;/code&gt; = &lt;code&gt;x@1&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;anon @2&lt;/code&gt; = &lt;code&gt;print(x@2)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export x&lt;/code&gt; = &lt;code&gt;x@2&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Of note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The keys are things like &lt;code&gt;define&lt;/code&gt; (the definition of something), &lt;code&gt;use&lt;/code&gt; (a usage of a thing) and &lt;code&gt;anon&lt;/code&gt; (a statement we need to type check, but don't care about the result of).&lt;/li&gt; 
 &lt;li&gt;In many cases the value of a key refers to other keys.&lt;/li&gt; 
 &lt;li&gt;Some keys are imported from other modules, via &lt;code&gt;export&lt;/code&gt; keys and &lt;code&gt;import&lt;/code&gt; values.&lt;/li&gt; 
 &lt;li&gt;In order to disambiguate identifiers we use the textual position at which they occur (in the example we've used &lt;code&gt;@line&lt;/code&gt;, but in reality it's the byte offset in the file).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Example of &lt;code&gt;Var&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Given the program:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;1: x = 1
2: while test():
3:     x = x
4: print(x)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We end up with the bindings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;x@1&lt;/code&gt; = &lt;code&gt;1&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;x@3&lt;/code&gt; = &lt;code&gt;phi(x@1, x@3)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;x@4&lt;/code&gt; = &lt;code&gt;phi(x@1, x@3)&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The expression &lt;code&gt;phi&lt;/code&gt; is the join point of the two values, e.g. &lt;code&gt;phi(int, str)&lt;/code&gt; would be &lt;code&gt;int | str&lt;/code&gt;. We skip the distinction between &lt;code&gt;define&lt;/code&gt; and &lt;code&gt;use&lt;/code&gt;, since it is not necessary for this example.&lt;/p&gt; 
&lt;p&gt;When solving &lt;code&gt;x@3&lt;/code&gt; we encounter recursion. Operationally:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We start solving &lt;code&gt;x@3&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;That requires us to solve &lt;code&gt;x@1&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;We solve &lt;code&gt;x@1&lt;/code&gt; to be &lt;code&gt;Literal[1]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;We start solving &lt;code&gt;x@3&lt;/code&gt;. But we are currently solving &lt;code&gt;x@3&lt;/code&gt;, so we invent a fresh &lt;code&gt;Var&lt;/code&gt; (let's call it &lt;code&gt;?1&lt;/code&gt;) and return that.&lt;/li&gt; 
 &lt;li&gt;We conclude that &lt;code&gt;x@3&lt;/code&gt; must be &lt;code&gt;Literal[1] | ?1&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Since &lt;code&gt;?1&lt;/code&gt; was introduced by &lt;code&gt;x@3&lt;/code&gt; we record that &lt;code&gt;?1 = Literal[1] | ?1&lt;/code&gt;. We can take the upper reachable bound of that and conclude that &lt;code&gt;?1 = Literal[1]&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;We simplify &lt;code&gt;x@3&lt;/code&gt; to just &lt;code&gt;Literal[1]&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>pola-rs/polars</title>
      <link>https://github.com/pola-rs/polars</link>
      <description>&lt;p&gt;Extremely fast Query Engine for DataFrames, written in Rust&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://pola.rs"&gt; &lt;img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/banner/polars_github_banner.svg?sanitize=true" alt="Polars logo" /&gt; &lt;/a&gt; &lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://crates.io/crates/polars"&gt; &lt;img src="https://img.shields.io/crates/v/polars.svg?sanitize=true" alt="crates.io Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://pypi.org/project/polars/"&gt; &lt;img src="https://img.shields.io/pypi/v/polars.svg?sanitize=true" alt="PyPi Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://www.npmjs.com/package/nodejs-polars"&gt; &lt;img src="https://img.shields.io/npm/v/nodejs-polars.svg?sanitize=true" alt="NPM Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://community.r-multiverse.org/polars"&gt; &lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fcommunity.r-multiverse.org%2Fapi%2Fpackages%2Fpolars&amp;amp;query=%24.Version&amp;amp;label=r-multiverse" alt="R-multiverse Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://doi.org/10.5281/zenodo.7697217"&gt; &lt;img src="https://zenodo.org/badge/DOI/10.5281/zenodo.7697217.svg?sanitize=true" alt="DOI Latest Release" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;b&gt;Documentation&lt;/b&gt;: &lt;a href="https://docs.pola.rs/api/python/stable/reference/index.html"&gt;Python&lt;/a&gt; - &lt;a href="https://docs.rs/polars/latest/polars/"&gt;Rust&lt;/a&gt; - &lt;a href="https://pola-rs.github.io/nodejs-polars/index.html"&gt;Node.js&lt;/a&gt; - &lt;a href="https://pola-rs.github.io/r-polars/index.html"&gt;R&lt;/a&gt; | &lt;b&gt;StackOverflow&lt;/b&gt;: &lt;a href="https://stackoverflow.com/questions/tagged/python-polars"&gt;Python&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/rust-polars"&gt;Rust&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/nodejs-polars"&gt;Node.js&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/r-polars"&gt;R&lt;/a&gt; | &lt;a href="https://docs.pola.rs/"&gt;User guide&lt;/a&gt; | &lt;a href="https://discord.gg/4UfP5cfBE7"&gt;Discord&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Polars: Extremely fast Query Engine for DataFrames, written in Rust&lt;/h2&gt; 
&lt;p&gt;Polars is an analytical query engine written for DataFrames. It is designed to be fast, easy to use and expressive. Key features are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Lazy | Eager execution&lt;/li&gt; 
 &lt;li&gt;Streaming (larger-than-RAM datasets)&lt;/li&gt; 
 &lt;li&gt;Query optimization&lt;/li&gt; 
 &lt;li&gt;Multi-threaded&lt;/li&gt; 
 &lt;li&gt;Written in Rust&lt;/li&gt; 
 &lt;li&gt;SIMD&lt;/li&gt; 
 &lt;li&gt;Powerful expression API&lt;/li&gt; 
 &lt;li&gt;Front end in Python | Rust | NodeJS | R | SQL&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arrow.apache.org/docs/format/Columnar.html"&gt;Apache Arrow Columnar Format&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To learn more, read the &lt;a href="https://docs.pola.rs/"&gt;user guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Performance üöÄüöÄ&lt;/h2&gt; 
&lt;h3&gt;Blazingly fast&lt;/h3&gt; 
&lt;p&gt;Polars is very fast. In fact, it is one of the best performing solutions available. See the &lt;a href="https://www.pola.rs/benchmarks.html"&gt;PDS-H benchmarks&lt;/a&gt; results.&lt;/p&gt; 
&lt;h3&gt;Lightweight&lt;/h3&gt; 
&lt;p&gt;Polars is also very lightweight. It comes with zero required dependencies, and this shows in the import times:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;polars: 70ms&lt;/li&gt; 
 &lt;li&gt;numpy: 104ms&lt;/li&gt; 
 &lt;li&gt;pandas: 520ms&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Handles larger-than-RAM data&lt;/h3&gt; 
&lt;p&gt;If you have data that does not fit into memory, Polars' query engine is able to process your query (or parts of your query) in a streaming fashion. This drastically reduces memory requirements, so you might be able to process your 250GB dataset on your laptop. Collect with &lt;code&gt;collect(engine='streaming')&lt;/code&gt; to run the query streaming.&lt;/p&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;p&gt;Install the latest Polars version with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install polars
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.pola.rs/user-guide/installation/#feature-flags"&gt;User Guide&lt;/a&gt; for more details on optional dependencies&lt;/p&gt; 
&lt;p&gt;To see the current Polars version and a full list of its optional dependencies, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pl.show_versions()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute? Read our &lt;a href="https://docs.pola.rs/development/contributing/"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Managed/Distributed Polars&lt;/h2&gt; 
&lt;p&gt;Do you want a managed solution or scale out to distributed clusters? Consider our &lt;a href="https://cloud.pola.rs/"&gt;offering&lt;/a&gt; and help the project!&lt;/p&gt; 
&lt;h2&gt;Python: compile Polars from source&lt;/h2&gt; 
&lt;p&gt;If you want a bleeding edge release or maximal performance you should compile Polars from source.&lt;/p&gt; 
&lt;p&gt;This can be done by going through the following steps in sequence:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the latest &lt;a href="https://www.rust-lang.org/tools/install"&gt;Rust compiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://maturin.rs/"&gt;maturin&lt;/a&gt;: &lt;code&gt;pip install maturin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cd py-polars&lt;/code&gt; and choose one of the following: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;make build&lt;/code&gt;, slow binary with debug assertions and symbols, fast compile times&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-release&lt;/code&gt;, fast binary without debug assertions, minimal debug symbols, long compile times&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-nodebug-release&lt;/code&gt;, same as build-release but without any debug symbols, slightly faster to compile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-debug-release&lt;/code&gt;, same as build-release but with full debug symbols, slightly slower to compile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-dist-release&lt;/code&gt;, fastest binary, extreme compile times&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;By default the binary is compiled with optimizations turned on for a modern CPU. Specify &lt;code&gt;LTS_CPU=1&lt;/code&gt; with the command if your CPU is older and does not support e.g. AVX2.&lt;/p&gt; 
&lt;p&gt;Note that the Rust crate implementing the Python bindings is called &lt;code&gt;py-polars&lt;/code&gt; to distinguish from the wrapped Rust crate &lt;code&gt;polars&lt;/code&gt; itself. However, both the Python package and the Python module are named &lt;code&gt;polars&lt;/code&gt;, so you can &lt;code&gt;pip install polars&lt;/code&gt; and &lt;code&gt;import polars&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Using custom Rust functions in Python&lt;/h2&gt; 
&lt;p&gt;Extending Polars with UDFs compiled in Rust is easy. We expose PyO3 extensions for &lt;code&gt;DataFrame&lt;/code&gt; and &lt;code&gt;Series&lt;/code&gt; data structures. See more in &lt;a href="https://github.com/pola-rs/polars/tree/main/pyo3-polars"&gt;https://github.com/pola-rs/polars/tree/main/pyo3-polars&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Going big...&lt;/h2&gt; 
&lt;p&gt;Do you expect more than 2^32 (~4.2 billion) rows? Compile Polars with the &lt;code&gt;bigidx&lt;/code&gt; feature flag or, for Python users, install &lt;code&gt;pip install polars[rt64]&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Don't use this unless you hit the row boundary as the default build of Polars is faster and consumes less memory.&lt;/p&gt; 
&lt;h2&gt;Legacy&lt;/h2&gt; 
&lt;p&gt;Do you want Polars to run on an old CPU (e.g. dating from before 2011), or on an &lt;code&gt;x86-64&lt;/code&gt; build of Python on Apple Silicon under Rosetta? Install &lt;code&gt;pip install polars[rtcompat]&lt;/code&gt;. This version of Polars is compiled without &lt;a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions"&gt;AVX&lt;/a&gt; target features.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HelixDB/helix-db</title>
      <link>https://github.com/HelixDB/helix-db</link>
      <description>&lt;p&gt;HelixDB is an open-source graph-vector database built from scratch in Rust.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/HelixDB/helix-db/main/assets/full_logo.png" alt="HelixDB Logo" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;&lt;b&gt;HelixDB&lt;/b&gt;: an open-source graph-vector database built from scratch in Rust.&lt;/p&gt; 
 &lt;h3&gt; &lt;a href="https://helix-db.com"&gt;Website&lt;/a&gt; | &lt;a href="https://docs.helix-db.com"&gt;Docs&lt;/a&gt; | &lt;a href="https://discord.gg/2stgMPr5BD"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/hlx_db"&gt;X/Twitter&lt;/a&gt; &lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://docs.helix-db.com"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://docs.helix-db.com/change-log/helixdb"&gt;&lt;img src="https://img.shields.io/badge/changelog-latest-blue" alt="Change Log" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HelixDB/helix-db/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HelixDB/helix-db" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/2stgMPr5BD"&gt;&lt;img src="https://img.shields.io/discord/1354148209005559819?logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HelixDB/helix-db"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://ghloc.vercel.app/api/HelixDB/helix-db/badge?filter=.rs$,.sh$&amp;amp;style=flat&amp;amp;logoColor=white&amp;amp;label=Lines%20of%20Code" alt="LOC" /&gt;&lt;/a&gt; &lt;a href="https://getmanta.ai/helixdb"&gt;&lt;img src="https://getmanta.ai/api/badges?text=Manta%20Graph&amp;amp;link=helixdb" alt="Manta Graph" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.ycombinator.com/launches/Naz-helixdb-the-database-for-rag-ai" target="_blank"&gt;&lt;img src="https://www.ycombinator.com/launches/Naz-helixdb-the-database-for-rag-ai/upvote_embed.svg?sanitize=true" alt="Launch YC: HelixDB - The Database for Intelligence" style="margin-left: 12px;" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;HelixDB is a database that makes it easy to build all the components needed for an AI application in a single platform.&lt;/p&gt; 
&lt;p&gt;You no longer need a separate application DB, vector DB, graph DB, or application layers to manage the multiple storage locations to build the backend of any application that uses AI, agents or RAG. Just use Helix.&lt;/p&gt; 
&lt;p&gt;HelixDB primarily operates with a graph + vector data model, but it can also support KV, documents, and relational data.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Built-in MCP tools&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Helix has built-in MCP support to allow your agents to discover data and walk the graph rather than generating human readable queries.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Built-in Embeddings&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;No need to embed your data before sending it to Helix, just use the &lt;code&gt;Embed&lt;/code&gt; function to vectorize text.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Tooling for RAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HelixDB has a built-in vector search, keyword search, and graph traversals that can be used to power any type of RAG applications.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Secure by Default&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HelixDB is private by default. You can only access your data through your compiled HelixQL queries.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ultra-Low Latency&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Helix is built in Rust and uses LMDB as its storage engine to provide extremely low latencies.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Type-Safe Queries&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HelixQL is 100% type-safe, which lets you develop and deploy with the confidence that your queries will execute in production&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h4&gt;Helix CLI&lt;/h4&gt; 
&lt;p&gt;Start by installing the Helix CLI tool to deploy Helix locally.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install CLI&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL "https://install.helix-db.com" | bash
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Initialize a project&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir &amp;lt;path-to-project&amp;gt; &amp;amp;&amp;amp; cd &amp;lt;path-to-project&amp;gt;
helix init
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Write queries&lt;/p&gt; &lt;p&gt;Open your newly created &lt;code&gt;.hx&lt;/code&gt; files and start writing your schema and queries. Head over to &lt;a href="https://docs.helix-db.com/documentation/hql/hql"&gt;our docs&lt;/a&gt; for more information about writing queries.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-js"&gt;N::User {
   INDEX name: String,
   age: U32
}

QUERY getUser(user_name: String) =&amp;gt;
   user &amp;lt;- N&amp;lt;User&amp;gt;({name: user_name})
   RETURN user
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) Check your queries compile&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;helix check
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Deploy your queries to their API endpoints&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;helix push dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start calling them using our &lt;a href="https://github.com/HelixDB/helix-ts"&gt;TypeScript SDK&lt;/a&gt; or &lt;a href="https://github.com/HelixDB/helix-py"&gt;Python SDK&lt;/a&gt;. For example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-typescript"&gt;import HelixDB from "helix-ts";

// Create a new HelixDB client
// The default port is 6969
const client = new HelixDB();

// Query the database
await client.query("addUser", {
  name: "John",
  age: 20,
});

// Get the created user
const user = await client.query("getUser", {
  user_name: "John",
});

console.log(user);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;HelixDB is licensed under the The AGPL (Affero General Public License).&lt;/p&gt; 
&lt;h2&gt;Commercial Support&lt;/h2&gt; 
&lt;p&gt;HelixDB is available as a managed service for selected users, if you're interested in using Helix's managed service or want enterprise support, &lt;a href="mailto:founders@helix-db.com"&gt;contact&lt;/a&gt; us for more information and deployment options.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Just Use Helix&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>