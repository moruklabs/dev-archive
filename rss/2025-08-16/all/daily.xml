<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Fri, 15 Aug 2025 01:32:12 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>ostris/ai-toolkit</title>
      <link>https://github.com/ostris/ai-toolkit</link>
      <description>&lt;p&gt;The ultimate training toolkit for finetuning diffusion models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Toolkit by Ostris&lt;/h1&gt; 
&lt;p&gt;AI Toolkit is an all in one training suite for diffusion models. I try to support all the latest models on consumer grade hardware. Image and video models. It can be run as a GUI or CLI. It is designed to be easy to use but still have every feature imaginable.&lt;/p&gt; 
&lt;h2&gt;Support My Work&lt;/h2&gt; 
&lt;p&gt;If you enjoy my projects or use them commercially, please consider sponsoring me. Every bit helps! üíñ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/orgs/ostris"&gt;Sponsor on GitHub&lt;/a&gt; | &lt;a href="https://www.patreon.com/ostris"&gt;Support on Patreon&lt;/a&gt; | &lt;a href="https://www.paypal.com/donate/?hosted_button_id=9GEFUKC8T9R9W"&gt;Donate on PayPal&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Current Sponsors&lt;/h3&gt; 
&lt;p&gt;All of these people / organizations are the ones who selflessly make this project possible. Thank you!!&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Last updated: 2025-08-08 17:01 UTC&lt;/em&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://x.com/NuxZoe" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1919488160125616128/QAZXTMEj_400x400.png" alt="a16z" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/replicate" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/60410876?v=4" alt="Replicate" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/25720743?v=4" alt="Hugging Face" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/josephrocca" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1167575?u=92d92921b4cb5c8c7e225663fed53c4b41897736&amp;amp;v=4" alt="josephrocca" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/162524101/81a72689c3754ac5b9e38612ce5ce914/eyJ3IjoyMDB9/1.png?token-hash=JHRjAxd2XxV1aXIUijj-l65pfTnLoefYSvgNPAsw2lI%3D" alt="Prasanth Veerina" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/weights-ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/185568492?v=4" alt="Weights" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;" /&gt; 
&lt;p align="center"&gt; &lt;img src="https://c8.patreon.com/4/200/93304/J" alt="Joseph Rocca" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/161471720/dd330b4036d44a5985ed5985c12a5def/eyJ3IjoyMDB9/1.jpeg?token-hash=k1f4Vv7TevzYa9tqlzAjsogYmkZs8nrXQohPCDGJGkc%3D" alt="Vladimir Sotnikov" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/33158543/C" alt="clement Delangue" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/8654302/b0f5ebedc62a47c4b56222693e1254e9/eyJ3IjoyMDB9/2.jpeg?token-hash=suI7_QjKUgWpdPuJPaIkElkTrXfItHlL8ZHLPT-w_d4%3D" alt="Misch Strotz" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/120239481/49b1ce70d3d24704b8ec34de24ec8f55/eyJ3IjoyMDB9/1.jpeg?token-hash=o0y1JqSXqtGvVXnxb06HMXjQXs6OII9yMMx5WyyUqT4%3D" alt="nitish PNR" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;" /&gt; 
&lt;p align="center"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/2298192/1228b69bd7d7481baf3103315183250d/eyJ3IjoyMDB9/1.jpg?token-hash=opN1e4r4Nnvqbtr8R9HI8eyf9m5F50CiHDOdHzb4UcA%3D" alt="Mohamed Oumoumad" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/548524/S" alt="Steve Hanff" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/152118848/3b15a43d71714552b5ed1c9f84e66adf/eyJ3IjoyMDB9/1.png?token-hash=MKf3sWHz0MFPm_OAFjdsNvxoBfN5B5l54mn1ORdlRy8%3D" alt="Kristjan Retter" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/83319230/M" alt="Miguel Lara" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/8449560/P" alt="Patron" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://x.com/NuxZoe" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1916482710069014528/RDLnPRSg_400x400.jpg" alt="tungsten" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/169502989/220069e79ce745b29237e94c22a729df/eyJ3IjoyMDB9/1.png?token-hash=E8E2JOqx66k2zMtYUw8Gy57dw-gVqA6OPpdCmWFFSFw%3D" alt="Timothy Bielec" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/34200989/58ae95ebda0640c8b7a91b4fa31357aa/eyJ3IjoyMDB9/1.jpeg?token-hash=4mVDM1kCYGauYa33zLG14_g0oj9_UjDK_-Qp4zk42GE%3D" alt="Noah Miller" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/27288932/6c35d2d961ee4e14a7a368c990791315/eyJ3IjoyMDB9/1.jpeg?token-hash=TGIto_PGEG2NEKNyqwzEnRStOkhrjb3QlMhHA3raKJY%3D" alt="David Garrido" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://x.com/RalFingerLP" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/919595465041162241/ZU7X3T5k_400x400.jpg" alt="RalFinger" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;" /&gt; 
&lt;p align="center"&gt; &lt;a href="http://www.ir-ltd.net" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1602579392198283264/6Tm2GYus_400x400.jpg" alt="IR-Entertainment Ltd" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/9547341/bb35d9a222fd460e862e960ba3eacbaf/eyJ3IjoyMDB9/1.jpeg?token-hash=Q2XGDvkCbiONeWNxBCTeTMOcuwTjOaJ8Z-CAf5xq3Hs%3D" alt="Travis Harrington" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/98811435/3a3632d1795b4c2b9f8f0270f2f6a650/eyJ3IjoyMDB9/1.jpeg?token-hash=657rzuJ0bZavMRZW3XZ-xQGqm3Vk6FkMZgFJVMCOPdk%3D" alt="EmmanuelMr18" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/81275465/1e4148fe9c47452b838949d02dd9a70f/eyJ3IjoyMDB9/1.jpeg?token-hash=YAX1ucxybpCIujUCXfdwzUQkttIn3c7pfi59uaFPSwM%3D" alt="Aaron Amortegui" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/155963250/6f8fd7075c3b4247bfeb054ba49172d6/eyJ3IjoyMDB9/1.png?token-hash=z81EHmdU2cqSrwa9vJmZTV3h0LG-z9Qakhxq34FrYT4%3D" alt="Un Defined" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/45562978/0de33cf52ec642ae8a2f612cddec4ca6/eyJ3IjoyMDB9/1.jpeg?token-hash=aD4debMD5ZQjqTII6s4zYSgVK2-bdQt9p3eipi0bENs%3D" alt="Jack English" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/27791680/J" alt="Jean-Tristan Marin" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/570742/4ceb33453a5a4745b430a216aba9280f/eyJ3IjoyMDB9/1.jpg?token-hash=nPcJ2zj3sloND9jvbnbYnob2vMXRnXdRuujthqDLWlU%3D" alt="Al H" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/82763/f99cc484361d4b9d94fe4f0814ada303/eyJ3IjoyMDB9/1.jpeg?token-hash=A3JWlBNL0b24FFWb-FCRDAyhs-OAxg-zrhfBXP_axuU%3D" alt="Doron Adler" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/103077711/bb215761cc004e80bd9cec7d4bcd636d/eyJ3IjoyMDB9/2.jpeg?token-hash=3U8kdZSUpnmeYIDVK4zK9TTXFpnAud_zOwBRXx18018%3D" alt="John Dopamine" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/99036356/7ae9c4d80e604e739b68cca12ee2ed01/eyJ3IjoyMDB9/3.png?token-hash=ZhsBMoTOZjJ-Y6h5NOmU5MT-vDb2fjK46JDlpEehkVQ%3D" alt="Noctre" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/141098579/1a9f0a1249d447a7a0df718a57343912/eyJ3IjoyMDB9/2.png?token-hash=_n-AQmPgY0FP9zCGTIEsr5ka4Y7YuaMkt3qL26ZqGg8%3D" alt="The Local Lab" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/93348210/5c650f32a0bc481d80900d2674528777/eyJ3IjoyMDB9/1.jpeg?token-hash=0jiknRw3jXqYWW6En8bNfuHgVDj4LI_rL7lSS4-_xlo%3D" alt="Armin Behjati" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/134129880/680c7e14cd1a4d1a9face921fb010f88/eyJ3IjoyMDB9/1.png?token-hash=5fqqHE6DCTbt7gDQL7VRcWkV71jF7FvWcLhpYl5aMXA%3D" alt="Bharat Prabhakar" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/70218846/C" alt="Cosmosis" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/30931983/54ab4e4ceab946e79a6418d205f9ed51/eyJ3IjoyMDB9/1.png?token-hash=j2phDrgd6IWuqKqNIDbq9fR2B3fMF-GUCQSdETS1w5Y%3D" alt="HestoySeghuro ." width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/4105384/J" alt="Jack Blakely" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/4541423/S" alt="S√∂ren " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://www.youtube.com/@happyme7055" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://yt3.googleusercontent.com/ytc/AIdro_mFqhIRk99SoEWY2gvSvVp6u1SkCGMkRqYQ1OlBBeoOVp8=s160-c-k-c0x00ffffff-no-rj" alt="Marcus Rass" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/53077895/M" alt="Marc" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/157407541/bb9d80cffdab4334ad78366060561520/eyJ3IjoyMDB9/2.png?token-hash=WYz-U_9zabhHstOT5UIa5jBaoFwrwwqyWxWEzIR2m_c%3D" alt="Tokio Studio srl IT10640050968" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/44568304/a9d83a0e786b41b4bdada150f7c9271c/eyJ3IjoyMDB9/1.jpeg?token-hash=FtxnwrSrknQUQKvDRv2rqPceX2EF23eLq4pNQYM_fmw%3D" alt="Albert Bukoski" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/5048649/B" alt="Ben Ward" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/111904990/08b1cf65be6a4de091c9b73b693b3468/eyJ3IjoyMDB9/1.png?token-hash=_Odz6RD3CxtubEHbUxYujcjw6zAajbo3w8TRz249VBA%3D" alt="Brian Smith" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/494309/J" alt="Julian Tsependa" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/5602036/K" alt="Kelevra" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/159203973/36c817f941ac4fa18103a4b8c0cb9cae/eyJ3IjoyMDB9/1.png?token-hash=zkt72HW3EoiIEAn3LSk9gJPBsXfuTVcc4rRBS3CeR8w%3D" alt="Marko jak" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/24653779/R" alt="RayHell" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/76566911/6485eaf5ec6249a7b524ee0b979372f0/eyJ3IjoyMDB9/1.jpeg?token-hash=mwCSkTelDBaengG32NkN0lVl5mRjB-cwo6-a47wnOsU%3D" alt="the biitz" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/32633822/1ab5612efe80417cbebfe91e871fc052/eyJ3IjoyMDB9/1.png?token-hash=pOS_IU3b3RL5-iL96A3Xqoj2bQ-dDo4RUkBylcMED_s%3D" alt="Zack Abrams" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/97985240/3d1d0e6905d045aba713e8132cab4a30/eyJ3IjoyMDB9/1.png?token-hash=fRavvbO_yqWKA_OsJb5DzjfKZ1Yt-TG-ihMoeVBvlcM%3D" alt="◊¢◊ï◊û◊® ◊û◊õ◊ú◊ï◊£" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/julien-blanchon" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/11278197?v=4" alt="Blanchon" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/11198131/e696d9647feb4318bcf16243c2425805/eyJ3IjoyMDB9/1.jpeg?token-hash=c2c2p1SaiX86iXAigvGRvzm4jDHvIFCg298A49nIfUM%3D" alt="Nicholas Agranoff" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/785333/bdb9ede5765d42e5a2021a86eebf0d8f/eyJ3IjoyMDB9/2.jpg?token-hash=l_rajMhxTm6wFFPn7YdoKBxeUqhdRXKdy6_8SGCuNsE%3D" alt="Sapjes " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/2446176/S" alt="Scott VanKirk" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/83034/W" alt="william tatum" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/138787189/2b5662dcb638466282ac758e3ac651b4/eyJ3IjoyMDB9/1.png?token-hash=zwj7MScO18vhDxhKt6s5q4gdeNJM3xCLuhSt8zlqlZs%3D" alt="–ê–Ω—Ç–æ–Ω –ê–Ω—Ç–æ–Ω–∏–æ" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/30530914/T" alt="Techer " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/25209707/36ae876d662d4d85aaf162b6d67d31e7/eyJ3IjoyMDB9/1.png?token-hash=Zows_A6uqlY5jClhfr4Y3QfMnDKVkS3mbxNHUDkVejo%3D" alt="fjioq8" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/46680573/ee3d99c04a674dd5a8e1ecfb926db6a2/eyJ3IjoyMDB9/1.jpeg?token-hash=cgD4EXyfZMPnXIrcqWQ5jGqzRUfqjPafb9yWfZUPB4Q%3D" alt="Neil Murray" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Joakim S√§llstr√∂m" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/63510241/A" alt="Andrew Park" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/Spikhalskiy" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/532108?u=2464983638afea8caf4cd9f0e4a7bc3e6a63bb0a&amp;amp;v=4" alt="Dmitry Spikhalsky" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/88567307/E" alt="el Chavo" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/117569999/55f75c57f95343e58402529cec852b26/eyJ3IjoyMDB9/1.jpeg?token-hash=squblHZH4-eMs3gI46Uqu1oTOK9sQ-0gcsFdZcB9xQg%3D" alt="James Thompson" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/66157709/6fe70df085e24464995a1a9293a53760/eyJ3IjoyMDB9/1.jpeg?token-hash=eqe0wvg6JfbRUGMKpL_x3YPI5Ppf18aUUJe2EzADU-g%3D" alt="Joey Santana" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Heikki Rinkinen" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/6175608/B" alt="Bobbie " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/Slartibart23" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/133593860?u=31217adb2522fb295805824ffa7e14e8f0fca6fa&amp;amp;v=4" alt="Slarti" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Tommy Falkowski" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/28533016/e8f6044ccfa7483f87eeaa01c894a773/eyJ3IjoyMDB9/2.png?token-hash=ak-h3JWB50hyenCavcs32AAPw6nNhmH2nBFKpdk5hvM%3D" alt="William Tatum" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Karol Stƒôpie≈Ñ" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/156564939/17dbfd45c59d4cf29853d710cb0c5d6f/eyJ3IjoyMDB9/1.png?token-hash=e6wXA_S8cgJeEDI9eJK934eB0TiM8mxJm9zW_VH0gDU%3D" alt="Hans Untch" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/59408413/B" alt="ByteC" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/3712451/432e22a355494ec0a1ea1927ff8d452e/eyJ3IjoyMDB9/7.jpeg?token-hash=OpQ9SAfVQ4Un9dSYlGTHuApZo5GlJ797Mo0DtVtMOSc%3D" alt="David Shorey" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/53634141/c1441f6c605344bbaef885d4272977bb/eyJ3IjoyMDB9/1.JPG?token-hash=Aizd6AxQhY3n6TBE5AwCVeSwEBbjALxQmu6xqc08qBo%3D" alt="Jana Spacelight" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/11180426/J" alt="jarrett towe" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/21828017/J" alt="Jim" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/63232055/2300b4ab370341b5b476902c9b8218ee/eyJ3IjoyMDB9/1.png?token-hash=R9Nb4O0aLBRwxT1cGHUMThlvf6A2MD5SO88lpZBdH7M%3D" alt="Marek P" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/9944625/P" alt="Pomoe " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/25047900/423e4cb73aba457f8f9c6e5582eddaeb/eyJ3IjoyMDB9/1.jpeg?token-hash=81RvQXBbT66usxqtyWum9Ul4oBn3qHK1cM71IvthC-U%3D" alt="Ruairi Robinson" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/178476551/0b9e83efcd234df5a6bea30d59e6c1cd/eyJ3IjoyMDB9/1.png?token-hash=3XoYMrMxk-K6GelM22mE-FwkjFulX9hpIL7QI3wO2jI%3D" alt="Timmy" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/10876902/T" alt="Tyssel" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Juan Franco" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;python &amp;gt;3.10&lt;/li&gt; 
 &lt;li&gt;Nvidia GPU with enough ram to do what you need&lt;/li&gt; 
 &lt;li&gt;python venv&lt;/li&gt; 
 &lt;li&gt;git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Linux:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
python3 -m venv venv
source venv/bin/activate
# install torch first
pip3 install --no-cache-dir torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126
pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Windows:&lt;/p&gt; 
&lt;p&gt;If you are having issues with Windows. I recommend using the easy install script at &lt;a href="https://github.com/Tavris1/AI-Toolkit-Easy-Install"&gt;https://github.com/Tavris1/AI-Toolkit-Easy-Install&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
python -m venv venv
.\venv\Scripts\activate
pip install --no-cache-dir torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;AI Toolkit UI&lt;/h1&gt; 
&lt;img src="https://ostris.com/wp-content/uploads/2025/02/toolkit-ui.jpg" alt="AI Toolkit UI" width="100%" /&gt; 
&lt;p&gt;The AI Toolkit UI is a web interface for the AI Toolkit. It allows you to easily start, stop, and monitor jobs. It also allows you to easily train models with a few clicks. It also allows you to set a token for the UI to prevent unauthorized access so it is mostly safe to run on an exposed server.&lt;/p&gt; 
&lt;h2&gt;Running the UI&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Node.js &amp;gt; 18&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The UI does not need to be kept running for the jobs to run. It is only needed to start/stop/monitor jobs. The commands below will install / update the UI and it's dependencies and start the UI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ui
npm run build_and_start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can now access the UI at &lt;code&gt;http://localhost:8675&lt;/code&gt; or &lt;code&gt;http://&amp;lt;your-ip&amp;gt;:8675&lt;/code&gt; if you are running it on a server.&lt;/p&gt; 
&lt;h2&gt;Securing the UI&lt;/h2&gt; 
&lt;p&gt;If you are hosting the UI on a cloud provider or any network that is not secure, I highly recommend securing it with an auth token. You can do this by setting the environment variable &lt;code&gt;AI_TOOLKIT_AUTH&lt;/code&gt; to super secure password. This token will be required to access the UI. You can set this when starting the UI like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Linux
AI_TOOLKIT_AUTH=super_secure_password npm run build_and_start

# Windows
set AI_TOOLKIT_AUTH=super_secure_password &amp;amp;&amp;amp; npm run build_and_start

# Windows Powershell
$env:AI_TOOLKIT_AUTH="super_secure_password"; npm run build_and_start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FLUX.1 Training&lt;/h2&gt; 
&lt;h3&gt;Tutorial&lt;/h3&gt; 
&lt;p&gt;To get started quickly, check out &lt;a href="https://x.com/araminta_k"&gt;@araminta_k&lt;/a&gt; tutorial on &lt;a href="https://www.youtube.com/watch?v=HzGW_Kyermg"&gt;Finetuning Flux Dev on a 3090&lt;/a&gt; with 24GB VRAM.&lt;/p&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;You currently need a GPU with &lt;strong&gt;at least 24GB of VRAM&lt;/strong&gt; to train FLUX.1. If you are using it as your GPU to control your monitors, you probably need to set the flag &lt;code&gt;low_vram: true&lt;/code&gt; in the config file under &lt;code&gt;model:&lt;/code&gt;. This will quantize the model on CPU and should allow it to train with monitors attached. Users have gotten it to work on Windows with WSL, but there are some reports of a bug when running on windows natively. I have only tested on linux for now. This is still extremely experimental and a lot of quantizing and tricks had to happen to get it to fit on 24GB at all.&lt;/p&gt; 
&lt;h3&gt;FLUX.1-dev&lt;/h3&gt; 
&lt;p&gt;FLUX.1-dev has a non-commercial license. Which means anything you train will inherit the non-commercial license. It is also a gated model, so you need to accept the license on HF before using it. Otherwise, this will fail. Here are the required steps to setup a license.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Sign into HF and accept the model access here &lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-dev"&gt;black-forest-labs/FLUX.1-dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Make a file named &lt;code&gt;.env&lt;/code&gt; in the root on this folder&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/settings/tokens/new?"&gt;Get a READ key from huggingface&lt;/a&gt; and add it to the &lt;code&gt;.env&lt;/code&gt; file like so &lt;code&gt;HF_TOKEN=your_key_here&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;FLUX.1-schnell&lt;/h3&gt; 
&lt;p&gt;FLUX.1-schnell is Apache 2.0. Anything trained on it can be licensed however you want and it does not require a HF_TOKEN to train. However, it does require a special adapter to train with it, &lt;a href="https://huggingface.co/ostris/FLUX.1-schnell-training-adapter"&gt;ostris/FLUX.1-schnell-training-adapter&lt;/a&gt;. It is also highly experimental. For best overall quality, training on FLUX.1-dev is recommended.&lt;/p&gt; 
&lt;p&gt;To use it, You just need to add the assistant to the &lt;code&gt;model&lt;/code&gt; section of your config file like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      model:
        name_or_path: "black-forest-labs/FLUX.1-schnell"
        assistant_lora_path: "ostris/FLUX.1-schnell-training-adapter"
        is_flux: true
        quantize: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You also need to adjust your sample steps since schnell does not require as many&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      sample:
        guidance_scale: 1  # schnell does not do guidance
        sample_steps: 4  # 1 - 4 works well
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Training&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Copy the example config file located at &lt;code&gt;config/examples/train_lora_flux_24gb.yaml&lt;/code&gt; (&lt;code&gt;config/examples/train_lora_flux_schnell_24gb.yaml&lt;/code&gt; for schnell) to the &lt;code&gt;config&lt;/code&gt; folder and rename it to &lt;code&gt;whatever_you_want.yml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Edit the file following the comments in the file&lt;/li&gt; 
 &lt;li&gt;Run the file like so &lt;code&gt;python run.py config/whatever_you_want.yml&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A folder with the name and the training folder from the config file will be created when you start. It will have all checkpoints and images in it. You can stop the training at any time using ctrl+c and when you resume, it will pick back up from the last checkpoint.&lt;/p&gt; 
&lt;p&gt;IMPORTANT. If you press crtl+c while it is saving, it will likely corrupt that checkpoint. So wait until it is done saving&lt;/p&gt; 
&lt;h3&gt;Need help?&lt;/h3&gt; 
&lt;p&gt;Please do not open a bug report unless it is a bug in the code. You are welcome to &lt;a href="https://discord.gg/VXmU2f5WEU"&gt;Join my Discord&lt;/a&gt; and ask for help there. However, please refrain from PMing me directly with general question or support. Ask in the discord and I will answer when I can.&lt;/p&gt; 
&lt;h2&gt;Gradio UI&lt;/h2&gt; 
&lt;p&gt;To get started training locally with a with a custom UI, once you followed the steps above and &lt;code&gt;ai-toolkit&lt;/code&gt; is installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai-toolkit #in case you are not yet in the ai-toolkit folder
huggingface-cli login #provide a `write` token to publish your LoRA at the end
python flux_train_ui.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will instantiate a UI that will let you upload your images, caption them, train and publish your LoRA &lt;img src="https://raw.githubusercontent.com/ostris/ai-toolkit/main/assets/lora_ease_ui.png" alt="image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Training in RunPod&lt;/h2&gt; 
&lt;p&gt;Example RunPod template: &lt;strong&gt;runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You need a minimum of 24GB VRAM, pick a GPU by your preference.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Example config ($0.5/hr):&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;1x A40 (48 GB VRAM)&lt;/li&gt; 
 &lt;li&gt;19 vCPU 100 GB RAM&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Custom overrides (you need some storage to clone FLUX.1, store datasets, store trained models and samples):&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;~120 GB Disk&lt;/li&gt; 
 &lt;li&gt;~120 GB Pod Volume&lt;/li&gt; 
 &lt;li&gt;Start Jupyter Notebook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
git submodule update --init --recursive
python -m venv venv
source venv/bin/activate
pip install torch
pip install -r requirements.txt
pip install --upgrade accelerate transformers diffusers huggingface_hub #Optional, run it if you run into issues
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Upload your dataset&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a new folder in the root, name it &lt;code&gt;dataset&lt;/code&gt; or whatever you like.&lt;/li&gt; 
 &lt;li&gt;Drag and drop your .jpg, .jpeg, or .png images and .txt files inside the newly created dataset folder.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Login into Hugging Face with an Access Token&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Get a READ token from &lt;a href="https://huggingface.co/settings/tokens"&gt;here&lt;/a&gt; and request access to Flux.1-dev model from &lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-dev"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;huggingface-cli login&lt;/code&gt; and paste your token.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Training&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Copy an example config file located at &lt;code&gt;config/examples&lt;/code&gt; to the config folder and rename it to &lt;code&gt;whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Edit the config following the comments in the file.&lt;/li&gt; 
 &lt;li&gt;Change &lt;code&gt;folder_path: "/path/to/images/folder"&lt;/code&gt; to your dataset path like &lt;code&gt;folder_path: "/workspace/ai-toolkit/your-dataset"&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run the file: &lt;code&gt;python run.py config/whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Screenshot from RunPod&lt;/h3&gt; 
&lt;img width="1728" alt="RunPod Training Screenshot" src="https://github.com/user-attachments/assets/53a1b8ef-92fa-4481-81a7-bde45a14a7b5" /&gt; 
&lt;h2&gt;Training in Modal&lt;/h2&gt; 
&lt;h3&gt;1. Setup&lt;/h3&gt; 
&lt;h4&gt;ai-toolkit:&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
git submodule update --init --recursive
python -m venv venv
source venv/bin/activate
pip install torch
pip install -r requirements.txt
pip install --upgrade accelerate transformers diffusers huggingface_hub #Optional, run it if you run into issues
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Modal:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run &lt;code&gt;pip install modal&lt;/code&gt; to install the modal Python package.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;modal setup&lt;/code&gt; to authenticate (if this doesn‚Äôt work, try &lt;code&gt;python -m modal setup&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Hugging Face:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Get a READ token from &lt;a href="https://huggingface.co/settings/tokens"&gt;here&lt;/a&gt; and request access to Flux.1-dev model from &lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-dev"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;huggingface-cli login&lt;/code&gt; and paste your token.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. Upload your dataset&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Drag and drop your dataset folder containing the .jpg, .jpeg, or .png images and .txt files in &lt;code&gt;ai-toolkit&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Configs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Copy an example config file located at &lt;code&gt;config/examples/modal&lt;/code&gt; to the &lt;code&gt;config&lt;/code&gt; folder and rename it to &lt;code&gt;whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Edit the config following the comments in the file, &lt;strong&gt;&lt;ins&gt;be careful and follow the example &lt;code&gt;/root/ai-toolkit&lt;/code&gt; paths&lt;/ins&gt;&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Edit run_modal.py&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Set your entire local &lt;code&gt;ai-toolkit&lt;/code&gt; path at &lt;code&gt;code_mount = modal.Mount.from_local_dir&lt;/code&gt; like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;code_mount = modal.Mount.from_local_dir("/Users/username/ai-toolkit", remote_path="/root/ai-toolkit")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Choose a &lt;code&gt;GPU&lt;/code&gt; and &lt;code&gt;Timeout&lt;/code&gt; in &lt;code&gt;@app.function&lt;/code&gt; &lt;em&gt;(default is A100 40GB and 2 hour timeout)&lt;/em&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. Training&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run the config file in your terminal: &lt;code&gt;modal run run_modal.py --config-file-list-str=/root/ai-toolkit/config/whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;You can monitor your training in your local terminal, or on &lt;a href="https://modal.com/"&gt;modal.com&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Models, samples and optimizer will be stored in &lt;code&gt;Storage &amp;gt; flux-lora-models&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;6. Saving the model&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check contents of the volume by running &lt;code&gt;modal volume ls flux-lora-models&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Download the content by running &lt;code&gt;modal volume get flux-lora-models your-model-name&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Example: &lt;code&gt;modal volume get flux-lora-models my_first_flux_lora_v1&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Screenshot from Modal&lt;/h3&gt; 
&lt;img width="1728" alt="Modal Traning Screenshot" src="https://github.com/user-attachments/assets/7497eb38-0090-49d6-8ad9-9c8ea7b5388b" /&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Dataset Preparation&lt;/h2&gt; 
&lt;p&gt;Datasets generally need to be a folder containing images and associated text files. Currently, the only supported formats are jpg, jpeg, and png. Webp currently has issues. The text files should be named the same as the images but with a &lt;code&gt;.txt&lt;/code&gt; extension. For example &lt;code&gt;image2.jpg&lt;/code&gt; and &lt;code&gt;image2.txt&lt;/code&gt;. The text file should contain only the caption. You can add the word &lt;code&gt;[trigger]&lt;/code&gt; in the caption file and if you have &lt;code&gt;trigger_word&lt;/code&gt; in your config, it will be automatically replaced.&lt;/p&gt; 
&lt;p&gt;Images are never upscaled but they are downscaled and placed in buckets for batching. &lt;strong&gt;You do not need to crop/resize your images&lt;/strong&gt;. The loader will automatically resize them and can handle varying aspect ratios.&lt;/p&gt; 
&lt;h2&gt;Training Specific Layers&lt;/h2&gt; 
&lt;p&gt;To train specific layers with LoRA, you can use the &lt;code&gt;only_if_contains&lt;/code&gt; network kwargs. For instance, if you want to train only the 2 layers used by The Last Ben, &lt;a href="https://x.com/__TheBen/status/1829554120270987740"&gt;mentioned in this post&lt;/a&gt;, you can adjust your network kwargs like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lora"
        linear: 128
        linear_alpha: 128
        network_kwargs:
          only_if_contains:
            - "transformer.single_transformer_blocks.7.proj_out"
            - "transformer.single_transformer_blocks.20.proj_out"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The naming conventions of the layers are in diffusers format, so checking the state dict of a model will reveal the suffix of the name of the layers you want to train. You can also use this method to only train specific groups of weights. For instance to only train the &lt;code&gt;single_transformer&lt;/code&gt; for FLUX.1, you can use the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lora"
        linear: 128
        linear_alpha: 128
        network_kwargs:
          only_if_contains:
            - "transformer.single_transformer_blocks."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also exclude layers by their names by using &lt;code&gt;ignore_if_contains&lt;/code&gt; network kwarg. So to exclude all the single transformer blocks,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lora"
        linear: 128
        linear_alpha: 128
        network_kwargs:
          ignore_if_contains:
            - "transformer.single_transformer_blocks."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;ignore_if_contains&lt;/code&gt; takes priority over &lt;code&gt;only_if_contains&lt;/code&gt;. So if a weight is covered by both, if will be ignored.&lt;/p&gt; 
&lt;h2&gt;LoKr Training&lt;/h2&gt; 
&lt;p&gt;To learn more about LoKr, read more about it at &lt;a href="https://github.com/KohakuBlueleaf/LyCORIS/raw/main/docs/Guidelines.md"&gt;KohakuBlueleaf/LyCORIS&lt;/a&gt;. To train a LoKr model, you can adjust the network type in the config file like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lokr"
        lokr_full_rank: true
        lokr_factor: 8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Everything else should work the same including layer targeting.&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;Only larger updates are listed here. There are usually smaller daily updated that are omitted.&lt;/p&gt; 
&lt;h3&gt;Jul 17, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Make it easy to add control images to the samples in the ui&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Jul 11, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added better video config settings to the UI for video models.&lt;/li&gt; 
 &lt;li&gt;Added Wan I2V training to the UI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 29, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed issue where Kontext forced sizes on sampling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 26, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added support for FLUX.1 Kontext training&lt;/li&gt; 
 &lt;li&gt;added support for instruction dataset training&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 25, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added support for OmniGen2 training&lt;/li&gt; 
 &lt;li&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 17, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Performance optimizations for batch preparation&lt;/li&gt; 
 &lt;li&gt;Added some docs via a popup for items in the simple ui explaining what settings do. Still a WIP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 16, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hide control images in the UI when viewing datasets&lt;/li&gt; 
 &lt;li&gt;WIP on mean flow loss&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 12, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed issue that resulted in blank captions in the dataloader&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 10, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Decided to keep track up updates in the readme&lt;/li&gt; 
 &lt;li&gt;Added support for SDXL in the UI&lt;/li&gt; 
 &lt;li&gt;Added support for SD 1.5 in the UI&lt;/li&gt; 
 &lt;li&gt;Fixed UI Wan 2.1 14b name bug&lt;/li&gt; 
 &lt;li&gt;Added support for for conv training in the UI for models that support it&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>microsoft/poml</title>
      <link>https://github.com/microsoft/poml</link>
      <description>&lt;p&gt;Prompt Orchestration Markup Language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;POML: Prompt Orchestration Markup Language&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://microsoft.github.io/poml/"&gt;&lt;img src="https://img.shields.io/badge/docs-microsoft.github.io-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://marketplace.visualstudio.com/items?itemName=poml-team.poml"&gt;&lt;img src="https://img.shields.io/visual-studio-marketplace/v/poml-team.poml" alt="VSCode Extension" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/poml/"&gt;&lt;img src="https://img.shields.io/pypi/v/poml" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/pomljs"&gt;&lt;img src="https://img.shields.io/npm/v/pomljs" alt="npm (latest)" /&gt;&lt;/a&gt; &lt;a href="https://github.com/microsoft/poml/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/microsoft/poml/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Test Status" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/FhMCqWzAn6"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;POML (Prompt Orchestration Markup Language)&lt;/strong&gt; is a novel markup language designed to bring structure, maintainability, and versatility to advanced prompt engineering for Large Language Models (LLMs). It addresses common challenges in prompt development, such as lack of structure, complex data integration, format sensitivity, and inadequate tooling. POML provides a systematic way to organize prompt components, integrate diverse data types seamlessly, and manage presentation variations, empowering developers to create more sophisticated and reliable LLM applications.&lt;/p&gt; 
&lt;h2&gt;Demo Video&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/b9WDcFsKixo"&gt;&lt;img src="https://i3.ytimg.com/vi/b9WDcFsKixo/maxresdefault.jpg" alt="The 5-minute guide to POML" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Structured Prompting Markup&lt;/strong&gt;: Employs an HTML-like syntax with semantic components such as &lt;code&gt;&amp;lt;role&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;task&amp;gt;&lt;/code&gt;, and &lt;code&gt;&amp;lt;example&amp;gt;&lt;/code&gt; to encourage modular design, enhancing prompt readability, reusability, and maintainability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Data Handling&lt;/strong&gt;: Incorporates specialized data components (e.g., &lt;code&gt;&amp;lt;document&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;table&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt;) that seamlessly embed or reference external data sources like text files, spreadsheets, and images, with customizable formatting options.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Decoupled Presentation Styling&lt;/strong&gt;: Features a CSS-like styling system that separates content from presentation. This allows developers to modify styling (e.g., verbosity, syntax format) via &lt;code&gt;&amp;lt;stylesheet&amp;gt;&lt;/code&gt; definitions or inline attributes without altering core prompt logic, mitigating LLM format sensitivity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integrated Templating Engine&lt;/strong&gt;: Includes a built-in templating engine with support for variables (&lt;code&gt;{{ }}&lt;/code&gt;), loops (&lt;code&gt;for&lt;/code&gt;), conditionals (&lt;code&gt;if&lt;/code&gt;), and variable definitions (&lt;code&gt;&amp;lt;let&amp;gt;&lt;/code&gt;) for dynamically generating complex, data-driven prompts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rich Development Toolkit&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;IDE Extension (Visual Studio Code)&lt;/strong&gt;: Provides essential development aids like syntax highlighting, context-aware auto-completion, hover documentation, real-time previews, inline diagnostics for error checking, and integrated interactive testing.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Software Development Kits (SDKs)&lt;/strong&gt;: Offers SDKs for Node.js (JavaScript/TypeScript) and Python for seamless integration into various application workflows and popular LLM frameworks.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Here's a very simple POML example. Please put it in a file named &lt;code&gt;example.poml&lt;/code&gt;. Make sure it resides in the same directory as the &lt;code&gt;photosynthesis_diagram.png&lt;/code&gt; image file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&amp;lt;poml&amp;gt;
  &amp;lt;role&amp;gt;You are a patient teacher explaining concepts to a 10-year-old.&amp;lt;/role&amp;gt;
  &amp;lt;task&amp;gt;Explain the concept of photosynthesis using the provided image as a reference.&amp;lt;/task&amp;gt;

  &amp;lt;img src="photosynthesis_diagram.png" alt="Diagram of photosynthesis" /&amp;gt;

  &amp;lt;output-format&amp;gt;
    Keep the explanation simple, engaging, and under 100 words.
    Start with "Hey there, future scientist!".
  &amp;lt;/output-format&amp;gt;
&amp;lt;/poml&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This example defines a role and task for the LLM, includes an image for context, and specifies the desired output format. With the POML toolkit, the prompt can be easily rendered with a flexible format, and tested with a vision LLM.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Visual Studio Code Extension&lt;/h3&gt; 
&lt;p&gt;Install from &lt;a href="https://marketplace.visualstudio.com/items?itemName=poml-team.poml"&gt;Visual Studio Code Marketplace&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also install the extension manually by downloading the &lt;code&gt;.vsix&lt;/code&gt; file from our &lt;a href="https://github.com/microsoft/poml/releases"&gt;GitHub releases page&lt;/a&gt; and installing it in VS Code via the Extensions view.&lt;/p&gt; 
&lt;p&gt;Before testing prompts with the POML toolkit, make sure you have configured your preferred LLM model, API key, and endpoint. If these are not set, prompt testing will not work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;To configure in Visual Studio Code:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open the extension settings (open "Settings" and search for "POML").&lt;/li&gt; 
 &lt;li&gt;Set your model provider (e.g., OpenAI, Azure, Google), API key, and endpoint URL in the POML section.&lt;/li&gt; 
 &lt;li&gt;Alternatively, you can add these settings directly to your &lt;code&gt;settings.json&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Node.js (via npm)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install pomljs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Python (via pip)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install poml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For development or local installation, you might use &lt;code&gt;pip install -e .&lt;/code&gt; from a cloned repository.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Refer to the &lt;a href="https://microsoft.github.io/poml"&gt;documentation&lt;/a&gt; for more details on installing the nightly build.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed information on POML syntax, components, styling, templating, SDKs, and the VS Code extension, please refer to our &lt;a href="https://microsoft.github.io/poml"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Learn More&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Watch our Demo Video on YouTube:&lt;/strong&gt; &lt;a href="https://youtu.be/b9WDcFsKixo"&gt;POML Introduction &amp;amp; Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Join our Discord community:&lt;/strong&gt; Connect with the team and other users on our &lt;a href="https://discord.gg/FhMCqWzAn6"&gt;Discord server&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Read the Research Paper (coming soon):&lt;/strong&gt; For an in-depth understanding of POML's design, implementation, and evaluation, check out our paper: &lt;a href="https://raw.githubusercontent.com/microsoft/poml/main/TBD"&gt;Paper link TBD&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt; 
&lt;h2&gt;Responsible AI&lt;/h2&gt; 
&lt;p&gt;This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise. For more details, refer to the &lt;a href="https://raw.githubusercontent.com/microsoft/poml/main/RAI_README"&gt;Responsible AI Readme&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/microsoft/poml/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>bytedance/UI-TARS-desktop</title>
      <link>https://github.com/bytedance/UI-TARS-desktop</link>
      <description>&lt;p&gt;The Open-sourced Multimodal AI Agent Stack connecting Cutting-edge AI Models and Agent Infra.&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;img alt="Agent TARS Banner" src="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/images/tars.png" /&gt; 
&lt;/picture&gt; 
&lt;br /&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/README.zh-CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/13584"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13584" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;b&gt;TARS&lt;sup&gt;*&lt;/sup&gt;&lt;/b&gt; is a Multimodal AI Agent stack, currently shipping two projects: &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS-desktop&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="50%" align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt;&lt;/th&gt; 
   &lt;th width="50%" align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS-desktop&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br /&gt; &lt;br /&gt; It primarily ships with a &lt;a href="https://agent-tars.com/guide/basic/cli.html" target="_blank"&gt;CLI&lt;/a&gt; and &lt;a href="https://agent-tars.com/guide/basic/web-ui.html" target="_blank"&gt;Web UI&lt;/a&gt; for usage. It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href="https://agent-tars.com/guide/basic/mcp.html" target="_blank"&gt;MCP&lt;/a&gt; tools. &lt;/td&gt; 
   &lt;td align="left"&gt; &lt;b&gt;UI-TARS Desktop&lt;/b&gt; is a desktop application that provides a native GUI Agent based on the &lt;a href="https://github.com/bytedance/UI-TARS" target="_blank"&gt;UI-TARS&lt;/a&gt; model. &lt;br /&gt; &lt;br /&gt; It primarily ships a &lt;a href="https://github.com/bytedance/UI-TARS-desktop/raw/main/docs/quick-start.md#get-model-and-run-local-operator" target="_blank"&gt;local&lt;/a&gt; and &lt;a href="https://github.com/bytedance/UI-TARS-desktop/raw/main/docs/quick-start.md#run-remote-operator" target="_blank"&gt;remote&lt;/a&gt; computer as well as browser operators. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt; 
&lt;!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#news"&gt;News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#showcase"&gt;Showcase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#core-features"&gt;Core Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS Desktop&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#showcase-1"&gt;Showcase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#quick-start-1"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-06-25]&lt;/strong&gt; We released a Agent TARS Beta and Agent TARS CLI - &lt;a href="https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html"&gt;Introducing Agent TARS Beta&lt;/a&gt;, a multimodal AI agent that aims to explore a work form that is closer to human-like task completion through rich multimodal capabilities (such as GUI Agent, Vision) and seamless integration with various real-world tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-06-12]&lt;/strong&gt; - üéÅ We are thrilled to announce the release of UI-TARS Desktop v0.2.0! This update introduces two powerful new features: &lt;strong&gt;Remote Computer Operator&lt;/strong&gt; and &lt;strong&gt;Remote Browser Operator&lt;/strong&gt;‚Äîboth completely free. No configuration required: simply click to remotely control any computer or browser, and experience a new level of convenience and intelligence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-04-17]&lt;/strong&gt; - üéâ We're thrilled to announce the release of new UI-TARS Desktop application v0.1.0, featuring a redesigned Agent UI. The application enhances the computer using experience, introduces new browser operation features, and supports &lt;a href="https://seed-tars.com/1.5"&gt;the advanced UI-TARS-1.5 model&lt;/a&gt; for improved performance and precise control.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-02-20]&lt;/strong&gt; - üì¶ Introduced &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/sdk.md"&gt;UI TARS SDK&lt;/a&gt;, is a powerful cross-platform toolkit for building GUI automation agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-01-23]&lt;/strong&gt; - üöÄ We updated the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/deployment.md#cloud-deployment"&gt;Cloud Deployment&lt;/a&gt;&lt;/strong&gt; section in the ‰∏≠ÊñáÁâà: &lt;a href="https://bytedance.sg.larkoffice.com/docx/TCcudYwyIox5vyxiSDLlgIsTgWf#U94rdCxzBoJMLex38NPlHL21gNb"&gt;GUIÊ®°ÂûãÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/a&gt; with new information related to the ModelScope platform. You can now use the ModelScope platform for deployment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Agent TARS&lt;/h2&gt; 
&lt;p&gt; &lt;a href="https://npmjs.com/package/@agent-tars/cli?activeTab=readme"&gt;&lt;img src="https://img.shields.io/npm/v/@agent-tars/cli?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=3B82F6&amp;amp;logo=npm&amp;amp;logoColor=white" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://npmcharts.com/compare/@agent-tars/cli?minimal=true"&gt;&lt;img src="https://img.shields.io/npm/dm/@agent-tars/cli.svg?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=0EA5E9&amp;amp;logo=npm&amp;amp;logoColor=white" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://nodejs.org/en/about/previous-releases"&gt;&lt;img src="https://img.shields.io/node/v/@agent-tars/cli.svg?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=06B6D4&amp;amp;logo=node.js&amp;amp;logoColor=white" alt="node version" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/HnKcSBgTVx"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord Community" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/agent_tars"&gt;&lt;img src="https://img.shields.io/badge/Twitter-Follow%20%40agent__tars-1DA1F2?style=for-the-badge&amp;amp;logo=twitter&amp;amp;logoColor=white" alt="Official Twitter" /&gt;&lt;/a&gt; &lt;a href="https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=279h3365-b0fa-407f-89f3-0f96f36cd4d8"&gt;&lt;img src="https://img.shields.io/badge/È£û‰π¶Áæ§-Âä†ÂÖ•‰∫§ÊµÅÁæ§-00D4AA?style=for-the-badge&amp;amp;logo=lark&amp;amp;logoColor=white" alt="È£û‰π¶‰∫§ÊµÅÁæ§" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/bytedance/UI-TARS-desktop"&gt;&lt;img src="https://img.shields.io/badge/DeepWiki-Ask%20AI-8B5CF6?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br /&gt; &lt;br /&gt; It primarily ships with a &lt;a href="https://agent-tars.com/guide/basic/cli.html" target="_blank"&gt;CLI&lt;/a&gt; and &lt;a href="https://agent-tars.com/guide/basic/web-ui.html" target="_blank"&gt;Web UI&lt;/a&gt; for usage. It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href="https://agent-tars.com/guide/basic/mcp.html" target="_blank"&gt;MCP&lt;/a&gt; tools.&lt;/p&gt; 
&lt;h3&gt;Showcase&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Please help me book the earliest flight from San Jose to New York on September 1st and the last return flight on September 6th on Priceline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8"&gt;https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="50%" align="center"&gt;Booking Hotel&lt;/th&gt; 
   &lt;th width="50%" align="center"&gt;Generate Chart with extra MCP Servers&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/a9fd72d0-01bb-4233-aa27-ca95194bbce9" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;I am in Los Angeles from September 1st to September 6th, with a budget of $5,000. Please help me book a Ritz-Carlton hotel closest to the airport on booking.com and compile a transportation guide for me&lt;/i&gt; &lt;/td&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;Draw me a chart of Hangzhou's weather for one month&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For more use cases, please check out &lt;a href="https://github.com/bytedance/UI-TARS-desktop/issues/842"&gt;#842&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Core Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üñ±Ô∏è &lt;strong&gt;One-Click Out-of-the-box CLI&lt;/strong&gt; - Supports both &lt;strong&gt;headful&lt;/strong&gt; &lt;a href="https://agent-tars.com/guide/basic/web-ui.html"&gt;Web UI&lt;/a&gt; and &lt;strong&gt;headless&lt;/strong&gt; &lt;a href="https://agent-tars.com/guide/advanced/server.html"&gt;server&lt;/a&gt;) &lt;a href="https://agent-tars.com/guide/basic/cli.html"&gt;execution&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Hybrid Browser Agent&lt;/strong&gt; - Control browsers using &lt;a href="https://agent-tars.com/guide/basic/browser.html#visual-grounding"&gt;GUI Agent&lt;/a&gt;, &lt;a href="https://agent-tars.com/guide/basic/browser.html#dom"&gt;DOM&lt;/a&gt;, or a hybrid strategy.&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Event Stream&lt;/strong&gt; - Protocol-driven Event Stream drives &lt;a href="https://agent-tars.com/beta#context-engineering"&gt;Context Engineering&lt;/a&gt; and &lt;a href="https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html#easy-to-build-applications"&gt;Agent UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üß∞ &lt;strong&gt;MCP Integration&lt;/strong&gt; - The kernel is built on MCP and also supports mounting &lt;a href="https://agent-tars.com/guide/basic/mcp.html"&gt;MCP Servers&lt;/a&gt; to connect to real-world tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;img alt="Agent TARS CLI" src="https://agent-tars.com/agent-tars-cli.png" /&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Luanch with `npx`.
npx @agent-tars/cli@latest

# Install globally, required Node.js &amp;gt;= 22
npm install @agent-tars/cli@latest -g

# Run with your preferred model provider
agent-tars --provider volcengine --model doubao-1-5-thinking-vision-pro-250428 --apiKey your-api-key
agent-tars --provider anthropic --model claude-3-7-sonnet-latest --apiKey your-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit the comprehensive &lt;a href="https://agent-tars.com/guide/get-started/quick-start.html"&gt;Quick Start&lt;/a&gt; guide for detailed setup instructions.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üåü &lt;strong&gt;Explore Agent TARS Universe&lt;/strong&gt; üåü&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="20%" align="center"&gt;Category&lt;/th&gt; 
   &lt;th width="30%" align="center"&gt;Resource Link&lt;/th&gt; 
   &lt;th width="50%" align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üè† &lt;strong&gt;Central Hub&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com"&gt; &lt;img src="https://img.shields.io/badge/Visit-Website-4F46E5?style=for-the-badge&amp;amp;logo=globe&amp;amp;logoColor=white" alt="Website" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Your gateway to Agent TARS ecosystem&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üìö &lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/guide/get-started/quick-start.html"&gt; &lt;img src="https://img.shields.io/badge/Get-Started-06B6D4?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Quick Start" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Zero to hero in 5 minutes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üöÄ &lt;strong&gt;What's New&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/beta"&gt; &lt;img src="https://img.shields.io/badge/Read-Blog-F59E0B?style=for-the-badge&amp;amp;logo=rss&amp;amp;logoColor=white" alt="Blog" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Discover cutting-edge features &amp;amp; vision&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üõ†Ô∏è &lt;strong&gt;Developer Zone&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/guide/get-started/introduction.html"&gt; &lt;img src="https://img.shields.io/badge/View-Docs-10B981?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Docs" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Master every command &amp;amp; features&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üéØ &lt;strong&gt;Showcase&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/bytedance/UI-TARS-desktop/issues/842"&gt; &lt;img src="https://img.shields.io/badge/View-Examples-8B5CF6?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="Examples" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;View use cases built by the official and community&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üîß &lt;strong&gt;Reference&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/api/"&gt; &lt;img src="https://img.shields.io/badge/API-Reference-EF4444?style=for-the-badge&amp;amp;logo=book&amp;amp;logoColor=white" alt="API" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Complete technical reference&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;h2&gt;UI-TARS Desktop&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img alt="UI-TARS" width="260" src="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/apps/ui-tars/resources/icon.png" /&gt; &lt;/p&gt; 
&lt;p&gt;UI-TARS Desktop is a native GUI agent driven by &lt;a href="https://github.com/bytedance/UI-TARS"&gt;UI-TARS&lt;/a&gt; and Seed-1.5-VL/1.6 series models, available on your local computer and remote VM sandbox on cloud.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &amp;nbsp;&amp;nbsp; üìë &lt;a href="https://arxiv.org/abs/2501.12326"&gt;Paper&lt;/a&gt; &amp;nbsp;&amp;nbsp; | ü§ó &lt;a href="https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B"&gt;Hugging Face Models&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü´® &lt;a href="https://discord.gg/pTXwYVjfcs"&gt;Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü§ñ &lt;a href="https://www.modelscope.cn/collections/UI-TARS-bccb56fa1ef640"&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;br /&gt; üñ•Ô∏è Desktop Application &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; üëì &lt;a href="https://github.com/web-infra-dev/midscene"&gt;Midscene (use in browser)&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;Showcase&lt;/h3&gt; 
&lt;!-- // FIXME: Choose only two demo, one local computer and one remote computer showcase. --&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Instruction&lt;/th&gt; 
   &lt;th align="center"&gt;Local Operator&lt;/th&gt; 
   &lt;th align="center"&gt;Remote Operator&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Please help me open the autosave feature of VS Code and delay AutoSave operations for 500 milliseconds in the VS Code setting.&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/01e49b69-7070-46c8-b3e3-2aaaaec71800" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Could you help me check the latest open issue of the UI-TARS-Desktop project on GitHub?&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/3d159f54-d24a-4268-96c0-e149607e9199" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/072fb72d-7394-4bfa-95f5-4736e29f7e58" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ Natural language control powered by Vision-Language Model&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Screenshot and visual recognition support&lt;/li&gt; 
 &lt;li&gt;üéØ Precise mouse and keyboard control&lt;/li&gt; 
 &lt;li&gt;üíª Cross-platform support (Windows/MacOS/Browser)&lt;/li&gt; 
 &lt;li&gt;üîÑ Real-time feedback and status display&lt;/li&gt; 
 &lt;li&gt;üîê Private and secure - fully local processing&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è Effortless setup and intuitive remote operators&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/quick-start.md"&gt;Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our paper and code useful in your research, please consider giving a star &lt;span&gt;‚≠ê&lt;/span&gt; and citation &lt;span&gt;üìù&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@article{qin2025ui,
  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},
  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},
  journal={arXiv preprint arXiv:2501.12326},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>midday-ai/midday</title>
      <link>https://github.com/midday-ai/midday</link>
      <description>&lt;p&gt;Invoicing, Time tracking, File reconciliation, Storage, Financial Overview &amp; your own Assistant made for Freelancers&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/midday-ai/midday/main/github.png" alt="hero" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;&lt;b&gt;Midday&lt;/b&gt;&lt;/h1&gt; 
&lt;p align="center"&gt; Run your business smarter &lt;br /&gt; &lt;br /&gt; &lt;a href="https://go.midday.ai/anPiuRx"&gt;Discord&lt;/a&gt; ¬∑ &lt;a href="https://midday.ai"&gt;Website&lt;/a&gt; ¬∑ &lt;a href="https://github.com/midday-ai/midday/issues"&gt;Issues&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://go.midday.ai/K7GwMoQ"&gt; &lt;img src="https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&amp;amp;logo=supabase&amp;amp;logoColor=white" alt="Supabase" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;About Midday&lt;/h2&gt; 
&lt;p&gt;Midday is an all-in-one tool designed to help freelancers, contractors, consultants, and solo entrepreneurs manage their business operations more efficiently. It integrates various functions typically scattered across multiple platforms into a single, cohesive system.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Time Tracking&lt;/strong&gt;: Allows for live time tracking of projects to boost productivity and collaboration, providing insightful project overviews.&lt;br /&gt; &lt;strong&gt;Invoicing&lt;/strong&gt;: An upcoming feature that will enable users to create web-based invoices, collaborate in real-time, and synchronize projects seamlessly.&lt;br /&gt; &lt;strong&gt;Magic Inbox&lt;/strong&gt;: Automatically matches incoming invoices or receipts to the correct transactions, simplifying financial tracking and organization.&lt;br /&gt; &lt;strong&gt;Vault&lt;/strong&gt;: Secure storage for important files like contracts and agreements, keeping everything in one place for easy access‚Äã.&lt;br /&gt; &lt;strong&gt;Seamless Export&lt;/strong&gt;: Facilitates easy export of financial data, packaged neatly in CSV files for accountants.&lt;br /&gt; &lt;strong&gt;Assistant&lt;/strong&gt;: Provides tailored insights into financial situations, helping users understand spending patterns, cut costs, and find documents.&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;We are working on the documentation to get started with Midday for local development: &lt;a href="https://docs.midday.ai"&gt;https://docs.midday.ai&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;App Architecture&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Monorepo&lt;/li&gt; 
 &lt;li&gt;Bun&lt;/li&gt; 
 &lt;li&gt;React&lt;/li&gt; 
 &lt;li&gt;TypeScript&lt;/li&gt; 
 &lt;li&gt;Nextjs&lt;/li&gt; 
 &lt;li&gt;Supabase&lt;/li&gt; 
 &lt;li&gt;Shadcn&lt;/li&gt; 
 &lt;li&gt;Tauri&lt;/li&gt; 
 &lt;li&gt;Expo&lt;/li&gt; 
 &lt;li&gt;TailwindCSS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Hosting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supabase (database, storage, realtime, auth)&lt;/li&gt; 
 &lt;li&gt;Vercel (Website, Dashboard)&lt;/li&gt; 
 &lt;li&gt;Fly.io (API/tRPC)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Services&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Trigger.dev (background jobs)&lt;/li&gt; 
 &lt;li&gt;Resend (Transactional &amp;amp; Marketing)&lt;/li&gt; 
 &lt;li&gt;Novu (notifications)&lt;/li&gt; 
 &lt;li&gt;Github Actions (CI/CD)&lt;/li&gt; 
 &lt;li&gt;GoCardLess (Bank connection EU)&lt;/li&gt; 
 &lt;li&gt;Plaid (Bank connection in Canada and US)&lt;/li&gt; 
 &lt;li&gt;Teller (Bank connection in the US)&lt;/li&gt; 
 &lt;li&gt;OpenPanel (Events and Analytics)&lt;/li&gt; 
 &lt;li&gt;Polar (Payment processing)&lt;/li&gt; 
 &lt;li&gt;Typesense (Search)&lt;/li&gt; 
 &lt;li&gt;Mistral&lt;/li&gt; 
 &lt;li&gt;OpenAI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Repo Activity&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/96aae855e5dd87c30d53c1d154b37cf7aa5a89b3.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;strong&gt;&lt;a href="https://opensource.org/licenses/AGPL-3.0"&gt;AGPL-3.0&lt;/a&gt;&lt;/strong&gt; for non-commercial use.&lt;/p&gt; 
&lt;h3&gt;Commercial Use&lt;/h3&gt; 
&lt;p&gt;For commercial use or deployments requiring a setup fee, please contact us for a commercial license at &lt;a href="mailto:engineer@midday.ai"&gt;engineer@midday.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;By using this software, you agree to the terms of the license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ubicloud/ubicloud</title>
      <link>https://github.com/ubicloud/ubicloud</link>
      <description>&lt;p&gt;Open source alternative to AWS. Elastic compute, block storage (non replicated), firewall and load balancer, managed Postgres, K8s, AI inference, and IAM services.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/779e73bd-c260-4729-8430-c630628f1b6b" /&gt; &lt;/p&gt; 
&lt;h1&gt;Ubicloud &lt;a href="https://github.com/ubicloud/ubicloud/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/ubicloud/ubicloud/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ubicloud/ubicloud/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/ubicloud/ubicloud/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build" /&gt;&lt;/a&gt; &lt;a href="https://app.greptile.com/repo/ubicloud/ubicloud"&gt;&lt;img src="https://img.shields.io/badge/learn_with-greptile-%091B12?color=%091B12" alt="Learn this repo using Greptile" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;Ubicloud is an open source cloud that can run anywhere. Think of it as an open alternative to cloud providers, like what Linux is to proprietary operating systems.&lt;/p&gt; 
&lt;p&gt;Ubicloud provides IaaS cloud features on bare metal providers, such as Hetzner, Leaseweb, and AWS Bare Metal. You can set it up yourself on these providers or you can use our &lt;a href="https://console.ubicloud.com"&gt;managed service&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;h3&gt;Managed platform&lt;/h3&gt; 
&lt;p&gt;You can use Ubicloud without installing anything. When you do this, we pass along the underlying provider's benefits to you, such as price or location.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://console.ubicloud.com"&gt;https://console.ubicloud.com&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Build your own cloud&lt;/h3&gt; 
&lt;p&gt;You can also build your own cloud. To do this, start up Ubicloud's control plane and connect to its cloud console.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone git@github.com:ubicloud/ubicloud.git

# Generate secrets for demo
./demo/generate_env

# Run containers: db-migrator, app (web &amp;amp; respirate), postgresql
docker-compose -f demo/docker-compose.yml up

# Visit localhost:3000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The control plane is responsible for cloudifying bare metal Linux machines. The easiest way to build your own cloud is to lease instances from one of those providers. For example: &lt;a href="https://www.hetzner.com/sb"&gt;https://www.hetzner.com/sb&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Once you lease instance(s), update the &lt;code&gt;.env&lt;/code&gt; file with the following environment variables:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;HETZNER_USER&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;HETZNER_PASSWORD&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;HETZNER_SSH_PUBLIC_KEY&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;HETZNER_SSH_PRIVATE_KEY&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, run the following script for each instance to cloudify it. Currently, the script cloudifies bare metal instances leased from Hetzner. After you cloudify your instances, you can provision and manage cloud resources on these machines.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Enter hostname/IP and provider
docker exec -it ubicloud-app ./demo/cloudify_server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Later when you create VMs, Ubicloud will assign them IPv6 addresses. If your ISP doesn't support IPv6, please use a VPN or tunnel broker such as Mullvad or Hurricane Electric's &lt;a href="https://tunnelbroker.net/"&gt;https://tunnelbroker.net/&lt;/a&gt; to connect. Alternatively, you could lease IPv4 addresses from your provider and add them to your control plane.&lt;/p&gt; 
&lt;h2&gt;Why use it&lt;/h2&gt; 
&lt;p&gt;Public cloud providers like AWS, Azure, and Google Cloud have made life easier for start-ups and enterprises. But they are closed source, have you rent computers at a huge premium, and lock you in. Ubicloud offers an open source alternative, reduces your costs, and returns control of your infrastructure back to you. All without sacrificing the cloud's convenience.&lt;/p&gt; 
&lt;p&gt;Today, AWS offers about two hundred cloud services. Ultimately, we will implement 10% of the cloud services that make up 80% of that consumption.&lt;/p&gt; 
&lt;p&gt;Example workloads and reasons to use Ubicloud today include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You have an ephemeral workload like a CI/CD pipeline (we're integrating with GitHub Actions), or you'd like to run compute/memory heavy tests. Our managed cloud is ~3x cheaper than AWS, so you save on costs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You want a portable and simple app deployment service like &lt;a href="https://github.com/basecamp/kamal"&gt;Kamal&lt;/a&gt;. We're moving Ubicloud's control plane from Heroku to Kamal; and we want to provide open and portable services for Kamal's dependencies in the process.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You have bare metal machines sitting somewhere. You'd like to build your own cloud for portability, security, or compliance reasons.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;You can provide us your feedback, get help, or ask us questions regarding your Ubicloud installations in the &lt;a href="https://github.com/ubicloud/ubicloud/discussions"&gt;Community Forum&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We follow an established architectural pattern in building public cloud services. A control plane manages a data plane, where the data plane leverages open source software. You can find our current cloud components / services below.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Elastic Compute&lt;/strong&gt;: Our control plane communicates with Linux bare metal servers using SSH. We use &lt;a href="https://github.com/cloud-hypervisor/cloud-hypervisor"&gt;Cloud Hypervisor&lt;/a&gt; as our virtual machine monitor (VMM); and each instance of the VMM is contained within Linux namespaces for further isolation / security.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Networking&lt;/strong&gt;: We use &lt;a href="https://en.wikipedia.org/wiki/IPsec"&gt;IPsec&lt;/a&gt; tunneling to establish an encrypted and private network environment. We support IPv4 and IPv6 in a dual-stack setup and provide both public and private networking. For security, each customer‚Äôs VMs operate in their own networking namespace. For &lt;a href="https://www.ubicloud.com/blog/ubicloud-firewalls-how-linux-nftables-enables-flexible-rules"&gt;firewalls&lt;/a&gt; and &lt;a href="https://www.ubicloud.com/blog/ubicloud-load-balancer-simple-and-cost-free"&gt;load balancers&lt;/a&gt;, we use Linux nftables.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Block Storage, non replicated&lt;/strong&gt;: We use Storage Performance Development Toolkit (&lt;a href="https://spdk.io"&gt;SPDK&lt;/a&gt;) to provide virtualized block storage to VMs. SPDK enables us to add enterprise features such as snapshot and replication in the future. We follow security best practices and encrypt the data encryption key itself.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Attribute-Based Access Control (ABAC)&lt;/strong&gt;: With ABAC, you can define attributes, roles, and permissions for users and give them fine-grained access to resources. You can read more about our &lt;a href="https://raw.githubusercontent.com/ubicloud/ubicloud/main/doc/authorization.md"&gt;ABAC design here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;What's Next?&lt;/strong&gt;: We're planning to work on a managed K8s or metrics/monitoring service next. If you have a workload that would benefit from a specific cloud service, please get in touch with us through our &lt;a href="https://github.com/ubicloud/ubicloud/discussions"&gt;Community Forum&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Control plane: Manages data plane services and resources. This is a Ruby program that stores its data in Postgres. We use the &lt;a href="https://roda.jeremyevans.net/"&gt;Roda&lt;/a&gt; framework to serve HTTP requests and &lt;a href="http://sequel.jeremyevans.net/"&gt;Sequel&lt;/a&gt; to access the database. We manage web authentication with &lt;a href="http://rodauth.jeremyevans.net/"&gt;Rodauth&lt;/a&gt;. We communicate with data plane servers using SSH, via the library &lt;a href="https://github.com/net-ssh/net-ssh"&gt;net-ssh&lt;/a&gt;. For our tests, we use &lt;a href="https://rspec.info/"&gt;RSpec&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Cloud console: Server-side web app served by the Roda framework. For the visual design, we use &lt;a href="https://tailwindcss.com"&gt;Tailwind CSS&lt;/a&gt; with components from &lt;a href="https://tailwindui.com"&gt;Tailwind UI&lt;/a&gt;. We also use jQuery for interactivity.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you‚Äôd like to start hacking with Ubicloud, any method of obtaining Ruby and Postgres versions is acceptable. If you have no opinion on this, our development team uses &lt;code&gt;mise&lt;/code&gt; as &lt;a href="https://raw.githubusercontent.com/ubicloud/ubicloud/main/DEVELOPERS.md"&gt;documented here in detail&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://greptile.com/"&gt;Greptile&lt;/a&gt; provides an AI/LLM that indexes Ubicloud's source code &lt;a href="https://learnthisrepo.com/ubicloud"&gt;can answer questions about it&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Do you have any experience with building this sort of thing?&lt;/h3&gt; 
&lt;p&gt;Our founding team comes from Azure; and worked at Amazon and Heroku before that. We also have start-up experience. We were co-founders and founding team members at &lt;a href="https://github.com/citusdata/citus"&gt;Citus Data&lt;/a&gt;, &lt;a href="https://news.ycombinator.com/item?id=18990469"&gt;which got acquired by Microsoft&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;How is this different than OpenStack?&lt;/h3&gt; 
&lt;p&gt;We see three differences. First, Ubicloud is available as a managed service (vs boxed software). This way, you can get started in minutes rather than weeks. Since Ubicloud is designed for multi-tenancy, it comes with built-in features such as encryption at rest and in transit, virtual networking, secrets rotation, etc.&lt;/p&gt; 
&lt;p&gt;Second, we're initially targeting developers. This -we hope- will give us fast feedback cycles and enable us to have 6 key services in GA form in the next two years. OpenStack is still primarily used for 3 cloud services.&lt;/p&gt; 
&lt;p&gt;Last, we're designing for simplicity. With OpenStack, you pick between 10 hypervisors, 10 S3 implementations, and 5 block storage implementations. The software needs to work in a way where all of these implementations are compatible with each other. That leads to consultant-ware. We'll take a more opinionated approach with Ubicloud.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pathwaycom/pathway</title>
      <link>https://github.com/pathwaycom/pathway</link>
      <description>&lt;p&gt;Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://pathway.com/"&gt; &lt;img src="https://pathway.com/logo-light.svg?sanitize=true" /&gt; &lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;a href="https://trendshift.io/repositories/10388" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10388" alt="pathwaycom%2Fpathway | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg?sanitize=true" alt="ubuntu" /&gt; &lt;br /&gt; &lt;/a&gt;&lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/release.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg?sanitize=true" alt="Last release" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://badge.fury.io/py/pathway.svg?sanitize=true" alt="PyPI version" height="18" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://static.pepy.tech/badge/pathway" alt="PyPI downloads" height="18" /&gt;&lt;/a&gt; &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt; &lt;img src="https://img.shields.io/badge/license-BSL-green" alt="License: BSL" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://discord.gg/pathway"&gt; &lt;img src="https://img.shields.io/discord/1042405378304004156?logo=discord" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=pathway_com"&gt; &lt;img src="https://img.shields.io/twitter/follow/pathwaycom" alt="follow on Twitter" /&gt;&lt;/a&gt; &lt;a href="https://linkedin.com/company/pathway"&gt; &lt;img src="https://img.shields.io/badge/pathway-0077B5?style=social&amp;amp;logo=linkedin" alt="follow on LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dylanhogg/awesome-python/raw/main/README.md"&gt; &lt;img src="https://awesome.re/badge.svg?sanitize=true" alt="Awesome Python" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/pathway"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF" alt="Pathway Guru" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#deployment"&gt;Deployment&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#resources"&gt;Documentation and Support&lt;/a&gt; | &lt;a href="https://pathway.com/blog/"&gt;Blog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Pathway&lt;a id="pathway"&gt; Live Data Framework&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pathway.com"&gt;Pathway&lt;/a&gt; is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt; 
&lt;p&gt;Pathway comes with an &lt;strong&gt;easy-to-use Python API&lt;/strong&gt;, allowing you to seamlessly integrate your favorite Python ML libraries. Pathway code is versatile and robust: &lt;strong&gt;you can use it in both development and production environments, handling both batch and streaming data effectively&lt;/strong&gt;. The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.&lt;/p&gt; 
&lt;p&gt;Pathway is powered by a &lt;strong&gt;scalable Rust engine&lt;/strong&gt; based on Differential Dataflow and performs incremental computation. Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations. All the pipeline is kept in memory and can be easily deployed with &lt;strong&gt;Docker and Kubernetes&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;You can install Pathway with pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For any questions, you will find the community and team behind the project &lt;a href="https://discord.com/invite/pathway"&gt;on Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Use-cases and templates&lt;/h2&gt; 
&lt;p&gt;Ready to see what Pathway can do?&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pathway.com/developers/templates"&gt;Try one of our easy-to-run examples&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!&lt;/p&gt; 
&lt;h3&gt;Event processing and real-time analytics pipelines&lt;/h3&gt; 
&lt;p&gt;With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/kafka-etl"&gt;Showcase: Real-time ETL.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/realtime-log-monitoring"&gt;Showcase: Event-driven pipelines with alerting.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/linear_regression_with_kafka/"&gt;Showcase: Realtime analytics.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming"&gt;Docs: Switch from batch to streaming.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;AI Pipelines&lt;/h3&gt; 
&lt;p&gt;Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/overview"&gt;LLM xpack documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Don't hesitate to try one of our runnable examples featuring LLM tooling. You can find such examples &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/llm-examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/unstructured-to-structured/"&gt;Template: Unstructured data to SQL on-the-fly.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/private-rag-ollama-mistral"&gt;Template: Private RAG with Ollama and Mistral AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/adaptive-rag"&gt;Template: Adaptive RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/multimodal-rag"&gt;Template: Multimodal RAG with gpt-4o&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A wide range of connectors&lt;/strong&gt;: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stateless and stateful transformations&lt;/strong&gt;: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistence&lt;/strong&gt;: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the "at least once" consistency while the enterprise version provides the "exactly once" consistency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Rust engine&lt;/strong&gt;: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM helpers&lt;/strong&gt;: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;a id="getting-started"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;a id="installation"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Pathway requires Python 3.10 or above.&lt;/p&gt; 
&lt;p&gt;You can install the current release of Pathway using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚ö†Ô∏è Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.&lt;/p&gt; 
&lt;h3&gt;Example: computing the sum of positive values in real time.&lt;a id="example"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  "./input/",
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&amp;gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, "output.jsonl")

# Run the computation
pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run Pathway &lt;a href="https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing"&gt;in Google Colab&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find more examples &lt;a href="https://github.com/pathwaycom/pathway/tree/main/examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deployment&lt;a id="deployment"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Locally&lt;a id="running-pathway-locally"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;To use Pathway, you only need to import it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then run your Pathway project (say, &lt;code&gt;main.py&lt;/code&gt;) just like a normal Python script: &lt;code&gt;$ python main.py&lt;/code&gt;. Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages.&lt;/p&gt; 
&lt;img src="https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png" width="1326" alt="Pathway dashboard" /&gt; 
&lt;p&gt;Alternatively, you can use the pathway'ish version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pathway natively supports multithreading. To launch your application with 3 threads, you can do as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn --threads 3 python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To jumpstart a Pathway project, you can use our &lt;a href="https://github.com/pathwaycom/cookiecutter-pathway"&gt;cookiecutter template&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;a id="docker"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;You can easily run Pathway using docker.&lt;/p&gt; 
&lt;h4&gt;Pathway image&lt;/h4&gt; 
&lt;p&gt;You can use the &lt;a href="https://hub.docker.com/r/pathwaycom/pathway"&gt;Pathway docker image&lt;/a&gt;, using a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ "python", "./your-script.py" ]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then build and run the Docker image:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run a single Python script&lt;/h4&gt; 
&lt;p&gt;When dealing with single-file projects, creating a full-fledged &lt;code&gt;Dockerfile&lt;/code&gt; might seem unnecessary. In such scenarios, you can execute a Python script directly using the Pathway Docker image. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker run -it --rm --name my-pathway-app -v "$PWD":/app pathwaycom/pathway:latest python my-pathway-app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python docker image&lt;/h4&gt; 
&lt;p&gt;You can also use a standard Python image and install Pathway using pip with a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD ["python", "-u", "pathway-script.py"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Kubernetes and cloud&lt;a id="k8s"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Docker containers are ideally suited for deployment on the cloud with Kubernetes. If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise. Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics. It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.&lt;/p&gt; 
&lt;p&gt;You can easily deploy Pathway using services like Render: see &lt;a href="https://pathway.com/developers/user-guide/deployment/render-deploy/"&gt;how to deploy Pathway in a few clicks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested, don't hesitate to &lt;a href="mailto:contact@pathway.com"&gt;contact us&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;a id="performance"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).&lt;/p&gt; 
&lt;p&gt;If you are curious, here are &lt;a href="https://github.com/pathwaycom/pathway-benchmarks"&gt;some benchmarks to play with&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png" width="1326" alt="WordCount Graph" /&gt; 
&lt;h2&gt;Documentation and Support&lt;a id="resources"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The entire documentation of Pathway is available at &lt;a href="https://pathway.com/developers/user-guide/introduction/welcome"&gt;pathway.com/developers/&lt;/a&gt;, including the &lt;a href="https://pathway.com/developers/api-docs/pathway"&gt;API Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have any question, don't hesitate to &lt;a href="https://github.com/pathwaycom/pathway/issues"&gt;open an issue on GitHub&lt;/a&gt;, join us on &lt;a href="https://discord.com/invite/pathway"&gt;Discord&lt;/a&gt;, or send us an email at &lt;a href="mailto:contact@pathway.com"&gt;contact@pathway.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;a id="license"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is distributed on a &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt;BSL 1.1 License&lt;/a&gt; which allows for unlimited non-commercial use, as well as use of the Pathway package &lt;a href="https://pathway.com/license/"&gt;for most commercial purposes&lt;/a&gt;, free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some &lt;a href="https://github.com/pathwaycom"&gt;public repos&lt;/a&gt; which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.&lt;/p&gt; 
&lt;h2&gt;Contribution guidelines&lt;a id="contribution-guidelines"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license.&lt;/p&gt; 
&lt;p&gt;For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don't hesitate to engage with Pathway's &lt;a href="https://discord.gg/pathway"&gt;Discord community&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>redis/go-redis</title>
      <link>https://github.com/redis/go-redis</link>
      <description>&lt;p&gt;Redis Go client&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Redis client for Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/redis/go-redis/actions"&gt;&lt;img src="https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build workflow" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/redis/go-redis/v9" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;a href="https://redis.uptrace.dev/"&gt;&lt;img src="https://img.shields.io/badge/redis-documentation-informational" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/redis/go-redis/v9"&gt;&lt;img src="https://goreportcard.com/badge/github.com/redis/go-redis/v9" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/github/redis/go-redis"&gt;&lt;img src="https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;&lt;img src="https://img.shields.io/discord/697882427875393627.svg?style=social&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://www.twitch.tv/redisinc"&gt;&lt;img src="https://img.shields.io/twitch/status/redisinc?style=social" alt="Twitch" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/redisinc"&gt;&lt;img src="https://img.shields.io/youtube/channel/views/UCD78lHSwYqMlyetR0_P4Vig?style=social" alt="YouTube" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/redisinc"&gt;&lt;img src="https://img.shields.io/twitter/follow/redisinc?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/go-redis"&gt;&lt;img src="https://img.shields.io/stackexchange/stackoverflow/t/go-redis?style=social&amp;amp;logo=stackoverflow&amp;amp;label=Stackoverflow" alt="Stack Exchange questions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Supported versions&lt;/h2&gt; 
&lt;p&gt;In &lt;code&gt;go-redis&lt;/code&gt; we are aiming to support the last three releases of Redis. Currently, this means we do support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.2/00-RELEASENOTES"&gt;Redis 7.2&lt;/a&gt; - using Redis Stack 7.2 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.4/00-RELEASENOTES"&gt;Redis 7.4&lt;/a&gt; - using Redis Stack 7.4 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES"&gt;Redis 8.0&lt;/a&gt; - using Redis CE 8.0 where modules are included&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.2/00-RELEASENOTES"&gt;Redis 8.2&lt;/a&gt; - using Redis CE 8.2 where modules are included&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although the &lt;code&gt;go.mod&lt;/code&gt; states it requires at minimum &lt;code&gt;go 1.18&lt;/code&gt;, our CI is configured to run the tests against all three versions of Redis and latest two versions of Go (&lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt;, &lt;a href="https://go.dev/doc/devel/release#go1.24.0"&gt;1.24&lt;/a&gt;). We observe that some modules related test may not pass with Redis Stack 7.2 and some commands are changed with Redis CE 8.0. Please do refer to the documentation and the tests if you experience any issues. We do plan to update the go version in the &lt;code&gt;go.mod&lt;/code&gt; to &lt;code&gt;go 1.24&lt;/code&gt; in one of the next releases.&lt;/p&gt; 
&lt;h2&gt;How do I Redis?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://university.redis.com/"&gt;Learn for free at Redis University&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://launchpad.redis.com/"&gt;Build faster with the Redis Launchpad&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/try-free/"&gt;Try the Redis Cloud&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developer.redis.com/"&gt;Dive in developer tutorials&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/community/"&gt;Join the Redis community&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/company/careers/jobs/"&gt;Work at Redis&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/zh/"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/redis/go-redis/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9"&gt;Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redismock"&gt;Redis Mock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bsm/redislock"&gt;Distributed Locks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/cache"&gt;Redis Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redis_rate"&gt;Rate limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This client also works with &lt;a href="https://github.com/apache/incubator-kvrocks"&gt;Kvrocks&lt;/a&gt;, a distributed key value NoSQL database that uses RocksDB as storage engine and is compatible with Redis protocol.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Redis commands except QUIT and SYNC.&lt;/li&gt; 
 &lt;li&gt;Automatic connection pooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#1-streaming-credentials-provider-highest-priority"&gt;StreamingCredentialsProvider (e.g. entra id, oauth)&lt;/a&gt; (experimental)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pubsub.html"&gt;Pub/Sub&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pipelines.html"&gt;Pipelines and transactions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/lua-scripting.html"&gt;Scripting&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-sentinel.html"&gt;Redis Sentinel&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-cluster.html"&gt;Redis Cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/ring.html"&gt;Redis Ring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/redis-performance-monitoring.html"&gt;Redis Performance Monitoring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.io/docs/data-types/probabilistic/"&gt;Redis Probabilistic [RedisStack]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#custom-buffer-sizes"&gt;Customizable read and write buffers size.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;go-redis supports 2 last Go versions and requires a Go version with &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;modules&lt;/a&gt; support. So make sure to initialize a Go module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go mod init github.com/my/repo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install go-redis/&lt;strong&gt;v9&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go get github.com/redis/go-redis/v9
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "context"
    "fmt"

    "github.com/redis/go-redis/v9"
)

var ctx = context.Background()

func ExampleClient() {
    rdb := redis.NewClient(&amp;amp;redis.Options{
        Addr:     "localhost:6379",
        Password: "", // no password set
        DB:       0,  // use default DB
    })

    err := rdb.Set(ctx, "key", "value", 0).Err()
    if err != nil {
        panic(err)
    }

    val, err := rdb.Get(ctx, "key").Result()
    if err != nil {
        panic(err)
    }
    fmt.Println("key", val)

    val2, err := rdb.Get(ctx, "key2").Result()
    if err == redis.Nil {
        fmt.Println("key2 does not exist")
    } else if err != nil {
        panic(err)
    } else {
        fmt.Println("key2", val2)
    }
    // Output: key value
    // key2 does not exist
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;The Redis client supports multiple ways to provide authentication credentials, with a clear priority order. Here are the available options:&lt;/p&gt; 
&lt;h4&gt;1. Streaming Credentials Provider (Highest Priority) - Experimental feature&lt;/h4&gt; 
&lt;p&gt;The streaming credentials provider allows for dynamic credential updates during the connection lifetime. This is particularly useful for managed identity services and token-based authentication.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type StreamingCredentialsProvider interface {
    Subscribe(listener CredentialsListener) (Credentials, UnsubscribeFunc, error)
}

type CredentialsListener interface {
    OnNext(credentials Credentials)  // Called when credentials are updated
    OnError(err error)              // Called when an error occurs
}

type Credentials interface {
    BasicAuth() (username string, password string)
    RawCredentials() string
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    StreamingCredentialsProvider: &amp;amp;MyCredentialsProvider{},
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The streaming credentials provider can be used with &lt;a href="https://github.com/redis/go-redis-entraid"&gt;go-redis-entraid&lt;/a&gt; to enable Entra ID (formerly Azure AD) authentication. This allows for seamless integration with Azure's managed identity services and token-based authentication.&lt;/p&gt; 
&lt;p&gt;Example with Entra ID:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis-entraid"
)

// Create an Entra ID credentials provider
provider := entraid.NewDefaultAzureIdentityProvider()

// Configure Redis client with Entra ID authentication
rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "your-redis-server.redis.cache.windows.net:6380",
    StreamingCredentialsProvider: provider,
    TLSConfig: &amp;amp;tls.Config{
        MinVersion: tls.VersionTLS12,
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Context-based Credentials Provider&lt;/h4&gt; 
&lt;p&gt;The context-based provider allows credentials to be determined at the time of each operation, using the context.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProviderContext: func(ctx context.Context) (string, string, error) {
        // Return username, password, and any error
        return "user", "pass", nil
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Regular Credentials Provider&lt;/h4&gt; 
&lt;p&gt;A simple function-based provider that returns static credentials.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProvider: func() (string, string) {
        // Return username and password
        return "user", "pass"
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Username/Password Fields (Lowest Priority)&lt;/h4&gt; 
&lt;p&gt;The most basic way to provide credentials is through the &lt;code&gt;Username&lt;/code&gt; and &lt;code&gt;Password&lt;/code&gt; fields in the options.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Username: "user",
    Password: "pass",
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Priority Order&lt;/h4&gt; 
&lt;p&gt;The client will use credentials in the following priority order:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Streaming Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Context-based Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Regular Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Username/Password fields (if set)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If none of these are set, the client will attempt to connect without authentication.&lt;/p&gt; 
&lt;h3&gt;Protocol Version&lt;/h3&gt; 
&lt;p&gt;The client supports both RESP2 and RESP3 protocols. You can specify the protocol version in the options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Password: "", // no password set
    DB:       0,  // use default DB
    Protocol: 3,  // specify 2 for RESP 2 or 3 for RESP 3
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting via a redis url&lt;/h3&gt; 
&lt;p&gt;go-redis also supports connecting via the &lt;a href="https://github.com/redis/redis-specifications/tree/master/uri/redis.txt"&gt;redis uri specification&lt;/a&gt;. The example below demonstrates how the connection can easily be configured using a string, adhering to this specification.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
)

func ExampleClient() *redis.Client {
    url := "redis://user:password@localhost:6379/0?protocol=3"
    opts, err := redis.ParseURL(url)
    if err != nil {
        panic(err)
    }

    return redis.NewClient(opts)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instrument with OpenTelemetry&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis/extra/redisotel/v9"
    "errors"
)

func main() {
    ...
    rdb := redis.NewClient(&amp;amp;redis.Options{...})

    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {
        log.Fatal(err)
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Buffer Size Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis uses 0.5MiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis supports extending the client identification phase to allow projects to send their own custom client identification.&lt;/p&gt; 
&lt;h4&gt;Default Client Identification&lt;/h4&gt; 
&lt;p&gt;By default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is "fire and forget", meaning it should fail silently, in the case that the redis server does not support this feature.&lt;/p&gt; 
&lt;h4&gt;Disabling Identity Verification&lt;/h4&gt; 
&lt;p&gt;When connection identity verification is not required or needs to be explicitly disabled, a &lt;code&gt;DisableIdentity&lt;/code&gt; configuration option exists. Initially there was a typo and the option was named &lt;code&gt;DisableIndentity&lt;/code&gt; instead of &lt;code&gt;DisableIdentity&lt;/code&gt;. The misspelled option is marked as Deprecated and will be removed in V10 of this library. Although both options will work at the moment, the correct option is &lt;code&gt;DisableIdentity&lt;/code&gt;. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.&lt;/p&gt; 
&lt;p&gt;To disable verification, set the &lt;code&gt;DisableIdentity&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt; in the Redis client options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    Password:        "",
    DB:              0,
    DisableIdentity: true, // Disable set-info on connect
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Unstable RESP3 Structures for RediSearch Commands&lt;/h4&gt; 
&lt;p&gt;When integrating Redis with application functionalities using RESP3, it's important to note that some response structures aren't final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.&lt;/p&gt; 
&lt;p&gt;To enable unstable RESP3, set the option in your client configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;redis.NewClient(&amp;amp;redis.Options{
			UnstableResp3: true,
		})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When UnstableResp3 mode is enabled, it's necessary to use RawResult() and RawVal() to retrieve a raw data. Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn't have any affect on them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;res1, err := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawResult()
val1 := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawVal()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redis-Search Default Dialect&lt;/h4&gt; 
&lt;p&gt;In the Redis-Search module, &lt;strong&gt;the default dialect is 2&lt;/strong&gt;. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;	res2, err := rdb.FTSearchWithArgs(ctx,
		"idx:bicycle",
		"@pickup_zone:[CONTAINS $bike]",
		&amp;amp;redis.FTSearchOptions{
			Params: map[string]interface{}{
				"bike": "POINT(-0.1278 51.5074)",
			},
			DialectVersion: 3,
		},
	).Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find further details in the &lt;a href="https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/"&gt;query dialect documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Custom buffer sizes&lt;/h4&gt; 
&lt;p&gt;Prior to v9.12, the buffer size was the default go value of 4096 bytes. Starting from v9.12, go-redis uses 256KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: If you experience any issues with the default buffer sizes, please try setting them to the go default of 4096 bytes.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub. We appreciate your help in making go-redis better for everyone. If you are interested in contributing to the go-redis library, please check out our &lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; for more information on how to get started.&lt;/p&gt; 
&lt;h2&gt;Look and feel&lt;/h2&gt; 
&lt;p&gt;Some corner cases:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// SET key value EX 10 NX
set, err := rdb.SetNX(ctx, "key", "value", 10*time.Second).Result()

// SET key value keepttl NX
set, err := rdb.SetNX(ctx, "key", "value", redis.KeepTTL).Result()

// SORT list LIMIT 0 2 ASC
vals, err := rdb.Sort(ctx, "list", &amp;amp;redis.Sort{Offset: 0, Count: 2, Order: "ASC"}).Result()

// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2
vals, err := rdb.ZRangeByScoreWithScores(ctx, "zset", &amp;amp;redis.ZRangeBy{
    Min: "-inf",
    Max: "+inf",
    Offset: 0,
    Count: 2,
}).Result()

// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM
vals, err := rdb.ZInterStore(ctx, "out", &amp;amp;redis.ZStore{
    Keys: []string{"zset1", "zset2"},
    Weights: []int64{2, 3}
}).Result()

// EVAL "return {KEYS[1],ARGV[1]}" 1 "key" "hello"
vals, err := rdb.Eval(ctx, "return {KEYS[1],ARGV[1]}", []string{"key"}, "hello").Result()

// custom command
res, err := rdb.Do(ctx, "set", "key", "value").Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Run the test&lt;/h2&gt; 
&lt;p&gt;go-redis will start a redis-server and run the test cases.&lt;/p&gt; 
&lt;p&gt;The paths of redis-server bin file and redis config file are defined in &lt;code&gt;main_test.go&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;var (
	redisServerBin, _  = filepath.Abs(filepath.Join("testdata", "redis", "src", "redis-server"))
	redisServerConf, _ = filepath.Abs(filepath.Join("testdata", "redis", "redis.conf"))
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For local testing, you can change the variables to refer to your local files, or create a soft link to the corresponding folder for redis-server and copy the config file to &lt;code&gt;testdata/redis/&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ln -s /usr/bin/redis-server ./go-redis/testdata/redis/src
cp ./go-redis/testdata/redis.conf ./go-redis/testdata/redis/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Lastly, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Another option is to run your specific tests with an already running redis. The example below, tests against a redis running on port 9999.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;REDIS_PORT=9999 go test &amp;lt;your options&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;See also&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev"&gt;Golang ORM&lt;/a&gt; for PostgreSQL, MySQL, MSSQL, and SQLite&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev/postgres/"&gt;Golang PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bunrouter.uptrace.dev/"&gt;Golang HTTP router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/uptrace/go-clickhouse"&gt;Golang ClickHouse ORM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The go-redis project was originally initiated by &lt;span&gt;‚≠ê&lt;/span&gt; &lt;a href="https://github.com/uptrace/uptrace"&gt;&lt;strong&gt;uptrace/uptrace&lt;/strong&gt;&lt;/a&gt;. Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can use it to monitor applications and set up automatic alerts to receive notifications via email, Slack, Telegram, and others.&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/redis/go-redis/tree/master/example/otel"&gt;OpenTelemetry&lt;/a&gt; example which demonstrates how you can use Uptrace to monitor go-redis.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thanks to all the people who already contributed!&lt;/p&gt; 
&lt;a href="https://github.com/redis/go-redis/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=redis/go-redis" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>external-secrets/external-secrets</title>
      <link>https://github.com/external-secrets/external-secrets</link>
      <description>&lt;p&gt;External Secrets Operator reads information from a third-party service like AWS Secrets Manager and automatically injects the values as Kubernetes Secrets.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/external-secrets/external-secrets/main/assets/eso-logo-large.png" width="30%" align="center" alt="external-secrets" /&gt; &lt;/p&gt; 
&lt;h2&gt;Project Releases Paused Until Maintainer Team is Rebuilt ‚ö†Ô∏è&lt;/h2&gt; 
&lt;p&gt;The current maintainers of External Secrets Operator decided to pause official SemVer releases.&lt;/p&gt; 
&lt;p&gt;Despite strong adoption and a growing user base, the project is currently maintained by a very small core team. This limited capacity makes it unsustainable to continue regular development, community support, and release management.&lt;/p&gt; 
&lt;p&gt;To ensure the long-term health of the project, we are temporarily pausing all official releases - including new features, patches, and published container images - until we have at least five consistent, long-term community maintainers.&lt;/p&gt; 
&lt;h3&gt;What does this mean?&lt;/h3&gt; 
&lt;p&gt;‚úÖ We will continue reviewing and merging community PRs.&lt;/p&gt; 
&lt;p&gt;‚úÖ Contributions will be available on the main branch.&lt;/p&gt; 
&lt;p&gt;‚ùå We will not provide support via GitHub Discussions, Slack, or issue comments.&lt;/p&gt; 
&lt;p&gt;‚ùå We will not publish any new releases (major, minor, or patch), including 0.19.x and 1.0.x.&lt;/p&gt; 
&lt;h3&gt;How You Can Help&lt;/h3&gt; 
&lt;p&gt;If your company or team relies on External Secrets Operator, please consider contributing back - especially if you work for an organization with a defined open source strategy.&lt;/p&gt; 
&lt;p&gt;‚û°Ô∏è To get involved, please fill out &lt;a href="https://forms.gle/utsekWEBwrfo1dHs8"&gt;this form&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also check out the &lt;a href="https://github.com/external-secrets/external-secrets/raw/main/GOVERNANCE.md"&gt;Governance document&lt;/a&gt; or join the &lt;a href="https://github.com/external-secrets/external-secrets/issues/5084"&gt;GitHub Issue&lt;/a&gt; for more context.&lt;/p&gt; 
&lt;p&gt;We truly regret having to take this step, but it's necessary to raise awareness among the many organizations relying on External Secrets in production. We need your support to continue moving the project forward.&lt;/p&gt; 
&lt;p&gt;Thank you for your understanding and for being part of this community.&lt;/p&gt; 
&lt;h1&gt;External Secrets&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/external-secrets/external-secrets/actions/workflows/ci.yml/badge.svg?branch=main" alt="ci" /&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/5947"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/5327/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/external-secrets/external-secrets"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/external-secrets/external-secrets/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/external-secrets/external-secrets"&gt;&lt;img src="https://goreportcard.com/badge/github.com/external-secrets/external-secrets" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/helm/external-secrets-operator/external-secrets"&gt;&lt;img alt="Artifact Hub" src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/external-secrets" /&gt;&lt;/a&gt; &lt;a href="https://operatorhub.io/operator/external-secrets-operator"&gt;&lt;img alt="operatorhub.io" src="https://img.shields.io/badge/operatorhub.io-external--secrets-brightgreen" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;External Secrets Operator&lt;/strong&gt; is a Kubernetes operator that integrates external secret management systems like &lt;a href="https://aws.amazon.com/secrets-manager/"&gt;AWS Secrets Manager&lt;/a&gt;, &lt;a href="https://www.vaultproject.io/"&gt;HashiCorp Vault&lt;/a&gt;, &lt;a href="https://cloud.google.com/secret-manager"&gt;Google Secrets Manager&lt;/a&gt;, &lt;a href="https://azure.microsoft.com/en-us/services/key-vault/"&gt;Azure Key Vault&lt;/a&gt;, &lt;a href="https://www.ibm.com/cloud/secrets-manager"&gt;IBM Cloud Secrets Manager&lt;/a&gt;, &lt;a href="https://akeyless.io"&gt;Akeyless&lt;/a&gt;, &lt;a href="https://www.conjur.org"&gt;CyberArk Conjur&lt;/a&gt;, &lt;a href="https://www.pulumi.com/product/esc/"&gt;Pulumi ESC&lt;/a&gt; and many more. The operator reads information from external APIs and automatically injects the values into a &lt;a href="https://kubernetes.io/docs/concepts/configuration/secret/"&gt;Kubernetes Secret&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Multiple people and organizations are joining efforts to create a single External Secrets solution based on existing projects. If you are curious about the origins of this project, check out &lt;a href="https://github.com/external-secrets/kubernetes-external-secrets/issues/47"&gt;this issue&lt;/a&gt; and &lt;a href="https://github.com/external-secrets/kubernetes-external-secrets/pull/477"&gt;this PR&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;External Secrets Operator guides and reference documentation is available at &lt;a href="https://external-secrets.io"&gt;external-secrets.io&lt;/a&gt;. Also see our &lt;a href="https://external-secrets.io/main/introduction/stability-support/"&gt;stability and support&lt;/a&gt; policy.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and encourage contributions to this project! Please read the &lt;a href="https://www.external-secrets.io/main/contributing/devguide/"&gt;Developer&lt;/a&gt; and &lt;a href="https://www.external-secrets.io/main/contributing/process/"&gt;Contribution process&lt;/a&gt; guides. Also make sure to check the &lt;a href="https://www.external-secrets.io/main/contributing/coc/"&gt;Code of Conduct&lt;/a&gt; and adhere to its guidelines.&lt;/p&gt; 
&lt;h3&gt;Sponsoring&lt;/h3&gt; 
&lt;p&gt;Please consider sponsoring this project, there are many ways you can help us with: engineering time, providing infrastructure, donating money, etc. We are open to cooperations, feel free to approach as and we discuss how this could look like. We can keep your contribution anonymized if that's required (depending on the type of contribution), and anonymous donations are possible inside &lt;a href="https://opencollective.com/external-secrets-org"&gt;Opencollective&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Bi-weekly Development Meeting&lt;/h2&gt; 
&lt;p&gt;We host our development meeting every odd wednesday on &lt;a href="https://meet.jit.si/eso-community-meeting"&gt;Jitsi&lt;/a&gt;. We run the meeting with alternating times &lt;a href="https://dateful.com/time-zone-converter?t=20:00&amp;amp;tz=Europe/Berlin"&gt;8:00 PM Berlin Time&lt;/a&gt; and &lt;a href="https://dateful.com/time-zone-converter?t=13:00&amp;amp;tz=Europe/Berlin"&gt;1:00 PM Berlin Time&lt;/a&gt;, we'll announce the time in our &lt;a href="https://kubernetes.slack.com/messages/external-secrets"&gt;Kubernetes Slack channel&lt;/a&gt;. Meeting notes are recorded on &lt;a href="https://hackmd.io/GSGEpTVdRZCP6LDxV3FHJA"&gt;hackmd&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Anyone is welcome to join. Feel free to ask questions, request feedback, raise awareness for an issue, or just say hi. ;)&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;Please report vulnerabilities by email to &lt;a href="mailto:cncf-ExternalSecretsOp-maintainers@lists.cncf.io"&gt;cncf-ExternalSecretsOp-maintainers@lists.cncf.io&lt;/a&gt;. Also see our &lt;a href="https://raw.githubusercontent.com/external-secrets/external-secrets/main/SECURITY.md"&gt;SECURITY.md file&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;software bill of materials&lt;/h2&gt; 
&lt;p&gt;We attach SBOM and provenance file to our GitHub release. Also, they are attached to container images.&lt;/p&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;Please create a PR and add your company or project to our &lt;a href="https://raw.githubusercontent.com/external-secrets/external-secrets/main/ADOPTERS.md"&gt;ADOPTERS.md file&lt;/a&gt; if you are using our project!&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;You can find the roadmap in our documentation: &lt;a href="https://external-secrets.io/main/contributing/roadmap/"&gt;https://external-secrets.io/main/contributing/roadmap/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Kicked off by&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/external-secrets/external-secrets/main/assets/Godaddylogo_2020.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsored by&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/external-secrets/external-secrets/main/assets/ESI_Logo.svg?sanitize=true" alt="External Secrets Inc." /&gt; &lt;img src="https://raw.githubusercontent.com/external-secrets/external-secrets/main/assets/CS_logo_1.png" alt="Container Solutions" /&gt; &lt;img src="https://raw.githubusercontent.com/external-secrets/external-secrets/main/assets/form3_logo.png" alt="Form 3" /&gt; &lt;img src="https://raw.githubusercontent.com/external-secrets/external-secrets/main/assets/pento_logo.png" alt="Pento " /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets?ref=badge_large"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>colmap/colmap</title>
      <link>https://github.com/colmap/colmap</link>
      <description>&lt;p&gt;COLMAP - Structure-from-Motion and Multi-View Stereo&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;COLMAP&lt;/h1&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;COLMAP is a general-purpose Structure-from-Motion (SfM) and Multi-View Stereo (MVS) pipeline with a graphical and command-line interface. It offers a wide range of features for reconstruction of ordered and unordered image collections. The software is licensed under the new BSD license. If you use this project for your research, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@inproceedings{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={Pixelwise View Selection for Unstructured Multi-View Stereo},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you use the image retrieval / vocabulary tree engine, please also cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@inproceedings{schoenberger2016vote,
    author={Sch\"{o}nberger, Johannes Lutz and Price, True and Sattler, Torsten and Frahm, Jan-Michael and Pollefeys, Marc},
    title={A Vote-and-Verify Strategy for Fast Spatial Verification in Image Retrieval},
    booktitle={Asian Conference on Computer Vision (ACCV)},
    year={2016},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The latest source code is available at &lt;a href="https://github.com/colmap/colmap"&gt;https://github.com/colmap/colmap&lt;/a&gt;. COLMAP builds on top of existing works and when using specific algorithms within COLMAP, please also cite the original authors, as specified in the source code, and consider citing relevant third-party dependencies (most notably ceres-solver, poselib, sift-gpu, vlfeat).&lt;/p&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Binaries for &lt;strong&gt;Windows&lt;/strong&gt; and other resources can be downloaded from &lt;a href="https://github.com/colmap/colmap/releases"&gt;https://github.com/colmap/colmap/releases&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Binaries for &lt;strong&gt;Linux/Unix/BSD&lt;/strong&gt; are available at &lt;a href="https://repology.org/metapackage/colmap/versions"&gt;https://repology.org/metapackage/colmap/versions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Pre-built &lt;strong&gt;Docker&lt;/strong&gt; images are available at &lt;a href="https://hub.docker.com/r/colmap/colmap"&gt;https://hub.docker.com/r/colmap/colmap&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python bindings&lt;/strong&gt; are available at &lt;a href="https://pypi.org/project/pycolmap"&gt;https://pypi.org/project/pycolmap&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;To &lt;strong&gt;build from source&lt;/strong&gt;, please see &lt;a href="https://colmap.github.io/install.html"&gt;https://colmap.github.io/install.html&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download pre-built binaries or build from source.&lt;/li&gt; 
 &lt;li&gt;Download one of the provided datasets at &lt;a href="https://demuc.de/colmap/datasets/"&gt;https://demuc.de/colmap/datasets/&lt;/a&gt; or use your own images.&lt;/li&gt; 
 &lt;li&gt;Use the &lt;strong&gt;automatic reconstruction&lt;/strong&gt; to easily build models with a single click or command.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The documentation is available at &lt;a href="https://colmap.github.io/"&gt;https://colmap.github.io/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Please, use GitHub Discussions at &lt;a href="https://github.com/colmap/colmap/discussions"&gt;https://github.com/colmap/colmap/discussions&lt;/a&gt; for questions and the GitHub issue tracker at &lt;a href="https://github.com/colmap/colmap"&gt;https://github.com/colmap/colmap&lt;/a&gt; for bug reports, feature requests/additions, etc.&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;COLMAP was originally written by &lt;a href="https://demuc.de/"&gt;Johannes Sch√∂nberger&lt;/a&gt; with funding provided by his PhD advisors Jan-Michael Frahm and Marc Pollefeys. The team of core project maintainers currently includes &lt;a href="https://github.com/ahojnnes"&gt;Johannes Sch√∂nberger&lt;/a&gt;, &lt;a href="https://github.com/sarlinpe"&gt;Paul-Edouard Sarlin&lt;/a&gt;, and &lt;a href="https://github.com/B1ueber2y"&gt;Shaohui Liu&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The Python bindings in PyCOLMAP were originally added by &lt;a href="https://github.com/mihaidusmanu"&gt;Mihai Dusmanu&lt;/a&gt;, &lt;a href="https://github.com/Phil26AT"&gt;Philipp Lindenberger&lt;/a&gt;, and &lt;a href="https://github.com/sarlinpe"&gt;Paul-Edouard Sarlin&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The project has also benefitted from countless community contributions, including bug fixes, improvements, new features, third-party tooling, and community support (special credits to &lt;a href="https://tsattler.github.io"&gt;Torsten Sattler&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Contributions (bug reports, bug fixes, improvements, etc.) are very welcome and should be submitted in the form of new issues and/or pull requests on GitHub.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The COLMAP library is licensed under the new BSD license. Note that this text refers only to the license for COLMAP itself, independent of its thirdparty dependencies, which are separately licensed. Building COLMAP with these dependencies may affect the resulting COLMAP license.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (c), ETH Zurich and UNC Chapel Hill.
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

    * Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.

    * Redistributions in binary form must reproduce the above copyright
      notice, this list of conditions and the following disclaimer in the
      documentation and/or other materials provided with the distribution.

    * Neither the name of ETH Zurich and UNC Chapel Hill nor the names of
      its contributors may be used to endorse or promote products derived
      from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>angular/components</title>
      <link>https://github.com/angular/components</link>
      <description>&lt;p&gt;Component infrastructure and Material Design components for Angular&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Official components for Angular&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.npmjs.com/package/@angular/cdk"&gt;&lt;img src="https://badge.fury.io/js/%40angular%2Fcdk.svg?sanitize=true" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://circleci.com/gh/angular/components"&gt;&lt;img src="https://circleci.com/gh/angular/components.svg?style=svg" alt="Build status" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/angular/material2?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge"&gt;&lt;img src="https://badges.gitter.im/angular/components.svg?sanitize=true" alt="Gitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The Angular team builds and maintains both common UI components and tools to help you build your own custom components. The team maintains several npm packages.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Package&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;@angular/cdk&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Library that helps you author custom UI components with common interaction patterns&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://material.angular.dev/cdk/categories"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;@angular/material&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://material.io"&gt;Material Design&lt;/a&gt; UI components for Angular applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://material.angular.dev"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;@angular/google-maps&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Angular components built on top of the &lt;a href="https://developers.google.com/maps/documentation/javascript/tutorial"&gt;Google Maps JavaScript API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/angular/components/raw/main/src/google-maps/README.md"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;@angular/youtube-player&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Angular component built on top of the &lt;a href="https://developers.google.com/youtube/iframe_api_reference"&gt;YouTube Player API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/angular/components/raw/main/src/youtube-player/README.md"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Quick links&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://material.angular.dev"&gt;Documentation, demos, and guides&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/angular/components/main/FAQ.md"&gt;Frequently Asked Questions&lt;/a&gt; | &lt;a href="https://groups.google.com/forum/#!forum/angular-material2"&gt;Community Google group&lt;/a&gt; | &lt;a href="https://github.com/angular/components/raw/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; | &lt;a href="https://stackblitz.com/fork/components-issue"&gt;StackBlitz Template&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;See our &lt;a href="https://material.angular.dev/guide/getting-started"&gt;Getting Started Guide&lt;/a&gt; if you're building your first project with Angular Material.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you'd like to contribute, please follow our &lt;a href="https://github.com/angular/components/raw/main/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt;. Please see our &lt;a href="https://github.com/angular/components/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22"&gt;&lt;code&gt;help wanted&lt;/code&gt;&lt;/a&gt; label for a list of issues with good opportunities for contribution. You can also use the &lt;a href="https://github.com/angular/components/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22+label%3A%22good+first+issue%22"&gt;&lt;code&gt;good first issue&lt;/code&gt;&lt;/a&gt; label to find issues if you are just starting to contribute to the project.&lt;/p&gt; 
&lt;h2&gt;About the team&lt;/h2&gt; 
&lt;p&gt;The Angular Components team is part of the Angular team at Google. The team includes both Google employees and community contributors from around the globe.&lt;/p&gt; 
&lt;p&gt;Our team has two primary goals:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Build high-quality UI components that developers can drop into existing applications&lt;/li&gt; 
 &lt;li&gt;Provide tools that help developers build their own custom components with common interaction patterns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;What do we mean by "high-quality" components?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Internationalized and accessible so that all users can use them.&lt;/li&gt; 
 &lt;li&gt;Straightforward APIs that don't confuse developers.&lt;/li&gt; 
 &lt;li&gt;Behave as expected across a wide variety of use-cases without bugs.&lt;/li&gt; 
 &lt;li&gt;Behavior is well-tested with both unit and integration tests.&lt;/li&gt; 
 &lt;li&gt;Customizable within the bounds of the Material Design specification.&lt;/li&gt; 
 &lt;li&gt;Performance cost is minimized.&lt;/li&gt; 
 &lt;li&gt;Code is clean and well-documented to serve as an example for Angular developers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Browser and screen reader support&lt;/h2&gt; 
&lt;p&gt;The Angular Components team supports the most recent two versions of all major browsers: Chrome (including Android), Firefox, Safari (including iOS), and Edge.&lt;/p&gt; 
&lt;p&gt;We aim for great user experience with the following screen readers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: NVDA and JAWS with FF / Chrome.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: VoiceOver with Safari / Chrome.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;iOS&lt;/strong&gt;: VoiceOver with Safari&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Android&lt;/strong&gt;: Android Accessibility Suite (formerly TalkBack) with Chrome.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chrome OS&lt;/strong&gt;: ChromeVox with Chrome.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>hashicorp/terraform</title>
      <link>https://github.com/hashicorp/terraform</link>
      <description>&lt;p&gt;Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Terraform&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href="https://developer.hashicorp.com/terraform"&gt;https://developer.hashicorp.com/terraform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Forums: &lt;a href="https://discuss.hashicorp.com/c/terraform-core"&gt;HashiCorp Discuss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://developer.hashicorp.com/terraform/docs"&gt;https://developer.hashicorp.com/terraform/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tutorials: &lt;a href="https://developer.hashicorp.com/terraform/tutorials"&gt;HashiCorp's Learn Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Certification Exam: &lt;a href="https://www.hashicorp.com/certification/#hashicorp-certified-terraform-associate"&gt;HashiCorp Certified: Terraform Associate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img alt="Terraform" src="https://www.datocms-assets.com/2885/1731373310-terraform_white.svg?sanitize=true" width="600px" /&gt; 
&lt;p&gt;Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.&lt;/p&gt; 
&lt;p&gt;The key features of Terraform are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Infrastructure as Code&lt;/strong&gt;: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Execution Plans&lt;/strong&gt;: Terraform has a "planning" step where it generates an execution plan. The execution plan shows what Terraform will do when you call apply. This lets you avoid any surprises when Terraform manipulates infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Resource Graph&lt;/strong&gt;: Terraform builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, Terraform builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Change Automation&lt;/strong&gt;: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what Terraform will change and in what order, avoiding many possible human errors.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information, refer to the &lt;a href="https://www.terraform.io/intro"&gt;What is Terraform?&lt;/a&gt; page on the Terraform website.&lt;/p&gt; 
&lt;h2&gt;Getting Started &amp;amp; Documentation&lt;/h2&gt; 
&lt;p&gt;Documentation is available on the &lt;a href="https://developer.hashicorp.com/terraform"&gt;Terraform website&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.hashicorp.com/terraform/intro"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.hashicorp.com/terraform/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you're new to Terraform and want to get started creating infrastructure, please check out our &lt;a href="https://learn.hashicorp.com/terraform#getting-started"&gt;Getting Started guides&lt;/a&gt; on HashiCorp's learning platform. There are also &lt;a href="https://learn.hashicorp.com/terraform#operations-and-development"&gt;additional guides&lt;/a&gt; to continue your learning.&lt;/p&gt; 
&lt;p&gt;Show off your Terraform knowledge by passing a certification exam. Visit the &lt;a href="https://www.hashicorp.com/certification/"&gt;certification page&lt;/a&gt; for information about exams and find &lt;a href="https://learn.hashicorp.com/terraform/certification/terraform-associate"&gt;study materials&lt;/a&gt; on HashiCorp's learning platform.&lt;/p&gt; 
&lt;h2&gt;Developing Terraform&lt;/h2&gt; 
&lt;p&gt;This repository contains only Terraform core, which includes the command line interface and the main graph engine. Providers are implemented as plugins, and Terraform can automatically download providers that are published on &lt;a href="https://registry.terraform.io"&gt;the Terraform Registry&lt;/a&gt;. HashiCorp develops some providers, and others are developed by other organizations. For more information, refer to &lt;a href="https://developer.hashicorp.com/terraform/plugin"&gt;Plugin development&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;To learn more about compiling Terraform and contributing suggested changes, refer to &lt;a href="https://raw.githubusercontent.com/hashicorp/terraform/main/.github/CONTRIBUTING.md"&gt;the contributing guide&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To learn more about how we handle bug reports, refer to the &lt;a href="https://raw.githubusercontent.com/hashicorp/terraform/main/BUGPROCESS.md"&gt;bug triage guide&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To learn how to contribute to the Terraform documentation, refer to the &lt;a href="https://github.com/hashicorp/web-unified-docs"&gt;Web Unified Docs repository&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/hashicorp/terraform/raw/main/LICENSE"&gt;Business Source License 1.1&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>oop7/YTSage</title>
      <link>https://github.com/oop7/YTSage</link>
      <description>&lt;p&gt;Modern YouTube downloader with a clean PySide6 interface. Download videos in any quality, extract audio, fetch subtitles, sponserBlock, and view video metadata. Built with yt-dlp for reliable performance.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;üé• YTSage&lt;/h1&gt; 
 &lt;img src="https://github.com/user-attachments/assets/f95f7bfb-8591-4d32-b795-68e61efd670c" width="800" alt="YTSage Interface" /&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/ytsage"&gt;&lt;img src="https://img.shields.io/pypi/v/ytsage?color=dc2626&amp;amp;style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-374151?style=for-the-badge&amp;amp;logo=opensource&amp;amp;logoColor=white" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.7+-1f2937?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white" alt="Python 3.7+" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/ytsage"&gt;&lt;img src="https://img.shields.io/pypi/dm/ytsage?color=4b5563&amp;amp;style=for-the-badge&amp;amp;logo=download&amp;amp;logoColor=white" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/oop7/YTSage/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/oop7/YTSage?color=dc2626&amp;amp;style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GitHub Stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;A modern YouTube downloader with a clean PySide6 interface.&lt;/strong&gt;&lt;br /&gt; Download videos in any quality, extract audio, fetch subtitles, and more.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/oop7/YTSage/main/#installation"&gt;Installation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/oop7/YTSage/main/#features"&gt;Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/oop7/YTSage/main/#usage"&gt;Usage&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/oop7/YTSage/main/#screenshots"&gt;Screenshots&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/oop7/YTSage/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a id="features"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Core Features&lt;/th&gt; 
    &lt;th&gt;Advanced Features&lt;/th&gt; 
    &lt;th&gt;Extra Features&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üé• Format Table&lt;/td&gt; 
    &lt;td&gt;üö´ SponsorBlock Integration&lt;/td&gt; 
    &lt;td&gt;üíæ Save Download Path&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üéµ Audio Extraction&lt;/td&gt; 
    &lt;td&gt;üìù Multi-Subtitle Select &amp;amp; Merge&lt;/td&gt; 
    &lt;td&gt;üîÑ Auto-Update yt-dlp&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;‚ú® Simple UI&lt;/td&gt; 
    &lt;td&gt;üíæ Save Description&lt;/td&gt; 
    &lt;td&gt;üõ†Ô∏è FFmpeg/yt-dlp Detection&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üìã Playlist Support&lt;/td&gt; 
    &lt;td&gt;üñºÔ∏è Save thumbnail&lt;/td&gt; 
    &lt;td&gt;‚öôÔ∏è Custom Commands&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üñºÔ∏è Playlist Selector&lt;/td&gt; 
    &lt;td&gt;üöÄ Speed Limiter&lt;/td&gt; 
    &lt;td&gt;üç™ Login with Cookies&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;‚úÇÔ∏è Trim Video Sections&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a id="installation"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Installation&lt;/h2&gt; 
&lt;h3&gt;Quick Install (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install ytsage
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the application
ytsage
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üì¶ Other Installation Methods&lt;/h3&gt; 
&lt;h3&gt;Pre-built Executables&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü™ü Windows: &lt;code&gt;YTSage.exe&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ü™ü Windows: &lt;code&gt;YTSage-ffmpeg.exe&lt;/code&gt; (Includes FFmpeg)&lt;/li&gt; 
 &lt;li&gt;üêß Linux: &lt;code&gt;YTSage_{version}_amd64.deb&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;üêß Linux: &lt;code&gt;YTSage-x86_64.AppImage&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;üçé macOS: &lt;code&gt;YTSage-macOS-app.zip&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;üçé macOS: &lt;code&gt;YTSage-{version}.dmg&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;üõ†Ô∏è Manual Installation from Source&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone https://github.com/oop7/YTSage.git

# Navigate to directory
cd YTSage

# Install dependencies
pip install -r requirements.txt

# Run application
python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;a id="screenshots"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∏ Screenshots&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/f95f7bfb-8591-4d32-b795-68e61efd670c" alt="Main Interface" width="400" /&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/f7b3ebab-3054-4c77-8109-c899a8b10047" alt="Playlist Download" width="400" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;em&gt;Main Interface&lt;/em&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;em&gt;Playlist Download&lt;/em&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/a80d2ae2-0031-4ed0-bee4-93293634c62a" alt="Audio Format Selection with Save Thumbnail" width="400" /&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/5236e3cc-8a8d-4d85-a660-782a740ef9af" alt="Subtitle Options merged with Remove Sponsor Segments" width="400" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;em&gt;Audio Format&lt;/em&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;em&gt;Subtitle Options&lt;/em&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a id="usage"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ Usage&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;üéØ Basic Usage&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Launch YTSage&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Paste YouTube URL&lt;/strong&gt; (or use "Paste URL" button)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click "Analyze"&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Select Format:&lt;/strong&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;Video&lt;/code&gt; for video downloads&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;Audio Only&lt;/code&gt; for audio extraction&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Choose Options:&lt;/strong&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Enable subtitles &amp;amp; select language&lt;/li&gt; 
    &lt;li&gt;Enable subtitle merge&lt;/li&gt; 
    &lt;li&gt;Save thumbnail&lt;/li&gt; 
    &lt;li&gt;Remove sponsor segments&lt;/li&gt; 
    &lt;li&gt;Save description&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Select Output Directory&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click "Download"&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìã Playlist Download&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Paste Playlist URL&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click "Analyze"&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Select videos from the playlist selector (optional, defaults to all)&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Choose desired format/quality&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click "Download"&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;üí° The application automatically handles the download queue&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üß∞ Advanced Options&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Quality Selection:&lt;/strong&gt; Choose the highest resolution for best quality&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Subtitle Options:&lt;/strong&gt; Filter languages and embed into video&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Custom Commands:&lt;/strong&gt; Access advanced yt-dlp features&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Save Description:&lt;/strong&gt; Save the description of the video&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Save Thumbnail:&lt;/strong&gt; Save the thumbnail of the video&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Remove Sponsor Segments:&lt;/strong&gt; Remove sponsor segments from the video&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed Limiter:&lt;/strong&gt; Limit the download speed&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Login with Cookies:&lt;/strong&gt; Login to YouTube using cookies to access private content&lt;br /&gt; How to use it: 
   &lt;ol&gt; 
    &lt;li&gt;Extract cookies from your browser using an extension like &lt;a href="https://github.com/moustachauve/cookie-editor?tab=readme-ov-file"&gt;cookie-editor&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Copy the cookies in Netscape format&lt;/li&gt; 
    &lt;li&gt;Create a file named &lt;code&gt;cookies.txt&lt;/code&gt; and paste the cookies into it&lt;/li&gt; 
    &lt;li&gt;Select the &lt;code&gt;cookies.txt&lt;/code&gt; file in the app&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Save Download Path:&lt;/strong&gt; Save the download path&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Update yt-dlp:&lt;/strong&gt; Update yt-dlp&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;FFmpeg/yt-dlp Detection:&lt;/strong&gt; Automatically detect FFmpeg/yt-dlp&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Custom Commands:&lt;/strong&gt; Access advanced yt-dlp features&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Trim Video:&lt;/strong&gt; Download only specific parts of a video by specifying time ranges (HH:MM:SS format)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üõ†Ô∏è Troubleshooting&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Format table not displaying:&lt;/strong&gt; Update yt-dlp to the latest version&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Download fails:&lt;/strong&gt; Check your internet connection and ensure the video is available&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Audio extraction issues:&lt;/strong&gt; Verify FFmpeg is properly installed&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üß© Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python:&lt;/strong&gt; 3.7 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GUI Framework:&lt;/strong&gt; PySide6&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Download Engine:&lt;/strong&gt; yt-dlp&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Media Processing:&lt;/strong&gt; FFmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Additional Libraries:&lt;/strong&gt; Pillow, requests, packaging, markdown, pygame&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a id="contributing"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üë• Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Here's how you can help:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;üç¥ Fork the repository&lt;/li&gt; 
 &lt;li&gt;üåø Create your feature branch: &lt;pre&gt;&lt;code class="language-bash"&gt;git checkout -b feature/AmazingFeature
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;üíæ Commit your changes: &lt;pre&gt;&lt;code class="language-bash"&gt;git commit -m 'Add some AmazingFeature'
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;üì§ Push to the branch: &lt;pre&gt;&lt;code class="language-bash"&gt;git push origin feature/AmazingFeature
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;üîÑ Open a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìä Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#oop7/YTSage&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=oop7/YTSage&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìú License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/oop7/YTSage/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Technology&lt;/th&gt; 
    &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp"&gt;yt-dlp&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Download Engine&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://wiki.qt.io/Qt_for_Python"&gt;PySide6&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;GUI Framework&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://ffmpeg.org/"&gt;FFmpeg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Media Processing&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://python-pillow.org/"&gt;Pillow&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Image Processing&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://requests.readthedocs.io/"&gt;requests&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;HTTP Requests&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://packaging.python.org/"&gt;packaging&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Packaging&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://python-markdown.github.io/"&gt;markdown&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Markdown Processing&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.pygame.org/"&gt;pygame&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Audio Playback&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://pixabay.com/sound-effects/new-notification-09-352705/"&gt;New Notification 09 by Universfield&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Notification Sound&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ö†Ô∏è Disclaimer&lt;/h2&gt; 
&lt;p&gt;This tool is for personal use only. Please respect YouTube's terms of service and content creators' rights.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;Made with ‚ù§Ô∏è by &lt;a href="https://github.com/oop7"&gt;oop7&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>conductor-oss/conductor</title>
      <link>https://github.com/conductor-oss/conductor</link>
      <description>&lt;p&gt;Conductor is an event driven orchestration platform providing durable and highly resilient execution engine for your applications&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;!-- Dark mode logo --&gt; 
 &lt;source srcset="https://github.com/user-attachments/assets/104b3a67-6013-4622-8075-a45da3a9e726" media="(prefers-color-scheme: dark)" /&gt; 
 &lt;!-- Light mode logo --&gt; 
 &lt;img src="https://assets.conductor-oss.org/logo.png" alt="Logo" /&gt; 
&lt;/picture&gt; 
&lt;h1 align="center" style="border-bottom: none"&gt; Conductor - Scalable Workflow Orchestration &lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/conductor-oss/conductor/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/conductor-oss/conductor?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/conductor-oss/conductor/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/conductor-oss/conductor.svg?sanitize=true" alt="Github release" /&gt;&lt;/a&gt; &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;&lt;img src="https://img.shields.io/github/license/conductor-oss/conductor.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://join.slack.com/t/orkes-conductor/shared_invite/zt-2vdbx239s-Eacdyqya9giNLHfrCavfaA"&gt;&lt;img src="https://img.shields.io/badge/Slack-Join%20the%20Community-blueviolet?logo=slack" alt="Conductor Slack" /&gt;&lt;/a&gt; &lt;a href="https://conductor-oss.org"&gt;&lt;img src="https://img.shields.io/badge/Conductor%20OSS-Visit%20Site-blue" alt="Conductor OSS" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Conductor is an open-source orchestration engine built at Netflix to help developers manage microservices and event-driven workflows. Today, it‚Äôs actively maintained by the team at &lt;a href="https://orkes.io"&gt;Orkes&lt;/a&gt; and a growing &lt;a href="https://orkes-conductor.slack.com/join/shared_invite/zt-2vdbx239s-Eacdyqya9giNLHfrCavfaA#/shared-invite/email"&gt;community of contributors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/4azDdDlx27M"&gt;&lt;img src="https://github.com/user-attachments/assets/6153aa58-8ad1-4ec5-93d1-38ba1b83e3f4" alt="conductor_oss_getting_started" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#what-is-conductor"&gt;What is Conductor?&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#key-benefits"&gt;Key benefits&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#getting-started"&gt;Getting Started with Docker&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#quick-start-guide"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#create-your-first-workflow"&gt;Create your first workflow&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#build-from-source"&gt;Build from source&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#database-specifications"&gt;Database Specifications&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#conductor-oss-roadmap"&gt;Conductor Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#contributors"&gt;How to Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#resources"&gt;Additional Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/#slack-community"&gt;Community &amp;amp; Support&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;What is Conductor?&lt;/h1&gt; 
&lt;p&gt;Conductor (or &lt;a href="https://netflixtechblog.com/netflix-conductor-a-microservices-orchestrator-2e8d4771bf40"&gt;Netflix Conductor&lt;/a&gt;) is a microservices orchestration engine for distributed and asynchronous workflows. It empowers developers to create workflows that define interactions between services, databases, and other external systems.&lt;/p&gt; 
&lt;p&gt;Conductor is designed to enable flexible, resilient, and scalable workflows. It allows you to compose services into complex workflows without coupling them tightly, simplifying orchestration across cloud-native applications and enterprise systems alike.&lt;/p&gt; 
&lt;h2&gt;Key benefits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Resilience and Error Handling:&lt;/strong&gt; Conductor enables automatic retries and fallback mechanisms.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; Built to scale with complex workflows in high-traffic environments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability:&lt;/strong&gt; Provides monitoring and debugging capabilities for workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ease of Integration:&lt;/strong&gt; Seamlessly integrates with microservices, external APIs, and legacy systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Workflow as code:&lt;/strong&gt; Define workflows in JSON and manage them with versioning.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rich task types:&lt;/strong&gt; Includes task types like HTTP, JSON, Lambda, Sub Workflow, and Event tasks, allowing for flexible workflow definitions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic workflow management:&lt;/strong&gt; Workflows can evolve independently of the underlying services.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in UI:&lt;/strong&gt; A customizable UI is available to monitor and manage workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible persistence and queue options:&lt;/strong&gt; Use Redis, MySQL, Postgres, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Getting Started with Conductor&lt;/h1&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install Docker Desktop (&lt;a href="https://docs.docker.com/desktop/setup/install/mac-install/"&gt;Mac&lt;/a&gt;, &lt;a href="https://docs.docker.com/desktop/setup/install/windows-install/"&gt;Windows/PC&lt;/a&gt;, &lt;a href="https://docs.docker.com/desktop/setup/install/linux/"&gt;Linux&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Install Java (JDK) 17 or newer&lt;/li&gt; 
 &lt;li&gt;Node 14 for the UI to build 
  &lt;ul&gt; 
   &lt;li&gt;&lt;em&gt;Earlier versions may work, but are untested&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start guide&lt;/h2&gt; 
&lt;h4&gt;Clone the repo&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/conductor-oss/conductor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Change to new Conductor directory&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd conductor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Start with Docker Compose (&lt;em&gt;recommended for local deployment&lt;/em&gt;)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker compose -f docker/docker-compose.yaml up
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Create your first workflow&lt;/h4&gt; 
&lt;h5&gt;With the UI:&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8127"&gt;http://localhost:8127&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Or the REST API with your preferred HTTP client:&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;Check-out the &lt;a href="https://github.com/conductor-oss/conductor/tree/main/docs"&gt;Conductor docs&lt;/a&gt; for additional details&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Database Specifications&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;The default persistence used is Redis&lt;/li&gt; 
 &lt;li&gt;The indexing backend is &lt;a href="https://www.elastic.co/"&gt;Elasticsearch&lt;/a&gt; (7.x)&lt;/li&gt; 
 &lt;li&gt;To use &lt;a href="https://opensearch.org/"&gt;Opensearch&lt;/a&gt; (2.x), comment out Elasticsearch import so lucene dependencies don't conflict &lt;a href="https://github.com/conductor-oss/conductor/raw/main/server/build.gradle#L44-L46"&gt;server/build.gradle&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configuration for various database backends&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Configuration&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Redis + ES7&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/docker/server/config/config-redis.properties"&gt;config-redis.properties&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Postgres&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/docker/server/config/config-postgres.properties"&gt;config-postgres.properties&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Postgres + ES7&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/docker/server/config/config-postgres-es7.properties"&gt;config-postgres-es7.properties&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MySQL + ES7&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/docker/server/config/config-mysql.properties"&gt;config-mysql.properties&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Build from source&lt;/h1&gt; 
&lt;p&gt;Build from source and deploy Conductor as a standalone Java application. Configure databases, queues, and environment settings as needed. Follow the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/docs/devguide/running/source.md"&gt;Building Conductor From Source&lt;/a&gt;&lt;/strong&gt; guide included in this repo.&lt;/p&gt; 
&lt;h2&gt;Available SDKs&lt;/h2&gt; 
&lt;p&gt;Conductor provides several SDKs for interacting with the API and creating custom clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/conductor-oss/java-sdk"&gt;&lt;strong&gt;Java SDK:&lt;/strong&gt;&lt;/a&gt; Fully featured for building and executing workflows in Java.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/conductor-oss/python-sdk"&gt;&lt;strong&gt;Python SDK:&lt;/strong&gt;&lt;/a&gt; Python library for creating and managing workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/conductor-oss/javascript-sdk"&gt;&lt;strong&gt;Javascript SDK:&lt;/strong&gt;&lt;/a&gt; For integrating Conductor workflows with Javascript/Typescript-based services.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/conductor-oss/go-sdk"&gt;&lt;strong&gt;Go SDK:&lt;/strong&gt;&lt;/a&gt; For integrating Conductor workflows with Go-based services.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/conductor-oss/csharp-sdk"&gt;&lt;strong&gt;C# SDK:&lt;/strong&gt;&lt;/a&gt;The conductor-csharp repository provides the client SDKs to build task workers in C#&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each SDK is maintained as part of the Conductor project, providing examples and comprehensive API documentation.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome contributions from everyone!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Report Issues:&lt;/strong&gt; Found a bug or have a feature request? Open an &lt;a href="https://github.com/conductor-oss/conductor/issues"&gt;issue on GitHub&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contribute code:&lt;/strong&gt; Check out our &lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;, and explore our &lt;a href="https://github.com/conductor-oss/conductor/labels/good%20first%20issue"&gt;Good first issues&lt;/a&gt; for beginner-friendly tasks to tackle first.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contribute to our Docs:&lt;/strong&gt; Contribute edits or updates to keep our &lt;a href="https://github.com/conductor-oss/conductor/tree/main/docs"&gt;documentation&lt;/a&gt; in great shape for the community.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Conductor SDK:&lt;/strong&gt; Need an &lt;a href="https://github.com/conductor-sdk"&gt;SDK&lt;/a&gt; not available for Conductor today? Build your own using the &lt;a href="http://localhost:8080"&gt;Swagger API&lt;/a&gt; included with your local deployment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Community&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://join.slack.com/t/orkes-conductor/shared_invite/zt-2vdbx239s-Eacdyqya9giNLHfrCavfaA"&gt;Join the Conductor Slack&lt;/a&gt;&lt;/strong&gt; channel for community discussions and support.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/conductor-oss/conductor/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=conductor-oss/conductor" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Conductor OSS Roadmap&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/ROADMAP.md"&gt;See the roadmap for the Conductor&lt;/a&gt; If you would like to participate in the roadmap and development, &lt;a href="https://forms.gle/P2i1xHrxPQLrjzTB7"&gt;please reach out&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Conductor is licensed under the &lt;a href="https://raw.githubusercontent.com/conductor-oss/conductor/main/LICENSE"&gt;Apache 2.0 License ¬©&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>apple/embedding-atlas</title>
      <link>https://github.com/apple/embedding-atlas</link>
      <description>&lt;p&gt;Embedding Atlas is a tool that provides interactive visualizations for large embeddings. It allows you to visualize, cross-filter, and search embeddings and metadata.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Embedding Atlas&lt;/h1&gt; 
&lt;p&gt;Embedding Atlas is a tool that provides interactive visualizations for large embeddings. It allows you to visualize, cross-filter, and search embeddings and metadata.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üè∑Ô∏è &lt;strong&gt;Automatic data clustering &amp;amp; labeling:&lt;/strong&gt; Interactively visualize and navigate overall data structure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ü´ß &lt;strong&gt;Kernel density estimation &amp;amp; density contours:&lt;/strong&gt; Easily explore and distinguish between dense regions of data and outliers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üßä &lt;strong&gt;Order-independent transparency:&lt;/strong&gt; Ensure clear, accurate rendering of overlapping points.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîç &lt;strong&gt;Real-time search &amp;amp; nearest neighbors:&lt;/strong&gt; Find similar data to a given query or existing data point.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üöÄ &lt;strong&gt;WebGPU implementation (with WebGL 2 fallback):&lt;/strong&gt; Fast, smooth performance (up to few million points) with modern rendering stack.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìä &lt;strong&gt;Multi-coordinated views for metadata exploration:&lt;/strong&gt; Interactively link and filter data across metadata columns.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please visit &lt;a href="https://apple.github.io/embedding-atlas"&gt;https://apple.github.io/embedding-atlas&lt;/a&gt; for a demo and documentation.&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="./packages/docs/assets/embedding-atlas-dark.png" /&gt; 
 &lt;img alt="screenshot of Embedding Atlas" src="https://raw.githubusercontent.com/apple/embedding-atlas/main/packages/docs/assets/embedding-atlas-light.png" /&gt; 
&lt;/picture&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;To use Embedding Atlas with Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install embedding-atlas

embedding-atlas &amp;lt;your-dataset.parquet&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to the command line tool, Embedding Atlas is also available as a Jupyter widget:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from embedding_atlas.widget import EmbeddingAtlasWidget

# Show the Embedding Atlas widget for your data frame:
EmbeddingAtlasWidget(df)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, components from Embedding Atlas are also available in an npm package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install embedding-atlas
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;import { EmbeddingAtlas, EmbeddingView, Table } from "embedding-atlas";

// or with React:
import { EmbeddingAtlas, EmbeddingView, Table } from "embedding-atlas/react";

// or Svelte:
import { EmbeddingAtlas, EmbeddingView, Table } from "embedding-atlas/svelte";
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information, please visit &lt;a href="https://apple.github.io/embedding-atlas/overview.html"&gt;https://apple.github.io/embedding-atlas/overview.html&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;BibTeX&lt;/h2&gt; 
&lt;p&gt;For the Embedding Atlas tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{ren2025embedding,
  title={Embedding Atlas: Low-Friction, Interactive Embedding Visualization},
  author={Donghao Ren and Fred Hohman and Halden Lin and Dominik Moritz},
  year={2025},
  eprint={2505.06386},
  archivePrefix={arXiv},
  primaryClass={cs.HC},
  url={https://arxiv.org/abs/2505.06386},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the algorithm that automatically produces clusters and labels in the embedding view:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{ren2025scalable,
  title={A Scalable Approach to Clustering Embedding Projections},
  author={Donghao Ren and Fred Hohman and Dominik Moritz},
  year={2025},
  eprint={2504.07285},
  archivePrefix={arXiv},
  primaryClass={cs.HC},
  url={https://arxiv.org/abs/2504.07285},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;This repo contains multiple sub-packages:&lt;/p&gt; 
&lt;p&gt;Frontend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;packages/component&lt;/code&gt;: The &lt;code&gt;EmbeddingView&lt;/code&gt; and &lt;code&gt;EmbeddingViewMosaic&lt;/code&gt; components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;packages/table&lt;/code&gt;: The &lt;code&gt;Table&lt;/code&gt; component.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;packages/viewer&lt;/code&gt;: The frontend application for visualizing embedding and other columns. It also provides the &lt;code&gt;EmbeddingAtlas&lt;/code&gt; component that can be embedded in other applications.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;packages/density-clustering&lt;/code&gt;: The density clustering algorithm, written in Rust.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;packages/umap-wasm&lt;/code&gt;: An implementation of UMAP algorithm in WebAssembly (with the &lt;a href="https://github.com/libscran/umappp"&gt;umappp&lt;/a&gt; C++ library).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;packages/embedding-atlas&lt;/code&gt;: The &lt;code&gt;embedding-atlas&lt;/code&gt; package that get published. It imports all of the above and exposes their API in a single package.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Python:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;packages/backend&lt;/code&gt;: A Python package named &lt;code&gt;embedding-atlas&lt;/code&gt; that provides the &lt;code&gt;embedding-atlas&lt;/code&gt; command line tool.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;packages/docs&lt;/code&gt;: The documentation website.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information, please visit &lt;a href="https://apple.github.io/embedding-atlas/develop.html"&gt;https://apple.github.io/embedding-atlas/develop.html&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This code is released under the &lt;a href="https://raw.githubusercontent.com/apple/embedding-atlas/main/LICENSE"&gt;&lt;code&gt;MIT license&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>