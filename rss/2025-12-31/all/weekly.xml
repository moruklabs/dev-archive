<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Tue, 30 Dec 2026 01:41:10 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>sst/opencode</title>
      <link>https://github.com/sst/opencode</link>
      <description>&lt;p&gt;The open source coding agent.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://opencode.ai"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-light.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/console/app/src/asset/logo-ornate-light.svg?sanitize=true" alt="OpenCode logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;The open source AI coding agent.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://opencode.ai/discord"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;amp;label=discord" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/opencode-ai"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/opencode-ai?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sst/opencode/actions/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/sst/opencode/publish.yml?style=flat-square&amp;amp;branch=dev" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencode.ai"&gt;&lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/web/src/assets/lander/screenshot.png" alt="OpenCode Terminal UI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
scoop bucket add extras; scoop install extras/opencode  # Windows
choco install opencode             # Windows
brew install opencode              # macOS and Linux
paru -S opencode-bin               # Arch Linux
mise use -g github:sst/opencode # Any OS
nix run nixpkgs#opencode           # or github:sst/opencode for latest dev branch
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Remove versions older than 0.1.x before installing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Desktop App (BETA)&lt;/h3&gt; 
&lt;p&gt;OpenCode is also available as a desktop application. Download directly from the &lt;a href="https://github.com/sst/opencode/releases"&gt;releases page&lt;/a&gt; or &lt;a href="https://opencode.ai/download"&gt;opencode.ai/download&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Apple Silicon)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-aarch64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Intel)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-x64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-windows-x64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, or AppImage&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (Homebrew)
brew install --cask opencode-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installation Directory&lt;/h4&gt; 
&lt;p&gt;The install script respects the following priority order for the installation path:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;$OPENCODE_INSTALL_DIR&lt;/code&gt; - Custom installation directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$XDG_BIN_DIR&lt;/code&gt; - XDG Base Directory Specification compliant path&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/bin&lt;/code&gt; - Standard user binary directory (if exists or can be created)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.opencode/bin&lt;/code&gt; - Default fallback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Agents&lt;/h3&gt; 
&lt;p&gt;OpenCode includes two built-in agents you can switch between, you can switch between these using the &lt;code&gt;Tab&lt;/code&gt; key.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;build&lt;/strong&gt; - Default, full access agent for development work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;plan&lt;/strong&gt; - Read-only agent for analysis and code exploration 
  &lt;ul&gt; 
   &lt;li&gt;Denies file edits by default&lt;/li&gt; 
   &lt;li&gt;Asks permission before running bash commands&lt;/li&gt; 
   &lt;li&gt;Ideal for exploring unfamiliar codebases or planning changes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, included is a &lt;strong&gt;general&lt;/strong&gt; subagent for complex searches and multistep tasks. This is used internally and can be invoked using &lt;code&gt;@general&lt;/code&gt; in messages.&lt;/p&gt; 
&lt;p&gt;Learn more about &lt;a href="https://opencode.ai/docs/agents"&gt;agents&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;For more info on how to configure OpenCode &lt;a href="https://opencode.ai/docs"&gt;&lt;strong&gt;head over to our docs&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;If you're interested in contributing to OpenCode, please read our &lt;a href="https://raw.githubusercontent.com/sst/opencode/dev/CONTRIBUTING.md"&gt;contributing docs&lt;/a&gt; before submitting a pull request.&lt;/p&gt; 
&lt;h3&gt;Building on OpenCode&lt;/h3&gt; 
&lt;p&gt;If you are working on a project that's related to OpenCode and is using "opencode" as a part of its name; for example, "opencode-dashboard" or "opencode-mobile", please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in any way.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;h4&gt;How is this different from Claude Code?&lt;/h4&gt; 
&lt;p&gt;It's very similar to Claude Code in terms of capability. Here are the key differences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100% open source&lt;/li&gt; 
 &lt;li&gt;Not coupled to any provider. Although we recommend the models we provide through &lt;a href="https://opencode.ai/zen"&gt;OpenCode Zen&lt;/a&gt;; OpenCode can be used with Claude, OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.&lt;/li&gt; 
 &lt;li&gt;Out of the box LSP support&lt;/li&gt; 
 &lt;li&gt;A focus on TUI. OpenCode is built by neovim users and the creators of &lt;a href="https://terminal.shop"&gt;terminal.shop&lt;/a&gt;; we are going to push the limits of what's possible in the terminal.&lt;/li&gt; 
 &lt;li&gt;A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;What's the other repo?&lt;/h4&gt; 
&lt;p&gt;The other confusingly named repo has no relation to this one. You can &lt;a href="https://x.com/thdxr/status/1933561254481666466"&gt;read the story behind it here&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Join our community&lt;/strong&gt; &lt;a href="https://discord.gg/opencode"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/opencode"&gt;X.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>davila7/claude-code-templates</title>
      <link>https://github.com/davila7/claude-code-templates</link>
      <description>&lt;p&gt;CLI tool for configuring and monitoring Claude Code&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://www.npmjs.com/package/claude-code-templates"&gt;&lt;img src="https://img.shields.io/npm/v/claude-code-templates.svg?sanitize=true" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/claude-code-templates"&gt;&lt;img src="https://img.shields.io/npm/dt/claude-code-templates.svg?sanitize=true" alt="npm downloads" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/davila7/claude-code-templates/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true" alt="PRs Welcome" /&gt;&lt;/a&gt; &lt;a href="https://z.ai/subscribe?ic=8JVLJQFSKB&amp;amp;utm_source=github&amp;amp;utm_medium=badge&amp;amp;utm_campaign=readme"&gt;&lt;img src="https://img.shields.io/badge/Sponsored%20by-Z.AI-2563eb?style=flat&amp;amp;logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTEyIDJMMiAyMkgyMkwxMiAyWiIgZmlsbD0id2hpdGUiLz4KPC9zdmc+" alt="Sponsored by Z.AI" /&gt;&lt;/a&gt; &lt;a href="https://buymeacoffee.com/daniavila"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20A%20Coffee-support-yellow?style=flat&amp;amp;logo=buy-me-a-coffee" alt="Buy Me A Coffee" /&gt;&lt;/a&gt; &lt;a href="https://github.com/davila7/claude-code-templates"&gt;&lt;img src="https://img.shields.io/github/stars/davila7/claude-code-templates.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15113" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15113" alt="davila7%2Fclaude-code-templates | Trendshift" style="width: 200px; height: 40px;" width="125" height="40" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://vercel.com/oss"&gt; &lt;img alt="Vercel OSS Program" src="https://vercel.com/oss/program-badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;ü§ù Partnership&lt;/h3&gt; 
 &lt;p&gt; &lt;strong&gt;This project is sponsored by &lt;a href="https://z.ai" target="_blank"&gt;Z.AI&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt; Supporting Claude Code Templates with the &lt;strong&gt;GLM CODING PLAN&lt;/strong&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://z.ai/subscribe?ic=8JVLJQFSKB&amp;amp;utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=partnership" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/Get%2010%25%20OFF-GLM%20Coding%20Plan-2563eb?style=for-the-badge" alt="GLM Coding Plan" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;em&gt;Top-tier coding performance powered by GLM-4.6 ‚Ä¢ Starting at $3/month&lt;/em&gt;&lt;br /&gt; &lt;em&gt;Seamlessly integrates with Claude Code, Cursor, Cline &amp;amp; 10+ AI coding tools&lt;/em&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;code&gt;npx claude-code-templates@latest --setting partnerships/glm-coding-plan --yes&lt;/code&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Claude Code Templates (&lt;a href="https://aitmpl.com"&gt;aitmpl.com&lt;/a&gt;)&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Ready-to-use configurations for Anthropic's Claude Code.&lt;/strong&gt; A comprehensive collection of AI agents, custom commands, settings, hooks, external integrations (MCPs), and project templates to enhance your development workflow.&lt;/p&gt; 
&lt;h2&gt;Browse &amp;amp; Install Components and Templates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aitmpl.com"&gt;Browse All Templates&lt;/a&gt;&lt;/strong&gt; - Interactive web interface to explore and install 100+ agents, commands, settings, hooks, and MCPs.&lt;/p&gt; 
&lt;img width="1049" height="855" alt="Screenshot 2025-08-19 at 08 09 24" src="https://github.com/user-attachments/assets/e3617410-9b1c-4731-87b7-a3858800b737" /&gt; 
&lt;h2&gt;üöÄ Quick Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install a complete development stack
npx claude-code-templates@latest --agent development-team/frontend-developer --command testing/generate-tests --mcp development/github-integration --yes

# Browse and install interactively
npx claude-code-templates@latest

# Install specific components
npx claude-code-templates@latest --agent development-tools/code-reviewer --yes
npx claude-code-templates@latest --command performance/optimize-bundle --yes
npx claude-code-templates@latest --setting performance/mcp-timeouts --yes
npx claude-code-templates@latest --hook git/pre-commit-validation --yes
npx claude-code-templates@latest --mcp database/postgresql-integration --yes
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What You Get&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ü§ñ Agents&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;AI specialists for specific domains&lt;/td&gt; 
   &lt;td&gt;Security auditor, React performance optimizer, database architect&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚ö° Commands&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Custom slash commands&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/generate-tests&lt;/code&gt;, &lt;code&gt;/optimize-bundle&lt;/code&gt;, &lt;code&gt;/check-security&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üîå MCPs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;External service integrations&lt;/td&gt; 
   &lt;td&gt;GitHub, PostgreSQL, Stripe, AWS, OpenAI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚öôÔ∏è Settings&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Claude Code configurations&lt;/td&gt; 
   &lt;td&gt;Timeouts, memory settings, output styles&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ü™ù Hooks&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Automation triggers&lt;/td&gt; 
   &lt;td&gt;Pre-commit validation, post-completion actions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üé® Skills&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Reusable capabilities with progressive disclosure&lt;/td&gt; 
   &lt;td&gt;PDF processing, Excel automation, custom workflows&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üõ†Ô∏è Additional Tools&lt;/h2&gt; 
&lt;p&gt;Beyond the template catalog, Claude Code Templates includes powerful development tools:&lt;/p&gt; 
&lt;h3&gt;üìä Claude Code Analytics&lt;/h3&gt; 
&lt;p&gt;Monitor your AI-powered development sessions in real-time with live state detection and performance metrics.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx claude-code-templates@latest --analytics
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üí¨ Conversation Monitor&lt;/h3&gt; 
&lt;p&gt;Mobile-optimized interface to view Claude responses in real-time with secure remote access.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Local access
npx claude-code-templates@latest --chats

# Secure remote access via Cloudflare Tunnel
npx claude-code-templates@latest --chats --tunnel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîç Health Check&lt;/h3&gt; 
&lt;p&gt;Comprehensive diagnostics to ensure your Claude Code installation is optimized.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx claude-code-templates@latest --health-check
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîå Plugin Dashboard&lt;/h3&gt; 
&lt;p&gt;View marketplaces, installed plugins, and manage permissions from a unified interface.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx claude-code-templates@latest --plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.aitmpl.com/"&gt;üìö docs.aitmpl.com&lt;/a&gt;&lt;/strong&gt; - Complete guides, examples, and API reference for all components and tools.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! &lt;strong&gt;&lt;a href="https://aitmpl.com"&gt;Browse existing templates&lt;/a&gt;&lt;/strong&gt; to see what's available, then check our &lt;a href="https://raw.githubusercontent.com/davila7/claude-code-templates/main/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to add your own agents, commands, MCPs, settings, or hooks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Please read our &lt;a href="https://raw.githubusercontent.com/davila7/claude-code-templates/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; before contributing.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Attribution&lt;/h2&gt; 
&lt;p&gt;This collection includes components from multiple sources:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Scientific Skills:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/K-Dense-AI/claude-scientific-skills"&gt;K-Dense-AI/claude-scientific-skills&lt;/a&gt;&lt;/strong&gt; by K-Dense Inc. - MIT License (139 scientific skills for biology, chemistry, medicine, and computational research)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Official Anthropic:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/anthropics/skills"&gt;anthropics/skills&lt;/a&gt;&lt;/strong&gt; - Official Anthropic skills (21 skills)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/anthropics/claude-code"&gt;anthropics/claude-code&lt;/a&gt;&lt;/strong&gt; - Development guides and examples (10 skills)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Community Skills &amp;amp; Agents:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/obra/superpowers"&gt;obra/superpowers&lt;/a&gt;&lt;/strong&gt; by Jesse Obra - MIT License (14 workflow skills)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/alirezarezvani/claude-skills"&gt;alirezarezvani/claude-skills&lt;/a&gt;&lt;/strong&gt; by Alireza Rezvani - MIT License (36 professional role skills)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/wshobson/agents"&gt;wshobson/agents&lt;/a&gt;&lt;/strong&gt; by wshobson - MIT License (48 agents)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NerdyChefsAI Skills&lt;/strong&gt; - Community contribution - MIT License (specialized enterprise skills)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Commands &amp;amp; Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/hesreallyhim/awesome-claude-code"&gt;awesome-claude-code&lt;/a&gt;&lt;/strong&gt; by hesreallyhim - CC0 1.0 Universal (21 commands)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/mehdi-lamrani/awesome-claude-skills"&gt;awesome-claude-skills&lt;/a&gt;&lt;/strong&gt; - Apache 2.0 (community skills)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;move-code-quality-skill&lt;/strong&gt; - MIT License&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;cocoindex-claude&lt;/strong&gt; - Apache 2.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each of these resources retains its &lt;strong&gt;original license and attribution&lt;/strong&gt;, as defined by their respective authors. We respect and credit all original creators for their work and contributions to the Claude ecosystem.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/davila7/claude-code-templates/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üîó Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Browse Templates&lt;/strong&gt;: &lt;a href="https://aitmpl.com"&gt;aitmpl.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Documentation&lt;/strong&gt;: &lt;a href="https://docs.aitmpl.com"&gt;docs.aitmpl.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üí¨ Community&lt;/strong&gt;: &lt;a href="https://github.com/davila7/claude-code-templates/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üêõ Issues&lt;/strong&gt;: &lt;a href="https://github.com/davila7/claude-code-templates/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/davila7/claude-code-templates"&gt;&lt;img src="https://starchart.cc/davila7/claude-code-templates.svg?variant=adaptive" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;‚≠ê Found this useful? Give us a star to support the project!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://buymeacoffee.com/daniavila"&gt;&lt;img src="https://img.buymeacoffee.com/button-api/?text=Buy%20me%20a%20coffee&amp;amp;slug=daniavila&amp;amp;button_colour=FFDD00&amp;amp;font_colour=000000&amp;amp;font_family=Cookie&amp;amp;outline_colour=000000&amp;amp;coffee_colour=ffffff" alt="Buy Me A Coffee" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sinelaw/fresh</title>
      <link>https://github.com/sinelaw/fresh</link>
      <description>&lt;p&gt;Text editor for your terminal: easy, powerful and fast&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Fresh&lt;/h1&gt; 
&lt;p&gt;A terminal-based text editor. &lt;a href="https://sinelaw.github.io/fresh/"&gt;Official Website ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#installation"&gt;üì¶ Installation Instructions&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#contributing"&gt;Contributing&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Why?&lt;/h2&gt; 
&lt;p&gt;Why another text editor? Fresh brings the intuitive, conventional UX of editors like VS Code and Sublime Text to the terminal.&lt;/p&gt; 
&lt;p&gt;While veterans like Emacs and Vim - and newer editors like Neovim and Helix - are excellent for power users who prefer modal, highly specialized workflows, they often present a steep learning curve for those used to standard GUI interactions. Fresh is built for the developer who wants a familiar, non-modal experience out-of-the-box, without sacrificing the speed and portability of the command line. Keyboard bindings, mouse support, menus, command palette etc. are all designed to be familiar to most modern users.&lt;/p&gt; 
&lt;p&gt;Architecturally, Fresh is built to handle multi-gigabyte files or slow network streams efficiently, maintaining a negligible memory overhead regardless of file size. While traditional editors struggle with latency and RAM bloat on large files, Fresh delivers consistent, high-speed performance on any scale.&lt;/p&gt; 
&lt;p&gt;The goal for Fresh is to be an intuitive and accessible, high-performance terminal-based editor that "just works" on any hardware, for everyone.&lt;/p&gt; 
&lt;h2&gt;Discovery &amp;amp; Ease of Use&lt;/h2&gt; 
&lt;p&gt;Fresh is designed for discovery. It features native UIs, a full Menu system, and a powerful Command Palette. With full mouse support, transitioning from graphical editors is seamless.&lt;/p&gt; 
&lt;h2&gt;Modern Extensibility&lt;/h2&gt; 
&lt;p&gt;Extend Fresh easily using modern tools. Plugins are written in TypeScript and run securely in a sandboxed Deno environment, providing access to a modern JavaScript ecosystem without compromising stability.&lt;/p&gt; 
&lt;h2&gt;Low-Latency Performance&lt;/h2&gt; 
&lt;p&gt;Fresh is engineered for speed. It delivers a low-latency experience, with text appearing instantly. The editor is designed to be light and fast, reliably opening and editing &lt;a href="https://noamlewis.com/blog/2025/12/09/how-fresh-loads-huge-files-fast"&gt;huge files up to multi-gigabyte sizes&lt;/a&gt; without slowdown.&lt;/p&gt; 
&lt;h2&gt;Comprehensive Feature Set&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;File Management&lt;/strong&gt;: open/save/new/close, file explorer, tabs, auto-revert, git file finder&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Editing&lt;/strong&gt;: undo/redo, multi-cursor, block selection, smart indent, comments, clipboard&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search &amp;amp; Replace&lt;/strong&gt;: incremental search, find in selection, query replace, git grep&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Navigation&lt;/strong&gt;: go to line/bracket, word movement, position history, bookmarks, error navigation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Views &amp;amp; Layout&lt;/strong&gt;: split panes, line numbers, line wrap, backgrounds, markdown preview&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Language Server (LSP)&lt;/strong&gt;: go to definition, references, hover, code actions, rename, diagnostics, autocompletion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Productivity&lt;/strong&gt;: command palette, menu bar, keyboard macros, git log, diagnostics panel&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Plugins &amp;amp; Extensibility&lt;/strong&gt;: TypeScript plugins, color highlighter, TODO highlighter, merge conflicts, path complete, keymaps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sinelaw/fresh/master/docs/screenshot1.png" alt="Fresh Screenshot" /&gt; &lt;img src="https://raw.githubusercontent.com/sinelaw/fresh/master/docs/screenshot2.png" alt="Fresh Screenshot" /&gt; &lt;img src="https://raw.githubusercontent.com/sinelaw/fresh/master/docs/screenshot3.png" alt="Fresh Screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Quick install (autodetect best method):&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;curl https://raw.githubusercontent.com/sinelaw/fresh/refs/heads/master/scripts/install.sh | sh&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Or, pick your preferred method:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#brew"&gt;brew&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Bazzite/Bluefin/Aurora Linux&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#brew"&gt;brew&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arch Linux&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#arch-linux-aur"&gt;AUR&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Debian/Ubuntu&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#debianubuntu-deb"&gt;.deb&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fedora/RHEL&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#fedorarhelopensuse-rpm"&gt;.rpm&lt;/a&gt;, &lt;a href="https://terra.fyralabs.com/"&gt;Terra&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux (any distro)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#appimage"&gt;AppImage&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#flatpak"&gt;Flatpak&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All platforms&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#pre-built-binaries"&gt;Pre-built binaries&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;npm&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#npm"&gt;npm / npx&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Rust users (Fast)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#using-cargo-binstall"&gt;cargo-binstall&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Rust users&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#from-cratesio"&gt;crates.io&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nix&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#nix-flakes"&gt;Nix flakes&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Developers&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/#from-source"&gt;From source&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Brew&lt;/h3&gt; 
&lt;p&gt;On macOS and some linux distros (Bazzite/Bluefin/Aurora):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew tap sinelaw/fresh
brew install fresh-editor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Arch Linux (&lt;a href="https://aur.archlinux.org/packages/fresh-editor-bin"&gt;AUR&lt;/a&gt;)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Binary package (recommended, faster install):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://aur.archlinux.org/fresh-editor-bin.git
cd fresh-editor-bin
makepkg --syncdeps --install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Build from source:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://aur.archlinux.org/fresh-editor.git
cd fresh-editor
makepkg --syncdeps --install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Using an AUR helper (such as &lt;code&gt;yay&lt;/code&gt; or &lt;code&gt;paru&lt;/code&gt;):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Binary package (recommended, faster install)
yay -S fresh-editor-bin

# Or build from source
yay -S fresh-editor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debian/Ubuntu (.deb)&lt;/h3&gt; 
&lt;p&gt;Download and install the latest release:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sL $(curl -s https://api.github.com/repos/sinelaw/fresh/releases/latest | grep "browser_download_url.*_$(dpkg --print-architecture)\.deb" | cut -d '"' -f 4) -o fresh-editor.deb &amp;amp;&amp;amp; sudo dpkg -i fresh-editor.deb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or download the &lt;code&gt;.deb&lt;/code&gt; file manually from the &lt;a href="https://github.com/sinelaw/fresh/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Fedora/RHEL/openSUSE (.rpm)&lt;/h3&gt; 
&lt;p&gt;Download and install the latest release:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sL $(curl -s https://api.github.com/repos/sinelaw/fresh/releases/latest | grep "browser_download_url.*\.$(uname -m)\.rpm" | cut -d '"' -f 4) -o fresh-editor.rpm &amp;amp;&amp;amp; sudo rpm -U fresh-editor.rpm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or download the &lt;code&gt;.rpm&lt;/code&gt; file manually from the &lt;a href="https://github.com/sinelaw/fresh/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;AppImage&lt;/h3&gt; 
&lt;p&gt;Download the &lt;code&gt;.AppImage&lt;/code&gt; file from the &lt;a href="https://github.com/sinelaw/fresh/releases"&gt;releases page&lt;/a&gt; and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;chmod +x fresh-editor-VERSION-x86_64.AppImage
./fresh-editor-VERSION-x86_64.AppImage
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;For faster startup&lt;/strong&gt; (recommended): Extract the AppImage instead of running it directly. This avoids the FUSE mount overhead on each launch (~10x faster):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./fresh-editor-VERSION-x86_64.AppImage --appimage-extract
mkdir -p ~/.local/share/fresh-editor ~/.local/bin
mv squashfs-root/* ~/.local/share/fresh-editor/
ln -sf ~/.local/share/fresh-editor/usr/bin/fresh ~/.local/bin/fresh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure &lt;code&gt;~/.local/bin&lt;/code&gt; is in your PATH. Available for x86_64 and aarch64 architectures.&lt;/p&gt; 
&lt;h3&gt;Flatpak&lt;/h3&gt; 
&lt;p&gt;Download the &lt;code&gt;.flatpak&lt;/code&gt; bundle from the &lt;a href="https://github.com/sinelaw/fresh/releases"&gt;releases page&lt;/a&gt; and install:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;flatpak install --user fresh-editor-VERSION-x86_64.flatpak
flatpak run io.github.sinelaw.fresh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/flatpak/README.md"&gt;flatpak/README.md&lt;/a&gt; for building from source.&lt;/p&gt; 
&lt;h3&gt;Pre-built binaries&lt;/h3&gt; 
&lt;p&gt;Download the latest release for your platform from the &lt;a href="https://github.com/sinelaw/fresh/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;npm&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g @fresh-editor/fresh-editor
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or try it without installing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx @fresh-editor/fresh-editor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using cargo-binstall&lt;/h3&gt; 
&lt;p&gt;To install the binary directly without compiling (much faster than crates.io):&lt;/p&gt; 
&lt;p&gt;First, install cargo-binstall if you haven't already&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-binstall
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install fresh&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo binstall fresh-editor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Nix flakes&lt;/h3&gt; 
&lt;p&gt;Run without installing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nix run github:sinelaw/fresh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or install to your profile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nix profile add github:sinelaw/fresh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From crates.io&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install fresh-editor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/sinelaw/fresh.git
cd fresh
cargo build --release
./target/release/fresh [file]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/docs/USER_GUIDE.md"&gt;User Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/docs/PLUGIN_DEVELOPMENT.md"&gt;Plugin Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sinelaw/fresh/master/docs/ARCHITECTURE.md"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thanks for contributing!&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reproduce Before Fixing&lt;/strong&gt;: Always include a test case that reproduces the bug (fails) without the fix, and passes with the fix. This ensures the issue is verified and prevents future regressions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;E2E Tests for New Flows&lt;/strong&gt;: Any new user flow or feature must include an end-to-end (e2e) test. E2E tests send keyboard/mouse events and examines the final rendered output, do not examine internal state.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;No timeouts or time-sensitive tests&lt;/strong&gt;: Use "semantic waiting" (waiting for specific state changes/events) instead of fixed timers to ensure test stability. Wait indefinitely, don't put timeouts inside tests (cargo nextest will timeout externally).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Test isolation&lt;/strong&gt;: Tests should run in parallel. Use the internal clipboard mode in tests to isolate them from the host system and prevent flakiness in CI. Same for other external resources (temp files, etc. should all be isolated between tests, under a per-test temporary workdir).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Required Formatting&lt;/strong&gt;: All code must be formatted with &lt;code&gt;cargo fmt&lt;/code&gt; before submission. PRs that fail formatting checks will not be merged.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cross-Platform Consistency&lt;/strong&gt;: Avoid hard-coding newline or CRLF related logic, consider the buffer mode.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LSP&lt;/strong&gt;: Ensure LSP interactions follow the correct lifecycle (e.g., &lt;code&gt;didOpen&lt;/code&gt; must always precede other requests to avoid server-side errors). Use the appropriate existing helpers for this pattern.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can use tmux + send-keys + render-pane to script ad-hoc tests on the UI, for example when trying to reproduce an issue.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) Noam Lewis&lt;/p&gt; 
&lt;p&gt;This project is licensed under the GNU General Public License v2.0 (GPL-2.0).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google/langextract</title>
      <link>https://github.com/google/langextract</link>
      <description>&lt;p&gt;A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://github.com/google/langextract"&gt; &lt;img src="https://raw.githubusercontent.com/google/langextract/main/docs/_static/logo.svg?sanitize=true" alt="LangExtract Logo" width="128" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;LangExtract&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/langextract/"&gt;&lt;img src="https://img.shields.io/pypi/v/langextract.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/google/langextract"&gt;&lt;img src="https://img.shields.io/github/stars/google/langextract.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;img src="https://github.com/google/langextract/actions/workflows/ci.yaml/badge.svg?sanitize=true" alt="Tests" /&gt; &lt;a href="https://doi.org/10.5281/zenodo.17015089"&gt;&lt;img src="https://zenodo.org/badge/DOI/10.5281/zenodo.17015089.svg?sanitize=true" alt="DOI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#why-langextract"&gt;Why LangExtract?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models"&gt;API Key Setup for Cloud Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#adding-custom-model-providers"&gt;Adding Custom Model Providers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#using-openai-models"&gt;Using OpenAI Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#using-local-llms-with-ollama"&gt;Using Local LLMs with Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#more-examples"&gt;More Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#romeo-and-juliet-full-text-extraction"&gt;&lt;em&gt;Romeo and Juliet&lt;/em&gt; Full Text Extraction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#medication-extraction"&gt;Medication Extraction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#radiology-report-structuring-radextract"&gt;Radiology Report Structuring: RadExtract&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#community-providers"&gt;Community Providers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#testing"&gt;Testing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/langextract/main/#disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;LangExtract is a Python library that uses LLMs to extract structured information from unstructured text documents based on user-defined instructions. It processes materials such as clinical notes or reports, identifying and organizing key details while ensuring the extracted data corresponds to the source text.&lt;/p&gt; 
&lt;h2&gt;Why LangExtract?&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Precise Source Grounding:&lt;/strong&gt; Maps every extraction to its exact location in the source text, enabling visual highlighting for easy traceability and verification.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable Structured Outputs:&lt;/strong&gt; Enforces a consistent output schema based on your few-shot examples, leveraging controlled generation in supported models like Gemini to guarantee robust, structured results.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimized for Long Documents:&lt;/strong&gt; Overcomes the "needle-in-a-haystack" challenge of large document extraction by using an optimized strategy of text chunking, parallel processing, and multiple passes for higher recall.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Visualization:&lt;/strong&gt; Instantly generates a self-contained, interactive HTML file to visualize and review thousands of extracted entities in their original context.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible LLM Support:&lt;/strong&gt; Supports your preferred models, from cloud-based LLMs like the Google Gemini family to local open-source models via the built-in Ollama interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adaptable to Any Domain:&lt;/strong&gt; Define extraction tasks for any domain using just a few examples. LangExtract adapts to your needs without requiring any model fine-tuning.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leverages LLM World Knowledge:&lt;/strong&gt; Utilize precise prompt wording and few-shot examples to influence how the extraction task may utilize LLM knowledge. The accuracy of any inferred information and its adherence to the task specification are contingent upon the selected LLM, the complexity of the task, the clarity of the prompt instructions, and the nature of the prompt examples.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Using cloud-hosted models like Gemini requires an API key. See the &lt;a href="https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models"&gt;API Key Setup&lt;/a&gt; section for instructions on how to get and configure your key.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Extract structured information with just a few lines of code.&lt;/p&gt; 
&lt;h3&gt;1. Define Your Extraction Task&lt;/h3&gt; 
&lt;p&gt;First, create a prompt that clearly describes what you want to extract. Then, provide a high-quality example to guide the model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import langextract as lx
import textwrap

# 1. Define the prompt and extraction rules
prompt = textwrap.dedent("""\
    Extract characters, emotions, and relationships in order of appearance.
    Use exact text for extractions. Do not paraphrase or overlap entities.
    Provide meaningful attributes for each entity to add context.""")

# 2. Provide a high-quality example to guide the model
examples = [
    lx.data.ExampleData(
        text="ROMEO. But soft! What light through yonder window breaks? It is the east, and Juliet is the sun.",
        extractions=[
            lx.data.Extraction(
                extraction_class="character",
                extraction_text="ROMEO",
                attributes={"emotional_state": "wonder"}
            ),
            lx.data.Extraction(
                extraction_class="emotion",
                extraction_text="But soft!",
                attributes={"feeling": "gentle awe"}
            ),
            lx.data.Extraction(
                extraction_class="relationship",
                extraction_text="Juliet is the sun",
                attributes={"type": "metaphor"}
            ),
        ]
    )
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Examples drive model behavior. Each &lt;code&gt;extraction_text&lt;/code&gt; should ideally be verbatim from the example's &lt;code&gt;text&lt;/code&gt; (no paraphrasing), listed in order of appearance. LangExtract raises &lt;code&gt;Prompt alignment&lt;/code&gt; warnings by default if examples don't follow this pattern‚Äîresolve these for best results.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;2. Run the Extraction&lt;/h3&gt; 
&lt;p&gt;Provide your input text and the prompt materials to the &lt;code&gt;lx.extract&lt;/code&gt; function.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# The input text to be processed
input_text = "Lady Juliet gazed longingly at the stars, her heart aching for Romeo"

# Run the extraction
result = lx.extract(
    text_or_documents=input_text,
    prompt_description=prompt,
    examples=examples,
    model_id="gemini-2.5-flash",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Model Selection&lt;/strong&gt;: &lt;code&gt;gemini-2.5-flash&lt;/code&gt; is the recommended default, offering an excellent balance of speed, cost, and quality. For highly complex tasks requiring deeper reasoning, &lt;code&gt;gemini-2.5-pro&lt;/code&gt; may provide superior results. For large-scale or production use, a Tier 2 Gemini quota is suggested to increase throughput and avoid rate limits. See the &lt;a href="https://ai.google.dev/gemini-api/docs/rate-limits#tier-2"&gt;rate-limit documentation&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Model Lifecycle&lt;/strong&gt;: Note that Gemini models have a lifecycle with defined retirement dates. Users should consult the &lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions"&gt;official model version documentation&lt;/a&gt; to stay informed about the latest stable and legacy versions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;3. Visualize the Results&lt;/h3&gt; 
&lt;p&gt;The extractions can be saved to a &lt;code&gt;.jsonl&lt;/code&gt; file, a popular format for working with language model data. LangExtract can then generate an interactive HTML visualization from this file to review the entities in context.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Save the results to a JSONL file
lx.io.save_annotated_documents([result], output_name="extraction_results.jsonl", output_dir=".")

# Generate the visualization from the file
html_content = lx.visualize("extraction_results.jsonl")
with open("visualization.html", "w") as f:
    if hasattr(html_content, 'data'):
        f.write(html_content.data)  # For Jupyter/Colab
    else:
        f.write(html_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This creates an animated and interactive HTML file:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/google/langextract/main/docs/_static/romeo_juliet_basic.gif" alt="Romeo and Juliet Basic Visualization " /&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note on LLM Knowledge Utilization:&lt;/strong&gt; This example demonstrates extractions that stay close to the text evidence - extracting "longing" for Lady Juliet's emotional state and identifying "yearning" from "gazed longingly at the stars." The task could be modified to generate attributes that draw more heavily from the LLM's world knowledge (e.g., adding &lt;code&gt;"identity": "Capulet family daughter"&lt;/code&gt; or &lt;code&gt;"literary_context": "tragic heroine"&lt;/code&gt;). The balance between text-evidence and knowledge-inference is controlled by your prompt instructions and example attributes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Scaling to Longer Documents&lt;/h3&gt; 
&lt;p&gt;For larger texts, you can process entire documents directly from URLs with parallel processing and enhanced sensitivity:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Process Romeo &amp;amp; Juliet directly from Project Gutenberg
result = lx.extract(
    text_or_documents="https://www.gutenberg.org/files/1513/1513-0.txt",
    prompt_description=prompt,
    examples=examples,
    model_id="gemini-2.5-flash",
    extraction_passes=3,    # Improves recall through multiple passes
    max_workers=20,         # Parallel processing for speed
    max_char_buffer=1000    # Smaller contexts for better accuracy
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This approach can extract hundreds of entities from full novels while maintaining high accuracy. The interactive visualization seamlessly handles large result sets, making it easy to explore hundreds of entities from the output JSONL file. &lt;strong&gt;&lt;a href="https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md"&gt;See the full &lt;em&gt;Romeo and Juliet&lt;/em&gt; extraction example ‚Üí&lt;/a&gt;&lt;/strong&gt; for detailed results and performance insights.&lt;/p&gt; 
&lt;h3&gt;Vertex AI Batch Processing&lt;/h3&gt; 
&lt;p&gt;Save costs on large-scale tasks by enabling Vertex AI Batch API: &lt;code&gt;language_model_params={"vertexai": True, "batch": {"enabled": True}}&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;See an example of the Vertex AI Batch API usage in &lt;a href="https://raw.githubusercontent.com/google/langextract/main/docs/examples/batch_api_example.md"&gt;this example&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;From PyPI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install langextract
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Recommended for most users. For isolated environments, consider using a virtual environment:&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv langextract_env
source langextract_env/bin/activate  # On Windows: langextract_env\Scripts\activate
pip install langextract
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;p&gt;LangExtract uses modern Python packaging with &lt;code&gt;pyproject.toml&lt;/code&gt; for dependency management:&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Installing with &lt;code&gt;-e&lt;/code&gt; puts the package in development mode, allowing you to modify the code without reinstalling.&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/google/langextract.git
cd langextract

# For basic installation:
pip install -e .

# For development (includes linting tools):
pip install -e ".[dev]"

# For testing (includes pytest):
pip install -e ".[test]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t langextract .
docker run --rm -e LANGEXTRACT_API_KEY="your-api-key" langextract python your_script.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;API Key Setup for Cloud Models&lt;/h2&gt; 
&lt;p&gt;When using LangExtract with cloud-hosted models (like Gemini or OpenAI), you'll need to set up an API key. On-device models don't require an API key. For developers using local LLMs, LangExtract offers built-in support for Ollama and can be extended to other third-party APIs by updating the inference endpoints.&lt;/p&gt; 
&lt;h3&gt;API Key Sources&lt;/h3&gt; 
&lt;p&gt;Get API keys from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aistudio.google.com/app/apikey"&gt;AI Studio&lt;/a&gt; for Gemini models&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/sdks/overview"&gt;Vertex AI&lt;/a&gt; for enterprise use&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://platform.openai.com/api-keys"&gt;OpenAI Platform&lt;/a&gt; for OpenAI models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setting up API key in your environment&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Environment Variable&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export LANGEXTRACT_API_KEY="your-api-key-here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: .env File (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Add your API key to a &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Add API key to .env file
cat &amp;gt;&amp;gt; .env &amp;lt;&amp;lt; 'EOF'
LANGEXTRACT_API_KEY=your-api-key-here
EOF

# Keep your API key secure
echo '.env' &amp;gt;&amp;gt; .gitignore
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In your Python code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import langextract as lx

result = lx.extract(
    text_or_documents=input_text,
    prompt_description="Extract information...",
    examples=[...],
    model_id="gemini-2.5-flash"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 3: Direct API Key (Not Recommended for Production)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can also provide the API key directly in your code, though this is not recommended for production use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result = lx.extract(
    text_or_documents=input_text,
    prompt_description="Extract information...",
    examples=[...],
    model_id="gemini-2.5-flash",
    api_key="your-api-key-here"  # Only use this for testing/development
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 4: Vertex AI (Service Accounts)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Use &lt;a href="https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform"&gt;Vertex AI&lt;/a&gt; for authentication with service accounts:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result = lx.extract(
    text_or_documents=input_text,
    prompt_description="Extract information...",
    examples=[...],
    model_id="gemini-2.5-flash",
    language_model_params={
        "vertexai": True,
        "project": "your-project-id",
        "location": "global"  # or regional endpoint
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Adding Custom Model Providers&lt;/h2&gt; 
&lt;p&gt;LangExtract supports custom LLM providers via a lightweight plugin system. You can add support for new models without changing core code.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add new model support independently of the core library&lt;/li&gt; 
 &lt;li&gt;Distribute your provider as a separate Python package&lt;/li&gt; 
 &lt;li&gt;Keep custom dependencies isolated&lt;/li&gt; 
 &lt;li&gt;Override or extend built-in providers via priority-based resolution&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the detailed guide in &lt;a href="https://raw.githubusercontent.com/google/langextract/main/langextract/providers/README.md"&gt;Provider System Documentation&lt;/a&gt; to learn how to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Register a provider with &lt;code&gt;@registry.register(...)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Publish an entry point for discovery&lt;/li&gt; 
 &lt;li&gt;Optionally provide a schema with &lt;code&gt;get_schema_class()&lt;/code&gt; for structured output&lt;/li&gt; 
 &lt;li&gt;Integrate with the factory via &lt;code&gt;create_model(...)&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Using OpenAI Models&lt;/h2&gt; 
&lt;p&gt;LangExtract supports OpenAI models (requires optional dependency: &lt;code&gt;pip install langextract[openai]&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import langextract as lx

result = lx.extract(
    text_or_documents=input_text,
    prompt_description=prompt,
    examples=examples,
    model_id="gpt-4o",  # Automatically selects OpenAI provider
    api_key=os.environ.get('OPENAI_API_KEY'),
    fence_output=True,
    use_schema_constraints=False
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: OpenAI models require &lt;code&gt;fence_output=True&lt;/code&gt; and &lt;code&gt;use_schema_constraints=False&lt;/code&gt; because LangExtract doesn't implement schema constraints for OpenAI yet.&lt;/p&gt; 
&lt;h2&gt;Using Local LLMs with Ollama&lt;/h2&gt; 
&lt;p&gt;LangExtract supports local inference using Ollama, allowing you to run models without API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import langextract as lx

result = lx.extract(
    text_or_documents=input_text,
    prompt_description=prompt,
    examples=examples,
    model_id="gemma2:2b",  # Automatically selects Ollama provider
    model_url="http://localhost:11434",
    fence_output=False,
    use_schema_constraints=False
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Quick setup:&lt;/strong&gt; Install Ollama from &lt;a href="https://ollama.com/"&gt;ollama.com&lt;/a&gt;, run &lt;code&gt;ollama pull gemma2:2b&lt;/code&gt;, then &lt;code&gt;ollama serve&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For detailed installation, Docker setup, and examples, see &lt;a href="https://raw.githubusercontent.com/google/langextract/main/examples/ollama/"&gt;&lt;code&gt;examples/ollama/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;More Examples&lt;/h2&gt; 
&lt;p&gt;Additional examples of LangExtract in action:&lt;/p&gt; 
&lt;h3&gt;&lt;em&gt;Romeo and Juliet&lt;/em&gt; Full Text Extraction&lt;/h3&gt; 
&lt;p&gt;LangExtract can process complete documents directly from URLs. This example demonstrates extraction from the full text of &lt;em&gt;Romeo and Juliet&lt;/em&gt; from Project Gutenberg (147,843 characters), showing parallel processing, sequential extraction passes, and performance optimization for long document processing.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md"&gt;View &lt;em&gt;Romeo and Juliet&lt;/em&gt; Full Text Example ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Medication Extraction&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; This demonstration is for illustrative purposes of LangExtract's baseline capability only. It does not represent a finished or approved product, is not intended to diagnose or suggest treatment of any disease or condition, and should not be used for medical advice.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;LangExtract excels at extracting structured medical information from clinical text. These examples demonstrate both basic entity recognition (medication names, dosages, routes) and relationship extraction (connecting medications to their attributes), showing LangExtract's effectiveness for healthcare applications.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/google/langextract/raw/main/docs/examples/medication_examples.md"&gt;View Medication Examples ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Radiology Report Structuring: RadExtract&lt;/h3&gt; 
&lt;p&gt;Explore RadExtract, a live interactive demo on HuggingFace Spaces that shows how LangExtract can automatically structure radiology reports. Try it directly in your browser with no setup required.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://huggingface.co/spaces/google/radextract"&gt;View RadExtract Demo ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Community Providers&lt;/h2&gt; 
&lt;p&gt;Extend LangExtract with custom model providers! Check out our &lt;a href="https://raw.githubusercontent.com/google/langextract/main/COMMUNITY_PROVIDERS.md"&gt;Community Provider Plugins&lt;/a&gt; registry to discover providers created by the community or add your own.&lt;/p&gt; 
&lt;p&gt;For detailed instructions on creating a provider plugin, see the &lt;a href="https://raw.githubusercontent.com/google/langextract/main/examples/custom_provider_plugin/"&gt;Custom Provider Plugin Example&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! See &lt;a href="https://github.com/google/langextract/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; to get started with development, testing, and pull requests. You must sign a &lt;a href="https://cla.developers.google.com/about"&gt;Contributor License Agreement&lt;/a&gt; before submitting patches.&lt;/p&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;p&gt;To run tests locally from the source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/google/langextract.git
cd langextract

# Install with test dependencies
pip install -e ".[test]"

# Run all tests
pytest tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or reproduce the full CI matrix locally with tox:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;tox  # runs pylint + pytest on Python 3.10 and 3.11
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ollama Integration Testing&lt;/h3&gt; 
&lt;p&gt;If you have Ollama installed locally, you can run integration tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test Ollama integration (requires Ollama running with gemma2:2b model)
tox -e ollama-integration
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This test will automatically detect if Ollama is available and run real inference tests.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Code Formatting&lt;/h3&gt; 
&lt;p&gt;This project uses automated formatting tools to maintain consistent code style:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Auto-format all code
./autoformat.sh

# Or run formatters separately
isort langextract tests --profile google --line-length 80
pyink langextract tests --config pyproject.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Pre-commit Hooks&lt;/h3&gt; 
&lt;p&gt;For automatic formatting checks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pre-commit install  # One-time setup
pre-commit run --all-files  # Manual run
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linting&lt;/h3&gt; 
&lt;p&gt;Run linting before submitting PRs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pylint --rcfile=.pylintrc langextract tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/google/langextract/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for full development guidelines.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This is not an officially supported Google product. If you use LangExtract in production or publications, please cite accordingly and acknowledge usage. Use is subject to the &lt;a href="https://github.com/google/langextract/raw/main/LICENSE"&gt;Apache 2.0 License&lt;/a&gt;. For health-related applications, use of LangExtract is also subject to the &lt;a href="https://developers.google.com/health-ai-developer-foundations/terms"&gt;Health AI Developer Foundations Terms of Use&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Happy Extracting!&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/skills</title>
      <link>https://github.com/anthropics/skills</link>
      <description>&lt;p&gt;Public repository for Agent Skills&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This repository contains Anthropic's implementation of skills for Claude. For information about the Agent Skills standard, see &lt;a href="http://agentskills.io"&gt;agentskills.io&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Skills&lt;/h1&gt; 
&lt;p&gt;Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that's creating documents with your company's brand guidelines, analyzing data using your organization's specific workflows, or automating personal tasks.&lt;/p&gt; 
&lt;p&gt;For more information, check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512176-what-are-skills"&gt;What are skills?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512180-using-skills-in-claude"&gt;Using skills in Claude&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512198-creating-custom-skills"&gt;How to create custom skills&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills"&gt;Equipping agents for the real world with Agent Skills&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;About This Repository&lt;/h1&gt; 
&lt;p&gt;This repository contains skills that demonstrate what's possible with Claude's skills system. These skills range from creative applications (art, music, design) to technical tasks (testing web apps, MCP server generation) to enterprise workflows (communications, branding, etc.).&lt;/p&gt; 
&lt;p&gt;Each skill is self-contained in its own folder with a &lt;code&gt;SKILL.md&lt;/code&gt; file containing the instructions and metadata that Claude uses. Browse through these skills to get inspiration for your own skills or to understand different patterns and approaches.&lt;/p&gt; 
&lt;p&gt;Many skills in this repo are open source (Apache 2.0). We've also included the document creation &amp;amp; editing skills that power &lt;a href="https://www.anthropic.com/news/create-files"&gt;Claude's document capabilities&lt;/a&gt; under the hood in the &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/docx"&gt;&lt;code&gt;skills/docx&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/pdf"&gt;&lt;code&gt;skills/pdf&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/pptx"&gt;&lt;code&gt;skills/pptx&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/xlsx"&gt;&lt;code&gt;skills/xlsx&lt;/code&gt;&lt;/a&gt; subfolders. These are source-available, not open source, but we wanted to share these with developers as a reference for more complex skills that are actively used in a production AI application.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;These skills are provided for demonstration and educational purposes only.&lt;/strong&gt; While some of these capabilities may be available in Claude, the implementations and behaviors you receive from Claude may differ from what is shown in these skills. These skills are meant to illustrate patterns and possibilities. Always test skills thoroughly in your own environment before relying on them for critical tasks.&lt;/p&gt; 
&lt;h1&gt;Skill Sets&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills"&gt;./skills&lt;/a&gt;: Skill examples for Creative &amp;amp; Design, Development &amp;amp; Technical, Enterprise &amp;amp; Communication, and Document Skills&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/spec"&gt;./spec&lt;/a&gt;: The Agent Skills specification&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/template"&gt;./template&lt;/a&gt;: Skill template&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Try in Claude Code, Claude.ai, and the API&lt;/h1&gt; 
&lt;h2&gt;Claude Code&lt;/h2&gt; 
&lt;p&gt;You can register this repository as a Claude Code Plugin marketplace by running the following command in Claude Code:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/plugin marketplace add anthropics/skills
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, to install a specific set of skills:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Select &lt;code&gt;Browse and install plugins&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;anthropic-agent-skills&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;document-skills&lt;/code&gt; or &lt;code&gt;example-skills&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;Install now&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Alternatively, directly install either Plugin via:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/plugin install document-skills@anthropic-agent-skills
/plugin install example-skills@anthropic-agent-skills
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After installing the plugin, you can use the skill by just mentioning it. For instance, if you install the &lt;code&gt;document-skills&lt;/code&gt; plugin from the marketplace, you can ask Claude Code to do something like: "Use the PDF skill to extract the form fields from &lt;code&gt;path/to/some-file.pdf&lt;/code&gt;"&lt;/p&gt; 
&lt;h2&gt;Claude.ai&lt;/h2&gt; 
&lt;p&gt;These example skills are all already available to paid plans in Claude.ai.&lt;/p&gt; 
&lt;p&gt;To use any skill from this repository or upload custom skills, follow the instructions in &lt;a href="https://support.claude.com/en/articles/12512180-using-skills-in-claude#h_a4222fa77b"&gt;Using skills in Claude&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Claude API&lt;/h2&gt; 
&lt;p&gt;You can use Anthropic's pre-built skills, and upload custom skills, via the Claude API. See the &lt;a href="https://docs.claude.com/en/api/skills-guide#creating-a-skill"&gt;Skills API Quickstart&lt;/a&gt; for more.&lt;/p&gt; 
&lt;h1&gt;Creating a Basic Skill&lt;/h1&gt; 
&lt;p&gt;Skills are simple to create - just a folder with a &lt;code&gt;SKILL.md&lt;/code&gt; file containing YAML frontmatter and instructions. You can use the &lt;strong&gt;template-skill&lt;/strong&gt; in this repository as a starting point:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;---
name: my-skill-name
description: A clear description of what this skill does and when to use it
---

# My Skill Name

[Add your instructions here that Claude will follow when this skill is active]

## Examples
- Example usage 1
- Example usage 2

## Guidelines
- Guideline 1
- Guideline 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The frontmatter requires only two fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; - A unique identifier for your skill (lowercase, hyphens for spaces)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; - A complete description of what the skill does and when to use it&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The markdown content below contains the instructions, examples, and guidelines that Claude will follow. For more details, see &lt;a href="https://support.claude.com/en/articles/12512198-creating-custom-skills"&gt;How to create custom skills&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Partner Skills&lt;/h1&gt; 
&lt;p&gt;Skills are a great way to teach Claude how to get better at using specific pieces of software. As we see awesome example skills from partners, we may highlight some of them here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Notion&lt;/strong&gt; - &lt;a href="https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0"&gt;Notion Skills for Claude&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>resemble-ai/chatterbox</title>
      <link>https://github.com/resemble-ai/chatterbox</link>
      <description>&lt;p&gt;SoTA open-source TTS&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/Chatterbox-Turbo.jpg" alt="Chatterbox Turbo Image" /&gt;&lt;/p&gt; 
&lt;h1&gt;Chatterbox TTS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;&lt;img src="https://img.shields.io/badge/listen-demo_samples-blue" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;&lt;img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://podonos.com/resembleai/chatterbox"&gt;&lt;img src="https://static-public.podonos.com/badges/insight-on-pdns-sm-dark.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;&lt;img src="https://img.shields.io/discord/1377773249798344776?label=join%20discord&amp;amp;logo=discord&amp;amp;style=flat" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;_Made with ‚ô•Ô∏è by &lt;a href="https://resemble.ai" target="_blank"&gt;&lt;img width="100" alt="resemble-logo-horizontal" src="https://github.com/user-attachments/assets/35cf756b-3506-4943-9c72-c05ddfa4e525" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Chatterbox&lt;/strong&gt; is a family of three state-of-the-art, open-source text-to-speech models by Resemble AI.&lt;/p&gt; 
&lt;p&gt;We are excited to introduce &lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;, our most efficient model yet. Built on a streamlined 350M parameter architecture, &lt;strong&gt;Turbo&lt;/strong&gt; delivers high-quality speech with less compute and VRAM than our previous models. We have also distilled the speech-token-to-mel decoder, previously a bottleneck, reducing generation from 10 steps to just &lt;strong&gt;one&lt;/strong&gt;, while retaining high-fidelity audio output.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Paralinguistic tags&lt;/strong&gt; are now native to the Turbo model, allowing you to use &lt;code&gt;[cough]&lt;/code&gt;, &lt;code&gt;[laugh]&lt;/code&gt;, &lt;code&gt;[chuckle]&lt;/code&gt;, and more to add distinct realism. While Turbo was built primarily for low-latency voice agents, it excels at narration and creative workflows.&lt;/p&gt; 
&lt;p&gt;If you like the model but need to scale or tune it for higher accuracy, check out our competitively priced TTS service (&lt;a href="https://resemble.ai"&gt;link&lt;/a&gt;). It delivers reliable performance with ultra-low latency of sub 200ms‚Äîideal for production use in agents, applications, or interactive media.&lt;/p&gt; 
&lt;img width="1200" height="600" alt="Podonos Turbo Eval" src="https://storage.googleapis.com/chatterbox-demo-samples/turbo/podonos_turbo.png" /&gt; 
&lt;h3&gt;‚ö° Model Zoo&lt;/h3&gt; 
&lt;p&gt;Choose the right model for your application.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="left"&gt;Size&lt;/th&gt; 
   &lt;th align="left"&gt;Languages&lt;/th&gt; 
   &lt;th align="left"&gt;Key Features&lt;/th&gt; 
   &lt;th align="left"&gt;Best For&lt;/th&gt; 
   &lt;th align="left"&gt;ü§ó&lt;/th&gt; 
   &lt;th align="left"&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;350M&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Paralinguistic Tags (&lt;code&gt;[laugh]&lt;/code&gt;), Lower Compute and VRAM&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot voice agents, Production&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox-Multilingual &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#supported-languages"&gt;(Language list)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;23+&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot cloning, Multiple Languages&lt;/td&gt; 
   &lt;td align="left"&gt;Global applications, Localization&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox-Multilingual-TTS"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#original-chatterbox-tips"&gt;(Tips and Tricks)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;English&lt;/td&gt; 
   &lt;td align="left"&gt;CFG &amp;amp; Exaggeration tuning&lt;/td&gt; 
   &lt;td align="left"&gt;General zero-shot TTS with creative controls&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install chatterbox-tts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# conda create -yn chatterbox python=3.11
# conda activate chatterbox

git clone https://github.com/resemble-ai/chatterbox.git
cd chatterbox
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We developed and tested Chatterbox on Python 3.11 on Debian 11 OS; the versions of the dependencies are pinned in &lt;code&gt;pyproject.toml&lt;/code&gt; to ensure consistency. You can modify the code or dependencies in this installation mode.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h5&gt;Chatterbox-Turbo&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torchaudio as ta
import torch
from chatterbox.tts_turbo import ChatterboxTurboTTS

# Load the Turbo model
model = ChatterboxTurboTTS.from_pretrained(device="cuda")

# Generate with Paralinguistic Tags
text = "Hi there, Sarah here from MochaFone calling you back [chuckle], have you got one minute to chat about the billing issue?"

# Generate audio (requires a reference clip for voice cloning)
wav = model.generate(text, audio_prompt_path="your_10s_ref_clip.wav")

ta.save("test-turbo.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Chatterbox and Chatterbox-Multilingual&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
from chatterbox.mtl_tts import ChatterboxMultilingualTTS

# English example
model = ChatterboxTTS.from_pretrained(device="cuda")

text = "Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy's Nexus in an epic late-game pentakill."
wav = model.generate(text)
ta.save("test-english.wav", wav, model.sr)

# Multilingual examples
multilingual_model = ChatterboxMultilingualTTS.from_pretrained(device=device)

french_text = "Bonjour, comment √ßa va? Ceci est le mod√®le de synth√®se vocale multilingue Chatterbox, il prend en charge 23 langues."
wav_french = multilingual_model.generate(spanish_text, language_id="fr")
ta.save("test-french.wav", wav_french, model.sr)

chinese_text = "‰Ω†Â•ΩÔºå‰ªäÂ§©Â§©Ê∞îÁúü‰∏çÈîôÔºåÂ∏åÊúõ‰Ω†Êúâ‰∏Ä‰∏™ÊÑâÂø´ÁöÑÂë®Êú´„ÄÇ"
wav_chinese = multilingual_model.generate(chinese_text, language_id="zh")
ta.save("test-chinese.wav", wav_chinese, model.sr)

# If you want to synthesize with a different voice, specify the audio prompt
AUDIO_PROMPT_PATH = "YOUR_FILE.wav"
wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)
ta.save("test-2.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;code&gt;example_tts.py&lt;/code&gt; and &lt;code&gt;example_vc.py&lt;/code&gt; for more examples.&lt;/p&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;p&gt;Arabic (ar) ‚Ä¢ Danish (da) ‚Ä¢ German (de) ‚Ä¢ Greek (el) ‚Ä¢ English (en) ‚Ä¢ Spanish (es) ‚Ä¢ Finnish (fi) ‚Ä¢ French (fr) ‚Ä¢ Hebrew (he) ‚Ä¢ Hindi (hi) ‚Ä¢ Italian (it) ‚Ä¢ Japanese (ja) ‚Ä¢ Korean (ko) ‚Ä¢ Malay (ms) ‚Ä¢ Dutch (nl) ‚Ä¢ Norwegian (no) ‚Ä¢ Polish (pl) ‚Ä¢ Portuguese (pt) ‚Ä¢ Russian (ru) ‚Ä¢ Swedish (sv) ‚Ä¢ Swahili (sw) ‚Ä¢ Turkish (tr) ‚Ä¢ Chinese (zh)&lt;/p&gt; 
&lt;h2&gt;Original Chatterbox Tips&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;General Use (TTS and Voice Agents):&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure that the reference clip matches the specified language tag. Otherwise, language transfer outputs may inherit the accent of the reference clip‚Äôs language. To mitigate this, set &lt;code&gt;cfg_weight&lt;/code&gt; to &lt;code&gt;0&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;The default settings (&lt;code&gt;exaggeration=0.5&lt;/code&gt;, &lt;code&gt;cfg_weight=0.5&lt;/code&gt;) work well for most prompts across all languages.&lt;/li&gt; 
   &lt;li&gt;If the reference speaker has a fast speaking style, lowering &lt;code&gt;cfg_weight&lt;/code&gt; to around &lt;code&gt;0.3&lt;/code&gt; can improve pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Expressive or Dramatic Speech:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Try lower &lt;code&gt;cfg_weight&lt;/code&gt; values (e.g. &lt;code&gt;~0.3&lt;/code&gt;) and increase &lt;code&gt;exaggeration&lt;/code&gt; to around &lt;code&gt;0.7&lt;/code&gt; or higher.&lt;/li&gt; 
   &lt;li&gt;Higher &lt;code&gt;exaggeration&lt;/code&gt; tends to speed up speech; reducing &lt;code&gt;cfg_weight&lt;/code&gt; helps compensate with slower, more deliberate pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built-in PerTh Watermarking for Responsible AI&lt;/h2&gt; 
&lt;p&gt;Every audio file generated by Chatterbox includes &lt;a href="https://github.com/resemble-ai/perth"&gt;Resemble AI's Perth (Perceptual Threshold) Watermarker&lt;/a&gt; - imperceptible neural watermarks that survive MP3 compression, audio editing, and common manipulations while maintaining nearly 100% detection accuracy.&lt;/p&gt; 
&lt;h2&gt;Watermark extraction&lt;/h2&gt; 
&lt;p&gt;You can look for the watermark using the following script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import perth
import librosa

AUDIO_PATH = "YOUR_FILE.wav"

# Load the watermarked audio
watermarked_audio, sr = librosa.load(AUDIO_PATH, sr=None)

# Initialize watermarker (same as used for embedding)
watermarker = perth.PerthImplicitWatermarker()

# Extract watermark
watermark = watermarker.get_watermark(watermarked_audio, sample_rate=sr)
print(f"Extracted watermark: {watermark}")
# Output: 0.0 (no watermark) or 1.0 (watermarked)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Official Discord&lt;/h2&gt; 
&lt;p&gt;üëã Join us on &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;Discord&lt;/a&gt; and let's build something awesome together!&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FunAudioLLM/CosyVoice"&gt;Cosyvoice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning"&gt;Real-Time-Voice-Cloning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yl4579/HiFTNet"&gt;HiFT-GAN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;Llama 3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xingchensong/S3Tokenizer"&gt;S3Tokenizer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this model useful, please consider citing.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{chatterboxtts2025,
  author       = {{Resemble AI}},
  title        = {{Chatterbox-TTS}},
  year         = {2025},
  howpublished = {\url{https://github.com/resemble-ai/chatterbox}},
  note         = {GitHub repository}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Don't use this model to do bad things. Prompts are sourced from freely available data on the internet.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AUTOMATIC1111/stable-diffusion-webui</title>
      <link>https://github.com/AUTOMATIC1111/stable-diffusion-webui</link>
      <description>&lt;p&gt;Stable Diffusion web UI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion web UI&lt;/h1&gt; 
&lt;p&gt;A web interface for Stable Diffusion, implemented using Gradio library.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/screenshot.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features"&gt;Detailed feature showcase with images&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Original txt2img and img2img modes&lt;/li&gt; 
 &lt;li&gt;One click install and run script (but you still must install python and git)&lt;/li&gt; 
 &lt;li&gt;Outpainting&lt;/li&gt; 
 &lt;li&gt;Inpainting&lt;/li&gt; 
 &lt;li&gt;Color Sketch&lt;/li&gt; 
 &lt;li&gt;Prompt Matrix&lt;/li&gt; 
 &lt;li&gt;Stable Diffusion Upscale&lt;/li&gt; 
 &lt;li&gt;Attention, specify parts of text that the model should pay more attention to 
  &lt;ul&gt; 
   &lt;li&gt;a man in a &lt;code&gt;((tuxedo))&lt;/code&gt; - will pay more attention to tuxedo&lt;/li&gt; 
   &lt;li&gt;a man in a &lt;code&gt;(tuxedo:1.21)&lt;/code&gt; - alternative syntax&lt;/li&gt; 
   &lt;li&gt;select text and press &lt;code&gt;Ctrl+Up&lt;/code&gt; or &lt;code&gt;Ctrl+Down&lt;/code&gt; (or &lt;code&gt;Command+Up&lt;/code&gt; or &lt;code&gt;Command+Down&lt;/code&gt; if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Loopback, run img2img processing multiple times&lt;/li&gt; 
 &lt;li&gt;X/Y/Z plot, a way to draw a 3 dimensional plot of images with different parameters&lt;/li&gt; 
 &lt;li&gt;Textual Inversion 
  &lt;ul&gt; 
   &lt;li&gt;have as many embeddings as you want and use any names you like for them&lt;/li&gt; 
   &lt;li&gt;use multiple embeddings with different numbers of vectors per token&lt;/li&gt; 
   &lt;li&gt;works with half precision floating point numbers&lt;/li&gt; 
   &lt;li&gt;train embeddings on 8GB (also reports of 6GB working)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Extras tab with: 
  &lt;ul&gt; 
   &lt;li&gt;GFPGAN, neural network that fixes faces&lt;/li&gt; 
   &lt;li&gt;CodeFormer, face restoration tool as an alternative to GFPGAN&lt;/li&gt; 
   &lt;li&gt;RealESRGAN, neural network upscaler&lt;/li&gt; 
   &lt;li&gt;ESRGAN, neural network upscaler with a lot of third party models&lt;/li&gt; 
   &lt;li&gt;SwinIR and Swin2SR (&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092"&gt;see here&lt;/a&gt;), neural network upscalers&lt;/li&gt; 
   &lt;li&gt;LDSR, Latent diffusion super resolution upscaling&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Resizing aspect ratio options&lt;/li&gt; 
 &lt;li&gt;Sampling method selection 
  &lt;ul&gt; 
   &lt;li&gt;Adjust sampler eta values (noise multiplier)&lt;/li&gt; 
   &lt;li&gt;More advanced noise setting options&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Interrupt processing at any time&lt;/li&gt; 
 &lt;li&gt;4GB video card support (also reports of 2GB working)&lt;/li&gt; 
 &lt;li&gt;Correct seeds for batches&lt;/li&gt; 
 &lt;li&gt;Live prompt token length validation&lt;/li&gt; 
 &lt;li&gt;Generation parameters 
  &lt;ul&gt; 
   &lt;li&gt;parameters you used to generate images are saved with that image&lt;/li&gt; 
   &lt;li&gt;in PNG chunks for PNG, in EXIF for JPEG&lt;/li&gt; 
   &lt;li&gt;can drag the image to PNG info tab to restore generation parameters and automatically copy them into UI&lt;/li&gt; 
   &lt;li&gt;can be disabled in settings&lt;/li&gt; 
   &lt;li&gt;drag and drop an image/text-parameters to promptbox&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Read Generation Parameters Button, loads parameters in promptbox to UI&lt;/li&gt; 
 &lt;li&gt;Settings page&lt;/li&gt; 
 &lt;li&gt;Running arbitrary python code from UI (must run with &lt;code&gt;--allow-code&lt;/code&gt; to enable)&lt;/li&gt; 
 &lt;li&gt;Mouseover hints for most UI elements&lt;/li&gt; 
 &lt;li&gt;Possible to change defaults/mix/max/step values for UI elements via text config&lt;/li&gt; 
 &lt;li&gt;Tiling support, a checkbox to create images that can be tiled like textures&lt;/li&gt; 
 &lt;li&gt;Progress bar and live image generation preview 
  &lt;ul&gt; 
   &lt;li&gt;Can use a separate neural network to produce previews with almost none VRAM or compute requirement&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Negative prompt, an extra text field that allows you to list what you don't want to see in generated image&lt;/li&gt; 
 &lt;li&gt;Styles, a way to save part of prompt and easily apply them via dropdown later&lt;/li&gt; 
 &lt;li&gt;Variations, a way to generate same image but with tiny differences&lt;/li&gt; 
 &lt;li&gt;Seed resizing, a way to generate same image but at slightly different resolution&lt;/li&gt; 
 &lt;li&gt;CLIP interrogator, a button that tries to guess prompt from an image&lt;/li&gt; 
 &lt;li&gt;Prompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway&lt;/li&gt; 
 &lt;li&gt;Batch Processing, process a group of files using img2img&lt;/li&gt; 
 &lt;li&gt;Img2img Alternative, reverse Euler method of cross attention control&lt;/li&gt; 
 &lt;li&gt;Highres Fix, a convenience option to produce high resolution pictures in one click without usual distortions&lt;/li&gt; 
 &lt;li&gt;Reloading checkpoints on the fly&lt;/li&gt; 
 &lt;li&gt;Checkpoint Merger, a tab that allows you to merge up to 3 checkpoints into one&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts"&gt;Custom scripts&lt;/a&gt; with many extensions from community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/"&gt;Composable-Diffusion&lt;/a&gt;, a way to use multiple prompts at once 
  &lt;ul&gt; 
   &lt;li&gt;separate prompts using uppercase &lt;code&gt;AND&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;also supports weights for prompts: &lt;code&gt;a cat :1.2 AND a dog AND a penguin :2.2&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;No token limit for prompts (original stable diffusion lets you use up to 75 tokens)&lt;/li&gt; 
 &lt;li&gt;DeepDanbooru integration, creates danbooru style tags for anime prompts&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers"&gt;xformers&lt;/a&gt;, major speed increase for select cards: (add &lt;code&gt;--xformers&lt;/code&gt; to commandline args)&lt;/li&gt; 
 &lt;li&gt;via extension: &lt;a href="https://github.com/yfszzx/stable-diffusion-webui-images-browser"&gt;History tab&lt;/a&gt;: view, direct and delete images conveniently within the UI&lt;/li&gt; 
 &lt;li&gt;Generate forever option&lt;/li&gt; 
 &lt;li&gt;Training tab 
  &lt;ul&gt; 
   &lt;li&gt;hypernetworks and embeddings options&lt;/li&gt; 
   &lt;li&gt;Preprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Clip skip&lt;/li&gt; 
 &lt;li&gt;Hypernetworks&lt;/li&gt; 
 &lt;li&gt;Loras (same as Hypernetworks but more pretty)&lt;/li&gt; 
 &lt;li&gt;A separate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your prompt&lt;/li&gt; 
 &lt;li&gt;Can select to load a different VAE from settings screen&lt;/li&gt; 
 &lt;li&gt;Estimated completion time in progress bar&lt;/li&gt; 
 &lt;li&gt;API&lt;/li&gt; 
 &lt;li&gt;Support for dedicated &lt;a href="https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion"&gt;inpainting model&lt;/a&gt; by RunwayML&lt;/li&gt; 
 &lt;li&gt;via extension: &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients"&gt;Aesthetic Gradients&lt;/a&gt;, a way to generate images with a specific aesthetic by using clip images embeds (implementation of &lt;a href="https://github.com/vicgalle/stable-diffusion-aesthetic-gradients"&gt;https://github.com/vicgalle/stable-diffusion-aesthetic-gradients&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Stability-AI/stablediffusion"&gt;Stable Diffusion 2.0&lt;/a&gt; support - see &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20"&gt;wiki&lt;/a&gt; for instructions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2211.06679"&gt;Alt-Diffusion&lt;/a&gt; support - see &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion"&gt;wiki&lt;/a&gt; for instructions&lt;/li&gt; 
 &lt;li&gt;Now without any bad letters!&lt;/li&gt; 
 &lt;li&gt;Load checkpoints in safetensors format&lt;/li&gt; 
 &lt;li&gt;Eased resolution restriction: generated image's dimensions must be a multiple of 8 rather than 64&lt;/li&gt; 
 &lt;li&gt;Now with a license!&lt;/li&gt; 
 &lt;li&gt;Reorder elements in the UI from settings screen&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/segmind/SSD-1B"&gt;Segmind Stable Diffusion&lt;/a&gt; support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation and Running&lt;/h2&gt; 
&lt;p&gt;Make sure the required &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies"&gt;dependencies&lt;/a&gt; are met and follow the instructions available for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs"&gt;NVidia&lt;/a&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs"&gt;AMD&lt;/a&gt; GPUs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon"&gt;Intel CPUs, Intel GPUs (both integrated and discrete)&lt;/a&gt; (external wiki page)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs"&gt;Ascend NPUs&lt;/a&gt; (external wiki page)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Alternatively, use online services (like Google Colab):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services"&gt;List of Online Services&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation on Windows 10/11 with NVidia-GPUs using release package&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download &lt;code&gt;sd.webui.zip&lt;/code&gt; from &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre"&gt;v1.0.0-pre&lt;/a&gt; and extract its contents.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;update.bat&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;run.bat&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For more details see &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs"&gt;Install-and-Run-on-NVidia-GPUs&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Automatic Installation on Windows&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install &lt;a href="https://www.python.org/downloads/release/python-3106/"&gt;Python 3.10.6&lt;/a&gt; (Newer version of Python does not support torch), checking "Add Python to PATH".&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://git-scm.com/download/win"&gt;git&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Download the stable-diffusion-webui repository, for example by running &lt;code&gt;git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;webui-user.bat&lt;/code&gt; from Windows Explorer as normal, non-administrator, user.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Automatic Installation on Linux&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Debian-based:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Red Hat-based:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# openSUSE-based:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Arch-based:
sudo pacman -S wget git python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your system is very new, you need to install python3.11 or python3.10:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # do not confuse with python3.11 package

# Only for 3.11
# Then set up env variable in launch script
export python_cmd="python3.11"
# or in webui-user.sh
python_cmd="python3.11"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Navigate to the directory you would like the webui to be installed and execute the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or just clone the repo wherever you want:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Run &lt;code&gt;webui.sh&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Check &lt;code&gt;webui-user.sh&lt;/code&gt; for options.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Installation on Apple Silicon&lt;/h3&gt; 
&lt;p&gt;Find the instructions &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Here's how to add code to this repo: &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing"&gt;Contributing&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The documentation was moved from this README over to the project's &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki"&gt;wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) &lt;a href="https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki"&gt;crawlable wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Licenses for borrowed code can be found in &lt;code&gt;Settings -&amp;gt; Licenses&lt;/code&gt; screen, and also in &lt;code&gt;html/licenses.html&lt;/code&gt; file.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stable Diffusion - &lt;a href="https://github.com/Stability-AI/stablediffusion"&gt;https://github.com/Stability-AI/stablediffusion&lt;/a&gt;, &lt;a href="https://github.com/CompVis/taming-transformers"&gt;https://github.com/CompVis/taming-transformers&lt;/a&gt;, &lt;a href="https://github.com/mcmonkey4eva/sd3-ref"&gt;https://github.com/mcmonkey4eva/sd3-ref&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;k-diffusion - &lt;a href="https://github.com/crowsonkb/k-diffusion.git"&gt;https://github.com/crowsonkb/k-diffusion.git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spandrel - &lt;a href="https://github.com/chaiNNer-org/spandrel"&gt;https://github.com/chaiNNer-org/spandrel&lt;/a&gt; implementing 
  &lt;ul&gt; 
   &lt;li&gt;GFPGAN - &lt;a href="https://github.com/TencentARC/GFPGAN.git"&gt;https://github.com/TencentARC/GFPGAN.git&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;CodeFormer - &lt;a href="https://github.com/sczhou/CodeFormer"&gt;https://github.com/sczhou/CodeFormer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;ESRGAN - &lt;a href="https://github.com/xinntao/ESRGAN"&gt;https://github.com/xinntao/ESRGAN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;SwinIR - &lt;a href="https://github.com/JingyunLiang/SwinIR"&gt;https://github.com/JingyunLiang/SwinIR&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Swin2SR - &lt;a href="https://github.com/mv-lab/swin2sr"&gt;https://github.com/mv-lab/swin2sr&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;LDSR - &lt;a href="https://github.com/Hafiidz/latent-diffusion"&gt;https://github.com/Hafiidz/latent-diffusion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MiDaS - &lt;a href="https://github.com/isl-org/MiDaS"&gt;https://github.com/isl-org/MiDaS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ideas for optimizations - &lt;a href="https://github.com/basujindal/stable-diffusion"&gt;https://github.com/basujindal/stable-diffusion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Cross Attention layer optimization - Doggettx - &lt;a href="https://github.com/Doggettx/stable-diffusion"&gt;https://github.com/Doggettx/stable-diffusion&lt;/a&gt;, original idea for prompt editing.&lt;/li&gt; 
 &lt;li&gt;Cross Attention layer optimization - InvokeAI, lstein - &lt;a href="https://github.com/invoke-ai/InvokeAI"&gt;https://github.com/invoke-ai/InvokeAI&lt;/a&gt; (originally &lt;a href="http://github.com/lstein/stable-diffusion"&gt;http://github.com/lstein/stable-diffusion&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Sub-quadratic Cross Attention layer optimization - Alex Birch (&lt;a href="https://github.com/Birch-san/diffusers/pull/1"&gt;https://github.com/Birch-san/diffusers/pull/1&lt;/a&gt;), Amin Rezaei (&lt;a href="https://github.com/AminRezaei0x443/memory-efficient-attention"&gt;https://github.com/AminRezaei0x443/memory-efficient-attention&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Textual Inversion - Rinon Gal - &lt;a href="https://github.com/rinongal/textual_inversion"&gt;https://github.com/rinongal/textual_inversion&lt;/a&gt; (we're not using his code, but we are using his ideas).&lt;/li&gt; 
 &lt;li&gt;Idea for SD upscale - &lt;a href="https://github.com/jquesnelle/txt2imghd"&gt;https://github.com/jquesnelle/txt2imghd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Noise generation for outpainting mk2 - &lt;a href="https://github.com/parlance-zz/g-diffuser-bot"&gt;https://github.com/parlance-zz/g-diffuser-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;CLIP interrogator idea and borrowing some code - &lt;a href="https://github.com/pharmapsychotic/clip-interrogator"&gt;https://github.com/pharmapsychotic/clip-interrogator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Idea for Composable Diffusion - &lt;a href="https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch"&gt;https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;xformers - &lt;a href="https://github.com/facebookresearch/xformers"&gt;https://github.com/facebookresearch/xformers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DeepDanbooru - interrogator for anime diffusers &lt;a href="https://github.com/KichangKim/DeepDanbooru"&gt;https://github.com/KichangKim/DeepDanbooru&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Sampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (&lt;a href="https://github.com/Birch-san/diffusers-play/tree/92feee6"&gt;https://github.com/Birch-san/diffusers-play/tree/92feee6&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - &lt;a href="https://github.com/timothybrooks/instruct-pix2pix"&gt;https://github.com/timothybrooks/instruct-pix2pix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Security advice - RyotaK&lt;/li&gt; 
 &lt;li&gt;UniPC sampler - Wenliang Zhao - &lt;a href="https://github.com/wl-zhao/UniPC"&gt;https://github.com/wl-zhao/UniPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;TAESD - Ollin Boer Bohan - &lt;a href="https://github.com/madebyollin/taesd"&gt;https://github.com/madebyollin/taesd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;LyCORIS - KohakuBlueleaf&lt;/li&gt; 
 &lt;li&gt;Restart sampling - lambertae - &lt;a href="https://github.com/Newbeeer/diffusion_restart_sampling"&gt;https://github.com/Newbeeer/diffusion_restart_sampling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hypertile - tfernd - &lt;a href="https://github.com/tfernd/HyperTile"&gt;https://github.com/tfernd/HyperTile&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Initial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.&lt;/li&gt; 
 &lt;li&gt;(You)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>google/A2UI</title>
      <link>https://github.com/google/A2UI</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;A2UI: Agent-to-User Interface&lt;/h1&gt; 
&lt;p&gt;A2UI is an open-source project, complete with a format optimized for representing updateable agent-generated UIs and an initial set of renderers, that allows agents to generate or populate rich user interfaces.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/google/A2UI/main/docs/assets/a2ui_gallery_examples.png" alt="Gallery of A2UI components" height="400" /&gt; 
&lt;p&gt;&lt;em&gt;A gallery of A2UI rendered cards, showing a variety of UI compositions that A2UI can achieve.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;‚ö†Ô∏è Status: Early Stage Public Preview&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; A2UI is currently in &lt;strong&gt;v0.8 (Public Preview)&lt;/strong&gt;. The specification and implementations are functional but are still evolving. We are opening the project to foster collaboration, gather feedback, and solicit contributions (e.g., on client renderers). Expect changes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Summary&lt;/h2&gt; 
&lt;p&gt;Generative AI excels at creating text and code, but agents can struggle to present rich, interactive interfaces to users, especially when those agents are remote or running across trust boundaries.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A2UI&lt;/strong&gt; is an open standard and set of libraries that allows agents to "speak UI." Agents send a declarative JSON format describing the &lt;em&gt;intent&lt;/em&gt; of the UI. The client application then renders this using its own native component library (Flutter, Angular, Lit, etc.).&lt;/p&gt; 
&lt;p&gt;This approach ensures that agent-generated UIs are &lt;strong&gt;safe like data, but expressive like code&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;High-Level Philosophy&lt;/h2&gt; 
&lt;p&gt;A2UI was designed to address the specific challenges of interoperable, cross-platform, generative or template-based UI responses from agents.&lt;/p&gt; 
&lt;p&gt;The project's core philosophies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Security first&lt;/strong&gt;: Running arbitrary code generated by an LLM may present a security risk. A2UI is a declarative data format, not executable code. Your client application maintains a "catalog" of trusted, pre-approved UI components (e.g., Card, Button, TextField), and the agent can only request to render components from that catalog.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-friendly and incrementally updateable&lt;/strong&gt;: The UI is represented as a flat list of components with ID references which is easy for LLMs to generate incrementally, allowing for progressive rendering and a responsive user experience. An agent can efficiently make incremental changes to the UI based on new user requests as the conversation progresses.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Framework-agnostic and portable&lt;/strong&gt;: A2UI separates the UI structure from the UI implementation. The agent sends a description of the component tree and its associated data model. Your client application is responsible for mapping these abstract descriptions to its native widgets‚Äîbe it web components, Flutter widgets, React components, SwiftUI views or something else entirely. The same A2UI JSON payload from an agent can be rendered on multiple different clients built on top of different frameworks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexibility&lt;/strong&gt;: A2UI also features an open registry pattern that allows developers to map server-side types to custom client implementations, from native mobile widgets to React components. By registering a "Smart Wrapper," you can connect any existing UI component‚Äîincluding secure iframe containers for legacy content‚Äîto A2UI's data binding and event system. Crucially, this places security firmly in the developer's hands, enabling them to enforce strict sandboxing policies and "trust ladders" directly within their custom component logic rather than relying solely on the core system.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Use Cases&lt;/h2&gt; 
&lt;p&gt;Some of the use cases include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Data Collection:&lt;/strong&gt; An agent generates a bespoke form (date pickers, sliders, inputs) based on the specific context of a conversation (e.g., booking a specialized reservation).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote Sub-Agents:&lt;/strong&gt; An orchestrator agent delegates a task to a remote specialized agent (e.g., a travel booking agent) which returns a UI payload to be rendered inside the main chat window.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adaptive Workflows:&lt;/strong&gt; Enterprise agents that generate approval dashboards or data visualizations on the fly based on the user's query.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;The A2UI flow disconnects the generation of UI from the execution of UI:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Generation:&lt;/strong&gt; An Agent (using Gemini or another LLM) generates or uses a pre-generated &lt;code&gt;A2UI Response&lt;/code&gt;, a JSON payload describing the composition of UI components and their properties.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transport:&lt;/strong&gt; This message is sent to the client application (via A2A, AG UI, etc.).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Resolution:&lt;/strong&gt; The Client's &lt;strong&gt;A2UI Renderer&lt;/strong&gt; parses the JSON.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rendering:&lt;/strong&gt; The Renderer maps the abstract components (e.g., &lt;code&gt;type: 'text-field'&lt;/code&gt;) to the concrete implementation in the client's codebase.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;p&gt;A2UI is designed to be a lightweight format, but it fits into a larger ecosystem:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Transports:&lt;/strong&gt; Compatible with &lt;strong&gt;A2A Protocol&lt;/strong&gt; and &lt;strong&gt;AG UI&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLMs:&lt;/strong&gt; Can be generated by any model capable of generating JSON output.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Host Frameworks:&lt;/strong&gt; Requires a host application built in a supported framework (currently: Web or Flutter).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;The best way to understand A2UI is to run the samples.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Node.js (for web clients)&lt;/li&gt; 
 &lt;li&gt;Python (for agent samples)&lt;/li&gt; 
 &lt;li&gt;A valid &lt;a href="https://aistudio.google.com/"&gt;Gemini API Key&lt;/a&gt; is required for the samples.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Running the Restaurant Finder Demo&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/google/A2UI.git
cd A2UI
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Set your API Key:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export GEMINI_API_KEY="your_gemini_api_key"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run the Agent (Backend):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd samples/agent/adk/restaurant_finder
uv run .
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run the Client (Frontend):&lt;/strong&gt; Open a new terminal window:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Install and build the Lit renderer
cd renderers/lit
npm install
npm run build

# Install and run the shell client
cd ../../samples/client/lit/shell
npm install
npm run dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For Flutter developers, check out the &lt;a href="https://github.com/flutter/genui"&gt;GenUI SDK&lt;/a&gt;, which uses A2UI under the hood.&lt;/p&gt; 
&lt;p&gt;CopilotKit has a public &lt;a href="https://go.copilotkit.ai/A2UI-widget-builder"&gt;A2UI Widget Builder&lt;/a&gt; to try out as well.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;We hope to work with the community on the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Spec Stabilization:&lt;/strong&gt; Moving towards a v1.0 specification.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;More Renderers:&lt;/strong&gt; Adding official support for React, Jetpack Compose, iOS (SwiftUI), and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Additional Transports:&lt;/strong&gt; Support for REST and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Additional Agent Frameworks:&lt;/strong&gt; Genkit, LangGraph, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;A2UI is an &lt;strong&gt;Apache 2.0&lt;/strong&gt; licensed project. We believe the future of UI is agentic, and we want to work with you to help build it.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/google/A2UI/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for details on how to get started.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>exo-explore/exo</title>
      <link>https://github.com/exo-explore/exo</link>
      <description>&lt;p&gt;Run your own AI cluster at home with everyday devices üì±üíª üñ•Ô∏è‚åö&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/imgs/exo-logo-black-bg.jpg" /&gt; 
  &lt;img alt="exo logo" src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/imgs/exo-logo-transparent.png" width="50%" height="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;exo: Run your own AI cluster at home with everyday devices. Maintained by &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://discord.gg/72NsF6ux" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/exolabs" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/exolabs?style=social" alt="X" /&gt;&lt;/a&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0.html" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/License-Apache2.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;exo connects all your devices into an AI cluster. Not only does exo enable running models larger than would fit on a single device, but with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt&lt;/a&gt;, makes models run faster as you add more devices.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Device Discovery&lt;/strong&gt;: Devices running exo automatically discover each other - no manual configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RDMA over Thunderbolt&lt;/strong&gt;: exo ships with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt 5&lt;/a&gt;, enabling 99% reduction in latency between devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Topology-Aware Auto Parallel&lt;/strong&gt;: exo figures out the best way to split your model across all available devices based on a realtime view of your device topology. It takes into account device resources and network latency/bandwidth between each link.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;: exo supports sharding models, for up to 1.8x speedup on 2 devices and 3.2x speedup on 4 devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MLX Support&lt;/strong&gt;: exo uses &lt;a href="https://github.com/ml-explore/mlx"&gt;MLX&lt;/a&gt; as an inference backend and &lt;a href="https://ml-explore.github.io/mlx/build/html/usage/distributed.html"&gt;MLX distributed&lt;/a&gt; for distributed communication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qwen3-235B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-1-qwen3-235b.jpeg" alt="Benchmark - Qwen3-235B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;DeepSeek v3.1 671B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-2-deepseek-3.1-671b.jpeg" alt="Benchmark - DeepSeek v3.1 671B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Kimi K2 Thinking (native 4-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-3-kimi-k2-thinking.jpeg" alt="Benchmark - Kimi K2 Thinking (native 4-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Devices running exo automatically discover each other, without needing any manual configuration. Each device provides an API and a dashboard for interacting with your cluster (runs at &lt;code&gt;http://localhost:52415&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;There are two ways to run exo:&lt;/p&gt; 
&lt;h3&gt;Run from Source (macOS)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Homebrew/brew"&gt;brew&lt;/a&gt; (for simple package management on macOS)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (for Python dependency management)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/vladkens/macmon"&gt;macmon&lt;/a&gt; (for hardware monitoring on Apple Silicon)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/nodejs/node"&gt;node&lt;/a&gt; (for building the dashboard)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;brew install uv macmon node
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/rust-lang/rustup"&gt;rust&lt;/a&gt; (to build Rust bindings, nightly for now)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Clone the repo, build the dashboard, and run exo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone exo
git clone https://github.com/exo-explore/exo

# Build dashboard
cd exo/dashboard &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; cd ..

# Run exo
uv run exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the exo dashboard and API at &lt;a href="http://localhost:52415/"&gt;http://localhost:52415/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Run from Source (Linux)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (for Python dependency management)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nodejs/node"&gt;node&lt;/a&gt; (for building the dashboard) - version 18 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rust-lang/rustup"&gt;rust&lt;/a&gt; (to build Rust bindings, nightly for now)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Installation methods:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Using system package manager (Ubuntu/Debian example):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Node.js and npm
sudo apt update
sudo apt install nodejs npm

# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install Rust (using rustup)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Using Homebrew on Linux (if preferred):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Homebrew on Linux
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install dependencies
brew install uv node

# Install Rust (using rustup)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The &lt;code&gt;macmon&lt;/code&gt; package is macOS-only and not required for Linux.&lt;/p&gt; 
&lt;p&gt;Clone the repo, build the dashboard, and run exo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone exo
git clone https://github.com/exo-explore/exo

# Build dashboard
cd exo/dashboard &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; cd ..

# Run exo
uv run exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the exo dashboard and API at &lt;a href="http://localhost:52415/"&gt;http://localhost:52415/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important note for Linux users:&lt;/strong&gt; Currently, exo runs on CPU on Linux. GPU support for Linux platforms is under development. If you'd like to see support for your specific Linux hardware, please &lt;a href="https://github.com/exo-explore/exo/issues"&gt;search for existing feature requests&lt;/a&gt; or create a new one.&lt;/p&gt; 
&lt;h3&gt;macOS App&lt;/h3&gt; 
&lt;p&gt;exo ships a macOS app that runs in the background on your Mac.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/imgs/macos-app-one-macbook.png" alt="exo macOS App - running on a MacBook" width="35%" /&gt; 
&lt;p&gt;The macOS app requires macOS Tahoe 26.2 or later.&lt;/p&gt; 
&lt;p&gt;Download the latest build here: &lt;a href="https://assets.exolabs.net/EXO-latest.dmg"&gt;EXO-latest.dmg&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The app will ask for permission to modify system settings and install a new Network profile. Improvements to this are being worked on.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Enabling RDMA on macOS&lt;/h3&gt; 
&lt;p&gt;RDMA is a new capability added to macOS 26.2. It works on any Mac with Thunderbolt 5 (M4 Pro Mac Mini, M4 Max Mac Studio, M4 Max MacBook Pro, M3 Ultra Mac Studio).&lt;/p&gt; 
&lt;p&gt;Note that on Mac Studio, you cannot use the Thunderbolt 5 port next to the Ethernet port.&lt;/p&gt; 
&lt;p&gt;To enable RDMA on macOS, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Shut down your Mac.&lt;/li&gt; 
 &lt;li&gt;Hold down the power button for 10 seconds until the boot menu appears.&lt;/li&gt; 
 &lt;li&gt;Select "Options" to enter Recovery mode.&lt;/li&gt; 
 &lt;li&gt;When the Recovery UI appears, open the Terminal from the Utilities menu.&lt;/li&gt; 
 &lt;li&gt;In the Terminal, type: &lt;pre&gt;&lt;code&gt;rdma_ctl enable
&lt;/code&gt;&lt;/pre&gt; and press Enter.&lt;/li&gt; 
 &lt;li&gt;Reboot your Mac.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;After that, RDMA will be enabled in macOS and exo will take care of the rest.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Using the API&lt;/h3&gt; 
&lt;p&gt;If you prefer to interact with exo via the API, here is an example creating an instance of a small model (&lt;code&gt;mlx-community/Llama-3.2-1B-Instruct-4bit&lt;/code&gt;), sending a chat completions request and deleting the instance.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;1. Preview instance placements&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;/instance/previews&lt;/code&gt; endpoint will preview all valid placements for your model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "previews": [
    {
      "model_id": "mlx-community/Llama-3.2-1B-Instruct-4bit",
      "sharding": "Pipeline",
      "instance_meta": "MlxRing",
      "instance": {...},
      "memory_delta_by_node": {"local": 729808896},
      "error": null
    }
    // ...possibly more placements...
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will return all valid placements for this model. Pick a placement that you like. To pick the first one, pipe into &lt;code&gt;jq&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b" | jq -c '.previews[] | select(.error == null) | .instance' | head -n1
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;2. Create a model instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Send a POST to &lt;code&gt;/instance&lt;/code&gt; with your desired placement in the &lt;code&gt;instance&lt;/code&gt; field (the full payload must match types as in &lt;code&gt;CreateInstanceParams&lt;/code&gt;), which you can copy from step 1:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:52415/instance \
  -H 'Content-Type: application/json' \
  -d '{
    "instance": {...}
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "message": "Command received.",
  "command_id": "e9d1a8ab-...."
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;3. Send a chat completion&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Now, make a POST to &lt;code&gt;/v1/chat/completions&lt;/code&gt; (the same format as OpenAI's API):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -N -X POST http://localhost:52415/v1/chat/completions \
  -H 'Content-Type: application/json' \
  -d '{
    "model": "mlx-community/Llama-3.2-1B-Instruct-4bit",
    "messages": [
      {"role": "user", "content": "What is Llama 3.2 1B?"}
    ],
    "stream": true
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;4. Delete the instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;When you're done, delete the instance by its ID (find it via &lt;code&gt;/state&lt;/code&gt; or &lt;code&gt;/instance&lt;/code&gt; endpoints):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X DELETE http://localhost:52415/instance/YOUR_INSTANCE_ID
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;&lt;em&gt;Other useful API endpoints&lt;/em&gt;:&lt;/em&gt;*&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;List all models: &lt;code&gt;curl http://localhost:52415/models&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Inspect instance IDs and deployment state: &lt;code&gt;curl http://localhost:52415/state&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For further details, see API types and endpoints in &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/src/exo/master/api.py"&gt;src/exo/master/api.py&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Hardware Accelerator Support&lt;/h2&gt; 
&lt;p&gt;On macOS, exo uses the GPU. On Linux, exo currently runs on CPU. We are working on extending hardware accelerator support. If you'd like support for a new hardware platform, please &lt;a href="https://github.com/exo-explore/exo/issues"&gt;search for an existing feature request&lt;/a&gt; and add a thumbs up so we know what hardware is important to the community.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidelines on how to contribute to exo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Flowseal/zapret-discord-youtube</title>
      <link>https://github.com/Flowseal/zapret-discord-youtube</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;&lt;img src="https://cdn-icons-png.flaticon.com/128/5968/5968756.png" height="28" /&gt; &lt;a href="https://github.com/Flowseal/"&gt;Flowseal&lt;/a&gt;&lt;a href="https://github.com/Flowseal/zapret-discord-youtube"&gt;/zapret-discord-youtube&lt;/a&gt; &lt;img src="https://cdn-icons-png.flaticon.com/128/1384/1384060.png" height="28" /&gt;&lt;/h1&gt; 
 &lt;p&gt;–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ &lt;a href="https://github.com/bol-van/zapret-win-bundle"&gt;https://github.com/bol-van/zapret-win-bundle&lt;/a&gt;&lt;br /&gt; –¢–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –º–∞—Ç–µ—Ä–∏–∞–ª—å–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ zapret &lt;a href="https://github.com/bol-van/zapret?tab=readme-ov-file#%D0%BF%D0%BE%D0%B4%D0%B4%D0%B5%D1%80%D0%B6%D0%B0%D1%82%D1%8C-%D1%80%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%87%D0%B8%D0%BA%D0%B0"&gt;—Ç—É—Ç&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION]&lt;/p&gt; 
 &lt;h3&gt;–§–ï–ô–ö–ò&lt;/h3&gt; 
 &lt;p&gt;–Ø –Ω–µ –≤–µ–¥—É –Ω–∏–∫–∞–∫–∏–µ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã/–≥—Ä—É–ø–ø—ã –≤ —Ç–µ–ª–µ–≥—Ä–∞–º/—é—Ç—É–± –∫–∞–Ω–∞–ª—ã&lt;br /&gt; –ï—Å–ª–∏ –≤—ã –Ω–∞—Ç–∫–Ω—É–ª–∏—Å—å –Ω–∞ —á—Ç–æ-—Ç–æ –≤–Ω–µ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≥–∏—Ç—Ö–∞–±–∞, —á—Ç–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –æ—Ç –º–æ–µ–≥–æ –ª–∏—Ü–∞ - &lt;strong&gt;–§–ï–ô–ö&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;h3&gt;–ê–ù–¢–ò–í–ò–†–£–°–´&lt;/h3&gt; 
 &lt;p&gt;WinDivert –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å —Ä–µ–∞–∫—Ü–∏—é –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. WinDivert - —ç—Ç–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ç—Ä–∞—Ñ–∏–∫–∞, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π –¥–ª—è —Ä–∞–±–æ—Ç—ã zapret. –ó–∞–º–µ–Ω–∞ iptables –∏ NFQUEUE –≤ Linux, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –ø–æ–¥ Windows. –û–Ω –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ —Ö–æ—Ä–æ—à–∏–º–∏, —Ç–∞–∫ –∏ –ø–ª–æ—Ö–∏–º–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º–∏, –Ω–æ —Å–∞–º –ø–æ —Å–µ–±–µ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∏—Ä—É—Å–æ–º. –î—Ä–∞–π–≤–µ—Ä WinDivert64.sys –ø–æ–¥–ø–∏—Å–∞–Ω –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ 64-–±–∏—Ç–Ω–æ–µ —è–¥—Ä–æ Windows. –ù–æ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å—ã —Å–∫–ª–æ–Ω–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç—å –ø–æ–¥–æ–±–Ω–æ–µ –∫ –∫–ª–∞—Å—Å–∞–º –ø–æ–≤—ã—à–µ–Ω–Ω–æ–≥–æ —Ä–∏—Å–∫–∞ –∏–ª–∏ —Ö–∞–∫–µ—Ä—Å–∫–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º. –í —Å–ª—É—á–∞–µ –ø—Ä–æ–±–ª–µ–º –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–ª–∏ –≤—ã–∫–ª—é—á–∞–π—Ç–µ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Å–æ–≤—Å–µ–º.&lt;/p&gt; 
 &lt;p&gt;*&lt;em&gt;–í—ã–¥–µ—Ä–∂–∫–∞ –∏–∑ &lt;a href="https://github.com/bol-van/zapret-win-bundle/raw/master/readme.md#%D0%B0%D0%BD%D1%82%D0%B8%D0%B2%D0%B8%D1%80%D1%83%D1%81%D1%8B"&gt;&lt;code&gt;readme.md&lt;/code&gt;&lt;/a&gt; —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è &lt;a href="https://github.com/bol-van/zapret-win-bundle"&gt;bol-van/zapret-win-bundle&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] –í—Å–µ –±–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ &lt;a href="https://raw.githubusercontent.com/Flowseal/zapret-discord-youtube/main/bin"&gt;&lt;code&gt;bin&lt;/code&gt;&lt;/a&gt; –≤–∑—è—Ç—ã –∏–∑ &lt;a href="https://github.com/bol-van/zapret-win-bundle/tree/master/zapret-winws"&gt;zapret-win-bundle/zapret-winws&lt;/a&gt;. –í—ã –º–æ–∂–µ—Ç–µ —ç—Ç–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å –ø–æ–º–æ—â—å—é —Ö—ç—à–µ–π/–∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º. –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ, —á—Ç–æ –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É—è —Å–±–æ—Ä–∫–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚öôÔ∏è–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;–í–∫–ª—é—á–∏—Ç–µ Secure DNS&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;–í Chrome - "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω—ã–π DNS", –∏ –≤—ã–±—Ä–∞—Ç—å –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ —É—Å–ª—É–≥ DNS (–≤—ã–±—Ä–∞—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç, –æ—Ç–ª–∏—á–Ω—ã–π –æ—Ç –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)&lt;/li&gt; 
   &lt;li&gt;–í Firefox - "–í–∫–ª—é—á–∏—Ç—å DNS —á–µ—Ä–µ–∑ HTTPS, –∏—Å–ø–æ–ª—å–∑—É—è: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –∑–∞—â–∏—Ç—É", –∑–∞—Ç–µ–º "–í—ã–±—Ä–∞—Ç—å –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞" –∏ –≤–ø–∏—Å–∞—Ç—å URL –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –≤—Ä—É—á–Ω—É—é, –Ω–∞–ø—Ä–∏–º–µ—Ä –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å &lt;code&gt;https://dns.google/dns-query&lt;/code&gt; (—Ç.–∫. –ø–æ—Å—Ç–∞–≤—â–∏–∫ Cloudflare –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω)&lt;/li&gt; 
   &lt;li&gt;–í Windows 11 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤–∫–ª—é—á–µ–Ω–∏–µ Secure DNS –ø—Ä—è–º–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –û–° - &lt;a href="https://www.howtogeek.com/765940/how-to-enable-dns-over-https-on-windows-11/"&gt;–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Ç—É—Ç&lt;/a&gt;. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è, –µ—Å–ª–∏ –≤—ã –ø–æ–ª—å–∑—É–µ—Ç–µ—Å—å Windows 11&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;–°–∫–∞—á–∞–π—Ç–µ –∞—Ä—Ö–∏–≤ (zip/rar) —Å–æ &lt;a href="https://github.com/Flowseal/zapret-discord-youtube/releases/latest"&gt;—Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ä–µ–ª–∏–∑–∞&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;–ó–∞–π–¥–∏—Ç–µ –≤ —Å–≤–æ–π—Å—Ç–≤–∞ —Å–∫–∞—á–∞–Ω–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞ –∏ –ø–æ—Å—Ç–∞–≤—å—Ç–µ –≥–∞–ª–æ—á–∫—É "–†–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å". –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –∞—Ä—Ö–∏–≤–∞—Ç–æ—Ä 7-Zip –∏–ª–∏ PeaZip, —ç—Ç–æ—Ç —à–∞–≥ –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;–†–∞—Å–ø–∞–∫—É–π—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∞—Ä—Ö–∏–≤–∞ –ø–æ –ø—É—Ç–∏, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É/—Å–ø–µ—Ü. —Å–∏–º–≤–æ–ª—ã&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;–ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ω—É–∂–Ω—ã–π —Ñ–∞–π–ª&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;‚ÑπÔ∏è–ö—Ä–∞—Ç–∫–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Flowseal/zapret-discord-youtube/main/general.bat"&gt;&lt;strong&gt;&lt;code&gt;general.bat ...&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; - –∑–∞–ø—É—Å–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤—Ä—É—á–Ω—É—é&lt;/p&gt; &lt;p&gt;–ó–∞–ø—É—Å–∫ –≤—Ä—É—á–Ω—É—é –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π. –†–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ç–æ–π –∏–ª–∏ –∏–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–Ω–æ–≥–∏—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤. &lt;strong&gt;–ü—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (ALT, FAKE –∏ –¥—Ä—É–≥–∏–µ), –ø–æ–∫–∞ –Ω–µ –Ω–∞–π–¥—ë—Ç–µ —Ä–∞–±–æ—á–µ–µ –¥–ª—è –≤–∞—Å —Ä–µ—à–µ–Ω–∏–µ&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Flowseal/zapret-discord-youtube/main/service.bat"&gt;&lt;strong&gt;&lt;code&gt;service.bat&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; - —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫ –∏ –¥—Ä—É–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;ins&gt;&lt;strong&gt;&lt;code&gt;Install Service&lt;/code&gt;&lt;/strong&gt; - —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ª—é–±–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫ (services.msc)&lt;/ins&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Remove Services&lt;/code&gt;&lt;/strong&gt; - —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏ WinDivert –∏–∑ —Å–ª—É–∂–±&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Check Status&lt;/code&gt;&lt;/strong&gt; - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—Ö–æ–¥–∞ –∏ —Å–ª—É–∂–± (—Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫–µ –∏ WinDivert)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Run Diagnostics&lt;/code&gt;&lt;/strong&gt; - –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –Ω–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã, –ø–æ –∫–æ—Ç–æ—Ä—ã–º zapret –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å.&lt;br /&gt; –í –∫–æ–Ω—Ü–µ –º–æ–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å –∫—ç—à &lt;img src="https://cdn-icons-png.flaticon.com/128/5968/5968756.png" height="11" /&gt; &lt;code&gt;Discord&lt;/code&gt;, —á—Ç–æ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å, –µ—Å–ª–∏ –æ–Ω –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ –ø–µ—Ä–µ—Å—Ç–∞–ª —Ä–∞–±–æ—Ç–∞—Ç—å&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Check Updates&lt;/code&gt;&lt;/strong&gt; - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Switch Check Updates&lt;/code&gt;&lt;/strong&gt; - –í–∫–ª/–í—ã–∫–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Switch Game Filter&lt;/code&gt;&lt;/strong&gt; - –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –æ–±—Ö–æ–¥–∞ –¥–ª—è –∏–≥—Ä (–∏ –¥—Ä—É–≥–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏—Ö UDP –∏ TCP –Ω–∞ –ø–æ—Ä—Ç–∞—Ö –≤—ã—à–µ 1023).&lt;br /&gt; &lt;strong&gt;–ü–æ—Å–ª–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.&lt;/strong&gt;&lt;br /&gt; –í —Å–∫–æ–±–∫–∞—Ö —É–∫–∞–∑–∞–Ω —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å (–≤–∫–ª—é—á–µ–Ω–æ/–≤—ã–∫–ª—é—á–µ–Ω–æ).&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Switch ipset&lt;/code&gt;&lt;/strong&gt; - –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –æ–±—Ö–æ–¥–∞ —Å–µ—Ä–≤–∏—Å–æ–≤ –∏–∑ &lt;code&gt;ipset-all.txt&lt;/code&gt;.&lt;br /&gt; –ü–æ–ª–µ–∑–Ω–æ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏, –µ—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ä–µ—Å—É—Ä—Å, –∫–æ—Ç–æ—Ä—ã–π –±–µ–∑ zapret —Ä–∞–±–æ—Ç–∞–µ—Ç&lt;br /&gt; –í —Å–∫–æ–±–∫–∞—Ö —É–∫–∞–∑–∞–Ω —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;none&lt;/code&gt; - –Ω–∏–∫–∞–∫–∏–µ –∞–π–ø–∏ –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç –ø–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫—É&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;loaded&lt;/code&gt; - –∞–π–ø–∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è –Ω–∞ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –≤ —Å–ø–∏—Å–æ–∫&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;any&lt;/code&gt; - –ª—é–±–æ–π –∞–π–ø–∏ –ø–æ–ø–∞–¥–∞–µ—Ç –ø–æ–¥ —Ñ–∏–ª—å—Ç—Ä&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Update ipset list&lt;/code&gt;&lt;/strong&gt; - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ &lt;code&gt;ipset-all.txt&lt;/code&gt; –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Update hosts file&lt;/code&gt;&lt;/strong&gt; - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ hosts &lt;ins&gt;&lt;strong&gt;–¥–ª—è –ø–æ—á–∏–Ω–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É —á–∞—Ç—É Discord&lt;/strong&gt;&lt;/ins&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;Run Tests&lt;/code&gt;&lt;/strong&gt; - –∑–∞–ø—É—Å–∫ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;Standard tests&lt;/code&gt; - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∞–π—Ç–æ–≤ –∏–∑ &lt;code&gt;utils/targets.txt&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;DPI checkers&lt;/code&gt; - –ø—Ä–æ–≤–µ—Ä–∫–∞ DPI –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞—Ö (Cloudflare, Amazon –∏ –¥—Ä.)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚òëÔ∏è–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –ø—Ä–æ–±–ª–µ–º—ã&lt;/h2&gt; 
&lt;h3&gt;–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞ &lt;code&gt;general*&lt;/code&gt; –Ω–∏—á–µ–≥–æ –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–æ—Ç–¥–µ–ª—å–Ω—ã–º bat —Ñ–∞–π–ª–æ–º, –Ω–µ —á–µ—Ä–µ–∑ service), –¥–æ–ª–∂–µ–Ω –æ—Ç–∫—Ä—ã—Ç—å—Å—è winws.exe (–æ–±—Ö–æ–¥), –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å –≤ –ø–∞–Ω–µ–ª–∏ –∑–∞–¥–∞—á.&lt;br /&gt; –ï—Å–ª–∏ —ç—Ç–æ–≥–æ –Ω–µ –ø—Ä–æ–∏–∑–æ—à–ª–æ, —Ç–æ —Å–º. &lt;a href="https://github.com/Flowseal/zapret-discord-youtube/issues/522"&gt;#522&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;–ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ–µ "–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ" –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É —á–∞—Ç—É Discord&lt;/h3&gt; 
&lt;p&gt;–ó–∞–ø—É—Å—Ç–∏—Ç–µ &lt;strong&gt;&lt;code&gt;service.bat&lt;/code&gt;&lt;/strong&gt;, –≤—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç &lt;strong&gt;&lt;code&gt;Update hosts file (for discord voice)&lt;/code&gt;&lt;/strong&gt;. –ü–æ—Å–ª–µ —á–µ–≥–æ, –µ—Å–ª–∏ –≤–∞—à hosts –±—É–¥–µ—Ç –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã–º, —Ç–æ –í–∞–º –±—É–¥–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –µ–≥–æ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;C–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–∫—Ä—ã–≤—à–µ–≥–æ—Å—è –±–ª–æ–∫–Ω–æ—Ç–∞&lt;/li&gt; 
 &lt;li&gt;–û—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª &lt;code&gt;hosts&lt;/code&gt; –≤ –ø–æ—è–≤–∏–≤—à–µ–π—Å—è –ø–∞–ø–∫–µ —Å –ø–æ–º–æ—â—å—é —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞&lt;/li&gt; 
 &lt;li&gt;–î–æ–±–∞–≤—å—Ç–µ –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞ &lt;code&gt;hosts&lt;/code&gt; —Ç–æ, —á—Ç–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–ª–∏ (–∏–ª–∏ –∑–∞–º–µ–Ω–∏—Ç–µ, –µ—Å–ª–∏ –¥–æ —ç—Ç–æ–≥–æ –í—ã —É–∂–µ –¥–æ–±–∞–≤–ª—è–ª–∏ –ø–æ–¥–æ–±–Ω–æ–µ)&lt;/li&gt; 
 &lt;li&gt;–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∏ –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ. –ï—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª &lt;code&gt;hosts&lt;/code&gt; –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª—Å—è.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;–û–±—Ö–æ–¥ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç / –ø–µ—Ä–µ—Å—Ç–∞–ª —Ä–∞–±–æ—Ç–∞—Ç—å&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –º–æ–≥—É—Ç –ø–µ—Ä–µ—Å—Ç–∞–≤–∞—Ç—å —Ä–∞–±–æ—Ç–∞—Ç—å.&lt;/strong&gt; –û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫–æ–µ-—Ç–æ –≤—Ä–µ–º—è, –Ω–æ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –æ–Ω–∞ –º–æ–∂–µ—Ç –ø–µ—Ä–µ—Å—Ç–∞–≤–∞—Ç—å —Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑-–∑–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è. –í —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –æ–±—Ö–æ–¥–∞. –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ –∏–∑ –Ω–∏—Ö –≤–∞–º –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç, —Ç–æ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é, –≤–∑—è–≤ –∑–∞ –æ—Å–Ω–æ–≤—É –æ–¥–Ω—É –∏–∑ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–¥–µ—Å—å –∏ –∏–∑–º–µ–Ω–∏–≤ –µ—ë –ø–∞—Ä–∞–º–µ—Ç—Ä—ã. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø—Ä–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤—ã –º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏ &lt;a href="https://github.com/bol-van/zapret/raw/master/docs/readme.md#nfqws"&gt;—Ç—É—Ç&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫ –≤ &lt;code&gt;service.bat&lt;/code&gt; -&amp;gt; &lt;code&gt;Run Diagnostics&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∞–¥—Ä–µ—Å —Ä–µ—Å—É—Ä—Å–∞ –∑–∞–ø–∏—Å–∞–Ω –≤ —Å–ø–∏—Å–∫–∞—Ö –¥–æ–º–µ–Ω–æ–≤ –∏–ª–∏ IP&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (&lt;strong&gt;&lt;code&gt;ALT&lt;/code&gt;&lt;/strong&gt;/&lt;strong&gt;&lt;code&gt;FAKE&lt;/code&gt;&lt;/strong&gt; –∏ –¥—Ä—É–≥–∏–µ)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–ª–Ω—É—é –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫—É (—Å–º. —Ä–∞–∑–¥–µ–ª –Ω–∏–∂–µ)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;–°–º. &lt;a href="https://github.com/Flowseal/zapret-discord-youtube/issues/765"&gt;#765&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;–ö–∞–∫ –ø–µ—Ä–µ—É—Å—Ç–Ω–æ–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ä–µ—Å—É—Ä—Å—ã/–¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —Å–∞–º–∏ –¥–æ–±–∞–≤–ª—è–ª–∏&lt;/li&gt; 
 &lt;li&gt;–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;service.bat&lt;/code&gt; -&amp;gt; &lt;code&gt;Remove Services&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;service.bat&lt;/code&gt; -&amp;gt; &lt;code&gt;Run Diagnostics&lt;/code&gt; (–µ—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏ - —É—Å—Ç—Ä–∞–Ω–∏—Ç–µ –∏—Ö) -&amp;gt; –≤ –∫–æ–Ω—Ü–µ Y&lt;/li&gt; 
 &lt;li&gt;–£–¥–∞–ª–∏—Ç–µ –ø–∞–ø–∫—É —Å –∑–∞–ø—Ä–µ—Ç–æ–º&lt;/li&gt; 
 &lt;li&gt;–°–∫–∞—á–∞–π—Ç–µ –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é &lt;a href="https://github.com/Flowseal/zapret-discord-youtube/releases"&gt;—Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ä–µ–ª–∏–∑–æ–≤&lt;/a&gt; (&lt;code&gt;zapret-discord-youtube-...&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;–ù–∞–∂–º–∏—Ç–µ –ø–∫–º –ø–æ –∞—Ä—Ö–∏–≤—É -&amp;gt; —Å–≤–æ–π—Å—Ç–≤–∞. –ï—Å–ª–∏ —Å–Ω–∏–∑—É —Å–ø—Ä–∞–≤–∞ –µ—Å—Ç—å –≥–∞–ª–æ—á–∫–∞ —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å, —Ç–æ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –Ω–µ—ë -&amp;gt; –ø—Ä–∏–º–µ–Ω–∏—Ç—å -&amp;gt; –û–ö&lt;/li&gt; 
 &lt;li&gt;–†–∞—Å–ø–∞–∫—É–π—Ç–µ –≤ –Ω–æ–≤—É—é –ø–∞–ø–∫—É –≤ –∫–æ—Ä–Ω–µ –¥–∏—Å–∫–∞ (–±–µ–∑ —Å–ø–µ—Ü. —Å–∏–º–≤–æ–ª–æ–≤ –∏ –ø—Ä–æ–±–µ–ª–æ–≤)&lt;/li&gt; 
 &lt;li&gt;–î–∞–ª–µ–µ –ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å–∫–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ &lt;code&gt;general&lt;/code&gt; —Å–∫—Ä–∏–ø—Ç—ã (—Å—Ç—Ä–∞—Ç–µ–≥–∏–∏). –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤ - –µ—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç, —Ç–æ –∑–∞–∫—Ä—ã–≤–∞–π—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É (–≤ –ø–∞–Ω–µ–ª–∏ –∑–∞–¥–∞—á –∏–∫–æ–Ω–∫–∞ –∑–∞–º–æ—á–∫–∞) –∏ –ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é&lt;/li&gt; 
 &lt;li&gt;–ö–∞–∫ –Ω–∞–π–¥—ë—Ç–µ —Ä–∞–±–æ—á—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é, –º–æ–∂–µ—Ç–µ –ø–æ—Å—Ç–∞–≤–∏—Ç—å –µ—ë –Ω–∞ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫: &lt;code&gt;service.bat&lt;/code&gt; -&amp;gt; &lt;code&gt;Install Service&lt;/code&gt; -&amp;gt; –≤—ã–±–∏—Ä–∞–µ—Ç–µ –Ω—É–∂–Ω—É—é&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;–ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–≥—Ä–∞/–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å –≤–∫–ª—é—á—ë–Ω–Ω—ã–º –∑–∞–ø—Ä–µ—Ç–æ–º&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤ service.bat &lt;code&gt;Game Filter&lt;/code&gt; &lt;strong&gt;&lt;code&gt;disabled&lt;/code&gt;&lt;/strong&gt;, –∞ &lt;code&gt;ipset&lt;/code&gt; &lt;strong&gt;&lt;code&gt;empty&lt;/code&gt;&lt;/strong&gt;. –ò–Ω–∞—á–µ —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞—Ç—Ä–æ–Ω—É—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ä–µ—Å—É—Ä—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã –Ω–µ –æ–∂–∏–¥–∞–ª–∏.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;–ê–Ω—Ç–∏—á–∏—Ç —Ä—É–≥–∞–µ—Ç—Å—è –Ω–∞ WinDivert&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;–ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é —Ç—É—Ç - &lt;a href="https://github.com/bol-van/zapret-win-bundle/tree/master/windivert-hide"&gt;https://github.com/bol-van/zapret-win-bundle/tree/master/windivert-hide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;–¢—Ä–µ–±—É–µ—Ç—Å—è —Ü–∏—Ñ—Ä–æ–≤–∞—è –ø–æ–¥–ø–∏—Å—å –¥—Ä–∞–π–≤–µ—Ä–∞ WinDivert (Windows 7)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;–ó–∞–º–µ–Ω–∏—Ç–µ —Ñ–∞–π–ª—ã &lt;code&gt;WinDivert.dll&lt;/code&gt; –∏ &lt;code&gt;WinDivert64.sys&lt;/code&gt; –≤ –ø–∞–ø–∫–µ &lt;a href="https://raw.githubusercontent.com/Flowseal/zapret-discord-youtube/main/bin"&gt;&lt;code&gt;bin&lt;/code&gt;&lt;/a&gt; –Ω–∞ –æ–¥–Ω–æ–∏–º–µ–Ω–Ω—ã–µ –∏–∑ &lt;a href="https://github.com/bol-van/zapret-win-bundle/tree/master/win7"&gt;zapret-win-bundle/win7&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;–ü—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å –ø–æ–º–æ—â—å—é &lt;a href="https://raw.githubusercontent.com/Flowseal/zapret-discord-youtube/main/service.bat"&gt;&lt;strong&gt;&lt;code&gt;service.bat&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;, WinDivert –æ—Å—Ç–∞–µ—Ç—Å—è –≤ —Å–ª—É–∂–±–∞—Ö&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;–£–∑–Ω–∞–π—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–ª—É–∂–±—ã —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã, –≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ Windows (Win+R, &lt;code&gt;cmd&lt;/code&gt;):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-cmd"&gt;driverquery | find "Divert"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;–û—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏ —É–¥–∞–ª–∏—Ç–µ —Å–ª—É–∂–±—É –∫–æ–º–∞–Ω–¥–∞–º–∏:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-cmd"&gt;sc stop –Ω–∞–∑–≤–∞–Ω–∏–µ_–∏–∑_–ø–µ—Ä–≤–æ–≥–æ_—à–∞–≥–∞

sc delete –Ω–∞–∑–≤–∞–Ω–∏–µ_–∏–∑_–ø–µ—Ä–≤–æ–≥–æ_—à–∞–≥–∞
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;–ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç &lt;img src="https://cdn-icons-png.flaticon.com/128/1384/1384060.png" height="18" /&gt; YouTube&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤—ã –Ω–∞—Å—Ç—Ä–æ–∏–ª–∏ Secure DNS.&lt;/li&gt; 
 &lt;li&gt;–û—Ç–∫–ª—é—á–∏—Ç–µ –±–ª–æ–∫–∏—Ä–æ–≤—â–∏–∫ —Ä–µ–∫–ª–∞–º—ã, –∏–∑–≤–µ—Å—Ç–Ω–æ —á—Ç–æ YouTube –Ω–∞—á–∞–ª —Å –Ω–∏–º–∏ –±–æ—Ä–æ—Ç—å—Å—è.&lt;/li&gt; 
 &lt;li&gt;–ü—Ä–æ–±—É–π—Ç–µ –≤—Å–µ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–µ—Å–ª–∏ —Ä–∞–Ω—å—à–µ —Ä–∞–±–æ—Ç–∞–ª–æ, –Ω–æ –ø–µ—Ä–µ—Å—Ç–∞–ª–æ).&lt;/li&gt; 
 &lt;li&gt;–°–º. —Ç–∞–∫–∂–µ &lt;a href="https://github.com/Flowseal/zapret-discord-youtube/discussions/251"&gt;#251&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;–ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç &lt;img src="https://cdn-icons-png.flaticon.com/128/5968/5968756.png" height="18" /&gt; Discord&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;–ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ —Å–Ω–∞—á–∞–ª–∞ —É–∑–Ω–∞—Ç—å, –Ω–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è —Å–∞–π—Ç YouTube. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—é.&lt;/li&gt; 
 &lt;li&gt;–ü—Ä–æ–≤–µ—Ä—å—Ç–µ Discord –≤ –±—Ä–∞—É–∑–µ—Ä–µ: &lt;a href="https://discord.com/app"&gt;https://discord.com/app&lt;/a&gt;. –í –±—Ä–∞—É–∑–µ—Ä–µ —Ä–∞–±–æ—Ç–∞–µ—Ç? –ï—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç, —Ç–æ –º–æ–∂–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –Ω—ë–º.&lt;/li&gt; 
 &lt;li&gt;–ï—Å–ª–∏ Discord –∏ –≤ –±—Ä–∞—É–∑–µ—Ä–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤—ã –Ω–∞—Å—Ç—Ä–æ–∏–ª–∏ Secure DNS, –∏ –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –µ—â—ë —Ä–∞–∑ –ø—Ä–æ–±—É–π—Ç–µ –≤—Å–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏. –ë—ã–≤–∞–µ—Ç —Ç–∞–∫–æ–µ, —á—Ç–æ –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ YouTube —Ä–∞–±–æ—Ç–∞–µ—Ç, –∞ Discord –Ω–µ—Ç.&lt;/li&gt; 
 &lt;li&gt;–°–º. —Ç–∞–∫–∂–µ &lt;a href="https://github.com/Flowseal/zapret-discord-youtube/discussions/252"&gt;#252&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;–ù–µ –Ω–∞—à–ª–∏ —Å–≤–æ–µ–π –ø—Ä–æ–±–ª–µ–º—ã&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;–°–æ–∑–¥–∞–π—Ç–µ –µ—ë &lt;a href="https://github.com/Flowseal/zapret-discord-youtube/issues"&gt;—Ç—É—Ç&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üóíÔ∏è–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–æ–≤ –ø—Ä–æ—á–∏—Ö —Ä–µ—Å—É—Ä—Å–æ–≤&lt;/h2&gt; 
&lt;p&gt;–°–ø–∏—Å–æ–∫ –∞–¥—Ä–µ—Å–æ–≤ –¥–ª—è –æ–±—Ö–æ–¥–∞ –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å, –¥–æ–±–∞–≤–ª—è—è –∏—Ö –≤:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Flowseal/zapret-discord-youtube/main/lists/list-general.txt"&gt;&lt;code&gt;list-general.txt&lt;/code&gt;&lt;/a&gt; –¥–ª—è –¥–æ–º–µ–Ω–æ–≤ (–ø–æ–¥–¥–æ–º–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Flowseal/zapret-discord-youtube/main/lists/list-exclude.txt"&gt;&lt;code&gt;list-exclude.txt&lt;/code&gt;&lt;/a&gt; –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥–æ–º–µ–Ω–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –∞–π–ø–∏ —Å–µ—Ç–∏ —É–∫–∞–∑–∞–Ω –≤ &lt;code&gt;ipset-all.txt&lt;/code&gt;, –Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–æ–º–µ–Ω –∏–∑ —ç—Ç–æ–π —Å–µ—Ç–∏ –Ω–µ –Ω–∞–¥–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Flowseal/zapret-discord-youtube/main/lists/ipset-all.txt"&gt;&lt;code&gt;ipset-all.txt&lt;/code&gt;&lt;/a&gt; –¥–ª—è IP –∏ –ø–æ–¥—Å–µ—Ç–µ–π&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Flowseal/zapret-discord-youtube/main/lists/ipset-exclude.txt"&gt;&lt;code&gt;ipset-exclude.txt&lt;/code&gt;&lt;/a&gt; –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è IP –∏ –ø–æ–¥—Å–µ—Ç–µ–π&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚≠ê–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞&lt;/h2&gt; 
&lt;p&gt;–í—ã –º–æ–∂–µ—Ç–µ –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–æ–µ–∫—Ç, –ø–æ—Å—Ç–∞–≤–∏–≤ &lt;span&gt;‚≠ê&lt;/span&gt; —ç—Ç–æ–º—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é (—Å–≤–µ—Ä—Ö—É —Å–ø—Ä–∞–≤–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã)&lt;/p&gt; 
&lt;p&gt;–¢–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –º–∞—Ç–µ—Ä–∏–∞–ª—å–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ zapret &lt;a href="https://github.com/bol-van/zapret?tab=readme-ov-file#%D0%BF%D0%BE%D0%B4%D0%B4%D0%B5%D1%80%D0%B6%D0%B0%D1%82%D1%8C-%D1%80%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%87%D0%B8%D0%BA%D0%B0"&gt;—Ç—É—Ç&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://star-history.com/#Flowseal/zapret-discord-youtube&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Flowseal/zapret-discord-youtube&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Flowseal/zapret-discord-youtube&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Flowseal/zapret-discord-youtube&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;‚öñÔ∏è–õ–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏–µ&lt;/h2&gt; 
&lt;p&gt;–ü—Ä–æ–µ–∫—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞ —É—Å–ª–æ–≤–∏—è—Ö –ª–∏—Ü–µ–Ω–∑–∏–∏ &lt;a href="https://github.com/Flowseal/zapret-discord-youtube/raw/main/LICENSE.txt"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü©∑–ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å —É—á–∞—Å—Ç–Ω–∏–∫–∞–º –ø—Ä–æ–µ–∫—Ç–∞&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/Flowseal/zapret-discord-youtube/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Flowseal/zapret-discord-youtube" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üíñ –û—Ç–¥–µ–ª—å–Ω–∞—è –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É &lt;a href="https://github.com/bol-van/zapret"&gt;zapret&lt;/a&gt; - &lt;a href="https://github.com/bol-van"&gt;bol-van&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-code</title>
      <link>https://github.com/anthropics/claude-code</link>
      <description>&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square" alt="" /&gt; &lt;a href="https://www.npmjs.com/package/@anthropic-ai/claude-code"&gt;&lt;img src="https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square" alt="npm" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn more in the &lt;a href="https://docs.anthropic.com/en/docs/claude-code/overview"&gt;official documentation&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/anthropics/claude-code/main/demo.gif" /&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Claude Code:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;MacOS/Linux:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://claude.ai/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Homebrew (MacOS):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install --cask claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://claude.ai/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NPM:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g @anthropic-ai/claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: If installing with NPM, you also need to install &lt;a href="https://nodejs.org/en/download/"&gt;Node.js 18+&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Navigate to your project directory and run &lt;code&gt;claude&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;This repository includes several Claude Code plugins that extend functionality with custom commands and agents. See the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-code/main/plugins/README.md"&gt;plugins directory&lt;/a&gt; for detailed documentation on available plugins.&lt;/p&gt; 
&lt;h2&gt;Reporting Bugs&lt;/h2&gt; 
&lt;p&gt;We welcome your feedback. Use the &lt;code&gt;/bug&lt;/code&gt; command to report issues directly within Claude Code, or file a &lt;a href="https://github.com/anthropics/claude-code/issues"&gt;GitHub issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Connect on Discord&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://anthropic.com/discord"&gt;Claude Developers Discord&lt;/a&gt; to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.&lt;/p&gt; 
&lt;h2&gt;Data collection, usage, and retention&lt;/h2&gt; 
&lt;p&gt;When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the &lt;code&gt;/bug&lt;/code&gt; command.&lt;/p&gt; 
&lt;h3&gt;How we use your data&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://docs.anthropic.com/en/docs/claude-code/data-usage"&gt;data usage policies&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Privacy safeguards&lt;/h3&gt; 
&lt;p&gt;We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.&lt;/p&gt; 
&lt;p&gt;For full details, please review our &lt;a href="https://www.anthropic.com/legal/commercial-terms"&gt;Commercial Terms of Service&lt;/a&gt; and &lt;a href="https://www.anthropic.com/legal/privacy"&gt;Privacy Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>danielmiessler/Fabric</title>
      <link>https://github.com/danielmiessler/Fabric</link>
      <description>&lt;p&gt;Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://go.warp.dev/fabric" target="_blank"&gt; &lt;sup&gt;Special thanks to:&lt;/sup&gt; &lt;br /&gt; &lt;img alt="Warp sponsorship" width="400" src="https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;br /&gt; 
  &lt;h&gt;
   Warp, built for coding with multiple AI agents 
   &lt;br /&gt; 
   &lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt; 
  &lt;/h&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/danielmiessler/Fabric/main/docs/images/fabric-logo-gif.gif" alt="fabriclogo" width="400" height="400" /&gt; 
 &lt;h1&gt;&lt;code&gt;fabric&lt;/code&gt;&lt;/h1&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple" alt="Static Badge" /&gt; &lt;br /&gt; &lt;img src="https://img.shields.io/github/languages/top/danielmiessler/fabric" alt="GitHub top language" /&gt; &lt;img src="https://img.shields.io/github/last-commit/danielmiessler/fabric" alt="GitHub last commit" /&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/danielmiessler/fabric"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;h4&gt;&lt;code&gt;fabric&lt;/code&gt; is an open-source framework for augmenting humans using AI.&lt;/h4&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/danielmiessler/Fabric/main/docs/images/fabric-summarize.png" alt="Screenshot of fabric" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#updates"&gt;Updates&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#what-and-why"&gt;What and Why&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#philosophy"&gt;Philosophy&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#installation"&gt;Installation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#usage"&gt;Usage&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#rest-api-server"&gt;REST API&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#examples"&gt;Examples&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#just-use-the-patterns"&gt;Just Use the Patterns&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#custom-patterns"&gt;Custom Patterns&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#helper-apps"&gt;Helper Apps&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#meta"&gt;Meta&lt;/a&gt;&lt;/p&gt;  
&lt;h2&gt;What and why&lt;/h2&gt; 
&lt;p&gt;Since the start of modern AI in late 2022 we've seen an &lt;strong&gt;&lt;em&gt;extraordinary&lt;/em&gt;&lt;/strong&gt; number of AI applications for accomplishing tasks. There are thousands of websites, chat-bots, mobile apps, and other interfaces for using all the different AI out there.&lt;/p&gt; 
&lt;p&gt;It's all really exciting and powerful, but &lt;em&gt;it's not easy to integrate this functionality into our lives.&lt;/em&gt;&lt;/p&gt; 
&lt;div class="align center"&gt; 
 &lt;h4&gt;In other words, AI doesn't have a capabilities problem‚Äîit has an &lt;em&gt;integration&lt;/em&gt; problem.&lt;/h4&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Fabric was created to address this by creating and organizing the fundamental units of AI‚Äîthe prompts themselves!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Fabric organizes prompts by real-world task, allowing people to create, collect, and organize their most important AI solutions in a single place for use in their favorite tools. And if you're command-line focused, you can use Fabric itself as the interface!&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view recent updates&lt;/summary&gt; 
 &lt;p&gt;Dear Users,&lt;/p&gt; 
 &lt;p&gt;We've been doing so many exciting things here at Fabric, I wanted to give a quick summary here to give you a sense of our development velocity!&lt;/p&gt; 
 &lt;p&gt;Below are the &lt;strong&gt;new features and capabilities&lt;/strong&gt; we've added (newest first):&lt;/p&gt; 
 &lt;h3&gt;Recent Major Features&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.356"&gt;v1.4.356&lt;/a&gt; (Dec 22, 2025) ‚Äî &lt;strong&gt;Complete Internationalization&lt;/strong&gt;: Full i18n support for setup prompts across all 10 languages with intelligent environment variable handling‚Äîmaking Fabric truly accessible worldwide while maintaining configuration consistency.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.350"&gt;v1.4.350&lt;/a&gt; (Dec 18, 2025) ‚Äî &lt;strong&gt;Interactive API Documentation&lt;/strong&gt;: Adds Swagger/OpenAPI UI at &lt;code&gt;/swagger/index.html&lt;/code&gt; with comprehensive REST API documentation, enhanced developer guides, and improved endpoint discoverability for easier integration.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.338"&gt;v1.4.338&lt;/a&gt; (Dec 4, 2025) ‚Äî Add Abacus vendor support for Chat-LLM models (see &lt;a href="https://abacus.ai/app/route-llm-apis"&gt;RouteLLM APIs&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.337"&gt;v1.4.337&lt;/a&gt; (Dec 4, 2025) ‚Äî Add "Z AI" vendor support. See the &lt;a href="https://docs.z.ai/guides/overview/overview"&gt;Z AI overview&lt;/a&gt; page for more details.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.334"&gt;v1.4.334&lt;/a&gt; (Nov 26, 2025) ‚Äî &lt;strong&gt;Claude Opus 4.5&lt;/strong&gt;: Updates the Anthropic SDK to the latest and adds the new &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Claude Opus 4.5&lt;/a&gt; to the available models.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.331"&gt;v1.4.331&lt;/a&gt; (Nov 23, 2025) ‚Äî &lt;strong&gt;Support for GitHub Models&lt;/strong&gt;: Adds support for using GitHub Models.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.322"&gt;v1.4.322&lt;/a&gt; (Nov 5, 2025) ‚Äî &lt;strong&gt;Interactive HTML Concept Maps and Claude Sonnet 4.5&lt;/strong&gt;: Adds &lt;code&gt;create_conceptmap&lt;/code&gt; pattern for visual knowledge representation using Vis.js, introduces WELLNESS category with psychological analysis patterns, and upgrades to Claude Sonnet 4.5&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.317"&gt;v1.4.317&lt;/a&gt; (Sep 21, 2025) ‚Äî &lt;strong&gt;Portuguese Language Variants&lt;/strong&gt;: Adds BCP 47 locale normalization with support for Brazilian Portuguese (pt-BR) and European Portuguese (pt-PT) with intelligent fallback chains&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.314"&gt;v1.4.314&lt;/a&gt; (Sep 17, 2025) ‚Äî &lt;strong&gt;Azure OpenAI Migration&lt;/strong&gt;: Migrates to official &lt;code&gt;openai-go/azure&lt;/code&gt; SDK with improved authentication and default API version support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.311"&gt;v1.4.311&lt;/a&gt; (Sep 13, 2025) ‚Äî &lt;strong&gt;More internationalization support&lt;/strong&gt;: Adds de (German), fa (Persian / Farsi), fr (French), it (Italian), ja (Japanese), pt (Portuguese), zh (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.309"&gt;v1.4.309&lt;/a&gt; (Sep 9, 2025) ‚Äî &lt;strong&gt;Comprehensive internationalization support&lt;/strong&gt;: Includes English and Spanish locale files.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.303"&gt;v1.4.303&lt;/a&gt; (Aug 29, 2025) ‚Äî &lt;strong&gt;New Binary Releases&lt;/strong&gt;: Linux ARM and Windows ARM targets. You can run Fabric on the Raspberry PI and on your Windows Surface!&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.294"&gt;v1.4.294&lt;/a&gt; (Aug 20, 2025) ‚Äî &lt;strong&gt;Venice AI Support&lt;/strong&gt;: Added the Venice AI provider. Venice is a Privacy-First, Open-Source AI provider. See their &lt;a href="https://docs.venice.ai/overview/about-venice"&gt;"About Venice"&lt;/a&gt; page for details.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.291"&gt;v1.4.291&lt;/a&gt; (Aug 18, 2025) ‚Äî &lt;strong&gt;Speech To Text&lt;/strong&gt;: Add OpenAI speech-to-text support with &lt;code&gt;--transcribe-file&lt;/code&gt;, &lt;code&gt;--transcribe-model&lt;/code&gt;, and &lt;code&gt;--split-media-file&lt;/code&gt; flags.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.287"&gt;v1.4.287&lt;/a&gt; (Aug 16, 2025) ‚Äî &lt;strong&gt;AI Reasoning&lt;/strong&gt;: Add Thinking to Gemini models and introduce &lt;code&gt;readme_updates&lt;/code&gt; python script&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.286"&gt;v1.4.286&lt;/a&gt; (Aug 14, 2025) ‚Äî &lt;strong&gt;AI Reasoning&lt;/strong&gt;: Introduce Thinking Config Across Anthropic and OpenAI Providers&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.285"&gt;v1.4.285&lt;/a&gt; (Aug 13, 2025) ‚Äî &lt;strong&gt;Extended Context&lt;/strong&gt;: Enable One Million Token Context Beta Feature for Sonnet-4&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.284"&gt;v1.4.284&lt;/a&gt; (Aug 12, 2025) ‚Äî &lt;strong&gt;Easy Shell Completions Setup&lt;/strong&gt;: Introduce One-Liner Curl Install for Completions&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.283"&gt;v1.4.283&lt;/a&gt; (Aug 12, 2025) ‚Äî &lt;strong&gt;Model Management&lt;/strong&gt;: Add Vendor Selection Support for Models&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.282"&gt;v1.4.282&lt;/a&gt; (Aug 11, 2025) ‚Äî &lt;strong&gt;Enhanced Shell Completions&lt;/strong&gt;: Enhanced Shell Completions for Fabric CLI Binaries&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.281"&gt;v1.4.281&lt;/a&gt; (Aug 11, 2025) ‚Äî &lt;strong&gt;Gemini Search Tool&lt;/strong&gt;: Add Web Search Tool Support for Gemini Models&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.278"&gt;v1.4.278&lt;/a&gt; (Aug 9, 2025) ‚Äî &lt;strong&gt;Enhance YouTube Transcripts&lt;/strong&gt;: Enhance YouTube Support with Custom yt-dlp Arguments&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.277"&gt;v1.4.277&lt;/a&gt; (Aug 8, 2025) ‚Äî &lt;strong&gt;Desktop Notifications&lt;/strong&gt;: Add cross-platform desktop notifications to Fabric CLI&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.274"&gt;v1.4.274&lt;/a&gt; (Aug 7, 2025) ‚Äî &lt;strong&gt;Claude 4.1 Added&lt;/strong&gt;: Add Support for Claude Opus 4.1 Model&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.271"&gt;v1.4.271&lt;/a&gt; (Jul 28, 2025) ‚Äî &lt;strong&gt;AI Summarized Release Notes&lt;/strong&gt;: Enable AI summary updates for GitHub releases&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.268"&gt;v1.4.268&lt;/a&gt; (Jul 26, 2025) ‚Äî &lt;strong&gt;Gemini TTS Voice Selection&lt;/strong&gt;: add Gemini TTS voice selection and listing functionality&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.267"&gt;v1.4.267&lt;/a&gt; (Jul 26, 2025) ‚Äî &lt;strong&gt;Text-to-Speech&lt;/strong&gt;: Update Gemini Plugin to New SDK with TTS Support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.258"&gt;v1.4.258&lt;/a&gt; (Jul 17, 2025) ‚Äî &lt;strong&gt;Onboarding Improved&lt;/strong&gt;: Add startup check to initialize config and .env file automatically&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.257"&gt;v1.4.257&lt;/a&gt; (Jul 17, 2025) ‚Äî &lt;strong&gt;OpenAI Routing Control&lt;/strong&gt;: Introduce CLI Flag to Disable OpenAI Responses API&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.252"&gt;v1.4.252&lt;/a&gt; (Jul 16, 2025) ‚Äî &lt;strong&gt;Hide Thinking Block&lt;/strong&gt;: Optional Hiding of Model Thinking Process with Configurable Tags&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.246"&gt;v1.4.246&lt;/a&gt; (Jul 14, 2025) ‚Äî &lt;strong&gt;Automatic ChangeLog Updates&lt;/strong&gt;: Add AI-powered changelog generation with high-performance Go tool and comprehensive caching&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.245"&gt;v1.4.245&lt;/a&gt; (Jul 11, 2025) ‚Äî &lt;strong&gt;Together AI&lt;/strong&gt;: Together AI Support with OpenAI Fallback Mechanism Added&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.232"&gt;v1.4.232&lt;/a&gt; (Jul 6, 2025) ‚Äî &lt;strong&gt;Add Custom&lt;/strong&gt;: Add Custom Patterns Directory Support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.231"&gt;v1.4.231&lt;/a&gt; (Jul 5, 2025) ‚Äî &lt;strong&gt;OAuth Auto-Auth&lt;/strong&gt;: OAuth Authentication Support for Anthropic (Use your Max Subscription)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.230"&gt;v1.4.230&lt;/a&gt; (Jul 5, 2025) ‚Äî &lt;strong&gt;Model Management&lt;/strong&gt;: Add advanced image generation parameters for OpenAI models with four new CLI flags&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.227"&gt;v1.4.227&lt;/a&gt; (Jul 4, 2025) ‚Äî &lt;strong&gt;Add Image&lt;/strong&gt;: Add Image Generation Support to Fabric&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.226"&gt;v1.4.226&lt;/a&gt; (Jul 4, 2025) ‚Äî &lt;strong&gt;Web Search&lt;/strong&gt;: OpenAI Plugin Now Supports Web Search Functionality&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.225"&gt;v1.4.225&lt;/a&gt; (Jul 4, 2025) ‚Äî &lt;strong&gt;Web Search&lt;/strong&gt;: Runtime Web Search Control via Command-Line &lt;code&gt;--search&lt;/code&gt; Flag&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.224"&gt;v1.4.224&lt;/a&gt; (Jul 1, 2025) ‚Äî &lt;strong&gt;Add code_review&lt;/strong&gt;: Add code_review pattern and updates in Pattern_Descriptions&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.222"&gt;v1.4.222&lt;/a&gt; (Jul 1, 2025) ‚Äî &lt;strong&gt;OpenAI Plugin&lt;/strong&gt;: OpenAI Plugin Migrates to New Responses API&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.218"&gt;v1.4.218&lt;/a&gt; (Jun 27, 2025) ‚Äî &lt;strong&gt;Model Management&lt;/strong&gt;: Add Support for OpenAI Search and Research Model Variants&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.217"&gt;v1.4.217&lt;/a&gt; (Jun 26, 2025) ‚Äî &lt;strong&gt;New YouTube&lt;/strong&gt;: New YouTube Transcript Endpoint Added to REST API&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.212"&gt;v1.4.212&lt;/a&gt; (Jun 23, 2025) ‚Äî &lt;strong&gt;Add Langdock&lt;/strong&gt;: Add Langdock AI and enhance generic OpenAI compatible support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.211"&gt;v1.4.211&lt;/a&gt; (Jun 19, 2025) ‚Äî &lt;strong&gt;REST API&lt;/strong&gt;: REST API and Web UI Now Support Dynamic Pattern Variables&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.210"&gt;v1.4.210&lt;/a&gt; (Jun 18, 2025) ‚Äî &lt;strong&gt;Add Citations&lt;/strong&gt;: Add Citation Support to Perplexity Response&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.208"&gt;v1.4.208&lt;/a&gt; (Jun 17, 2025) ‚Äî &lt;strong&gt;Add Perplexity&lt;/strong&gt;: Add Perplexity AI Provider with Token Limits Support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.203"&gt;v1.4.203&lt;/a&gt; (Jun 14, 2025) ‚Äî &lt;strong&gt;Add Amazon Bedrock&lt;/strong&gt;: Add support for Amazon Bedrock&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;These features represent our commitment to making Fabric the most powerful and flexible AI augmentation framework available!&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Intro videos&lt;/h2&gt; 
&lt;p&gt;Keep in mind that many of these were recorded when Fabric was Python-based, so remember to use the current &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#installation"&gt;install instructions&lt;/a&gt; below.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=UbDyjIIGaxQ"&gt;Network Chuck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=vF-MQmVxnCs"&gt;David Bombal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wPEyyigh10g"&gt;My Own Intro to the Tool&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/results?search_query=fabric+ai"&gt;More Fabric YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Navigation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#fabric"&gt;&lt;code&gt;fabric&lt;/code&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#what-and-why"&gt;What and why&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#updates"&gt;Updates&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#recent-major-features"&gt;Recent Major Features&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#intro-videos"&gt;Intro videos&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#navigation"&gt;Navigation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#changelog"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#philosophy"&gt;Philosophy&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#breaking-problems-into-components"&gt;Breaking problems into components&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#too-many-prompts"&gt;Too many prompts&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#installation"&gt;Installation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#one-line-install-recommended"&gt;One-Line Install (Recommended)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#manual-binary-downloads"&gt;Manual Binary Downloads&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#using-package-managers"&gt;Using package managers&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#macos-homebrew"&gt;macOS (Homebrew)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#arch-linux-aur"&gt;Arch Linux (AUR)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#windows"&gt;Windows&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#from-source"&gt;From Source&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#environment-variables"&gt;Environment Variables&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#setup"&gt;Setup&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#per-pattern-model-mapping"&gt;Per-Pattern Model Mapping&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#add-aliases-for-all-patterns"&gt;Add aliases for all patterns&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#save-your-files-in-markdown-using-aliases"&gt;Save your files in markdown using aliases&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#migration"&gt;Migration&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#upgrading"&gt;Upgrading&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#shell-completions"&gt;Shell Completions&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#quick-install-no-clone-required"&gt;Quick install (no clone required)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#zsh-completion"&gt;Zsh Completion&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#bash-completion"&gt;Bash Completion&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#fish-completion"&gt;Fish Completion&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#usage"&gt;Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#debug-levels"&gt;Debug Levels&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#extensions"&gt;Extensions&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#rest-api-server"&gt;REST API Server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#our-approach-to-prompting"&gt;Our approach to prompting&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#just-use-the-patterns"&gt;Just use the Patterns&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#prompt-strategies"&gt;Prompt Strategies&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#custom-patterns"&gt;Custom Patterns&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#setting-up-custom-patterns"&gt;Setting Up Custom Patterns&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#using-custom-patterns"&gt;Using Custom Patterns&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#how-it-works"&gt;How It Works&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#helper-apps"&gt;Helper Apps&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#to_pdf"&gt;&lt;code&gt;to_pdf&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#to_pdf-installation"&gt;&lt;code&gt;to_pdf&lt;/code&gt; Installation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#code_helper"&gt;&lt;code&gt;code_helper&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#pbpaste"&gt;pbpaste&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#web-interface-fabric-web-app"&gt;Web Interface (Fabric Web App)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#meta"&gt;Meta&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#primary-contributors"&gt;Primary contributors&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;Fabric is evolving rapidly.&lt;/p&gt; 
&lt;p&gt;Stay current with the latest features by reviewing the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt; for all recent changes.&lt;/p&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;AI isn't a thing; it's a &lt;em&gt;magnifier&lt;/em&gt; of a thing. And that thing is &lt;strong&gt;human creativity&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the &lt;strong&gt;human&lt;/strong&gt; problems we want to solve.&lt;/p&gt; 
&lt;h3&gt;Breaking problems into components&lt;/h3&gt; 
&lt;p&gt;Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.&lt;/p&gt; 
&lt;img width="2078" alt="augmented_challenges" src="https://github.com/danielmiessler/fabric/assets/50654/31997394-85a9-40c2-879b-b347e4701f06" /&gt; 
&lt;h3&gt;Too many prompts&lt;/h3&gt; 
&lt;p&gt;Prompts are good for this, but the biggest challenge I faced in 2023‚Äî‚Äîwhich still exists today‚Äîis &lt;strong&gt;the sheer number of AI prompts out there&lt;/strong&gt;. We all have prompts that are useful, but it's hard to discover new ones, know if they are good or not, &lt;em&gt;and manage different versions of the ones we like&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;One of &lt;code&gt;fabric&lt;/code&gt;'s primary features is helping people collect and integrate prompts, which we call &lt;em&gt;Patterns&lt;/em&gt;, into various parts of their lives.&lt;/p&gt; 
&lt;p&gt;Fabric has Patterns for all sorts of life and work activities, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extracting the most interesting parts of YouTube videos and podcasts&lt;/li&gt; 
 &lt;li&gt;Writing an essay in your own voice with just an idea as an input&lt;/li&gt; 
 &lt;li&gt;Summarizing opaque academic papers&lt;/li&gt; 
 &lt;li&gt;Creating perfectly matched AI art prompts for a piece of writing&lt;/li&gt; 
 &lt;li&gt;Rating the quality of content to see if you want to read/watch the whole thing&lt;/li&gt; 
 &lt;li&gt;Getting summaries of long, boring content&lt;/li&gt; 
 &lt;li&gt;Explaining code to you&lt;/li&gt; 
 &lt;li&gt;Turning bad documentation into usable documentation&lt;/li&gt; 
 &lt;li&gt;Creating social media posts from any content input&lt;/li&gt; 
 &lt;li&gt;And a million more‚Ä¶&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;One-Line Install (Recommended)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Unix/Linux/macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows PowerShell:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;iwr -useb https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/scripts/installer/README.md"&gt;scripts/installer/README.md&lt;/a&gt; for custom installation options and troubleshooting.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Manual Binary Downloads&lt;/h3&gt; 
&lt;p&gt;The latest release binary archives and their expected SHA256 hashes can be found at &lt;a href="https://github.com/danielmiessler/fabric/releases/latest"&gt;https://github.com/danielmiessler/fabric/releases/latest&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using package managers&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; using Homebrew or the Arch Linux package managers makes &lt;code&gt;fabric&lt;/code&gt; available as &lt;code&gt;fabric-ai&lt;/code&gt;, so add the following alias to your shell startup files to account for this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;alias fabric='fabric-ai'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;macOS (Homebrew)&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;brew install fabric-ai&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Arch Linux (AUR)&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;yay -S fabric-ai&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;p&gt;Use the official Microsoft supported &lt;code&gt;Winget&lt;/code&gt; tool:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;winget install danielmiessler.Fabric&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;p&gt;To install Fabric, &lt;a href="https://go.dev/doc/install"&gt;make sure Go is installed&lt;/a&gt;, and then run the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Fabric directly from the repo
go install github.com/danielmiessler/fabric/cmd/fabric@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Run Fabric using pre-built Docker images:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use latest image from Docker Hub
docker run --rm -it kayvan/fabric:latest --version

# Use specific version from GHCR
docker run --rm -it ghcr.io/ksylvan/fabric:v1.4.305 --version

# Run setup (first time)
mkdir -p $HOME/.fabric-config
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --setup

# Use Fabric with your patterns
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest -p summarize

# Run the REST API server (see REST API Server section)
docker run --rm -it -p 8080:8080 -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Images available at:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker Hub: &lt;a href="https://hub.docker.com/repository/docker/kayvan/fabric/general"&gt;kayvan/fabric&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GHCR: &lt;a href="https://github.com/ksylvan/fabric/pkgs/container/fabric"&gt;ksylvan/fabric&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/scripts/docker/README.md"&gt;scripts/docker/README.md&lt;/a&gt; for building custom images and advanced configuration.&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;You may need to set some environment variables in your &lt;code&gt;~/.bashrc&lt;/code&gt; on linux or &lt;code&gt;~/.zshrc&lt;/code&gt; file on mac to be able to run the &lt;code&gt;fabric&lt;/code&gt; command. Here is an example of what you can add:&lt;/p&gt; 
&lt;p&gt;For Intel based macs or linux&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Golang environment variables
export GOROOT=/usr/local/go
export GOPATH=$HOME/go

# Update PATH to include GOPATH and GOROOT binaries
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;for Apple Silicon based macs&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Golang environment variables
export GOROOT=$(brew --prefix go)/libexec
export GOPATH=$HOME/go
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;p&gt;Now run the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the setup to set up your directories and keys
fabric --setup
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If everything works you are good to go.&lt;/p&gt; 
&lt;h3&gt;Per-Pattern Model Mapping&lt;/h3&gt; 
&lt;p&gt;You can configure specific models for individual patterns using environment variables like &lt;code&gt;FABRIC_MODEL_PATTERN_NAME=vendor|model&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This makes it easy to maintain these per-pattern model mappings in your shell startup files.&lt;/p&gt; 
&lt;h3&gt;Add aliases for all patterns&lt;/h3&gt; 
&lt;p&gt;In order to add aliases for all your patterns and use them directly as commands, for example, &lt;code&gt;summarize&lt;/code&gt; instead of &lt;code&gt;fabric --pattern summarize&lt;/code&gt; You can add the following to your &lt;code&gt;.zshrc&lt;/code&gt; or &lt;code&gt;.bashrc&lt;/code&gt; file. You can also optionally set the &lt;code&gt;FABRIC_ALIAS_PREFIX&lt;/code&gt; environment variable before, if you'd prefer all the fabric aliases to start with the same prefix.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in $HOME/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name="$(basename "$pattern_file")"
    alias_name="${FABRIC_ALIAS_PREFIX:-}${pattern_name}"

    # Create an alias in the form: alias pattern_name="fabric --pattern pattern_name"
    alias_command="alias $alias_name='fabric --pattern $pattern_name'"

    # Evaluate the alias command to add it to the current shell
    eval "$alias_command"
done

yt() {
    if [ "$#" -eq 0 ] || [ "$#" -gt 2 ]; then
        echo "Usage: yt [-t | --timestamps] youtube-link"
        echo "Use the '-t' flag to get the transcript with timestamps."
        return 1
    fi

    transcript_flag="--transcript"
    if [ "$1" = "-t" ] || [ "$1" = "--timestamps" ]; then
        transcript_flag="--transcript-with-timestamps"
        shift
    fi
    local video_link="$1"
    fabric -y "$video_link" $transcript_flag
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can add the below code for the equivalent aliases inside PowerShell by running &lt;code&gt;notepad $PROFILE&lt;/code&gt; inside a PowerShell window:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# Path to the patterns directory
$patternsPath = Join-Path $HOME ".config/fabric/patterns"
foreach ($patternDir in Get-ChildItem -Path $patternsPath -Directory) {
    # Prepend FABRIC_ALIAS_PREFIX if set; otherwise use empty string
    $prefix = $env:FABRIC_ALIAS_PREFIX ?? ''
    $patternName = "$($patternDir.Name)"
    $aliasName = "$prefix$patternName"
    # Dynamically define a function for each pattern
    $functionDefinition = @"
function $aliasName {
    [CmdletBinding()]
    param(
        [Parameter(ValueFromPipeline = `$true)]
        [string] `$InputObject,

        [Parameter(ValueFromRemainingArguments = `$true)]
        [String[]] `$patternArgs
    )

    begin {
        # Initialize an array to collect pipeline input
        `$collector = @()
    }

    process {
        # Collect pipeline input objects
        if (`$InputObject) {
            `$collector += `$InputObject
        }
    }

    end {
        # Join all pipeline input into a single string, separated by newlines
        `$pipelineContent = `$collector -join "`n"

        # If there's pipeline input, include it in the call to fabric
        if (`$pipelineContent) {
            `$pipelineContent | fabric --pattern $patternName `$patternArgs
        } else {
            # No pipeline input; just call fabric with the additional args
            fabric --pattern $patternName `$patternArgs
        }
    }
}
"@
    # Add the function to the current session
    Invoke-Expression $functionDefinition
}

# Define the 'yt' function as well
function yt {
    [CmdletBinding()]
    param(
        [Parameter()]
        [Alias("timestamps")]
        [switch]$t,

        [Parameter(Position = 0, ValueFromPipeline = $true)]
        [string]$videoLink
    )

    begin {
        $transcriptFlag = "--transcript"
        if ($t) {
            $transcriptFlag = "--transcript-with-timestamps"
        }
    }

    process {
        if (-not $videoLink) {
            Write-Error "Usage: yt [-t | --timestamps] youtube-link"
            return
        }
    }

    end {
        if ($videoLink) {
            # Execute and allow output to flow through the pipeline
            fabric -y $videoLink $transcriptFlag
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This also creates a &lt;code&gt;yt&lt;/code&gt; alias that allows you to use &lt;code&gt;yt https://www.youtube.com/watch?v=4b0iet22VIk&lt;/code&gt; to get transcripts, comments, and metadata.&lt;/p&gt; 
&lt;h4&gt;Save your files in markdown using aliases&lt;/h4&gt; 
&lt;p&gt;If in addition to the above aliases you would like to have the option to save the output to your favorite markdown note vault like Obsidian then instead of the above add the following to your &lt;code&gt;.zshrc&lt;/code&gt; or &lt;code&gt;.bashrc&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Define the base directory for Obsidian notes
obsidian_base="/path/to/obsidian"

# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in ~/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name=$(basename "$pattern_file")

    # Remove any existing alias with the same name
    unalias "$pattern_name" 2&amp;gt;/dev/null

    # Define a function dynamically for each pattern
    eval "
    $pattern_name() {
        local title=\$1
        local date_stamp=\$(date +'%Y-%m-%d')
        local output_path=\"\$obsidian_base/\${date_stamp}-\${title}.md\"

        # Check if a title was provided
        if [ -n \"\$title\" ]; then
            # If a title is provided, use the output path
            fabric --pattern \"$pattern_name\" -o \"\$output_path\"
        else
            # If no title is provided, use --stream
            fabric --pattern \"$pattern_name\" --stream
        fi
    }
    "
done
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will allow you to use the patterns as aliases like in the above for example &lt;code&gt;summarize&lt;/code&gt; instead of &lt;code&gt;fabric --pattern summarize --stream&lt;/code&gt;, however if you pass in an extra argument like this &lt;code&gt;summarize "my_article_title"&lt;/code&gt; your output will be saved in the destination that you set in &lt;code&gt;obsidian_base="/path/to/obsidian"&lt;/code&gt; in the following format &lt;code&gt;YYYY-MM-DD-my_article_title.md&lt;/code&gt; where the date gets autogenerated for you. You can tweak the date format by tweaking the &lt;code&gt;date_stamp&lt;/code&gt; format.&lt;/p&gt; 
&lt;h3&gt;Migration&lt;/h3&gt; 
&lt;p&gt;If you have the Legacy (Python) version installed and want to migrate to the Go version, here's how you do it. It's basically two steps: 1) uninstall the Python version, and 2) install the Go version.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Uninstall Legacy Fabric
pipx uninstall fabric

# Clear any old Fabric aliases
(check your .bashrc, .zshrc, etc.)
# Install the Go version
go install github.com/danielmiessler/fabric/cmd/fabric@latest
# Run setup for the new version. Important because things have changed
fabric --setup
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#environment-variables"&gt;set your environmental variables&lt;/a&gt; as shown above.&lt;/p&gt; 
&lt;h3&gt;Upgrading&lt;/h3&gt; 
&lt;p&gt;The great thing about Go is that it's super easy to upgrade. Just run the same command you used to install it in the first place and you'll always get the latest version.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/fabric@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Shell Completions&lt;/h3&gt; 
&lt;p&gt;Fabric provides shell completion scripts for Zsh, Bash, and Fish shells, making it easier to use the CLI by providing tab completion for commands and options.&lt;/p&gt; 
&lt;h4&gt;Quick install (no clone required)&lt;/h4&gt; 
&lt;p&gt;You can install completions directly via a one-liner:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions/setup-completions.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optional variants:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Dry-run (see actions without changing your system)
curl -fsSL https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions/setup-completions.sh | sh -s -- --dry-run

# Override the download source (advanced)
FABRIC_COMPLETIONS_BASE_URL="https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions" \
    sh -c "$(curl -fsSL https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions/setup-completions.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Zsh Completion&lt;/h4&gt; 
&lt;p&gt;To enable Zsh completion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the completion file to a directory in your $fpath
mkdir -p ~/.zsh/completions
cp completions/_fabric ~/.zsh/completions/

# Add the directory to fpath in your .zshrc before compinit
echo 'fpath=(~/.zsh/completions $fpath)' &amp;gt;&amp;gt; ~/.zshrc
echo 'autoload -Uz compinit &amp;amp;&amp;amp; compinit' &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Bash Completion&lt;/h4&gt; 
&lt;p&gt;To enable Bash completion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Source the completion script in your .bashrc
echo 'source /path/to/fabric/completions/fabric.bash' &amp;gt;&amp;gt; ~/.bashrc

# Or copy to the system-wide bash completion directory
sudo cp completions/fabric.bash /etc/bash_completion.d/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Fish Completion&lt;/h4&gt; 
&lt;p&gt;To enable Fish completion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the completion file to the fish completions directory
mkdir -p ~/.config/fish/completions
cp completions/fabric.fish ~/.config/fish/completions/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Once you have it all set up, here's how to use it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fabric -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-plaintext"&gt;Usage:
  fabric [OPTIONS]

Application Options:
  -p, --pattern=                    Choose a pattern from the available patterns
  -v, --variable=                   Values for pattern variables, e.g. -v=#role:expert -v=#points:30
  -C, --context=                    Choose a context from the available contexts
      --session=                    Choose a session from the available sessions
  -a, --attachment=                 Attachment path or URL (e.g. for OpenAI image recognition messages)
  -S, --setup                       Run setup for all reconfigurable parts of fabric
  -t, --temperature=                Set temperature (default: 0.7)
  -T, --topp=                       Set top P (default: 0.9)
  -s, --stream                      Stream
  -P, --presencepenalty=            Set presence penalty (default: 0.0)
  -r, --raw                         Use the defaults of the model without sending chat options
                                    (temperature, top_p, etc.). Only affects OpenAI-compatible providers.
                                    Anthropic models always use smart parameter selection to comply with
                                    model-specific requirements.
  -F, --frequencypenalty=           Set frequency penalty (default: 0.0)
  -l, --listpatterns                List all patterns
  -L, --listmodels                  List all available models
  -x, --listcontexts                List all contexts
  -X, --listsessions                List all sessions
  -U, --updatepatterns              Update patterns
  -c, --copy                        Copy to clipboard
  -m, --model=                      Choose model
  -V, --vendor=                     Specify vendor for chosen model (e.g., -V "LM Studio" -m openai/gpt-oss-20b)
      --modelContextLength=         Model context length (only affects ollama)
  -o, --output=                     Output to file
      --output-session              Output the entire session (also a temporary one) to the output file
  -n, --latest=                     Number of latest patterns to list (default: 0)
  -d, --changeDefaultModel          Change default model
  -y, --youtube=                    YouTube video or play list "URL" to grab transcript, comments from it
                                    and send to chat or print it put to the console and store it in the
                                    output file
      --playlist                    Prefer playlist over video if both ids are present in the URL
      --transcript                  Grab transcript from YouTube video and send to chat (it is used per
                                    default).
      --transcript-with-timestamps  Grab transcript from YouTube video with timestamps and send to chat
      --comments                    Grab comments from YouTube video and send to chat
      --metadata                    Output video metadata
  -g, --language=                   Specify the Language Code for the chat, e.g. -g=en -g=zh
  -u, --scrape_url=                 Scrape website URL to markdown using Jina AI
  -q, --scrape_question=            Search question using Jina AI
  -e, --seed=                       Seed to be used for LMM generation
  -w, --wipecontext=                Wipe context
  -W, --wipesession=                Wipe session
      --printcontext=               Print context
      --printsession=               Print session
      --readability                 Convert HTML input into a clean, readable view
      --input-has-vars              Apply variables to user input
      --no-variable-replacement     Disable pattern variable replacement
      --dry-run                     Show what would be sent to the model without actually sending it
      --serve                       Serve the Fabric Rest API
      --serveOllama                 Serve the Fabric Rest API with ollama endpoints
      --address=                    The address to bind the REST API (default: :8080)
      --api-key=                    API key used to secure server routes
      --config=                     Path to YAML config file
      --version                     Print current version
      --listextensions              List all registered extensions
      --addextension=               Register a new extension from config file path
      --rmextension=                Remove a registered extension by name
      --strategy=                   Choose a strategy from the available strategies
      --liststrategies              List all strategies
      --listvendors                 List all vendors
      --shell-complete-list         Output raw list without headers/formatting (for shell completion)
      --search                      Enable web search tool for supported models (Anthropic, OpenAI, Gemini)
      --search-location=            Set location for web search results (e.g., 'America/Los_Angeles')
      --image-file=                 Save generated image to specified file path (e.g., 'output.png')
      --image-size=                 Image dimensions: 1024x1024, 1536x1024, 1024x1536, auto (default: auto)
      --image-quality=              Image quality: low, medium, high, auto (default: auto)
      --image-compression=          Compression level 0-100 for JPEG/WebP formats (default: not set)
      --image-background=           Background type: opaque, transparent (default: opaque, only for
                                    PNG/WebP)
      --suppress-think              Suppress text enclosed in thinking tags
      --think-start-tag=            Start tag for thinking sections (default: &amp;lt;think&amp;gt;)
      --think-end-tag=              End tag for thinking sections (default: &amp;lt;/think&amp;gt;)
      --disable-responses-api       Disable OpenAI Responses API (default: false)
      --voice=                      TTS voice name for supported models (e.g., Kore, Charon, Puck)
                                    (default: Kore)
      --list-gemini-voices          List all available Gemini TTS voices
      --notification                Send desktop notification when command completes
      --notification-command=       Custom command to run for notifications (overrides built-in
                                    notifications)
      --yt-dlp-args=                Additional arguments to pass to yt-dlp (e.g. '--cookies-from-browser brave')
      --thinking=                   Set reasoning/thinking level (e.g., off, low, medium, high, or
                                    numeric tokens for Anthropic or Google Gemini)
      --debug=                     Set debug level (0: off, 1: basic, 2: detailed, 3: trace)
Help Options:
  -h, --help                        Show this help message
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debug Levels&lt;/h3&gt; 
&lt;p&gt;Use the &lt;code&gt;--debug&lt;/code&gt; flag to control runtime logging:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;0&lt;/code&gt;: off (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1&lt;/code&gt;: basic debug info&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2&lt;/code&gt;: detailed debugging&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;3&lt;/code&gt;: trace level&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extensions&lt;/h3&gt; 
&lt;p&gt;Fabric supports extensions that can be called within patterns. See the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/internal/plugins/template/Examples/README.md"&gt;Extension Guide&lt;/a&gt; for complete documentation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Extensions only work within pattern files, not via direct stdin. See the guide for details and examples.&lt;/p&gt; 
&lt;h2&gt;REST API Server&lt;/h2&gt; 
&lt;p&gt;Fabric includes a built-in REST API server that exposes all core functionality over HTTP. Start the server with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fabric --serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The server provides endpoints for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chat completions with streaming responses&lt;/li&gt; 
 &lt;li&gt;Pattern management (create, read, update, delete)&lt;/li&gt; 
 &lt;li&gt;Context and session management&lt;/li&gt; 
 &lt;li&gt;Model and vendor listing&lt;/li&gt; 
 &lt;li&gt;YouTube transcript extraction&lt;/li&gt; 
 &lt;li&gt;Configuration management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For complete endpoint documentation, authentication setup, and usage examples, see &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/docs/rest-api.md"&gt;REST API Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Our approach to prompting&lt;/h2&gt; 
&lt;p&gt;Fabric &lt;em&gt;Patterns&lt;/em&gt; are different than most prompts you'll see.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;First, we use &lt;code&gt;Markdown&lt;/code&gt; to help ensure maximum readability and editability&lt;/strong&gt;. This not only helps the creator make a good one, but also anyone who wants to deeply understand what it does. &lt;em&gt;Importantly, this also includes the AI you're sending it to!&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here's an example of a Fabric Pattern.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;https://github.com/danielmiessler/Fabric/blob/main/data/patterns/extract_wisdom/system.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;img width="1461" alt="pattern-example" src="https://github.com/danielmiessler/fabric/assets/50654/b910c551-9263-405f-9735-71ca69bbab6d" /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Next, we are extremely clear in our instructions&lt;/strong&gt;, and we use the Markdown structure to emphasize what we want the AI to do, and in what order.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;And finally, we tend to use the System section of the prompt almost exclusively&lt;/strong&gt;. In over a year of being heads-down with this stuff, we've just seen more efficacy from doing that. If that changes, or we're shown data that says otherwise, we will adjust.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following examples use the macOS &lt;code&gt;pbpaste&lt;/code&gt; to paste from the clipboard. See the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#pbpaste"&gt;pbpaste&lt;/a&gt; section below for Windows and Linux alternatives.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Now let's look at some things you can do with Fabric.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run the &lt;code&gt;summarize&lt;/code&gt; Pattern based on input from &lt;code&gt;stdin&lt;/code&gt;. In this case, the body of an article.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pbpaste | fabric --pattern summarize
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the &lt;code&gt;analyze_claims&lt;/code&gt; Pattern with the &lt;code&gt;--stream&lt;/code&gt; option to get immediate and streaming results.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pbpaste | fabric --stream --pattern analyze_claims
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the &lt;code&gt;extract_wisdom&lt;/code&gt; Pattern with the &lt;code&gt;--stream&lt;/code&gt; option to get immediate and streaming results from any Youtube video (much like in the original introduction video).&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric -y "https://youtube.com/watch?v=uXs-zPc63kM" --stream --pattern extract_wisdom
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create patterns- you must create a .md file with the pattern and save it to &lt;code&gt;~/.config/fabric/patterns/[yourpatternname]&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run a &lt;code&gt;analyze_claims&lt;/code&gt; pattern on a website. Fabric uses Jina AI to scrape the URL into markdown format before sending it to the model.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric -u https://github.com/danielmiessler/fabric/ -p analyze_claims
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Just use the Patterns&lt;/h2&gt; 
&lt;img width="1173" alt="fabric-patterns-screenshot" src="https://github.com/danielmiessler/fabric/assets/50654/9186a044-652b-4673-89f7-71cf066f32d8" /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;If you're not looking to do anything fancy, and you just want a lot of great prompts, you can navigate to the &lt;a href="https://github.com/danielmiessler/fabric/tree/main/data/patterns"&gt;&lt;code&gt;/patterns&lt;/code&gt;&lt;/a&gt; directory and start exploring!&lt;/p&gt; 
&lt;p&gt;We hope that if you used nothing else from Fabric, the Patterns by themselves will make the project useful.&lt;/p&gt; 
&lt;p&gt;You can use any of the Patterns you see there in any AI application that you have, whether that's ChatGPT or some other app or website. Our plan and prediction is that people will soon be sharing many more than those we've published, and they will be way better than ours.&lt;/p&gt; 
&lt;p&gt;The wisdom of crowds for the win.&lt;/p&gt; 
&lt;h3&gt;Prompt Strategies&lt;/h3&gt; 
&lt;p&gt;Fabric also implements prompt strategies like "Chain of Thought" or "Chain of Draft" which can be used in addition to the basic patterns.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://arxiv.org/pdf/2502.18600"&gt;Thinking Faster by Writing Less&lt;/a&gt; paper and the &lt;a href="https://learnprompting.org/docs/advanced/thought_generation/introduction"&gt;Thought Generation section of Learn Prompting&lt;/a&gt; for examples of prompt strategies.&lt;/p&gt; 
&lt;p&gt;Each strategy is available as a small &lt;code&gt;json&lt;/code&gt; file in the &lt;a href="https://github.com/danielmiessler/fabric/tree/main/data/strategies"&gt;&lt;code&gt;/strategies&lt;/code&gt;&lt;/a&gt; directory.&lt;/p&gt; 
&lt;p&gt;The prompt modification of the strategy is applied to the system prompt and passed on to the LLM in the chat session.&lt;/p&gt; 
&lt;p&gt;Use &lt;code&gt;fabric -S&lt;/code&gt; and select the option to install the strategies in your &lt;code&gt;~/.config/fabric&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Custom Patterns&lt;/h2&gt; 
&lt;p&gt;You may want to use Fabric to create your own custom Patterns‚Äîbut not share them with others. No problem!&lt;/p&gt; 
&lt;p&gt;Fabric now supports a dedicated custom patterns directory that keeps your personal patterns separate from the built-in ones. This means your custom patterns won't be overwritten when you update Fabric's built-in patterns.&lt;/p&gt; 
&lt;h3&gt;Setting Up Custom Patterns&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run the Fabric setup:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric --setup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select the "Custom Patterns" option from the Tools menu and enter your desired directory path (e.g., &lt;code&gt;~/my-custom-patterns&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Fabric will automatically create the directory if it does not exist.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Using Custom Patterns&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create your custom pattern directory structure:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p ~/my-custom-patterns/my-analyzer
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create your pattern file&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;echo "You are an expert analyzer of ..." &amp;gt; ~/my-custom-patterns/my-analyzer/system.md
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Use your custom pattern:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric --pattern my-analyzer "analyze this text"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;How It Works&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Priority System&lt;/strong&gt;: Custom patterns take precedence over built-in patterns with the same name&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integration&lt;/strong&gt;: Custom patterns appear in &lt;code&gt;fabric --listpatterns&lt;/code&gt; alongside built-in ones&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update Safe&lt;/strong&gt;: Your custom patterns are never affected by &lt;code&gt;fabric --updatepatterns&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Private by Default&lt;/strong&gt;: Custom patterns remain private unless you explicitly share them&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your custom patterns are completely private and won't be affected by Fabric updates!&lt;/p&gt; 
&lt;h2&gt;Helper Apps&lt;/h2&gt; 
&lt;p&gt;Fabric also makes use of some core helper apps (tools) to make it easier to integrate with your various workflows. Here are some examples:&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;to_pdf&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;to_pdf&lt;/code&gt; is a helper command that converts LaTeX files to PDF format. You can use it like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;to_pdf input.tex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create a PDF file from the input LaTeX file in the same directory.&lt;/p&gt; 
&lt;p&gt;You can also use it with stdin which works perfectly with the &lt;code&gt;write_latex&lt;/code&gt; pattern:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo "ai security primer" | fabric --pattern write_latex | to_pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create a PDF file named &lt;code&gt;output.pdf&lt;/code&gt; in the current directory.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;to_pdf&lt;/code&gt; Installation&lt;/h3&gt; 
&lt;p&gt;To install &lt;code&gt;to_pdf&lt;/code&gt;, install it the same way as you install Fabric, just with a different repo name.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/to_pdf@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure you have a LaTeX distribution (like TeX Live or MiKTeX) installed on your system, as &lt;code&gt;to_pdf&lt;/code&gt; requires &lt;code&gt;pdflatex&lt;/code&gt; to be available in your system's PATH.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;code_helper&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;code_helper&lt;/code&gt; is used in conjunction with the &lt;code&gt;create_coding_feature&lt;/code&gt; pattern. It generates a &lt;code&gt;json&lt;/code&gt; representation of a directory of code that can be fed into an AI model with instructions to create a new feature or edit the code in a specified way.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/data/patterns/create_coding_feature/README.md"&gt;the Create Coding Feature Pattern README&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Install it first using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/code_helper@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;pbpaste&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#examples"&gt;examples&lt;/a&gt; use the macOS program &lt;code&gt;pbpaste&lt;/code&gt; to paste content from the clipboard to pipe into &lt;code&gt;fabric&lt;/code&gt; as the input. &lt;code&gt;pbpaste&lt;/code&gt; is not available on Windows or Linux, but there are alternatives.&lt;/p&gt; 
&lt;p&gt;On Windows, you can use the PowerShell command &lt;code&gt;Get-Clipboard&lt;/code&gt; from a PowerShell command prompt. If you like, you can also alias it to &lt;code&gt;pbpaste&lt;/code&gt;. If you are using classic PowerShell, edit the file &lt;code&gt;~\Documents\WindowsPowerShell\.profile.ps1&lt;/code&gt;, or if you are using PowerShell Core, edit &lt;code&gt;~\Documents\PowerShell\.profile.ps1&lt;/code&gt; and add the alias,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;Set-Alias pbpaste Get-Clipboard
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Linux, you can use &lt;code&gt;xclip -selection clipboard -o&lt;/code&gt; to paste from the clipboard. You will likely need to install &lt;code&gt;xclip&lt;/code&gt; with your package manager. For Debian based systems including Ubuntu,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt update
sudo apt install xclip -y
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also create an alias by editing &lt;code&gt;~/.bashrc&lt;/code&gt; or &lt;code&gt;~/.zshrc&lt;/code&gt; and adding the alias,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;alias pbpaste='xclip -selection clipboard -o'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Web Interface (Fabric Web App)&lt;/h2&gt; 
&lt;p&gt;Fabric now includes a built-in web interface that provides a GUI alternative to the command-line interface. Refer to &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/web/README.md"&gt;Web App README&lt;/a&gt; for installation instructions and an overview of features.&lt;/p&gt; 
&lt;h2&gt;Meta&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Special thanks to the following people for their inspiration and contributions!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;Jonathan Dunn&lt;/em&gt; for being the absolute MVP dev on the project, including spearheading the new Go version, as well as the GUI! All this while also being a full-time medical doctor!&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Caleb Sima&lt;/em&gt; for pushing me over the edge of whether to make this a public project or not.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Eugen Eisler&lt;/em&gt; and &lt;em&gt;Frederick Ros&lt;/em&gt; for their invaluable contributions to the Go version&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;David Peters&lt;/em&gt; for his work on the web interface.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Joel Parish&lt;/em&gt; for super useful input on the project's Github directory structure..&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Joseph Thacker&lt;/em&gt; for the idea of a &lt;code&gt;-c&lt;/code&gt; context flag that adds pre-created context in the &lt;code&gt;./config/fabric/&lt;/code&gt; directory to all Pattern queries.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Jason Haddix&lt;/em&gt; for the idea of a stitch (chained Pattern) to filter content using a local model before sending on to a cloud model, i.e., cleaning customer data using &lt;code&gt;llama2&lt;/code&gt; before sending on to &lt;code&gt;gpt-4&lt;/code&gt; for analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Andre Guerra&lt;/em&gt; for assisting with numerous components to make things simpler and more maintainable.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Primary contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/danielmiessler"&gt;&lt;img src="https://avatars.githubusercontent.com/u/50654?v=4" title="Daniel Miessler" width="50" height="50" alt="Daniel Miessler" /&gt;&lt;/a&gt; &lt;a href="https://github.com/xssdoctor"&gt;&lt;img src="https://avatars.githubusercontent.com/u/9218431?v=4" title="Jonathan Dunn" width="50" height="50" alt="Jonathan Dunn" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sbehrens"&gt;&lt;img src="https://avatars.githubusercontent.com/u/688589?v=4" title="Scott Behrens" width="50" height="50" alt="Scott Behrens" /&gt;&lt;/a&gt; &lt;a href="https://github.com/agu3rra"&gt;&lt;img src="https://avatars.githubusercontent.com/u/10410523?v=4" title="Andre Guerra" width="50" height="50" alt="Andre Guerra" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;a href="https://github.com/danielmiessler/fabric/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=danielmiessler/fabric" alt="contrib.rocks" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;fabric&lt;/code&gt; was created by &lt;a href="https://danielmiessler.com/subscribe" target="_blank"&gt;Daniel Miessler&lt;/a&gt; in January of 2024. &lt;br /&gt;&lt;br /&gt; &lt;a href="https://twitter.com/intent/user?screen_name=danielmiessler"&gt;&lt;img src="https://img.shields.io/twitter/follow/danielmiessler" alt="X (formerly Twitter) Follow" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BloopAI/vibe-kanban</title>
      <link>https://github.com/BloopAI/vibe-kanban</link>
      <description>&lt;p&gt;Get 10X more out of Claude Code, Codex or any coding agent&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://vibekanban.com"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="frontend/public/vibe-kanban-logo-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="frontend/public/vibe-kanban-logo.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/BloopAI/vibe-kanban/main/frontend/public/vibe-kanban-logo.svg?sanitize=true" alt="Vibe Kanban Logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.npmjs.com/package/vibe-kanban"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/vibe-kanban?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/BloopAI/vibe-kanban/raw/main/.github/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/BloopAI/vibe-kanban"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; &lt;a href="https://jobs.polymer.co/vibe-kanban?source=github"&gt;&lt;strong&gt;We're hiring!&lt;/strong&gt;&lt;/a&gt; &lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/BloopAI/vibe-kanban/main/frontend/public/vibe-kanban-screenshot-overview.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;AI coding agents are increasingly writing the world's code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easily switch between different coding agents&lt;/li&gt; 
 &lt;li&gt;Orchestrate the execution of multiple coding agents in parallel or in sequence&lt;/li&gt; 
 &lt;li&gt;Quickly review work and start dev servers&lt;/li&gt; 
 &lt;li&gt;Track the status of tasks that your coding agents are working on&lt;/li&gt; 
 &lt;li&gt;Centralise configuration of coding agent MCP configs&lt;/li&gt; 
 &lt;li&gt;Open projects remotely via SSH when running Vibe Kanban on a remote server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can watch a video overview &lt;a href="https://youtu.be/TFT3KnZOOAk"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Make sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the &lt;a href="https://vibekanban.com/docs"&gt;docs&lt;/a&gt;. Then in your terminal run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx vibe-kanban
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Please head to the &lt;a href="https://vibekanban.com/docs"&gt;website&lt;/a&gt; for the latest documentation and user guides.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/BloopAI/vibe-kanban/discussions"&gt;GitHub Discussions&lt;/a&gt; for feature requests. Please open a discussion to create a feature request. For bugs please open an issue on this repo.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We would prefer that ideas and changes are first raised with the core team via &lt;a href="https://github.com/BloopAI/vibe-kanban/discussions"&gt;GitHub Discussions&lt;/a&gt; or &lt;a href="https://discord.gg/AC4nwVtJM3"&gt;Discord&lt;/a&gt;, where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt; (latest stable)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; (&amp;gt;=18)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt; (&amp;gt;=8)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additional development tools:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-watch
cargo install sqlx-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm i
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running the dev server&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start the backend. A blank DB will be copied from the &lt;code&gt;dev_assets_seed&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h3&gt;Building the frontend&lt;/h3&gt; 
&lt;p&gt;To build just the frontend:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
pnpm build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build from source (macOS)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run &lt;code&gt;./local-build.sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Test with &lt;code&gt;cd npx-cli &amp;amp;&amp;amp; node bin/cli.js&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;The following environment variables can be configured at build time or runtime:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POSTHOG_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Build-time&lt;/td&gt; 
   &lt;td&gt;Empty&lt;/td&gt; 
   &lt;td&gt;PostHog analytics API key (disables analytics if empty)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POSTHOG_API_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Build-time&lt;/td&gt; 
   &lt;td&gt;Empty&lt;/td&gt; 
   &lt;td&gt;PostHog analytics endpoint (disables analytics if empty)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;Auto-assign&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Production&lt;/strong&gt;: Server port. &lt;strong&gt;Dev&lt;/strong&gt;: Frontend port (backend uses PORT+1)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BACKEND_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0&lt;/code&gt; (auto-assign)&lt;/td&gt; 
   &lt;td&gt;Backend server port (dev mode only, overrides PORT+1)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FRONTEND_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;3000&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Frontend dev server port (dev mode only, overrides PORT)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;127.0.0.1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Backend server host&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DISABLE_WORKTREE_ORPHAN_CLEANUP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;Not set&lt;/td&gt; 
   &lt;td&gt;Disable git worktree cleanup (for debugging)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Build-time variables&lt;/strong&gt; must be set when running &lt;code&gt;pnpm run build&lt;/code&gt;. &lt;strong&gt;Runtime variables&lt;/strong&gt; are read when the application starts.&lt;/p&gt; 
&lt;h3&gt;Remote Deployment&lt;/h3&gt; 
&lt;p&gt;When running Vibe Kanban on a remote server (e.g., via systemctl, Docker, or cloud hosting), you can configure your editor to open projects via SSH:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Access via tunnel&lt;/strong&gt;: Use Cloudflare Tunnel, ngrok, or similar to expose the web UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configure remote SSH&lt;/strong&gt; in Settings ‚Üí Editor Integration: 
  &lt;ul&gt; 
   &lt;li&gt;Set &lt;strong&gt;Remote SSH Host&lt;/strong&gt; to your server hostname or IP&lt;/li&gt; 
   &lt;li&gt;Set &lt;strong&gt;Remote SSH User&lt;/strong&gt; to your SSH username (optional)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;SSH access from your local machine to the remote server&lt;/li&gt; 
   &lt;li&gt;SSH keys configured (passwordless authentication)&lt;/li&gt; 
   &lt;li&gt;VSCode Remote-SSH extension&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;When configured, the "Open in VSCode" buttons will generate URLs like &lt;code&gt;vscode://vscode-remote/ssh-remote+user@host/path&lt;/code&gt; that open your local editor and connect to the remote server.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://vibekanban.com/docs/configuration-customisation/global-settings#remote-ssh-configuration"&gt;documentation&lt;/a&gt; for detailed setup instructions.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>