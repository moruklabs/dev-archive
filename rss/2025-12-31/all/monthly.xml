<rss version="2.0">
  <channel>
    <title>GitHub All Languages Monthly Trending</title>
    <description>Monthly Trending of All Languages in GitHub</description>
    <pubDate>Tue, 30 Dec 2026 01:49:36 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>sst/opencode</title>
      <link>https://github.com/sst/opencode</link>
      <description>&lt;p&gt;The open source coding agent.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://opencode.ai"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-light.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/console/app/src/asset/logo-ornate-light.svg?sanitize=true" alt="OpenCode logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;The open source AI coding agent.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://opencode.ai/discord"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;amp;label=discord" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/opencode-ai"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/opencode-ai?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sst/opencode/actions/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/sst/opencode/publish.yml?style=flat-square&amp;amp;branch=dev" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencode.ai"&gt;&lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/web/src/assets/lander/screenshot.png" alt="OpenCode Terminal UI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
scoop bucket add extras; scoop install extras/opencode  # Windows
choco install opencode             # Windows
brew install opencode              # macOS and Linux
paru -S opencode-bin               # Arch Linux
mise use -g github:sst/opencode # Any OS
nix run nixpkgs#opencode           # or github:sst/opencode for latest dev branch
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Remove versions older than 0.1.x before installing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Desktop App (BETA)&lt;/h3&gt; 
&lt;p&gt;OpenCode is also available as a desktop application. Download directly from the &lt;a href="https://github.com/sst/opencode/releases"&gt;releases page&lt;/a&gt; or &lt;a href="https://opencode.ai/download"&gt;opencode.ai/download&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Apple Silicon)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-aarch64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Intel)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-x64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-windows-x64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, or AppImage&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (Homebrew)
brew install --cask opencode-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installation Directory&lt;/h4&gt; 
&lt;p&gt;The install script respects the following priority order for the installation path:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;$OPENCODE_INSTALL_DIR&lt;/code&gt; - Custom installation directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$XDG_BIN_DIR&lt;/code&gt; - XDG Base Directory Specification compliant path&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/bin&lt;/code&gt; - Standard user binary directory (if exists or can be created)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.opencode/bin&lt;/code&gt; - Default fallback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Agents&lt;/h3&gt; 
&lt;p&gt;OpenCode includes two built-in agents you can switch between, you can switch between these using the &lt;code&gt;Tab&lt;/code&gt; key.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;build&lt;/strong&gt; - Default, full access agent for development work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;plan&lt;/strong&gt; - Read-only agent for analysis and code exploration 
  &lt;ul&gt; 
   &lt;li&gt;Denies file edits by default&lt;/li&gt; 
   &lt;li&gt;Asks permission before running bash commands&lt;/li&gt; 
   &lt;li&gt;Ideal for exploring unfamiliar codebases or planning changes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, included is a &lt;strong&gt;general&lt;/strong&gt; subagent for complex searches and multistep tasks. This is used internally and can be invoked using &lt;code&gt;@general&lt;/code&gt; in messages.&lt;/p&gt; 
&lt;p&gt;Learn more about &lt;a href="https://opencode.ai/docs/agents"&gt;agents&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;For more info on how to configure OpenCode &lt;a href="https://opencode.ai/docs"&gt;&lt;strong&gt;head over to our docs&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;If you're interested in contributing to OpenCode, please read our &lt;a href="https://raw.githubusercontent.com/sst/opencode/dev/CONTRIBUTING.md"&gt;contributing docs&lt;/a&gt; before submitting a pull request.&lt;/p&gt; 
&lt;h3&gt;Building on OpenCode&lt;/h3&gt; 
&lt;p&gt;If you are working on a project that's related to OpenCode and is using "opencode" as a part of its name; for example, "opencode-dashboard" or "opencode-mobile", please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in any way.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;h4&gt;How is this different from Claude Code?&lt;/h4&gt; 
&lt;p&gt;It's very similar to Claude Code in terms of capability. Here are the key differences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100% open source&lt;/li&gt; 
 &lt;li&gt;Not coupled to any provider. Although we recommend the models we provide through &lt;a href="https://opencode.ai/zen"&gt;OpenCode Zen&lt;/a&gt;; OpenCode can be used with Claude, OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.&lt;/li&gt; 
 &lt;li&gt;Out of the box LSP support&lt;/li&gt; 
 &lt;li&gt;A focus on TUI. OpenCode is built by neovim users and the creators of &lt;a href="https://terminal.shop"&gt;terminal.shop&lt;/a&gt;; we are going to push the limits of what's possible in the terminal.&lt;/li&gt; 
 &lt;li&gt;A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;What's the other repo?&lt;/h4&gt; 
&lt;p&gt;The other confusingly named repo has no relation to this one. You can &lt;a href="https://x.com/thdxr/status/1933561254481666466"&gt;read the story behind it here&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Join our community&lt;/strong&gt; &lt;a href="https://discord.gg/opencode"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/opencode"&gt;X.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rustfs/rustfs</title>
      <link>https://github.com/rustfs/rustfs</link>
      <description>&lt;p&gt;üöÄ2.3x faster than MinIO for 4KB object payloads. RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://rustfs.com"&gt;&lt;img src="https://rustfs.com/images/rustfs-github.png" alt="RustFS" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;RustFS is a high-performance, distributed object storage system built in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/ci.yml"&gt;&lt;img alt="CI" src="https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/docker.yml"&gt;&lt;img alt="Build and Push Docker Images" src="https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/rustfs/rustfs" /&gt; &lt;img alt="Github Last Commit" src="https://img.shields.io/github/last-commit/rustfs/rustfs" /&gt; &lt;a href="https://hellogithub.com/repository/rustfs/rustfs" target="_blank"&gt;&lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&amp;amp;claim_uid=MsbvjYeLDKAH457&amp;amp;theme=small" alt="FeaturedÔΩúHelloGitHub" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://docs.rustfs.com/installation/"&gt;Getting Started&lt;/a&gt; ¬∑ &lt;a href="https://docs.rustfs.com/"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;Bug reports&lt;/a&gt; ¬∑ &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;Discussions&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; English | &lt;a href="https://github.com/rustfs/rustfs/raw/main/README_ZH.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=pt"&gt;Portuguese&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;RustFS is a high-performance, distributed object storage system built in Rust‚Äîone of the most loved programming languages worldwide. RustFS combines the simplicity of MinIO with the memory safety and raw performance of Rust. It offers full S3 compatibility, is completely open-source, and is optimized for data lakes, AI, and big data workloads.&lt;/p&gt; 
&lt;p&gt;Unlike other storage systems, RustFS is released under the permissible Apache 2.0 license, avoiding the restrictions of AGPL. With Rust as its foundation, RustFS delivers superior speed and secure distributed features for next-generation object storage.&lt;/p&gt; 
&lt;h2&gt;Feature &amp;amp; Status&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Built with Rust to ensure maximum speed and resource efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Architecture&lt;/strong&gt;: Scalable and fault-tolerant design suitable for large-scale deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3 Compatibility&lt;/strong&gt;: Seamless integration with existing S3-compatible applications and tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Lake Support&lt;/strong&gt;: Optimized for high-throughput big data and AI workloads.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source&lt;/strong&gt;: Licensed under Apache 2.0, encouraging unrestricted community contributions and commercial usage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User-Friendly&lt;/strong&gt;: Designed with simplicity in mind for easy deployment and management.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;S3 Core Features&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Bitrot Protection&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Upload / Download&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Single Node Mode&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Versioning&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Bucket Replication&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚ö†Ô∏è Partial Support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Logging&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Lifecycle Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;üöß Under Testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Event Notifications&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Distributed Mode&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;üöß Under Testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;K8s Helm Charts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;OPA (Open Policy Agent)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;üöß Under Testing&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;RustFS vs MinIO Performance&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Stress Test Environment:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Parameter&lt;/th&gt; 
   &lt;th&gt;Remark&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
   &lt;td&gt;2 Core&lt;/td&gt; 
   &lt;td&gt;Intel Xeon (Sapphire Rapids) Platinum 8475B, 2.7/3.2 GHz&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Network&lt;/td&gt; 
   &lt;td&gt;15Gbps&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Drive&lt;/td&gt; 
   &lt;td&gt;40GB x 4&lt;/td&gt; 
   &lt;td&gt;IOPS 3800 / Drive&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a"&gt;https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RustFS vs Other Object Storage&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;RustFS&lt;/th&gt; 
   &lt;th align="left"&gt;Other Object Storage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Console Experience&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Powerful Console&lt;/strong&gt;&lt;br /&gt;Comprehensive management interface.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Basic / Limited Console&lt;/strong&gt;&lt;br /&gt;Often overly simple or lacking critical features.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Language &amp;amp; Safety&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Rust-based&lt;/strong&gt;&lt;br /&gt;Memory safety by design.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Go or C-based&lt;/strong&gt;&lt;br /&gt;Potential for memory GC pauses or leaks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Data Sovereignty&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;No Telemetry / Full Compliance&lt;/strong&gt;&lt;br /&gt;Guards against unauthorized cross-border data egress. Compliant with GDPR (EU/UK), CCPA (US), and APPI (Japan).&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Potential Risk&lt;/strong&gt;&lt;br /&gt;Possible legal exposure and unwanted data telemetry.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Licensing&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Permissive Apache 2.0&lt;/strong&gt;&lt;br /&gt;Business-friendly, no "poison pill" clauses.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Restrictive AGPL v3&lt;/strong&gt;&lt;br /&gt;Risk of license traps and intellectual property pollution.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Compatibility&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;100% S3 Compatible&lt;/strong&gt;&lt;br /&gt;Works with any cloud provider or client, anywhere.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Variable Compatibility&lt;/strong&gt;&lt;br /&gt;May lack support for local cloud vendors or specific APIs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Edge &amp;amp; IoT&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Strong Edge Support&lt;/strong&gt;&lt;br /&gt;Ideal for secure, innovative edge devices.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Weak Edge Support&lt;/strong&gt;&lt;br /&gt;Often too heavy for edge gateways.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Risk Profile&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Enterprise Risk Mitigation&lt;/strong&gt;&lt;br /&gt;Clear IP rights and safe for commercial use.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Legal Risks&lt;/strong&gt;&lt;br /&gt;Intellectual property ambiguity and usage restrictions.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To get started with RustFS, follow these steps:&lt;/p&gt; 
&lt;h3&gt;1. One-click Installation (Option 1)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -O https://rustfs.com/install_rustfs.sh &amp;amp;&amp;amp; bash install_rustfs.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Docker Quick Start (Option 2)&lt;/h3&gt; 
&lt;p&gt;The RustFS container runs as a non-root user &lt;code&gt;rustfs&lt;/code&gt; (UID &lt;code&gt;10001&lt;/code&gt;). If you run Docker with &lt;code&gt;-v&lt;/code&gt; to mount a host directory, please ensure the host directory owner is set to &lt;code&gt;10001&lt;/code&gt;, otherwise you will encounter permission denied errors.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; # Create data and logs directories
 mkdir -p data logs

 # Change the owner of these directories
 chown -R 10001:10001 data logs

 # Using latest version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:latest

 # Using specific version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0-alpha.76
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use Docker Compose. Using the &lt;code&gt;docker-compose.yml&lt;/code&gt; file in the root directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose --profile observability up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: We recommend reviewing the &lt;code&gt;docker-compose.yaml&lt;/code&gt; file before running. It defines several services including Grafana, Prometheus, and Jaeger, which are helpful for RustFS observability. If you wish to start Redis or Nginx containers, you can specify the corresponding profiles.&lt;/p&gt; 
&lt;h3&gt;3. Build from Source (Option 3) - Advanced Users&lt;/h3&gt; 
&lt;p&gt;For developers who want to build RustFS Docker images from source with multi-architecture support:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build multi-architecture images locally
./docker-buildx.sh --build-arg RELEASE=latest

# Build and push to registry
./docker-buildx.sh --push

# Build specific version
./docker-buildx.sh --release v1.0.0 --push

# Build for custom registry
./docker-buildx.sh --registry your-registry.com --namespace yourname --push
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;docker-buildx.sh&lt;/code&gt; script supports: - &lt;strong&gt;Multi-architecture builds&lt;/strong&gt;: &lt;code&gt;linux/amd64&lt;/code&gt;, &lt;code&gt;linux/arm64&lt;/code&gt; - &lt;strong&gt;Automatic version detection&lt;/strong&gt;: Uses git tags or commit hashes - &lt;strong&gt;Registry flexibility&lt;/strong&gt;: Supports Docker Hub, GitHub Container Registry, etc. - &lt;strong&gt;Build optimization&lt;/strong&gt;: Includes caching and parallel builds&lt;/p&gt; 
&lt;p&gt;You can also use Make targets for convenience:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make docker-buildx                    # Build locally
make docker-buildx-push               # Build and push
make docker-buildx-version VERSION=v1.0.0  # Build specific version
make help-docker                      # Show all Docker-related commands
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Heads-up (macOS cross-compilation)&lt;/strong&gt;: macOS keeps the default &lt;code&gt;ulimit -n&lt;/code&gt; at 256, so &lt;code&gt;cargo zigbuild&lt;/code&gt; or &lt;code&gt;./build-rustfs.sh --platform ...&lt;/code&gt; may fail with &lt;code&gt;ProcessFdQuotaExceeded&lt;/code&gt; when targeting Linux. The build script attempts to raise the limit automatically, but if you still see the warning, run &lt;code&gt;ulimit -n 4096&lt;/code&gt; (or higher) in your shell before building.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;4. Build with Helm Chart (Option 4) - Cloud Native&lt;/h3&gt; 
&lt;p&gt;Follow the instructions in the &lt;a href="https://charts.rustfs.com/"&gt;Helm Chart README&lt;/a&gt; to install RustFS on a Kubernetes cluster.&lt;/p&gt; 
&lt;h3&gt;5. Nix Flake (Option 5)&lt;/h3&gt; 
&lt;p&gt;If you have &lt;a href="https://nixos.wiki/wiki/Flakes#Enable_flakes"&gt;Nix with flakes enabled&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run directly without installing
nix run github:rustfs/rustfs

# Build the binary
nix build github:rustfs/rustfs
./result/bin/rustfs --help

# Or from a local checkout
nix build
nix run
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Accessing RustFS&lt;/h3&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;&lt;strong&gt;Access the Console&lt;/strong&gt;: Open your web browser and navigate to &lt;code&gt;http://localhost:9001&lt;/code&gt; to access the RustFS console. 
  &lt;ul&gt; 
   &lt;li&gt;Default credentials: &lt;code&gt;rustfsadmin&lt;/code&gt; / &lt;code&gt;rustfsadmin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Bucket&lt;/strong&gt;: Use the console to create a new bucket for your objects.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload Objects&lt;/strong&gt;: You can upload files directly through the console or use S3-compatible APIs/clients to interact with your RustFS instance.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: To access the RustFS instance via &lt;code&gt;https&lt;/code&gt;, please refer to the &lt;a href="https://docs.rustfs.com/integration/tls-configured.html"&gt;TLS Configuration Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, including configuration options, API references, and advanced usage, please visit our &lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or need assistance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check the &lt;a href="https://github.com/rustfs/rustfs/discussions/categories/q-a"&gt;FAQ&lt;/a&gt; for common issues and solutions.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; to ask questions and share your experiences.&lt;/li&gt; 
 &lt;li&gt;Open an issue on our &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt; page for bug reports or feature requests.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt; - The manual you should read&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/releases"&gt;Changelog&lt;/a&gt; - What we broke and fixed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; - Where the community lives&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bugs&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business&lt;/strong&gt;: &lt;a href="mailto:hello@rustfs.com"&gt;hello@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jobs&lt;/strong&gt;: &lt;a href="mailto:jobs@rustfs.com"&gt;jobs@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General Discussion&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contributing&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/rustfs/rustfs/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;RustFS is a community-driven project, and we appreciate all contributions. Check out the &lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt;Contributors&lt;/a&gt; page to see the amazing people who have helped make RustFS better.&lt;/p&gt; 
&lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt; &lt;img src="https://opencollective.com/rustfs/contributors.svg?width=890&amp;amp;limit=500&amp;amp;button=false" alt="Contributors" /&gt; &lt;/a&gt; 
&lt;h2&gt;Github Trending Top&lt;/h2&gt; 
&lt;p&gt;üöÄ RustFS is beloved by open-source enthusiasts and enterprise users worldwide, often appearing on the GitHub Trending top charts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/14181" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/rustfs/rustfs/refs/heads/main/docs/rustfs-trending.jpg" alt="rustfs%2Frustfs | Trendshift" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;Apache 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RustFS&lt;/strong&gt; is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>thedotmack/claude-mem</title>
      <link>https://github.com/thedotmack/claude-mem</link>
      <description>&lt;p&gt;A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;a href="https://github.com/thedotmack/claude-mem"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-dark-mode.webp" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp" alt="Claude-Mem" width="400" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.zh.md"&gt;üá®üá≥ ‰∏≠Êñá&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ja.md"&gt;üáØüáµ Êó•Êú¨Ë™û&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.pt-br.md"&gt;üáßüá∑ Portugu√™s&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ko.md"&gt;üá∞üá∑ ÌïúÍµ≠Ïñ¥&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.es.md"&gt;üá™üá∏ Espa√±ol&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.de.md"&gt;üá©üá™ Deutsch&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.fr.md"&gt;üá´üá∑ Fran√ßais&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.he.md"&gt;üáÆüá± ◊¢◊ë◊®◊ô◊™&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ar.md"&gt;üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ru.md"&gt;üá∑üá∫ –†—É—Å—Å–∫–∏–π&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.pl.md"&gt;üáµüá± Polski&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.cs.md"&gt;üá®üáø ƒåe≈°tina&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.nl.md"&gt;üá≥üá± Nederlands&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.tr.md"&gt;üáπüá∑ T√ºrk√ße&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.uk.md"&gt;üá∫üá¶ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.vi.md"&gt;üáªüá≥ Ti·∫øng Vi·ªát&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.id.md"&gt;üáÆüá© Indonesia&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.th.md"&gt;üáπüá≠ ‡πÑ‡∏ó‡∏¢&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.hi.md"&gt;üáÆüá≥ ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.bn.md"&gt;üáßüá© ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ro.md"&gt;üá∑üá¥ Rom√¢nƒÉ&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.sv.md"&gt;üá∏üá™ Svenska&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.it.md"&gt;üáÆüáπ Italiano&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.el.md"&gt;üá¨üá∑ ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.hu.md"&gt;üá≠üá∫ Magyar&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.fi.md"&gt;üá´üáÆ Suomi&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.da.md"&gt;üá©üá∞ Dansk&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.no.md"&gt;üá≥üá¥ Norsk&lt;/a&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt;Persistent memory compression system built for &lt;a href="https://claude.com/claude-code" target="_blank"&gt;Claude Code&lt;/a&gt;.&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-AGPL%203.0-blue.svg?sanitize=true" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/package.json"&gt; &lt;img src="https://img.shields.io/badge/version-6.5.0-green.svg?sanitize=true" alt="Version" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/package.json"&gt; &lt;img src="https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg?sanitize=true" alt="Node" /&gt; &lt;/a&gt; &lt;a href="https://github.com/thedotmack/awesome-claude-code"&gt; &lt;img src="https://awesome.re/mentioned-badge.svg?sanitize=true" alt="Mentioned in Awesome Claude Code" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15496" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge-dark.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg?sanitize=true" alt="thedotmack/claude-mem | Trendshift" width="250" height="55" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/thedotmack/claude-mem"&gt; 
  &lt;picture&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/cm-preview.gif" alt="Claude-Mem Preview" width="800" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#quick-start"&gt;Quick Start&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#how-it-works"&gt;How It Works&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#mcp-search-tools"&gt;Search Tools&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#documentation"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#configuration"&gt;Configuration&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Claude-Mem seamlessly preserves context across sessions by automatically capturing tool usage observations, generating semantic summaries, and making them available to future sessions. This enables Claude to maintain continuity of knowledge about projects even after sessions end or reconnect. &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Start a new Claude Code session in the terminal and enter the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; /plugin marketplace add thedotmack/claude-mem

&amp;gt; /plugin install claude-mem
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Claude Code. Context from previous sessions will automatically appear in new sessions.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß† &lt;strong&gt;Persistent Memory&lt;/strong&gt; - Context survives across sessions&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Progressive Disclosure&lt;/strong&gt; - Layered memory retrieval with token cost visibility&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Skill-Based Search&lt;/strong&gt; - Query your project history with mem-search skill&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è &lt;strong&gt;Web Viewer UI&lt;/strong&gt; - Real-time memory stream at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üíª &lt;strong&gt;Claude Desktop Skill&lt;/strong&gt; - Search memory from Claude Desktop conversations&lt;/li&gt; 
 &lt;li&gt;üîí &lt;strong&gt;Privacy Control&lt;/strong&gt; - Use &lt;code&gt;&amp;lt;private&amp;gt;&lt;/code&gt; tags to exclude sensitive content from storage&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Context Configuration&lt;/strong&gt; - Fine-grained control over what context gets injected&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Automatic Operation&lt;/strong&gt; - No manual intervention required&lt;/li&gt; 
 &lt;li&gt;üîó &lt;strong&gt;Citations&lt;/strong&gt; - Reference past observations with IDs (access via &lt;a href="http://localhost:37777/api/observation/%7Bid%7D"&gt;http://localhost:37777/api/observation/{id}&lt;/a&gt; or view all in the web viewer at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Beta Channel&lt;/strong&gt; - Try experimental features like Endless Mode via version switching&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;üìö &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/"&gt;View Full Documentation&lt;/a&gt;&lt;/strong&gt; - Browse markdown docs on GitHub&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/installation"&gt;Installation Guide&lt;/a&gt;&lt;/strong&gt; - Quick start &amp;amp; advanced installation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/usage/getting-started"&gt;Usage Guide&lt;/a&gt;&lt;/strong&gt; - How Claude-Mem works automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/usage/search-tools"&gt;Search Tools&lt;/a&gt;&lt;/strong&gt; - Query your project history with natural language&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/beta-features"&gt;Beta Features&lt;/a&gt;&lt;/strong&gt; - Try experimental features like Endless Mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Best Practices&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/context-engineering"&gt;Context Engineering&lt;/a&gt;&lt;/strong&gt; - AI agent context optimization principles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/progressive-disclosure"&gt;Progressive Disclosure&lt;/a&gt;&lt;/strong&gt; - Philosophy behind Claude-Mem's context priming strategy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/overview"&gt;Overview&lt;/a&gt;&lt;/strong&gt; - System components &amp;amp; data flow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture-evolution"&gt;Architecture Evolution&lt;/a&gt;&lt;/strong&gt; - The journey from v3 to v5&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/hooks-architecture"&gt;Hooks Architecture&lt;/a&gt;&lt;/strong&gt; - How Claude-Mem uses lifecycle hooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/hooks"&gt;Hooks Reference&lt;/a&gt;&lt;/strong&gt; - 7 hook scripts explained&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/worker-service"&gt;Worker Service&lt;/a&gt;&lt;/strong&gt; - HTTP API &amp;amp; Bun management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/database"&gt;Database&lt;/a&gt;&lt;/strong&gt; - SQLite schema &amp;amp; FTS5 search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/search-architecture"&gt;Search Architecture&lt;/a&gt;&lt;/strong&gt; - Hybrid search with Chroma vector database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configuration &amp;amp; Development&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/configuration"&gt;Configuration&lt;/a&gt;&lt;/strong&gt; - Environment variables &amp;amp; settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/development"&gt;Development&lt;/a&gt;&lt;/strong&gt; - Building, testing, contributing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/strong&gt; - Common issues &amp;amp; solutions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Core Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;5 Lifecycle Hooks&lt;/strong&gt; - SessionStart, UserPromptSubmit, PostToolUse, Stop, SessionEnd (6 hook scripts)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Install&lt;/strong&gt; - Cached dependency checker (pre-hook script, not a lifecycle hook)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Worker Service&lt;/strong&gt; - HTTP API on port 37777 with web viewer UI and 10 search endpoints, managed by Bun&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite Database&lt;/strong&gt; - Stores sessions, observations, summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;mem-search Skill&lt;/strong&gt; - Natural language queries with progressive disclosure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chroma Vector Database&lt;/strong&gt; - Hybrid semantic + keyword search for intelligent context retrieval&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/architecture/overview"&gt;Architecture Overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;MCP Search Tools&lt;/h2&gt; 
&lt;p&gt;Claude-Mem provides intelligent memory search through &lt;strong&gt;4 MCP tools&lt;/strong&gt; following a token-efficient &lt;strong&gt;3-layer workflow pattern&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The 3-Layer Workflow:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;search&lt;/code&gt;&lt;/strong&gt; - Get compact index with IDs (~50-100 tokens/result)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;timeline&lt;/code&gt;&lt;/strong&gt; - Get chronological context around interesting results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_observations&lt;/code&gt;&lt;/strong&gt; - Fetch full details ONLY for filtered IDs (~500-1,000 tokens/result)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;How It Works:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude uses MCP tools to search your memory&lt;/li&gt; 
 &lt;li&gt;Start with &lt;code&gt;search&lt;/code&gt; to get an index of results&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;timeline&lt;/code&gt; to see what was happening around specific observations&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;get_observations&lt;/code&gt; to fetch full details for relevant IDs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;~10x token savings&lt;/strong&gt; by filtering before fetching details&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Available MCP Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;search&lt;/code&gt;&lt;/strong&gt; - Search memory index with full-text queries, filters by type/date/project&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;timeline&lt;/code&gt;&lt;/strong&gt; - Get chronological context around a specific observation or query&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_observations&lt;/code&gt;&lt;/strong&gt; - Fetch full observation details by IDs (always batch multiple IDs)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;__IMPORTANT&lt;/code&gt;&lt;/strong&gt; - Workflow documentation (always visible to Claude)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Step 1: Search for index
search(query="authentication bug", type="bugfix", limit=10)

// Step 2: Review index, identify relevant IDs (e.g., #123, #456)

// Step 3: Fetch full details
get_observations(ids=[123, 456])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/usage/search-tools"&gt;Search Tools Guide&lt;/a&gt; for detailed examples.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Beta Features&lt;/h2&gt; 
&lt;p&gt;Claude-Mem offers a &lt;strong&gt;beta channel&lt;/strong&gt; with experimental features like &lt;strong&gt;Endless Mode&lt;/strong&gt; (biomimetic memory architecture for extended sessions). Switch between stable and beta versions from the web viewer UI at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt; ‚Üí Settings.&lt;/p&gt; 
&lt;p&gt;See &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/beta-features"&gt;Beta Features Documentation&lt;/a&gt;&lt;/strong&gt; for details on Endless Mode and how to try it.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: 18.0.0 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Code&lt;/strong&gt;: Latest version with plugin support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bun&lt;/strong&gt;: JavaScript runtime and process manager (auto-installed if missing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;uv&lt;/strong&gt;: Python package manager for vector search (auto-installed if missing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite 3&lt;/strong&gt;: For persistent storage (bundled)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Settings are managed in &lt;code&gt;~/.claude-mem/settings.json&lt;/code&gt; (auto-created with defaults on first run). Configure AI model, worker port, data directory, log level, and context injection settings.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/configuration"&gt;Configuration Guide&lt;/a&gt;&lt;/strong&gt; for all available settings and examples.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;See the &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/development"&gt;Development Guide&lt;/a&gt;&lt;/strong&gt; for build instructions, testing, and contribution workflow.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If experiencing issues, describe the problem to Claude and the troubleshoot skill will automatically diagnose and provide fixes.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/troubleshooting"&gt;Troubleshooting Guide&lt;/a&gt;&lt;/strong&gt; for common issues and solutions.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Bug Reports&lt;/h2&gt; 
&lt;p&gt;Create comprehensive bug reports with the automated generator:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ~/.claude/plugins/marketplaces/thedotmack
npm run bug-report
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Make your changes with tests&lt;/li&gt; 
 &lt;li&gt;Update documentation&lt;/li&gt; 
 &lt;li&gt;Submit a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/development"&gt;Development Guide&lt;/a&gt; for contribution workflow.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;strong&gt;GNU Affero General Public License v3.0&lt;/strong&gt; (AGPL-3.0).&lt;/p&gt; 
&lt;p&gt;Copyright (C) 2025 Alex Newman (@thedotmack). All rights reserved.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for full details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;What This Means:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can use, modify, and distribute this software freely&lt;/li&gt; 
 &lt;li&gt;If you modify and deploy on a network server, you must make your source code available&lt;/li&gt; 
 &lt;li&gt;Derivative works must also be licensed under AGPL-3.0&lt;/li&gt; 
 &lt;li&gt;There is NO WARRANTY for this software&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note on Ragtime&lt;/strong&gt;: The &lt;code&gt;ragtime/&lt;/code&gt; directory is licensed separately under the &lt;strong&gt;PolyForm Noncommercial License 1.0.0&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/ragtime/LICENSE"&gt;ragtime/LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/"&gt;docs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/thedotmack/claude-mem/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repository&lt;/strong&gt;: &lt;a href="https://github.com/thedotmack/claude-mem"&gt;github.com/thedotmack/claude-mem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Author&lt;/strong&gt;: Alex Newman (&lt;a href="https://github.com/thedotmack"&gt;@thedotmack&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Built with Claude Agent SDK&lt;/strong&gt; | &lt;strong&gt;Powered by Claude Code&lt;/strong&gt; | &lt;strong&gt;Made with TypeScript&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>exo-explore/exo</title>
      <link>https://github.com/exo-explore/exo</link>
      <description>&lt;p&gt;Run your own AI cluster at home with everyday devices üì±üíª üñ•Ô∏è‚åö&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/imgs/exo-logo-black-bg.jpg" /&gt; 
  &lt;img alt="exo logo" src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/imgs/exo-logo-transparent.png" width="50%" height="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;exo: Run your own AI cluster at home with everyday devices. Maintained by &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://discord.gg/72NsF6ux" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/exolabs" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/exolabs?style=social" alt="X" /&gt;&lt;/a&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0.html" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/License-Apache2.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;exo connects all your devices into an AI cluster. Not only does exo enable running models larger than would fit on a single device, but with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt&lt;/a&gt;, makes models run faster as you add more devices.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Device Discovery&lt;/strong&gt;: Devices running exo automatically discover each other - no manual configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RDMA over Thunderbolt&lt;/strong&gt;: exo ships with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt 5&lt;/a&gt;, enabling 99% reduction in latency between devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Topology-Aware Auto Parallel&lt;/strong&gt;: exo figures out the best way to split your model across all available devices based on a realtime view of your device topology. It takes into account device resources and network latency/bandwidth between each link.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;: exo supports sharding models, for up to 1.8x speedup on 2 devices and 3.2x speedup on 4 devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MLX Support&lt;/strong&gt;: exo uses &lt;a href="https://github.com/ml-explore/mlx"&gt;MLX&lt;/a&gt; as an inference backend and &lt;a href="https://ml-explore.github.io/mlx/build/html/usage/distributed.html"&gt;MLX distributed&lt;/a&gt; for distributed communication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qwen3-235B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-1-qwen3-235b.jpeg" alt="Benchmark - Qwen3-235B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;DeepSeek v3.1 671B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-2-deepseek-3.1-671b.jpeg" alt="Benchmark - DeepSeek v3.1 671B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Kimi K2 Thinking (native 4-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-3-kimi-k2-thinking.jpeg" alt="Benchmark - Kimi K2 Thinking (native 4-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Devices running exo automatically discover each other, without needing any manual configuration. Each device provides an API and a dashboard for interacting with your cluster (runs at &lt;code&gt;http://localhost:52415&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;There are two ways to run exo:&lt;/p&gt; 
&lt;h3&gt;Run from Source (macOS)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Homebrew/brew"&gt;brew&lt;/a&gt; (for simple package management on macOS)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (for Python dependency management)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/vladkens/macmon"&gt;macmon&lt;/a&gt; (for hardware monitoring on Apple Silicon)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/nodejs/node"&gt;node&lt;/a&gt; (for building the dashboard)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;brew install uv macmon node
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/rust-lang/rustup"&gt;rust&lt;/a&gt; (to build Rust bindings, nightly for now)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Clone the repo, build the dashboard, and run exo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone exo
git clone https://github.com/exo-explore/exo

# Build dashboard
cd exo/dashboard &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; cd ..

# Run exo
uv run exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the exo dashboard and API at &lt;a href="http://localhost:52415/"&gt;http://localhost:52415/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Run from Source (Linux)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (for Python dependency management)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nodejs/node"&gt;node&lt;/a&gt; (for building the dashboard) - version 18 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rust-lang/rustup"&gt;rust&lt;/a&gt; (to build Rust bindings, nightly for now)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Installation methods:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Using system package manager (Ubuntu/Debian example):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Node.js and npm
sudo apt update
sudo apt install nodejs npm

# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install Rust (using rustup)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Using Homebrew on Linux (if preferred):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Homebrew on Linux
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install dependencies
brew install uv node

# Install Rust (using rustup)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The &lt;code&gt;macmon&lt;/code&gt; package is macOS-only and not required for Linux.&lt;/p&gt; 
&lt;p&gt;Clone the repo, build the dashboard, and run exo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone exo
git clone https://github.com/exo-explore/exo

# Build dashboard
cd exo/dashboard &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; cd ..

# Run exo
uv run exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the exo dashboard and API at &lt;a href="http://localhost:52415/"&gt;http://localhost:52415/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important note for Linux users:&lt;/strong&gt; Currently, exo runs on CPU on Linux. GPU support for Linux platforms is under development. If you'd like to see support for your specific Linux hardware, please &lt;a href="https://github.com/exo-explore/exo/issues"&gt;search for existing feature requests&lt;/a&gt; or create a new one.&lt;/p&gt; 
&lt;h3&gt;macOS App&lt;/h3&gt; 
&lt;p&gt;exo ships a macOS app that runs in the background on your Mac.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/imgs/macos-app-one-macbook.png" alt="exo macOS App - running on a MacBook" width="35%" /&gt; 
&lt;p&gt;The macOS app requires macOS Tahoe 26.2 or later.&lt;/p&gt; 
&lt;p&gt;Download the latest build here: &lt;a href="https://assets.exolabs.net/EXO-latest.dmg"&gt;EXO-latest.dmg&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The app will ask for permission to modify system settings and install a new Network profile. Improvements to this are being worked on.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Enabling RDMA on macOS&lt;/h3&gt; 
&lt;p&gt;RDMA is a new capability added to macOS 26.2. It works on any Mac with Thunderbolt 5 (M4 Pro Mac Mini, M4 Max Mac Studio, M4 Max MacBook Pro, M3 Ultra Mac Studio).&lt;/p&gt; 
&lt;p&gt;Note that on Mac Studio, you cannot use the Thunderbolt 5 port next to the Ethernet port.&lt;/p&gt; 
&lt;p&gt;To enable RDMA on macOS, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Shut down your Mac.&lt;/li&gt; 
 &lt;li&gt;Hold down the power button for 10 seconds until the boot menu appears.&lt;/li&gt; 
 &lt;li&gt;Select "Options" to enter Recovery mode.&lt;/li&gt; 
 &lt;li&gt;When the Recovery UI appears, open the Terminal from the Utilities menu.&lt;/li&gt; 
 &lt;li&gt;In the Terminal, type: &lt;pre&gt;&lt;code&gt;rdma_ctl enable
&lt;/code&gt;&lt;/pre&gt; and press Enter.&lt;/li&gt; 
 &lt;li&gt;Reboot your Mac.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;After that, RDMA will be enabled in macOS and exo will take care of the rest.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Using the API&lt;/h3&gt; 
&lt;p&gt;If you prefer to interact with exo via the API, here is an example creating an instance of a small model (&lt;code&gt;mlx-community/Llama-3.2-1B-Instruct-4bit&lt;/code&gt;), sending a chat completions request and deleting the instance.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;1. Preview instance placements&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;/instance/previews&lt;/code&gt; endpoint will preview all valid placements for your model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "previews": [
    {
      "model_id": "mlx-community/Llama-3.2-1B-Instruct-4bit",
      "sharding": "Pipeline",
      "instance_meta": "MlxRing",
      "instance": {...},
      "memory_delta_by_node": {"local": 729808896},
      "error": null
    }
    // ...possibly more placements...
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will return all valid placements for this model. Pick a placement that you like. To pick the first one, pipe into &lt;code&gt;jq&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b" | jq -c '.previews[] | select(.error == null) | .instance' | head -n1
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;2. Create a model instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Send a POST to &lt;code&gt;/instance&lt;/code&gt; with your desired placement in the &lt;code&gt;instance&lt;/code&gt; field (the full payload must match types as in &lt;code&gt;CreateInstanceParams&lt;/code&gt;), which you can copy from step 1:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:52415/instance \
  -H 'Content-Type: application/json' \
  -d '{
    "instance": {...}
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "message": "Command received.",
  "command_id": "e9d1a8ab-...."
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;3. Send a chat completion&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Now, make a POST to &lt;code&gt;/v1/chat/completions&lt;/code&gt; (the same format as OpenAI's API):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -N -X POST http://localhost:52415/v1/chat/completions \
  -H 'Content-Type: application/json' \
  -d '{
    "model": "mlx-community/Llama-3.2-1B-Instruct-4bit",
    "messages": [
      {"role": "user", "content": "What is Llama 3.2 1B?"}
    ],
    "stream": true
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;4. Delete the instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;When you're done, delete the instance by its ID (find it via &lt;code&gt;/state&lt;/code&gt; or &lt;code&gt;/instance&lt;/code&gt; endpoints):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X DELETE http://localhost:52415/instance/YOUR_INSTANCE_ID
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;&lt;em&gt;Other useful API endpoints&lt;/em&gt;:&lt;/em&gt;*&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;List all models: &lt;code&gt;curl http://localhost:52415/models&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Inspect instance IDs and deployment state: &lt;code&gt;curl http://localhost:52415/state&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For further details, see API types and endpoints in &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/src/exo/master/api.py"&gt;src/exo/master/api.py&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Hardware Accelerator Support&lt;/h2&gt; 
&lt;p&gt;On macOS, exo uses the GPU. On Linux, exo currently runs on CPU. We are working on extending hardware accelerator support. If you'd like support for a new hardware platform, please &lt;a href="https://github.com/exo-explore/exo/issues"&gt;search for an existing feature request&lt;/a&gt; and add a thumbs up so we know what hardware is important to the community.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidelines on how to contribute to exo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-code</title>
      <link>https://github.com/anthropics/claude-code</link>
      <description>&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square" alt="" /&gt; &lt;a href="https://www.npmjs.com/package/@anthropic-ai/claude-code"&gt;&lt;img src="https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square" alt="npm" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn more in the &lt;a href="https://docs.anthropic.com/en/docs/claude-code/overview"&gt;official documentation&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/anthropics/claude-code/main/demo.gif" /&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Claude Code:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;MacOS/Linux:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://claude.ai/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Homebrew (MacOS):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install --cask claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://claude.ai/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NPM:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g @anthropic-ai/claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: If installing with NPM, you also need to install &lt;a href="https://nodejs.org/en/download/"&gt;Node.js 18+&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Navigate to your project directory and run &lt;code&gt;claude&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;This repository includes several Claude Code plugins that extend functionality with custom commands and agents. See the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-code/main/plugins/README.md"&gt;plugins directory&lt;/a&gt; for detailed documentation on available plugins.&lt;/p&gt; 
&lt;h2&gt;Reporting Bugs&lt;/h2&gt; 
&lt;p&gt;We welcome your feedback. Use the &lt;code&gt;/bug&lt;/code&gt; command to report issues directly within Claude Code, or file a &lt;a href="https://github.com/anthropics/claude-code/issues"&gt;GitHub issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Connect on Discord&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://anthropic.com/discord"&gt;Claude Developers Discord&lt;/a&gt; to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.&lt;/p&gt; 
&lt;h2&gt;Data collection, usage, and retention&lt;/h2&gt; 
&lt;p&gt;When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the &lt;code&gt;/bug&lt;/code&gt; command.&lt;/p&gt; 
&lt;h3&gt;How we use your data&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://docs.anthropic.com/en/docs/claude-code/data-usage"&gt;data usage policies&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Privacy safeguards&lt;/h3&gt; 
&lt;p&gt;We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.&lt;/p&gt; 
&lt;p&gt;For full details, please review our &lt;a href="https://www.anthropic.com/legal/commercial-terms"&gt;Commercial Terms of Service&lt;/a&gt; and &lt;a href="https://www.anthropic.com/legal/privacy"&gt;Privacy Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;a href="https://trendshift.io/repositories/15289" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15289" alt="Tencent%2FWeKnora | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.6-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;üîå &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;‚úÖ ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;‚úÖ FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;‚úÖ Extensible search engines, DuckDuckGo&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/api/README.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;‚ö° Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;‚úÖ No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;‚úÖ Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;üìà Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-quickstarts</title>
      <link>https://github.com/anthropics/claude-quickstarts</link>
      <description>&lt;p&gt;A collection of projects designed to help developers quickly get started with building deployable applications using the Claude API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Quickstarts&lt;/h1&gt; 
&lt;p&gt;Claude Quickstarts is a collection of projects designed to help developers quickly get started with building applications using the Claude API. Each quickstart provides a foundation that you can easily build upon and customize for your specific needs.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To use these quickstarts, you'll need an Claude API key. If you don't have one yet, you can sign up for free at &lt;a href="https://console.anthropic.com"&gt;console.anthropic.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Available Quickstarts&lt;/h2&gt; 
&lt;h3&gt;Customer Support Agent&lt;/h3&gt; 
&lt;p&gt;A customer support agent powered by Claude. This project demonstrates how to leverage Claude's natural language understanding and generation capabilities to create an AI-assisted customer support system with access to a knowledge base.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/customer-support-agent"&gt;Go to Customer Support Agent Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Financial Data Analyst&lt;/h3&gt; 
&lt;p&gt;A financial data analyst powered by Claude. This project demonstrates how to leverage Claude's capabilities with interactive data visualization to analyze financial data via chat.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/financial-data-analyst"&gt;Go to Financial Data Analyst Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Computer Use Demo&lt;/h3&gt; 
&lt;p&gt;An environment and tools that Claude can use to control a desktop computer. This project demonstrates how to leverage the computer use capabilities of Claude, including support for the latest &lt;code&gt;computer_use_20251124&lt;/code&gt; tool version with zoom actions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/computer-use-demo"&gt;Go to Computer Use Demo Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Browser Tools API Demo&lt;/h3&gt; 
&lt;p&gt;A complete reference implementation for browser automation powered by Claude. This project demonstrates how to leverage Claude's browser tools API for web interaction, including navigation, DOM inspection, and form manipulation using Playwright.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/browser-tools-api-demo"&gt;Go to Browser Tools API Demo Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Autonomous Coding Agent&lt;/h3&gt; 
&lt;p&gt;An autonomous coding agent powered by the Claude Agent SDK. This project demonstrates a two-agent pattern (initializer + coding agent) that can build complete applications over multiple sessions, with progress persisted via git and a feature list that the agent works through incrementally.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/autonomous-coding"&gt;Go to Autonomous Coding Agent Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;General Usage&lt;/h2&gt; 
&lt;p&gt;Each quickstart project comes with its own README and setup instructions. Generally, you'll follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repository&lt;/li&gt; 
 &lt;li&gt;Navigate to the specific quickstart directory&lt;/li&gt; 
 &lt;li&gt;Install the required dependencies&lt;/li&gt; 
 &lt;li&gt;Set up your Claude API key as an environment variable&lt;/li&gt; 
 &lt;li&gt;Run the quickstart application&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;p&gt;To deepen your understanding of working with Claude and the Claude API, check out these resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.claude.com"&gt;Claude API Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/claude-cookbooks"&gt;Claude Cookbooks&lt;/a&gt; - A collection of code snippets and guides for common tasks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/courses/tree/master/anthropic_api_fundamentals"&gt;Claude API Fundamentals Course&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the Claude Quickstarts repository! If you have ideas for new quickstart projects or improvements to existing ones, please open an issue or submit a pull request.&lt;/p&gt; 
&lt;h2&gt;Community and Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join our &lt;a href="https://www.anthropic.com/discord"&gt;Anthropic Discord community&lt;/a&gt; for discussions and support&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://support.anthropic.com"&gt;Anthropic support documentation&lt;/a&gt; for additional help&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>agentsmd/agents.md</title>
      <link>https://github.com/agentsmd/agents.md</link>
      <description>&lt;p&gt;AGENTS.md ‚Äî a simple, open format for guiding coding agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AGENTS.md&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/agentsmd/agents.md/main/public/og.png" alt="AGENTS.md logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://agents.md"&gt;AGENTS.md&lt;/a&gt; is a simple, open format for guiding coding agents.&lt;/p&gt; 
&lt;p&gt;Think of AGENTS.md as a README for agents: a dedicated, predictable place to provide context and instructions to help AI coding agents work on your project.&lt;/p&gt; 
&lt;p&gt;Below is a minimal example of an AGENTS.md file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;# Sample AGENTS.md file

## Dev environment tips
- Use `pnpm dlx turbo run where &amp;lt;project_name&amp;gt;` to jump to a package instead of scanning with `ls`.
- Run `pnpm install --filter &amp;lt;project_name&amp;gt;` to add the package to your workspace so Vite, ESLint, and TypeScript can see it.
- Use `pnpm create vite@latest &amp;lt;project_name&amp;gt; -- --template react-ts` to spin up a new React + Vite package with TypeScript checks ready.
- Check the name field inside each package's package.json to confirm the right name‚Äîskip the top-level one.

## Testing instructions
- Find the CI plan in the .github/workflows folder.
- Run `pnpm turbo run test --filter &amp;lt;project_name&amp;gt;` to run every check defined for that package.
- From the package root you can just call `pnpm test`. The commit should pass all tests before you merge.
- To focus on one step, add the Vitest pattern: `pnpm vitest run -t "&amp;lt;test name&amp;gt;"`.
- Fix any test or type errors until the whole suite is green.
- After moving files or changing imports, run `pnpm lint --filter &amp;lt;project_name&amp;gt;` to be sure ESLint and TypeScript rules still pass.
- Add or update tests for the code you change, even if nobody asked.

## PR instructions
- Title format: [&amp;lt;project_name&amp;gt;] &amp;lt;Title&amp;gt;
- Always run `pnpm lint` and `pnpm test` before committing.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Website&lt;/h2&gt; 
&lt;p&gt;This repository also includes a basic Next.js website hosted at &lt;a href="https://agents.md/"&gt;https://agents.md/&lt;/a&gt; that explains the project‚Äôs goals in a simple way, and featuring some examples.&lt;/p&gt; 
&lt;h3&gt;Running the app locally&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install dependencies: &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Start the development server: &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm run dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Open your browser and go to &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>cocoindex-io/cocoindex</title>
      <link>https://github.com/cocoindex-io/cocoindex</link>
      <description>&lt;p&gt;Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/github.svg?sanitize=true" alt="CocoIndex" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Data transformation for AI&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;&lt;img src="https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;amp;logoColor=00B9FF" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/cocoindex/"&gt;&lt;img src="https://img.shields.io/pypi/v/cocoindex?color=5B5BD6" alt="PyPI version" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) --&gt; 
 &lt;p&gt;&lt;a href="https://pepy.tech/projects/cocoindex"&gt;&lt;img src="https://static.pepy.tech/badge/cocoindex/month" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml/badge.svg?sanitize=true" alt="Link Check" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;&lt;img src="https://img.shields.io/discord/1314801574169673738?logo=discord&amp;amp;color=5B5BD6&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13939" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13939" alt="cocoindex-io%2Fcocoindex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box. Exceptional developer velocity. Production-ready at day 0.&lt;/p&gt; 
&lt;p&gt;‚≠ê Drop a star to help us grow!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
 &lt;p&gt;&lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=en"&gt;English&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/transformation.svg?sanitize=true" alt="CocoIndex Transformation" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;CocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether you‚Äôre building a vector index, creating knowledge graphs for context engineering or performing any custom data transformations ‚Äî goes beyond SQL.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img alt="CocoIndex Features" src="https://cocoindex.io/images/venn2.svg?sanitize=true" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Exceptional velocity&lt;/h2&gt; 
&lt;p&gt;Just declare transformation in dataflow with ~100 lines of python&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# import
data['content'] = flow_builder.add_source(...)

# transform
data['out'] = data['content']
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CocoIndex follows the idea of &lt;a href="https://en.wikipedia.org/wiki/Dataflow_programming"&gt;Dataflow&lt;/a&gt; programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Particularly&lt;/strong&gt;, developers don't explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.&lt;/p&gt; 
&lt;h2&gt;Plug-and-Play Building Blocks&lt;/h2&gt; 
&lt;p&gt;Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/components.svg?sanitize=true" alt="CocoIndex Features" /&gt; &lt;/p&gt; 
&lt;h2&gt;Data Freshness&lt;/h2&gt; 
&lt;p&gt;CocoIndex keep source data and target in sync effortlessly.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6" alt="Incremental Processing" width="700" /&gt; &lt;/p&gt; 
&lt;p&gt;It has out-of-box support for incremental indexing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;minimal recomputation on source or logic change.&lt;/li&gt; 
 &lt;li&gt;(re-)processing necessary portions; reuse cache when possible&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;If you're new to CocoIndex, we recommend checking out&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;a href="https://cocoindex.io/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üé¨ &lt;a href="https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT"&gt;Quick Start Video Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install CocoIndex Python library&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install -U cocoindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://cocoindex.io/docs/getting_started/installation#-install-postgres"&gt;Install Postgres&lt;/a&gt; if you don't have one. CocoIndex uses it for incremental processing.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) Install Claude Code skill for enhanced development experience. Run these commands in &lt;a href="https://claude.com/claude-code"&gt;Claude Code&lt;/a&gt;:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;/plugin marketplace add cocoindex-io/cocoindex-claude
/plugin install cocoindex-skills@cocoindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Define data flow&lt;/h2&gt; 
&lt;p&gt;Follow &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt; to define your first indexing flow. An example flow looks like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@cocoindex.flow_def(name="TextEmbedding")
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope["documents"] = flow_builder.add_source(cocoindex.sources.LocalFile(path="markdown_files"))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope["documents"].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc["chunks"] = doc["content"].transform(
            cocoindex.functions.SplitRecursively(),
            language="markdown", chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc["chunks"].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk["embedding"] = chunk["text"].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model="sentence-transformers/all-MiniLM-L6-v2"))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc["filename"], location=chunk["location"],
                                   text=chunk["text"], embedding=chunk["embedding"])

    # Export collected data to a vector index.
    doc_embeddings.export(
        "doc_embeddings",
        cocoindex.targets.Postgres(),
        primary_key_fields=["filename", "location"],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name="embedding",
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It defines an index flow like this:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="400" alt="Data Flow" src="https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463" /&gt; &lt;/p&gt; 
&lt;h2&gt;üöÄ Examples and demo&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding"&gt;Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents with embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/code_embedding"&gt;Code Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index code embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/pdf_embedding"&gt;PDF Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Parse PDF and index text embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/pdf_elements_embedding"&gt;PDF Elements Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/manuals_llm_extraction"&gt;Manuals LLM Extraction&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured information from a manual using LLM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/amazon_s3_embedding"&gt;Amazon S3 Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Amazon S3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/azure_blob_embedding"&gt;Azure Blob Storage Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Azure Blob Storage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/gdrive_text_embedding"&gt;Google Drive Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Google Drive&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/meeting_notes_graph"&gt;Meeting Notes to Knowledge Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured meeting info from Google Drive and build a knowledge graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/docs_to_knowledge_graph"&gt;Docs to Knowledge Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract relationships from Markdown documents and build a knowledge graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding_qdrant"&gt;Embeddings to Qdrant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index documents in a Qdrant collection for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding_lancedb"&gt;Embeddings to LanceDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index documents in a LanceDB collection for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/fastapi_server_docker"&gt;FastAPI Server with Docker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Run the semantic search server in a Dockerized FastAPI setup&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/product_recommendation"&gt;Product Recommendation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build real-time product recommendations with LLM and graph database&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/image_search"&gt;Image Search with Vision API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/face_recognition"&gt;Face Recognition&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Recognize faces in images and build embedding index&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/paper_metadata"&gt;Paper Metadata&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index papers in PDF files, and build metadata tables for each paper&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/multi_format_indexing"&gt;Multi Format Indexing&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build visual document index from PDFs and images with ColPali for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/custom_source_hn"&gt;Custom Source HackerNews&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index HackerNews threads and comments, using &lt;em&gt;CocoIndex Custom Source&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/custom_output_files"&gt;Custom Output Files&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Convert markdown files to HTML files and save them to a local directory, using &lt;em&gt;CocoIndex Custom Targets&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/patient_intake_extraction"&gt;Patient intake form extraction&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Use LLM to extract structured data from patient intake forms with different formats&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/hn_trending_topics"&gt;HackerNews Trending Topics&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract trending topics from HackerNews threads and comments, using &lt;em&gt;CocoIndex Custom Source&lt;/em&gt; and LLM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/patient_intake_extraction_baml"&gt;Patient Intake Form Extraction with BAML&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured data from patient intake forms using BAML&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/patient_intake_extraction_dspy"&gt;Patient Intake Form Extraction with DSPy&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured data from patient intake forms using DSPy&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More coming and stay tuned üëÄ!&lt;/p&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, visit &lt;a href="https://cocoindex.io/docs"&gt;CocoIndex Documentation&lt;/a&gt;, including a &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quickstart guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our &lt;a href="https://cocoindex.io/docs/about/contributing"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üë• Community&lt;/h2&gt; 
&lt;p&gt;Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it's code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.&lt;/p&gt; 
&lt;p&gt;Join our community here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üåü &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;Star us on GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üëã &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;Join our Discord community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ñ∂Ô∏è &lt;a href="https://www.youtube.com/@cocoindex-io"&gt;Subscribe to our YouTube channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://cocoindex.io/blogs/"&gt;Read our blog posts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support us&lt;/h2&gt; 
&lt;p&gt;We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub" /&gt;&lt;/a&gt; to stay tuned and help us grow.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;CocoIndex is Apache 2.0 licensed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>datawhalechina/hello-agents</title>
      <link>https://github.com/datawhalechina/hello-agents</link>
      <description>&lt;p&gt;üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã&lt;/p&gt;&lt;hr&gt;&lt;div align="right"&gt; 
 &lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/README_EN.md"&gt;English&lt;/a&gt; | ‰∏≠Êñá 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/hello-agents.png" alt="alt text" width="100%" /&gt; 
 &lt;h1&gt;Hello-Agents&lt;/h1&gt; 
 &lt;h3&gt;ü§ñ „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/15520" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15520" alt="datawhalechina%2Fhello-agents | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;em&gt;‰ªéÂü∫Á°ÄÁêÜËÆ∫Âà∞ÂÆûÈôÖÂ∫îÁî®ÔºåÂÖ®Èù¢ÊéåÊè°Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂÆûÁé∞&lt;/em&gt;&lt;/p&gt; 
 &lt;img src="https://img.shields.io/github/stars/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub stars" /&gt; 
 &lt;img src="https://img.shields.io/github/forks/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub forks" /&gt; 
 &lt;img src="https://img.shields.io/badge/language-Chinese-brightgreen?style=flat" alt="Language" /&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents"&gt;&lt;img src="https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;amp;logo=github" alt="GitHub Project" /&gt;&lt;/a&gt; 
 &lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;&lt;img src="https://img.shields.io/badge/Âú®Á∫øÈòÖËØª-Online%20Reading-green?style=flat&amp;amp;logo=gitbook" alt="Online Reading" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ È°πÁõÆ‰ªãÁªç&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÂ¶ÇÊûúËØ¥ 2024 Âπ¥ÊòØ"ÁôæÊ®°Â§ßÊàò"ÁöÑÂÖÉÂπ¥ÔºåÈÇ£‰πà 2025 Âπ¥Êó†ÁñëÂºÄÂêØ‰∫Ü"Agent ÂÖÉÂπ¥"„ÄÇÊäÄÊúØÁöÑÁÑ¶ÁÇπÊ≠£‰ªéËÆ≠ÁªÉÊõ¥Â§ßÁöÑÂü∫Á°ÄÊ®°ÂûãÔºåËΩ¨ÂêëÊûÑÂª∫Êõ¥ËÅ™ÊòéÁöÑÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁ≥ªÁªüÊÄß„ÄÅÈáçÂÆûË∑µÁöÑÊïôÁ®ãÂç¥ÊûÅÂ∫¶ÂåÆ‰πè„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂèëËµ∑‰∫Ü Hello-Agents È°πÁõÆÔºåÂ∏åÊúõËÉΩ‰∏∫Á§æÂå∫Êèê‰æõ‰∏ÄÊú¨‰ªéÈõ∂ÂºÄÂßã„ÄÅÁêÜËÆ∫‰∏éÂÆûÊàòÂπ∂ÈáçÁöÑÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÊûÑÂª∫ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉHello-Agents ÊòØ Datawhale Á§æÂå∫ÁöÑ&lt;strong&gt;Á≥ªÁªüÊÄßÊô∫ËÉΩ‰ΩìÂ≠¶‰π†ÊïôÁ®ã&lt;/strong&gt;„ÄÇÂ¶Ç‰ªä Agent ÊûÑÂª∫‰∏ªË¶ÅÂàÜ‰∏∫‰∏§Ê¥æÔºå‰∏ÄÊ¥æÊòØ DifyÔºåCozeÔºån8n ËøôÁ±ªËΩØ‰ª∂Â∑•Á®ãÁ±ª AgentÔºåÂÖ∂Êú¨Ë¥®ÊòØÊµÅÁ®ãÈ©±Âä®ÁöÑËΩØ‰ª∂ÂºÄÂèëÔºåLLM ‰Ωú‰∏∫Êï∞ÊçÆÂ§ÑÁêÜÁöÑÂêéÁ´ØÔºõÂè¶‰∏ÄÊ¥æÂàôÊòØ AI ÂéüÁîüÁöÑ AgentÔºåÂç≥ÁúüÊ≠£‰ª• AI È©±Âä®ÁöÑ Agent„ÄÇÊú¨ÊïôÁ®ãÊó®Âú®Â∏¶È¢ÜÂ§ßÂÆ∂Ê∑±ÂÖ•ÁêÜËß£Âπ∂ÊûÑÂª∫ÂêéËÄÖ‚Äî‚ÄîÁúüÊ≠£ÁöÑ AI Native Agent„ÄÇÊïôÁ®ãÂ∞ÜÂ∏¶È¢Ü‰Ω†Á©øÈÄèÊ°ÜÊû∂Ë°®Ë±°Ôºå‰ªéÊô∫ËÉΩ‰ΩìÁöÑÊ†∏ÂøÉÂéüÁêÜÂá∫ÂèëÔºåÊ∑±ÂÖ•ÂÖ∂Ê†∏ÂøÉÊû∂ÊûÑÔºåÁêÜËß£ÂÖ∂ÁªèÂÖ∏ËåÉÂºèÔºåÂπ∂ÊúÄÁªà‰∫≤ÊâãÊûÑÂª∫Ëµ∑Â±û‰∫éËá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÊàë‰ª¨Áõ∏‰ø°ÔºåÊúÄÂ•ΩÁöÑÂ≠¶‰π†ÊñπÂºèÂ∞±ÊòØÂä®ÊâãÂÆûË∑µ„ÄÇÂ∏åÊúõËøôÊú¨ÊïôÁ®ãËÉΩÊàê‰∏∫‰Ω†Êé¢Á¥¢Êô∫ËÉΩ‰Ωì‰∏ñÁïåÁöÑËµ∑ÁÇπÔºåËÉΩÂ§ü‰ªé‰∏ÄÂêçÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ"‰ΩøÁî®ËÄÖ"ÔºåËúïÂèò‰∏∫‰∏ÄÂêçÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑ"ÊûÑÂª∫ËÄÖ"„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üìö Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;h3&gt;Âú®Á∫øÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;üåê ÁÇπÂáªËøôÈáåÂºÄÂßãÂú®Á∫øÈòÖËØª&lt;/a&gt;&lt;/strong&gt; - Êó†ÈúÄ‰∏ãËΩΩÔºåÈöèÊó∂ÈöèÂú∞Â≠¶‰π†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://book.heterocat.com.cn/"&gt;üìñ Cookbook(ÊµãËØïÁâà)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Êú¨Âú∞ÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®Êú¨Âú∞ÈòÖËØªÊàñË¥°ÁåÆÂÜÖÂÆπÔºåËØ∑ÂèÇËÄÉ‰∏ãÊñπÁöÑÂ≠¶‰π†ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;h3&gt;‚ú® ‰Ω†Â∞ÜÊî∂Ëé∑‰ªÄ‰πàÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Datawhale ÂºÄÊ∫êÂÖçË¥π&lt;/strong&gt; ÂÆåÂÖ®ÂÖçË¥πÂ≠¶‰π†Êú¨È°πÁõÆÊâÄÊúâÂÜÖÂÆπÔºå‰∏éÁ§æÂå∫ÂÖ±ÂêåÊàêÈïø&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;ÁêÜËß£Ê†∏ÂøÉÂéüÁêÜ&lt;/strong&gt; Ê∑±ÂÖ•ÁêÜËß£Êô∫ËÉΩ‰ΩìÁöÑÊ¶ÇÂøµ„ÄÅÂéÜÂè≤‰∏éÁªèÂÖ∏ËåÉÂºè&lt;/li&gt; 
 &lt;li&gt;üèóÔ∏è &lt;strong&gt;‰∫≤ÊâãÂÆûÁé∞&lt;/strong&gt; ÊéåÊè°ÁÉ≠Èó®‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÂíåÊô∫ËÉΩ‰Ωì‰ª£Á†ÅÊ°ÜÊû∂ÁöÑ‰ΩøÁî®&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;strong&gt;Ëá™Á†îÊ°ÜÊû∂&lt;a href="https://github.com/jjyaoao/helloagents"&gt;HelloAgents&lt;/a&gt;&lt;/strong&gt; Âü∫‰∫é Openai ÂéüÁîü API ‰ªéÈõ∂ÊûÑÂª∫‰∏Ä‰∏™Ëá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;ÊéåÊè°È´òÁ∫ßÊäÄËÉΩ&lt;/strong&gt; ‰∏ÄÊ≠•Ê≠•ÂÆûÁé∞‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅMemory„ÄÅÂçèËÆÆ„ÄÅËØÑ‰º∞Á≠âÁ≥ªÁªüÊÄßÊäÄÊúØ&lt;/li&gt; 
 &lt;li&gt;ü§ù &lt;strong&gt;Ê®°ÂûãËÆ≠ÁªÉ&lt;/strong&gt; ÊéåÊè° Agentic RLÔºå‰ªé SFT Âà∞ GRPO ÁöÑÂÖ®ÊµÅÁ®ãÂÆûÊàòËÆ≠ÁªÉ LLM&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;È©±Âä®ÁúüÂÆûÊ°à‰æã&lt;/strong&gt; ÂÆûÊàòÂºÄÂèëÊô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËµõÂçöÂ∞èÈïáÁ≠âÁªºÂêàÈ°πÁõÆ&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Ê±ÇËÅåÈù¢ËØï&lt;/strong&gt; Â≠¶‰π†Êô∫ËÉΩ‰ΩìÊ±ÇËÅåÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ ÂÜÖÂÆπÂØºËà™&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á´†ËäÇ&lt;/th&gt; 
   &lt;th&gt;ÂÖ≥ÈîÆÂÜÖÂÆπ&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/%E5%89%8D%E8%A8%80.md"&gt;ÂâçË®Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;È°πÁõÆÁöÑÁºòËµ∑„ÄÅËÉåÊôØÂèäËØªËÄÖÂª∫ËÆÆ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%88%9D%E8%AF%86%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨‰∏ÄÁ´† ÂàùËØÜÊô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Êô∫ËÉΩ‰ΩìÂÆö‰πâ„ÄÅÁ±ªÂûã„ÄÅËåÉÂºè‰∏éÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter2/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E5%8F%91%E5%B1%95%E5%8F%B2.md"&gt;Á¨¨‰∫åÁ´† Êô∫ËÉΩ‰ΩìÂèëÂ±ïÂè≤&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªéÁ¨¶Âè∑‰∏ª‰πâÂà∞ LLM È©±Âä®ÁöÑÊô∫ËÉΩ‰ΩìÊºîËøõ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter3/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md"&gt;Á¨¨‰∏âÁ´† Â§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Transformer„ÄÅÊèêÁ§∫„ÄÅ‰∏ªÊµÅ LLM ÂèäÂÖ∂Â±ÄÈôê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA.md"&gt;Á¨¨ÂõõÁ´† Êô∫ËÉΩ‰ΩìÁªèÂÖ∏ËåÉÂºèÊûÑÂª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊâãÊääÊâãÂÆûÁé∞ ReAct„ÄÅPlan-and-Solve„ÄÅReflection&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter5/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%9F%BA%E4%BA%8E%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E6%90%AD%E5%BB%BA.md"&gt;Á¨¨‰∫îÁ´† Âü∫‰∫é‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÊê≠Âª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∫ÜËß£ Coze„ÄÅDify„ÄÅn8n Á≠â‰Ωé‰ª£Á†ÅÊô∫ËÉΩ‰ΩìÂπ≥Âè∞‰ΩøÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5.md"&gt;Á¨¨ÂÖ≠Á´† Ê°ÜÊû∂ÂºÄÂèëÂÆûË∑µ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AutoGen„ÄÅAgentScope„ÄÅLangGraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂Â∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter7/%E7%AC%AC%E4%B8%83%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84Agent%E6%A1%86%E6%9E%B6.md"&gt;Á¨¨‰∏ÉÁ´† ÊûÑÂª∫‰Ω†ÁöÑAgentÊ°ÜÊû∂&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé 0 ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter8/%E7%AC%AC%E5%85%AB%E7%AB%A0%20%E8%AE%B0%E5%BF%86%E4%B8%8E%E6%A3%80%E7%B4%A2.md"&gt;Á¨¨ÂÖ´Á´† ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ËÆ∞ÂøÜÁ≥ªÁªüÔºåRAGÔºåÂ≠òÂÇ®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter9/%E7%AC%AC%E4%B9%9D%E7%AB%A0%20%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B.md"&gt;Á¨¨‰πùÁ´† ‰∏ä‰∏ãÊñáÂ∑•Á®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊåÅÁª≠‰∫§‰∫íÁöÑ"ÊÉÖÂ¢ÉÁêÜËß£"&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter10/%E7%AC%AC%E5%8D%81%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE.md"&gt;Á¨¨ÂçÅÁ´† Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP„ÄÅA2A„ÄÅANP Á≠âÂçèËÆÆËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter11/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%20Agentic-RL.md"&gt;Á¨¨ÂçÅ‰∏ÄÁ´† Agentic-RL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé SFT Âà∞ GRPO ÁöÑ LLM ËÆ≠ÁªÉÂÆûÊàò&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter12/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0.md"&gt;Á¨¨ÂçÅ‰∫åÁ´† Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ê†∏ÂøÉÊåáÊ†á„ÄÅÂü∫ÂáÜÊµãËØï‰∏éËØÑ‰º∞Ê°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter13/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%20%E6%99%BA%E8%83%BD%E6%97%85%E8%A1%8C%E5%8A%A9%E6%89%8B.md"&gt;Á¨¨ÂçÅ‰∏âÁ´† Êô∫ËÉΩÊóÖË°åÂä©Êâã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP ‰∏éÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÁöÑÁúüÂÆû‰∏ñÁïåÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter14/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%20%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨ÂçÅÂõõÁ´† Ëá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DeepResearch Agent Â§çÁé∞‰∏éËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter15/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E8%B5%9B%E5%8D%9A%E5%B0%8F%E9%95%87.md"&gt;Á¨¨ÂçÅ‰∫îÁ´† ÊûÑÂª∫ËµõÂçöÂ∞èÈïá&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent ‰∏éÊ∏∏ÊàèÁöÑÁªìÂêàÔºåÊ®°ÊãüÁ§æ‰ºöÂä®ÊÄÅ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter16/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0%20%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1.md"&gt;Á¨¨ÂçÅÂÖ≠Á´† ÊØï‰∏öËÆæËÆ°&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊûÑÂª∫Â±û‰∫é‰Ω†ÁöÑÂÆåÊï¥Â§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ (Community Blog)&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢ËøéÂ§ßÂÆ∂Â∞ÜÂú®Â≠¶‰π† Hello-Agents Êàñ Agent Áõ∏ÂÖ≥ÊäÄÊúØ‰∏≠ÁöÑÁã¨Âà∞ËßÅËß£„ÄÅÂÆûË∑µÊÄªÁªìÔºå‰ª• PR ÁöÑÂΩ¢ÂºèË¥°ÁåÆÂà∞Á§æÂå∫Á≤æÈÄâ„ÄÇÂ¶ÇÊûúÊòØÁã¨Á´ã‰∫éÊ≠£ÊñáÁöÑÂÜÖÂÆπÔºå‰πüÂèØ‰ª•ÊäïÁ®øËá≥ Extra-ChapterÔºÅ&lt;strong&gt;ÊúüÂæÖ‰Ω†ÁöÑÁ¨¨‰∏ÄÊ¨°Ë¥°ÁåÆÔºÅ&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á§æÂå∫Á≤æÈÄâ&lt;/th&gt; 
   &lt;th&gt;ÂÜÖÂÆπÊÄªÁªì&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md"&gt;01-AgentÈù¢ËØïÈ¢òÊÄªÁªì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent Â≤ó‰ΩçÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88.md"&gt;01-AgentÈù¢ËØïÈ¢òÁ≠îÊ°à&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Áõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢òÁ≠îÊ°à&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra02-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86.md"&gt;02-‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπË°•ÂÖÖ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπÊâ©Â±ï&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra03-Dify%E6%99%BA%E8%83%BD%E4%BD%93%E5%88%9B%E5%BB%BA%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B.md"&gt;03-DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra04-DatawhaleFAQ.md"&gt;04-Hello-agentsËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DatawhaleËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra05-AgentSkills%E8%A7%A3%E8%AF%BB.md"&gt;05-Agent Skills‰∏éMCPÂØπÊØîËß£ËØª&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent Skills‰∏éMCPÊäÄÊúØÂØπÊØî&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra06-GUIAgent%E7%A7%91%E6%99%AE%E4%B8%8E%E5%AE%9E%E6%88%98.md"&gt;06-GUI AgentÁßëÊôÆ‰∏éÂÆûÊàò&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GUI AgentÁßëÊôÆ‰∏éÂ§öÂú∫ÊôØÂÆûÊàò&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;PDF ÁâàÊú¨‰∏ãËΩΩ&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉ&lt;em&gt;&lt;strong&gt;Êú¨ Hello-Agents PDF ÊïôÁ®ãÂÆåÂÖ®ÂºÄÊ∫êÂÖçË¥π„ÄÇ‰∏∫Èò≤Ê≠¢ÂêÑÁ±ªËê•ÈîÄÂè∑Âä†Ê∞¥Âç∞ÂêéË¥©ÂçñÁªôÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÂàùÂ≠¶ËÄÖÔºåÊàë‰ª¨ÁâπÂú∞Âú® PDF Êñá‰ª∂‰∏≠È¢ÑÂÖàÊ∑ªÂä†‰∫Ü‰∏çÂΩ±ÂìçÈòÖËØªÁöÑ Datawhale ÂºÄÊ∫êÊ†áÂøóÊ∞¥Âç∞ÔºåÊï¨ËØ∑Ë∞ÖËß£ÔΩû&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Hello-Agents PDF : &lt;a href="https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0"&gt;https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0&lt;/a&gt;&lt;/em&gt;&lt;br /&gt; &lt;em&gt;Hello-Agents PDF ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄ : &lt;a href="https://www.datawhale.cn/learn/summary/239"&gt;https://www.datawhale.cn/learn/summary/239&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üí° Â¶Ç‰ΩïÂ≠¶‰π†&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢Ëøé‰Ω†ÔºåÊú™Êù•ÁöÑÊô∫ËÉΩÁ≥ªÁªüÊûÑÂª∫ËÄÖÔºÅÂú®ÂºÄÂêØËøôÊÆµÊøÄÂä®‰∫∫ÂøÉÁöÑÊóÖÁ®ã‰πãÂâçÔºåËØ∑ÂÖÅËÆ∏Êàë‰ª¨Áªô‰Ω†‰∏Ä‰∫õÊ∏ÖÊô∞ÁöÑÊåáÂºï„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊú¨È°πÁõÆÂÜÖÂÆπÂÖºÈ°æÁêÜËÆ∫‰∏éÂÆûÊàòÔºåÊó®Âú®Â∏ÆÂä©‰Ω†Á≥ªÁªüÊÄßÂú∞ÊéåÊè°‰ªéÂçï‰∏™Êô∫ËÉΩ‰ΩìÂà∞Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂºÄÂèëÂÖ®ÊµÅÁ®ã„ÄÇÂõ†Ê≠§ÔºåÂ∞§ÂÖ∂ÈÄÇÂêàÊúâ‰∏ÄÂÆöÁºñÁ®ãÂü∫Á°ÄÁöÑ &lt;strong&gt;AI ÂºÄÂèëËÄÖ„ÄÅËΩØ‰ª∂Â∑•Á®ãÂ∏à„ÄÅÂú®Ê†°Â≠¶Áîü&lt;/strong&gt; ‰ª•ÂèäÂØπÂâçÊ≤ø AI ÊäÄÊúØÊä±ÊúâÊµìÂéöÂÖ¥Ë∂£ÁöÑ &lt;strong&gt;Ëá™Â≠¶ËÄÖ&lt;/strong&gt;„ÄÇÂú®Â≠¶‰π†Êú¨È°πÁõÆ‰πãÂâçÔºåÊàë‰ª¨Â∏åÊúõ‰Ω†ÂÖ∑Â§áÂü∫Á°ÄÁöÑ Python ÁºñÁ®ãËÉΩÂäõÔºåÂπ∂ÂØπÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúâÂü∫Êú¨ÁöÑÊ¶ÇÂøµÊÄß‰∫ÜËß£Ôºà‰æãÂ¶ÇÔºåÁü•ÈÅìÂ¶Ç‰ΩïÈÄöËøá API Ë∞ÉÁî®‰∏Ä‰∏™ LLMÔºâ„ÄÇÈ°πÁõÆÁöÑÈáçÁÇπÊòØÂ∫îÁî®‰∏éÊûÑÂª∫ÔºåÂõ†Ê≠§‰Ω†Êó†ÈúÄÂÖ∑Â§áÊ∑±ÂéöÁöÑÁÆóÊ≥ïÊàñÊ®°ÂûãËÆ≠ÁªÉËÉåÊôØ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÈ°πÁõÆÂàÜ‰∏∫‰∫îÂ§ßÈÉ®ÂàÜÔºåÊØè‰∏ÄÈÉ®ÂàÜÈÉΩÊòØÈÄöÂæÄ‰∏ã‰∏ÄÈò∂ÊÆµÁöÑÂùöÂÆûÈò∂Ê¢ØÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;ÔºàÁ¨¨‰∏ÄÁ´†ÔΩûÁ¨¨‰∏âÁ´†ÔºâÔºåÊàë‰ª¨Â∞Ü‰ªéÊô∫ËÉΩ‰ΩìÁöÑÂÆö‰πâ„ÄÅÁ±ªÂûã‰∏éÂèëÂ±ïÂéÜÂè≤ËÆ≤Ëµ∑Ôºå‰∏∫‰Ω†Ê¢≥ÁêÜ"Êô∫ËÉΩ‰Ωì"Ëøô‰∏ÄÊ¶ÇÂøµÁöÑÊù•ÈæôÂéªËÑâ„ÄÇÈöèÂêéÔºåÊàë‰ª¨‰ºöÂø´ÈÄüÂ∑©Âõ∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ†∏ÂøÉÁü•ËØÜÔºå‰∏∫‰Ω†ÁöÑÂÆûË∑µ‰πãÊóÖÊâì‰∏ãÂùöÂÆûÁöÑÁêÜËÆ∫Âú∞Âü∫„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;ÔºàÁ¨¨ÂõõÁ´†ÔΩûÁ¨¨‰∏ÉÁ´†ÔºâÔºåËøôÊòØ‰Ω†Âä®ÊâãÂÆûË∑µÁöÑËµ∑ÁÇπ„ÄÇ‰Ω†Â∞Ü‰∫≤ÊâãÂÆûÁé∞ ReAct Á≠âÁªèÂÖ∏ËåÉÂºèÔºå‰ΩìÈ™å Coze Á≠â‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑ‰æøÊç∑ÔºåÂπ∂ÊéåÊè° Langgraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂ÁöÑÂ∫îÁî®„ÄÇÊúÄÁªàÔºåÊàë‰ª¨Ëøò‰ºöÂ∏¶‰Ω†‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫‰∏Ä‰∏™Â±û‰∫éËá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåËÆ©‰Ω†ÂÖºÂÖ∑‚ÄúÁî®ËΩÆÂ≠ê‚Äù‰∏é‚ÄúÈÄ†ËΩÆÂ≠ê‚ÄùÁöÑËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;ÔºàÁ¨¨ÂÖ´Á´†ÔΩûÁ¨¨ÂçÅ‰∫åÁ´†ÔºâÔºåÂú®Ëøô‰∏ÄÈÉ®ÂàÜÔºå‰Ω†ÁöÑÊô∫ËÉΩ‰ΩìÂ∞Ü‚ÄúÂ≠¶‰ºö‚ÄùÊÄùËÄÉ‰∏éÂçè‰Ωú„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®Á¨¨‰∫åÈÉ®ÂàÜÁöÑËá™Á†îÊ°ÜÊû∂ÔºåÊ∑±ÂÖ•Êé¢Á¥¢ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢„ÄÅ‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅAgent ËÆ≠ÁªÉÁ≠âÊ†∏ÂøÉÊäÄÊúØÔºåÂπ∂Â≠¶‰π†Â§öÊô∫ËÉΩ‰ΩìÈó¥ÁöÑÈÄö‰ø°ÂçèËÆÆ„ÄÇÊúÄÁªàÔºå‰Ω†Â∞ÜÊéåÊè°ËØÑ‰º∞Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÊÄßËÉΩÁöÑ‰∏ì‰∏öÊñπÊ≥ï„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;ÔºàÁ¨¨ÂçÅ‰∏âÁ´†ÔΩûÁ¨¨ÂçÅ‰∫îÁ´†ÔºâÔºåËøôÈáåÊòØÁêÜËÆ∫‰∏éÂÆûË∑µÁöÑ‰∫§Ê±áÁÇπ„ÄÇ‰Ω†Â∞ÜÊääÊâÄÂ≠¶Ëûç‰ºöË¥ØÈÄöÔºå‰∫≤ÊâãÊâìÈÄ†Êô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰ΩìÔºå‰πÉËá≥‰∏Ä‰∏™Ê®°ÊãüÁ§æ‰ºöÂä®ÊÄÅÁöÑËµõÂçöÂ∞èÈïáÔºåÂú®ÁúüÂÆûÊúâË∂£ÁöÑÈ°πÁõÆ‰∏≠Ê∑¨ÁÇº‰Ω†ÁöÑÊûÑÂª∫ËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;ÔºàÁ¨¨ÂçÅÂÖ≠Á´†ÔºâÔºåÂú®ÊóÖÁ®ãÁöÑÁªàÁÇπÔºå‰Ω†Â∞ÜËøéÊù•‰∏Ä‰∏™ÊØï‰∏öËÆæËÆ°ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄÅÂ±û‰∫é‰Ω†Ëá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®ÔºåÂÖ®Èù¢Ê£ÄÈ™å‰Ω†ÁöÑÂ≠¶‰π†ÊàêÊûú„ÄÇÊàë‰ª¨ËøòÂ∞Ü‰∏é‰Ω†‰∏ÄÂêåÂ±ïÊúõÊô∫ËÉΩ‰ΩìÁöÑÊú™Êù•ÔºåÊé¢Á¥¢ÊøÄÂä®‰∫∫ÂøÉÁöÑÂâçÊ≤øÊñπÂêë„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊô∫ËÉΩ‰ΩìÊòØ‰∏Ä‰∏™È£ûÈÄüÂèëÂ±ï‰∏îÊûÅÂ∫¶‰æùËµñÂÆûË∑µÁöÑÈ¢ÜÂüü„ÄÇ‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥ÁöÑÂ≠¶‰π†ÊïàÊûúÔºåÊàë‰ª¨Âú®È°πÁõÆÁöÑ&lt;code&gt;code&lt;/code&gt;Êñá‰ª∂Â§πÂÜÖÊèê‰æõ‰∫ÜÈÖçÂ•óÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºåÂº∫ÁÉàÂª∫ËÆÆ‰Ω†&lt;strong&gt;Â∞ÜÁêÜËÆ∫‰∏éÂÆûË∑µÁõ∏ÁªìÂêà&lt;/strong&gt;„ÄÇËØ∑Âä°ÂøÖ‰∫≤ÊâãËøêË°å„ÄÅË∞ÉËØïÁîöËá≥‰øÆÊîπÈ°πÁõÆÈáåÊèê‰æõÁöÑÊØè‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇÊ¨¢Ëøé‰Ω†ÈöèÊó∂ÂÖ≥Ê≥® Datawhale ‰ª•ÂèäÂÖ∂‰ªñ Agent Áõ∏ÂÖ≥Á§æÂå∫ÔºåÂΩìÈÅáÂà∞ÈóÆÈ¢òÊó∂Ôºå‰Ω†ÂèØ‰ª•ÈöèÊó∂Âú®Êú¨È°πÁõÆÁöÑ issue Âå∫ÊèêÈóÆ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÁé∞Âú®ÔºåÂáÜÂ§áÂ•ΩËøõÂÖ•Êô∫ËÉΩ‰ΩìÁöÑÂ•áÂ¶ô‰∏ñÁïå‰∫ÜÂêóÔºüËÆ©Êàë‰ª¨Âç≥ÂàªÂêØÁ®ãÔºÅ&lt;/p&gt; 
&lt;h2&gt;‰∏ã‰∏ÄÊ≠•ËßÑÂàí&lt;/h2&gt; 
&lt;p&gt;ÂèåËØ≠ËßÜÈ¢ëËØæÁ®ã[Ëã±Êñá+‰∏≠Êñá]ÔºàÂ∞Ü‰ºöÊõ¥Âä†ÁªÜËá¥ÔºåÂÆûË∑µËØæÂ∏¶È¢ÜÂ§ßÂÆ∂‰ªéËÆæËÆ°ÊÄùË∑ØÂà∞ÂÆûÊñΩÔºåÊéà‰∫∫‰ª•È±º‰πüÊéà‰∫∫‰ª•Ê∏îÔºâ&lt;/p&gt; 
&lt;h2&gt;ü§ù Â¶Ç‰ΩïË¥°ÁåÆ&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨ÊòØ‰∏Ä‰∏™ÂºÄÊîæÁöÑÂºÄÊ∫êÁ§æÂå∫ÔºåÊ¨¢Ëøé‰ªª‰ΩïÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Êä•Âëä Bug&lt;/strong&gt; - ÂèëÁé∞ÂÜÖÂÆπÊàñ‰ª£Á†ÅÈóÆÈ¢òÔºåËØ∑Êèê‰∫§ Issue&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;ÊèêÂá∫Âª∫ËÆÆ&lt;/strong&gt; - ÂØπÈ°πÁõÆÊúâÂ•ΩÊÉ≥Ê≥ïÔºåÊ¨¢ËøéÂèëËµ∑ËÆ®ËÆ∫&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;ÂÆåÂñÑÂÜÖÂÆπ&lt;/strong&gt; - Â∏ÆÂä©ÊîπËøõÊïôÁ®ãÔºåÊèê‰∫§‰Ω†ÁöÑ Pull Request&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;strong&gt;ÂàÜ‰∫´ÂÆûË∑µ&lt;/strong&gt; - Âú®"Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ"‰∏≠ÂàÜ‰∫´‰Ω†ÁöÑÂ≠¶‰π†Á¨îËÆ∞ÂíåÈ°πÁõÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Ëá¥Ë∞¢&lt;/h2&gt; 
&lt;h3&gt;Ê†∏ÂøÉË¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jjyaoao"&gt;ÈôàÊÄùÂ∑û-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, ÂÖ®ÊñáÂÜô‰ΩúÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fengju0213"&gt;Â≠ôÈü¨-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, Á¨¨‰πùÁ´†ÂÜÖÂÆπÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tsumugii24"&gt;ÂßúËàíÂá°-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt;ÔºàDatawhale ÊàêÂëò, Á´†ËäÇ‰π†È¢òËÆæËÆ°ÂíåÊ†°ÂØπÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HeteroCat"&gt;ÈªÑ‰Ω©Êûó-DatawhaleÊÑèÂêëÊàêÂëò&lt;/a&gt; (Agent ÂºÄÂèëÂ∑•Á®ãÂ∏à, Á¨¨‰∫îÁ´†ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fancyboi999"&gt;ÊõæÈë´Ê∞ë-AgentÂ∑•Á®ãÂ∏à&lt;/a&gt; (ÁâõÂÆ¢ÁßëÊäÄ, Á¨¨ÂçÅÂõõÁ´†Ê°à‰æãÂºÄÂèë)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xinzhongzhu.github.io/"&gt;Êú±‰ø°Âø†-ÊåáÂØº‰∏ìÂÆ∂&lt;/a&gt; (DatawhaleÈ¶ñÂ∏≠ÁßëÂ≠¶ÂÆ∂-ÊµôÊ±üÂ∏àËåÉÂ§ßÂ≠¶Êù≠Â∑û‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Èô¢ÊïôÊéà)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extra-Chapter Ë¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/WHQAQ11"&gt;WH&lt;/a&gt; (ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thunderbolt-fire"&gt;Âë®Â••Êù∞-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ë•øÂÆâ‰∫§ÈÄöÂ§ßÂ≠¶, Extra02 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tasselszcx"&gt;Âº†ÂÆ∏Êó≠-‰∏™‰∫∫ÂºÄÂèëËÄÖ&lt;/a&gt;(Â∏ùÂõΩÁêÜÂ∑•Â≠¶Èô¢, Extra03 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XiaoMa-PM"&gt;ÈªÑÂÆèÊôó-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ê∑±Âú≥Â§ßÂ≠¶, Extra04 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÁâπÂà´ÊÑüË∞¢&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊÑüË∞¢ &lt;a href="https://github.com/Sm1les"&gt;@Sm1les&lt;/a&gt; ÂØπÊú¨È°πÁõÆÁöÑÂ∏ÆÂä©‰∏éÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;ÊÑüË∞¢ÊâÄÊúâ‰∏∫Êú¨È°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖ‰ª¨ ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center" style="margin-top: 30px;"&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=datawhalechina/Hello-Agents" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/star-history-20251223.png" alt="Datawhale" width="90%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‚≠ê Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ÁªôÊàë‰ª¨‰∏Ä‰∏™ StarÔºÅ&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ÂÖ≥‰∫é Datawhale&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/datawhale.png" alt="Datawhale" width="30%" /&gt; 
 &lt;p&gt;Êâ´Êèè‰∫åÁª¥Á†ÅÂÖ≥Ê≥® Datawhale ÂÖ¨‰ºóÂè∑ÔºåËé∑ÂèñÊõ¥Â§ö‰ºòË¥®ÂºÄÊ∫êÂÜÖÂÆπ&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìú ÂºÄÊ∫êÂçèËÆÆ&lt;/h2&gt; 
&lt;p&gt;Êú¨‰ΩúÂìÅÈááÁî®&lt;a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆ&lt;/a&gt;ËøõË°åËÆ∏ÂèØ„ÄÇ&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>oven-sh/bun</title>
      <link>https://github.com/oven-sh/bun</link>
      <description>&lt;p&gt;Incredibly fast JavaScript runtime, bundler, test runner, and package manager ‚Äì all in one&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://bun.com"&gt;&lt;img src="https://github.com/user-attachments/assets/50282090-adfd-4ddb-9e27-c30753c6b161" alt="Logo" height="170" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Bun&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://bun.com/discord" target="_blank"&gt;&lt;img height="20" src="https://img.shields.io/discord/876711213126520882" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/oven-sh/bun" alt="stars" /&gt; &lt;a href="https://twitter.com/jarredsumner/status/1542824445810642946"&gt;&lt;img src="https://img.shields.io/static/v1?label=speed&amp;amp;message=fast&amp;amp;color=success" alt="Bun speed" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://bun.com/docs"&gt;Documentation&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://discord.com/invite/CXdq2DP29u"&gt;Discord&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://github.com/oven-sh/bun/issues/new"&gt;Issues&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://github.com/oven-sh/bun/issues/159"&gt;Roadmap&lt;/a&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;a href="https://bun.com/docs"&gt;Read the docs ‚Üí&lt;/a&gt;&lt;/h3&gt; 
&lt;h2&gt;What is Bun?&lt;/h2&gt; 
&lt;p&gt;Bun is an all-in-one toolkit for JavaScript and TypeScript apps. It ships as a single executable called &lt;code&gt;bun&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;At its core is the &lt;em&gt;Bun runtime&lt;/em&gt;, a fast JavaScript runtime designed as &lt;strong&gt;a drop-in replacement for Node.js&lt;/strong&gt;. It's written in Zig and powered by JavaScriptCore under the hood, dramatically reducing startup times and memory usage.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run index.tsx             # TS and JSX supported out-of-the-box
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;bun&lt;/code&gt; command-line tool also implements a test runner, script runner, and Node.js-compatible package manager. Instead of 1,000 node_modules for development, you only need &lt;code&gt;bun&lt;/code&gt;. Bun's built-in tools are significantly faster than existing options and usable in existing Node.js projects with little to no changes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun test                      # run tests
bun run start                 # run the `start` script in `package.json`
bun install &amp;lt;pkg&amp;gt;             # install a package
bunx cowsay 'Hello, world!'   # execute a package
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;Bun supports Linux (x64 &amp;amp; arm64), macOS (x64 &amp;amp; Apple Silicon) and Windows (x64).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Linux users&lt;/strong&gt; ‚Äî Kernel version 5.6 or higher is strongly recommended, but the minimum is 5.1.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;x64 users&lt;/strong&gt; ‚Äî if you see "illegal instruction" or similar errors, check our &lt;a href="https://bun.com/docs/installation#cpu-requirements-and-baseline-builds"&gt;CPU requirements&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# with install script (recommended)
curl -fsSL https://bun.com/install | bash

# on windows
powershell -c "irm bun.sh/install.ps1 | iex"

# with npm
npm install -g bun

# with Homebrew
brew tap oven-sh/bun
brew install bun

# with Docker
docker pull oven/bun
docker run --rm --init --ulimit memlock=-1:-1 oven/bun
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Upgrade&lt;/h3&gt; 
&lt;p&gt;To upgrade to the latest version of Bun, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;bun upgrade
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Bun automatically releases a canary build on every commit to &lt;code&gt;main&lt;/code&gt;. To upgrade to the latest canary build, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;bun upgrade --canary
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/oven-sh/bun/releases/tag/canary"&gt;View canary build&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quick links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Intro&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/index"&gt;What is Bun?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/typescript"&gt;TypeScript&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Templating&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/init"&gt;&lt;code&gt;bun init&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/bun-create"&gt;&lt;code&gt;bun create&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CLI&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/bun-upgrade"&gt;&lt;code&gt;bun upgrade&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Runtime&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/run"&gt;&lt;code&gt;bun run&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/loaders"&gt;File types (Loaders)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/typescript"&gt;TypeScript&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/jsx"&gt;JSX&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/environment-variables"&gt;Environment variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/bun-apis"&gt;Bun APIs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/web-apis"&gt;Web APIs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/nodejs-compat"&gt;Node.js compatibility&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/executables"&gt;Single-file executable&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/plugins"&gt;Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/watch-mode"&gt;Watch mode / Hot Reloading&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/modules"&gt;Module resolution&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/autoimport"&gt;Auto-install&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/bunfig"&gt;bunfig.toml&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/debugger"&gt;Debugger&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/shell"&gt;$ Shell&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Package manager&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/install"&gt;&lt;code&gt;bun install&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/add"&gt;&lt;code&gt;bun add&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/remove"&gt;&lt;code&gt;bun remove&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/update"&gt;&lt;code&gt;bun update&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/link"&gt;&lt;code&gt;bun link&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/unlink"&gt;&lt;code&gt;bun unlink&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/pm"&gt;&lt;code&gt;bun pm&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/outdated"&gt;&lt;code&gt;bun outdated&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/publish"&gt;&lt;code&gt;bun publish&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/install/patch"&gt;&lt;code&gt;bun patch&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/patch-commit"&gt;&lt;code&gt;bun patch-commit&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/install/cache"&gt;Global cache&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/install/workspaces"&gt;Workspaces&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/install/lifecycle"&gt;Lifecycle scripts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/filter"&gt;Filter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/install/lockfile"&gt;Lockfile&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/install/registries"&gt;Scopes and registries&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/install/overrides"&gt;Overrides and resolutions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/install/npmrc"&gt;&lt;code&gt;.npmrc&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Bundler&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler"&gt;&lt;code&gt;Bun.build&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/loaders"&gt;Loaders&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/plugins"&gt;Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/macros"&gt;Macros&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/vs-esbuild"&gt;vs esbuild&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/executables"&gt;Single-file executable&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/css"&gt;CSS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/html"&gt;HTML&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/hmr"&gt;Hot Module Replacement (HMR)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/bundler/fullstack"&gt;Full-stack with HTML imports&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Test runner&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/test"&gt;&lt;code&gt;bun test&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/writing"&gt;Writing tests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/hot"&gt;Watch mode&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/lifecycle"&gt;Lifecycle hooks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/mocks"&gt;Mocks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/snapshots"&gt;Snapshots&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/time"&gt;Dates and times&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/dom"&gt;DOM testing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/coverage"&gt;Code coverage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/discovery"&gt;Discovery&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/reporters"&gt;Reporters&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/test/runtime-behavior"&gt;Runtime Behavior&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Package runner&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/cli/bunx"&gt;&lt;code&gt;bunx&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;API&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/http"&gt;HTTP server (&lt;code&gt;Bun.serve&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/websockets"&gt;WebSockets&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/workers"&gt;Workers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/binary-data"&gt;Binary data&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/streams"&gt;Streams&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/file-io"&gt;File I/O (&lt;code&gt;Bun.file&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/import-meta"&gt;import.meta&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/sqlite"&gt;SQLite (&lt;code&gt;bun:sqlite&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/sql"&gt;PostgreSQL (&lt;code&gt;Bun.sql&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/redis"&gt;Redis (&lt;code&gt;Bun.redis&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/s3"&gt;S3 Client (&lt;code&gt;Bun.s3&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/file-system-router"&gt;FileSystemRouter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/tcp"&gt;TCP sockets&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/udp"&gt;UDP sockets&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/globals"&gt;Globals&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/runtime/shell"&gt;$ Shell&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/spawn"&gt;Child processes (spawn)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/transpiler"&gt;Transpiler (&lt;code&gt;Bun.Transpiler&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/hashing"&gt;Hashing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/color"&gt;Colors (&lt;code&gt;Bun.color&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/console"&gt;Console&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/ffi"&gt;FFI (&lt;code&gt;bun:ffi&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/cc"&gt;C Compiler (&lt;code&gt;bun:ffi&lt;/code&gt; cc)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/html-rewriter"&gt;HTMLRewriter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/test"&gt;Testing (&lt;code&gt;bun:test&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/cookie"&gt;Cookies (&lt;code&gt;Bun.Cookie&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/utils"&gt;Utils&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/node-api"&gt;Node-API&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/glob"&gt;Glob (&lt;code&gt;Bun.Glob&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/semver"&gt;Semver (&lt;code&gt;Bun.semver&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/dns"&gt;DNS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/docs/api/fetch"&gt;fetch API extensions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Guides&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Binary&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/blob-to-string"&gt;Convert a Blob to a string&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/buffer-to-blob"&gt;Convert a Buffer to a blob&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/blob-to-dataview"&gt;Convert a Blob to a DataView&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/buffer-to-string"&gt;Convert a Buffer to a string&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/blob-to-stream"&gt;Convert a Blob to a ReadableStream&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/blob-to-typedarray"&gt;Convert a Blob to a Uint8Array&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/dataview-to-string"&gt;Convert a DataView to a string&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/typedarray-to-blob"&gt;Convert a Uint8Array to a Blob&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/blob-to-arraybuffer"&gt;Convert a Blob to an ArrayBuffer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/arraybuffer-to-blob"&gt;Convert an ArrayBuffer to a Blob&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/buffer-to-typedarray"&gt;Convert a Buffer to a Uint8Array&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/typedarray-to-buffer"&gt;Convert a Uint8Array to a Buffer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/typedarray-to-string"&gt;Convert a Uint8Array to a string&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/buffer-to-arraybuffer"&gt;Convert a Buffer to an ArrayBuffer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/arraybuffer-to-buffer"&gt;Convert an ArrayBuffer to a Buffer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/arraybuffer-to-string"&gt;Convert an ArrayBuffer to a string&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/typedarray-to-dataview"&gt;Convert a Uint8Array to a DataView&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/buffer-to-readablestream"&gt;Convert a Buffer to a ReadableStream&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/typedarray-to-arraybuffer"&gt;Convert a Uint8Array to an ArrayBuffer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/arraybuffer-to-typedarray"&gt;Convert an ArrayBuffer to a Uint8Array&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/arraybuffer-to-array"&gt;Convert an ArrayBuffer to an array of numbers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/binary/typedarray-to-readablestream"&gt;Convert a Uint8Array to a ReadableStream&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ecosystem&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/react"&gt;Use React and JSX&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/gel"&gt;Use Gel with Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/prisma"&gt;Use Prisma with Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/sentry"&gt;Add Sentry to a Bun app&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/discordjs"&gt;Create a Discord bot&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/pm2"&gt;Run Bun as a daemon with PM2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/drizzle"&gt;Use Drizzle ORM with Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/nuxt"&gt;Build an app with Nuxt and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/qwik"&gt;Build an app with Qwik and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/astro"&gt;Build an app with Astro and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/remix"&gt;Build an app with Remix and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/vite"&gt;Build a frontend using Vite and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/nextjs"&gt;Build an app with Next.js and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/systemd"&gt;Run Bun as a daemon with systemd&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/render"&gt;Deploy a Bun application on Render&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/hono"&gt;Build an HTTP server using Hono and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/sveltekit"&gt;Build an app with SvelteKit and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/solidstart"&gt;Build an app with SolidStart and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/elysia"&gt;Build an HTTP server using Elysia and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/stric"&gt;Build an HTTP server using StricJS and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/docker"&gt;Containerize a Bun application with Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/express"&gt;Build an HTTP server using Express and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/neon-drizzle"&gt;Use Neon Postgres through Drizzle ORM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/ssr-react"&gt;Server-side render (SSR) a React component&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/mongoose"&gt;Read and write data to MongoDB using Mongoose and Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/ecosystem/neon-serverless-postgres"&gt;Use Neon's Serverless Postgres with Bun&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HTMLRewriter&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/html-rewriter/extract-links"&gt;Extract links from a webpage using HTMLRewriter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/html-rewriter/extract-social-meta"&gt;Extract social share images and Open Graph tags&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HTTP&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/hot"&gt;Hot reload an HTTP server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/server"&gt;Common HTTP server usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/simple"&gt;Write a simple HTTP server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/tls"&gt;Configure TLS on an HTTP server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/fetch"&gt;Send an HTTP request using fetch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/proxy"&gt;Proxy HTTP requests using fetch()&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/cluster"&gt;Start a cluster of HTTP servers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/stream-file"&gt;Stream a file as an HTTP Response&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/fetch-unix"&gt;fetch with unix domain sockets in Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/file-uploads"&gt;Upload files via HTTP using FormData&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/stream-iterator"&gt;Streaming HTTP Server with Async Iterators&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/http/stream-node-streams-in-bun"&gt;Streaming HTTP Server with Node.js Streams&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/add"&gt;Add a dependency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/add-git"&gt;Add a Git dependency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/add-peer"&gt;Add a peer dependency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/trusted"&gt;Add a trusted dependency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/add-dev"&gt;Add a development dependency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/add-tarball"&gt;Add a tarball dependency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/add-optional"&gt;Add an optional dependency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/yarnlock"&gt;Generate a yarn-compatible lockfile&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/workspaces"&gt;Configuring a monorepo using workspaces&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/npm-alias"&gt;Install a package under a different name&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/cicd"&gt;Install dependencies with Bun in GitHub Actions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/jfrog-artifactory"&gt;Using bun install with Artifactory&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/git-diff-bun-lockfile"&gt;Configure git to diff Bun's lockb lockfile&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/custom-registry"&gt;Override the default npm registry for bun install&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/azure-artifacts"&gt;Using bun install with an Azure Artifacts npm registry&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/from-npm-install-to-bun-install"&gt;Migrate from npm install to bun install&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/install/registry-scope"&gt;Configure a private registry for an organization scope with bun install&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Process&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/process/stdin"&gt;Read from stdin&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/process/ctrl-c"&gt;Listen for CTRL+C&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/process/spawn"&gt;Spawn a child process&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/process/os-signals"&gt;Listen to OS signals&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/process/argv"&gt;Parse command-line arguments&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/process/spawn-stderr"&gt;Read stderr from a child process&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/process/spawn-stdout"&gt;Read stdout from a child process&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/process/nanoseconds"&gt;Get the process uptime in nanoseconds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/process/ipc"&gt;Spawn a child process and communicate using IPC&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Read file&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/read-file/json"&gt;Read a JSON file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/read-file/exists"&gt;Check if a file exists&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/read-file/string"&gt;Read a file as a string&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/read-file/buffer"&gt;Read a file to a Buffer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/read-file/mime"&gt;Get the MIME type of a file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/read-file/watch"&gt;Watch a directory for changes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/read-file/stream"&gt;Read a file as a ReadableStream&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/read-file/uint8array"&gt;Read a file to a Uint8Array&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/read-file/arraybuffer"&gt;Read a file to an ArrayBuffer&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Runtime&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/delete-file"&gt;Delete files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/shell"&gt;Run a Shell Command&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/import-json"&gt;Import a JSON file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/import-toml"&gt;Import a TOML file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/timezone"&gt;Set a time zone in Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/set-env"&gt;Set environment variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/tsconfig-paths"&gt;Re-map import paths&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/delete-directory"&gt;Delete directories&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/read-env"&gt;Read environment variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/import-html"&gt;Import a HTML file as text&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/cicd"&gt;Install and run Bun in GitHub Actions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/web-debugger"&gt;Debugging Bun with the web debugger&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/typescript"&gt;Install TypeScript declarations for Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/vscode-debugger"&gt;Debugging Bun with the VS Code extension&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/heap-snapshot"&gt;Inspect memory usage using V8 heap snapshots&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/define-constant"&gt;Define and replace static globals &amp;amp; constants&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/runtime/codesign-macos-executable"&gt;Codesign a single-file JavaScript executable on macOS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Streams&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/to-json"&gt;Convert a ReadableStream to JSON&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/to-blob"&gt;Convert a ReadableStream to a Blob&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/to-buffer"&gt;Convert a ReadableStream to a Buffer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/to-string"&gt;Convert a ReadableStream to a string&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/to-typedarray"&gt;Convert a ReadableStream to a Uint8Array&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/to-array"&gt;Convert a ReadableStream to an array of chunks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/node-readable-to-json"&gt;Convert a Node.js Readable to JSON&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/to-arraybuffer"&gt;Convert a ReadableStream to an ArrayBuffer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/node-readable-to-blob"&gt;Convert a Node.js Readable to a Blob&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/node-readable-to-string"&gt;Convert a Node.js Readable to a string&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/node-readable-to-uint8array"&gt;Convert a Node.js Readable to an Uint8Array&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/streams/node-readable-to-arraybuffer"&gt;Convert a Node.js Readable to an ArrayBuffer&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Test&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/spy-on"&gt;Spy on methods in &lt;code&gt;bun test&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/bail"&gt;Bail early with the Bun test runner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/mock-functions"&gt;Mock functions in &lt;code&gt;bun test&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/watch-mode"&gt;Run tests in watch mode with Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/snapshot"&gt;Use snapshot testing in &lt;code&gt;bun test&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/skip-tests"&gt;Skip tests with the Bun test runner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/testing-library"&gt;Using Testing Library with Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/update-snapshots"&gt;Update snapshots in &lt;code&gt;bun test&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/run-tests"&gt;Run your tests with the Bun test runner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/mock-clock"&gt;Set the system time in Bun's test runner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/timeout"&gt;Set a per-test timeout with the Bun test runner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/migrate-from-jest"&gt;Migrate from Jest to Bun's test runner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/happy-dom"&gt;Write browser DOM tests with Bun and happy-dom&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/todo-tests"&gt;Mark a test as a "todo" with the Bun test runner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/rerun-each"&gt;Re-run tests multiple times with the Bun test runner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/coverage"&gt;Generate code coverage reports with the Bun test runner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/svelte-test"&gt;import, require, and test Svelte components with bun test&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/test/coverage-threshold"&gt;Set a code coverage threshold with the Bun test runner&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Util&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/javascript-uuid"&gt;Generate a UUID&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/hash-a-password"&gt;Hash a password&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/escape-html"&gt;Escape an HTML string&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/version"&gt;Get the current Bun version&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/base64"&gt;Encode and decode base64 strings&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/gzip"&gt;Compress and decompress data with gzip&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/sleep"&gt;Sleep for a fixed number of milliseconds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/detect-bun"&gt;Detect when code is executed with Bun&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/deep-equals"&gt;Check if two objects are deeply equal&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/deflate"&gt;Compress and decompress data with DEFLATE&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/main"&gt;Get the absolute path to the current entrypoint&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/import-meta-dir"&gt;Get the directory of the current file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/entrypoint"&gt;Check if the current file is the entrypoint&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/import-meta-file"&gt;Get the file name of the current file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/file-url-to-path"&gt;Convert a file URL to an absolute path&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/path-to-file-url"&gt;Convert an absolute path to a file URL&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/import-meta-path"&gt;Get the absolute path of the current file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/util/which-path-to-executable-bin"&gt;Get the path to an executable bin file&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;WebSocket&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/websocket/pubsub"&gt;Build a publish-subscribe WebSocket server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/websocket/simple"&gt;Build a simple WebSocket server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/websocket/compression"&gt;Enable compression for WebSocket messages&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/websocket/context"&gt;Set per-socket contextual data on a WebSocket&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Write file&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/unlink"&gt;Delete a file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/stdout"&gt;Write to stdout&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/cat"&gt;Write a file to stdout&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/blob"&gt;Write a Blob to a file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/basic"&gt;Write a string to a file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/append"&gt;Append content to a file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/filesink"&gt;Write a file incrementally&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/response"&gt;Write a Response to a file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/file-cp"&gt;Copy a file to another location&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bun.com/guides/write-file/stream"&gt;Write a ReadableStream to a file&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://bun.com/docs/project/contributing"&gt;Project &amp;gt; Contributing&lt;/a&gt; guide to start contributing to Bun.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://bun.com/docs/project/licensing"&gt;Project &amp;gt; License&lt;/a&gt; page for information about Bun's licensing.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>simstudioai/sim</title>
      <link>https://github.com/simstudioai/sim</link>
      <description>&lt;p&gt;Open-source platform to build and deploy AI agent workflows.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/logo/reverse/text/large.png" alt="Sim Logo" width="500" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Build and deploy AI agent workflows in minutes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA" alt="Sim.ai" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Hr4UWYEcTT" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/simdotai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/simstudioai?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://docs.sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Docs-6F3DFA.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;Build Workflows with Ease&lt;/h3&gt; 
&lt;p&gt;Design agent workflows visually on a canvas‚Äîconnect agents, tools, and blocks, then run them instantly.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/workflow.gif" alt="Workflow Builder Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h3&gt;Supercharge with Copilot&lt;/h3&gt; 
&lt;p&gt;Leverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/copilot.gif" alt="Copilot Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h3&gt;Integrate Vector Databases&lt;/h3&gt; 
&lt;p&gt;Upload documents to a vector store and let agents answer questions grounded in your specific content.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/knowledge.gif" alt="Knowledge Uploads and Retrieval Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Cloud-hosted: &lt;a href="https://sim.ai"&gt;sim.ai&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&amp;amp;logoColor=white" alt="Sim.ai" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Self-hosted: NPM Package&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx simstudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Note&lt;/h4&gt; 
&lt;p&gt;Docker must be installed and running on your machine.&lt;/p&gt; 
&lt;h4&gt;Options&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-p, --port &amp;lt;port&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port to run Sim on (default &lt;code&gt;3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-pull&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Skip pulling latest Docker images&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Self-hosted: Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the application at &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Local Models with Ollama&lt;/h4&gt; 
&lt;p&gt;Run Sim with local AI models using &lt;a href="https://ollama.ai"&gt;Ollama&lt;/a&gt; - no external APIs required:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the model to download, then visit &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;. Add more models with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using an External Ollama Instance&lt;/h4&gt; 
&lt;p&gt;If you already have Ollama running on your host machine (outside Docker), you need to configure the &lt;code&gt;OLLAMA_URL&lt;/code&gt; to use &lt;code&gt;host.docker.internal&lt;/code&gt; instead of &lt;code&gt;localhost&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Docker Desktop (macOS/Windows)
OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d

# Linux (add extra_hosts or use host IP)
docker compose -f docker-compose.prod.yml up -d  # Then set OLLAMA_URL to your host's IP
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; When running inside Docker, &lt;code&gt;localhost&lt;/code&gt; refers to the container itself, not your host machine. &lt;code&gt;host.docker.internal&lt;/code&gt; is a special DNS name that resolves to the host.&lt;/p&gt; 
&lt;p&gt;For Linux users, you can either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use your host machine's actual IP address (e.g., &lt;code&gt;http://192.168.1.100:11434&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Add &lt;code&gt;extra_hosts: ["host.docker.internal:host-gateway"]&lt;/code&gt; to the simstudio service in your compose file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using vLLM&lt;/h4&gt; 
&lt;p&gt;Sim also supports &lt;a href="https://docs.vllm.ai/"&gt;vLLM&lt;/a&gt; for self-hosted models with OpenAI-compatible API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Set these environment variables
VLLM_BASE_URL=http://your-vllm-server:8000
VLLM_API_KEY=your_optional_api_key  # Only if your vLLM instance requires auth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running with Docker, use &lt;code&gt;host.docker.internal&lt;/code&gt; if vLLM is on your host machine (same as Ollama above).&lt;/p&gt; 
&lt;h3&gt;Self-hosted: Dev Containers&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open VS Code with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers"&gt;Remote - Containers extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open the project and click "Reopen in Container" when prompted&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;bun run dev:full&lt;/code&gt; in the terminal or use the &lt;code&gt;sim-start&lt;/code&gt; alias 
  &lt;ul&gt; 
   &lt;li&gt;This starts both the main application and the realtime socket server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Self-hosted: Manual Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt; runtime&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; v20+ (required for sandboxed code execution)&lt;/li&gt; 
 &lt;li&gt;PostgreSQL 12+ with &lt;a href="https://github.com/pgvector/pgvector"&gt;pgvector extension&lt;/a&gt; (required for AI embeddings)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the &lt;code&gt;pgvector&lt;/code&gt; PostgreSQL extension.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/simstudioai/sim.git
cd sim
bun install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Set up PostgreSQL with pgvector:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You need PostgreSQL with the &lt;code&gt;vector&lt;/code&gt; extension for embedding support. Choose one option:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Using Docker (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Manual Installation&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install PostgreSQL 12+ and the pgvector extension&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/pgvector/pgvector#installation"&gt;pgvector installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Set up the database:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;First, configure the database package environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd packages/db
cp .env.example .env 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;packages/db/.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run the migrations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd packages/db # Required so drizzle picks correct .env file
bunx drizzle-kit migrate --config=./drizzle.config.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Start the development servers:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Recommended approach - run both servers together (from project root):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev:full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts both the main Next.js application and the realtime socket server required for full functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Alternative - run servers separately:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Next.js app (from project root):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Realtime socket server (from &lt;code&gt;apps/sim&lt;/code&gt; directory in a separate terminal):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
bun run dev:sockets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Copilot API Keys&lt;/h2&gt; 
&lt;p&gt;Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href="https://sim.ai"&gt;https://sim.ai&lt;/a&gt; ‚Üí Settings ‚Üí Copilot and generate a Copilot API key&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;COPILOT_API_KEY&lt;/code&gt; environment variable in your self-hosted apps/sim/.env file to that value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Environment Variables&lt;/h2&gt; 
&lt;p&gt;Key environment variables for self-hosted deployments (see &lt;code&gt;apps/sim/.env.example&lt;/code&gt; for full list):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DATABASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;PostgreSQL connection string with pgvector&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BETTER_AUTH_SECRET&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Auth secret (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BETTER_AUTH_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Your app URL (e.g., &lt;code&gt;http://localhost:3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;NEXT_PUBLIC_APP_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Public app URL (same as above)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENCRYPTION_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Encryption key (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Ollama server URL (default: &lt;code&gt;http://localhost:11434&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VLLM_BASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;vLLM server URL for self-hosted models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;COPILOT_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;API key from sim.ai for Copilot features&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Ollama models not showing in dropdown (Docker)&lt;/h3&gt; 
&lt;p&gt;If you're running Ollama on your host machine and Sim in Docker, change &lt;code&gt;OLLAMA_URL&lt;/code&gt; from &lt;code&gt;localhost&lt;/code&gt; to &lt;code&gt;host.docker.internal&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/#using-an-external-ollama-instance"&gt;Using an External Ollama Instance&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Database connection issues&lt;/h3&gt; 
&lt;p&gt;Ensure PostgreSQL has the pgvector extension installed. When using Docker, wait for the database to be healthy before running migrations.&lt;/p&gt; 
&lt;h3&gt;Port conflicts&lt;/h3&gt; 
&lt;p&gt;If ports 3000, 3002, or 5432 are in use, configure alternatives:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Custom ports
NEXT_PUBLIC_APP_URL=http://localhost:3100 POSTGRES_PORT=5433 docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: &lt;a href="https://nextjs.org/"&gt;Next.js&lt;/a&gt; (App Router)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: PostgreSQL with &lt;a href="https://orm.drizzle.team"&gt;Drizzle ORM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: &lt;a href="https://better-auth.com"&gt;Better Auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: &lt;a href="https://ui.shadcn.com/"&gt;Shadcn&lt;/a&gt;, &lt;a href="https://tailwindcss.com"&gt;Tailwind CSS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;State Management&lt;/strong&gt;: &lt;a href="https://zustand-demo.pmnd.rs/"&gt;Zustand&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flow Editor&lt;/strong&gt;: &lt;a href="https://reactflow.dev/"&gt;ReactFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://fumadocs.vercel.app/"&gt;Fumadocs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monorepo&lt;/strong&gt;: &lt;a href="https://turborepo.org/"&gt;Turborepo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Realtime&lt;/strong&gt;: &lt;a href="https://socket.io/"&gt;Socket.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Jobs&lt;/strong&gt;: &lt;a href="https://trigger.dev/"&gt;Trigger.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote Code Execution&lt;/strong&gt;: &lt;a href="https://www.e2b.dev/"&gt;E2B&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p align="center"&gt;Made with ‚ù§Ô∏è by the Sim Team&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>resemble-ai/chatterbox</title>
      <link>https://github.com/resemble-ai/chatterbox</link>
      <description>&lt;p&gt;SoTA open-source TTS&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/Chatterbox-Turbo.jpg" alt="Chatterbox Turbo Image" /&gt;&lt;/p&gt; 
&lt;h1&gt;Chatterbox TTS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;&lt;img src="https://img.shields.io/badge/listen-demo_samples-blue" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;&lt;img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://podonos.com/resembleai/chatterbox"&gt;&lt;img src="https://static-public.podonos.com/badges/insight-on-pdns-sm-dark.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;&lt;img src="https://img.shields.io/discord/1377773249798344776?label=join%20discord&amp;amp;logo=discord&amp;amp;style=flat" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;_Made with ‚ô•Ô∏è by &lt;a href="https://resemble.ai" target="_blank"&gt;&lt;img width="100" alt="resemble-logo-horizontal" src="https://github.com/user-attachments/assets/35cf756b-3506-4943-9c72-c05ddfa4e525" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Chatterbox&lt;/strong&gt; is a family of three state-of-the-art, open-source text-to-speech models by Resemble AI.&lt;/p&gt; 
&lt;p&gt;We are excited to introduce &lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;, our most efficient model yet. Built on a streamlined 350M parameter architecture, &lt;strong&gt;Turbo&lt;/strong&gt; delivers high-quality speech with less compute and VRAM than our previous models. We have also distilled the speech-token-to-mel decoder, previously a bottleneck, reducing generation from 10 steps to just &lt;strong&gt;one&lt;/strong&gt;, while retaining high-fidelity audio output.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Paralinguistic tags&lt;/strong&gt; are now native to the Turbo model, allowing you to use &lt;code&gt;[cough]&lt;/code&gt;, &lt;code&gt;[laugh]&lt;/code&gt;, &lt;code&gt;[chuckle]&lt;/code&gt;, and more to add distinct realism. While Turbo was built primarily for low-latency voice agents, it excels at narration and creative workflows.&lt;/p&gt; 
&lt;p&gt;If you like the model but need to scale or tune it for higher accuracy, check out our competitively priced TTS service (&lt;a href="https://resemble.ai"&gt;link&lt;/a&gt;). It delivers reliable performance with ultra-low latency of sub 200ms‚Äîideal for production use in agents, applications, or interactive media.&lt;/p&gt; 
&lt;img width="1200" height="600" alt="Podonos Turbo Eval" src="https://storage.googleapis.com/chatterbox-demo-samples/turbo/podonos_turbo.png" /&gt; 
&lt;h3&gt;‚ö° Model Zoo&lt;/h3&gt; 
&lt;p&gt;Choose the right model for your application.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="left"&gt;Size&lt;/th&gt; 
   &lt;th align="left"&gt;Languages&lt;/th&gt; 
   &lt;th align="left"&gt;Key Features&lt;/th&gt; 
   &lt;th align="left"&gt;Best For&lt;/th&gt; 
   &lt;th align="left"&gt;ü§ó&lt;/th&gt; 
   &lt;th align="left"&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;350M&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Paralinguistic Tags (&lt;code&gt;[laugh]&lt;/code&gt;), Lower Compute and VRAM&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot voice agents, Production&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox-Multilingual &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#supported-languages"&gt;(Language list)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;23+&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot cloning, Multiple Languages&lt;/td&gt; 
   &lt;td align="left"&gt;Global applications, Localization&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox-Multilingual-TTS"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#original-chatterbox-tips"&gt;(Tips and Tricks)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;English&lt;/td&gt; 
   &lt;td align="left"&gt;CFG &amp;amp; Exaggeration tuning&lt;/td&gt; 
   &lt;td align="left"&gt;General zero-shot TTS with creative controls&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install chatterbox-tts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# conda create -yn chatterbox python=3.11
# conda activate chatterbox

git clone https://github.com/resemble-ai/chatterbox.git
cd chatterbox
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We developed and tested Chatterbox on Python 3.11 on Debian 11 OS; the versions of the dependencies are pinned in &lt;code&gt;pyproject.toml&lt;/code&gt; to ensure consistency. You can modify the code or dependencies in this installation mode.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h5&gt;Chatterbox-Turbo&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torchaudio as ta
import torch
from chatterbox.tts_turbo import ChatterboxTurboTTS

# Load the Turbo model
model = ChatterboxTurboTTS.from_pretrained(device="cuda")

# Generate with Paralinguistic Tags
text = "Hi there, Sarah here from MochaFone calling you back [chuckle], have you got one minute to chat about the billing issue?"

# Generate audio (requires a reference clip for voice cloning)
wav = model.generate(text, audio_prompt_path="your_10s_ref_clip.wav")

ta.save("test-turbo.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Chatterbox and Chatterbox-Multilingual&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
from chatterbox.mtl_tts import ChatterboxMultilingualTTS

# English example
model = ChatterboxTTS.from_pretrained(device="cuda")

text = "Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy's Nexus in an epic late-game pentakill."
wav = model.generate(text)
ta.save("test-english.wav", wav, model.sr)

# Multilingual examples
multilingual_model = ChatterboxMultilingualTTS.from_pretrained(device=device)

french_text = "Bonjour, comment √ßa va? Ceci est le mod√®le de synth√®se vocale multilingue Chatterbox, il prend en charge 23 langues."
wav_french = multilingual_model.generate(spanish_text, language_id="fr")
ta.save("test-french.wav", wav_french, model.sr)

chinese_text = "‰Ω†Â•ΩÔºå‰ªäÂ§©Â§©Ê∞îÁúü‰∏çÈîôÔºåÂ∏åÊúõ‰Ω†Êúâ‰∏Ä‰∏™ÊÑâÂø´ÁöÑÂë®Êú´„ÄÇ"
wav_chinese = multilingual_model.generate(chinese_text, language_id="zh")
ta.save("test-chinese.wav", wav_chinese, model.sr)

# If you want to synthesize with a different voice, specify the audio prompt
AUDIO_PROMPT_PATH = "YOUR_FILE.wav"
wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)
ta.save("test-2.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;code&gt;example_tts.py&lt;/code&gt; and &lt;code&gt;example_vc.py&lt;/code&gt; for more examples.&lt;/p&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;p&gt;Arabic (ar) ‚Ä¢ Danish (da) ‚Ä¢ German (de) ‚Ä¢ Greek (el) ‚Ä¢ English (en) ‚Ä¢ Spanish (es) ‚Ä¢ Finnish (fi) ‚Ä¢ French (fr) ‚Ä¢ Hebrew (he) ‚Ä¢ Hindi (hi) ‚Ä¢ Italian (it) ‚Ä¢ Japanese (ja) ‚Ä¢ Korean (ko) ‚Ä¢ Malay (ms) ‚Ä¢ Dutch (nl) ‚Ä¢ Norwegian (no) ‚Ä¢ Polish (pl) ‚Ä¢ Portuguese (pt) ‚Ä¢ Russian (ru) ‚Ä¢ Swedish (sv) ‚Ä¢ Swahili (sw) ‚Ä¢ Turkish (tr) ‚Ä¢ Chinese (zh)&lt;/p&gt; 
&lt;h2&gt;Original Chatterbox Tips&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;General Use (TTS and Voice Agents):&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure that the reference clip matches the specified language tag. Otherwise, language transfer outputs may inherit the accent of the reference clip‚Äôs language. To mitigate this, set &lt;code&gt;cfg_weight&lt;/code&gt; to &lt;code&gt;0&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;The default settings (&lt;code&gt;exaggeration=0.5&lt;/code&gt;, &lt;code&gt;cfg_weight=0.5&lt;/code&gt;) work well for most prompts across all languages.&lt;/li&gt; 
   &lt;li&gt;If the reference speaker has a fast speaking style, lowering &lt;code&gt;cfg_weight&lt;/code&gt; to around &lt;code&gt;0.3&lt;/code&gt; can improve pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Expressive or Dramatic Speech:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Try lower &lt;code&gt;cfg_weight&lt;/code&gt; values (e.g. &lt;code&gt;~0.3&lt;/code&gt;) and increase &lt;code&gt;exaggeration&lt;/code&gt; to around &lt;code&gt;0.7&lt;/code&gt; or higher.&lt;/li&gt; 
   &lt;li&gt;Higher &lt;code&gt;exaggeration&lt;/code&gt; tends to speed up speech; reducing &lt;code&gt;cfg_weight&lt;/code&gt; helps compensate with slower, more deliberate pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built-in PerTh Watermarking for Responsible AI&lt;/h2&gt; 
&lt;p&gt;Every audio file generated by Chatterbox includes &lt;a href="https://github.com/resemble-ai/perth"&gt;Resemble AI's Perth (Perceptual Threshold) Watermarker&lt;/a&gt; - imperceptible neural watermarks that survive MP3 compression, audio editing, and common manipulations while maintaining nearly 100% detection accuracy.&lt;/p&gt; 
&lt;h2&gt;Watermark extraction&lt;/h2&gt; 
&lt;p&gt;You can look for the watermark using the following script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import perth
import librosa

AUDIO_PATH = "YOUR_FILE.wav"

# Load the watermarked audio
watermarked_audio, sr = librosa.load(AUDIO_PATH, sr=None)

# Initialize watermarker (same as used for embedding)
watermarker = perth.PerthImplicitWatermarker()

# Extract watermark
watermark = watermarker.get_watermark(watermarked_audio, sample_rate=sr)
print(f"Extracted watermark: {watermark}")
# Output: 0.0 (no watermark) or 1.0 (watermarked)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Official Discord&lt;/h2&gt; 
&lt;p&gt;üëã Join us on &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;Discord&lt;/a&gt; and let's build something awesome together!&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FunAudioLLM/CosyVoice"&gt;Cosyvoice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning"&gt;Real-Time-Voice-Cloning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yl4579/HiFTNet"&gt;HiFT-GAN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;Llama 3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xingchensong/S3Tokenizer"&gt;S3Tokenizer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this model useful, please consider citing.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{chatterboxtts2025,
  author       = {{Resemble AI}},
  title        = {{Chatterbox-TTS}},
  year         = {2025},
  howpublished = {\url{https://github.com/resemble-ai/chatterbox}},
  note         = {GitHub repository}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Don't use this model to do bad things. Prompts are sourced from freely available data on the internet.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>virattt/ai-hedge-fund</title>
      <link>https://github.com/virattt/ai-hedge-fund</link>
      <description>&lt;p&gt;An AI Hedge Fund Team&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Hedge Fund&lt;/h1&gt; 
&lt;p&gt;This is a proof of concept for an AI-powered hedge fund. The goal of this project is to explore the use of AI to make trading decisions. This project is for &lt;strong&gt;educational&lt;/strong&gt; purposes only and is not intended for real trading or investment.&lt;/p&gt; 
&lt;p&gt;This system employs several agents working together:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation&lt;/li&gt; 
 &lt;li&gt;Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety&lt;/li&gt; 
 &lt;li&gt;Bill Ackman Agent - An activist investor, takes bold positions and pushes for change&lt;/li&gt; 
 &lt;li&gt;Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption&lt;/li&gt; 
 &lt;li&gt;Charlie Munger Agent - Warren Buffett's partner, only buys wonderful businesses at fair prices&lt;/li&gt; 
 &lt;li&gt;Michael Burry Agent - The Big Short contrarian who hunts for deep value&lt;/li&gt; 
 &lt;li&gt;Mohnish Pabrai Agent - The Dhandho investor, who looks for doubles at low risk&lt;/li&gt; 
 &lt;li&gt;Peter Lynch Agent - Practical investor who seeks "ten-baggers" in everyday businesses&lt;/li&gt; 
 &lt;li&gt;Phil Fisher Agent - Meticulous growth investor who uses deep "scuttlebutt" research&lt;/li&gt; 
 &lt;li&gt;Rakesh Jhunjhunwala Agent - The Big Bull of India&lt;/li&gt; 
 &lt;li&gt;Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential&lt;/li&gt; 
 &lt;li&gt;Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price&lt;/li&gt; 
 &lt;li&gt;Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Sentiment Agent - Analyzes market sentiment and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Fundamentals Agent - Analyzes fundamental data and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Technicals Agent - Analyzes technical indicators and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Risk Manager - Calculates risk metrics and sets position limits&lt;/li&gt; 
 &lt;li&gt;Portfolio Manager - Makes final trading decisions and generates orders&lt;/li&gt; 
&lt;/ol&gt; 
&lt;img width="1042" alt="Screenshot 2025-03-22 at 6 19 07 PM" src="https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4" /&gt; 
&lt;p&gt;Note: the system does not actually make any trades.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/virattt"&gt;&lt;img src="https://img.shields.io/twitter/follow/virattt?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for &lt;strong&gt;educational and research purposes only&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not intended for real trading or investment&lt;/li&gt; 
 &lt;li&gt;No investment advice or guarantees provided&lt;/li&gt; 
 &lt;li&gt;Creator assumes no liability for financial losses&lt;/li&gt; 
 &lt;li&gt;Consult a financial advisor for investment decisions&lt;/li&gt; 
 &lt;li&gt;Past performance does not indicate future results&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to use it solely for learning purposes.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-install"&gt;How to Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-run"&gt;How to Run&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-command-line-interface"&gt;‚å®Ô∏è Command Line Interface&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-web-application"&gt;üñ•Ô∏è Web Application&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-contribute"&gt;How to Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#feature-requests"&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;Before you can run the AI Hedge Fund, you'll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.&lt;/p&gt; 
&lt;h3&gt;1. Clone the Repository&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set up API keys&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file for your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create .env file for your API keys (in the root directory)
cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open and edit the &lt;code&gt;.env&lt;/code&gt; file to add your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: You must set at least one LLM API key (e.g. &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;GROQ_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, or &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt;) for the hedge fund to work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Financial Data&lt;/strong&gt;: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the &lt;code&gt;FINANCIAL_DATASETS_API_KEY&lt;/code&gt; in the .env file.&lt;/p&gt; 
&lt;h2&gt;How to Run&lt;/h2&gt; 
&lt;h3&gt;‚å®Ô∏è Command Line Interface&lt;/h3&gt; 
&lt;p&gt;You can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.&lt;/p&gt; 
&lt;img width="992" alt="Screenshot 2025-01-06 at 5 50 17 PM" src="https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b" /&gt; 
&lt;h4&gt;Quick Start&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Poetry (if not already installed):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://install.python-poetry.org | python3 -
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the AI Hedge Fund&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;--ollama&lt;/code&gt; flag to run the AI hedge fund using local LLMs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can optionally specify the start and end dates to make decisions over a specific time period.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the Backtester&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt; &lt;img width="941" alt="Screenshot 2025-01-06 at 5 47 52 PM" src="https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47" /&gt;&lt;/p&gt; 
&lt;p&gt;Note: The &lt;code&gt;--ollama&lt;/code&gt;, &lt;code&gt;--start-date&lt;/code&gt;, and &lt;code&gt;--end-date&lt;/code&gt; flags work for the backtester, as well!&lt;/p&gt; 
&lt;h3&gt;üñ•Ô∏è Web Application&lt;/h3&gt; 
&lt;p&gt;The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. This is recommended for users who prefer visual interfaces over command line tools.&lt;/p&gt; 
&lt;p&gt;Please see detailed instructions on how to install and run the web application &lt;a href="https://github.com/virattt/ai-hedge-fund/tree/main/app"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;img width="1721" alt="Screenshot 2025-06-28 at 6 41 03‚ÄØPM" src="https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b" /&gt; 
&lt;h2&gt;How to Contribute&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Commit your changes&lt;/li&gt; 
 &lt;li&gt;Push to the branch&lt;/li&gt; 
 &lt;li&gt;Create a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Please keep your pull requests small and focused. This will make it easier to review and merge.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;If you have a feature request, please open an &lt;a href="https://github.com/virattt/ai-hedge-fund/issues"&gt;issue&lt;/a&gt; and make sure it is tagged with &lt;code&gt;enhancement&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>FunAudioLLM/CosyVoice</title>
      <link>https://github.com/FunAudioLLM/CosyVoice</link>
      <description>&lt;p&gt;Multi-lingual large voice generation model, providing inference, training and deployment full-stack ability.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://svg-banners.vercel.app/api?type=origin&amp;amp;text1=CosyVoice%F0%9F%A4%A0&amp;amp;text2=Text-to-Speech%20%F0%9F%92%96%20Large%20Language%20Model&amp;amp;width=800&amp;amp;height=210" alt="SVG Banners" /&gt;&lt;/p&gt; 
&lt;h2&gt;üëâüèª CosyVoice üëàüèª&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Fun-CosyVoice 3.0&lt;/strong&gt;: &lt;a href="https://funaudiollm.github.io/cosyvoice3/"&gt;Demos&lt;/a&gt;; &lt;a href="https://arxiv.org/pdf/2505.17589"&gt;Paper&lt;/a&gt;; &lt;a href="https://www.modelscope.cn/models/FunAudioLLM/Fun-CosyVoice3-0.5B-2512"&gt;Modelscope&lt;/a&gt;; &lt;a href="https://huggingface.co/FunAudioLLM/Fun-CosyVoice3-0.5B-2512"&gt;Huggingface&lt;/a&gt;; &lt;a href="https://github.com/FunAudioLLM/CV3-Eval"&gt;CV3-Eval&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CosyVoice 2.0&lt;/strong&gt;: &lt;a href="https://funaudiollm.github.io/cosyvoice2/"&gt;Demos&lt;/a&gt;; &lt;a href="https://arxiv.org/pdf/2412.10117"&gt;Paper&lt;/a&gt;; &lt;a href="https://www.modelscope.cn/models/iic/CosyVoice2-0.5B"&gt;Modelscope&lt;/a&gt;; &lt;a href="https://huggingface.co/FunAudioLLM/CosyVoice2-0.5B"&gt;HuggingFace&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CosyVoice 1.0&lt;/strong&gt;: &lt;a href="https://fun-audio-llm.github.io"&gt;Demos&lt;/a&gt;; &lt;a href="https://funaudiollm.github.io/pdf/CosyVoice_v1.pdf"&gt;Paper&lt;/a&gt;; &lt;a href="https://www.modelscope.cn/models/iic/CosyVoice-300M"&gt;Modelscope&lt;/a&gt;; &lt;a href="https://huggingface.co/FunAudioLLM/CosyVoice-300M"&gt;HuggingFace&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Highlightüî•&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Fun-CosyVoice 3.0&lt;/strong&gt; is an advanced text-to-speech (TTS) system based on large language models (LLM), surpassing its predecessor (CosyVoice 2.0) in content consistency, speaker similarity, and prosody naturalness. It is designed for zero-shot multilingual speech synthesis in the wild.&lt;/p&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Language Coverage&lt;/strong&gt;: Covers 9 common languages (Chinese, English, Japanese, Korean, German, Spanish, French, Italian, Russian), 18+ Chinese dialects/accents (Guangdong, Minnan, Sichuan, Dongbei, Shan3xi, Shan1xi, Shanghai, Tianjin, Shandong, Ningxia, Gansu, etc.) and meanwhile supports both multi-lingual/cross-lingual zero-shot voice cloning.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Consistency &amp;amp; Naturalness&lt;/strong&gt;: Achieves state-of-the-art performance in content consistency, speaker similarity, and prosody naturalness.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pronunciation Inpainting&lt;/strong&gt;: Supports pronunciation inpainting of Chinese Pinyin and English CMU phonemes, providing more controllability and thus suitable for production use.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Normalization&lt;/strong&gt;: Supports reading of numbers, special symbols and various text formats without a traditional frontend module.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bi-Streaming&lt;/strong&gt;: Support both text-in streaming and audio-out streaming, and achieves latency as low as 150ms while maintaining high-quality audio output.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instruct Support&lt;/strong&gt;: Supports various instructions such as languages, dialects, emotions, speed, volume, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2025/12&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; release Fun-CosyVoice3-0.5B-2512 base model, rl model and its training/inference script&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; release Fun-CosyVoice3-0.5B modelscope gradio space&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2025/08&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Thanks to the contribution from NVIDIA Yuekai Zhang, add triton trtllm runtime support and cosyvoice2 grpo training support&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2025/07&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; release Fun-CosyVoice 3.0 eval set&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2025/05&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; add CosyVoice2-0.5B vllm support&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2024/12&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 25hz CosyVoice2-0.5B released&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2024/09&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 25hz CosyVoice-300M base model&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 25hz CosyVoice-300M voice conversion function&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2024/08&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Repetition Aware Sampling(RAS) inference for llm stability&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Streaming inference mode support, including kv cache and sdpa for rtf optimization&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2024/07&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Flow matching training support&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; WeTextProcessing support when ttsfrd is not available&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Fastapi server and client&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Evaluation&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Open-Source&lt;/th&gt; 
   &lt;th align="center"&gt;Model Size&lt;/th&gt; 
   &lt;th align="center"&gt;test-zh&lt;br /&gt;CER (%) ‚Üì&lt;/th&gt; 
   &lt;th align="center"&gt;test-zh&lt;br /&gt;Speaker Similarity (%) ‚Üë&lt;/th&gt; 
   &lt;th align="center"&gt;test-en&lt;br /&gt;WER (%) ‚Üì&lt;/th&gt; 
   &lt;th align="center"&gt;test-en&lt;br /&gt;Speaker Similarity (%) ‚Üë&lt;/th&gt; 
   &lt;th align="center"&gt;test-hard&lt;br /&gt;CER (%) ‚Üì&lt;/th&gt; 
   &lt;th align="center"&gt;test-hard&lt;br /&gt;Speaker Similarity (%) ‚Üë&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Human&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;1.26&lt;/td&gt; 
   &lt;td align="center"&gt;75.5&lt;/td&gt; 
   &lt;td align="center"&gt;2.14&lt;/td&gt; 
   &lt;td align="center"&gt;73.4&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Seed-TTS&lt;/td&gt; 
   &lt;td align="center"&gt;‚ùå&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;1.12&lt;/td&gt; 
   &lt;td align="center"&gt;79.6&lt;/td&gt; 
   &lt;td align="center"&gt;2.25&lt;/td&gt; 
   &lt;td align="center"&gt;76.2&lt;/td&gt; 
   &lt;td align="center"&gt;7.59&lt;/td&gt; 
   &lt;td align="center"&gt;77.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniMax-Speech&lt;/td&gt; 
   &lt;td align="center"&gt;‚ùå&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;0.83&lt;/td&gt; 
   &lt;td align="center"&gt;78.3&lt;/td&gt; 
   &lt;td align="center"&gt;1.65&lt;/td&gt; 
   &lt;td align="center"&gt;69.2&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;F5-TTS&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;0.3B&lt;/td&gt; 
   &lt;td align="center"&gt;1.52&lt;/td&gt; 
   &lt;td align="center"&gt;74.1&lt;/td&gt; 
   &lt;td align="center"&gt;2.00&lt;/td&gt; 
   &lt;td align="center"&gt;64.7&lt;/td&gt; 
   &lt;td align="center"&gt;8.67&lt;/td&gt; 
   &lt;td align="center"&gt;71.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Spark TTS&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;0.5B&lt;/td&gt; 
   &lt;td align="center"&gt;1.2&lt;/td&gt; 
   &lt;td align="center"&gt;66.0&lt;/td&gt; 
   &lt;td align="center"&gt;1.98&lt;/td&gt; 
   &lt;td align="center"&gt;57.3&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;CosyVoice2&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;0.5B&lt;/td&gt; 
   &lt;td align="center"&gt;1.45&lt;/td&gt; 
   &lt;td align="center"&gt;75.7&lt;/td&gt; 
   &lt;td align="center"&gt;2.57&lt;/td&gt; 
   &lt;td align="center"&gt;65.9&lt;/td&gt; 
   &lt;td align="center"&gt;6.83&lt;/td&gt; 
   &lt;td align="center"&gt;72.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;FireRedTTS2&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;1.5B&lt;/td&gt; 
   &lt;td align="center"&gt;1.14&lt;/td&gt; 
   &lt;td align="center"&gt;73.2&lt;/td&gt; 
   &lt;td align="center"&gt;1.95&lt;/td&gt; 
   &lt;td align="center"&gt;66.5&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Index-TTS2&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;1.5B&lt;/td&gt; 
   &lt;td align="center"&gt;1.03&lt;/td&gt; 
   &lt;td align="center"&gt;76.5&lt;/td&gt; 
   &lt;td align="center"&gt;2.23&lt;/td&gt; 
   &lt;td align="center"&gt;70.6&lt;/td&gt; 
   &lt;td align="center"&gt;7.12&lt;/td&gt; 
   &lt;td align="center"&gt;75.5&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;VibeVoice-1.5B&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;1.5B&lt;/td&gt; 
   &lt;td align="center"&gt;1.16&lt;/td&gt; 
   &lt;td align="center"&gt;74.4&lt;/td&gt; 
   &lt;td align="center"&gt;3.04&lt;/td&gt; 
   &lt;td align="center"&gt;68.9&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;VibeVoice-Realtime&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;0.5B&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;2.05&lt;/td&gt; 
   &lt;td align="center"&gt;63.3&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;HiggsAudio-v2&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;3B&lt;/td&gt; 
   &lt;td align="center"&gt;1.50&lt;/td&gt; 
   &lt;td align="center"&gt;74.0&lt;/td&gt; 
   &lt;td align="center"&gt;2.44&lt;/td&gt; 
   &lt;td align="center"&gt;67.7&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;VoxCPM&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;0.5B&lt;/td&gt; 
   &lt;td align="center"&gt;0.93&lt;/td&gt; 
   &lt;td align="center"&gt;77.2&lt;/td&gt; 
   &lt;td align="center"&gt;1.85&lt;/td&gt; 
   &lt;td align="center"&gt;72.9&lt;/td&gt; 
   &lt;td align="center"&gt;8.87&lt;/td&gt; 
   &lt;td align="center"&gt;73.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;GLM-TTS&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;1.5B&lt;/td&gt; 
   &lt;td align="center"&gt;1.03&lt;/td&gt; 
   &lt;td align="center"&gt;76.1&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;GLM-TTS RL&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;1.5B&lt;/td&gt; 
   &lt;td align="center"&gt;0.89&lt;/td&gt; 
   &lt;td align="center"&gt;76.4&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Fun-CosyVoice3-0.5B-2512&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;0.5B&lt;/td&gt; 
   &lt;td align="center"&gt;1.21&lt;/td&gt; 
   &lt;td align="center"&gt;78.0&lt;/td&gt; 
   &lt;td align="center"&gt;2.24&lt;/td&gt; 
   &lt;td align="center"&gt;71.8&lt;/td&gt; 
   &lt;td align="center"&gt;6.71&lt;/td&gt; 
   &lt;td align="center"&gt;75.8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Fun-CosyVoice3-0.5B-2512_RL&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;0.5B&lt;/td&gt; 
   &lt;td align="center"&gt;0.81&lt;/td&gt; 
   &lt;td align="center"&gt;77.4&lt;/td&gt; 
   &lt;td align="center"&gt;1.68&lt;/td&gt; 
   &lt;td align="center"&gt;69.5&lt;/td&gt; 
   &lt;td align="center"&gt;5.44&lt;/td&gt; 
   &lt;td align="center"&gt;75.0&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;h3&gt;Clone and install&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repo&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git
# If you failed to clone the submodule due to network failures, please run the following command until success
cd CosyVoice
git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install Conda: please see &lt;a href="https://docs.conda.io/en/latest/miniconda.html"&gt;https://docs.conda.io/en/latest/miniconda.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create Conda env:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;conda create -n cosyvoice -y python=3.10
conda activate cosyvoice
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com

# If you encounter sox compatibility issues
# ubuntu
sudo apt-get install sox libsox-dev
# centos
sudo yum install sox sox-devel
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Model download&lt;/h3&gt; 
&lt;p&gt;We strongly recommend that you download our pretrained &lt;code&gt;Fun-CosyVoice3-0.5B&lt;/code&gt; &lt;code&gt;CosyVoice2-0.5B&lt;/code&gt; &lt;code&gt;CosyVoice-300M&lt;/code&gt; &lt;code&gt;CosyVoice-300M-SFT&lt;/code&gt; &lt;code&gt;CosyVoice-300M-Instruct&lt;/code&gt; model and &lt;code&gt;CosyVoice-ttsfrd&lt;/code&gt; resource.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# modelscope SDK model download
from modelscope import snapshot_download
snapshot_download('FunAudioLLM/Fun-CosyVoice3-0.5B-2512', local_dir='pretrained_models/Fun-CosyVoice3-0.5B')
snapshot_download('iic/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')
snapshot_download('iic/CosyVoice-300M', local_dir='pretrained_models/CosyVoice-300M')
snapshot_download('iic/CosyVoice-300M-SFT', local_dir='pretrained_models/CosyVoice-300M-SFT')
snapshot_download('iic/CosyVoice-300M-Instruct', local_dir='pretrained_models/CosyVoice-300M-Instruct')
snapshot_download('iic/CosyVoice-ttsfrd', local_dir='pretrained_models/CosyVoice-ttsfrd')

# for oversea users, huggingface SDK model download
from huggingface_hub import snapshot_download
snapshot_download('FunAudioLLM/Fun-CosyVoice3-0.5B-2512', local_dir='pretrained_models/Fun-CosyVoice3-0.5B')
snapshot_download('FunAudioLLM/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')
snapshot_download('FunAudioLLM/CosyVoice-300M', local_dir='pretrained_models/CosyVoice-300M')
snapshot_download('FunAudioLLM/CosyVoice-300M-SFT', local_dir='pretrained_models/CosyVoice-300M-SFT')
snapshot_download('FunAudioLLM/CosyVoice-300M-Instruct', local_dir='pretrained_models/CosyVoice-300M-Instruct')
snapshot_download('FunAudioLLM/CosyVoice-ttsfrd', local_dir='pretrained_models/CosyVoice-ttsfrd')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optionally, you can unzip &lt;code&gt;ttsfrd&lt;/code&gt; resource and install &lt;code&gt;ttsfrd&lt;/code&gt; package for better text normalization performance.&lt;/p&gt; 
&lt;p&gt;Notice that this step is not necessary. If you do not install &lt;code&gt;ttsfrd&lt;/code&gt; package, we will use wetext by default.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd pretrained_models/CosyVoice-ttsfrd/
unzip resource.zip -d .
pip install ttsfrd_dependency-0.1-py3-none-any.whl
pip install ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Basic Usage&lt;/h3&gt; 
&lt;p&gt;We strongly recommend using &lt;code&gt;Fun-CosyVoice3-0.5B&lt;/code&gt; for better performance. Follow the code in &lt;code&gt;example.py&lt;/code&gt; for detailed usage of each model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python example.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;CosyVoice2 vllm Usage&lt;/h4&gt; 
&lt;p&gt;If you want to use vllm for inference, please install &lt;code&gt;vllm==v0.9.0&lt;/code&gt;. Older vllm version do not support CosyVoice2 inference.&lt;/p&gt; 
&lt;p&gt;Notice that &lt;code&gt;vllm==v0.9.0&lt;/code&gt; has a lot of specific requirements, for example &lt;code&gt;torch==2.7.0&lt;/code&gt;. You can create a new env to in case your hardward do not support vllm and old env is corrupted.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;conda create -n cosyvoice_vllm --clone cosyvoice
conda activate cosyvoice_vllm
pip install vllm==v0.9.0 transformers==4.51.3 numpy==1.26.4 -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com
python vllm_example.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Start web demo&lt;/h4&gt; 
&lt;p&gt;You can use our web demo page to get familiar with CosyVoice quickly.&lt;/p&gt; 
&lt;p&gt;Please see the demo website for details.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# change iic/CosyVoice-300M-SFT for sft inference, or iic/CosyVoice-300M-Instruct for instruct inference
python3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice-300M
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Advanced Usage&lt;/h4&gt; 
&lt;p&gt;For advanced users, we have provided training and inference scripts in &lt;code&gt;examples/libritts/cosyvoice/run.sh&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Build for deployment&lt;/h4&gt; 
&lt;p&gt;Optionally, if you want service deployment, You can run the following steps.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd runtime/python
docker build -t cosyvoice:v1.0 .
# change iic/CosyVoice-300M to iic/CosyVoice-300M-Instruct if you want to use instruct inference
# for grpc usage
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/grpc &amp;amp;&amp;amp; python3 server.py --port 50000 --max_conc 4 --model_dir iic/CosyVoice-300M &amp;amp;&amp;amp; sleep infinity"
cd grpc &amp;amp;&amp;amp; python3 client.py --port 50000 --mode &amp;lt;sft|zero_shot|cross_lingual|instruct&amp;gt;
# for fastapi usage
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/fastapi &amp;amp;&amp;amp; python3 server.py --port 50000 --model_dir iic/CosyVoice-300M &amp;amp;&amp;amp; sleep infinity"
cd fastapi &amp;amp;&amp;amp; python3 client.py --port 50000 --mode &amp;lt;sft|zero_shot|cross_lingual|instruct&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Nvidia TensorRT-LLM for deployment&lt;/h4&gt; 
&lt;p&gt;Using TensorRT-LLM to accelerate cosyvoice2 llm could give 4x acceleration comparing with huggingface transformers implementation. To quick start:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd runtime/triton_trtllm
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details, you could check &lt;a href="https://github.com/FunAudioLLM/CosyVoice/tree/main/runtime/triton_trtllm"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Discussion &amp;amp; Communication&lt;/h2&gt; 
&lt;p&gt;You can directly discuss on &lt;a href="https://github.com/FunAudioLLM/CosyVoice/issues"&gt;Github Issues&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also scan the QR code to join our official Dingding chat group.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/FunAudioLLM/CosyVoice/main/asset/dingding.png" width="250px" /&gt; 
&lt;h2&gt;Acknowledge&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/modelscope/FunASR"&gt;FunASR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/modelscope/FunCodec"&gt;FunCodec&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/shivammehta25/Matcha-TTS"&gt;Matcha-TTS&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/yangdongchao/AcademiCodec"&gt;AcademiCodec&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/wenet-e2e/wenet"&gt;WeNet&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Citations&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{du2024cosyvoice,
  title={Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

@article{du2024cosyvoice,
  title={Cosyvoice 2: Scalable streaming speech synthesis with large language models},
  author={Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and others},
  journal={arXiv preprint arXiv:2412.10117},
  year={2024}
}

@article{du2025cosyvoice,
  title={CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training},
  author={Du, Zhihao and Gao, Changfeng and Wang, Yuxuan and Yu, Fan and Zhao, Tianyu and Wang, Hao and Lv, Xiang and Wang, Hui and Shi, Xian and An, Keyu and others},
  journal={arXiv preprint arXiv:2505.17589},
  year={2025}
}

@inproceedings{lyu2025build,
  title={Build LLM-Based Zero-Shot Streaming TTS System with Cosyvoice},
  author={Lyu, Xiang and Wang, Yuxuan and Zhao, Tianyu and Wang, Hao and Liu, Huadai and Du, Zhihao},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--2},
  year={2025},
  organization={IEEE}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;The content provided above is for academic purposes only and is intended to demonstrate technical capabilities. Some examples are sourced from the internet. If any content infringes on your rights, please contact us to request its removal.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/ty</title>
      <link>https://github.com/astral-sh/ty</link>
      <description>&lt;p&gt;An extremely fast Python type checker and language server, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ty&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/ty"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ty/main/assets/badge/v0.json" alt="ty" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/ty"&gt;&lt;img src="https://img.shields.io/pypi/v/ty.svg?sanitize=true" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python type checker and language server, written in Rust.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img alt="Shows a bar chart with benchmark results." width="500px" src="https://raw.githubusercontent.com/astral-sh/ty/main/docs/assets/ty-benchmark-cli.svg?sanitize=true" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Type checking the &lt;a href="https://github.com/home-assistant/core"&gt;home-assistant&lt;/a&gt; project without caching.&lt;/i&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;ty is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;, the creators of &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; and &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;10x - 100x faster than mypy and Pyright&lt;/li&gt; 
 &lt;li&gt;Comprehensive &lt;a href="https://docs.astral.sh/ty/features/diagnostics/"&gt;diagnostics&lt;/a&gt; with rich contextual information&lt;/li&gt; 
 &lt;li&gt;Configurable &lt;a href="https://docs.astral.sh/ty/rules/"&gt;rule levels&lt;/a&gt;, &lt;a href="https://docs.astral.sh/ty/reference/configuration/#overrides"&gt;per-file overrides&lt;/a&gt;, &lt;a href="https://docs.astral.sh/ty/suppression/"&gt;suppression comments&lt;/a&gt;, and first-class project support&lt;/li&gt; 
 &lt;li&gt;Designed for adoption, with support for &lt;a href="https://docs.astral.sh/ty/features/type-system/#redeclarations"&gt;redeclarations&lt;/a&gt; and &lt;a href="https://docs.astral.sh/ty/features/type-system/#gradual-guarantee"&gt;partially typed code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.astral.sh/ty/features/language-server/"&gt;Language server&lt;/a&gt; with code navigation, completions, code actions, auto-import, inlay hints, on-hover help, etc.&lt;/li&gt; 
 &lt;li&gt;Fine-grained &lt;a href="https://docs.astral.sh/ty/features/language-server/#fine-grained-incrementality"&gt;incremental analysis&lt;/a&gt; designed for fast updates when editing files in an IDE&lt;/li&gt; 
 &lt;li&gt;Editor integrations for &lt;a href="https://docs.astral.sh/ty/editors/#vs-code"&gt;VS Code&lt;/a&gt;, &lt;a href="https://docs.astral.sh/ty/editors/#pycharm"&gt;PyCharm&lt;/a&gt;, &lt;a href="https://docs.astral.sh/ty/editors/#neovim"&gt;Neovim&lt;/a&gt; and more&lt;/li&gt; 
 &lt;li&gt;Advanced typing features like first-class &lt;a href="https://docs.astral.sh/ty/features/type-system/#intersection-types"&gt;intersection types&lt;/a&gt;, advanced &lt;a href="https://docs.astral.sh/ty/features/type-system/#top-and-bottom-materializations"&gt;type narrowing&lt;/a&gt;, and &lt;a href="https://docs.astral.sh/ty/features/type-system/#reachability-based-on-types"&gt;sophisticated reachability analysis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Run ty with &lt;a href="https://docs.astral.sh/uv/guides/tools/#running-tools"&gt;uvx&lt;/a&gt; to get started quickly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;uvx ty check
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, check out the &lt;a href="https://play.ty.dev"&gt;ty playground&lt;/a&gt; to try it out in your browser.&lt;/p&gt; 
&lt;p&gt;To learn more about using ty, see the &lt;a href="https://docs.astral.sh/ty/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install ty, see the &lt;a href="https://docs.astral.sh/ty/installation/"&gt;installation&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;p&gt;To add the ty language server to your editor, see the &lt;a href="https://docs.astral.sh/ty/editors/"&gt;editor integration&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h2&gt;Getting help&lt;/h2&gt; 
&lt;p&gt;If you have questions or want to report a bug, please open an &lt;a href="https://github.com/astral-sh/ty/issues"&gt;issue&lt;/a&gt; in this repository.&lt;/p&gt; 
&lt;p&gt;You may also join our &lt;a href="https://discord.com/invite/astral-sh"&gt;Discord server&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Development of this project takes place in the &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt; repository at this time. Please &lt;a href="https://github.com/astral-sh/ruff/pulls"&gt;open pull requests&lt;/a&gt; there for changes to anything in the &lt;code&gt;ruff&lt;/code&gt; submodule (which includes all of the Rust source code).&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/astral-sh/ty/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;!-- We intentionally use smaller headings for the FAQ items --&gt; 
&lt;!-- markdownlint-disable MD001 --&gt; 
&lt;h4&gt;Why is ty doing _____?&lt;/h4&gt; 
&lt;p&gt;See our &lt;a href="https://docs.astral.sh/ty/reference/typing-faq"&gt;typing FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;How do you pronounce ty?&lt;/h4&gt; 
&lt;p&gt;It's pronounced as "tee - why" (&lt;a href="https://en.wikipedia.org/wiki/Help:IPA/English#Key"&gt;&lt;code&gt;/tiÀê wa…™/&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; 
&lt;h4&gt;How should I stylize ty?&lt;/h4&gt; 
&lt;p&gt;Just "ty", please.&lt;/p&gt; 
&lt;!-- markdownlint-enable MD001 --&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;ty is licensed under the MIT license (&lt;a href="https://raw.githubusercontent.com/astral-sh/ty/main/LICENSE"&gt;LICENSE&lt;/a&gt; or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in ty by you, as defined in the MIT license, shall be licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral" /&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>