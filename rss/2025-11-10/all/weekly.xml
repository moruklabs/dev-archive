<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Sun, 09 Nov 2025 01:42:02 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>nocobase/nocobase</title>
      <link>https://github.com/nocobase/nocobase</link>
      <description>&lt;p&gt;NocoBase is the most extensible AI-powered no-code/low-code platform for building business applications and enterprise solutions.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/nocobase/nocobase/main/README.zh-CN.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/nocobase/nocobase/main/README.ja-JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4d11a87b-00e2-48f3-9bf7-389d21072d13"&gt;https://github.com/user-attachments/assets/4d11a87b-00e2-48f3-9bf7-389d21072d13&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/4112" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4112" alt="nocobase%2Fnocobase | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;a href="https://www.producthunt.com/posts/nocobase?embed=true&amp;amp;utm_source=badge-top-post-topic-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-nocobase" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=456520&amp;amp;theme=light&amp;amp;period=weekly&amp;amp;topic_id=267" alt="NocoBase - Scalability-first, open-source no-code platform | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;What is NocoBase&lt;/h2&gt; 
&lt;p&gt;NocoBase is the most extensible AI-powered no-code platform.&lt;br /&gt; Total control. Infinite extensibility. AI collaboration.&lt;br /&gt; Enable your team to adapt quickly and cut costs dramatically.&lt;br /&gt; No years of development. No millions wasted.&lt;br /&gt; Deploy NocoBase in minutes ‚Äî and take control of everything.&lt;/p&gt; 
&lt;p&gt;Homepage:&lt;br /&gt; &lt;a href="https://www.nocobase.com/"&gt;https://www.nocobase.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Online Demo:&lt;br /&gt; &lt;a href="https://demo.nocobase.com/new"&gt;https://demo.nocobase.com/new&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Documents:&lt;br /&gt; &lt;a href="https://docs.nocobase.com/"&gt;https://docs.nocobase.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Forum:&lt;br /&gt; &lt;a href="https://forum.nocobase.com/"&gt;https://forum.nocobase.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Use Cases:&lt;br /&gt; &lt;a href="https://www.nocobase.com/en/blog/tags/customer-stories"&gt;https://www.nocobase.com/en/blog/tags/customer-stories&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Release Notes&lt;/h2&gt; 
&lt;p&gt;Our &lt;a href="https://www.nocobase.com/en/blog/timeline"&gt;blog&lt;/a&gt; is regularly updated with release notes and provides a weekly summary.&lt;/p&gt; 
&lt;h2&gt;Distinctive features&lt;/h2&gt; 
&lt;h3&gt;1. Data model-driven, not form/table‚Äìdriven&lt;/h3&gt; 
&lt;p&gt;Instead of being constrained by forms or tables, NocoBase adopts a data model‚Äìdriven approach, separating data structure from user interface to unlock unlimited possibilities.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;UI and data structure are fully decoupled&lt;/li&gt; 
 &lt;li&gt;Multiple blocks and actions can be created for the same table or record in any quantity or form&lt;/li&gt; 
 &lt;li&gt;Supports the main database, external databases, and third-party APIs as data sources&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static-docs.nocobase.com/model.png" alt="model" /&gt;&lt;/p&gt; 
&lt;h3&gt;2. AI employees, integrated into your business systems&lt;/h3&gt; 
&lt;p&gt;Unlike standalone AI demos, NocoBase allows you to embed AI capabilities seamlessly into your interfaces, workflows, and data context, making AI truly useful in real business scenarios.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Define AI employees for roles such as translator, analyst, researcher, or assistant&lt;/li&gt; 
 &lt;li&gt;Seamless AI‚Äìhuman collaboration in interfaces and workflows&lt;/li&gt; 
 &lt;li&gt;Ensure AI usage is secure, transparent, and customizable for your business needs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static-docs.nocobase.com/ai-employee-home.png" alt="AI-employee" /&gt;&lt;/p&gt; 
&lt;h3&gt;3. What you see is what you get, incredibly easy to use&lt;/h3&gt; 
&lt;p&gt;While enabling the development of complex business systems, NocoBase keeps the experience simple and intuitive.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;One-click switch between usage mode and configuration mode&lt;/li&gt; 
 &lt;li&gt;Pages serve as a canvas to arrange blocks and actions, similar to Notion&lt;/li&gt; 
 &lt;li&gt;Configuration mode is designed for ordinary users, not just programmers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static-docs.nocobase.com/wysiwyg.gif" alt="wysiwyg" /&gt;&lt;/p&gt; 
&lt;h3&gt;4. Everything is a plugin, designed for extension&lt;/h3&gt; 
&lt;p&gt;Adding more no-code features will never cover every business case. NocoBase is built for extension through its plugin-based microkernel architecture.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All functionalities are plugins, similar to WordPress&lt;/li&gt; 
 &lt;li&gt;Plugins are ready to use upon installation&lt;/li&gt; 
 &lt;li&gt;Pages, blocks, actions, APIs, and data sources can all be extended through custom plugins&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static-docs.nocobase.com/plugins.png" alt="plugins" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;NocoBase supports three installation methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a target="_blank" href="https://docs.nocobase.com/welcome/getting-started/installation/docker-compose"&gt;Installing With Docker (üëçRecommended)&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Suitable for no-code scenarios, no code to write. When upgrading, just download the latest image and reboot.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a target="_blank" href="https://docs.nocobase.com/welcome/getting-started/installation/create-nocobase-app"&gt;Installing from create-nocobase-app CLI&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The business code of the project is completely independent and supports low-code development.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a target="_blank" href="https://docs.nocobase.com/welcome/getting-started/installation/git-clone"&gt;Installing from Git source code&lt;/a&gt;&lt;/p&gt; &lt;p&gt;If you want to experience the latest unreleased version, or want to participate in the contribution, you need to make changes and debug on the source code, it is recommended to choose this installation method, which requires a high level of development skills, and if the code has been updated, you can git pull the latest code.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How NocoBase works&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/8d183b44-9bb5-4792-b08f-bc08fe8dfaaf"&gt;https://github.com/user-attachments/assets/8d183b44-9bb5-4792-b08f-bc08fe8dfaaf&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>topoteretes/cognee</title>
      <link>https://github.com/topoteretes/cognee</link>
      <description>&lt;p&gt;Memory for AI Agents in 6 lines of code&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/topoteretes/cognee"&gt; &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png" alt="Cognee Logo" height="60" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Cognee - Accurate and Persistent AI Memory&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=1bezuvLwJmw&amp;amp;t=2s"&gt;Demo&lt;/a&gt; . &lt;a href="https://docs.cognee.ai/"&gt;Docs&lt;/a&gt; . &lt;a href="https://cognee.ai"&gt;Learn More&lt;/a&gt; ¬∑ &lt;a href="https://discord.gg/NQPKmU5CCg"&gt;Join Discord&lt;/a&gt; ¬∑ &lt;a href="https://www.reddit.com/r/AIMemory/"&gt;Join r/AIMemory&lt;/a&gt; . &lt;a href="https://github.com/topoteretes/cognee-community"&gt;Community Plugins &amp;amp; Add-ons&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/topoteretes/cognee/network/"&gt;&lt;img src="https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;amp;label=Fork&amp;amp;maxAge=2592000" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/commit/"&gt;&lt;img src="https://badgen.net/github/commits/topoteretes/cognee" alt="GitHub commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/tags/"&gt;&lt;img src="https://badgen.net/github/tag/topoteretes/cognee" alt="GitHub tag" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/cognee"&gt;&lt;img src="https://static.pepy.tech/badge/cognee" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/topoteretes"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-‚ù§Ô∏è-ff69b4.svg" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://www.producthunt.com/posts/cognee?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cognee" target="_blank" style="display:inline-block; margin-right:10px;"&gt; &lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1744472480704" alt="cognee - Memory for AI Agents  in 5 lines of code | Product Hunt" width="250" height="54" /&gt; &lt;/a&gt; &lt;a href="https://trendshift.io/repositories/13955" target="_blank" style="display:inline-block;"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/13955" alt="topoteretes%2Fcognee | Trendshift" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;Use your data to build personalized and dynamic memory for AI Agents. Cognee lets you replace RAG with scalable and modular ECL (Extract, Cognify, Load) pipelines.&lt;/p&gt; 
 &lt;p align="center"&gt; üåê Available Languages : 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=fr"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
 &lt;div style="text-align: center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png" alt="Why cognee?" width="50%" /&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;About Cognee&lt;/h2&gt; 
&lt;p&gt;Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships.&lt;/p&gt; 
&lt;p&gt;You can use Cognee in two ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.cognee.ai/getting-started/installation"&gt;Self-host Cognee Open Source&lt;/a&gt;, which stores all data locally by default.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://platform.cognee.ai/"&gt;Connect to Cognee Cloud&lt;/a&gt;, and get the same OSS stack on managed infrastructure for easier development and productionization.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Cognee Open Source (self-hosted):&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interconnects any type of data ‚Äî including past conversations, files, images, and audio transcriptions&lt;/li&gt; 
 &lt;li&gt;Replaces traditional RAG systems with a unified memory layer built on graphs and vectors&lt;/li&gt; 
 &lt;li&gt;Reduces developer effort and infrastructure cost while improving quality and precision&lt;/li&gt; 
 &lt;li&gt;Provides Pythonic data pipelines for ingestion from 30+ data sources&lt;/li&gt; 
 &lt;li&gt;Offers high customizability through user-defined tasks, modular pipelines, and built-in search endpoints&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cognee Cloud (managed):&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hosted web UI dashboard&lt;/li&gt; 
 &lt;li&gt;Automatic version updates&lt;/li&gt; 
 &lt;li&gt;Resource usage analytics&lt;/li&gt; 
 &lt;li&gt;GDPR compliant, enterprise-grade security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Basic Usage &amp;amp; Feature Guide&lt;/h2&gt; 
&lt;p&gt;To learn more, &lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;check out this short, end-to-end Colab walkthrough&lt;/a&gt; of Cognee's core features.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Let‚Äôs try Cognee in just a few lines of code. For detailed setup and configuration, see the &lt;a href="https://docs.cognee.ai/getting-started/installation#environment-configuration"&gt;Cognee Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 to 3.12&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 1: Install Cognee&lt;/h3&gt; 
&lt;p&gt;You can install Cognee with &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt;, &lt;strong&gt;uv&lt;/strong&gt;, or your preferred Python package manager.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install cognee
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Configure the LLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ["LLM_API_KEY"] = "YOUR OPENAI_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, create a &lt;code&gt;.env&lt;/code&gt; file using our &lt;a href="https://github.com/topoteretes/cognee/raw/main/.env.template"&gt;template&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To integrate other LLM providers, see our &lt;a href="https://docs.cognee.ai/setup-configuration/llm-providers"&gt;LLM Provider Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Step 3: Run the Pipeline&lt;/h3&gt; 
&lt;p&gt;Cognee will take your documents, generate a knowledge graph from them and then query the graph based on combined relationships.&lt;/p&gt; 
&lt;p&gt;Now, run a minimal pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cognee
import asyncio


async def main():
    # Add text to cognee
    await cognee.add("Cognee turns documents into AI memory.")

    # Generate the knowledge graph
    await cognee.cognify()

    # Add memory algorithms to the graph
    await cognee.memify()

    # Query the knowledge graph
    results = await cognee.search("What does Cognee do?")

    # Display the results
    for result in results:
        print(result)


if __name__ == '__main__':
    asyncio.run(main())

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As you can see, the output is generated from the document we previously stored in Cognee:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  Cognee turns documents into AI memory.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use the Cognee CLI&lt;/h3&gt; 
&lt;p&gt;As an alternative, you can get started with these essential commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli add "Cognee turns documents into AI memory."

cognee-cli cognify

cognee-cli search "What does Cognee do?"
cognee-cli delete --all

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To open the local UI, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli -ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Demos &amp;amp; Examples&lt;/h2&gt; 
&lt;p&gt;See Cognee in action:&lt;/p&gt; 
&lt;h3&gt;Persistent Agent Memory&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/e113b628-7212-4a2b-b288-0be39a93a1c3"&gt;Cognee Memory for LangGraph Agents&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Simple GraphRAG&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f2186b2e-305a-42b0-9c2d-9f4473f15df8"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Cognee with Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/39672858-f774-4136-b957-1e2de67b8981"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions from the community! Your input helps make Cognee better for everyone. See &lt;a href="https://raw.githubusercontent.com/topoteretes/cognee/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;We're committed to fostering an inclusive and respectful community. Read our &lt;a href="https://github.com/topoteretes/cognee/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; for guidelines.&lt;/p&gt; 
&lt;h2&gt;Research &amp;amp; Citation&lt;/h2&gt; 
&lt;p&gt;We recently published a research paper on optimizing knowledge graphs for LLM reasoning:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{markovic2025optimizinginterfaceknowledgegraphs,
      title={Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning},
      author={Vasilije Markovic and Lazar Obradovic and Laszlo Hajdu and Jovan Pavlovic},
      year={2025},
      eprint={2505.24478},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.24478},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>mudler/LocalAI</title>
      <link>https://github.com/mudler/LocalAI</link>
      <description>&lt;p&gt;ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;img width="300" src="https://raw.githubusercontent.com/mudler/LocalAI/master/core/http/static/logo.png" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/go-skynet/LocalAI/fork" target="blank"&gt; &lt;img src="https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/stargazers" target="blank"&gt; &lt;img src="https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/pulls" target="blank"&gt; &lt;img src="https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI pull-requests" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/releases"&gt; &lt;img src="https://img.shields.io/github/release/go-skynet/LocalAI?&amp;amp;label=Latest&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://hub.docker.com/r/localai/localai" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker" alt="LocalAI Docker hub" /&gt; &lt;/a&gt; &lt;a href="https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;amp;tag=latest" target="blank"&gt; &lt;img src="https://img.shields.io/badge/quay.io-images-important.svg?" alt="LocalAI Quay.io" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://twitter.com/LocalAI_API" target="blank"&gt; &lt;img src="https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=white&amp;amp;label=LocalAI_API" alt="Follow LocalAI_API" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy" target="blank"&gt; &lt;img src="https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;amp;theme=default-inverted" alt="Join LocalAI Discord Community" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/5539" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/5539" alt="mudler%2FLocalAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;üí°&lt;/span&gt; Get help - &lt;a href="https://localai.io/faq/"&gt;‚ùìFAQ&lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/discussions"&gt;üí≠Discussions&lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy"&gt;&lt;span&gt;üí¨&lt;/span&gt; Discord&lt;/a&gt; &lt;a href="https://localai.io/"&gt;&lt;span&gt;üìñ&lt;/span&gt; Documentation website&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://localai.io/basics/getting_started/"&gt;üíª Quickstart&lt;/a&gt; &lt;a href="https://models.localai.io/"&gt;üñºÔ∏è Models&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;üöÄ Roadmap&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;üõ´ Examples&lt;/a&gt; Try on &lt;a href="https://t.me/localaiofficial_bot"&gt;&lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;amp;logo=telegram&amp;amp;logoColor=white" alt="Telegram" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg?sanitize=true" alt="tests" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Build and Release" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg?sanitize=true" alt="build container images" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg?sanitize=true" alt="Bump dependencies" /&gt;&lt;/a&gt;&lt;a href="https://artifacthub.io/packages/search?repo=localai"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;LocalAI&lt;/strong&gt; is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by &lt;a href="https://github.com/mudler"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìöüÜï Local Stack Family&lt;/h2&gt; 
&lt;p&gt;üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="300" alt="LocalAGI Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="300" alt="LocalRecall Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Talk Interface&lt;/th&gt; 
   &lt;th&gt;Generate Audio&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Models Overview&lt;/th&gt; 
   &lt;th&gt;Generate Images&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_gallery.png" alt="Screenshot 2025-03-31 at 12-01-20 LocalAI - Models" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_image.png" alt="Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chat Interface&lt;/th&gt; 
   &lt;th&gt;Home&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_chat.png" alt="Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_home.png" alt="Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Login&lt;/th&gt; 
   &lt;th&gt;Swarm&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_login.png" alt="Screenshot 2025-03-31 at 12-09-59 " /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_p2p.png" alt="Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üíª Quickstart&lt;/h2&gt; 
&lt;p&gt;Run the installer script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
curl https://localai.io/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more installation options, see &lt;a href="https://localai.io/docs/advanced/installer/"&gt;Installer Options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS Download:&lt;/h3&gt; 
&lt;a href="https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg"&gt; &lt;img src="https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Download LocalAI for macOS" /&gt; &lt;/a&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: the DMGs are not signed by Apple as quarantined. See &lt;a href="https://github.com/mudler/LocalAI/issues/6268"&gt;https://github.com/mudler/LocalAI/issues/6268&lt;/a&gt; for a workaround, fix is tracked here: &lt;a href="https://github.com/mudler/LocalAI/issues/6244"&gt;https://github.com/mudler/LocalAI/issues/6244&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Or run with docker:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Docker Run vs Docker Start&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker run&lt;/code&gt; creates and starts a new container. If a container with the same name already exists, this command will fail.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;docker start&lt;/code&gt; starts an existing container that was previously created with &lt;code&gt;docker run&lt;/code&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you've already run LocalAI before and want to start it again, use: &lt;code&gt;docker start -i local-ai&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;CPU only image:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;NVIDIA GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AMD GPU Images (ROCm):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Intel GPU Images (oneAPI):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Vulkan GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AIO Images (pre-downloaded models):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information about the AIO images and pre-downloaded models, see &lt;a href="https://localai.io/basics/container/"&gt;Container Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To load models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö° &lt;strong&gt;Automatic Backend Detection&lt;/strong&gt;: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see &lt;a href="https://localai.io/features/gpu-acceleration/#automatic-backend-detection"&gt;GPU Acceleration&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more information, see &lt;a href="https://localai.io/basics/getting_started/index.html"&gt;üíª Getting started&lt;/a&gt;, if you are interested in our roadmap items and future enhancements, you can see the &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;Issues labeled as Roadmap here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ Latest project news&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;October 2025: üîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; support added for agentic capabilities with external tools&lt;/li&gt; 
 &lt;li&gt;September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.&lt;/li&gt; 
 &lt;li&gt;August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with &lt;code&gt;development&lt;/code&gt; suffix in the gallery ): &lt;a href="https://github.com/mudler/LocalAI/pull/6049"&gt;https://github.com/mudler/LocalAI/pull/6049&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6119"&gt;https://github.com/mudler/LocalAI/pull/6119&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6121"&gt;https://github.com/mudler/LocalAI/pull/6121&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6060"&gt;https://github.com/mudler/LocalAI/pull/6060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July/August 2025: üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt; added to the API featuring &lt;a href="https://github.com/roboflow/rf-detr"&gt;rf-detr&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v3.2.0"&gt;Read the release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;Backend management&lt;/a&gt; has been added. Attention: extras images are going to be deprecated from the next release! Read &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;the backend management PR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5466"&gt;Audio input&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/5396"&gt;Reranking&lt;/a&gt; in llama.cpp backend, &lt;a href="https://github.com/mudler/LocalAI/pull/5392"&gt;Realtime API&lt;/a&gt;, Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).&lt;/li&gt; 
 &lt;li&gt;May 2025: Important: image name changes &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v2.29.0"&gt;See release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apr 2025: Rebrand, WebUI enhancements&lt;/li&gt; 
 &lt;li&gt;Apr 2025: &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt; join the LocalAI family stack.&lt;/li&gt; 
 &lt;li&gt;Apr 2025: WebUI overhaul, AIO images updates&lt;/li&gt; 
 &lt;li&gt;Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images&lt;/li&gt; 
 &lt;li&gt;Jan 2025: LocalAI model release: &lt;a href="https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3"&gt;https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3&lt;/a&gt;, SANA support in diffusers: &lt;a href="https://github.com/mudler/LocalAI/pull/4603"&gt;https://github.com/mudler/LocalAI/pull/4603&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dec 2024: stablediffusion.cpp backend (ggml) added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4289"&gt;https://github.com/mudler/LocalAI/pull/4289&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Bark.cpp backend added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4287"&gt;https://github.com/mudler/LocalAI/pull/4287&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Voice activity detection models (&lt;strong&gt;VAD&lt;/strong&gt;) added to the API: &lt;a href="https://github.com/mudler/LocalAI/pull/4204"&gt;https://github.com/mudler/LocalAI/pull/4204&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oct 2024: examples moved to &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;LocalAI-examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Aug 2024: üÜï FLUX-1, &lt;a href="https://explorer.localai.io"&gt;P2P Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: &lt;a href="https://github.com/mudler/LocalAI/pull/2723"&gt;https://github.com/mudler/LocalAI/pull/2723&lt;/a&gt;. P2P Global community pools: &lt;a href="https://github.com/mudler/LocalAI/issues/3113"&gt;https://github.com/mudler/LocalAI/issues/3113&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Decentralized P2P llama.cpp: &lt;a href="https://github.com/mudler/LocalAI/pull/2343"&gt;https://github.com/mudler/LocalAI/pull/2343&lt;/a&gt; (peer2peer llama.cpp!) üëâ Docs &lt;a href="https://localai.io/features/distribute/"&gt;https://localai.io/features/distribute/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Distributed inferencing: &lt;a href="https://github.com/mudler/LocalAI/pull/2324"&gt;https://github.com/mudler/LocalAI/pull/2324&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 2024: Reranker API: &lt;a href="https://github.com/mudler/LocalAI/pull/2121"&gt;https://github.com/mudler/LocalAI/pull/2121&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Roadmap items: &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;List of issues&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ &lt;a href="https://localai.io/features/"&gt;Features&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß© &lt;a href="https://localai.io/backends/"&gt;Backend Gallery&lt;/a&gt;: Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://localai.io/features/text-generation/"&gt;Text generation with GPTs&lt;/a&gt; (&lt;code&gt;llama.cpp&lt;/code&gt;, &lt;code&gt;transformers&lt;/code&gt;, &lt;code&gt;vllm&lt;/code&gt; ... &lt;a href="https://localai.io/model-compatibility/index.html#model-compatibility-table"&gt;&lt;span&gt;üìñ&lt;/span&gt; and more&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üó£ &lt;a href="https://localai.io/features/text-to-audio/"&gt;Text to Audio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîà &lt;a href="https://localai.io/features/audio-to-text/"&gt;Audio to Text&lt;/a&gt; (Audio transcription with &lt;code&gt;whisper.cpp&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üé® &lt;a href="https://localai.io/features/image-generation"&gt;Image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî• &lt;a href="https://localai.io/features/openai-functions/"&gt;OpenAI-alike tools API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß† &lt;a href="https://localai.io/features/embeddings/"&gt;Embeddings generation for vector databases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;a href="https://localai.io/features/constrained_grammars/"&gt;Constrained grammars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üñºÔ∏è &lt;a href="https://localai.io/models/"&gt;Download Models directly from Huggingface &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü•Ω &lt;a href="https://localai.io/features/gpt-vision/"&gt;Vision API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://localai.io/features/reranker/"&gt;Reranker API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüñß &lt;a href="https://localai.io/features/distribute/"&gt;P2P Inferencing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; - Agentic capabilities with external tools and &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI's Agentic capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîä Voice activity detection (Silero-VAD support)&lt;/li&gt; 
 &lt;li&gt;üåç Integrated WebUI!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© Supported Backends &amp;amp; Acceleration&lt;/h2&gt; 
&lt;p&gt;LocalAI supports a comprehensive range of AI backends with multiple acceleration options:&lt;/p&gt; 
&lt;h3&gt;Text Generation &amp;amp; Language Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM inference in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel SYCL, Vulkan, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast LLM inference with PagedAttention&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;transformers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace transformers framework&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;exllama2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GPTQ inference library&lt;/td&gt; 
   &lt;td&gt;CUDA 12&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon LLM inference&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX-VLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon Vision-Language Models&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Audio &amp;amp; Speech Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;whisper.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Whisper in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;faster-whisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast Whisper with CTranslate2&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-audio generation&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark-cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;C++ implementation of Bark&lt;/td&gt; 
   &lt;td&gt;CUDA, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;coqui&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Advanced TTS with 1100+ languages&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kokoro&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight TTS model&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;chatterbox&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Production-grade TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;piper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast neural TTS system&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kitten-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Kitten TTS models&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;silero-vad&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;neutts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-speech with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Image &amp;amp; Video Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;stablediffusion.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Stable Diffusion in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;diffusers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace diffusion models&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Specialized AI Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rfdetr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time object detection&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rerankers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document reranking API&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;local-store&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Vector database&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;huggingface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace API integration&lt;/td&gt; 
   &lt;td&gt;API-based&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Acceleration Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Acceleration Type&lt;/th&gt; 
   &lt;th&gt;Supported Backends&lt;/th&gt; 
   &lt;th&gt;Hardware Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 11&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rerankers, bark, chatterbox&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 12&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AMD ROCm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts&lt;/td&gt; 
   &lt;td&gt;AMD Graphics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Intel oneAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark&lt;/td&gt; 
   &lt;td&gt;Intel Arc, Intel iGPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apple Metal&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp&lt;/td&gt; 
   &lt;td&gt;Apple M1/M2/M3+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vulkan&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion&lt;/td&gt; 
   &lt;td&gt;Cross-platform GPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;CPU Optimized&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All backends&lt;/td&gt; 
   &lt;td&gt;AVX/AVX2/AVX512, quantization support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üîó Community and integrations&lt;/h3&gt; 
&lt;p&gt;Build and deploy custom containers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sozercan/aikit"&gt;https://github.com/sozercan/aikit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;WebUIs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jirubizu/localai-admin"&gt;https://github.com/Jirubizu/localai-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/LocalAI-frontend"&gt;https://github.com/go-skynet/LocalAI-frontend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) &lt;a href="https://github.com/reid41/QA-Pilot"&gt;https://github.com/reid41/QA-Pilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Agentic Libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/cogito"&gt;https://github.com/mudler/cogito&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCPs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/MCPs"&gt;https://github.com/mudler/MCPs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model galleries&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/model-gallery"&gt;https://github.com/go-skynet/model-gallery&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Voice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richiejp/VoxInput"&gt;https://github.com/richiejp/VoxInput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm chart &lt;a href="https://github.com/go-skynet/helm-charts"&gt;https://github.com/go-skynet/helm-charts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VSCode extension &lt;a href="https://github.com/badgooooor/localai-vscode-plugin"&gt;https://github.com/badgooooor/localai-vscode-plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Langchain: &lt;a href="https://python.langchain.com/docs/integrations/providers/localai/"&gt;https://python.langchain.com/docs/integrations/providers/localai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Terminal utility &lt;a href="https://github.com/djcopley/ShellOracle"&gt;https://github.com/djcopley/ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local Smart assistant &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Home Assistant &lt;a href="https://github.com/sammcj/homeassistant-localai"&gt;https://github.com/sammcj/homeassistant-localai&lt;/a&gt; / &lt;a href="https://github.com/drndos/hass-openai-custom-conversation"&gt;https://github.com/drndos/hass-openai-custom-conversation&lt;/a&gt; / &lt;a href="https://github.com/valentinfrlch/ha-gpt4vision"&gt;https://github.com/valentinfrlch/ha-gpt4vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/discord"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/slack"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) &lt;a href="https://github.com/reid41/shell-pilot"&gt;https://github.com/reid41/shell-pilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram bot &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot"&gt;https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Another Telegram Bot &lt;a href="https://github.com/JackBekket/Hellper"&gt;https://github.com/JackBekket/Hellper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Auto-documentation &lt;a href="https://github.com/JackBekket/Reflexia"&gt;https://github.com/JackBekket/Reflexia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github bot which answer on issues, with code and documentation as context &lt;a href="https://github.com/JackBekket/GitHelper"&gt;https://github.com/JackBekket/GitHelper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github Actions: &lt;a href="https://github.com/marketplace/actions/start-localai"&gt;https://github.com/marketplace/actions/start-localai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Examples: &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/"&gt;https://github.com/mudler/LocalAI/tree/master/examples/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/advanced/fine-tuning/"&gt;LLM finetuning guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/build/index.html"&gt;How to build locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes"&gt;How to install in Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/integrations/"&gt;Projects integrating LocalAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://io.midori-ai.xyz/howtos/"&gt;How tos section&lt;/a&gt; (curated by our community)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;üìñ&lt;/span&gt; üé• &lt;a href="https://localai.io/basics/news/#media-blogs-social"&gt;Media, Blogs, Social&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.suse.com/c/running-ai-locally/"&gt;Run Visual studio code with LocalAI (SUSE)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://mudler.pm/posts/local-ai-jetson-nano-devkit/"&gt;Run LocalAI on Jetson Nano Devkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/"&gt;Run LocalAI on AWS EKS with Pulumi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance"&gt;Run LocalAI on AWS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/smart-slackbot-for-teams/"&gt;Create a slackbot for teams and OSS projects that answer to documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PKrDNuJ_dfE"&gt;LocalAI meets k8sgpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/localai-question-answering/"&gt;Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65"&gt;Tutorial to use k8sgpt with LocalAI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/go-skynet/LocalAI}},
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ù§Ô∏è Sponsors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Do you find LocalAI useful?&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Support the project by becoming &lt;a href="https://github.com/sponsors/mudler"&gt;a backer or sponsor&lt;/a&gt;. Your logo will show up here with a link to your website.&lt;/p&gt; 
&lt;p&gt;A huge thank you to our generous sponsors who support this project covering CI expenses, and our &lt;a href="https://github.com/sponsors/mudler"&gt;Sponsor list&lt;/a&gt;:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.spectrocloud.com/" target="blank"&gt; &lt;img height="200" src="https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962" /&gt; &lt;/a&gt; &lt;a href="https://www.premai.io/" target="blank"&gt; &lt;img height="200" src="https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6" /&gt; &lt;br /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üåü Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#go-skynet/LocalAI&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=go-skynet/LocalAI&amp;amp;type=Date" alt="LocalAI Star history Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ License&lt;/h2&gt; 
&lt;p&gt;LocalAI is a community-driven project created by &lt;a href="https://github.com/mudler/"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;MIT - Author Ettore Di Giacinto &lt;a href="mailto:mudler@localai.io"&gt;mudler@localai.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üôá Acknowledgements&lt;/h2&gt; 
&lt;p&gt;LocalAI couldn't have been built without the help of great software already available from the community. Thank you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cornelk/llama-go"&gt;https://github.com/cornelk/llama-go&lt;/a&gt; for the initial ideas&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/antimatter15/alpaca.cpp"&gt;https://github.com/antimatter15/alpaca.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EdVince/Stable-Diffusion-NCNN"&gt;https://github.com/EdVince/Stable-Diffusion-NCNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;https://github.com/ggerganov/whisper.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rhasspy/piper"&gt;https://github.com/rhasspy/piper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ó Contributors&lt;/h2&gt; 
&lt;p&gt;This is a community project, a special thanks to our contributors! ü§ó &lt;a href="https://github.com/go-skynet/LocalAI/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=go-skynet/LocalAI" /&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>666ghj/BettaFish</title>
      <link>https://github.com/666ghj/BettaFish</link>
      <description>&lt;p&gt;ÂæÆËàÜÔºö‰∫∫‰∫∫ÂèØÁî®ÁöÑÂ§öAgentËàÜÊÉÖÂàÜÊûêÂä©ÊâãÔºåÊâìÁ†¥‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñÔºÅ‰ªé0ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÊ°ÜÊû∂„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_compressed.png" alt="BettaFish Logo" width="100%" /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15286" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15286" alt="666ghj%2FBettaFish | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;‚ÄÇ &lt;a href="https://lioncc.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;‚ÄÇ &lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/666ghj/BettaFish?style=flat-square" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/666ghj/BettaFish?style=flat-square" alt="GitHub Watchers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/network"&gt;&lt;img src="https://img.shields.io/github/forks/666ghj/BettaFish?style=flat-square" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;&lt;img src="https://img.shields.io/github/issues/666ghj/BettaFish?style=flat-square" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/666ghj/BettaFish?style=flat-square" alt="GitHub Pull Requests" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/666ghj/BettaFish?style=flat-square" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish"&gt;&lt;img src="https://img.shields.io/badge/version-v1.1.2-green.svg?style=flat-square" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/"&gt;&lt;img src="https://img.shields.io/badge/Docker-Build-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README-EN.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README.md"&gt;‰∏≠ÊñáÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ö° È°πÁõÆÊ¶ÇËø∞&lt;/h2&gt; 
&lt;p&gt;‚Äú&lt;strong&gt;ÂæÆËàÜ&lt;/strong&gt;‚Äù ÊòØ‰∏Ä‰∏™‰ªé0ÂÆûÁé∞ÁöÑÂàõÊñ∞Âûã Â§öÊô∫ËÉΩ‰Ωì ËàÜÊÉÖÂàÜÊûêÁ≥ªÁªüÔºåÂ∏ÆÂä©Â§ßÂÆ∂Á†¥Èô§‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñ„ÄÇÁî®Êà∑Âè™ÈúÄÂÉèËÅäÂ§©‰∏ÄÊ†∑ÊèêÂá∫ÂàÜÊûêÈúÄÊ±ÇÔºåÊô∫ËÉΩ‰ΩìÂºÄÂßãÂÖ®Ëá™Âä®ÂàÜÊûê ÂõΩÂÜÖÂ§ñ30+‰∏ªÊµÅÁ§æÂ™í ‰∏é Êï∞Áôæ‰∏áÊù°Â§ß‰ºóËØÑËÆ∫„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ÄúÂæÆËàÜ‚ÄùË∞êÈü≥‚ÄúÂæÆÈ±º‚ÄùÔºåBettaFishÊòØ‰∏ÄÁßç‰ΩìÂûãÂæàÂ∞è‰ΩÜÈùûÂ∏∏Â•ΩÊñó„ÄÅÊºÇ‰∫ÆÁöÑÈ±ºÔºåÂÆÉË±°ÂæÅÁùÄ‚ÄúÂ∞èËÄåÂº∫Â§ßÔºå‰∏çÁïèÊåëÊàò‚Äù&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Êü•ÁúãÁ≥ªÁªü‰ª•‚ÄúÊ≠¶Ê±âÂ§ßÂ≠¶ËàÜÊÉÖ‚Äù‰∏∫‰æãÔºåÁîüÊàêÁöÑÁ†îÁ©∂Êä•ÂëäÔºö&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/final_reports/final_report__20250827_131630.html"&gt;Ê≠¶Ê±âÂ§ßÂ≠¶ÂìÅÁâåÂ£∞Ë™âÊ∑±Â∫¶ÂàÜÊûêÊä•Âëä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Êü•ÁúãÁ≥ªÁªü‰ª•‚ÄúÊ≠¶Ê±âÂ§ßÂ≠¶ËàÜÊÉÖ‚Äù‰∏∫‰æãÔºå‰∏ÄÊ¨°ÂÆåÊï¥ËøêË°åÁöÑËßÜÈ¢ëÔºö&lt;a href="https://www.bilibili.com/video/BV1TH1WBxEWN/?vd_source=da3512187e242ce17dceee4c537ec7a6#reply279744466833"&gt;ËßÜÈ¢ë-Ê≠¶Ê±âÂ§ßÂ≠¶ÂìÅÁâåÂ£∞Ë™âÊ∑±Â∫¶ÂàÜÊûêÊä•Âëä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‰∏ç‰ªÖ‰ªÖ‰ΩìÁé∞Âú®Êä•ÂëäË¥®Èáè‰∏äÔºåÁõ∏ÊØîÂêåÁ±ª‰∫ßÂìÅÔºåÊàë‰ª¨Êã•ÊúâüöÄÂÖ≠Â§ß‰ºòÂäøÔºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIÈ©±Âä®ÁöÑÂÖ®ÂüüÁõëÊéß&lt;/strong&gt;ÔºöAIÁà¨Ëô´ÈõÜÁæ§7x24Â∞èÊó∂‰∏çÈó¥Êñ≠‰Ωú‰∏öÔºåÂÖ®Èù¢Ë¶ÜÁõñÂæÆÂçö„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÊäñÈü≥„ÄÅÂø´ÊâãÁ≠â10+ÂõΩÂÜÖÂ§ñÂÖ≥ÈîÆÁ§æÂ™í„ÄÇ‰∏ç‰ªÖÂÆûÊó∂ÊçïËé∑ÁÉ≠ÁÇπÂÜÖÂÆπÔºåÊõ¥ËÉΩ‰∏ãÈíªËá≥Êµ∑ÈáèÁî®Êà∑ËØÑËÆ∫ÔºåËÆ©ÊÇ®Âê¨Âà∞ÊúÄÁúüÂÆû„ÄÅÊúÄÂπøÊ≥õÁöÑÂ§ß‰ºóÂ£∞Èü≥„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ë∂ÖË∂äLLMÁöÑÂ§çÂêàÂàÜÊûêÂºïÊìé&lt;/strong&gt;ÔºöÊàë‰ª¨‰∏ç‰ªÖ‰æùËµñËÆæËÆ°ÁöÑ5Á±ª‰∏ì‰∏öAgentÔºåÊõ¥ËûçÂêà‰∫ÜÂæÆË∞ÉÊ®°Âûã„ÄÅÁªüËÆ°Ê®°ÂûãÁ≠â‰∏≠Èó¥‰ª∂„ÄÇÈÄöËøáÂ§öÊ®°ÂûãÂçèÂêåÂ∑•‰ΩúÔºåÁ°Æ‰øù‰∫ÜÂàÜÊûêÁªìÊûúÁöÑÊ∑±Â∫¶„ÄÅÂáÜÂ∫¶‰∏éÂ§öÁª¥ËßÜËßí„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅËÉΩÂäõ&lt;/strong&gt;ÔºöÁ™ÅÁ†¥ÂõæÊñáÈôêÂà∂ÔºåËÉΩÊ∑±Â∫¶Ëß£ÊûêÊäñÈü≥„ÄÅÂø´ÊâãÁ≠âÁü≠ËßÜÈ¢ëÂÜÖÂÆπÔºåÂπ∂Á≤æÂáÜÊèêÂèñÁé∞‰ª£ÊêúÁ¥¢ÂºïÊìé‰∏≠ÁöÑÂ§©Ê∞î„ÄÅÊó•ÂéÜ„ÄÅËÇ°Á•®Á≠âÁªìÊûÑÂåñÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÂç°ÁâáÔºåËÆ©ÊÇ®ÂÖ®Èù¢ÊéåÊè°ËàÜÊÉÖÂä®ÊÄÅ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Agent‚ÄúËÆ∫Âùõ‚ÄùÂçè‰ΩúÊú∫Âà∂&lt;/strong&gt;Ôºö‰∏∫‰∏çÂêåAgentËµã‰∫àÁã¨ÁâπÁöÑÂ∑•ÂÖ∑ÈõÜ‰∏éÊÄùÁª¥Ê®°ÂºèÔºåÂºïÂÖ•Ëæ©ËÆ∫‰∏ªÊåÅ‰∫∫Ê®°ÂûãÔºåÈÄöËøá‚ÄúËÆ∫Âùõ‚ÄùÊú∫Âà∂ËøõË°åÈìæÂºèÊÄùÁª¥Á¢∞Êíû‰∏éËæ©ËÆ∫„ÄÇËøô‰∏ç‰ªÖÈÅøÂÖç‰∫ÜÂçï‰∏ÄÊ®°ÂûãÁöÑÊÄùÁª¥Â±ÄÈôê‰∏é‰∫§ÊµÅÂØºËá¥ÁöÑÂêåË¥®ÂåñÔºåÊõ¥ÂÇ¨ÁîüÂá∫Êõ¥È´òË¥®ÈáèÁöÑÈõÜ‰ΩìÊô∫ËÉΩ‰∏éÂÜ≥Á≠ñÊîØÊåÅ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂÖ¨ÁßÅÂüüÊï∞ÊçÆÊó†ÁºùËûçÂêà&lt;/strong&gt;ÔºöÂπ≥Âè∞‰∏ç‰ªÖÂàÜÊûêÂÖ¨ÂºÄËàÜÊÉÖÔºåËøòÊèê‰æõÈ´òÂÆâÂÖ®ÊÄßÁöÑÊé•Âè£ÔºåÊîØÊåÅÊÇ®Â∞ÜÂÜÖÈÉ®‰∏öÂä°Êï∞ÊçÆÂ∫ì‰∏éËàÜÊÉÖÊï∞ÊçÆÊó†ÁºùÈõÜÊàê„ÄÇÊâìÈÄöÊï∞ÊçÆÂ£ÅÂûíÔºå‰∏∫ÂûÇÁõ¥‰∏öÂä°Êèê‰æõ‚ÄúÂ§ñÈÉ®Ë∂ãÂäø+ÂÜÖÈÉ®Ê¥ûÂØü‚ÄùÁöÑÂº∫Â§ßÂàÜÊûêËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ËΩªÈáèÂåñ‰∏éÈ´òÊâ©Â±ïÊÄßÊ°ÜÊû∂&lt;/strong&gt;ÔºöÂü∫‰∫éÁ∫ØPythonÊ®°ÂùóÂåñËÆæËÆ°ÔºåÂÆûÁé∞ËΩªÈáèÂåñ„ÄÅ‰∏ÄÈîÆÂºèÈÉ®ÁΩ≤„ÄÇ‰ª£Á†ÅÁªìÊûÑÊ∏ÖÊô∞ÔºåÂºÄÂèëËÄÖÂèØËΩªÊùæÈõÜÊàêËá™ÂÆö‰πâÊ®°Âûã‰∏é‰∏öÂä°ÈÄªËæëÔºåÂÆûÁé∞Âπ≥Âè∞ÁöÑÂø´ÈÄüÊâ©Â±ï‰∏éÊ∑±Â∫¶ÂÆöÂà∂„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Âßã‰∫éËàÜÊÉÖÔºåËÄå‰∏çÊ≠¢‰∫éËàÜÊÉÖ&lt;/strong&gt;„ÄÇ‚ÄúÂæÆËàÜ‚ÄùÁöÑÁõÆÊ†áÔºåÊòØÊàê‰∏∫È©±Âä®‰∏ÄÂàá‰∏öÂä°Âú∫ÊôØÁöÑÁÆÄÊ¥ÅÈÄöÁî®ÁöÑÊï∞ÊçÆÂàÜÊûêÂºïÊìé„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏æ‰∏™‰æãÂ≠ê. ‰Ω†Âè™ÈúÄÁÆÄÂçï‰øÆÊîπAgentÂ∑•ÂÖ∑ÈõÜÁöÑapiÂèÇÊï∞‰∏épromptÔºåÂ∞±ÂèØ‰ª•Êää‰ªñÂèòÊàê‰∏Ä‰∏™ÈáëËûçÈ¢ÜÂüüÁöÑÂ∏ÇÂú∫ÂàÜÊûêÁ≥ªÁªü&lt;/p&gt; 
 &lt;p&gt;ÈôÑ‰∏Ä‰∏™ÊØîËæÉÊ¥ªË∑ÉÁöÑLÁ´ôÈ°πÁõÆËÆ®ËÆ∫Â∏ñÔºö&lt;a href="https://linux.do/t/topic/1009280"&gt;https://linux.do/t/topic/1009280&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/system_schematic.png" alt="banner" width="800" /&gt; 
 &lt;p&gt;ÂëäÂà´‰º†ÁªüÁöÑÊï∞ÊçÆÁúãÊùøÔºåÂú®‚ÄúÂæÆËàÜ‚ÄùÔºå‰∏ÄÂàáÁî±‰∏Ä‰∏™ÁÆÄÂçïÁöÑÈóÆÈ¢òÂºÄÂßãÔºåÊÇ®Âè™ÈúÄÂÉèÂØπËØù‰∏ÄÊ†∑ÔºåÊèêÂá∫ÊÇ®ÁöÑÂàÜÊûêÈúÄÊ±Ç&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ü™Ñ ËµûÂä©ÂïÜ&lt;/h2&gt; 
&lt;p&gt;LLMÊ®°ÂûãAPIËµûÂä©Ôºö&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;(ÁÇπÂºÄ‚ñ∂ÊúâËµûÂä©LLMÁÆóÂäõÁ¶èÂà©)ÁºñÁ®ãÊãºËΩ¶codecodex.aiÔºõÁºñÁ®ãÁÆóÂäõVibeCodingAPI.aiÔºö&lt;span style="margin-left: 10px"&gt;&lt;a href="https://codecodex.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÊâÄÁΩóÈó®ÂçöÂÆ¢LionCC.aiÂ∑≤Êõ¥Êñ∞„ÄäBettaFish ÂæÆËàÜÁ≥ªÁªü - LionCC API ÈÉ®ÁΩ≤ÈÖçÁΩÆÂÆåÂÖ®ÊåáÂçó„ÄãÊ≠£Âú®‰∫åÂºÄ‰ºòÂåñ‰∏ÄÈîÆÈÉ®ÁΩ≤Âíå‰∫ëÊúçÂä°Âô®Ë∞ÉÁî®ÊñπÊ°à„ÄÇ&lt;/li&gt; 
  &lt;li&gt;VibeCodingapi.aiÁãÆÂ≠êÁÆóÂäõÂπ≥Âè∞Â∑≤ÁªèÈÄÇÈÖç„ÄäBettaFish ÂæÆËàÜÁ≥ªÁªü„ÄãÊâÄÊúâLLMÊ®°ÂûãÂê´claude codeÂíåopenai codexÂíågemini cliÁºñÁ®ãÂºÄÂèë‰∏âÂ∑®Â§¥ÁÆóÂäõ„ÄÇÈ¢ùÂ∫¶‰ª∑Ê†ºÔºåÂè™Ë¶Å‰∏ÄÊØî‰∏ÄÔºà100ÂÖÉÁ≠â‰∫é100ÁæéÂàÄÈ¢ùÂ∫¶Ôºâ&lt;/li&gt; 
  &lt;li&gt;Codecodex.aiÁãÆÂ≠êÁºñÁ®ãÊãºËΩ¶Á≥ªÁªüÔºåÂ∑≤ÂÆûÁé∞Êó†IPÈó®ÊßõÁªïËøáclaude codeÂíåopenai codexÂ∞ÅÈîÅÔºåÊåâÂÆòÊñπÈÉ®ÁΩ≤ÊïôÁ®ãÂêéÂàáÊç¢BASE_URLË∞ÉÁî®Âú∞ÂùÄÂíåToken keyË∞ÉÁî®ÂØÜÈí•Âç≥ÂèØ‰ΩøÁî®ÊúÄÂº∫ÁºñÁ®ãÊ®°Âûã„ÄÇ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;ÊâÄÁΩóÈó®LionCCËµûÂä©BettaFish ÂæÆËàÜÁ¶èÂà©ÔºöÊâìÂºÄcodecodex.aiÁãÆÂ≠êÁºñÁ®ãÈ¢ëÈÅìÊâ´Á†ÅÂä†ÂÖ•ÂæÆ‰ø°Á§æÁæ§ÔºåÊ≥®ÂÜåVibeCodingapi.aiÁãÆÂ≠êÁÆóÂäõÔºåÁªü‰∏ÄÈÄÅ20ÂàÄAPIÈ¢ùÂ∫¶Ôºà‰ªÖÈôêÂâç‰∏ÄÂçÉÂêçÔºâ&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ÊåâÁî®Èáè‰ªòË¥πÁöÑ‰ºÅ‰∏öÁ∫ßAIËµÑÊ∫êÂπ≥Âè∞ÔºåÊèê‰æõÂ∏ÇÂú∫‰∏äÂÖ®Èù¢ÁöÑAIÊ®°ÂûãÂíåAPIÔºå‰ª•ÂèäÂ§öÁßçÂú®Á∫øAIÂ∫îÁî®Ôºö&lt;span style="margin-left: 10px"&gt;&lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_302ai_ch.jpg" alt="banner" /&gt;302.AIÊòØ‰∏Ä‰∏™ÊåâÁî®Èáè‰ªòË¥πÁöÑ‰ºÅ‰∏öÁ∫ßAIËµÑÊ∫êÂπ≥Âè∞ÔºåÊèê‰æõÂ∏ÇÂú∫‰∏äÊúÄÊñ∞„ÄÅÊúÄÂÖ®Èù¢ÁöÑAIÊ®°ÂûãÂíåAPIÔºå‰ª•ÂèäÂ§öÁßçÂºÄÁÆ±Âç≥Áî®ÁöÑÂú®Á∫øAIÂ∫îÁî®„ÄÇ 
&lt;/details&gt; 
&lt;h2&gt;üèóÔ∏è Á≥ªÁªüÊû∂ÊûÑ&lt;/h2&gt; 
&lt;h3&gt;Êï¥‰ΩìÊû∂ÊûÑÂõæ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Insight Agent&lt;/strong&gt; ÁßÅÊúâÊï∞ÊçÆÂ∫ìÊåñÊéòÔºöÁßÅÊúâËàÜÊÉÖÊï∞ÊçÆÂ∫ìÊ∑±Â∫¶ÂàÜÊûêAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Media Agent&lt;/strong&gt; Â§öÊ®°ÊÄÅÂÜÖÂÆπÂàÜÊûêÔºöÂÖ∑Â§áÂº∫Â§ßÂ§öÊ®°ÊÄÅËÉΩÂäõÁöÑAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Query Agent&lt;/strong&gt; Á≤æÂáÜ‰ø°ÊÅØÊêúÁ¥¢ÔºöÂÖ∑Â§áÂõΩÂÜÖÂ§ñÁΩëÈ°µÊêúÁ¥¢ËÉΩÂäõÁöÑAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Report Agent&lt;/strong&gt; Êô∫ËÉΩÊä•ÂëäÁîüÊàêÔºöÂÜÖÁΩÆÊ®°ÊùøÁöÑÂ§öËΩÆÊä•ÂëäÁîüÊàêAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/framework.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;‰∏ÄÊ¨°ÂÆåÊï¥ÂàÜÊûêÊµÅÁ®ã&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ê≠•È™§&lt;/th&gt; 
   &lt;th&gt;Èò∂ÊÆµÂêçÁß∞&lt;/th&gt; 
   &lt;th&gt;‰∏ªË¶ÅÊìç‰Ωú&lt;/th&gt; 
   &lt;th&gt;ÂèÇ‰∏éÁªÑ‰ª∂&lt;/th&gt; 
   &lt;th&gt;Âæ™ÁéØÁâπÊÄß&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;Áî®Êà∑ÊèêÈóÆ&lt;/td&gt; 
   &lt;td&gt;Flask‰∏ªÂ∫îÁî®Êé•Êî∂Êü•ËØ¢&lt;/td&gt; 
   &lt;td&gt;Flask‰∏ªÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;Âπ∂Ë°åÂêØÂä®&lt;/td&gt; 
   &lt;td&gt;‰∏â‰∏™AgentÂêåÊó∂ÂºÄÂßãÂ∑•‰Ωú&lt;/td&gt; 
   &lt;td&gt;Query Agent„ÄÅMedia Agent„ÄÅInsight Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;ÂàùÊ≠•ÂàÜÊûê&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent‰ΩøÁî®‰∏ìÂ±ûÂ∑•ÂÖ∑ËøõË°åÊ¶ÇËßàÊêúÁ¥¢&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + ‰∏ìÂ±ûÂ∑•ÂÖ∑ÈõÜ&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;Á≠ñÁï•Âà∂ÂÆö&lt;/td&gt; 
   &lt;td&gt;Âü∫‰∫éÂàùÊ≠•ÁªìÊûúÂà∂ÂÆöÂàÜÂùóÁ†îÁ©∂Á≠ñÁï•&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÂÜÖÈÉ®ÂÜ≥Á≠ñÊ®°Âùó&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5-N&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Âæ™ÁéØÈò∂ÊÆµ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ËÆ∫ÂùõÂçè‰Ωú + Ê∑±Â∫¶Á†îÁ©∂&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ForumEngine + ÊâÄÊúâAgent&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Â§öËΩÆÂæ™ÁéØ&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;Ê∑±Â∫¶Á†îÁ©∂&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÂü∫‰∫éËÆ∫Âùõ‰∏ªÊåÅ‰∫∫ÂºïÂØºËøõË°å‰∏ìÈ°πÊêúÁ¥¢&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + ÂèçÊÄùÊú∫Âà∂ + ËÆ∫ÂùõÂºïÂØº&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;ËÆ∫ÂùõÂçè‰Ωú&lt;/td&gt; 
   &lt;td&gt;ForumEngineÁõëÊéßAgentÂèëË®ÄÂπ∂ÁîüÊàê‰∏ªÊåÅ‰∫∫ÊÄªÁªì&lt;/td&gt; 
   &lt;td&gt;ForumEngine + LLM‰∏ªÊåÅ‰∫∫&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;‰∫§ÊµÅËûçÂêà&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÊ†πÊçÆËÆ®ËÆ∫Ë∞ÉÊï¥Á†îÁ©∂ÊñπÂêë&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + forum_readerÂ∑•ÂÖ∑&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+1&lt;/td&gt; 
   &lt;td&gt;ÁªìÊûúÊï¥Âêà&lt;/td&gt; 
   &lt;td&gt;Report AgentÊî∂ÈõÜÊâÄÊúâÂàÜÊûêÁªìÊûúÂíåËÆ∫ÂùõÂÜÖÂÆπ&lt;/td&gt; 
   &lt;td&gt;Report Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+2&lt;/td&gt; 
   &lt;td&gt;Êä•ÂëäÁîüÊàê&lt;/td&gt; 
   &lt;td&gt;Âä®ÊÄÅÈÄâÊã©Ê®°ÊùøÂíåÊ†∑ÂºèÔºåÂ§öËΩÆÁîüÊàêÊúÄÁªàÊä•Âëä&lt;/td&gt; 
   &lt;td&gt;Report Agent + Ê®°ÊùøÂºïÊìé&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;È°πÁõÆ‰ª£Á†ÅÁªìÊûÑÊ†ë&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;BettaFish/
‚îú‚îÄ‚îÄ QueryEngine/                   # ÂõΩÂÜÖÂ§ñÊñ∞ÈóªÂπøÂ∫¶ÊêúÁ¥¢Agent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£Â∞ÅË£Ö
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Â§ÑÁêÜËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # ÊêúÁ¥¢Â∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îî‚îÄ‚îÄ ...                        # ÂÖ∂‰ªñÊ®°Âùó
‚îú‚îÄ‚îÄ MediaEngine/                   # Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅÁêÜËß£Agent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Â§ÑÁêÜËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # ÊêúÁ¥¢Â∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îî‚îÄ‚îÄ ...                        # ÂÖ∂‰ªñÊ®°Âùó
‚îú‚îÄ‚îÄ InsightEngine/                 # ÁßÅÊúâÊï∞ÊçÆÂ∫ìÊåñÊéòAgent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£Â∞ÅË£Ö
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py                # Áªü‰∏ÄÁöÑ OpenAI ÂÖºÂÆπÂÆ¢Êà∑Á´Ø
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Â§ÑÁêÜËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_node.py           # Âü∫Á°ÄËäÇÁÇπÁ±ª
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ formatting_node.py     # Ê†ºÂºèÂåñËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report_structure_node.py # Êä•ÂëäÁªìÊûÑËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_node.py         # ÊêúÁ¥¢ËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summary_node.py        # ÊÄªÁªìËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # Êï∞ÊçÆÂ∫ìÊü•ËØ¢ÂíåÂàÜÊûêÂ∑•ÂÖ∑
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword_optimizer.py   # QwenÂÖ≥ÈîÆËØç‰ºòÂåñ‰∏≠Èó¥‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py              # Êï∞ÊçÆÂ∫ìÊìç‰ΩúÂ∑•ÂÖ∑ÈõÜ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sentiment_analyzer.py  # ÊÉÖÊÑüÂàÜÊûêÈõÜÊàêÂ∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ state/                     # Áä∂ÊÄÅÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ state.py               # AgentÁä∂ÊÄÅÂÆö‰πâ
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                   # ÊèêÁ§∫ËØçÊ®°Êùø
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py             # ÂêÑÁ±ªÊèêÁ§∫ËØç
‚îÇ   ‚îî‚îÄ‚îÄ utils/                     # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py              # ÈÖçÁΩÆÁÆ°ÁêÜ
‚îÇ       ‚îî‚îÄ‚îÄ text_processing.py     # ÊñáÊú¨Â§ÑÁêÜÂ∑•ÂÖ∑
‚îú‚îÄ‚îÄ ReportEngine/                  # Â§öËΩÆÊä•ÂëäÁîüÊàêAgent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Êä•ÂëäÁîüÊàêËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ template_selection.py  # Ê®°ÊùøÈÄâÊã©ËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ html_generation.py     # HTMLÁîüÊàêËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ report_template/           # Êä•ÂëäÊ®°ÊùøÂ∫ì
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Á§æ‰ºöÂÖ¨ÂÖ±ÁÉ≠ÁÇπ‰∫ã‰ª∂ÂàÜÊûê.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ÂïÜ‰∏öÂìÅÁâåËàÜÊÉÖÁõëÊµã.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...                    # Êõ¥Â§öÊ®°Êùø
‚îÇ   ‚îî‚îÄ‚îÄ flask_interface.py         # Flask APIÊé•Âè£
‚îú‚îÄ‚îÄ ForumEngine/                   # ËÆ∫ÂùõÂºïÊìéÁÆÄÊòìÂÆûÁé∞
‚îÇ   ‚îú‚îÄ‚îÄ monitor.py                 # Êó•ÂøóÁõëÊéßÂíåËÆ∫ÂùõÁÆ°ÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ llm_host.py                # ËÆ∫Âùõ‰∏ªÊåÅ‰∫∫LLMÊ®°Âùó
‚îú‚îÄ‚îÄ MindSpider/                    # ÂæÆÂçöÁà¨Ëô´Á≥ªÁªü
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Áà¨Ëô´‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Áà¨Ëô´ÈÖçÁΩÆÊñá‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ BroadTopicExtraction/      # ËØùÈ¢òÊèêÂèñÊ®°Âùó
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database_manager.py    # Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_today_news.py      # ‰ªäÊó•Êñ∞ÈóªËé∑Âèñ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                # ËØùÈ¢òÊèêÂèñ‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ topic_extractor.py     # ËØùÈ¢òÊèêÂèñÂô®
‚îÇ   ‚îú‚îÄ‚îÄ DeepSentimentCrawling/     # Ê∑±Â∫¶ËàÜÊÉÖÁà¨Âèñ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword_manager.py     # ÂÖ≥ÈîÆËØçÁÆ°ÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Ê∑±Â∫¶Áà¨Âèñ‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MediaCrawler/          # Â™í‰ΩìÁà¨Ëô´Ê†∏ÂøÉ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ platform_crawler.py    # Âπ≥Âè∞Áà¨Ëô´ÁÆ°ÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ schema/                    # Êï∞ÊçÆÂ∫ìÁªìÊûÑ
‚îÇ       ‚îú‚îÄ‚îÄ db_manager.py          # Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®
‚îÇ       ‚îú‚îÄ‚îÄ init_database.py       # Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñ
‚îÇ       ‚îî‚îÄ‚îÄ mindspider_tables.sql  # Êï∞ÊçÆÂ∫ìË°®ÁªìÊûÑ
‚îú‚îÄ‚îÄ SentimentAnalysisModel/        # ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÈõÜÂêà
‚îÇ   ‚îú‚îÄ‚îÄ WeiboSentiment_Finetuned/  # ÂæÆË∞ÉBERT/GPT-2Ê®°Âûã
‚îÇ   ‚îú‚îÄ‚îÄ WeiboMultilingualSentiment/# Â§öËØ≠Ë®ÄÊÉÖÊÑüÂàÜÊûêÔºàÊé®ËçêÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ WeiboSentiment_SmallQwen/  # Â∞èÂèÇÊï∞Qwen3ÂæÆË∞É
‚îÇ   ‚îî‚îÄ‚îÄ WeiboSentiment_MachineLearning/ # ‰º†ÁªüÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ï
‚îú‚îÄ‚îÄ SingleEngineApp/               # ÂçïÁã¨AgentÁöÑStreamlitÂ∫îÁî®
‚îÇ   ‚îú‚îÄ‚îÄ query_engine_streamlit_app.py
‚îÇ   ‚îú‚îÄ‚îÄ media_engine_streamlit_app.py
‚îÇ   ‚îî‚îÄ‚îÄ insight_engine_streamlit_app.py
‚îú‚îÄ‚îÄ templates/                     # FlaskÊ®°Êùø
‚îÇ   ‚îî‚îÄ‚îÄ index.html                 # ‰∏ªÁïåÈù¢ÂâçÁ´Ø
‚îú‚îÄ‚îÄ static/                        # ÈùôÊÄÅËµÑÊ∫ê
‚îú‚îÄ‚îÄ logs/                          # ËøêË°åÊó•ÂøóÁõÆÂΩï
‚îú‚îÄ‚îÄ final_reports/                 # ÊúÄÁªàÁîüÊàêÁöÑHTMLÊä•ÂëäÊñá‰ª∂
‚îú‚îÄ‚îÄ utils/                         # ÈÄöÁî®Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îú‚îÄ‚îÄ forum_reader.py            # AgentÈó¥ËÆ∫ÂùõÈÄö‰ø°
‚îÇ   ‚îî‚îÄ‚îÄ retry_helper.py            # ÁΩëÁªúËØ∑Ê±ÇÈáçËØïÊú∫Âà∂Â∑•ÂÖ∑
‚îú‚îÄ‚îÄ app.py                         # Flask‰∏ªÂ∫îÁî®ÂÖ•Âè£
‚îú‚îÄ‚îÄ config.py                      # ÂÖ®Â±ÄÈÖçÁΩÆÊñá‰ª∂
‚îî‚îÄ‚îÄ requirements.txt               # Python‰æùËµñÂåÖÊ∏ÖÂçï
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Âø´ÈÄüÂºÄÂßãÔºàDockerÔºâ&lt;/h2&gt; 
&lt;h3&gt;1. ÂêØÂä®È°πÁõÆ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ËøêË°åÂëΩ‰ª§Ôºö&lt;/strong&gt; ÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Âú®&lt;strong&gt;ÂêéÂè∞&lt;/strong&gt;ÂêØÂä®ÊâÄÊúâÊúçÂä°Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Ê≥®ÔºöÈïúÂÉèÊãâÂèñÈÄüÂ∫¶ÊÖ¢&lt;/strong&gt;ÔºåÂú®Âéü &lt;code&gt;docker-compose.yml&lt;/code&gt; Êñá‰ª∂‰∏≠ÔºåÊàë‰ª¨Â∑≤ÁªèÈÄöËøá&lt;strong&gt;Ê≥®Èáä&lt;/strong&gt;ÁöÑÊñπÂºèÊèê‰æõ‰∫ÜÂ§áÁî®ÈïúÂÉèÂú∞ÂùÄ‰æõÊÇ®ÊõøÊç¢&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;2. ÈÖçÁΩÆËØ¥Êòé&lt;/h3&gt; 
&lt;h4&gt;Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºàPostgreSQLÔºâ&lt;/h4&gt; 
&lt;p&gt;ËØ∑ÊåâÁÖß‰ª•‰∏ãÂèÇÊï∞ÈÖçÁΩÆÊï∞ÊçÆÂ∫ìËøûÊé•‰ø°ÊÅØÔºå‰πüÊîØÊåÅMysqlÂèØËá™Ë°å‰øÆÊîπÔºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;ÈÖçÁΩÆÈ°π&lt;/th&gt; 
   &lt;th align="left"&gt;Â°´ÂÜôÂÄº&lt;/th&gt; 
   &lt;th align="left"&gt;ËØ¥Êòé&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;db&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÊúçÂä°ÂêçÁß∞ (ÂØπÂ∫î &lt;code&gt;docker-compose.yml&lt;/code&gt; ‰∏≠ÁöÑÊúçÂä°Âêç)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;5432&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;ÈªòËÆ§ PostgreSQL Á´ØÂè£&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_USER&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÁî®Êà∑Âêç&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PASSWORD&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÂØÜÁ†Å&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÂêçÁß∞&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;ÂÖ∂‰ªñ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;‰øùÊåÅÈªòËÆ§&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìËøûÊé•Ê±†Á≠âÂÖ∂‰ªñÂèÇÊï∞ËØ∑‰øùÊåÅÈªòËÆ§ËÆæÁΩÆ„ÄÇ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Â§ßÊ®°ÂûãÈÖçÁΩÆ&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êàë‰ª¨ÊâÄÊúâ LLM Ë∞ÉÁî®‰ΩøÁî® OpenAI ÁöÑ API Êé•Âè£Ê†áÂáÜ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Âú®ÂÆåÊàêÊï∞ÊçÆÂ∫ìÈÖçÁΩÆÂêéÔºåËØ∑Ê≠£Â∏∏ÈÖçÁΩÆ&lt;strong&gt;ÊâÄÊúâÂ§ßÊ®°ÂûãÁõ∏ÂÖ≥ÁöÑÂèÇÊï∞&lt;/strong&gt;ÔºåÁ°Æ‰øùÁ≥ªÁªüËÉΩÂ§üËøûÊé•Âà∞ÊÇ®ÈÄâÊã©ÁöÑÂ§ßÊ®°ÂûãÊúçÂä°„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÂÆåÊàê‰∏äËø∞ÊâÄÊúâÈÖçÁΩÆÂπ∂‰øùÂ≠òÂêéÔºåÁ≥ªÁªüÂç≥ÂèØÊ≠£Â∏∏ËøêË°å„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üîß Ê∫êÁ†ÅÂêØÂä®ÊåáÂçó&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Â¶ÇÊûú‰Ω†ÊòØÂàùÊ¨°Â≠¶‰π†‰∏Ä‰∏™AgentÁ≥ªÁªüÁöÑÊê≠Âª∫ÔºåÂèØ‰ª•‰ªé‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÁöÑdemoÂºÄÂßãÔºö&lt;a href="https://github.com/666ghj/DeepSearchAgent-Demo"&gt;Deep Search Agent Demo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ÁéØÂ¢ÉË¶ÅÊ±Ç&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êìç‰ΩúÁ≥ªÁªü&lt;/strong&gt;: Windows„ÄÅLinux„ÄÅMacOS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PythonÁâàÊú¨&lt;/strong&gt;: 3.9+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt;: AnacondaÊàñMiniconda&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êï∞ÊçÆÂ∫ì&lt;/strong&gt;: PostgreSQLÔºàÊé®ËçêÔºâÊàñMySQL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÜÖÂ≠ò&lt;/strong&gt;: Âª∫ËÆÆ2GB‰ª•‰∏ä&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. ÂàõÂª∫ÁéØÂ¢É&lt;/h3&gt; 
&lt;h4&gt;Â¶ÇÊûú‰ΩøÁî®Conda&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫condaÁéØÂ¢É
conda create -n your_conda_name python=3.11
conda activate your_conda_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Â¶ÇÊûú‰ΩøÁî®uv&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫uvÁéØÂ¢É
uv venv --python 3.11 # ÂàõÂª∫3.11ÁéØÂ¢É
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. ÂÆâË£Ö‰æùËµñÂåÖ&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âü∫Á°Ä‰æùËµñÂÆâË£Ö
pip install -r requirements.txt

# uvÁâàÊú¨ÂëΩ‰ª§ÔºàÊõ¥Âø´ÈÄüÂÆâË£ÖÔºâ
uv pip install -r requirements.txt
# Â¶ÇÊûú‰∏çÊÉ≥‰ΩøÁî®Êú¨Âú∞ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÔºàÁÆóÂäõÈúÄÊ±ÇÂæàÂ∞èÔºåÈªòËÆ§ÂÆâË£ÖcpuÁâàÊú¨ÔºâÔºåÂèØ‰ª•Â∞ÜËØ•Êñá‰ª∂‰∏≠ÁöÑ‚ÄúÊú∫Âô®Â≠¶‰π†‚ÄùÈÉ®ÂàÜÊ≥®ÈáäÊéâÂÜçÊâßË°åÊåá‰ª§
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. ÂÆâË£ÖPlaywrightÊµèËßàÂô®È©±Âä®&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂÆâË£ÖÊµèËßàÂô®È©±Âä®ÔºàÁî®‰∫éÁà¨Ëô´ÂäüËÉΩÔºâ
playwright install chromium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. ÈÖçÁΩÆLLM‰∏éÊï∞ÊçÆÂ∫ì&lt;/h3&gt; 
&lt;p&gt;Â§çÂà∂‰∏Ä‰ªΩÈ°πÁõÆÊ†πÁõÆÂΩï &lt;code&gt;.env.example&lt;/code&gt; Êñá‰ª∂ÔºåÂëΩÂêç‰∏∫ &lt;code&gt;.env&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;ÁºñËæë &lt;code&gt;.env&lt;/code&gt; Êñá‰ª∂ÔºåÂ°´ÂÖ•ÊÇ®ÁöÑAPIÂØÜÈí•ÔºàÊÇ®‰πüÂèØ‰ª•ÈÄâÊã©Ëá™Â∑±ÁöÑÊ®°Âûã„ÄÅÊêúÁ¥¢‰ª£ÁêÜÔºåËØ¶ÊÉÖËßÅÊ†πÁõÆÂΩï.env.exampleÊñá‰ª∂ÂÜÖÊàñÊ†πÁõÆÂΩïconfig.py‰∏≠ÁöÑËØ¥ÊòéÔºâÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;# ====================== Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ ======================
# Êï∞ÊçÆÂ∫ì‰∏ªÊú∫Ôºå‰æãÂ¶Çlocalhost Êàñ 127.0.0.1
DB_HOST=your_db_host
# Êï∞ÊçÆÂ∫ìÁ´ØÂè£Âè∑ÔºåÈªòËÆ§‰∏∫3306
DB_PORT=3306
# Êï∞ÊçÆÂ∫ìÁî®Êà∑Âêç
DB_USER=your_db_user
# Êï∞ÊçÆÂ∫ìÂØÜÁ†Å
DB_PASSWORD=your_db_password
# Êï∞ÊçÆÂ∫ìÂêçÁß∞
DB_NAME=your_db_name
# Êï∞ÊçÆÂ∫ìÂ≠óÁ¨¶ÈõÜÔºåÊé®Ëçêutf8mb4ÔºåÂÖºÂÆπemoji
DB_CHARSET=utf8mb4
# Êï∞ÊçÆÂ∫ìÁ±ªÂûãpostgresqlÊàñmysql
DB_DIALECT=postgresql
# Êï∞ÊçÆÂ∫ì‰∏çÈúÄË¶ÅÂàùÂßãÂåñÔºåÊâßË°åapp.pyÊó∂‰ºöËá™Âä®Ê£ÄÊµã

# ====================== LLMÈÖçÁΩÆ ======================
# ÊÇ®ÂèØ‰ª•Êõ¥ÊîπÊØè‰∏™ÈÉ®ÂàÜLLM‰ΩøÁî®ÁöÑAPIÔºåÂè™Ë¶ÅÂÖºÂÆπOpenAIËØ∑Ê±ÇÊ†ºÂºèÈÉΩÂèØ‰ª•

# Insight Agent
INSIGHT_ENGINE_API_KEY=
# Insight Agent LLMÊé•Âè£BaseUrlÔºåÂèØËá™ÂÆö‰πâÂéÇÂïÜAPI
INSIGHT_ENGINE_BASE_URL=
# Insight Agent LLMÊ®°ÂûãÂêçÁß∞ÔºåÂ¶Çkimi-k2-0711-preview
INSIGHT_ENGINE_MODEL_NAME=

# Media Agent
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êé®ËçêLLM API‰æõÂ∫îÂïÜÔºö&lt;a href="https://aihubmix.com/?aff=8Ds9"&gt;Êé®ÁêÜÊó∂‰ª£&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;5. ÂêØÂä®Á≥ªÁªü&lt;/h3&gt; 
&lt;h4&gt;5.1 ÂÆåÊï¥Á≥ªÁªüÂêØÂä®ÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÔºåÊøÄÊ¥ªcondaÁéØÂ¢É
conda activate your_conda_name

# ÂêØÂä®‰∏ªÂ∫îÁî®Âç≥ÂèØ
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;uv ÁâàÊú¨ÂêØÂä®ÂëΩ‰ª§&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÔºåÊøÄÊ¥ªuvÁéØÂ¢É
.venv\Scripts\activate

# ÂêØÂä®‰∏ªÂ∫îÁî®Âç≥ÂèØ
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®1Ôºö‰∏ÄÊ¨°ËøêË°åÁªàÊ≠¢ÂêéÔºåstreamlit appÂèØËÉΩÁªìÊùüÂºÇÂ∏∏‰ªçÁÑ∂Âç†Áî®Á´ØÂè£ÔºåÊ≠§Êó∂ÊêúÁ¥¢Âç†Áî®Á´ØÂè£ÁöÑËøõÁ®ãkillÊéâÂç≥ÂèØ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®2ÔºöÊï∞ÊçÆÁà¨ÂèñÈúÄË¶ÅÂçïÁã¨Êìç‰ΩúÔºåËßÅ5.3ÊåáÂºï&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®3ÔºöÂ¶ÇÊûúÊúçÂä°Âô®ËøúÁ®ãÈÉ®ÁΩ≤Âá∫Áé∞È°µÈù¢ÊòæÁ§∫ÈóÆÈ¢òÔºåËßÅ&lt;a href="https://github.com/666ghj/BettaFish/pull/45"&gt;PR#45&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ËÆøÈóÆ &lt;a href="http://localhost:5000"&gt;http://localhost:5000&lt;/a&gt; Âç≥ÂèØ‰ΩøÁî®ÂÆåÊï¥Á≥ªÁªü&lt;/p&gt; 
&lt;h4&gt;5.2 ÂçïÁã¨ÂêØÂä®Êüê‰∏™Agent&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂêØÂä®QueryEngine
streamlit run SingleEngineApp/query_engine_streamlit_app.py --server.port 8503

# ÂêØÂä®MediaEngine  
streamlit run SingleEngineApp/media_engine_streamlit_app.py --server.port 8502

# ÂêØÂä®InsightEngine
streamlit run SingleEngineApp/insight_engine_streamlit_app.py --server.port 8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5.3 Áà¨Ëô´Á≥ªÁªüÂçïÁã¨‰ΩøÁî®&lt;/h4&gt; 
&lt;p&gt;ËøôÈÉ®ÂàÜÊúâËØ¶ÁªÜÁöÑÈÖçÁΩÆÊñáÊ°£Ôºö&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/MindSpider/README.md"&gt;MindSpider‰ΩøÁî®ËØ¥Êòé&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="MindSpider\img\example.png" alt="banner" width="600" /&gt; 
 &lt;p&gt;MindSpider ËøêË°åÁ§∫‰æã&lt;/p&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ËøõÂÖ•Áà¨Ëô´ÁõÆÂΩï
cd MindSpider

# È°πÁõÆÂàùÂßãÂåñ
python main.py --setup

# ËøêË°åËØùÈ¢òÊèêÂèñÔºàËé∑ÂèñÁÉ≠ÁÇπÊñ∞ÈóªÂíåÂÖ≥ÈîÆËØçÔºâ
python main.py --broad-topic

# ËøêË°åÂÆåÊï¥Áà¨Ëô´ÊµÅÁ®ã
python main.py --complete --date 2024-01-20

# ‰ªÖËøêË°åËØùÈ¢òÊèêÂèñ
python main.py --broad-topic --date 2024-01-20

# ‰ªÖËøêË°åÊ∑±Â∫¶Áà¨Âèñ
python main.py --deep-sentiment --platforms xhs dy wb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öôÔ∏è È´òÁ∫ßÈÖçÁΩÆÔºàÂ∑≤ËøáÊó∂ÔºåÂ∑≤ÁªèÁªü‰∏Ä‰∏∫È°πÁõÆÊ†πÁõÆÂΩï.envÊñá‰ª∂ÁÆ°ÁêÜÔºåÂÖ∂‰ªñÂ≠êagentËá™Âä®ÁªßÊâøÊ†πÁõÆÂΩïÈÖçÁΩÆÔºâ&lt;/h2&gt; 
&lt;h3&gt;‰øÆÊîπÂÖ≥ÈîÆÂèÇÊï∞&lt;/h3&gt; 
&lt;h4&gt;AgentÈÖçÁΩÆÂèÇÊï∞&lt;/h4&gt; 
&lt;p&gt;ÊØè‰∏™AgentÈÉΩÊúâ‰∏ìÈó®ÁöÑÈÖçÁΩÆÊñá‰ª∂ÔºåÂèØÊ†πÊçÆÈúÄÊ±ÇË∞ÉÊï¥Ôºå‰∏ãÈù¢ÊòØÈÉ®ÂàÜÁ§∫‰æãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# QueryEngine/utils/config.py
class Config:
    max_reflections = 2           # ÂèçÊÄùËΩÆÊ¨°
    max_search_results = 15       # ÊúÄÂ§ßÊêúÁ¥¢ÁªìÊûúÊï∞
    max_content_length = 8000     # ÊúÄÂ§ßÂÜÖÂÆπÈïøÂ∫¶
    
# MediaEngine/utils/config.py  
class Config:
    comprehensive_search_limit = 10  # ÁªºÂêàÊêúÁ¥¢ÈôêÂà∂
    web_search_limit = 15           # ÁΩëÈ°µÊêúÁ¥¢ÈôêÂà∂
    
# InsightEngine/utils/config.py
class Config:
    default_search_topic_globally_limit = 200    # ÂÖ®Â±ÄÊêúÁ¥¢ÈôêÂà∂
    default_get_comments_limit = 500             # ËØÑËÆ∫Ëé∑ÂèñÈôêÂà∂
    max_search_results_for_llm = 50              # ‰º†ÁªôLLMÁöÑÊúÄÂ§ßÁªìÊûúÊï∞
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÈÖçÁΩÆ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/sentiment_analyzer.py
SENTIMENT_CONFIG = {
    'model_type': 'multilingual',     # ÂèØÈÄâ: 'bert', 'multilingual', 'qwen'Á≠â
    'confidence_threshold': 0.8,      # ÁΩÆ‰ø°Â∫¶ÈòàÂÄº
    'batch_size': 32,                 # ÊâπÂ§ÑÁêÜÂ§ßÂ∞è
    'max_sequence_length': 512,       # ÊúÄÂ§ßÂ∫èÂàóÈïøÂ∫¶
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Êé•ÂÖ•‰∏çÂêåÁöÑLLMÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;ÊîØÊåÅ‰ªªÊÑèopenAIË∞ÉÁî®Ê†ºÂºèÁöÑLLMÊèê‰æõÂïÜÔºåÂè™ÈúÄË¶ÅÂú®/config.py‰∏≠Â°´ÂÜôÂØπÂ∫îÁöÑKEY„ÄÅBASE_URL„ÄÅMODEL_NAMEÂç≥ÂèØ„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰ªÄ‰πàÊòØopenAIË∞ÉÁî®Ê†ºÂºèÔºü‰∏ãÈù¢Êèê‰æõ‰∏Ä‰∏™ÁÆÄÂçïÁöÑ‰æãÂ≠êÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(api_key="your_api_key", 
               base_url="https://api.siliconflow.cn/v1")

response = client.chat.completions.create(
   model="Qwen/Qwen2.5-72B-Instruct",
   messages=[
       {'role': 'user', 
        'content': "Êé®ÁêÜÊ®°Âûã‰ºöÁªôÂ∏ÇÂú∫Â∏¶Êù•Âì™‰∫õÊñ∞ÁöÑÊú∫‰ºö"}
   ],
)

complete_response = response.choices[0].message.content
print(complete_response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Êõ¥ÊîπÊÉÖÊÑüÂàÜÊûêÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;Á≥ªÁªüÈõÜÊàê‰∫ÜÂ§öÁßçÊÉÖÊÑüÂàÜÊûêÊñπÊ≥ïÔºåÂèØÊ†πÊçÆÈúÄÊ±ÇÈÄâÊã©Ôºö&lt;/p&gt; 
&lt;h4&gt;1. Â§öËØ≠Ë®ÄÊÉÖÊÑüÂàÜÊûê&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboMultilingualSentiment
python predict.py --text "This product is amazing!" --lang "en"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Â∞èÂèÇÊï∞Qwen3ÂæÆË∞É&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_SmallQwen
python predict_universal.py --text "ËøôÊ¨°Ê¥ªÂä®ÂäûÂæóÂæàÊàêÂäü"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Âü∫‰∫éBERTÁöÑÂæÆË∞ÉÊ®°Âûã&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ‰ΩøÁî®BERT‰∏≠ÊñáÊ®°Âûã
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/BertChinese-Lora
python predict.py --text "Ëøô‰∏™‰∫ßÂìÅÁúüÁöÑÂæà‰∏çÈîô"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. GPT-2 LoRAÂæÆË∞ÉÊ®°Âûã&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_Finetuned/GPT2-Lora
python predict.py --text "‰ªäÂ§©ÂøÉÊÉÖ‰∏çÂ§™Â•Ω"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. ‰º†ÁªüÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ï&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_MachineLearning
python predict.py --model_type "svm" --text "ÊúçÂä°ÊÄÅÂ∫¶ÈúÄË¶ÅÊîπËøõ"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Êé•ÂÖ•Ëá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÂ∫ì&lt;/h3&gt; 
&lt;h4&gt;1. ‰øÆÊîπÊï∞ÊçÆÂ∫ìËøûÊé•ÈÖçÁΩÆ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# config.py ‰∏≠Ê∑ªÂä†ÊÇ®ÁöÑ‰∏öÂä°Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ
BUSINESS_DB_HOST = "your_business_db_host"
BUSINESS_DB_PORT = 3306
BUSINESS_DB_USER = "your_business_user"
BUSINESS_DB_PASSWORD = "your_business_password"
BUSINESS_DB_NAME = "your_business_database"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. ÂàõÂª∫Ëá™ÂÆö‰πâÊï∞ÊçÆËÆøÈóÆÂ∑•ÂÖ∑&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/custom_db_tool.py
class CustomBusinessDBTool:
    """Ëá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÂ∫ìÊü•ËØ¢Â∑•ÂÖ∑"""
    
    def __init__(self):
        self.connection_config = {
            'host': config.BUSINESS_DB_HOST,
            'port': config.BUSINESS_DB_PORT,
            'user': config.BUSINESS_DB_USER,
            'password': config.BUSINESS_DB_PASSWORD,
            'database': config.BUSINESS_DB_NAME,
        }
    
    def search_business_data(self, query: str, table: str):
        """Êü•ËØ¢‰∏öÂä°Êï∞ÊçÆ"""
        # ÂÆûÁé∞ÊÇ®ÁöÑ‰∏öÂä°ÈÄªËæë
        pass
    
    def get_customer_feedback(self, product_id: str):
        """Ëé∑ÂèñÂÆ¢Êà∑ÂèçÈ¶àÊï∞ÊçÆ"""
        # ÂÆûÁé∞ÂÆ¢Êà∑ÂèçÈ¶àÊü•ËØ¢ÈÄªËæë
        pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. ÈõÜÊàêÂà∞InsightEngine&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/agent.py ‰∏≠ÈõÜÊàêËá™ÂÆö‰πâÂ∑•ÂÖ∑
from .tools.custom_db_tool import CustomBusinessDBTool

class DeepSearchAgent:
    def __init__(self, config=None):
        # ... ÂÖ∂‰ªñÂàùÂßãÂåñ‰ª£Á†Å
        self.custom_db_tool = CustomBusinessDBTool()
    
    def execute_custom_search(self, query: str):
        """ÊâßË°åËá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÊêúÁ¥¢"""
        return self.custom_db_tool.search_business_data(query, "your_table")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ëá™ÂÆö‰πâÊä•ÂëäÊ®°Êùø&lt;/h3&gt; 
&lt;h4&gt;1. Âú®WebÁïåÈù¢‰∏≠‰∏ä‰º†&lt;/h4&gt; 
&lt;p&gt;Á≥ªÁªüÊîØÊåÅ‰∏ä‰º†Ëá™ÂÆö‰πâÊ®°ÊùøÊñá‰ª∂Ôºà.mdÊàñ.txtÊ†ºÂºèÔºâÔºåÂèØÂú®ÁîüÊàêÊä•ÂëäÊó∂ÈÄâÊã©‰ΩøÁî®„ÄÇ&lt;/p&gt; 
&lt;h4&gt;2. ÂàõÂª∫Ê®°ÊùøÊñá‰ª∂&lt;/h4&gt; 
&lt;p&gt;Âú® &lt;code&gt;ReportEngine/report_template/&lt;/code&gt; ÁõÆÂΩï‰∏ãÂàõÂª∫Êñ∞ÁöÑÊ®°ÊùøÔºåÊàë‰ª¨ÁöÑAgent‰ºöËá™Ë°åÈÄâÁî®ÊúÄÂêàÈÄÇÁöÑÊ®°Êùø„ÄÇ&lt;/p&gt; 
&lt;h2&gt;ü§ù Ë¥°ÁåÆÊåáÂçó&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨Ê¨¢ËøéÊâÄÊúâÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; 
&lt;h3&gt;Â¶Ç‰ΩïË¥°ÁåÆ&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ForkÈ°πÁõÆ&lt;/strong&gt;Âà∞ÊÇ®ÁöÑGitHubË¥¶Âè∑&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂàõÂª∫FeatureÂàÜÊîØ&lt;/strong&gt;Ôºö&lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êèê‰∫§Êõ¥Êîπ&lt;/strong&gt;Ôºö&lt;code&gt;git commit -m 'Add some AmazingFeature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅÂà∞ÂàÜÊîØ&lt;/strong&gt;Ôºö&lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºÄÂêØPull Request&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ÂºÄÂèëËßÑËåÉ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰ª£Á†ÅÈÅµÂæ™PEP8ËßÑËåÉ&lt;/li&gt; 
 &lt;li&gt;Êèê‰∫§‰ø°ÊÅØ‰ΩøÁî®Ê∏ÖÊô∞ÁöÑ‰∏≠Ëã±ÊñáÊèèËø∞&lt;/li&gt; 
 &lt;li&gt;Êñ∞ÂäüËÉΩÈúÄË¶ÅÂåÖÂê´Áõ∏Â∫îÁöÑÊµãËØïÁî®‰æã&lt;/li&gt; 
 &lt;li&gt;Êõ¥Êñ∞Áõ∏ÂÖ≥ÊñáÊ°£&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü¶ñ ‰∏ã‰∏ÄÊ≠•ÂºÄÂèëËÆ°Âàí&lt;/h2&gt; 
&lt;p&gt;Áé∞Âú®Á≥ªÁªüÂè™ÂÆåÊàê‰∫Ü"‰∏âÊùøÊñß"‰∏≠ÁöÑÂâç‰∏§Ê≠•ÔºåÂç≥ÔºöËæìÂÖ•Ë¶ÅÊ±Ç-&amp;gt;ËØ¶ÁªÜÂàÜÊûêÔºåËøòÁº∫Â∞ë‰∏ÄÊ≠•È¢ÑÊµãÔºåÁõ¥Êé•Â∞Ü‰ªñÁªßÁª≠‰∫§ÁªôLLMÊòØ‰∏çÂÖ∑ÊúâËØ¥ÊúçÂäõÁöÑ„ÄÇ&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_compressed.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;p&gt;ÁõÆÂâçÊàë‰ª¨ÁªèËøáÂæàÈïø‰∏ÄÊÆµÊó∂Èó¥ÁöÑÁà¨ÂèñÊî∂ÈõÜÔºåÊã•Êúâ‰∫ÜÂ§ßÈáèÂÖ®ÁΩëËØùÈ¢òÁÉ≠Â∫¶ÈöèÊó∂Èó¥„ÄÅÁàÜÁÇπÁ≠âÁöÑÂèòÂåñË∂ãÂäøÁÉ≠Â∫¶Êï∞ÊçÆÔºåÂ∑≤ÁªèÂÖ∑Â§á‰∫ÜÂèØ‰ª•ÂºÄÂèëÈ¢ÑÊµãÊ®°ÂûãÁöÑÊù°‰ª∂„ÄÇÊàë‰ª¨Âõ¢ÈòüÂ∞ÜËøêÁî®Êó∂Â∫èÊ®°Âûã„ÄÅÂõæÁ•ûÁªèÁΩëÁªú„ÄÅÂ§öÊ®°ÊÄÅËûçÂêàÁ≠âÈ¢ÑÊµãÊ®°ÂûãÊäÄÊúØÂÇ®Â§á‰∫éÊ≠§ÔºåÂÆûÁé∞ÁúüÊ≠£Âü∫‰∫éÊï∞ÊçÆÈ©±Âä®ÁöÑËàÜÊÉÖÈ¢ÑÊµãÂäüËÉΩ„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ÈáçË¶ÅÊèêÈÜíÔºöÊú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†„ÄÅÂ≠¶ÊúØÁ†îÁ©∂ÂíåÊïôËÇ≤ÁõÆÁöÑ‰ΩøÁî®&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêàËßÑÊÄßÂ£∞Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Êú¨È°πÁõÆ‰∏≠ÁöÑÊâÄÊúâ‰ª£Á†Å„ÄÅÂ∑•ÂÖ∑ÂíåÂäüËÉΩÂùá‰ªÖ‰æõÂ≠¶‰π†„ÄÅÂ≠¶ÊúØÁ†îÁ©∂ÂíåÊïôËÇ≤ÁõÆÁöÑ‰ΩøÁî®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÊú¨È°πÁõÆÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÁî®ÈÄîÊàñÁõàÂà©ÊÄßÊ¥ªÂä®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÊú¨È°πÁõÆÁî®‰∫é‰ªª‰ΩïËøùÊ≥ï„ÄÅËøùËßÑÊàñ‰æµÁäØ‰ªñ‰∫∫ÊùÉÁõäÁöÑË°å‰∏∫&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Áà¨Ëô´ÂäüËÉΩÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;È°πÁõÆ‰∏≠ÁöÑÁà¨Ëô´ÂäüËÉΩ‰ªÖÁî®‰∫éÊäÄÊúØÂ≠¶‰π†ÂíåÁ†îÁ©∂ÁõÆÁöÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂøÖÈ°ªÈÅµÂÆàÁõÆÊ†áÁΩëÁ´ôÁöÑrobots.txtÂçèËÆÆÂíå‰ΩøÁî®Êù°Ê¨æ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂøÖÈ°ªÈÅµÂÆàÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÔºå‰∏çÂæóËøõË°åÊÅ∂ÊÑèÁà¨ÂèñÊàñÊï∞ÊçÆÊª•Áî®&lt;/li&gt; 
   &lt;li&gt;Âõ†‰ΩøÁî®Áà¨Ëô´ÂäüËÉΩ‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãÂêéÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊãÖ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êï∞ÊçÆ‰ΩøÁî®ÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;È°πÁõÆÊ∂âÂèäÁöÑÊï∞ÊçÆÂàÜÊûêÂäüËÉΩ‰ªÖ‰æõÂ≠¶ÊúØÁ†îÁ©∂‰ΩøÁî®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÂàÜÊûêÁªìÊûúÁî®‰∫éÂïÜ‰∏öÂÜ≥Á≠ñÊàñÁõàÂà©ÁõÆÁöÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îÁ°Æ‰øùÊâÄÂàÜÊûêÊï∞ÊçÆÁöÑÂêàÊ≥ïÊÄßÂíåÂêàËßÑÊÄß&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÊäÄÊúØÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Êú¨È°πÁõÆÊåâ"Áé∞Áä∂"Êèê‰æõÔºå‰∏çÊèê‰æõ‰ªª‰ΩïÊòéÁ§∫ÊàñÊöóÁ§∫ÁöÑ‰øùËØÅ&lt;/li&gt; 
   &lt;li&gt;‰ΩúËÄÖ‰∏çÂØπ‰ΩøÁî®Êú¨È°πÁõÆÈÄ†ÊàêÁöÑ‰ªª‰ΩïÁõ¥Êé•ÊàñÈó¥Êé•ÊçüÂ§±ÊâøÊãÖË¥£‰ªª&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îËá™Ë°åËØÑ‰º∞È°πÁõÆÁöÑÈÄÇÁî®ÊÄßÂíåÈ£éÈô©&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ë¥£‰ªªÈôêÂà∂&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂú®‰ΩøÁî®Êú¨È°πÁõÆÂâçÂ∫îÂÖÖÂàÜ‰∫ÜËß£Áõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îÁ°Æ‰øùÂÖ∂‰ΩøÁî®Ë°å‰∏∫Á¨¶ÂêàÂΩìÂú∞Ê≥ïÂæãÊ≥ïËßÑË¶ÅÊ±Ç&lt;/li&gt; 
   &lt;li&gt;Âõ†ËøùÂèçÊ≥ïÂæãÊ≥ïËßÑ‰ΩøÁî®Êú¨È°πÁõÆËÄå‰∫ßÁîüÁöÑ‰ªª‰ΩïÂêéÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊãÖ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ËØ∑Âú®‰ΩøÁî®Êú¨È°πÁõÆÂâç‰ªîÁªÜÈòÖËØªÂπ∂ÁêÜËß£‰∏äËø∞ÂÖçË¥£Â£∞Êòé„ÄÇ‰ΩøÁî®Êú¨È°πÁõÆÂç≥Ë°®Á§∫ÊÇ®Â∑≤ÂêåÊÑèÂπ∂Êé•Âèó‰∏äËø∞ÊâÄÊúâÊù°Ê¨æ„ÄÇ&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ ËÆ∏ÂèØËØÅ&lt;/h2&gt; 
&lt;p&gt;Êú¨È°πÁõÆÈááÁî® &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/LICENSE"&gt;GPL-2.0ËÆ∏ÂèØËØÅ&lt;/a&gt;„ÄÇËØ¶ÁªÜ‰ø°ÊÅØËØ∑ÂèÇÈòÖLICENSEÊñá‰ª∂„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üéâ ÊîØÊåÅ‰∏éËÅîÁ≥ª&lt;/h2&gt; 
&lt;h3&gt;Ëé∑ÂèñÂ∏ÆÂä©&lt;/h3&gt; 
&lt;p&gt;Â∏∏ËßÅÈóÆÈ¢òËß£Á≠îÔºö&lt;a href="https://github.com/666ghj/BettaFish/issues/185"&gt;https://github.com/666ghj/BettaFish/issues/185&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;È°πÁõÆ‰∏ªÈ°µ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish"&gt;GitHub‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈóÆÈ¢òÂèçÈ¶à&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;IssuesÈ°µÈù¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂäüËÉΩÂª∫ËÆÆ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish/discussions"&gt;DiscussionsÈ°µÈù¢&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ËÅîÁ≥ªÊñπÂºè&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìß &lt;strong&gt;ÈÇÆÁÆ±&lt;/strong&gt;Ôºö&lt;a href="mailto:670939375@qq.com"&gt;670939375@qq.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÂïÜÂä°Âêà‰Ωú&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºÅ‰∏öÂÆöÂà∂ÂºÄÂèë&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§ßÊï∞ÊçÆÊúçÂä°&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â≠¶ÊúØÂêà‰Ωú&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊäÄÊúØÂüπËÆ≠&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Ë¥°ÁåÆËÄÖ&lt;/h2&gt; 
&lt;p&gt;ÊÑüË∞¢‰ª•‰∏ã‰ºòÁßÄÁöÑË¥°ÁåÆËÄÖ‰ª¨Ôºö&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=666ghj/BettaFish" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìà È°πÁõÆÁªüËÆ°&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e04e3eea4674edc39c148a7845c8d09c1b7b1922.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>usestrix/strix</title>
      <link>https://github.com/usestrix/strix</link>
      <description>&lt;p&gt;‚ú® Open-source AI hackers for your apps üë®üèª‚Äçüíª&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://usestrix.com/"&gt; &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/logo.png" width="150" alt="Strix Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Strix &lt;/h1&gt; 
&lt;h2 align="center"&gt;Open-source AI Hackers to secure your Apps&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/strix-agent?color=3776AB" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/v/strix-agent?color=10b981" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/strix-agent"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/strix-agent?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GREY&amp;amp;right_color=RED&amp;amp;left_text=Downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/usestrix/strix"&gt;&lt;img src="https://img.shields.io/github/stars/usestrix/strix" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://usestrix.com"&gt;&lt;img src="https://img.shields.io/badge/Website-usestrix.com-2d3748.svg?sanitize=true" alt="Website" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15362" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15362" alt="usestrix%2Fstrix | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;em&gt;Love Strix? Give us a star to help other developers discover it!&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/screenshot.png" alt="Strix Demo" width="800" style="border-radius: 16px; box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3), 0 0 0 1px rgba(255, 255, 255, 0.1), inset 0 1px 0 rgba(255, 255, 255, 0.2); transform: perspective(1000px) rotateX(2deg); transition: transform 0.3s ease;" /&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;New!&lt;/strong&gt; Strix now integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü¶â Strix Overview&lt;/h2&gt; 
&lt;p&gt;Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full hacker toolkit&lt;/strong&gt; out of the box&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teams of agents&lt;/strong&gt; that collaborate and scale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real validation&lt;/strong&gt; with PoCs, not false positives&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Developer‚Äëfirst&lt;/strong&gt; CLI with actionable reports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto‚Äëfix &amp;amp; reporting&lt;/strong&gt; to accelerate remediation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéØ Use Cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detect and validate critical vulnerabilities in your applications.&lt;/li&gt; 
 &lt;li&gt;Get penetration tests done in hours, not weeks, with compliance reports.&lt;/li&gt; 
 &lt;li&gt;Automate bug bounty research and generate PoCs for faster reporting.&lt;/li&gt; 
 &lt;li&gt;Run tests in CI/CD to block vulnerabilities before reaching production.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üöÄ Quick Start&lt;/h3&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker (running)&lt;/li&gt; 
 &lt;li&gt;Python 3.12+&lt;/li&gt; 
 &lt;li&gt;An LLM provider key (or a local LLM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install
pipx install strix-agent

# Configure AI provider
export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Run security assessment
strix --target ./app-directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;First run pulls the sandbox Docker image. Results are saved under &lt;code&gt;agent_runs/&amp;lt;run-name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;‚òÅÔ∏è Cloud Hosted&lt;/h3&gt; 
&lt;p&gt;Want to skip the setup? Try our cloud-hosted version: &lt;strong&gt;&lt;a href="https://usestrix.com"&gt;usestrix.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;h3&gt;üõ†Ô∏è Agentic Security Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîå Full HTTP Proxy&lt;/strong&gt; - Full request/response manipulation and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Browser Automation&lt;/strong&gt; - Multi-tab browser for testing of XSS, CSRF, auth flows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíª Terminal Environments&lt;/strong&gt; - Interactive shells for command execution and testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üêç Python Runtime&lt;/strong&gt; - Custom exploit development and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Reconnaissance&lt;/strong&gt; - Automated OSINT and attack surface mapping&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìÅ Code Analysis&lt;/strong&gt; - Static and dynamic analysis capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìù Knowledge Management&lt;/strong&gt; - Structured findings and attack documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéØ Comprehensive Vulnerability Detection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Access Control&lt;/strong&gt; - IDOR, privilege escalation, auth bypass&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Injection Attacks&lt;/strong&gt; - SQL, NoSQL, command injection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server-Side&lt;/strong&gt; - SSRF, XXE, deserialization flaws&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client-Side&lt;/strong&gt; - XSS, prototype pollution, DOM vulnerabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business Logic&lt;/strong&gt; - Race conditions, workflow manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; - JWT vulnerabilities, session management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt; - Misconfigurations, exposed services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üï∏Ô∏è Graph of Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Workflows&lt;/strong&gt; - Specialized agents for different attacks and assets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Testing&lt;/strong&gt; - Parallel execution for fast comprehensive coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Coordination&lt;/strong&gt; - Agents collaborate and share discoveries&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíª Usage Examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Local codebase analysis
strix --target ./app-directory

# Repository security review
strix --target https://github.com/org/repo

# Web application assessment
strix --target https://your-app.com

# Multi-target white-box testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Test multiple environments simultaneously
strix -t https://dev.your-app.com -t https://staging.your-app.com -t https://prod.your-app.com

# Focused testing with instructions
strix --target api.your-app.com --instruction "Prioritize authentication and authorization testing"

# Testing with credentials
strix --target https://your-app.com --instruction "Test with credentials: testuser/testpass. Focus on privilege escalation and access control bypasses."
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚öôÔ∏è Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Optional
export LLM_API_BASE="your-api-base-url"  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY="your-api-key"  # for search capabilities
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/providers"&gt;üìö View supported AI models&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;ü§ñ Headless Mode&lt;/h3&gt; 
&lt;p&gt;Run Strix programmatically without interactive UI using the &lt;code&gt;-n/--non-interactive&lt;/code&gt; flag‚Äîperfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;strix -n --target https://your-app.com --instruction "Focus on authentication and authorization vulnerabilities"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîÑ CI/CD (GitHub Actions)&lt;/h3&gt; 
&lt;p&gt;Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Strix
        run: pipx install strix-agent

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üèÜ Enterprise Platform&lt;/h2&gt; 
&lt;p&gt;Our managed platform provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üìà Executive Dashboards&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Custom Fine-Tuned Models&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è CI/CD Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Large-Scale Scanning&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå Third-Party Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Enterprise Support&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://usestrix.com"&gt;&lt;strong&gt;Get Enterprise Demo ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîí Security Architecture&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Container Isolation&lt;/strong&gt; - All testing in sandboxed Docker environments&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Local Processing&lt;/strong&gt; - Testing runs locally, no data sent to external services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Only test systems you own or have permission to test. You are responsible for using Strix ethically and legally.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! There are several ways to contribute:&lt;/p&gt; 
&lt;h3&gt;Code Contributions&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up your development environment&lt;/li&gt; 
 &lt;li&gt;Running tests and quality checks&lt;/li&gt; 
 &lt;li&gt;Submitting pull requests&lt;/li&gt; 
 &lt;li&gt;Code style guidelines&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prompt Modules Collection&lt;/h3&gt; 
&lt;p&gt;Help expand our collection of specialized prompt modules for AI agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Advanced testing techniques for vulnerabilities, frameworks, and technologies&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/strix/prompts/README.md"&gt;Prompt Modules Documentation&lt;/a&gt; for guidelines&lt;/li&gt; 
 &lt;li&gt;Submit via &lt;a href="https://github.com/usestrix/strix/pulls"&gt;pull requests&lt;/a&gt; or &lt;a href="https://github.com/usestrix/strix/issues"&gt;issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåü Support the Project&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Love Strix?&lt;/strong&gt; Give us a ‚≠ê on GitHub!&lt;/p&gt; 
&lt;h2&gt;üë• Join Our Community&lt;/h2&gt; 
&lt;p&gt;Have questions? Found a bug? Want to contribute? &lt;strong&gt;&lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;Join our Discord!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>droidrun/droidrun</title>
      <link>https://github.com/droidrun/droidrun</link>
      <description>&lt;p&gt;Automate your mobile devices with natural language commands - an LLM agnostic mobile Agent ü§ñ&lt;/p&gt;&lt;hr&gt;&lt;picture align="center"&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="./static/droidrun-dark.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="./static/droidrun.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/droidrun/droidrun/main/static/droidrun.png" width="full" /&gt; 
&lt;/picture&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://docs.droidrun.ai"&gt;&lt;img src="https://img.shields.io/badge/Docs-%F0%9F%93%95-0D9373?style=for-the-badge" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="http://cloud.droidrun.ai"&gt;&lt;img src="https://img.shields.io/badge/Cloud-%E2%98%81%EF%B8%8F-0D9373?style=for-the-badge" alt="Cloud" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/droidrun/droidrun/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/droidrun/droidrun?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://droidrun.ai"&gt;&lt;img src="https://img.shields.io/badge/droidrun.ai-white" alt="droidrun.ai" /&gt;&lt;/a&gt; &lt;a href="https://x.com/droid_run"&gt;&lt;img src="https://img.shields.io/twitter/follow/droid_run?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/ZZbKEZZkwK"&gt;&lt;img src="https://img.shields.io/discord/1360219330318696488?color=white&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://droidrun.ai/benchmark"&gt;&lt;img src="https://img.shields.io/badge/Benchmark-91.4%EF%B9%AA-white" alt="Benchmark" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=dark&amp;amp;period=daily&amp;amp;t=1753948032207" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=neutral&amp;amp;period=daily&amp;amp;t=1753948125523" /&gt; 
  &lt;a href="https://www.producthunt.com/products/droidrun-framework-for-mobile-agent?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-droidrun" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=neutral&amp;amp;period=daily&amp;amp;t=1753948125523" alt="Droidrun - Give AI native control of physical &amp;amp; virtual phones. | Product Hunt" style="width: 200px; height: 54px;" width="200" height="54" /&gt;&lt;/a&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;p&gt;DroidRun is a powerful framework for controlling Android and iOS devices through LLM agents. It allows you to automate device interactions using natural language commands. &lt;a href="https://droidrun.ai/benchmark"&gt;Checkout our benchmark results&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why Droidrun?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ Control Android and iOS devices with natural language commands&lt;/li&gt; 
 &lt;li&gt;üîÄ Supports multiple LLM providers (OpenAI, Anthropic, Gemini, Ollama, DeepSeek)&lt;/li&gt; 
 &lt;li&gt;üß† Planning capabilities for complex multi-step tasks&lt;/li&gt; 
 &lt;li&gt;üíª Easy to use CLI with enhanced debugging features&lt;/li&gt; 
 &lt;li&gt;üêç Extendable Python API for custom automations&lt;/li&gt; 
 &lt;li&gt;üì∏ Screenshot analysis for visual understanding of the device&lt;/li&gt; 
 &lt;li&gt;ü´Ü Execution tracing with Arize Phoenix&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'droidrun[google,anthropic,openai,deepseek,ollama,dev]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Quickstart&lt;/h2&gt; 
&lt;p&gt;Read on how to get droidrun up and running within seconds in &lt;a href="https://docs.droidrun.ai/v3/quickstart"&gt;our docs&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=4WT7FXJah2I"&gt;&lt;img src="https://img.youtube.com/vi/4WT7FXJah2I/0.jpg" alt="Quickstart Video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üé¨ Demo Videos&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accommodation booking&lt;/strong&gt;: Let Droidrun search for an apartment for you&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/VUpCyq1PSXw"&gt;&lt;img src="https://img.youtube.com/vi/VUpCyq1PSXw/0.jpg" alt="Droidrun Accommodation Booking Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Trend Hunter&lt;/strong&gt;: Let Droidrun hunt down trending posts&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/7V8S2f8PnkQ"&gt;&lt;img src="https://img.youtube.com/vi/7V8S2f8PnkQ/0.jpg" alt="Droidrun Trend Hunter Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Streak Saver&lt;/strong&gt;: Let Droidrun save your streak on your favorite language learning app&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/B5q2B467HKw"&gt;&lt;img src="https://img.youtube.com/vi/B5q2B467HKw/0.jpg" alt="Droidrun Streak Saver Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üí° Example Use Cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Automated UI testing of mobile applications&lt;/li&gt; 
 &lt;li&gt;Creating guided workflows for non-technical users&lt;/li&gt; 
 &lt;li&gt;Automating repetitive tasks on mobile devices&lt;/li&gt; 
 &lt;li&gt;Remote assistance for less technical users&lt;/li&gt; 
 &lt;li&gt;Exploring mobile UI with natural language commands&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt; 
&lt;h2&gt;Security Checks&lt;/h2&gt; 
&lt;p&gt;To ensure the security of the codebase, we have integrated security checks using &lt;code&gt;bandit&lt;/code&gt; and &lt;code&gt;safety&lt;/code&gt;. These tools help identify potential security issues in the code and dependencies.&lt;/p&gt; 
&lt;h3&gt;Running Security Checks&lt;/h3&gt; 
&lt;p&gt;Before submitting any code, please run the following security checks:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bandit&lt;/strong&gt;: A tool to find common security issues in Python code.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;bandit -r droidrun
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Safety&lt;/strong&gt;: A tool to check your installed dependencies for known security vulnerabilities.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;safety scan
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>prometheus/alertmanager</title>
      <link>https://github.com/prometheus/alertmanager</link>
      <description>&lt;p&gt;Prometheus Alertmanager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Alertmanager &lt;a href="https://circleci.com/gh/prometheus/alertmanager"&gt;&lt;img src="https://circleci.com/gh/prometheus/alertmanager/tree/main.svg?style=shield" alt="CircleCI" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;&lt;img src="https://quay.io/repository/prometheus/alertmanager/status" alt="Docker Repository on Quay" title="Docker Repository on Quay" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;&lt;img src="https://img.shields.io/docker/pulls/prom/alertmanager.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct &lt;a href="https://prometheus.io/docs/alerting/latest/configuration/#receiver"&gt;receiver integrations&lt;/a&gt; such as email, PagerDuty, OpsGenie, or many other &lt;a href="https://prometheus.io/docs/operating/integrations/#alertmanager-webhook-receiver"&gt;mechanisms&lt;/a&gt; thanks to the webhook receiver. It also takes care of silencing and inhibition of alerts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://prometheus.io/docs/alerting/alertmanager/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;There are various ways of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Precompiled binaries&lt;/h3&gt; 
&lt;p&gt;Precompiled binaries for released versions are available in the &lt;a href="https://prometheus.io/download/"&gt;&lt;em&gt;download&lt;/em&gt; section&lt;/a&gt; on &lt;a href="https://prometheus.io"&gt;prometheus.io&lt;/a&gt;. Using the latest production release binary is the recommended way of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Docker images&lt;/h3&gt; 
&lt;p&gt;Docker images are available on &lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;Quay.io&lt;/a&gt; or &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can launch an Alertmanager container for trying it out with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ docker run --name alertmanager -d -p 127.0.0.1:9093:9093 quay.io/prometheus/alertmanager
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alertmanager will now be reachable at &lt;a href="http://localhost:9093/"&gt;http://localhost:9093/&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling the binary&lt;/h3&gt; 
&lt;p&gt;You can either &lt;code&gt;go install&lt;/code&gt; it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/...@latest
# cd $GOPATH/src/github.com/prometheus/alertmanager
$ alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or clone the repository and build manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ mkdir -p $GOPATH/src/github.com/prometheus
$ cd $GOPATH/src/github.com/prometheus
$ git clone https://github.com/prometheus/alertmanager.git
$ cd alertmanager
$ make build
$ ./alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also build just one of the binaries in this repo by passing a name to the build function:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make build BINARIES=amtool
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;This is an example configuration that should cover most relevant aspects of the new YAML configuration format. The full documentation of the configuration can be found &lt;a href="https://prometheus.io/docs/alerting/configuration/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;global:
  # The smarthost and SMTP sender used for mail notifications.
  smtp_smarthost: 'localhost:25'
  smtp_from: 'alertmanager@example.org'

# The root route on which each incoming alert enters.
route:
  # The root route must not have any matchers as it is the entry point for
  # all alerts. It needs to have a receiver configured so alerts that do not
  # match any of the sub-routes are sent to someone.
  receiver: 'team-X-mails'

  # The labels by which incoming alerts are grouped together. For example,
  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
  # be batched into a single group.
  #
  # To aggregate by all possible labels use '...' as the sole label name.
  # This effectively disables aggregation entirely, passing through all
  # alerts as-is. This is unlikely to be what you want, unless you have
  # a very low alert volume or your upstream notification system performs
  # its own grouping. Example: group_by: [...]
  group_by: ['alertname', 'cluster']

  # When a new group of alerts is created by an incoming alert, wait at
  # least 'group_wait' to send the initial notification.
  # This way ensures that you get multiple alerts for the same group that start
  # firing shortly after another are batched together on the first
  # notification.
  group_wait: 30s

  # When the first notification was sent, wait 'group_interval' to send a batch
  # of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait 'repeat_interval' to
  # resend them.
  repeat_interval: 3h

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  # The child route trees.
  routes:
  # This route performs a regular expression match on alert labels to
  # catch alerts that are related to a list of services.
  - matchers:
    - service=~"^(foo1|foo2|baz)$"
    receiver: team-X-mails

    # The service has a sub-route for critical alerts, any alerts
    # that do not match, i.e. severity != critical, fall-back to the
    # parent node and are sent to 'team-X-mails'
    routes:
    - matchers:
      - severity="critical"
      receiver: team-X-pager

  - matchers:
    - service="files"
    receiver: team-Y-mails

    routes:
    - matchers:
      - severity="critical"
      receiver: team-Y-pager

  # This route handles all alerts coming from a database service. If there's
  # no team to handle it, it defaults to the DB team.
  - matchers:
    - service="database"

    receiver: team-DB-pager
    # Also group alerts by affected database.
    group_by: [alertname, cluster, database]

    routes:
    - matchers:
      - owner="team-X"
      receiver: team-X-pager

    - matchers:
      - owner="team-Y"
      receiver: team-Y-pager


# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
inhibit_rules:
- source_matchers:
    - severity="critical"
  target_matchers:
    - severity="warning"
  # Apply inhibition if the alertname is the same.
  # CAUTION: 
  #   If all label names listed in `equal` are missing 
  #   from both the source and target alerts,
  #   the inhibition rule will apply!
  equal: ['alertname']


receivers:
- name: 'team-X-mails'
  email_configs:
  - to: 'team-X+alerts@example.org, team-Y+alerts@example.org'

- name: 'team-X-pager'
  email_configs:
  - to: 'team-X+alerts-critical@example.org'
  pagerduty_configs:
  - routing_key: &amp;lt;team-X-key&amp;gt;

- name: 'team-Y-mails'
  email_configs:
  - to: 'team-Y+alerts@example.org'

- name: 'team-Y-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-Y-key&amp;gt;

- name: 'team-DB-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-DB-key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;p&gt;The current Alertmanager API is version 2. This API is fully generated via the &lt;a href="https://github.com/OAI/OpenAPI-Specification/raw/master/versions/2.0.md"&gt;OpenAPI project&lt;/a&gt; and &lt;a href="https://github.com/go-swagger/go-swagger/"&gt;Go Swagger&lt;/a&gt; with the exception of the HTTP handlers themselves. The API specification can be found in &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;api/v2/openapi.yaml&lt;/a&gt;. A HTML rendered version can be accessed &lt;a href="http://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;here&lt;/a&gt;. Clients can be easily generated via any OpenAPI generator for all major languages.&lt;/p&gt; 
&lt;p&gt;APIv2 is accessed via the &lt;code&gt;/api/v2&lt;/code&gt; prefix. APIv1 was deprecated in &lt;code&gt;0.16.0&lt;/code&gt; and is removed as of version &lt;code&gt;0.27.0&lt;/code&gt;. The v2 &lt;code&gt;/status&lt;/code&gt; endpoint would be &lt;code&gt;/api/v2/status&lt;/code&gt;. If &lt;code&gt;--web.route-prefix&lt;/code&gt; is set then API routes are prefixed with that as well, so &lt;code&gt;--web.route-prefix=/alertmanager/&lt;/code&gt; would relate to &lt;code&gt;/alertmanager/api/v2/status&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;amtool&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; is a cli tool for interacting with the Alertmanager API. It is bundled with all releases of Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;Alternatively you can install with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/amtool@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;p&gt;View all currently firing alerts:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool alert
Alertname        Starts At                Summary
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View all currently firing alerts with extended output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to viewing alerts, you can use the rich query syntax provided by Alertmanager:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert query alertname="Test_Alert"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query instance=~".+1"
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query alertname=~"Test.*" instance=~".+1"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Silence an alert:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence add alertname=Test_Alert
b3ede22e-ca14-4aa0-932c-ca2f3445f926

$ amtool silence add alertname="Test_Alert" instance=~".+0"
e48cb58a-0b17-49ba-b734-3585139b1d25
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query
ID                                    Matchers              Ends At                  Created By  Comment
b3ede22e-ca14-4aa0-932c-ca2f3445f926  alertname=Test_Alert  2017-08-02 19:54:50 UTC  kellel

$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire a silence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire b3ede22e-ca14-4aa0-932c-ca2f3445f926
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences matching a query:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel

$ amtool silence expire $(amtool silence query -q instance=~".+0")

$ amtool silence query instance=~".+0"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire $(amtool silence query -q)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try out how a template works. Let's say you have this in your configuration file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;templates:
  - '/foo/bar/*.tmpl'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can test out how a template would look like with example by using this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;amtool template render --template.glob='/foo/bar/*.tmpl' --template.text='{{ template "slack.default.markdown.v1" . }}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows a configuration file to specify some options for convenience. The default configuration file paths are &lt;code&gt;$HOME/.config/amtool/config.yml&lt;/code&gt; or &lt;code&gt;/etc/amtool/config.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;An example configuration file might look like the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Define the path that `amtool` can find your `alertmanager` instance
alertmanager.url: "http://localhost:9093"

# Override the default author. (unset defaults to your username)
author: me@example.com

# Force amtool to give you an error if you don't include a comment on a silence
comment_required: true

# Set a default output format. (unset defaults to simple)
output: extended

# Set a default receiver
receiver: team-X-pager
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Routes&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows you to visualize the routes of your configuration in form of text tree view. Also you can use it to test the routing by passing it label set of an alert and it prints out all receivers the alert would match ordered and separated by &lt;code&gt;,&lt;/code&gt;. (If you use &lt;code&gt;--verify.receivers&lt;/code&gt; amtool returns error code 1 on mismatch)&lt;/p&gt; 
&lt;p&gt;Example of usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# View routing tree of remote Alertmanager
$ amtool config routes --alertmanager.url=http://localhost:9090

# Test if alert matches expected receiver
$ amtool config routes test --config.file=doc/examples/simple.yml --tree --verify.receivers=team-X-pager service=database owner=team-X
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;High Availability&lt;/h2&gt; 
&lt;p&gt;Alertmanager's high availability is in production use at many companies and is enabled by default.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Both UDP and TCP are needed in alertmanager 0.15 and higher for the cluster to work.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you are using a firewall, make sure to whitelist the clustering port for both protocols.&lt;/li&gt; 
  &lt;li&gt;If you are running in a container, make sure to expose the clustering port for both protocols.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To create a highly available cluster of the Alertmanager the instances need to be configured to communicate with each other. This is configured using the &lt;code&gt;--cluster.*&lt;/code&gt; flags.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.listen-address&lt;/code&gt; string: cluster listen address (default "0.0.0.0:9094"; empty string disables HA mode)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.advertise-address&lt;/code&gt; string: cluster advertise address&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer&lt;/code&gt; value: initial peers (repeat flag for each additional peer)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer-timeout&lt;/code&gt; value: peer timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peers-resolve-timeout&lt;/code&gt; value: peers resolve timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.gossip-interval&lt;/code&gt; value: cluster message propagation speed (default "200ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.pushpull-interval&lt;/code&gt; value: lower values will increase convergence speeds at expense of bandwidth (default "1m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.settle-timeout&lt;/code&gt; value: maximum time to wait for cluster connections to settle before evaluating notifications.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.tcp-timeout&lt;/code&gt; value: timeout value for tcp connections, reads and writes (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-timeout&lt;/code&gt; value: time to wait for ack before marking node unhealthy (default "500ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-interval&lt;/code&gt; value: interval between random node probes (default "1s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-interval&lt;/code&gt; value: interval between attempting to reconnect to lost peers (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-timeout&lt;/code&gt; value: length of time to attempt to reconnect to a lost peer (default: "6h0m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.label&lt;/code&gt; value: the label is an optional string to include on each packet and stream. It uniquely identifies the cluster and prevents cross-communication issues when sending gossip messages (default:"")&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The chosen port in the &lt;code&gt;cluster.listen-address&lt;/code&gt; flag is the port that needs to be specified in the &lt;code&gt;cluster.peer&lt;/code&gt; flag of the other peers.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;cluster.advertise-address&lt;/code&gt; flag is required if the instance doesn't have an IP address that is part of &lt;a href="https://tools.ietf.org/html/rfc6890"&gt;RFC 6890&lt;/a&gt; with a default route.&lt;/p&gt; 
&lt;p&gt;To start a cluster of three peers on your local machine use &lt;a href="https://github.com/mattn/goreman"&gt;&lt;code&gt;goreman&lt;/code&gt;&lt;/a&gt; and the Procfile within this repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;goreman start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To point your Prometheus 1.4, or later, instance to multiple Alertmanagers, configure them in your &lt;code&gt;prometheus.yml&lt;/code&gt; configuration file, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager1:9093
      - alertmanager2:9093
      - alertmanager3:9093
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Do not load balance traffic between Prometheus and its Alertmanagers, but instead point Prometheus to a list of all Alertmanagers. The Alertmanager implementation expects all alerts to be sent to all Alertmanagers to ensure high availability.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Turn off high availability&lt;/h3&gt; 
&lt;p&gt;If running Alertmanager in high availability mode is not desired, setting &lt;code&gt;--cluster.listen-address=&lt;/code&gt; prevents Alertmanager from listening to incoming peer requests.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Check the &lt;a href="https://github.com/prometheus/prometheus/raw/main/CONTRIBUTING.md"&gt;Prometheus contributing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To contribute to the user interface, refer to &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/ui/app/CONTRIBUTING.md"&gt;ui/app/CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/prometheus/alertmanager/main/doc/arch.svg?sanitize=true" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0, see &lt;a href="https://github.com/prometheus/alertmanager/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kvcache-ai/ktransformers</title>
      <link>https://github.com/kvcache-ai/ktransformers</link>
      <description>&lt;p&gt;A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;!-- &lt;h1&gt;KTransformers&lt;/h1&gt; --&gt; 
 &lt;p align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="KTransformers" src="https://github.com/user-attachments/assets/d5a2492f-a415-4456-af99-4ab102f13f8b" width="50%" /&gt; 
  &lt;/picture&gt; &lt;/p&gt; 
 &lt;h3&gt;A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations&lt;/h3&gt; 
 &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#show-cases"&gt;üåü Show Cases&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#quick-start"&gt;üöÄ Quick Start&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#tutorial"&gt;üìÉ Tutorial&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#Citation"&gt;üî• Citation &lt;/a&gt; | &lt;a href="https://github.com/kvcache-ai/ktransformers/discussions"&gt;üí¨ Discussion &lt;/a&gt;|&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#FAQ"&gt; üôã FAQ&lt;/a&gt; &lt;/strong&gt; 
&lt;/div&gt; 
&lt;h2 id="intro"&gt;üéâ Introduction&lt;/h2&gt; KTransformers, pronounced as Quick Transformers, is designed to enhance your ü§ó 
&lt;a href="https://github.com/huggingface/transformers"&gt;Transformers&lt;/a&gt; experience with advanced kernel optimizations and placement/parallelism strategies. 
&lt;br /&gt;
&lt;br /&gt; KTransformers is a flexible, Python-centric framework designed with extensibility at its core. By implementing and injecting an optimized module with a single line of code, users gain access to a Transformers-compatible interface, RESTful APIs compliant with OpenAI and Ollama, and even a simplified ChatGPT-like web UI. 
&lt;br /&gt;
&lt;br /&gt; Our vision for KTransformers is to serve as a flexible platform for experimenting with innovative LLM inference optimizations. Please let us know if you need any other features. 
&lt;h2 id="Updates"&gt;üî• Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Nov 6, 2025&lt;/strong&gt;: Support Kimi-K2-Thinking inference (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2-Thinking.md"&gt;Tutorial&lt;/a&gt;) and fine-tune (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/SFT_Installation_Guide_KimiK2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Nov 4, 2025&lt;/strong&gt;: KTransformers Fine-Tuning √ó LLaMA-Factory Integration. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/KTransformers-Fine-Tuning_User-Guide.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 27, 2025&lt;/strong&gt;: Support Ascend NPU. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/zh/DeepseekR1_V3_tutorial_zh_for_Ascend_NPU.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 10, 2025&lt;/strong&gt;: Integrating into SGLang. (&lt;a href="https://github.com/sgl-project/sglang/issues/11425"&gt;Roadmap&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sept 11, 2025&lt;/strong&gt;: Support Qwen3-Next. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Qwen3-Next.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sept 05, 2025&lt;/strong&gt;: Support Kimi-K2-0905. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 26, 2025&lt;/strong&gt;: Support SmallThinker and GLM4-MoE. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/SmallThinker_and_Glm4moe.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 11, 2025&lt;/strong&gt;: Support Kimi-K2. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;June 30, 2025&lt;/strong&gt;: Support 3-layer (GPU-CPU-Disk) &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/prefix_cache.md"&gt;prefix cache&lt;/a&gt; reuse.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;May 14, 2025&lt;/strong&gt;: Support Intel Arc GPU (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/xpu.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 29, 2025&lt;/strong&gt;: Support AMX-Int8„ÄÅ AMX-BF16 and Qwen3MoE (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/AMX.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fafe8aec-4e22-49a8-8553-59fb5c6b00a2"&gt;https://github.com/user-attachments/assets/fafe8aec-4e22-49a8-8553-59fb5c6b00a2&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 9, 2025&lt;/strong&gt;: Experimental support for LLaMA 4 models (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/llama4.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 2, 2025&lt;/strong&gt;: Support Multi-concurrency. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/balance-serve.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/faa3bda2-928b-45a7-b44f-21e12ec84b8a"&gt;https://github.com/user-attachments/assets/faa3bda2-928b-45a7-b44f-21e12ec84b8a&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 15, 2025&lt;/strong&gt;: Support ROCm on AMD GPU (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/ROCm.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 5, 2025&lt;/strong&gt;: Support unsloth 1.58/2.51 bits weights and &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/fp8_kernel.md"&gt;IQ1_S/FP8 hybrid&lt;/a&gt; weights. Support 139K &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md#v022--v023-longer-context--fp8-kernel"&gt;Longer Context&lt;/a&gt; for DeepSeek-V3 and R1 in 24GB VRAM.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 25, 2025&lt;/strong&gt;: Support &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/fp8_kernel.md"&gt;FP8 GPU kernel&lt;/a&gt; for DeepSeek-V3 and R1; &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md#v022-longer-context"&gt;Longer Context&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 15, 2025&lt;/strong&gt;: Longer Context (from 4K to 8K for 24GB VRAM) &amp;amp; Slightly Faster Speed Ôºà+15%, up to 16 Tokens/s), update &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;docs&lt;/a&gt; and &lt;a href="https://kvcache-ai.github.io/ktransformers/"&gt;online books&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 10, 2025&lt;/strong&gt;: Support Deepseek-R1 and V3 on single (24GB VRAM)/multi gpu and 382G DRAM, up to 3~28x speedup. For detailed show case and reproduction tutorial, see &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 28, 2024&lt;/strong&gt;: Decrease DeepseekV2's required VRAM from 21G to 11G.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 15, 2024&lt;/strong&gt;: Update detailed &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/injection_tutorial.md"&gt;tutorial&lt;/a&gt; for injection and multi-GPU.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 14, 2024&lt;/strong&gt;: Support llamfile as linear backend.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 12, 2024&lt;/strong&gt;: Support multiple GPU; Support new model: mixtral 8*7B and 8*22B; Support q2k, q3k, q5k dequant on gpu.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 9, 2024&lt;/strong&gt;: Support windows native.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- * **Aug 28, 2024**: Support 1M context under the InternLM2.5-7B-Chat-1M model, utilizing 24GB of VRAM and 150GB of DRAM. The detailed tutorial is [here](./doc/en/long_context_tutorial.md). --&gt; 
&lt;h2 id="show-cases"&gt;üåü Show Cases&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;GPT-4/o1-level Local VSCode Copilot on a Desktop with only 24GB VRAM&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ebd70bfa-b2c1-4abb-ae3b-296ed38aa285"&gt;https://github.com/user-attachments/assets/ebd70bfa-b2c1-4abb-ae3b-296ed38aa285&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[NEW!!!] Local 671B DeepSeek-Coder-V3/R1:&lt;/strong&gt; Running its Q4_K_M version using only 14GB VRAM and 382GB DRAM(&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;Tutorial&lt;/a&gt;).&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Prefill Speed (tokens/s): 
    &lt;ul&gt; 
     &lt;li&gt;KTransformers: 54.21 (32 cores) ‚Üí 74.362 (dual-socket, 2√ó32 cores) ‚Üí 255.26 (optimized AMX-based MoE kernel, V0.3 only) ‚Üí 286.55 (selectively using 6 experts, V0.3 only)&lt;/li&gt; 
     &lt;li&gt;Compared to 10.31 tokens/s in llama.cpp with 2√ó32 cores, achieving up to &lt;strong&gt;27.79√ó speedup&lt;/strong&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Decode Speed (tokens/s): 
    &lt;ul&gt; 
     &lt;li&gt;KTransformers: 8.73 (32 cores) ‚Üí 11.26 (dual-socket, 2√ó32 cores) ‚Üí 13.69 (selectively using 6 experts, V0.3 only)&lt;/li&gt; 
     &lt;li&gt;Compared to 4.51 tokens/s in llama.cpp with 2√ó32 cores, achieving up to &lt;strong&gt;3.03√ó speedup&lt;/strong&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Upcoming Open Source Release: 
    &lt;ul&gt; 
     &lt;li&gt;AMX optimizations and selective expert activation will be open-sourced in V0.3.&lt;/li&gt; 
     &lt;li&gt;Currently available only in preview binary distribution, which can be downloaded &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;here&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Local 236B DeepSeek-Coder-V2:&lt;/strong&gt; Running its Q4_K_M version using only 21GB VRAM and 136GB DRAM, attainable on a local desktop machine, which scores even better than GPT4-0613 in &lt;a href="https://huggingface.co/blog/leaderboard-bigcodebench"&gt;BigCodeBench&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="DeepSeek-Coder-V2 Score" src="https://github.com/user-attachments/assets/d052924e-8631-44de-aad2-97c54b965693" width="100%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Faster Speed:&lt;/strong&gt; Achieving 126 tokens/s for 2K prompt prefill and 13.6 tokens/s for generation through MoE offloading and injecting advanced kernels from &lt;a href="https://github.com/Mozilla-Ocho/llamafile/tree/main"&gt;Llamafile&lt;/a&gt; and &lt;a href="https://github.com/IST-DASLab/marlin"&gt;Marlin&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;VSCode Integration:&lt;/strong&gt; Wrapped into an OpenAI and Ollama compatible API for seamless integration as a backend for &lt;a href="https://github.com/TabbyML/tabby"&gt;Tabby&lt;/a&gt; and various other frontends.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4c6a8a38-05aa-497d-8eb1-3a5b3918429c"&gt;https://github.com/user-attachments/assets/4c6a8a38-05aa-497d-8eb1-3a5b3918429c&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;!-- &lt;h3&gt;1M Context Local Inference on a Desktop with Only 24GB VRAM&lt;/h3&gt;
&lt;p align="center"&gt;

https://github.com/user-attachments/assets/a865e5e4-bca3-401e-94b8-af3c080e6c12

* **1M Context InternLM 2.5 7B**: Operates at full bf16 precision, utilizing 24GB VRAM and 150GB DRAM, which is feasible on a local desktop setup. It achieves a 92.88% success rate on the 1M "Needle In a Haystack" test and 100% on the 128K NIAH test.

&lt;p align="center"&gt;
  &lt;picture&gt;
    &lt;img alt="Single Needle Retrieval 128K" src="./doc/assets/needle_128K.png" width=100%&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align="center"&gt;
  &lt;picture&gt;
    &lt;img alt="Single Needle Retrieval 1000K" src="./doc/assets/needle_1M.png" width=100%&gt;
  &lt;/picture&gt;
&lt;/p&gt;

* **Enhanced Speed**: Reaches 16.91 tokens/s for generation with a 1M context using sparse attention, powered by llamafile kernels. This method is over 10 times faster than full attention approach of llama.cpp.

* **Flexible Sparse Attention Framework**: Offers a flexible block sparse attention framework for CPU offloaded decoding. Compatible with SnapKV, Quest, and InfLLm. Further information is available [here](./doc/en/long_context_introduction.md).
 --&gt; 
&lt;p&gt;&lt;strong&gt;More advanced features will coming soon, so stay tuned!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2 id="quick-start"&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;p&gt;Getting started with KTransformers is simple! Follow the steps below to set up and start using it.&lt;/p&gt; 
&lt;p&gt;we have already supported vendors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Metax&lt;/li&gt; 
 &lt;li&gt;Sanechips (ZhuFeng V1.0)&lt;/li&gt; 
 &lt;li&gt;Intel&lt;/li&gt; 
 &lt;li&gt;Ascend&lt;/li&gt; 
 &lt;li&gt;Kunpeng&lt;/li&gt; 
 &lt;li&gt;AMD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì• Installation&lt;/h3&gt; 
&lt;p&gt;To install KTransformers, follow the official &lt;a href="https://kvcache-ai.github.io/ktransformers/en/install.html"&gt;Installation Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2 id="tutorial"&gt;üìÉ Brief Injection Tutorial&lt;/h2&gt; At the heart of KTransformers is a user-friendly, template-based injection framework. This allows researchers to easily replace original torch modules with optimized variants. It also simplifies the process of combining multiple optimizations, allowing the exploration of their synergistic effects. 
&lt;br /&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="Inject-Struction" src="https://github.com/user-attachments/assets/6b4c1e54-9f6d-45c5-a3fc-8fa45e7d257e" width="65%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p&gt;Given that vLLM already serves as a great framework for large-scale deployment optimizations, KTransformers is particularly focused on local deployments that are constrained by limited resources. We pay special attention to heterogeneous computing opportunities, such as GPU/CPU offloading of quantized models. For example, we support the efficient &lt;a herf="https://github.com/Mozilla-Ocho/llamafile/tree/main"&gt;Llamafile&lt;/a&gt; and &lt;a herf="https://github.com/IST-DASLab/marlin"&gt;Marlin&lt;/a&gt; kernels for CPU and GPU, respectively. More details can be found &lt;a herf="doc/en/operators/llamafile.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Example Usage&lt;/h3&gt; To utilize the provided kernels, users only need to create a YAML-based injection template and add the call to `optimize_and_load_gguf` before using the Transformers model. 
&lt;pre&gt;&lt;code class="language-python"&gt;with torch.device("meta"):
    model = AutoModelForCausalLM.from_config(config, trust_remote_code=True)
optimize_and_load_gguf(model, optimize_config_path, gguf_path, config)
...
generated = prefill_and_generate(model, tokenizer, input_tensor.cuda(), max_new_tokens=1000)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this example, the AutoModel is first initialized on the meta device to avoid occupying any memory resources. Then, &lt;code&gt;optimize_and_load_gguf&lt;/code&gt; iterates through all sub-modules of the model, matches rules specified in your YAML rule file, and replaces them with advanced modules as specified.&lt;/p&gt; 
&lt;p&gt;After injection, the original &lt;code&gt;generate&lt;/code&gt; interface is available, but we also provide a compatible &lt;code&gt;prefill_and_generate&lt;/code&gt; method, which enables further optimizations like CUDAGraph to improve generation speed.&lt;/p&gt; 
&lt;h3&gt;How to custom your model&lt;/h3&gt; 
&lt;p&gt;A detailed tutorial of the injection and multi-GPU using DeepSeek-V2 as an example is given &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/injection_tutorial.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Below is an example of a YAML template for replacing all original Linear modules with Marlin, an advanced 4-bit quantization kernel.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;- match:
    name: "^model\\.layers\\..*$"  # regular expression 
    class: torch.nn.Linear  # only match modules matching name and class simultaneously
  replace:
    class: ktransformers.operators.linear.KTransformerLinear  # optimized Kernel on quantized data types
    device: "cpu"   # which devices to load this module when initializing
    kwargs:
      generate_device: "cuda"
      generate_linear_type: "QuantizedLinearMarlin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Each rule in the YAML file has two parts: &lt;code&gt;match&lt;/code&gt; and &lt;code&gt;replace&lt;/code&gt;. The &lt;code&gt;match&lt;/code&gt; part specifies which module should be replaced, and the &lt;code&gt;replace&lt;/code&gt; part specifies the module to be injected into the model along with the initialization keywords.&lt;/p&gt; 
&lt;p&gt;You can find example rule templates for optimizing DeepSeek-V2 and Qwen2-57B-A14, two SOTA MoE models, in the &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/ktransformers/optimize/optimize_rules"&gt;ktransformers/optimize/optimize_rules&lt;/a&gt; directory. These templates are used to power the &lt;code&gt;local_chat.py&lt;/code&gt; demo.&lt;/p&gt; 
&lt;p&gt;If you are interested in our design principles and the implementation of the injection framework, please refer to the &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/deepseek-v2-injection.md"&gt;design document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2 id="Citation"&gt;üî• Citation&lt;/h2&gt; 
&lt;p&gt;If you use KTransformers for your research, please cite our &lt;a href="https://madsys.cs.tsinghua.edu.cn/publication/ktransformers-unleashing-the-full-potential-of-cpu/gpu-hybrid-inference-for-moe-models/"&gt;paper&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@inproceedings{10.1145/3731569.3764843,
title = {KTransformers: Unleashing the Full Potential of CPU/GPU Hybrid Inference for MoE Models},
author = {Chen, Hongtao and Xie, Weiyu and Zhang, Boxin and Tang, Jingqi and Wang, Jiahao and Dong, Jianwei and Chen, Shaoyuan and Yuan, Ziwei and Lin, Chen and Qiu, Chengyu and Zhu, Yuening and Ou, Qingliang and Liao, Jiaqi and Chen, Xianglin and Ai, Zhiyuan and Wu, Yongwei and Zhang, Mingxing},
booktitle = {Proceedings of the ACM SIGOPS 31st Symposium on Operating Systems Principles},
year = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2 id="ack"&gt;Acknowledgment and Contributors&lt;/h2&gt; 
&lt;p&gt;The development of KTransformers is based on the flexible and versatile framework provided by Transformers. We also benefit from advanced kernels such as GGUF/GGML, Llamafile, Marlin, sglang and flashinfer. We are planning to contribute back to the community by upstreaming our modifications.&lt;/p&gt; 
&lt;p&gt;KTransformers is actively maintained and developed by contributors from the &lt;a href="https://madsys.cs.tsinghua.edu.cn/"&gt;MADSys group&lt;/a&gt; at Tsinghua University and members from &lt;a href="http://approaching.ai/"&gt;Approaching.AI&lt;/a&gt;. We welcome new contributors to join us in making KTransformers faster and easier to use.&lt;/p&gt; 
&lt;h2 id="ack"&gt;Discussion&lt;/h2&gt; 
&lt;p&gt;If you have any questions, feel free to open an issue. Alternatively, you can join our WeChat group for further discussion. QR Code: &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/WeChatGroup.png"&gt;WeChat Group&lt;/a&gt;&lt;/p&gt; 
&lt;h2 id="FAQ"&gt;üôã FAQ&lt;/h2&gt; 
&lt;p&gt;Some common questions are answered in the &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/FAQ.md"&gt;FAQ&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GeeeekExplorer/nano-vllm</title>
      <link>https://github.com/GeeeekExplorer/nano-vllm</link>
      <description>&lt;p&gt;Nano vLLM&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="300" src="https://raw.githubusercontent.com/GeeeekExplorer/nano-vllm/main/assets/logo.png" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15323" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15323" alt="GeeeekExplorer%2Fnano-vllm | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Nano-vLLM&lt;/h1&gt; 
&lt;p&gt;A lightweight vLLM implementation built from scratch.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Fast offline inference&lt;/strong&gt; - Comparable inference speeds to vLLM&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Readable codebase&lt;/strong&gt; - Clean implementation in ~ 1,200 lines of Python code&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Optimization Suite&lt;/strong&gt; - Prefix caching, Tensor Parallelism, Torch compilation, CUDA graph, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/GeeeekExplorer/nano-vllm.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Download&lt;/h2&gt; 
&lt;p&gt;To download the model weights manually, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;huggingface-cli download --resume-download Qwen/Qwen3-0.6B \
  --local-dir ~/huggingface/Qwen3-0.6B/ \
  --local-dir-use-symlinks False
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;example.py&lt;/code&gt; for usage. The API mirrors vLLM's interface with minor differences in the &lt;code&gt;LLM.generate&lt;/code&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from nanovllm import LLM, SamplingParams
llm = LLM("/YOUR/MODEL/PATH", enforce_eager=True, tensor_parallel_size=1)
sampling_params = SamplingParams(temperature=0.6, max_tokens=256)
prompts = ["Hello, Nano-vLLM."]
outputs = llm.generate(prompts, sampling_params)
outputs[0]["text"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;bench.py&lt;/code&gt; for benchmark.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Test Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hardware: RTX 4070 Laptop (8GB)&lt;/li&gt; 
 &lt;li&gt;Model: Qwen3-0.6B&lt;/li&gt; 
 &lt;li&gt;Total Requests: 256 sequences&lt;/li&gt; 
 &lt;li&gt;Input Length: Randomly sampled between 100‚Äì1024 tokens&lt;/li&gt; 
 &lt;li&gt;Output Length: Randomly sampled between 100‚Äì1024 tokens&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Results:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Inference Engine&lt;/th&gt; 
   &lt;th&gt;Output Tokens&lt;/th&gt; 
   &lt;th&gt;Time (s)&lt;/th&gt; 
   &lt;th&gt;Throughput (tokens/s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;98.37&lt;/td&gt; 
   &lt;td&gt;1361.84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nano-vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;93.41&lt;/td&gt; 
   &lt;td&gt;1434.13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#GeeeekExplorer/nano-vllm&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=GeeeekExplorer/nano-vllm&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/agent-lightning</title>
      <link>https://github.com/microsoft/agent-lightning</link>
      <description>&lt;p&gt;The absolute trainer to light up AI agents.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-banner.svg?sanitize=true" alt="Agent-lightning-banner" style="width:600px" /&gt; &lt;/p&gt; 
&lt;h1&gt;Agent Lightning‚ö°&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;&lt;img src="https://img.shields.io/badge/GitHub%20Pages-Documentation-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/agentlightning"&gt;&lt;img src="https://badge.fury.io/py/agentlightning.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/microsoft/agent-lightning"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The absolute trainer to light up AI agents.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;Discord community&lt;/a&gt; to connect with other users and contributors.&lt;/p&gt; 
&lt;h2&gt;‚ö° Core Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Turn your agent into an optimizable beast with &lt;strong&gt;ZERO CODE CHANGE&lt;/strong&gt; (almost)! üí§&lt;/li&gt; 
 &lt;li&gt;Build with &lt;strong&gt;ANY&lt;/strong&gt; agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! ü§ñ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Selectively&lt;/strong&gt; optimize one or more agents in a multi-agent system. üéØ&lt;/li&gt; 
 &lt;li&gt;Embraces &lt;strong&gt;Algorithms&lt;/strong&gt; like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. ü§ó&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more on our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-diff.svg?sanitize=true" alt="Agent-Lightning Core Quickstart" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install agentlightning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://microsoft.github.io/agent-lightning/stable/tutorials/installation/"&gt;installation guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;To start using Agent-lightning, check out our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/examples"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ö° Articles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;11/4/2025 &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-1-1d8c9a397f0e"&gt;Tuning ANY AI agent with Tinker ‚úï Agent-lightning&lt;/a&gt; Medium. See also &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-2-332c5437f0dc"&gt;Part 2&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;10/22/2025 &lt;a href="https://blog.vllm.ai/2025/10/22/agent-lightning.html"&gt;No More Retokenization Drift: Returning Token IDs via the OpenAI Compatible API Matters in Agent RL&lt;/a&gt; vLLM blog. See also &lt;a href="https://zhuanlan.zhihu.com/p/1965067274642785725"&gt;Zhihu writeup&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;8/11/2025 &lt;a href="https://medium.com/@yugez/training-ai-agents-to-write-and-self-correct-sql-with-reinforcement-learning-571ed31281ad"&gt;Training AI Agents to Write and Self-correct SQL with Reinforcement Learning&lt;/a&gt; Medium.&lt;/li&gt; 
 &lt;li&gt;8/5/2025 &lt;a href="https://arxiv.org/abs/2508.03680"&gt;Agent Lightning: Train ANY AI Agents with Reinforcement Learning&lt;/a&gt; arXiv paper.&lt;/li&gt; 
 &lt;li&gt;7/26/2025 &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/"&gt;We discovered an approach to train any AI agent with RL, with (almost) zero code changes.&lt;/a&gt; Reddit.&lt;/li&gt; 
 &lt;li&gt;6/6/2025 &lt;a href="https://www.microsoft.com/en-us/research/project/agent-lightning/"&gt;Agent Lightning - Microsoft Research&lt;/a&gt; Project page.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Community Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/af-74413592/DeepWerewolf"&gt;DeepWerewolf&lt;/a&gt; ‚Äî A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://agentflow.stanford.edu/"&gt;AgentFlow&lt;/a&gt; ‚Äî A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Architecture&lt;/h2&gt; 
&lt;p&gt;Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight &lt;code&gt;agl.emit_xxx()&lt;/code&gt; helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.&lt;/p&gt; 
&lt;p&gt;On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.&lt;/p&gt; 
&lt;p&gt;No rewrites, no lock-in, just a clear path from first rollout to steady improvement.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-architecture.svg?sanitize=true" alt="Agent-lightning Architecture" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° CI Status&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Workflow&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="tests workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GPU Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml/badge.svg?sanitize=true" alt="tests-full workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Examples Integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml/badge.svg?sanitize=true" alt="examples summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Latest Dependency Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml/badge.svg?sanitize=true" alt="latest summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Legacy Examples Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/examples-compat.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/examples-compat.yml/badge.svg?sanitize=true" alt="examples compatibility workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚ö° Citation&lt;/h2&gt; 
&lt;p&gt;If you find Agent Lightning useful in your research or projects, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{luo2025agentlightningtrainai,
      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},
      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},
      year={2025},
      eprint={2508.03680},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.03680},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ö° Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Start by reading the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/community/contributing.md"&gt;Contributing Guide&lt;/a&gt; for environment setup, branching conventions, and pull request expectations. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;‚ö° Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt; 
&lt;h2&gt;‚ö° Responsible AI&lt;/h2&gt; 
&lt;p&gt;This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.&lt;/p&gt; 
&lt;h2&gt;‚ö° License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù
    ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù
    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/üêçPython-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div align="center" style="margin-top: 10px;"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README.md"&gt; &lt;img src="https://img.shields.io/badge/English-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="English" /&gt; &lt;/a&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README_ZH.md"&gt; &lt;img src="https://img.shields.io/badge/‰∏≠Êñá-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="‰∏≠Êñá" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;üñ•Ô∏è &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;üñ•Ô∏è &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;üöÄ Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;‚ö° Fast command-line workflow&lt;br /&gt;üîß Developer-friendly interface&lt;br /&gt;üìä Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;üåê &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;üé® Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;üñ±Ô∏è Intuitive drag-and-drop&lt;br /&gt;üì± Responsive design&lt;br /&gt;üéØ Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;üé¨ &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;üéØ &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/‚ñ∂Ô∏è_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìë Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-news"&gt;üì∞ News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;üöÄ Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;üèóÔ∏è Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-experimental-results"&gt;üìä Experimental Results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;üöÄ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;üí° Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;üé¨ Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;‚≠ê Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;üìÑ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üì∞ News&lt;/h2&gt; 
&lt;p&gt;üéâ &lt;strong&gt;[2025-10] üéâ [2025-10-28] DeepCode Achieves SOTA on PaperBench!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode sets new benchmarks on OpenAI's PaperBench Code-Dev across all categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üèÜ &lt;strong&gt;Surpasses Human Experts&lt;/strong&gt;: &lt;strong&gt;75.9%&lt;/strong&gt; (DeepCode) vs Top Machine Learning PhDs 72.4% (+3.5%).&lt;/li&gt; 
 &lt;li&gt;ü•á &lt;strong&gt;Outperforms SOTA Commercial Code Agents&lt;/strong&gt;: &lt;strong&gt;84.8%&lt;/strong&gt; (DeepCode) vs Leading Commercial Code Agents (+26.1%) (Cursor, Claude Code, and Codex).&lt;/li&gt; 
 &lt;li&gt;üî¨ &lt;strong&gt;Advances Scientific Coding&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs PaperCoder 51.1% (+22.4%).&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Beats LLM Agents&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs best LLM frameworks 43.3% (+30.2%).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;üöÄ &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;üé® &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;‚öôÔ∏è &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìä Experimental Results&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/result_main02.jpg" /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;We evaluate &lt;strong&gt;DeepCode&lt;/strong&gt; on the &lt;a href="https://openai.com/index/paperbench/"&gt;&lt;em&gt;PaperBench&lt;/em&gt;&lt;/a&gt; benchmark (released by OpenAI), a rigorous testbed requiring AI agents to independently reproduce 20 ICML 2024 papers from scratch. The benchmark comprises 8,316 gradable components assessed using SimpleJudge with hierarchical weighting.&lt;/p&gt; 
&lt;p&gt;Our experiments compare DeepCode against four baseline categories: &lt;strong&gt;(1) Human Experts&lt;/strong&gt;, &lt;strong&gt;(2) State-of-the-Art Commercial Code Agents&lt;/strong&gt;, &lt;strong&gt;(3) Scientific Code Agents&lt;/strong&gt;, and &lt;strong&gt;(4) LLM-Based Agents&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;‚ë† üß† Human Expert Performance (Top Machine Learning PhD)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 75.9% vs. Top Machine Learning PhD: 72.4% (+3.5%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode achieves &lt;strong&gt;75.9%&lt;/strong&gt; on the 3-paper human evaluation subset, &lt;strong&gt;surpassing the best-of-3 human expert baseline (72.4%) by +3.5 percentage points&lt;/strong&gt;. This demonstrates that our framework not only matches but exceeds expert-level code reproduction capabilities, representing a significant milestone in autonomous scientific software engineering.&lt;/p&gt; 
&lt;h3&gt;‚ë° üíº State-of-the-Art Commercial Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 84.8% vs. Best Commercial Agent: 58.7% (+26.1%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;On the 5-paper subset, DeepCode substantially outperforms leading commercial coding tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cursor: 58.4%&lt;/li&gt; 
 &lt;li&gt;Claude Code: 58.7%&lt;/li&gt; 
 &lt;li&gt;Codex: 40.0%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 84.8%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This represents a &lt;strong&gt;+26.1% improvement&lt;/strong&gt; over the leading commercial code agent. All commercial agents utilize Claude Sonnet 4.5 or GPT-5 Codex-high, highlighting that &lt;strong&gt;DeepCode's superior architecture&lt;/strong&gt;‚Äîrather than base model capability‚Äîdrives this performance gap.&lt;/p&gt; 
&lt;h3&gt;‚ë¢ üî¨ Scientific Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. PaperCoder: 51.1% (+22.4%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Compared to PaperCoder (&lt;strong&gt;51.1%&lt;/strong&gt;), the state-of-the-art scientific code reproduction framework, DeepCode achieves &lt;strong&gt;73.5%&lt;/strong&gt;, demonstrating a &lt;strong&gt;+22.4% relative improvement&lt;/strong&gt;. This substantial margin validates our multi-module architecture combining planning, hierarchical task decomposition, code generation, and iterative debugging over simpler pipeline-based approaches.&lt;/p&gt; 
&lt;h3&gt;‚ë£ ü§ñ LLM-Based Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. Best LLM Agent: 43.3% (+30.2%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode significantly outperforms all tested LLM agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude 3.5 Sonnet + IterativeAgent: 27.5%&lt;/li&gt; 
 &lt;li&gt;o1 + IterativeAgent (36 hours): 42.4%&lt;/li&gt; 
 &lt;li&gt;o1 BasicAgent: 43.3%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 73.5%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;strong&gt;+30.2% improvement&lt;/strong&gt; over the best-performing LLM agent demonstrates that sophisticated agent scaffolding, rather than extended inference time or larger models, is critical for complex code reproduction tasks.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéØ &lt;strong&gt;Autonomous Self-Orchestrating Multi-Agent Architecture&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üìÑ &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üî¨ &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‚è±Ô∏è &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîÑ &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["üìÑ Research Papers&amp;lt;br/&amp;gt;üí¨ Text Prompts&amp;lt;br/&amp;gt;üåê URLs &amp;amp; Document&amp;lt;br/&amp;gt;üìé Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["üß† DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["üöÄ Algorithm Implementation &amp;lt;br/&amp;gt;üé® Frontend Development &amp;lt;br/&amp;gt;‚öôÔ∏è Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;h3&gt;üìä &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;üéØ &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;üß¨ &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;ü™Ñ &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;‚ö° &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;üíé &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;üîÆ &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üîß &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üß† &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üíæ &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîç &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ü§ñ &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéØ Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìÑ Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üèóÔ∏è Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìö Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üß¨ Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;üõ†Ô∏è &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;üîß Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;üì° &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;üõ†Ô∏è &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üîß &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üí° &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üîç brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåê bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÇ filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåê fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üì• github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìã file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚ö° command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üß¨ code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìö code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÑ document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;üîß &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;üõ†Ô∏è &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üéØ &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÑ read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚úçÔ∏è write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üêç execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÅ get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚öôÔ∏è set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìä get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;üéõÔ∏è &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üöÄ Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üåü &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; üí° &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; üìÑ Research Papers ‚Ä¢ üí¨ Natural Language ‚Ä¢ üåê URLs ‚Ä¢ üìã Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; üéØ &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making ‚Ä¢ Workflow Coordination ‚Ä¢ Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; üìù &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; üìÑ &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; üìã &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis ‚Ä¢ Code Requirements Parsing ‚Ä¢ Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; üîç &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; üìö &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; üß¨ &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation ‚Ä¢ Testing ‚Ä¢ Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ‚ö° &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; üì¶ Complete Codebase ‚Ä¢ üß™ Test Suite ‚Ä¢ üìö Documentation ‚Ä¢ üöÄ Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;üîÑ &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;üéØ Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;üß† Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;üîç Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;‚ö° Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;üì¶ &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;‚ö° &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# üöÄ Install DeepCode package directly
pip install deepcode-hku

# üîë Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# üîë Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# üîë Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# üìÑ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;üîß &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìÇ Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;üî• &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# üîΩ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# üì¶ Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# üîß Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# üîë Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# üîë Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# üìÑ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;üêç &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# üîΩ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# üì¶ Install dependencies
pip install -r requirements.txt

# üîë Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# üîë Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# üìÑ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;ü™ü &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;üîç &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üåê Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;‚ö° &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;üöÄ &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# üåê Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;üõ†Ô∏è &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;üåê &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;üñ•Ô∏è &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;üéØ &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üìÑ Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° Examples&lt;/h2&gt; 
&lt;h3&gt;üé¨ &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;üìÑ &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;‚ñ∂Ô∏è Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;üñºÔ∏è &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;‚ñ∂Ô∏è Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;üåê &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;‚ñ∂Ô∏è Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;üÜï &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;üìÑ &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üöÄ &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;üîß &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üìä &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ö° &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üöÄ &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/üöÄ_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/üèõÔ∏è_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/‚≠ê_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;üìÑ &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
 &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>sst/opentui</title>
      <link>https://github.com/sst/opentui</link>
      <description>&lt;p&gt;OpenTUI is a library for building terminal user interfaces (TUIs)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenTUI&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.npmjs.com/package/@opentui/core"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/@opentui/core?style=flat-square" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/sst/opentui/actions/workflows/build-core.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/sst/opentui/build-core.yml?style=flat-square&amp;amp;branch=main" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/msmps/awesome-opentui"&gt;&lt;img alt="awesome opentui list" src="https://awesome.re/badge-flat.svg?sanitize=true" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;OpenTUI is a TypeScript library for building terminal user interfaces (TUIs). It is currently in development and is not ready for production use. It will be the foundational TUI framework for both &lt;a href="https://opencode.ai"&gt;opencode&lt;/a&gt; and &lt;a href="https://terminal.shop"&gt;terminaldotshop&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Quick start with &lt;a href="https://bun.sh"&gt;bun&lt;/a&gt; and &lt;a href="https://github.com/msmps/create-tui"&gt;create-tui&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun create tui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This monorepo contains the following packages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/core"&gt;&lt;code&gt;@opentui/core&lt;/code&gt;&lt;/a&gt; - The core library works completely standalone, providing an imperative API and all the primitives.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/solid"&gt;&lt;code&gt;@opentui/solid&lt;/code&gt;&lt;/a&gt; - The SolidJS reconciler for OpenTUI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/react"&gt;&lt;code&gt;@opentui/react&lt;/code&gt;&lt;/a&gt; - The React reconciler for OpenTUI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/vue"&gt;&lt;code&gt;@opentui/vue&lt;/code&gt;&lt;/a&gt; - The Vue reconciler (unmaintained)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/go"&gt;&lt;code&gt;@opentui/go&lt;/code&gt;&lt;/a&gt; - Go bindings (unmaintained)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;NOTE: You must have &lt;a href="https://ziglang.org/learn/getting-started/"&gt;Zig&lt;/a&gt; installed on your system to build the packages.&lt;/p&gt; 
&lt;h3&gt;TypeScript/JavaScript&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun install @opentui/core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running Examples (from the repo root)&lt;/h2&gt; 
&lt;h3&gt;TypeScript Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun install
cd packages/core
bun run src/examples/index.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Local Development Linking&lt;/h3&gt; 
&lt;p&gt;When developing OpenTUI, you may want to test your changes in another project without publishing. The &lt;code&gt;link-opentui-dev.sh&lt;/code&gt; script makes this easy by creating symlinks (or copies) from your OpenTUI workspace to another project's &lt;code&gt;node_modules&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Basic usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/link-opentui-dev.sh /path/to/your/project
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will link &lt;code&gt;@opentui/core&lt;/code&gt; to your target project.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--react&lt;/code&gt; - Also link &lt;code&gt;@opentui/react&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--solid&lt;/code&gt; - Also link &lt;code&gt;@opentui/solid&lt;/code&gt; and &lt;code&gt;solid-js&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--dist&lt;/code&gt; - Link the built &lt;code&gt;dist&lt;/code&gt; directories instead of source packages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--copy&lt;/code&gt; - Copy the dist directories instead of symlinking (requires &lt;code&gt;--dist&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Link only core (default)
./scripts/link-opentui-dev.sh /path/to/your/project

# Link core and solid
./scripts/link-opentui-dev.sh /path/to/your/project --solid

# Link core and react, using dist directories
./scripts/link-opentui-dev.sh /path/to/your/project --react --dist

# Copy dist directories (useful for environments where symlinks don't work)
./scripts/link-opentui-dev.sh /path/to/your/project --dist --copy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The target project must have already run &lt;code&gt;bun install&lt;/code&gt; (or &lt;code&gt;npm install&lt;/code&gt;) to have a &lt;code&gt;node_modules&lt;/code&gt; directory&lt;/li&gt; 
 &lt;li&gt;By default, the script links to the source packages, allowing hot-reloading of changes&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;--dist&lt;/code&gt; when you need to test the built artifacts&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;--copy&lt;/code&gt; mode when working in environments that don't support symlinks well (e.g., Docker containers, Windows)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Showcase&lt;/h2&gt; 
&lt;p&gt;Consider showcasing your work on the &lt;a href="https://github.com/msmps/awesome-opentui"&gt;awesome-opentui&lt;/a&gt; list. A curated list of awesome resources and terminal user interfaces built with OpenTUI.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skyvern-AI/skyvern</title>
      <link>https://github.com/Skyvern-AI/skyvern</link>
      <description>&lt;p&gt;Automate browser based workflows with AI&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://www.skyvern.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_logo.png" /&gt; 
   &lt;img height="120" src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_logo_blackbg.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; üêâ Automate Browser-based workflows using LLMs and Computer Vision üêâ &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.skyvern.com/"&gt;&lt;img src="https://img.shields.io/badge/Website-blue?logo=googlechrome&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://www.skyvern.com/docs/"&gt;&lt;img src="https://img.shields.io/badge/Docs-yellow?logo=gitbook&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;&lt;img src="https://img.shields.io/discord/1212486326352617534?logo=discord&amp;amp;label=discord" /&gt;&lt;/a&gt; 
 &lt;!-- &lt;a href="https://pepy.tech/project/skyvern" target="_blank"&gt;&lt;img src="https://static.pepy.tech/badge/skyvern" alt="Total Downloads"/&gt;&lt;/a&gt; --&gt; &lt;a href="https://github.com/skyvern-ai/skyvern"&gt;&lt;img src="https://img.shields.io/github/stars/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/skyvernai"&gt;&lt;img src="https://img.shields.io/twitter/follow/skyvernai?style=social" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/95726232"&gt;&lt;img src="https://img.shields.io/badge/Follow%20 on%20LinkedIn-8A2BE2?logo=linkedin" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.skyvern.com"&gt;Skyvern&lt;/a&gt; automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;Traditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.&lt;/p&gt; 
&lt;p&gt;Instead of only relying on code-defined XPath interactions, Skyvern relies on Vision LLMs to learn and interact with the websites.&lt;/p&gt; 
&lt;h1&gt;How it works&lt;/h1&gt; 
&lt;p&gt;Skyvern was inspired by the Task-Driven autonomous agent design popularized by &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt; and &lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;AutoGPT&lt;/a&gt; -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Skyvern uses a swarm of agents to comprehend a website, and plan and execute its actions:&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_2_0_system_diagram.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_system_diagram.png" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;This approach has a few advantages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Skyvern can operate on websites it's never seen before, as it's able to map visual elements to actions necessary to complete a workflow, without any customized code&lt;/li&gt; 
 &lt;li&gt;Skyvern is resistant to website layout changes, as there are no pre-determined XPaths or other selectors our system is looking for while trying to navigate&lt;/li&gt; 
 &lt;li&gt;Skyvern is able to take a single workflow and apply it to a large number of websites, as it's able to reason through the interactions necessary to complete the workflow&lt;/li&gt; 
 &lt;li&gt;Skyvern leverages LLMs to reason through interactions to ensure we can cover complex situations. Examples include: 
  &lt;ol&gt; 
   &lt;li&gt;If you wanted to get an auto insurance quote from Geico, the answer to a common question "Were you eligible to drive at 18?" could be inferred from the driver receiving their license at age 16&lt;/li&gt; 
   &lt;li&gt;If you were doing competitor analysis, it's understanding that an Arnold Palmer 22 oz can at 7/11 is almost definitely the same product as a 23 oz can at Gopuff (even though the sizes are slightly different, which could be a rounding error!)&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A detailed technical report can be found &lt;a href="https://www.skyvern.com/blog/skyvern-2-0-state-of-the-art-web-navigation-with-85-8-on-webvoyager-eval/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Demo&lt;/h1&gt; 
&lt;!-- Redo demo --&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f"&gt;https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Performance &amp;amp; Evaluation&lt;/h1&gt; 
&lt;p&gt;Skyvern has SOTA performance on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/webbench.ai"&gt;WebBench benchmark&lt;/a&gt; with a 64.4% accuracy. The technical report + evaluation can be found &lt;a href="https://www.skyvern.com/blog/web-bench-a-new-way-to-compare-ai-browser-agents/"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_overall.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Performance on WRITE tasks (eg filling out forms, logging in, downloading files, etc)&lt;/h2&gt; 
&lt;p&gt;Skyvern is the best performing agent on WRITE tasks (eg filling out forms, logging in, downloading files, etc), which is primarily used for RPA (Robotic Process Automation) adjacent tasks.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_write.png" /&gt; &lt;/p&gt; 
&lt;h1&gt;Quickstart&lt;/h1&gt; 
&lt;h2&gt;Skyvern Cloud&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com"&gt;Skyvern Cloud&lt;/a&gt; is a managed cloud version of Skyvern that allows you to run Skyvern without worrying about the infrastructure. It allows you to run multiple Skyvern instances in parallel and comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solvers.&lt;/p&gt; 
&lt;p&gt;If you'd like to try it out, navigate to &lt;a href="https://app.skyvern.com"&gt;app.skyvern.com&lt;/a&gt; and create an account.&lt;/p&gt; 
&lt;h2&gt;Install &amp;amp; Run&lt;/h2&gt; 
&lt;p&gt;Dependencies needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python 3.11.x&lt;/a&gt;, works with 3.12, not ready yet for 3.13&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/en/download/"&gt;NodeJS &amp;amp; NPM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, for Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VS Code with C++ dev tools and Windows SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. Install Skyvern&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install skyvern
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Run Skyvern&lt;/h3&gt; 
&lt;p&gt;This is most helpful for first time run (db setup, db migrations etc).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run task&lt;/h3&gt; 
&lt;h4&gt;UI (Recommended)&lt;/h4&gt; 
&lt;p&gt;Start the Skyvern service and UI (when DB is up and running)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern run all
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Go to &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt; and use the UI to run a task&lt;/p&gt; 
&lt;h4&gt;Code&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Skyvern starts running the task in a browser that pops up and closes it when the task is done. You will be able to view the task from &lt;a href="http://localhost:8080/history"&gt;http://localhost:8080/history&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also run a task on different targets:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# Run on Skyvern Cloud
skyvern = Skyvern(api_key="SKYVERN API KEY")

# Local Skyvern service
skyvern = Skyvern(base_url="http://localhost:8000", api_key="LOCAL SKYVERN API KEY")

task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Control your own browser (Chrome)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è WARNING: Since &lt;a href="https://developer.chrome.com/blog/remote-debugging-port"&gt;Chrome 136&lt;/a&gt;, Chrome refuses any CDP connect to the browser using the default user_data_dir. In order to use your browser data, Skyvern copies your default user_data_dir to &lt;code&gt;./tmp/user_data_dir&lt;/code&gt; the first time connecting to your local browser. ‚ö†Ô∏è&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Just With Python Code&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# The path to your Chrome browser. This example path is for Mac.
browser_path = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
skyvern = Skyvern(
    base_url="http://localhost:8000",
    api_key="YOUR_API_KEY",
    browser_path=browser_path,
)
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;With Skyvern Service&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Add two variables to your .env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# The path to your Chrome browser. This example path is for Mac.
CHROME_EXECUTABLE_PATH="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
BROWSER_TYPE=cdp-connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Skyvern service &lt;code&gt;skyvern run all&lt;/code&gt; and run the task through UI or code&lt;/p&gt; 
&lt;h3&gt;Run Skyvern with any remote browser&lt;/h3&gt; 
&lt;p&gt;Grab the cdp connection url and pass it to Skyvern&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern(cdp_url="your cdp connection url")
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Get consistent output schema from your run&lt;/h3&gt; 
&lt;p&gt;You can do this by adding the &lt;code&gt;data_extraction_schema&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
    data_extraction_schema={
        "type": "object",
        "properties": {
            "title": {
                "type": "string",
                "description": "The title of the top post"
            },
            "url": {
                "type": "string",
                "description": "The URL of the top post"
            },
            "points": {
                "type": "integer",
                "description": "Number of points the post has received"
            }
        }
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Helpful commands to debug issues&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Skyvern Server Separately*
skyvern run server

# Launch the Skyvern UI
skyvern run ui

# Check status of the Skyvern service
skyvern status

# Stop the Skyvern service
skyvern stop all

# Stop the Skyvern UI
skyvern stop ui

# Stop the Skyvern Server Separately
skyvern stop server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker Compose setup&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make sure you have &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; installed and running on your machine&lt;/li&gt; 
 &lt;li&gt;Make sure you don't have postgres running locally (Run &lt;code&gt;docker ps&lt;/code&gt; to check)&lt;/li&gt; 
 &lt;li&gt;Clone the repository and navigate to the root directory&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;skyvern init llm&lt;/code&gt; to generate a &lt;code&gt;.env&lt;/code&gt; file. This will be copied into the Docker image.&lt;/li&gt; 
 &lt;li&gt;Fill in the LLM provider key on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;. &lt;em&gt;If you want to run Skyvern on a remote server, make sure you set the correct server ip for the UI container in &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Run the following command via the commandline: &lt;pre&gt;&lt;code class="language-bash"&gt; docker compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Only one Postgres container can run on port 5432 at a time. If you switch from the CLI-managed Postgres to Docker Compose, you must first remove the original container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker rm -f postgresql-container
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you encounter any database related errors while using Docker to run Skyvern, check which Postgres container is running with &lt;code&gt;docker ps&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Skyvern Features&lt;/h1&gt; 
&lt;h2&gt;Skyvern Tasks&lt;/h2&gt; 
&lt;p&gt;Tasks are the fundamental building block inside Skyvern. Each task is a single request to Skyvern, instructing it to navigate through a website and accomplish a specific goal.&lt;/p&gt; 
&lt;p&gt;Tasks require you to specify a &lt;code&gt;url&lt;/code&gt;, &lt;code&gt;prompt&lt;/code&gt;, and can optionally include a &lt;code&gt;data schema&lt;/code&gt; (if you want the output to conform to a specific schema) and &lt;code&gt;error codes&lt;/code&gt; (if you want Skyvern to stop running in specific situations).&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_screenshot.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Skyvern Workflows&lt;/h2&gt; 
&lt;p&gt;Workflows are a way to chain multiple tasks together to form a cohesive unit of work.&lt;/p&gt; 
&lt;p&gt;For example, if you wanted to download all invoices newer than January 1st, you could create a workflow that first navigated to the invoices page, then filtered down to only show invoices newer than January 1st, extracted a list of all eligible invoices, and iterated through each invoice to download it.&lt;/p&gt; 
&lt;p&gt;Another example is if you wanted to automate purchasing products from an e-commerce store, you could create a workflow that first navigated to the desired product, then added it to a cart. Second, it would navigate to the cart and validate the cart state. Finally, it would go through the checkout process to purchase the items.&lt;/p&gt; 
&lt;p&gt;Supported workflow features include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Browser Task&lt;/li&gt; 
 &lt;li&gt;Browser Action&lt;/li&gt; 
 &lt;li&gt;Data Extraction&lt;/li&gt; 
 &lt;li&gt;Validation&lt;/li&gt; 
 &lt;li&gt;For Loops&lt;/li&gt; 
 &lt;li&gt;File parsing&lt;/li&gt; 
 &lt;li&gt;Sending emails&lt;/li&gt; 
 &lt;li&gt;Text Prompts&lt;/li&gt; 
 &lt;li&gt;HTTP Request Block&lt;/li&gt; 
 &lt;li&gt;Custom Code Block&lt;/li&gt; 
 &lt;li&gt;Uploading files to block storage&lt;/li&gt; 
 &lt;li&gt;(Coming soon) Conditionals&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/block_example_v2.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Livestreaming&lt;/h2&gt; 
&lt;p&gt;Skyvern allows you to livestream the viewport of the browser to your local machine so that you can see exactly what Skyvern is doing on the web. This is useful for debugging and understanding how Skyvern is interacting with a website, and intervening when necessary&lt;/p&gt; 
&lt;h2&gt;Form Filling&lt;/h2&gt; 
&lt;p&gt;Skyvern is natively capable of filling out form inputs on websites. Passing in information via the &lt;code&gt;navigation_goal&lt;/code&gt; will allow Skyvern to comprehend the information and fill out the form accordingly.&lt;/p&gt; 
&lt;h2&gt;Data Extraction&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of extracting data from a website.&lt;/p&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;data_extraction_schema&lt;/code&gt; directly within the main prompt to tell Skyvern exactly what data you'd like to extract from the website, in jsonc format. Skyvern's output will be structured in accordance to the supplied schema.&lt;/p&gt; 
&lt;h2&gt;File Downloading&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of downloading files from a website. All downloaded files are automatically uploaded to block storage (if configured), and you can access them via the UI.&lt;/p&gt; 
&lt;h2&gt;Authentication&lt;/h2&gt; 
&lt;p&gt;Skyvern supports a number of different authentication methods to make it easier to automate tasks behind a login. If you'd like to try it out, please reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/secure_password_task_example.png" /&gt; &lt;/p&gt; 
&lt;h3&gt;üîê 2FA Support (TOTP)&lt;/h3&gt; 
&lt;p&gt;Skyvern supports a number of different 2FA methods to allow you to automate workflows that require 2FA.&lt;/p&gt; 
&lt;p&gt;Examples include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;QR-based 2FA (e.g. Google Authenticator, Authy)&lt;/li&gt; 
 &lt;li&gt;Email based 2FA&lt;/li&gt; 
 &lt;li&gt;SMS based 2FA&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;üîê Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Password Manager Integrations&lt;/h3&gt; 
&lt;p&gt;Skyvern currently supports the following password manager integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Bitwarden&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 1Password&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; LastPass&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;Skyvern supports the Model Context Protocol (MCP) to allow you to use any LLM that supports MCP.&lt;/p&gt; 
&lt;p&gt;See the MCP documentation &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/integrations/mcp/README.md"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Zapier / Make.com / N8N Integration&lt;/h2&gt; 
&lt;p&gt;Skyvern supports Zapier, Make.com, and N8N to allow you to connect your Skyvern workflows to other apps.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/zapier"&gt;Zapier&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/make.com"&gt;Make.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/n8n"&gt;N8N&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üîê Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Real-world examples of Skyvern&lt;/h1&gt; 
&lt;p&gt;We love to see how Skyvern is being used in the wild. Here are some examples of how Skyvern is being used to automate workflows in the real world. Please open PRs to add your own examples!&lt;/p&gt; 
&lt;h2&gt;Invoice Downloading on many different websites&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://meetings.hubspot.com/skyvern/demo"&gt;Book a demo to see it live&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/invoice_downloading.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate the job application process&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/job_application"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/job_application_demo.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate materials procurement for a manufacturing company&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/finditparts"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/finditparts_recording_crop.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Navigating to government websites to register accounts or fill out forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/california_edd"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/edd_services.gif" /&gt; &lt;/p&gt; 
&lt;!-- Add example of delaware entity lookups x2 --&gt; 
&lt;h2&gt;Filling out random contact us forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/contact_us_forms"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/contact_forms.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Retrieving insurance quotes from insurance providers in any language&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/bci_seguros"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/bci_seguros_recording.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/geico"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;h1&gt;Contributor Setup&lt;/h1&gt; 
&lt;p&gt;Make sure to have &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; installed.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run this to create your virtual environment (&lt;code&gt;.venv&lt;/code&gt;) &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync --group dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Perform initial server configuration &lt;pre&gt;&lt;code class="language-bash"&gt;uv run skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI &lt;em&gt;The Skyvern CLI supports Windows, WSL, macOS, and Linux environments.&lt;/em&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;More extensive documentation can be found on our &lt;a href="https://www.skyvern.com/docs"&gt;üìï docs page&lt;/a&gt;. Please let us know if something is unclear or missing by opening an issue or reaching out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Supported LLMs&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Supported Models&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;gpt4-turbo, gpt-4o, gpt-4o-mini&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;Any GPT models. Better performance with a multimodal llm (azure/gpt4-o)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS Bedrock&lt;/td&gt; 
   &lt;td&gt;Anthropic Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemini&lt;/td&gt; 
   &lt;td&gt;Gemini 2.5 Pro and flash, Gemini 2.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;Run any locally hosted model via &lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;Access models through &lt;a href="https://openrouter.ai"&gt;OpenRouter&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI-compatible&lt;/td&gt; 
   &lt;td&gt;Any custom API endpoint that follows OpenAI's API format (via &lt;a href="https://docs.litellm.ai/docs/providers/openai_compatible"&gt;liteLLM&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Environment Variables&lt;/h4&gt; 
&lt;h5&gt;OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Base, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://openai.api.base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_ORGANIZATION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Organization ID, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your-org-id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENAI_GPT4O&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4O_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4_1&lt;/code&gt;, &lt;code&gt;OPENAI_O4_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_O3&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Anthropic&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_ANTHROPIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Anthropic models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended&lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;ANTHROPIC_CLAUDE3.5_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE3.7_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_OPUS&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_SONNET&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Azure OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_AZURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Azure OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_DEPLOYMENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI Deployment Name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;skyvern-deployment&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment api base url&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://skyvern-deployment.openai.azure.com/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure API Version&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2024-02-01&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;AZURE_OPENAI&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;AWS Bedrock&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_BEDROCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register AWS Bedrock models. To use AWS Bedrock, you need to make sure your &lt;a href="https://github.com/boto/boto3?tab=readme-ov-file#using-boto3"&gt;AWS configurations&lt;/a&gt; are set up correctly first.&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE3.7_SONNET_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_OPUS_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_SONNET_INFERENCE_PROFILE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Gemini&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_GEMINI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Gemini models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Gemini API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your_google_gemini_api_key&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;GEMINI_2.5_PRO_PREVIEW&lt;/code&gt;, &lt;code&gt;GEMINI_2.5_FLASH_PREVIEW&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Ollama&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OLLAMA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register local models via Ollama&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL for your Ollama server&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Ollama model name to load&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;qwen2.5:7b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OLLAMA&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: Ollama does not support vision yet.&lt;/p&gt; 
&lt;h5&gt;OpenRouter&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENROUTER&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenRouter models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter model name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mistralai/mistral-small-3.1-24b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API base URL&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.openrouter.ai/v1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENROUTER&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;OpenAI-Compatible&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI_COMPATIBLE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register a custom OpenAI-compatible API endpoint&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MODEL_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Model name for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;yi-34b&lt;/code&gt;, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;, &lt;code&gt;mistral-large&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API key for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Base URL for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.together.xyz/v1&lt;/code&gt;, &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API version for OpenAI-compatible endpoint, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2023-05-15&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum tokens for completion, optional&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;4096&lt;/code&gt;, &lt;code&gt;8192&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_TEMPERATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Temperature setting, optional&lt;/td&gt; 
   &lt;td&gt;Float&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0.0&lt;/code&gt;, &lt;code&gt;0.5&lt;/code&gt;, &lt;code&gt;0.7&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_SUPPORTS_VISION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether model supports vision, optional&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Supported LLM Key: &lt;code&gt;OPENAI_COMPATIBLE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;General LLM Configuration&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model you want to use&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SECONDARY_LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model for mini agents skyvern runs with&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_CONFIG_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Override the max tokens used by the LLM&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;128000&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Feature Roadmap&lt;/h1&gt; 
&lt;p&gt;This is our planned roadmap for the next few months. If you have any suggestions or would like to see a feature added, please don't hesitate to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Open Source&lt;/strong&gt; - Open Source Skyvern's core codebase&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow support&lt;/strong&gt; - Allow support to chain multiple Skyvern calls together&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Improved context&lt;/strong&gt; - Improve Skyvern's ability to understand content around interactable elements by introducing feeding relevant label context through the text prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Cost Savings&lt;/strong&gt; - Improve Skyvern's stability and reduce the cost of running Skyvern by optimizing the context tree passed into Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Self-serve UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI component that allows users to kick off new jobs in Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow UI Builder&lt;/strong&gt; - Introduce a UI to allow users to build and analyze workflows visually&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Chrome Viewport streaming&lt;/strong&gt; - Introduce a way to live-stream the Chrome viewport to the user's browser (as a part of the self-serve UI)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Past Runs UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI that allows you to visualize past runs and their results&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Auto workflow builder ("Observer") mode&lt;/strong&gt; - Allow Skyvern to auto-generate workflows as it's navigating the web to make it easier to build new workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Prompt Caching&lt;/strong&gt; - Introduce a caching layer to the LLM calls to dramatically reduce the cost of running Skyvern (memorize past actions and repeat them!)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Web Evaluation Dataset&lt;/strong&gt; - Integrate Skyvern with public benchmark tests to track the quality of our models over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Improved Debug mode&lt;/strong&gt; - Allow Skyvern to plan its actions and get "approval" before running them, allowing you to debug what it's doing and more easily iterate on the prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Chrome Extension&lt;/strong&gt; - Allow users to interact with Skyvern through a Chrome extension (incl voice mode, saving tasks, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Skyvern Action Recorder&lt;/strong&gt; - Allow Skyvern to watch a user complete a task and then automatically generate a workflow for it&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Interactable Livestream&lt;/strong&gt; - Allow users to interact with the livestream in real-time to intervene when necessary (such as manually submitting sensitive forms)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Integrate LLM Observability tools&lt;/strong&gt; - Integrate LLM Observability tools to allow back-testing prompt changes with specific data sets + visualize the performance of Skyvern over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Langchain Integration&lt;/strong&gt; - Create langchain integration in langchain_community to use Skyvern as a "tool".&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome PRs and suggestions! Don't hesitate to open a PR/issue or to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;. Please have a look at our &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and &lt;a href="https://github.com/skyvern-ai/skyvern/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;"Help Wanted" issues&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;p&gt;If you want to chat with the skyvern repository to get a high level overview of how it is structured, how to build off it, and how to resolve usage questions, check out &lt;a href="https://sage.storia.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=skyvern-readme"&gt;Code Sage&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Telemetry&lt;/h1&gt; 
&lt;p&gt;By Default, Skyvern collects basic usage statistics to help us understand how Skyvern is being used. If you would like to opt-out of telemetry, please set the &lt;code&gt;SKYVERN_TELEMETRY&lt;/code&gt; environment variable to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Skyvern's open source repository is supported via a managed cloud. All of the core logic powering Skyvern is available in this open source repository licensed under the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/LICENSE"&gt;AGPL-3.0 License&lt;/a&gt;, with the exception of anti-bot measures available in our managed cloud offering.&lt;/p&gt; 
&lt;p&gt;If you have any questions or concerns around licensing, please &lt;a href="mailto:support@skyvern.com"&gt;contact us&lt;/a&gt; and we would be happy to help.&lt;/p&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Skyvern-AI/skyvern&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Skyvern-AI/skyvern&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>charmbracelet/glow</title>
      <link>https://github.com/charmbracelet/glow</link>
      <description>&lt;p&gt;Render markdown on the CLI, with pizzazz! üíÖüèª&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Glow&lt;/h1&gt; 
&lt;p&gt;Render markdown on the CLI, with &lt;em&gt;pizzazz&lt;/em&gt;!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://stuff.charm.sh/glow/glow-banner-github.gif" alt="Glow Logo" /&gt; &lt;a href="https://github.com/charmbracelet/glow/releases"&gt;&lt;img src="https://img.shields.io/github/release/charmbracelet/glow.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/charmbracelet/glow?tab=doc"&gt;&lt;img src="https://godoc.org/github.com/golang/gddo?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/charmbracelet/glow/actions"&gt;&lt;img src="https://github.com/charmbracelet/glow/workflows/build/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/charmbracelet/glow"&gt;&lt;img src="https://goreportcard.com/badge/charmbracelet/glow" alt="Go ReportCard" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/c2246366-f84b-4847-b431-32a61ca07b74" width="800" alt="Glow UI Demo" /&gt; &lt;/p&gt; 
&lt;h2&gt;What is it?&lt;/h2&gt; 
&lt;p&gt;Glow is a terminal based markdown reader designed from the ground up to bring out the beauty‚Äîand power‚Äîof the CLI.&lt;/p&gt; 
&lt;p&gt;Use it to discover markdown files, read documentation directly on the command line. Glow will find local markdown files in subdirectories or a local Git repository.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Package Manager&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS or Linux
brew install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (with MacPorts)
sudo port install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Arch Linux (btw)
pacman -S glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Void Linux
xbps-install -S glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Nix shell
nix-shell -p glow --command glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# FreeBSD
pkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Solus
eopkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Windows (with Chocolatey, Scoop, or Winget)
choco install glow
scoop install glow
winget install charmbracelet.glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Android (with termux)
pkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu (Snapcraft)
sudo snap install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Debian/Ubuntu
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo "deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *" | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;amp;&amp;amp; sudo apt install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fedora/RHEL
echo '[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key' | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or download a binary from the &lt;a href="https://github.com/charmbracelet/glow/releases"&gt;releases&lt;/a&gt; page. MacOS, Linux, Windows, FreeBSD and OpenBSD binaries are available, as well as Debian, RPM, and Alpine packages. ARM builds are also available for macOS, Linux, FreeBSD and OpenBSD.&lt;/p&gt; 
&lt;h3&gt;Go&lt;/h3&gt; 
&lt;p&gt;Or just install it with &lt;code&gt;go&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/charmbracelet/glow/v2@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build (requires Go 1.21+)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/charmbracelet/glow.git
cd glow
go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;The TUI&lt;/h2&gt; 
&lt;p&gt;Simply run &lt;code&gt;glow&lt;/code&gt; without arguments to start the textual user interface and browse local. Glow will find local markdown files in the current directory and below or, if you‚Äôre in a Git repository, Glow will search the repo.&lt;/p&gt; 
&lt;p&gt;Markdown files can be read with Glow's high-performance pager. Most of the keystrokes you know from &lt;code&gt;less&lt;/code&gt; are the same, but you can press &lt;code&gt;?&lt;/code&gt; to list the hotkeys.&lt;/p&gt; 
&lt;h2&gt;The CLI&lt;/h2&gt; 
&lt;p&gt;In addition to a TUI, Glow has a CLI for working with Markdown. To format a document use a markdown source as the primary argument:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Read from file
glow README.md

# Read from stdin
echo "[Glow](https://github.com/charmbracelet/glow)" | glow -

# Fetch README from GitHub / GitLab
glow github.com/charmbracelet/glow

# Fetch markdown from HTTP
glow https://host.tld/file.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Word Wrapping&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;-w&lt;/code&gt; flag lets you set a maximum width at which the output will be wrapped:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -w 60
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Paging&lt;/h3&gt; 
&lt;p&gt;CLI output can be displayed in your preferred pager with the &lt;code&gt;-p&lt;/code&gt; flag. This defaults to the ANSI-aware &lt;code&gt;less -r&lt;/code&gt; if &lt;code&gt;$PAGER&lt;/code&gt; is not explicitly set.&lt;/p&gt; 
&lt;h3&gt;Styles&lt;/h3&gt; 
&lt;p&gt;You can choose a style with the &lt;code&gt;-s&lt;/code&gt; flag. When no flag is provided &lt;code&gt;glow&lt;/code&gt; tries to detect your terminal's current background color and automatically picks either the &lt;code&gt;dark&lt;/code&gt; or the &lt;code&gt;light&lt;/code&gt; style for you.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -s [dark|light]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively you can also supply a custom JSON stylesheet:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -s mystyle.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For additional usage details see:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/charmbracelet/glamour/raw/master/styles/gallery/README.md"&gt;Glamour Style Section&lt;/a&gt; to find more styles. Or &lt;a href="https://github.com/charmbracelet/glamour/tree/master/styles"&gt;make your own&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;The Config File&lt;/h2&gt; 
&lt;p&gt;If you find yourself supplying the same flags to &lt;code&gt;glow&lt;/code&gt; all the time, it's probably a good idea to create a config file. Run &lt;code&gt;glow config&lt;/code&gt;, which will open it in your favorite $EDITOR. Alternatively you can manually put a file named &lt;code&gt;glow.yml&lt;/code&gt; in the default config path of you platform. If you're not sure where that is, please refer to &lt;code&gt;glow --help&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here's an example config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# style name or JSON path (default "auto")
style: "light"
# mouse wheel support (TUI-mode only)
mouse: true
# use pager to display markdown
pager: true
# at which column should we word wrap?
width: 80
# show all files, including hidden and ignored.
all: false
# show line numbers (TUI-mode only)
showLineNumbers: false
# preserve newlines in the output
preserveNewLines: false
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/charmbracelet/glow/contribute"&gt;contributing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;We‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/charmcli"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@charmcli"&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.sh/chat"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/glow/raw/master/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Part of &lt;a href="https://charm.sh"&gt;Charm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://charm.sh/"&gt;&lt;img alt="The Charm logo" src="https://stuff.charm.sh/charm-badge.jpg" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mindsdb/mindsdb</title>
      <link>https://github.com/mindsdb/mindsdb</link>
      <description>&lt;p&gt;Federated query engine for AI - The only MCP Server you'll ever need&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://pypi.org/project/MindsDB/" target="_blank"&gt;&lt;img src="https://badge.fury.io/py/MindsDB.svg?sanitize=true" alt="MindsDB Release" /&gt;&lt;/a&gt; 
 &lt;a href="https://www.python.org/downloads/" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/python-3.10.x%7C%203.11.x%7C%203.12.x%7C%203.13.x-brightgreen.svg?sanitize=true" alt="Python supported" /&gt;&lt;/a&gt; 
 &lt;a href="https://hub.docker.com/u/mindsdb" target="_blank"&gt;&lt;img src="https://img.shields.io/docker/pulls/mindsdb/mindsdb" alt="Docker pulls" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/3068" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3068" alt="mindsdb%2Fmindsdb | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;a href="https://github.com/mindsdb/mindsdb"&gt; &lt;img src="https://raw.githubusercontent.com/mindsdb/mindsdb/main/docs/assets/mindsdb_logo.png" alt="MindsDB" width="300" /&gt; &lt;/a&gt; 
 &lt;p align="center"&gt; &lt;br /&gt; &lt;a href="https://www.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Website&lt;/a&gt; ¬∑ &lt;a href="https://docs.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://mindsdb.com/contact"&gt;Contact us for a Demo&lt;/a&gt; ¬∑ &lt;a href="https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Community Slack&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;MindsDB enables humans, AI, agents, and applications to get highly accurate answers across large scale data sources.&lt;/p&gt; 
&lt;a href="https://www.youtube.com/watch?v=MX3OKpnsoLM" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/119e7b82-f901-4214-a26f-ff7c5ad86064" alt="MindsDB Demo" /&gt; &lt;/a&gt; 
&lt;h2&gt;Install MindsDB Server&lt;/h2&gt; 
&lt;p&gt;MindsDB is an open-source server that can be deployed anywhere - from your laptop to the cloud, and everywhere in between. And yes, you can customize it to your heart's content.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/setup/self-hosted/docker-desktop"&gt;Using Docker Desktop&lt;/a&gt;. This is the fastest and recommended way to get started and have it all running.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/setup/self-hosted/docker"&gt;Using Docker&lt;/a&gt;. This is also simple, but gives you more flexibility on how to further customize your server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://docs.mindsdb.com/mcp/overview"&gt;MindsDB has an MCP server built in&lt;/a&gt; that enables your MCP applications to connect, unify and respond to questions over large-scale federated data‚Äîspanning databases, data warehouses, and SaaS applications.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Core Philosophy: Connect, Unify, Respond&lt;/h1&gt; 
&lt;p&gt;MindsDB's architecture is built around three fundamental capabilities:&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/integrations/data-overview"&gt;Connect&lt;/a&gt; Your Data&lt;/h2&gt; 
&lt;p&gt;You can connect to hundreds of enterprise &lt;a href="https://docs.mindsdb.com/integrations/data-overview"&gt;data sources (learn more)&lt;/a&gt;. These integrations allow MindsDB to access data wherever it resides, forming the foundation for all other capabilities.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/overview"&gt;Unify&lt;/a&gt; Your Data&lt;/h2&gt; 
&lt;p&gt;In many situations, it‚Äôs important to be able to prepare and unify data before generating responses from it. MindsDB SQL offers knowledge bases and views that allow indexing and organizing structured and unstructured data as if it were unified in a single system.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/knowledge-bases"&gt;&lt;strong&gt;KNOWLEDGE BASES&lt;/strong&gt;&lt;/a&gt; ‚Äì Index and organize unstructured data for efficient Q&amp;amp;A.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/sql/create/view"&gt;&lt;strong&gt;VIEWS&lt;/strong&gt;&lt;/a&gt; ‚Äì Simplify data access by creating unified views across different sources (no-ETL).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Unification of data can be automated using JOBs&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/sql/create/jobs"&gt;&lt;strong&gt;JOBS&lt;/strong&gt;&lt;/a&gt; ‚Äì Schedule synchronization and transformation tasks for real-time processing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/agents/agent"&gt;Respond&lt;/a&gt; From Your Data&lt;/h2&gt; 
&lt;p&gt;Chat with Your Data&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/agents/agent"&gt;&lt;strong&gt;AGENTS&lt;/strong&gt;&lt;/a&gt; ‚Äì Configure built-in agents specialized in answering questions over your connected and unified data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mcp/overview"&gt;&lt;strong&gt;MCP&lt;/strong&gt;&lt;/a&gt; ‚Äì Connect to MindsDB through the MCP (Model Context Protocol) for seamless interaction.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contribute&lt;/h2&gt; 
&lt;p&gt;Interested in contributing to MindsDB? Follow our &lt;a href="https://docs.mindsdb.com/contribute/install?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;installation guide for development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find our &lt;a href="https://docs.mindsdb.com/contribute/contribute?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;contribution guide here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We welcome suggestions! Feel free to open new issues with your ideas, and we‚Äôll guide you.&lt;/p&gt; 
&lt;p&gt;This project adheres to a &lt;a href="https://github.com/mindsdb/mindsdb/raw/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating, you agree to follow its terms.&lt;/p&gt; 
&lt;p&gt;Also, check out our &lt;a href="https://mindsdb.com/community?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;community rewards and programs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ç Support&lt;/h2&gt; 
&lt;p&gt;If you find a bug, please submit an &lt;a href="https://github.com/mindsdb/mindsdb/issues/new/choose"&gt;issue on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Here‚Äôs how you can get community support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ask a question in our &lt;a href="https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Slack Community&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://github.com/mindsdb/mindsdb/discussions"&gt;GitHub Discussions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Post on &lt;a href="https://stackoverflow.com/questions/tagged/mindsdb"&gt;Stack Overflow&lt;/a&gt; with the MindsDB tag.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For commercial support, please &lt;a href="https://mindsdb.com/contact?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;contact the MindsDB team&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üíö Current Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/mindsdb/mindsdb/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=mindsdb/mindsdb" /&gt; &lt;/a&gt; 
&lt;p&gt;Generated with &lt;a href="https://contributors-img.web.app"&gt;contributors-img&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üîî Subscribe for Updates&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://mindsdb.com/joincommunity"&gt;Slack community&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lima-vm/lima</title>
      <link>https://github.com/lima-vm/lima</link>
      <description>&lt;p&gt;Linux virtual machines, with a focus on running containers&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://lima-vm.io/"&gt;[üåé&lt;strong&gt;Web site&lt;/strong&gt;]&lt;/a&gt; &lt;a href="https://lima-vm.io/docs/"&gt;[üìñ&lt;strong&gt;Documentation&lt;/strong&gt;]&lt;/a&gt; &lt;a href="https://slack.cncf.io"&gt;[üë§&lt;strong&gt;Slack (&lt;code&gt;#lima&lt;/code&gt;)&lt;/strong&gt;]&lt;/a&gt;&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="website/static/images/logo-dark.svg" /&gt; 
 &lt;img alt="Shows a stylized 'Lima' text in bold, modern font" src="https://raw.githubusercontent.com/lima-vm/lima/master/website/static/images/logo.svg?sanitize=true" width="400" /&gt; 
&lt;/picture&gt; 
&lt;h1&gt;Lima: Linux Machines&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://deepwiki.com/lima-vm/lima"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/6505"&gt;&lt;img src="https://www.bestpractices.dev/projects/6505/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/lima-vm/lima"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/lima-vm/lima/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lima-vm.io/"&gt;Lima&lt;/a&gt; launches Linux virtual machines with automatic file sharing and port forwarding (similar to WSL2).&lt;/p&gt; 
&lt;p&gt;The original goal of Lima was to promote &lt;a href="https://containerd.io"&gt;containerd&lt;/a&gt; including &lt;a href="https://github.com/containerd/nerdctl"&gt;nerdctl (contaiNERD ctl)&lt;/a&gt; to Mac users, but Lima can be used for non-container applications as well.&lt;/p&gt; 
&lt;p&gt;Lima also supports other container engines (Docker, Podman, Kubernetes, etc.) and non-macOS hosts (Linux, NetBSD, etc.).&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Set up (Homebrew):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install lima
limactl start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run Linux commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;lima uname -a
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run containers with containerd:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;lima nerdctl run --rm hello-world
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run containers with Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;limactl start template://docker
export DOCKER_HOST=$(limactl list docker --format 'unix://{{.Dir}}/sock/docker.sock')
docker run --rm hello-world
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run containers with Kubernetes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;limactl start template://k8s
export KUBECONFIG=$(limactl list k8s --format 'unix://{{.Dir}}/copied-from-guest/kubeconfig.yaml')
kubectl apply -f ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://lima-vm.io/docs/"&gt;https://lima-vm.io/docs/&lt;/a&gt; for the further information.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://lima-vm.io/docs/community/contributing/"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Developer Certificate of Origin (DCO)&lt;/strong&gt;: All commits must be signed off with &lt;code&gt;git commit -s&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Code licensing and pull request guidelines&lt;/li&gt; 
 &lt;li&gt;Testing requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;h3&gt;Adopters&lt;/h3&gt; 
&lt;p&gt;Container environments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rancherdesktop.io/"&gt;Rancher Desktop&lt;/a&gt;: Kubernetes and container management to the desktop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abiosoft/colima"&gt;Colima&lt;/a&gt;: Docker (and Kubernetes) on macOS with minimal setup&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/runfinch/finch"&gt;Finch&lt;/a&gt;: Finch is a command line client for local container development&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://podman-desktop.io/"&gt;Podman Desktop&lt;/a&gt;: Podman Desktop GUI has a plug-in for Lima virtual machines&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;GUI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unixorn/lima-xbar-plugin"&gt;Lima xbar plugin&lt;/a&gt;: &lt;a href="https://xbarapp.com/"&gt;xbar&lt;/a&gt; plugin to start/stop VMs from the menu bar and see their running status.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/afbjorklund/lima-gui"&gt;lima-gui&lt;/a&gt;: Qt GUI for Lima&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Communication channels&lt;/h3&gt; 
&lt;!-- Duplicated from https://lima-vm.io/docs/community/ --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lima-vm/lima/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;#lima&lt;/code&gt; channel in the CNCF Slack 
  &lt;ul&gt; 
   &lt;li&gt;New account: &lt;a href="https://slack.cncf.io/"&gt;https://slack.cncf.io/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Login: &lt;a href="https://cloud-native.slack.com/"&gt;https://cloud-native.slack.com/&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Zoom meetings (tentatively monthly) 
  &lt;ul&gt; 
   &lt;li&gt;Meeting notes &amp;amp; agenda proposals: &lt;a href="https://github.com/lima-vm/lima/discussions/categories/meetings"&gt;https://github.com/lima-vm/lima/discussions/categories/meetings&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Calendar: &lt;a href="https://zoom-lfx.platform.linuxfoundation.org/meetings/lima"&gt;https://zoom-lfx.platform.linuxfoundation.org/meetings/lima&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;Lima follows the &lt;a href="https://github.com/cncf/foundation/raw/main/code-of-conduct.md"&gt;CNCF Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;We are a &lt;a href="https://cncf.io/"&gt;Cloud Native Computing Foundation&lt;/a&gt; incubating project.&lt;/strong&gt;&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://www.cncf.io/wp-content/uploads/2022/07/cncf-white-logo.svg" /&gt; 
 &lt;img src="https://www.cncf.io/wp-content/uploads/2022/07/cncf-color-bg.svg?sanitize=true" width="300" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;The Linux Foundation¬Æ (TLF) has registered trademarks and uses trademarks. For a list of TLF trademarks, see &lt;a href="https://www.linuxfoundation.org/legal/trademark-usage"&gt;Trademark Usage&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>