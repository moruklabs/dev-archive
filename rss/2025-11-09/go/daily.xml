<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Sat, 08 Nov 2025 01:33:57 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>prometheus/alertmanager</title>
      <link>https://github.com/prometheus/alertmanager</link>
      <description>&lt;p&gt;Prometheus Alertmanager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Alertmanager &lt;a href="https://circleci.com/gh/prometheus/alertmanager"&gt;&lt;img src="https://circleci.com/gh/prometheus/alertmanager/tree/main.svg?style=shield" alt="CircleCI" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;&lt;img src="https://quay.io/repository/prometheus/alertmanager/status" alt="Docker Repository on Quay" title="Docker Repository on Quay" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;&lt;img src="https://img.shields.io/docker/pulls/prom/alertmanager.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct &lt;a href="https://prometheus.io/docs/alerting/latest/configuration/#receiver"&gt;receiver integrations&lt;/a&gt; such as email, PagerDuty, OpsGenie, or many other &lt;a href="https://prometheus.io/docs/operating/integrations/#alertmanager-webhook-receiver"&gt;mechanisms&lt;/a&gt; thanks to the webhook receiver. It also takes care of silencing and inhibition of alerts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://prometheus.io/docs/alerting/alertmanager/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;There are various ways of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Precompiled binaries&lt;/h3&gt; 
&lt;p&gt;Precompiled binaries for released versions are available in the &lt;a href="https://prometheus.io/download/"&gt;&lt;em&gt;download&lt;/em&gt; section&lt;/a&gt; on &lt;a href="https://prometheus.io"&gt;prometheus.io&lt;/a&gt;. Using the latest production release binary is the recommended way of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Docker images&lt;/h3&gt; 
&lt;p&gt;Docker images are available on &lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;Quay.io&lt;/a&gt; or &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can launch an Alertmanager container for trying it out with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ docker run --name alertmanager -d -p 127.0.0.1:9093:9093 quay.io/prometheus/alertmanager
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alertmanager will now be reachable at &lt;a href="http://localhost:9093/"&gt;http://localhost:9093/&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling the binary&lt;/h3&gt; 
&lt;p&gt;You can either &lt;code&gt;go install&lt;/code&gt; it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/...@latest
# cd $GOPATH/src/github.com/prometheus/alertmanager
$ alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or clone the repository and build manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ mkdir -p $GOPATH/src/github.com/prometheus
$ cd $GOPATH/src/github.com/prometheus
$ git clone https://github.com/prometheus/alertmanager.git
$ cd alertmanager
$ make build
$ ./alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also build just one of the binaries in this repo by passing a name to the build function:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make build BINARIES=amtool
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;This is an example configuration that should cover most relevant aspects of the new YAML configuration format. The full documentation of the configuration can be found &lt;a href="https://prometheus.io/docs/alerting/configuration/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;global:
  # The smarthost and SMTP sender used for mail notifications.
  smtp_smarthost: 'localhost:25'
  smtp_from: 'alertmanager@example.org'

# The root route on which each incoming alert enters.
route:
  # The root route must not have any matchers as it is the entry point for
  # all alerts. It needs to have a receiver configured so alerts that do not
  # match any of the sub-routes are sent to someone.
  receiver: 'team-X-mails'

  # The labels by which incoming alerts are grouped together. For example,
  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
  # be batched into a single group.
  #
  # To aggregate by all possible labels use '...' as the sole label name.
  # This effectively disables aggregation entirely, passing through all
  # alerts as-is. This is unlikely to be what you want, unless you have
  # a very low alert volume or your upstream notification system performs
  # its own grouping. Example: group_by: [...]
  group_by: ['alertname', 'cluster']

  # When a new group of alerts is created by an incoming alert, wait at
  # least 'group_wait' to send the initial notification.
  # This way ensures that you get multiple alerts for the same group that start
  # firing shortly after another are batched together on the first
  # notification.
  group_wait: 30s

  # When the first notification was sent, wait 'group_interval' to send a batch
  # of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait 'repeat_interval' to
  # resend them.
  repeat_interval: 3h

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  # The child route trees.
  routes:
  # This route performs a regular expression match on alert labels to
  # catch alerts that are related to a list of services.
  - matchers:
    - service=~"^(foo1|foo2|baz)$"
    receiver: team-X-mails

    # The service has a sub-route for critical alerts, any alerts
    # that do not match, i.e. severity != critical, fall-back to the
    # parent node and are sent to 'team-X-mails'
    routes:
    - matchers:
      - severity="critical"
      receiver: team-X-pager

  - matchers:
    - service="files"
    receiver: team-Y-mails

    routes:
    - matchers:
      - severity="critical"
      receiver: team-Y-pager

  # This route handles all alerts coming from a database service. If there's
  # no team to handle it, it defaults to the DB team.
  - matchers:
    - service="database"

    receiver: team-DB-pager
    # Also group alerts by affected database.
    group_by: [alertname, cluster, database]

    routes:
    - matchers:
      - owner="team-X"
      receiver: team-X-pager

    - matchers:
      - owner="team-Y"
      receiver: team-Y-pager


# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
inhibit_rules:
- source_matchers:
    - severity="critical"
  target_matchers:
    - severity="warning"
  # Apply inhibition if the alertname is the same.
  # CAUTION: 
  #   If all label names listed in `equal` are missing 
  #   from both the source and target alerts,
  #   the inhibition rule will apply!
  equal: ['alertname']


receivers:
- name: 'team-X-mails'
  email_configs:
  - to: 'team-X+alerts@example.org, team-Y+alerts@example.org'

- name: 'team-X-pager'
  email_configs:
  - to: 'team-X+alerts-critical@example.org'
  pagerduty_configs:
  - routing_key: &amp;lt;team-X-key&amp;gt;

- name: 'team-Y-mails'
  email_configs:
  - to: 'team-Y+alerts@example.org'

- name: 'team-Y-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-Y-key&amp;gt;

- name: 'team-DB-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-DB-key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;p&gt;The current Alertmanager API is version 2. This API is fully generated via the &lt;a href="https://github.com/OAI/OpenAPI-Specification/raw/master/versions/2.0.md"&gt;OpenAPI project&lt;/a&gt; and &lt;a href="https://github.com/go-swagger/go-swagger/"&gt;Go Swagger&lt;/a&gt; with the exception of the HTTP handlers themselves. The API specification can be found in &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;api/v2/openapi.yaml&lt;/a&gt;. A HTML rendered version can be accessed &lt;a href="http://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;here&lt;/a&gt;. Clients can be easily generated via any OpenAPI generator for all major languages.&lt;/p&gt; 
&lt;p&gt;APIv2 is accessed via the &lt;code&gt;/api/v2&lt;/code&gt; prefix. APIv1 was deprecated in &lt;code&gt;0.16.0&lt;/code&gt; and is removed as of version &lt;code&gt;0.27.0&lt;/code&gt;. The v2 &lt;code&gt;/status&lt;/code&gt; endpoint would be &lt;code&gt;/api/v2/status&lt;/code&gt;. If &lt;code&gt;--web.route-prefix&lt;/code&gt; is set then API routes are prefixed with that as well, so &lt;code&gt;--web.route-prefix=/alertmanager/&lt;/code&gt; would relate to &lt;code&gt;/alertmanager/api/v2/status&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;amtool&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; is a cli tool for interacting with the Alertmanager API. It is bundled with all releases of Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;Alternatively you can install with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/amtool@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;p&gt;View all currently firing alerts:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool alert
Alertname        Starts At                Summary
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View all currently firing alerts with extended output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to viewing alerts, you can use the rich query syntax provided by Alertmanager:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert query alertname="Test_Alert"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query instance=~".+1"
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query alertname=~"Test.*" instance=~".+1"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Silence an alert:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence add alertname=Test_Alert
b3ede22e-ca14-4aa0-932c-ca2f3445f926

$ amtool silence add alertname="Test_Alert" instance=~".+0"
e48cb58a-0b17-49ba-b734-3585139b1d25
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query
ID                                    Matchers              Ends At                  Created By  Comment
b3ede22e-ca14-4aa0-932c-ca2f3445f926  alertname=Test_Alert  2017-08-02 19:54:50 UTC  kellel

$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire a silence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire b3ede22e-ca14-4aa0-932c-ca2f3445f926
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences matching a query:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel

$ amtool silence expire $(amtool silence query -q instance=~".+0")

$ amtool silence query instance=~".+0"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire $(amtool silence query -q)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try out how a template works. Let's say you have this in your configuration file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;templates:
  - '/foo/bar/*.tmpl'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can test out how a template would look like with example by using this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;amtool template render --template.glob='/foo/bar/*.tmpl' --template.text='{{ template "slack.default.markdown.v1" . }}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows a configuration file to specify some options for convenience. The default configuration file paths are &lt;code&gt;$HOME/.config/amtool/config.yml&lt;/code&gt; or &lt;code&gt;/etc/amtool/config.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;An example configuration file might look like the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Define the path that `amtool` can find your `alertmanager` instance
alertmanager.url: "http://localhost:9093"

# Override the default author. (unset defaults to your username)
author: me@example.com

# Force amtool to give you an error if you don't include a comment on a silence
comment_required: true

# Set a default output format. (unset defaults to simple)
output: extended

# Set a default receiver
receiver: team-X-pager
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Routes&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows you to visualize the routes of your configuration in form of text tree view. Also you can use it to test the routing by passing it label set of an alert and it prints out all receivers the alert would match ordered and separated by &lt;code&gt;,&lt;/code&gt;. (If you use &lt;code&gt;--verify.receivers&lt;/code&gt; amtool returns error code 1 on mismatch)&lt;/p&gt; 
&lt;p&gt;Example of usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# View routing tree of remote Alertmanager
$ amtool config routes --alertmanager.url=http://localhost:9090

# Test if alert matches expected receiver
$ amtool config routes test --config.file=doc/examples/simple.yml --tree --verify.receivers=team-X-pager service=database owner=team-X
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;High Availability&lt;/h2&gt; 
&lt;p&gt;Alertmanager's high availability is in production use at many companies and is enabled by default.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Both UDP and TCP are needed in alertmanager 0.15 and higher for the cluster to work.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you are using a firewall, make sure to whitelist the clustering port for both protocols.&lt;/li&gt; 
  &lt;li&gt;If you are running in a container, make sure to expose the clustering port for both protocols.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To create a highly available cluster of the Alertmanager the instances need to be configured to communicate with each other. This is configured using the &lt;code&gt;--cluster.*&lt;/code&gt; flags.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.listen-address&lt;/code&gt; string: cluster listen address (default "0.0.0.0:9094"; empty string disables HA mode)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.advertise-address&lt;/code&gt; string: cluster advertise address&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer&lt;/code&gt; value: initial peers (repeat flag for each additional peer)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer-timeout&lt;/code&gt; value: peer timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peers-resolve-timeout&lt;/code&gt; value: peers resolve timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.gossip-interval&lt;/code&gt; value: cluster message propagation speed (default "200ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.pushpull-interval&lt;/code&gt; value: lower values will increase convergence speeds at expense of bandwidth (default "1m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.settle-timeout&lt;/code&gt; value: maximum time to wait for cluster connections to settle before evaluating notifications.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.tcp-timeout&lt;/code&gt; value: timeout value for tcp connections, reads and writes (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-timeout&lt;/code&gt; value: time to wait for ack before marking node unhealthy (default "500ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-interval&lt;/code&gt; value: interval between random node probes (default "1s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-interval&lt;/code&gt; value: interval between attempting to reconnect to lost peers (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-timeout&lt;/code&gt; value: length of time to attempt to reconnect to a lost peer (default: "6h0m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.label&lt;/code&gt; value: the label is an optional string to include on each packet and stream. It uniquely identifies the cluster and prevents cross-communication issues when sending gossip messages (default:"")&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The chosen port in the &lt;code&gt;cluster.listen-address&lt;/code&gt; flag is the port that needs to be specified in the &lt;code&gt;cluster.peer&lt;/code&gt; flag of the other peers.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;cluster.advertise-address&lt;/code&gt; flag is required if the instance doesn't have an IP address that is part of &lt;a href="https://tools.ietf.org/html/rfc6890"&gt;RFC 6890&lt;/a&gt; with a default route.&lt;/p&gt; 
&lt;p&gt;To start a cluster of three peers on your local machine use &lt;a href="https://github.com/mattn/goreman"&gt;&lt;code&gt;goreman&lt;/code&gt;&lt;/a&gt; and the Procfile within this repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;goreman start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To point your Prometheus 1.4, or later, instance to multiple Alertmanagers, configure them in your &lt;code&gt;prometheus.yml&lt;/code&gt; configuration file, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager1:9093
      - alertmanager2:9093
      - alertmanager3:9093
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Do not load balance traffic between Prometheus and its Alertmanagers, but instead point Prometheus to a list of all Alertmanagers. The Alertmanager implementation expects all alerts to be sent to all Alertmanagers to ensure high availability.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Turn off high availability&lt;/h3&gt; 
&lt;p&gt;If running Alertmanager in high availability mode is not desired, setting &lt;code&gt;--cluster.listen-address=&lt;/code&gt; prevents Alertmanager from listening to incoming peer requests.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Check the &lt;a href="https://github.com/prometheus/prometheus/raw/main/CONTRIBUTING.md"&gt;Prometheus contributing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To contribute to the user interface, refer to &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/ui/app/CONTRIBUTING.md"&gt;ui/app/CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/prometheus/alertmanager/main/doc/arch.svg?sanitize=true" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0, see &lt;a href="https://github.com/prometheus/alertmanager/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kubernetes-sigs/metrics-server</title>
      <link>https://github.com/kubernetes-sigs/metrics-server</link>
      <description>&lt;p&gt;Scalable and efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kubernetes Metrics Server&lt;/h1&gt; 
&lt;p&gt;Metrics Server is a scalable, efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.&lt;/p&gt; 
&lt;p&gt;Metrics Server collects resource metrics from Kubelets and exposes them in Kubernetes apiserver through &lt;a href="https://github.com/kubernetes/metrics"&gt;Metrics API&lt;/a&gt; for use by &lt;a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"&gt;Horizontal Pod Autoscaler&lt;/a&gt; and &lt;a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/"&gt;Vertical Pod Autoscaler&lt;/a&gt;. Metrics API can also be accessed by &lt;code&gt;kubectl top&lt;/code&gt;, making it easier to debug autoscaling pipelines.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] Metrics Server is meant only for autoscaling purposes. For example, don't use it to forward metrics to monitoring solutions, or as a source of monitoring solution metrics. In such cases please collect metrics from Kubelet &lt;code&gt;/metrics/resource&lt;/code&gt; endpoint directly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Metrics Server offers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A single deployment that works on most clusters (see &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/metrics-server/master/#requirements"&gt;Requirements&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Fast autoscaling, collecting metrics every 15 seconds.&lt;/li&gt; 
 &lt;li&gt;Resource efficiency, using 1 mili core of CPU and 2 MB of memory for each node in a cluster.&lt;/li&gt; 
 &lt;li&gt;Scalable support up to 5,000 node clusters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Use cases&lt;/h2&gt; 
&lt;p&gt;You can use Metrics Server for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU/Memory based horizontal autoscaling (learn more about &lt;a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"&gt;Horizontal Autoscaling&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Automatically adjusting/suggesting resources needed by containers (learn more about &lt;a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/"&gt;Vertical Autoscaling&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Don't use Metrics Server when you need:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Non-Kubernetes clusters&lt;/li&gt; 
 &lt;li&gt;An accurate source of resource usage metrics&lt;/li&gt; 
 &lt;li&gt;Horizontal autoscaling based on other resources than CPU/Memory&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For unsupported use cases, check out full monitoring solutions like &lt;a href="https://github.com/prometheus/prometheus"&gt;Prometheus&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;Metrics Server has specific requirements for cluster and network configuration. These requirements aren't the default for all cluster distributions. Please ensure that your cluster distribution supports these requirements before using Metrics Server:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The kube-apiserver must &lt;a href="https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/"&gt;enable an aggregation layer&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Nodes must have Webhook &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/kubelet-authn-authz/"&gt;authentication and authorization&lt;/a&gt; enabled.&lt;/li&gt; 
 &lt;li&gt;Kubelet certificate needs to be signed by cluster Certificate Authority (or disable certificate validation by passing &lt;code&gt;--kubelet-insecure-tls&lt;/code&gt; to Metrics Server)&lt;/li&gt; 
 &lt;li&gt;Container runtime must implement a &lt;a href="https://github.com/kubernetes/community/raw/master/contributors/devel/sig-node/cri-container-stats.md"&gt;container metrics RPCs&lt;/a&gt; (or have &lt;a href="https://github.com/google/cadvisor"&gt;cAdvisor&lt;/a&gt; support)&lt;/li&gt; 
 &lt;li&gt;Network should support following communication: 
  &lt;ul&gt; 
   &lt;li&gt;Control plane to Metrics Server. Control plane node needs to reach Metrics Server's pod IP and port 10250 (or node IP and custom port if &lt;code&gt;hostNetwork&lt;/code&gt; is enabled). Read more about &lt;a href="https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/#control-plane-to-node"&gt;control plane to node communication&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Metrics Server to Kubelet on all nodes. Metrics server needs to reach node address and Kubelet port. Addresses and ports are configured in Kubelet and published as part of Node object. Addresses in &lt;code&gt;.status.addresses&lt;/code&gt; and port in &lt;code&gt;.status.daemonEndpoints.kubeletEndpoint.port&lt;/code&gt; field (default 10250). Metrics Server will pick first node address based on the list provided by &lt;code&gt;kubelet-preferred-address-types&lt;/code&gt; command line flag (default &lt;code&gt;InternalIP,ExternalIP,Hostname&lt;/code&gt; in manifests).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Metrics Server can be installed either directly from YAML manifest or via the official &lt;a href="https://artifacthub.io/packages/helm/metrics-server/metrics-server"&gt;Helm chart&lt;/a&gt;. To install the latest Metrics Server release from the &lt;em&gt;components.yaml&lt;/em&gt; manifest, run the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Installation instructions for previous releases can be found in &lt;a href="https://github.com/kubernetes-sigs/metrics-server/releases"&gt;Metrics Server releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Compatibility Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metrics Server&lt;/th&gt; 
   &lt;th&gt;Metrics API group/version&lt;/th&gt; 
   &lt;th&gt;Supported Kubernetes version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.8.x&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;metrics.k8s.io/v1beta1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;1.31+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.7.x&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;metrics.k8s.io/v1beta1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;1.27+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.6.x&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;metrics.k8s.io/v1beta1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;1.25+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.5.x&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;metrics.k8s.io/v1beta1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;*1.8+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.4.x&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;metrics.k8s.io/v1beta1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;*1.8+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.3.x&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;metrics.k8s.io/v1beta1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;1.8-1.21&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Kubernetes versions lower than v1.16 require passing the &lt;code&gt;--authorization-always-allow-paths=/livez,/readyz&lt;/code&gt; command line flag&lt;/p&gt; 
&lt;h3&gt;High Availability&lt;/h3&gt; 
&lt;p&gt;Metrics Server can be installed in high availability mode directly from a YAML manifest or via the official &lt;a href="https://artifacthub.io/packages/helm/metrics-server/metrics-server"&gt;Helm chart&lt;/a&gt; by setting the &lt;code&gt;replicas&lt;/code&gt; value greater than &lt;code&gt;1&lt;/code&gt;. To install the latest Metrics Server release in high availability mode from the &lt;em&gt;high-availability.yaml&lt;/em&gt; manifest, run the following command.&lt;/p&gt; 
&lt;p&gt;On Kubernetes v1.21+:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/high-availability-1.21+.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Kubernetes v1.19-1.21:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/high-availability.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This configuration &lt;strong&gt;requires&lt;/strong&gt; having a cluster with at least 2 nodes on which Metrics Server can be scheduled.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Also, to maximize the efficiency of this highly available configuration, it is &lt;strong&gt;recommended&lt;/strong&gt; to add the &lt;code&gt;--enable-aggregator-routing=true&lt;/code&gt; CLI flag to the kube-apiserver so that requests sent to Metrics Server are load balanced between the 2 instances.&lt;/p&gt; 
&lt;h3&gt;Helm Chart&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://artifacthub.io/packages/helm/metrics-server/metrics-server"&gt;Helm chart&lt;/a&gt; is maintained as an additional component within this repo and released into a chart repository backed on the &lt;code&gt;gh-pages&lt;/code&gt; branch. A new version of the chart will be released for each Metrics Server release and can also be released independently if there is a need. The chart on the &lt;code&gt;master&lt;/code&gt; branch shouldn't be referenced directly as it might contain modifications since it was last released, to view the chart code use the chart release tag.&lt;/p&gt; 
&lt;h2&gt;Security context&lt;/h2&gt; 
&lt;p&gt;Metrics Server requires the &lt;code&gt;CAP_NET_BIND_SERVICE&lt;/code&gt; capability in order to bind to a privileged ports as non-root. If you are running Metrics Server in an environment that uses &lt;a href="https://kubernetes.io/docs/concepts/security/pod-security-standards/"&gt;PSSs&lt;/a&gt; or other mechanisms to restrict pod capabilities, ensure that Metrics Server is allowed to use this capability. This applies even if you use the &lt;code&gt;--secure-port&lt;/code&gt; flag to change the port that Metrics Server binds to a non-privileged port.&lt;/p&gt; 
&lt;h2&gt;Scaling&lt;/h2&gt; 
&lt;p&gt;Starting from v0.5.0 Metrics Server comes with default resource requests that should guarantee good performance for most cluster configurations up to 100 nodes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100m core of CPU&lt;/li&gt; 
 &lt;li&gt;200MiB of memory&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Metrics Server resource usage depends on multiple independent dimensions, creating a &lt;a href="https://github.com/kubernetes/community/raw/master/sig-scalability/configs-and-limits/thresholds.md"&gt;Scalability Envelope&lt;/a&gt;. Default Metrics Server configuration should work in clusters that don't exceed any of the thresholds listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Quantity&lt;/th&gt; 
   &lt;th&gt;Namespace threshold&lt;/th&gt; 
   &lt;th&gt;Cluster threshold&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;#Nodes&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;100&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;#Pods per node&lt;/td&gt; 
   &lt;td&gt;70&lt;/td&gt; 
   &lt;td&gt;70&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;#Deployments with HPAs&lt;/td&gt; 
   &lt;td&gt;100&lt;/td&gt; 
   &lt;td&gt;100&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Resources can be adjusted proportionally based on number of nodes in the cluster. For clusters of more than 100 nodes, allocate additionally:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;1m core per node&lt;/li&gt; 
 &lt;li&gt;2MiB memory per node&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can use the same approach to lower resource requests, but there is a boundary where this may impact other scalability dimensions like maximum number of pods per node.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Depending on your cluster setup, you may also need to change flags passed to the Metrics Server container. Most useful flags:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--kubelet-preferred-address-types&lt;/code&gt; - The priority of node address types used when determining an address for connecting to a particular node (default [Hostname,InternalDNS,InternalIP,ExternalDNS,ExternalIP])&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--kubelet-insecure-tls&lt;/code&gt; - Do not verify the CA of serving certificates presented by Kubelets. For testing purposes only.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--requestheader-client-ca-file&lt;/code&gt; - Specify a root certificate bundle for verifying client certificates on incoming requests.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--node-selector&lt;/code&gt; -Can complete to scrape the metrics from the Specified nodes based on labels&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can get a full list of Metrics Server configuration flags by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run --rm registry.k8s.io/metrics-server/metrics-server:v0.8.0 --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Design&lt;/h2&gt; 
&lt;p&gt;Metrics Server is a component in the core metrics pipeline described in &lt;a href="https://github.com/kubernetes/design-proposals-archive/raw/main/instrumentation/monitoring_architecture.md"&gt;Kubernetes monitoring architecture&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more information, see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubernetes/design-proposals-archive/raw/main/instrumentation/resource-metrics-api.md"&gt;Metrics API design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubernetes/design-proposals-archive/raw/main/instrumentation/metrics-server.md"&gt;Metrics Server design&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Have a question?&lt;/h2&gt; 
&lt;p&gt;Before posting an issue, first checkout &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/metrics-server/master/FAQ.md"&gt;Frequently Asked Questions&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/metrics-server/master/KNOWN_ISSUES.md"&gt;Known Issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community, discussion, contribution, and support&lt;/h2&gt; 
&lt;p&gt;Learn how to engage with the Kubernetes community on the &lt;a href="http://kubernetes.io/community/"&gt;community page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can reach the maintainers of this project at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kubernetes.slack.com/messages/sig-instrumentation"&gt;Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/kubernetes-sig-instrumentation"&gt;Mailing list&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This project is maintained by &lt;a href="https://github.com/kubernetes/community/tree/master/sig-instrumentation"&gt;SIG Instrumentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Code of conduct&lt;/h3&gt; 
&lt;p&gt;Participation in the Kubernetes community is governed by the &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/metrics-server/master/code-of-conduct.md"&gt;Kubernetes Code of Conduct&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kubernetes/autoscaler</title>
      <link>https://github.com/kubernetes/autoscaler</link>
      <description>&lt;p&gt;Autoscaling components for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kubernetes Autoscaler&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Release Charts" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml"&gt;&lt;img src="https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml/badge.svg?sanitize=true" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/k8s.io/autoscaler"&gt;&lt;img src="https://godoc.org/k8s.io/autoscaler?status.svg?sanitize=true" alt="GoDoc Widget" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repository contains autoscaling-related components for Kubernetes.&lt;/p&gt; 
&lt;h2&gt;What's inside&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler"&gt;Cluster Autoscaler&lt;/a&gt; - a component that automatically adjusts the size of a Kubernetes Cluster so that all pods have a place to run and there are no unneeded nodes. Supports several public cloud providers. Version 1.0 (GA) was released with kubernetes 1.8.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/charts"&gt;Cluster Autoscaler Helm Chart&lt;/a&gt; - Supported Helm chart for Cluster Autoscaler.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler"&gt;Vertical Pod Autoscaler&lt;/a&gt; - a set of components that automatically adjust the amount of CPU and memory requested by pods running in the Kubernetes Cluster. Current state - beta.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/charts"&gt;Vertical Pod Autoscaler Helm Chart&lt;/a&gt; - Supported Helm chart for Vertical Pod Autoscaler.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/addon-resizer"&gt;Addon Resizer&lt;/a&gt; - a simplified version of vertical pod autoscaler that modifies resource requests of a deployment based on the number of nodes in the Kubernetes Cluster. Current state - beta.&lt;/p&gt; 
&lt;h2&gt;Contact Info&lt;/h2&gt; 
&lt;p&gt;Interested in autoscaling? Want to talk? Have questions, concerns or great ideas?&lt;/p&gt; 
&lt;p&gt;Please join us on #sig-autoscaling at &lt;a href="https://kubernetes.slack.com/"&gt;https://kubernetes.slack.com/&lt;/a&gt;, or join one of our weekly meetings. See &lt;a href="https://github.com/kubernetes/community/raw/master/sig-autoscaling/README.md"&gt;the Kubernetes Community Repo&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Getting the Code&lt;/h2&gt; 
&lt;p&gt;Fork the repository in the cloud:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Visit &lt;a href="https://github.com/kubernetes/autoscaler"&gt;https://github.com/kubernetes/autoscaler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click Fork button (top right) to establish a cloud-based fork.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The code must be checked out as a subdirectory of &lt;code&gt;k8s.io&lt;/code&gt;, and not &lt;code&gt;github.com&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;mkdir -p $GOPATH/src/k8s.io
cd $GOPATH/src/k8s.io
# Replace "$YOUR_GITHUB_USERNAME" below with your github username
git clone https://github.com/$YOUR_GITHUB_USERNAME/autoscaler.git
cd autoscaler
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to Kubernetes &lt;a href="https://github.com/kubernetes/community/raw/master/contributors/guide/github-workflow.md"&gt;Github workflow guide&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mudler/LocalAI</title>
      <link>https://github.com/mudler/LocalAI</link>
      <description>&lt;p&gt;ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;img width="300" src="https://raw.githubusercontent.com/mudler/LocalAI/master/core/http/static/logo.png" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/go-skynet/LocalAI/fork" target="blank"&gt; &lt;img src="https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/stargazers" target="blank"&gt; &lt;img src="https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/pulls" target="blank"&gt; &lt;img src="https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI pull-requests" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/releases"&gt; &lt;img src="https://img.shields.io/github/release/go-skynet/LocalAI?&amp;amp;label=Latest&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://hub.docker.com/r/localai/localai" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker" alt="LocalAI Docker hub" /&gt; &lt;/a&gt; &lt;a href="https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;amp;tag=latest" target="blank"&gt; &lt;img src="https://img.shields.io/badge/quay.io-images-important.svg?" alt="LocalAI Quay.io" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://twitter.com/LocalAI_API" target="blank"&gt; &lt;img src="https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=white&amp;amp;label=LocalAI_API" alt="Follow LocalAI_API" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy" target="blank"&gt; &lt;img src="https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;amp;theme=default-inverted" alt="Join LocalAI Discord Community" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/5539" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/5539" alt="mudler%2FLocalAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;üí°&lt;/span&gt; Get help - &lt;a href="https://localai.io/faq/"&gt;‚ùìFAQ&lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/discussions"&gt;üí≠Discussions&lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy"&gt;&lt;span&gt;üí¨&lt;/span&gt; Discord&lt;/a&gt; &lt;a href="https://localai.io/"&gt;&lt;span&gt;üìñ&lt;/span&gt; Documentation website&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://localai.io/basics/getting_started/"&gt;üíª Quickstart&lt;/a&gt; &lt;a href="https://models.localai.io/"&gt;üñºÔ∏è Models&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;üöÄ Roadmap&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;üõ´ Examples&lt;/a&gt; Try on &lt;a href="https://t.me/localaiofficial_bot"&gt;&lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;amp;logo=telegram&amp;amp;logoColor=white" alt="Telegram" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg?sanitize=true" alt="tests" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Build and Release" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg?sanitize=true" alt="build container images" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg?sanitize=true" alt="Bump dependencies" /&gt;&lt;/a&gt;&lt;a href="https://artifacthub.io/packages/search?repo=localai"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;LocalAI&lt;/strong&gt; is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by &lt;a href="https://github.com/mudler"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìöüÜï Local Stack Family&lt;/h2&gt; 
&lt;p&gt;üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="300" alt="LocalAGI Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="300" alt="LocalRecall Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Talk Interface&lt;/th&gt; 
   &lt;th&gt;Generate Audio&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Models Overview&lt;/th&gt; 
   &lt;th&gt;Generate Images&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_gallery.png" alt="Screenshot 2025-03-31 at 12-01-20 LocalAI - Models" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_image.png" alt="Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chat Interface&lt;/th&gt; 
   &lt;th&gt;Home&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_chat.png" alt="Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_home.png" alt="Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Login&lt;/th&gt; 
   &lt;th&gt;Swarm&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_login.png" alt="Screenshot 2025-03-31 at 12-09-59 " /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_p2p.png" alt="Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üíª Quickstart&lt;/h2&gt; 
&lt;p&gt;Run the installer script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
curl https://localai.io/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more installation options, see &lt;a href="https://localai.io/docs/advanced/installer/"&gt;Installer Options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS Download:&lt;/h3&gt; 
&lt;a href="https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg"&gt; &lt;img src="https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Download LocalAI for macOS" /&gt; &lt;/a&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: the DMGs are not signed by Apple as quarantined. See &lt;a href="https://github.com/mudler/LocalAI/issues/6268"&gt;https://github.com/mudler/LocalAI/issues/6268&lt;/a&gt; for a workaround, fix is tracked here: &lt;a href="https://github.com/mudler/LocalAI/issues/6244"&gt;https://github.com/mudler/LocalAI/issues/6244&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Or run with docker:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Docker Run vs Docker Start&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker run&lt;/code&gt; creates and starts a new container. If a container with the same name already exists, this command will fail.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;docker start&lt;/code&gt; starts an existing container that was previously created with &lt;code&gt;docker run&lt;/code&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you've already run LocalAI before and want to start it again, use: &lt;code&gt;docker start -i local-ai&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;CPU only image:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;NVIDIA GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AMD GPU Images (ROCm):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Intel GPU Images (oneAPI):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Vulkan GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AIO Images (pre-downloaded models):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information about the AIO images and pre-downloaded models, see &lt;a href="https://localai.io/basics/container/"&gt;Container Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To load models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö° &lt;strong&gt;Automatic Backend Detection&lt;/strong&gt;: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see &lt;a href="https://localai.io/features/gpu-acceleration/#automatic-backend-detection"&gt;GPU Acceleration&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more information, see &lt;a href="https://localai.io/basics/getting_started/index.html"&gt;üíª Getting started&lt;/a&gt;, if you are interested in our roadmap items and future enhancements, you can see the &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;Issues labeled as Roadmap here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ Latest project news&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;October 2025: üîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; support added for agentic capabilities with external tools&lt;/li&gt; 
 &lt;li&gt;September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.&lt;/li&gt; 
 &lt;li&gt;August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with &lt;code&gt;development&lt;/code&gt; suffix in the gallery ): &lt;a href="https://github.com/mudler/LocalAI/pull/6049"&gt;https://github.com/mudler/LocalAI/pull/6049&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6119"&gt;https://github.com/mudler/LocalAI/pull/6119&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6121"&gt;https://github.com/mudler/LocalAI/pull/6121&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6060"&gt;https://github.com/mudler/LocalAI/pull/6060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July/August 2025: üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt; added to the API featuring &lt;a href="https://github.com/roboflow/rf-detr"&gt;rf-detr&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v3.2.0"&gt;Read the release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;Backend management&lt;/a&gt; has been added. Attention: extras images are going to be deprecated from the next release! Read &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;the backend management PR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5466"&gt;Audio input&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/5396"&gt;Reranking&lt;/a&gt; in llama.cpp backend, &lt;a href="https://github.com/mudler/LocalAI/pull/5392"&gt;Realtime API&lt;/a&gt;, Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).&lt;/li&gt; 
 &lt;li&gt;May 2025: Important: image name changes &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v2.29.0"&gt;See release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apr 2025: Rebrand, WebUI enhancements&lt;/li&gt; 
 &lt;li&gt;Apr 2025: &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt; join the LocalAI family stack.&lt;/li&gt; 
 &lt;li&gt;Apr 2025: WebUI overhaul, AIO images updates&lt;/li&gt; 
 &lt;li&gt;Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images&lt;/li&gt; 
 &lt;li&gt;Jan 2025: LocalAI model release: &lt;a href="https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3"&gt;https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3&lt;/a&gt;, SANA support in diffusers: &lt;a href="https://github.com/mudler/LocalAI/pull/4603"&gt;https://github.com/mudler/LocalAI/pull/4603&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dec 2024: stablediffusion.cpp backend (ggml) added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4289"&gt;https://github.com/mudler/LocalAI/pull/4289&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Bark.cpp backend added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4287"&gt;https://github.com/mudler/LocalAI/pull/4287&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Voice activity detection models (&lt;strong&gt;VAD&lt;/strong&gt;) added to the API: &lt;a href="https://github.com/mudler/LocalAI/pull/4204"&gt;https://github.com/mudler/LocalAI/pull/4204&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oct 2024: examples moved to &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;LocalAI-examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Aug 2024: üÜï FLUX-1, &lt;a href="https://explorer.localai.io"&gt;P2P Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: &lt;a href="https://github.com/mudler/LocalAI/pull/2723"&gt;https://github.com/mudler/LocalAI/pull/2723&lt;/a&gt;. P2P Global community pools: &lt;a href="https://github.com/mudler/LocalAI/issues/3113"&gt;https://github.com/mudler/LocalAI/issues/3113&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Decentralized P2P llama.cpp: &lt;a href="https://github.com/mudler/LocalAI/pull/2343"&gt;https://github.com/mudler/LocalAI/pull/2343&lt;/a&gt; (peer2peer llama.cpp!) üëâ Docs &lt;a href="https://localai.io/features/distribute/"&gt;https://localai.io/features/distribute/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Distributed inferencing: &lt;a href="https://github.com/mudler/LocalAI/pull/2324"&gt;https://github.com/mudler/LocalAI/pull/2324&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 2024: Reranker API: &lt;a href="https://github.com/mudler/LocalAI/pull/2121"&gt;https://github.com/mudler/LocalAI/pull/2121&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Roadmap items: &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;List of issues&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ &lt;a href="https://localai.io/features/"&gt;Features&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß© &lt;a href="https://localai.io/backends/"&gt;Backend Gallery&lt;/a&gt;: Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://localai.io/features/text-generation/"&gt;Text generation with GPTs&lt;/a&gt; (&lt;code&gt;llama.cpp&lt;/code&gt;, &lt;code&gt;transformers&lt;/code&gt;, &lt;code&gt;vllm&lt;/code&gt; ... &lt;a href="https://localai.io/model-compatibility/index.html#model-compatibility-table"&gt;&lt;span&gt;üìñ&lt;/span&gt; and more&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üó£ &lt;a href="https://localai.io/features/text-to-audio/"&gt;Text to Audio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîà &lt;a href="https://localai.io/features/audio-to-text/"&gt;Audio to Text&lt;/a&gt; (Audio transcription with &lt;code&gt;whisper.cpp&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üé® &lt;a href="https://localai.io/features/image-generation"&gt;Image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî• &lt;a href="https://localai.io/features/openai-functions/"&gt;OpenAI-alike tools API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß† &lt;a href="https://localai.io/features/embeddings/"&gt;Embeddings generation for vector databases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;a href="https://localai.io/features/constrained_grammars/"&gt;Constrained grammars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üñºÔ∏è &lt;a href="https://localai.io/models/"&gt;Download Models directly from Huggingface &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü•Ω &lt;a href="https://localai.io/features/gpt-vision/"&gt;Vision API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://localai.io/features/reranker/"&gt;Reranker API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüñß &lt;a href="https://localai.io/features/distribute/"&gt;P2P Inferencing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; - Agentic capabilities with external tools and &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI's Agentic capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîä Voice activity detection (Silero-VAD support)&lt;/li&gt; 
 &lt;li&gt;üåç Integrated WebUI!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© Supported Backends &amp;amp; Acceleration&lt;/h2&gt; 
&lt;p&gt;LocalAI supports a comprehensive range of AI backends with multiple acceleration options:&lt;/p&gt; 
&lt;h3&gt;Text Generation &amp;amp; Language Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM inference in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel SYCL, Vulkan, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast LLM inference with PagedAttention&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;transformers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace transformers framework&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;exllama2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GPTQ inference library&lt;/td&gt; 
   &lt;td&gt;CUDA 12&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon LLM inference&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX-VLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon Vision-Language Models&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Audio &amp;amp; Speech Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;whisper.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Whisper in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;faster-whisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast Whisper with CTranslate2&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-audio generation&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark-cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;C++ implementation of Bark&lt;/td&gt; 
   &lt;td&gt;CUDA, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;coqui&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Advanced TTS with 1100+ languages&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kokoro&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight TTS model&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;chatterbox&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Production-grade TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;piper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast neural TTS system&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kitten-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Kitten TTS models&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;silero-vad&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;neutts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-speech with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Image &amp;amp; Video Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;stablediffusion.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Stable Diffusion in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;diffusers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace diffusion models&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Specialized AI Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rfdetr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time object detection&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rerankers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document reranking API&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;local-store&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Vector database&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;huggingface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace API integration&lt;/td&gt; 
   &lt;td&gt;API-based&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Acceleration Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Acceleration Type&lt;/th&gt; 
   &lt;th&gt;Supported Backends&lt;/th&gt; 
   &lt;th&gt;Hardware Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 11&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rerankers, bark, chatterbox&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 12&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AMD ROCm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts&lt;/td&gt; 
   &lt;td&gt;AMD Graphics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Intel oneAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark&lt;/td&gt; 
   &lt;td&gt;Intel Arc, Intel iGPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apple Metal&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp&lt;/td&gt; 
   &lt;td&gt;Apple M1/M2/M3+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vulkan&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion&lt;/td&gt; 
   &lt;td&gt;Cross-platform GPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;CPU Optimized&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All backends&lt;/td&gt; 
   &lt;td&gt;AVX/AVX2/AVX512, quantization support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üîó Community and integrations&lt;/h3&gt; 
&lt;p&gt;Build and deploy custom containers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sozercan/aikit"&gt;https://github.com/sozercan/aikit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;WebUIs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jirubizu/localai-admin"&gt;https://github.com/Jirubizu/localai-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/LocalAI-frontend"&gt;https://github.com/go-skynet/LocalAI-frontend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) &lt;a href="https://github.com/reid41/QA-Pilot"&gt;https://github.com/reid41/QA-Pilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Agentic Libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/cogito"&gt;https://github.com/mudler/cogito&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCPs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/MCPs"&gt;https://github.com/mudler/MCPs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model galleries&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/model-gallery"&gt;https://github.com/go-skynet/model-gallery&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Voice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richiejp/VoxInput"&gt;https://github.com/richiejp/VoxInput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm chart &lt;a href="https://github.com/go-skynet/helm-charts"&gt;https://github.com/go-skynet/helm-charts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VSCode extension &lt;a href="https://github.com/badgooooor/localai-vscode-plugin"&gt;https://github.com/badgooooor/localai-vscode-plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Langchain: &lt;a href="https://python.langchain.com/docs/integrations/providers/localai/"&gt;https://python.langchain.com/docs/integrations/providers/localai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Terminal utility &lt;a href="https://github.com/djcopley/ShellOracle"&gt;https://github.com/djcopley/ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local Smart assistant &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Home Assistant &lt;a href="https://github.com/sammcj/homeassistant-localai"&gt;https://github.com/sammcj/homeassistant-localai&lt;/a&gt; / &lt;a href="https://github.com/drndos/hass-openai-custom-conversation"&gt;https://github.com/drndos/hass-openai-custom-conversation&lt;/a&gt; / &lt;a href="https://github.com/valentinfrlch/ha-gpt4vision"&gt;https://github.com/valentinfrlch/ha-gpt4vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/discord"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/slack"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) &lt;a href="https://github.com/reid41/shell-pilot"&gt;https://github.com/reid41/shell-pilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram bot &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot"&gt;https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Another Telegram Bot &lt;a href="https://github.com/JackBekket/Hellper"&gt;https://github.com/JackBekket/Hellper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Auto-documentation &lt;a href="https://github.com/JackBekket/Reflexia"&gt;https://github.com/JackBekket/Reflexia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github bot which answer on issues, with code and documentation as context &lt;a href="https://github.com/JackBekket/GitHelper"&gt;https://github.com/JackBekket/GitHelper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github Actions: &lt;a href="https://github.com/marketplace/actions/start-localai"&gt;https://github.com/marketplace/actions/start-localai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Examples: &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/"&gt;https://github.com/mudler/LocalAI/tree/master/examples/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/advanced/fine-tuning/"&gt;LLM finetuning guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/build/index.html"&gt;How to build locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes"&gt;How to install in Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/integrations/"&gt;Projects integrating LocalAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://io.midori-ai.xyz/howtos/"&gt;How tos section&lt;/a&gt; (curated by our community)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;üìñ&lt;/span&gt; üé• &lt;a href="https://localai.io/basics/news/#media-blogs-social"&gt;Media, Blogs, Social&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.suse.com/c/running-ai-locally/"&gt;Run Visual studio code with LocalAI (SUSE)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://mudler.pm/posts/local-ai-jetson-nano-devkit/"&gt;Run LocalAI on Jetson Nano Devkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/"&gt;Run LocalAI on AWS EKS with Pulumi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance"&gt;Run LocalAI on AWS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/smart-slackbot-for-teams/"&gt;Create a slackbot for teams and OSS projects that answer to documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PKrDNuJ_dfE"&gt;LocalAI meets k8sgpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/localai-question-answering/"&gt;Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65"&gt;Tutorial to use k8sgpt with LocalAI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/go-skynet/LocalAI}},
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ù§Ô∏è Sponsors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Do you find LocalAI useful?&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Support the project by becoming &lt;a href="https://github.com/sponsors/mudler"&gt;a backer or sponsor&lt;/a&gt;. Your logo will show up here with a link to your website.&lt;/p&gt; 
&lt;p&gt;A huge thank you to our generous sponsors who support this project covering CI expenses, and our &lt;a href="https://github.com/sponsors/mudler"&gt;Sponsor list&lt;/a&gt;:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.spectrocloud.com/" target="blank"&gt; &lt;img height="200" src="https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962" /&gt; &lt;/a&gt; &lt;a href="https://www.premai.io/" target="blank"&gt; &lt;img height="200" src="https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6" /&gt; &lt;br /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üåü Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#go-skynet/LocalAI&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=go-skynet/LocalAI&amp;amp;type=Date" alt="LocalAI Star history Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ License&lt;/h2&gt; 
&lt;p&gt;LocalAI is a community-driven project created by &lt;a href="https://github.com/mudler/"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;MIT - Author Ettore Di Giacinto &lt;a href="mailto:mudler@localai.io"&gt;mudler@localai.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üôá Acknowledgements&lt;/h2&gt; 
&lt;p&gt;LocalAI couldn't have been built without the help of great software already available from the community. Thank you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cornelk/llama-go"&gt;https://github.com/cornelk/llama-go&lt;/a&gt; for the initial ideas&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/antimatter15/alpaca.cpp"&gt;https://github.com/antimatter15/alpaca.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EdVince/Stable-Diffusion-NCNN"&gt;https://github.com/EdVince/Stable-Diffusion-NCNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;https://github.com/ggerganov/whisper.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rhasspy/piper"&gt;https://github.com/rhasspy/piper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ó Contributors&lt;/h2&gt; 
&lt;p&gt;This is a community project, a special thanks to our contributors! ü§ó &lt;a href="https://github.com/go-skynet/LocalAI/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=go-skynet/LocalAI" /&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>glanceapp/glance</title>
      <link>https://github.com/glanceapp/glance</link>
      <description>&lt;p&gt;A self-hosted dashboard that puts all your feeds in one place&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/logo.png" /&gt;&lt;/p&gt; 
&lt;h1 align="center"&gt;Glance&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/#installation"&gt;Install&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/configuration.md#configuring-glance"&gt;Configuration&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.com/invite/7KQ7Xa9kJd"&gt;Discord&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/sponsors/glanceapp"&gt;Sponsor&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/glanceapp/community-widgets"&gt;Community widgets&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/preconfigured-pages.md"&gt;Preconfigured pages&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/themes.md"&gt;Themes&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;A lightweight, highly customizable dashboard that displays&lt;br /&gt; your feeds in a beautiful, streamlined interface&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/images/readme-main-image.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Various widgets&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;RSS feeds&lt;/li&gt; 
 &lt;li&gt;Subreddit posts&lt;/li&gt; 
 &lt;li&gt;Hacker News posts&lt;/li&gt; 
 &lt;li&gt;Weather forecasts&lt;/li&gt; 
 &lt;li&gt;YouTube channel uploads&lt;/li&gt; 
 &lt;li&gt;Twitch channels&lt;/li&gt; 
 &lt;li&gt;Market prices&lt;/li&gt; 
 &lt;li&gt;Docker containers status&lt;/li&gt; 
 &lt;li&gt;Server stats&lt;/li&gt; 
 &lt;li&gt;Custom widgets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/configuration.md#configuring-glance"&gt;and many more...&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Fast and lightweight&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Low memory usage&lt;/li&gt; 
 &lt;li&gt;Few dependencies&lt;/li&gt; 
 &lt;li&gt;Minimal vanilla JS&lt;/li&gt; 
 &lt;li&gt;Single &amp;lt;20mb binary available for multiple OSs &amp;amp; architectures and just as small Docker container&lt;/li&gt; 
 &lt;li&gt;Uncached pages usually load within ~1s (depending on internet speed and number of widgets)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tons of customizability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Different layouts&lt;/li&gt; 
 &lt;li&gt;As many pages/tabs as you need&lt;/li&gt; 
 &lt;li&gt;Numerous configuration options for each widget&lt;/li&gt; 
 &lt;li&gt;Multiple styles for some widgets&lt;/li&gt; 
 &lt;li&gt;Custom CSS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Optimized for mobile devices&lt;/h3&gt; 
&lt;p&gt;Because you'll want to take it with you on the go.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/images/mobile-preview.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;Themeable&lt;/h3&gt; 
&lt;p&gt;Easily create your own theme by tweaking a few numbers or choose from one of the &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/themes.md"&gt;already available themes&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/images/themes-example.png" alt="" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Configuration is done through YAML files, to learn more about how the layout works, how to add more pages and how to configure widgets, visit the &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/configuration.md#configuring-glance"&gt;configuration documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Preview example configuration file&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;pages:
  - name: Home
    columns:
      - size: small
        widgets:
          - type: calendar
            first-day-of-week: monday

          - type: rss
            limit: 10
            collapse-after: 3
            cache: 12h
            feeds:
              - url: https://selfh.st/rss/
                title: selfh.st
                limit: 4
              - url: https://ciechanow.ski/atom.xml
              - url: https://www.joshwcomeau.com/rss.xml
                title: Josh Comeau
              - url: https://samwho.dev/rss.xml
              - url: https://ishadeed.com/feed.xml
                title: Ahmad Shadeed

          - type: twitch-channels
            channels:
              - theprimeagen
              - j_blow
              - piratesoftware
              - cohhcarnage
              - christitustech
              - EJ_SA

      - size: full
        widgets:
          - type: group
            widgets:
              - type: hacker-news
              - type: lobsters

          - type: videos
            channels:
              - UCXuqSBlHAE6Xw-yeJA0Tunw # Linus Tech Tips
              - UCR-DXc1voovS8nhAvccRZhg # Jeff Geerling
              - UCsBjURrPoezykLs9EqgamOA # Fireship
              - UCBJycsmduvYEL83R_U4JriQ # Marques Brownlee
              - UCHnyfMqiRRG1u-2MsSQLbXA # Veritasium

          - type: group
            widgets:
              - type: reddit
                subreddit: technology
                show-thumbnails: true
              - type: reddit
                subreddit: selfhosted
                show-thumbnails: true

      - size: small
        widgets:
          - type: weather
            location: London, United Kingdom
            units: metric
            hour-format: 12h

          - type: markets
            markets:
              - symbol: SPY
                name: S&amp;amp;P 500
              - symbol: BTC-USD
                name: Bitcoin
              - symbol: NVDA
                name: NVIDIA
              - symbol: AAPL
                name: Apple
              - symbol: MSFT
                name: Microsoft

          - type: releases
            cache: 1d
            repositories:
              - glanceapp/glance
              - go-gitea/gitea
              - immich-app/immich
              - syncthing/syncthing
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Choose one of the following methods:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Docker compose using provided directory structure (recommended)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Create a new directory called &lt;code&gt;glance&lt;/code&gt; as well as the template files within it by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir glance &amp;amp;&amp;amp; cd glance &amp;amp;&amp;amp; curl -sL https://github.com/glanceapp/docker-compose-template/archive/refs/heads/main.tar.gz | tar -xzf - --strip-components 2
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/glanceapp/docker-compose-template/tree/main/root"&gt;click here to view the files that will be created&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;Then, edit the following files as desired:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker-compose.yml&lt;/code&gt; to configure the port, volumes and other containery things&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/home.yml&lt;/code&gt; to configure the widgets or layout of the home page&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/glance.yml&lt;/code&gt; if you want to change the theme or add more pages&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Other files you may want to edit&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; to configure environment variables that will be available inside configuration files&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;assets/user.css&lt;/code&gt; to add custom CSS&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;p&gt;When ready, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you encounter any issues, you can check the logs by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose logs
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Docker compose manual&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Create a &lt;code&gt;docker-compose.yml&lt;/code&gt; file with the following contents:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  glance:
    container_name: glance
    image: glanceapp/glance
    restart: unless-stopped
    volumes:
      - ./config:/app/config
    ports:
      - 8080:8080
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Then, create a new directory called &lt;code&gt;config&lt;/code&gt; and download the example starting &lt;a href="https://github.com/glanceapp/glance/raw/main/docs/glance.yml"&gt;&lt;code&gt;glance.yml&lt;/code&gt;&lt;/a&gt; file into it by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir config &amp;amp;&amp;amp; wget -O config/glance.yml https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Feel free to edit the &lt;code&gt;glance.yml&lt;/code&gt; file to your liking, and when ready run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you encounter any issues, you can check the logs by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker logs glance
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Manual binary installation&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Precompiled binaries are available for Linux, Windows and macOS (x86, x86_64, ARM and ARM64 architectures).&lt;/p&gt; 
 &lt;h3&gt;Linux&lt;/h3&gt; 
 &lt;p&gt;Visit the &lt;a href="https://github.com/glanceapp/glance/releases/latest"&gt;latest release page&lt;/a&gt; for available binaries. You can place the binary in &lt;code&gt;/opt/glance/&lt;/code&gt; and have it start with your server via a &lt;a href="https://linuxhandbook.com/create-systemd-services/"&gt;systemd service&lt;/a&gt;. By default, when running the binary, it will look for a &lt;code&gt;glance.yml&lt;/code&gt; file in the directory it's placed in. To specify a different path for the config file, use the &lt;code&gt;--config&lt;/code&gt; option:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;/opt/glance/glance --config /etc/glance.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To grab a starting template for the config file, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;wget https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Windows&lt;/h3&gt; 
 &lt;p&gt;Download and extract the executable from the &lt;a href="https://github.com/glanceapp/glance/releases/latest"&gt;latest release&lt;/a&gt; (most likely the file called &lt;code&gt;glance-windows-amd64.zip&lt;/code&gt; if you're on a 64-bit system) and place it in a folder of your choice. Then, create a new text file called &lt;code&gt;glance.yml&lt;/code&gt; in the same folder and paste the content from &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml"&gt;here&lt;/a&gt; in it. You should then be able to run the executable and access the dashboard by visiting &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser.&lt;/p&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Other&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Glance can also be installed through the following 3rd party channels:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://community-scripts.github.io/ProxmoxVE/scripts?id=glance"&gt;Proxmox VE Helper Script&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://search.nixos.org/packages?channel=unstable&amp;amp;show=glance"&gt;NixOS package&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://coolify.io/docs/services/glance/"&gt;Coolify.io&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Common issues&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Requests timing out&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The most common cause of this is when using Pi-Hole, AdGuard Home or other ad-blocking DNS services, which by default have a fairly low rate limit. Depending on the number of widgets you have in a single page, this limit can very easily be exceeded. To fix this, increase the rate limit in the settings of your DNS service.&lt;/p&gt; 
 &lt;p&gt;If using Podman, in some rare cases the timeout can be caused by an unknown issue, in which case it may be resolved by adding the following to the bottom of your &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;networks:
  podman:
    external: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Broken layout for markets, bookmarks or other widgets&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;This is almost always caused by the browser extension Dark Reader. To fix this, disable dark mode for the domain where Glance is hosted.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;cannot unmarshal !!map into []glance.page&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The most common cause of this is having a &lt;code&gt;pages&lt;/code&gt; key in your &lt;code&gt;glance.yml&lt;/code&gt; and then also having a &lt;code&gt;pages&lt;/code&gt; key inside one of your included pages. To fix this, remove the &lt;code&gt;pages&lt;/code&gt; key from the top of your included pages.&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Does the information on the page update automatically?&lt;/strong&gt;&lt;/summary&gt; No, a page refresh is required to update the information. Some things do dynamically update where it makes sense, like the clock widget and the relative time showing how long ago something happened. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;How frequently do widgets update?&lt;/strong&gt;&lt;/summary&gt; No requests are made periodically in the background, information is only fetched upon loading the page and then cached. The default cache lifetime is different for each widget and can be configured. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Can I create my own widgets?&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Yes, there are multiple ways to create custom widgets:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;iframe&lt;/code&gt; widget - allows you to embed things from other websites&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;html&lt;/code&gt; widget - allows you to insert your own static HTML&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;extension&lt;/code&gt; widget - fetch HTML from a URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;custom-api&lt;/code&gt; widget - fetch JSON from a URL and render it using custom HTML&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Can I change the title of a widget?&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Yes, the title of all widgets can be changed by specifying the &lt;code&gt;title&lt;/code&gt; property in the widget's configuration:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;- type: rss
  title: My custom title

- type: markets
  title: My custom title

- type: videos
  title: My custom title

# and so on for all widgets...
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Feature requests&lt;/h2&gt; 
&lt;p&gt;New feature suggestions are always welcome and will be considered, though please keep in mind that some of them may be out of scope for what the project is trying to achieve (or is reasonably capable of). If you have an idea for a new feature and would like to share it, you can do so &lt;a href="https://github.com/glanceapp/glance/issues/new?template=feature_request.yml"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Feature requests are tagged with one of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glanceapp/glance/labels/roadmap"&gt;Roadmap&lt;/a&gt; - will be implemented in a future release&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glanceapp/glance/labels/backlog"&gt;Backlog&lt;/a&gt; - may be implemented in the future but needs further feedback or interest from the community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glanceapp/glance/labels/icebox"&gt;Icebox&lt;/a&gt; - no plans to implement as it doesn't currently align with the project's goals or capabilities, may be revised at a later date&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Building from source&lt;/h2&gt; 
&lt;p&gt;Choose one of the following methods:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build binary with Go&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Requirements: &lt;a href="https://go.dev/dl/"&gt;Go&lt;/a&gt; &amp;gt;= v1.23&lt;/p&gt; 
 &lt;p&gt;To build the project for your current OS and architecture, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;go build -o build/glance .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build for a specific OS and architecture, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;GOOS=linux GOARCH=amd64 go build -o build/glance .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;a href="https://go.dev/doc/install/source#:~:text=$GOOS%20and%20$GOARCH"&gt;&lt;em&gt;click here for a full list of GOOS and GOARCH combinations&lt;/em&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Alternatively, if you just want to run the app without creating a binary, like when you're testing out changes, you can run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;go run .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build project and Docker image with Docker&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Requirements: &lt;a href="https://docs.docker.com/engine/install/"&gt;Docker&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;To build the project and image using just Docker, run:&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;(replace &lt;code&gt;owner&lt;/code&gt; with your name or organization)&lt;/em&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t owner/glance:latest .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you wish to push the image to a registry (by default Docker Hub), run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker push owner/glance:latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Contributing guidelines&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Before working on a new feature it's preferable to submit a feature request first and state that you'd like to implement it yourself&lt;/li&gt; 
 &lt;li&gt;Please don't submit PRs for feature requests that are either in the roadmap&lt;sup&gt;[1]&lt;/sup&gt;, backlog&lt;sup&gt;[2]&lt;/sup&gt; or icebox&lt;sup&gt;[3]&lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;dev&lt;/code&gt; for the base branch if you're adding new features or fixing bugs, otherwise use &lt;code&gt;main&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Avoid introducing new dependencies&lt;/li&gt; 
 &lt;li&gt;Avoid making backwards-incompatible configuration changes&lt;/li&gt; 
 &lt;li&gt;Avoid introducing new colors or hard-coding colors, use the standard &lt;code&gt;primary&lt;/code&gt;, &lt;code&gt;positive&lt;/code&gt; and &lt;code&gt;negative&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For icons, try to use &lt;a href="https://heroicons.com/"&gt;heroicons&lt;/a&gt; where applicable&lt;/li&gt; 
 &lt;li&gt;Provide a screenshot of the changes if UI related where possible&lt;/li&gt; 
 &lt;li&gt;No &lt;code&gt;package.json&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;&lt;sup&gt;[1] [2] [3]&lt;/sup&gt;&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;[1] The feature likely already has work put into it that may conflict with your implementation&lt;/p&gt; 
 &lt;p&gt;[2] The demand, implementation or functionality for this feature is not yet clear&lt;/p&gt; 
 &lt;p&gt;[3] No plans to add this feature for the time being&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Thank you&lt;/h2&gt; 
&lt;p&gt;To all the people who were generous enough to &lt;a href="https://github.com/sponsors/glanceapp"&gt;sponsor&lt;/a&gt; the project and to everyone who has contributed in any way, be it PRs, submitting issues, helping others in the discussions or Discord server, creating guides and tools or just mentioning Glance on social media. Your support is greatly appreciated and helps keep the project going.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>moby/moby</title>
      <link>https://github.com/moby/moby</link>
      <description>&lt;p&gt;The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Moby Project&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/moby/moby/v2"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/moby/moby/v2" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/license/moby/moby" alt="GitHub License" /&gt; &lt;a href="https://goreportcard.com/report/github.com/moby/moby/v2"&gt;&lt;img src="https://goreportcard.com/badge/github.com/moby/moby/v2" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/moby/moby"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/moby/moby/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/10989"&gt;&lt;img src="https://www.bestpractices.dev/projects/10989/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/moby/moby/master/docs/static_files/moby-project-logo.png" alt="Moby Project logo" title="The Moby Project" /&gt;&lt;/p&gt; 
&lt;p&gt;Moby is an open-source project created by Docker to enable and accelerate software containerization.&lt;/p&gt; 
&lt;p&gt;It provides a "Lego set" of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas. Components include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.&lt;/p&gt; 
&lt;h2&gt;Principles&lt;/h2&gt; 
&lt;p&gt;Moby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience. It is open to the community to help set its direction.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modular: the project includes lots of components that have well-defined functions and APIs that work together.&lt;/li&gt; 
 &lt;li&gt;Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.&lt;/li&gt; 
 &lt;li&gt;Usable security: Moby provides secure defaults without compromising usability.&lt;/li&gt; 
 &lt;li&gt;Developer focused: The APIs are intended to be functional and useful to build powerful tools. They are not necessarily intended as end user tools but as components aimed at developers. Documentation and UX is aimed at developers not end users.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Audience&lt;/h2&gt; 
&lt;p&gt;The Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers. It is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.&lt;/p&gt; 
&lt;h2&gt;Relationship with Docker&lt;/h2&gt; 
&lt;p&gt;The components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project. New projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product. However, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.&lt;/p&gt; 
&lt;p&gt;The Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful. The releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; and &lt;a href="https://www.mirantis.com/software/mirantis-container-runtime/"&gt;Mirantis Container Runtime&lt;/a&gt; are the appropriate products for these use cases.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Legal&lt;/h1&gt; 
&lt;p&gt;&lt;em&gt;Brought to you courtesy of our legal counsel. For more context, please see the &lt;a href="https://github.com/moby/moby/raw/master/NOTICE"&gt;NOTICE&lt;/a&gt; document in this repo.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Use and transfer of Moby may be subject to certain restrictions by the United States and other governments.&lt;/p&gt; 
&lt;p&gt;It is your responsibility to ensure that your use and/or transfer does not violate applicable laws.&lt;/p&gt; 
&lt;p&gt;For more information, please see &lt;a href="https://www.bis.doc.gov"&gt;https://www.bis.doc.gov&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Licensing&lt;/h1&gt; 
&lt;p&gt;Moby is licensed under the Apache License, Version 2.0. See &lt;a href="https://github.com/moby/moby/raw/master/LICENSE"&gt;LICENSE&lt;/a&gt; for the full license text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>go-chi/chi</title>
      <link>https://github.com/go-chi/chi</link>
      <description>&lt;p&gt;lightweight, idiomatic and composable router for building Go HTTP services&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img alt="chi" src="https://cdn.rawgit.com/go-chi/chi/master/_examples/chi.svg?sanitize=true" width="220" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/v5"&gt;&lt;img src="https://godoc.org/github.com/go-chi/chi?status.svg?sanitize=true" alt="GoDoc Widget" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;chi&lt;/code&gt; is a lightweight, idiomatic and composable router for building Go HTTP services. It's especially good at helping you write large REST API services that are kept maintainable as your project grows and changes. &lt;code&gt;chi&lt;/code&gt; is built on the new &lt;code&gt;context&lt;/code&gt; package introduced in Go 1.7 to handle signaling, cancelation and request-scoped values across a handler chain.&lt;/p&gt; 
&lt;p&gt;The focus of the project has been to seek out an elegant and comfortable design for writing REST API servers, written during the development of the Pressly API service that powers our public API service, which in turn powers all of our client-side applications.&lt;/p&gt; 
&lt;p&gt;The key considerations of chi's design are: project structure, maintainability, standard http handlers (stdlib-only), developer productivity, and deconstructing a large system into many small parts. The core router &lt;code&gt;github.com/go-chi/chi&lt;/code&gt; is quite small (less than 1000 LOC), but we've also included some useful/optional subpackages: &lt;a href="https://raw.githubusercontent.com/go-chi/chi/master/middleware"&gt;middleware&lt;/a&gt;, &lt;a href="https://github.com/go-chi/render"&gt;render&lt;/a&gt; and &lt;a href="https://github.com/go-chi/docgen"&gt;docgen&lt;/a&gt;. We hope you enjoy it too!&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go get -u github.com/go-chi/chi/v5
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt; - cloc'd in ~1000 LOC for the chi router&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt; - yes, see &lt;a href="https://raw.githubusercontent.com/go-chi/chi/master/#benchmarks"&gt;benchmarks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% compatible with net/http&lt;/strong&gt; - use any http or middleware pkg in the ecosystem that is also compatible with &lt;code&gt;net/http&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Designed for modular/composable APIs&lt;/strong&gt; - middlewares, inline middlewares, route groups and sub-router mounting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Context control&lt;/strong&gt; - built on new &lt;code&gt;context&lt;/code&gt; package, providing value chaining, cancellations and timeouts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Robust&lt;/strong&gt; - in production at Pressly, Cloudflare, Heroku, 99Designs, and many others (see &lt;a href="https://github.com/go-chi/chi/issues/91"&gt;discussion&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Doc generation&lt;/strong&gt; - &lt;code&gt;docgen&lt;/code&gt; auto-generates routing documentation from your source to JSON or Markdown&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Go.mod support&lt;/strong&gt; - as of v5, go.mod support (see &lt;a href="https://github.com/go-chi/chi/raw/master/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No external dependencies&lt;/strong&gt; - plain ol' Go stdlib + net/http&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/go-chi/chi/raw/master/_examples/"&gt;_examples/&lt;/a&gt; for a variety of examples.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;As easy as:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"net/http"

	"github.com/go-chi/chi/v5"
	"github.com/go-chi/chi/v5/middleware"
)

func main() {
	r := chi.NewRouter()
	r.Use(middleware.Logger)
	r.Get("/", func(w http.ResponseWriter, r *http.Request) {
		w.Write([]byte("welcome"))
	})
	http.ListenAndServe(":3000", r)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;REST Preview:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Here is a little preview of what routing looks like with chi. Also take a look at the generated routing docs in JSON (&lt;a href="https://github.com/go-chi/chi/raw/master/_examples/rest/routes.json"&gt;routes.json&lt;/a&gt;) and in Markdown (&lt;a href="https://github.com/go-chi/chi/raw/master/_examples/rest/routes.md"&gt;routes.md&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;I highly recommend reading the source of the &lt;a href="https://github.com/go-chi/chi/raw/master/_examples/"&gt;examples&lt;/a&gt; listed above, they will show you all the features of chi and serve as a good form of documentation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  //...
  "context"
  "github.com/go-chi/chi/v5"
  "github.com/go-chi/chi/v5/middleware"
)

func main() {
  r := chi.NewRouter()

  // A good base middleware stack
  r.Use(middleware.RequestID)
  r.Use(middleware.RealIP)
  r.Use(middleware.Logger)
  r.Use(middleware.Recoverer)

  // Set a timeout value on the request context (ctx), that will signal
  // through ctx.Done() that the request has timed out and further
  // processing should be stopped.
  r.Use(middleware.Timeout(60 * time.Second))

  r.Get("/", func(w http.ResponseWriter, r *http.Request) {
    w.Write([]byte("hi"))
  })

  // RESTy routes for "articles" resource
  r.Route("/articles", func(r chi.Router) {
    r.With(paginate).Get("/", listArticles)                           // GET /articles
    r.With(paginate).Get("/{month}-{day}-{year}", listArticlesByDate) // GET /articles/01-16-2017

    r.Post("/", createArticle)                                        // POST /articles
    r.Get("/search", searchArticles)                                  // GET /articles/search

    // Regexp url parameters:
    r.Get("/{articleSlug:[a-z-]+}", getArticleBySlug)                // GET /articles/home-is-toronto

    // Subrouters:
    r.Route("/{articleID}", func(r chi.Router) {
      r.Use(ArticleCtx)
      r.Get("/", getArticle)                                          // GET /articles/123
      r.Put("/", updateArticle)                                       // PUT /articles/123
      r.Delete("/", deleteArticle)                                    // DELETE /articles/123
    })
  })

  // Mount the admin sub-router
  r.Mount("/admin", adminRouter())

  http.ListenAndServe(":3333", r)
}

func ArticleCtx(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    articleID := chi.URLParam(r, "articleID")
    article, err := dbGetArticle(articleID)
    if err != nil {
      http.Error(w, http.StatusText(404), 404)
      return
    }
    ctx := context.WithValue(r.Context(), "article", article)
    next.ServeHTTP(w, r.WithContext(ctx))
  })
}

func getArticle(w http.ResponseWriter, r *http.Request) {
  ctx := r.Context()
  article, ok := ctx.Value("article").(*Article)
  if !ok {
    http.Error(w, http.StatusText(422), 422)
    return
  }
  w.Write([]byte(fmt.Sprintf("title:%s", article.Title)))
}

// A completely separate router for administrator routes
func adminRouter() http.Handler {
  r := chi.NewRouter()
  r.Use(AdminOnly)
  r.Get("/", adminIndex)
  r.Get("/accounts", adminListAccounts)
  return r
}

func AdminOnly(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    perm, ok := ctx.Value("acl.permission").(YourPermissionType)
    if !ok || !perm.IsAdmin() {
      http.Error(w, http.StatusText(403), 403)
      return
    }
    next.ServeHTTP(w, r)
  })
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Router interface&lt;/h2&gt; 
&lt;p&gt;chi's router is based on a kind of &lt;a href="https://en.wikipedia.org/wiki/Radix_tree"&gt;Patricia Radix trie&lt;/a&gt;. The router is fully compatible with &lt;code&gt;net/http&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Built on top of the tree is the &lt;code&gt;Router&lt;/code&gt; interface:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Router consisting of the core routing methods used by chi's Mux,
// using only the standard net/http.
type Router interface {
	http.Handler
	Routes

	// Use appends one or more middlewares onto the Router stack.
	Use(middlewares ...func(http.Handler) http.Handler)

	// With adds inline middlewares for an endpoint handler.
	With(middlewares ...func(http.Handler) http.Handler) Router

	// Group adds a new inline-Router along the current routing
	// path, with a fresh middleware stack for the inline-Router.
	Group(fn func(r Router)) Router

	// Route mounts a sub-Router along a `pattern` string.
	Route(pattern string, fn func(r Router)) Router

	// Mount attaches another http.Handler along ./pattern/*
	Mount(pattern string, h http.Handler)

	// Handle and HandleFunc adds routes for `pattern` that matches
	// all HTTP methods.
	Handle(pattern string, h http.Handler)
	HandleFunc(pattern string, h http.HandlerFunc)

	// Method and MethodFunc adds routes for `pattern` that matches
	// the `method` HTTP method.
	Method(method, pattern string, h http.Handler)
	MethodFunc(method, pattern string, h http.HandlerFunc)

	// HTTP-method routing along `pattern`
	Connect(pattern string, h http.HandlerFunc)
	Delete(pattern string, h http.HandlerFunc)
	Get(pattern string, h http.HandlerFunc)
	Head(pattern string, h http.HandlerFunc)
	Options(pattern string, h http.HandlerFunc)
	Patch(pattern string, h http.HandlerFunc)
	Post(pattern string, h http.HandlerFunc)
	Put(pattern string, h http.HandlerFunc)
	Trace(pattern string, h http.HandlerFunc)

	// NotFound defines a handler to respond whenever a route could
	// not be found.
	NotFound(h http.HandlerFunc)

	// MethodNotAllowed defines a handler to respond whenever a method is
	// not allowed.
	MethodNotAllowed(h http.HandlerFunc)
}

// Routes interface adds two methods for router traversal, which is also
// used by the github.com/go-chi/docgen package to generate documentation for Routers.
type Routes interface {
	// Routes returns the routing tree in an easily traversable structure.
	Routes() []Route

	// Middlewares returns the list of middlewares in use by the router.
	Middlewares() Middlewares

	// Match searches the routing tree for a handler that matches
	// the method/path - similar to routing a http request, but without
	// executing the handler thereafter.
	Match(rctx *Context, method, path string) bool
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Each routing method accepts a URL &lt;code&gt;pattern&lt;/code&gt; and chain of &lt;code&gt;handlers&lt;/code&gt;. The URL pattern supports named params (ie. &lt;code&gt;/users/{userID}&lt;/code&gt;) and wildcards (ie. &lt;code&gt;/admin/*&lt;/code&gt;). URL parameters can be fetched at runtime by calling &lt;code&gt;chi.URLParam(r, "userID")&lt;/code&gt; for named parameters and &lt;code&gt;chi.URLParam(r, "*")&lt;/code&gt; for a wildcard parameter.&lt;/p&gt; 
&lt;h3&gt;Middleware handlers&lt;/h3&gt; 
&lt;p&gt;chi's middlewares are just stdlib net/http middleware handlers. There is nothing special about them, which means the router and all the tooling is designed to be compatible and friendly with any middleware in the community. This offers much better extensibility and reuse of packages and is at the heart of chi's purpose.&lt;/p&gt; 
&lt;p&gt;Here is an example of a standard net/http middleware where we assign a context key &lt;code&gt;"user"&lt;/code&gt; the value of &lt;code&gt;"123"&lt;/code&gt;. This middleware sets a hypothetical user identifier on the request context and calls the next handler in the chain.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// HTTP middleware setting a value on the request context
func MyMiddleware(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    // create new context from `r` request context, and assign key `"user"`
    // to value of `"123"`
    ctx := context.WithValue(r.Context(), "user", "123")

    // call the next handler in the chain, passing the response writer and
    // the updated request object with the new context value.
    //
    // note: context.Context values are nested, so any previously set
    // values will be accessible as well, and the new `"user"` key
    // will be accessible from this point forward.
    next.ServeHTTP(w, r.WithContext(ctx))
  })
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Request handlers&lt;/h3&gt; 
&lt;p&gt;chi uses standard net/http request handlers. This little snippet is an example of a http.Handler func that reads a user identifier from the request context - hypothetically, identifying the user sending an authenticated request, validated+set by a previous middleware handler.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// HTTP handler accessing data from the request context.
func MyRequestHandler(w http.ResponseWriter, r *http.Request) {
  // here we read from the request context and fetch out `"user"` key set in
  // the MyMiddleware example above.
  user := r.Context().Value("user").(string)

  // respond to the client
  w.Write([]byte(fmt.Sprintf("hi %s", user)))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;URL parameters&lt;/h3&gt; 
&lt;p&gt;chi's router parses and stores URL parameters right onto the request context. Here is an example of how to access URL params in your net/http handlers. And of course, middlewares are able to access the same information.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// HTTP handler accessing the url routing parameters.
func MyRequestHandler(w http.ResponseWriter, r *http.Request) {
  // fetch the url parameter `"userID"` from the request of a matching
  // routing pattern. An example routing pattern could be: /users/{userID}
  userID := chi.URLParam(r, "userID")

  // fetch `"key"` from the request context
  ctx := r.Context()
  key := ctx.Value("key").(string)

  // respond to the client
  w.Write([]byte(fmt.Sprintf("hi %v, %v", userID, key)))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Middlewares&lt;/h2&gt; 
&lt;p&gt;chi comes equipped with an optional &lt;code&gt;middleware&lt;/code&gt; package, providing a suite of standard &lt;code&gt;net/http&lt;/code&gt; middlewares. Please note, any middleware in the ecosystem that is also compatible with &lt;code&gt;net/http&lt;/code&gt; can be used with chi's mux.&lt;/p&gt; 
&lt;h3&gt;Core middlewares&lt;/h3&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;chi/middleware Handler&lt;/th&gt; 
   &lt;th align="left"&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentEncoding"&gt;AllowContentEncoding&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Enforces a whitelist of request Content-Encoding headers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentType"&gt;AllowContentType&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Explicit whitelist of accepted request Content-Types&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#BasicAuth"&gt;BasicAuth&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Basic HTTP authentication&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Compress"&gt;Compress&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Gzip compression for clients that accept compressed responses&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#ContentCharset"&gt;ContentCharset&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Ensure charset for Content-Type request headers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#CleanPath"&gt;CleanPath&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Clean double slashes from request path&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#GetHead"&gt;GetHead&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automatically route undefined HEAD requests to GET handlers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Heartbeat"&gt;Heartbeat&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Monitoring endpoint to check the servers pulse&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Logger"&gt;Logger&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Logs the start and end of each request with the elapsed processing time&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#NoCache"&gt;NoCache&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sets response headers to prevent clients from caching&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Profiler"&gt;Profiler&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easily attach net/http/pprof to your routers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#RealIP"&gt;RealIP&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sets a http.Request's RemoteAddr to either X-Real-IP or X-Forwarded-For&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Recoverer"&gt;Recoverer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Gracefully absorb panics and prints the stack trace&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#RequestID"&gt;RequestID&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Injects a request ID into the context of each request&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#RedirectSlashes"&gt;RedirectSlashes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Redirect slashes on routing paths&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#RouteHeaders"&gt;RouteHeaders&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Route handling for request headers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#SetHeader"&gt;SetHeader&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Short-hand middleware to set a response header key/value&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#StripSlashes"&gt;StripSlashes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Strip slashes on routing paths&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/v5/middleware#Sunset"&gt;Sunset&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sunset set Deprecation/Sunset header to response&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Throttle"&gt;Throttle&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Puts a ceiling on the number of concurrent requests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Timeout"&gt;Timeout&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Signals to the request context when the timeout deadline is reached&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#URLFormat"&gt;URLFormat&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Parse extension from url and put it on request context&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#WithValue"&gt;WithValue&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Short-hand middleware to set a key/value on the request context&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Extra middlewares &amp;amp; packages&lt;/h3&gt; 
&lt;p&gt;Please see &lt;a href="https://github.com/go-chi"&gt;https://github.com/go-chi&lt;/a&gt; for additional packages.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;package&lt;/th&gt; 
   &lt;th align="left"&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/cors"&gt;cors&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cross-origin resource sharing (CORS)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/docgen"&gt;docgen&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Print chi.Router routes at runtime&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/jwtauth"&gt;jwtauth&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;JWT authentication&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/hostrouter"&gt;hostrouter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Domain/host based request routing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/httplog"&gt;httplog&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small but powerful structured HTTP request logging&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/httprate"&gt;httprate&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTTP request rate limiter&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/httptracer"&gt;httptracer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTTP request performance tracing library&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/httpvcr"&gt;httpvcr&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Write deterministic tests for external sources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/stampede"&gt;stampede&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTTP request coalescer&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;context?&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;context&lt;/code&gt; is a tiny pkg that provides simple interface to signal context across call stacks and goroutines. It was originally written by &lt;a href="https://github.com/Sajmani"&gt;Sameer Ajmani&lt;/a&gt; and is available in stdlib since go1.7.&lt;/p&gt; 
&lt;p&gt;Learn more at &lt;a href="https://blog.golang.org/context"&gt;https://blog.golang.org/context&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;and..&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docs: &lt;a href="https://golang.org/pkg/context"&gt;https://golang.org/pkg/context&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Source: &lt;a href="https://github.com/golang/go/tree/master/src/context"&gt;https://github.com/golang/go/tree/master/src/context&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;The benchmark suite: &lt;a href="https://github.com/pkieltyka/go-http-routing-benchmark"&gt;https://github.com/pkieltyka/go-http-routing-benchmark&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Results as of Nov 29, 2020 with Go 1.15.5 on Linux AMD 3950x&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;BenchmarkChi_Param          	3075895	        384 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_Param5         	2116603	        566 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_Param20        	 964117	       1227 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_ParamWrite     	2863413	        420 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GithubStatic   	3045488	        395 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GithubParam    	2204115	        540 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GithubAll      	  10000	     113811 ns/op	    81203 B/op    406 allocs/op
BenchmarkChi_GPlusStatic    	3337485	        359 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GPlusParam     	2825853	        423 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GPlus2Params   	2471697	        483 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GPlusAll       	 194220	       5950 ns/op	     5200 B/op     26 allocs/op
BenchmarkChi_ParseStatic    	3365324	        356 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_ParseParam     	2976614	        404 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_Parse2Params   	2638084	        439 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_ParseAll       	 109567	      11295 ns/op	    10400 B/op     52 allocs/op
BenchmarkChi_StaticAll      	  16846	      71308 ns/op	    62802 B/op    314 allocs/op
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Comparison with other routers: &lt;a href="https://gist.github.com/pkieltyka/123032f12052520aaccab752bd3e78cc"&gt;https://gist.github.com/pkieltyka/123032f12052520aaccab752bd3e78cc&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;NOTE: the allocs in the benchmark above are from the calls to http.Request's &lt;code&gt;WithContext(context.Context)&lt;/code&gt; method that clones the http.Request, sets the &lt;code&gt;Context()&lt;/code&gt; on the duplicated (alloc'd) request and returns it the new request object. This is just how setting context on a request in Go works.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Carl Jackson for &lt;a href="https://github.com/zenazn/goji"&gt;https://github.com/zenazn/goji&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Parts of chi's thinking comes from goji, and chi's middleware package sources from &lt;a href="https://github.com/zenazn/goji/tree/master/web/middleware"&gt;goji&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Please see goji's &lt;a href="https://github.com/zenazn/goji/raw/master/LICENSE"&gt;LICENSE&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Armon Dadgar for &lt;a href="https://github.com/armon/go-radix"&gt;https://github.com/armon/go-radix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Contributions: &lt;a href="https://github.com/VojtechVitek"&gt;@VojtechVitek&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We'll be more than happy to see &lt;a href="https://raw.githubusercontent.com/go-chi/chi/master/CONTRIBUTING.md"&gt;your contributions&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Beyond REST&lt;/h2&gt; 
&lt;p&gt;chi is just a http router that lets you decompose request handling into many smaller layers. Many companies use chi to write REST services for their public APIs. But, REST is just a convention for managing state via HTTP, and there's a lot of other pieces required to write a complete client-server system or network of microservices.&lt;/p&gt; 
&lt;p&gt;Looking beyond REST, I also recommend some newer works in the field:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/webrpc/webrpc"&gt;webrpc&lt;/a&gt; - Web-focused RPC client+server framework with code-gen&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grpc/grpc-go"&gt;gRPC&lt;/a&gt; - Google's RPC framework via protobufs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/99designs/gqlgen"&gt;graphql&lt;/a&gt; - Declarative query language&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nats.io"&gt;NATS&lt;/a&gt; - lightweight pub-sub&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) 2015-present &lt;a href="https://github.com/pkieltyka"&gt;Peter Kieltyka&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Licensed under &lt;a href="https://raw.githubusercontent.com/go-chi/chi/master/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>prometheus/node_exporter</title>
      <link>https://github.com/prometheus/node_exporter</link>
      <description>&lt;p&gt;Exporter for machine metrics&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Node exporter&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://circleci.com/gh/prometheus/node_exporter"&gt;&lt;img src="https://circleci.com/gh/prometheus/node_exporter/tree/master.svg?style=shield" alt="CircleCI" /&gt;&lt;/a&gt; &lt;img src="https://github.com/prometheus/node_exporter/actions/workflows/bsd.yml/badge.svg?sanitize=true" alt="bsd workflow" /&gt; &lt;img src="https://github.com/prometheus/node_exporter/actions/workflows/golangci-lint.yml/badge.svg?sanitize=true" alt="golangci-lint workflow" /&gt; &lt;a href="https://quay.io/repository/prometheus/node-exporter"&gt;&lt;img src="https://quay.io/repository/prometheus/node-exporter/status" alt="Docker Repository on Quay" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/prom/node-exporter/"&gt;&lt;img src="https://img.shields.io/docker/pulls/prom/node-exporter.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/prometheus/node_exporter"&gt;&lt;img src="https://goreportcard.com/badge/github.com/prometheus/node_exporter" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Prometheus exporter for hardware and OS metrics exposed by *NIX kernels, written in Go with pluggable metric collectors.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://github.com/prometheus-community/windows_exporter"&gt;Windows exporter&lt;/a&gt; is recommended for Windows users. To expose NVIDIA GPU metrics, &lt;a href="https://github.com/NVIDIA/dcgm-exporter"&gt;prometheus-dcgm &lt;/a&gt; can be used.&lt;/p&gt; 
&lt;h2&gt;Installation and Usage&lt;/h2&gt; 
&lt;p&gt;If you are new to Prometheus and &lt;code&gt;node_exporter&lt;/code&gt; there is a &lt;a href="https://prometheus.io/docs/guides/node-exporter/"&gt;simple step-by-step guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;node_exporter&lt;/code&gt; listens on HTTP port 9100 by default. See the &lt;code&gt;--help&lt;/code&gt; output for more options.&lt;/p&gt; 
&lt;h3&gt;Ansible&lt;/h3&gt; 
&lt;p&gt;For automated installs with &lt;a href="https://www.ansible.com/"&gt;Ansible&lt;/a&gt;, there is the &lt;a href="https://github.com/prometheus-community/ansible"&gt;Prometheus Community role&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;node_exporter&lt;/code&gt; is designed to monitor the host system. Deploying in containers requires extra care in order to avoid monitoring the container itself.&lt;/p&gt; 
&lt;p&gt;For situations where containerized deployment is needed, some extra flags must be used to allow the &lt;code&gt;node_exporter&lt;/code&gt; access to the host namespaces.&lt;/p&gt; 
&lt;p&gt;Be aware that any non-root mount points you want to monitor will need to be bind-mounted into the container.&lt;/p&gt; 
&lt;p&gt;If you start container for host monitoring, specify &lt;code&gt;path.rootfs&lt;/code&gt; argument. This argument must match path in bind-mount of host root. The node_exporter will use &lt;code&gt;path.rootfs&lt;/code&gt; as prefix to access host filesystem.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --net="host" \
  --pid="host" \
  -v "/:/host:ro,rslave" \
  quay.io/prometheus/node-exporter:latest \
  --path.rootfs=/host
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Docker compose, similar flag changes are needed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;---
version: '3.8'

services:
  node_exporter:
    image: quay.io/prometheus/node-exporter:latest
    container_name: node_exporter
    command:
      - '--path.rootfs=/host'
    network_mode: host
    pid: host
    restart: unless-stopped
    volumes:
      - '/:/host:ro,rslave'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, the &lt;code&gt;timex&lt;/code&gt; collector requires an additional Docker flag, &lt;code&gt;--cap-add=SYS_TIME&lt;/code&gt;, in order to access the required syscalls.&lt;/p&gt; 
&lt;h2&gt;Collectors&lt;/h2&gt; 
&lt;p&gt;There is varying support for collectors on each operating system. The tables below list all existing collectors and the supported systems.&lt;/p&gt; 
&lt;p&gt;Collectors are enabled by providing a &lt;code&gt;--collector.&amp;lt;name&amp;gt;&lt;/code&gt; flag. Collectors that are enabled by default can be disabled by providing a &lt;code&gt;--no-collector.&amp;lt;name&amp;gt;&lt;/code&gt; flag. To enable only some specific collector(s), use &lt;code&gt;--collector.disable-defaults --collector.&amp;lt;name&amp;gt; ...&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Include &amp;amp; Exclude flags&lt;/h3&gt; 
&lt;p&gt;A few collectors can be configured to include or exclude certain patterns using dedicated flags. The exclude flags are used to indicate "all except", while the include flags are used to say "none except". Note that these flags are mutually exclusive on collectors that support both.&lt;/p&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-txt"&gt;--collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;List:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Collector&lt;/th&gt; 
   &lt;th&gt;Scope&lt;/th&gt; 
   &lt;th&gt;Include Flag&lt;/th&gt; 
   &lt;th&gt;Exclude Flag&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;arp&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.arp.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.arp.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu&lt;/td&gt; 
   &lt;td&gt;bugs&lt;/td&gt; 
   &lt;td&gt;--collector.cpu.info.bugs-include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu&lt;/td&gt; 
   &lt;td&gt;flags&lt;/td&gt; 
   &lt;td&gt;--collector.cpu.info.flags-include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;diskstats&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.diskstats.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.diskstats.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ethtool&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.ethtool.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.ethtool.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ethtool&lt;/td&gt; 
   &lt;td&gt;metrics&lt;/td&gt; 
   &lt;td&gt;--collector.ethtool.metrics-include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filesystem&lt;/td&gt; 
   &lt;td&gt;fs-types&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.fs-types-include&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.fs-types-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filesystem&lt;/td&gt; 
   &lt;td&gt;mount-points&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.mount-points-include&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.mount-points-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;hwmon&lt;/td&gt; 
   &lt;td&gt;chip&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.chip-include&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.chip-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;hwmon&lt;/td&gt; 
   &lt;td&gt;sensor&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.sensor-include&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.sensor-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;interrupts&lt;/td&gt; 
   &lt;td&gt;name&lt;/td&gt; 
   &lt;td&gt;--collector.interrupts.name-include&lt;/td&gt; 
   &lt;td&gt;--collector.interrupts.name-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netdev&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.netdev.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.netdev.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;qdisk&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.qdisk.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.qdisk.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;slabinfo&lt;/td&gt; 
   &lt;td&gt;slab-names&lt;/td&gt; 
   &lt;td&gt;--collector.slabinfo.slabs-include&lt;/td&gt; 
   &lt;td&gt;--collector.slabinfo.slabs-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;sysctl&lt;/td&gt; 
   &lt;td&gt;all&lt;/td&gt; 
   &lt;td&gt;--collector.sysctl.include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;systemd&lt;/td&gt; 
   &lt;td&gt;unit&lt;/td&gt; 
   &lt;td&gt;--collector.systemd.unit-include&lt;/td&gt; 
   &lt;td&gt;--collector.systemd.unit-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Enabled by default&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;OS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;arp&lt;/td&gt; 
   &lt;td&gt;Exposes ARP statistics from &lt;code&gt;/proc/net/arp&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;bcache&lt;/td&gt; 
   &lt;td&gt;Exposes bcache statistics from &lt;code&gt;/sys/fs/bcache/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;bonding&lt;/td&gt; 
   &lt;td&gt;Exposes the number of configured and active slaves of Linux bonding interfaces.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;btrfs&lt;/td&gt; 
   &lt;td&gt;Exposes btrfs statistics&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;boottime&lt;/td&gt; 
   &lt;td&gt;Exposes system boot time derived from the &lt;code&gt;kern.boottime&lt;/code&gt; sysctl.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, NetBSD, OpenBSD, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;conntrack&lt;/td&gt; 
   &lt;td&gt;Shows conntrack statistics (does nothing if no &lt;code&gt;/proc/sys/net/netfilter/&lt;/code&gt; present).&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu&lt;/td&gt; 
   &lt;td&gt;Exposes CPU statistics&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, Solaris, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpufreq&lt;/td&gt; 
   &lt;td&gt;Exposes CPU frequency statistics&lt;/td&gt; 
   &lt;td&gt;Linux, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;diskstats&lt;/td&gt; 
   &lt;td&gt;Exposes disk I/O statistics.&lt;/td&gt; 
   &lt;td&gt;Darwin, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;dmi&lt;/td&gt; 
   &lt;td&gt;Expose Desktop Management Interface (DMI) info from &lt;code&gt;/sys/class/dmi/id/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;edac&lt;/td&gt; 
   &lt;td&gt;Exposes error detection and correction statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;entropy&lt;/td&gt; 
   &lt;td&gt;Exposes available entropy.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;exec&lt;/td&gt; 
   &lt;td&gt;Exposes execution statistics.&lt;/td&gt; 
   &lt;td&gt;Dragonfly, FreeBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fibrechannel&lt;/td&gt; 
   &lt;td&gt;Exposes fibre channel information and statistics from &lt;code&gt;/sys/class/fc_host/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filefd&lt;/td&gt; 
   &lt;td&gt;Exposes file descriptor statistics from &lt;code&gt;/proc/sys/fs/file-nr&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filesystem&lt;/td&gt; 
   &lt;td&gt;Exposes filesystem statistics, such as disk space used.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;hwmon&lt;/td&gt; 
   &lt;td&gt;Expose hardware monitoring and sensor data from &lt;code&gt;/sys/class/hwmon/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;infiniband&lt;/td&gt; 
   &lt;td&gt;Exposes network statistics specific to InfiniBand and Intel OmniPath configurations.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ipvs&lt;/td&gt; 
   &lt;td&gt;Exposes IPVS status from &lt;code&gt;/proc/net/ip_vs&lt;/code&gt; and stats from &lt;code&gt;/proc/net/ip_vs_stats&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;loadavg&lt;/td&gt; 
   &lt;td&gt;Exposes load average.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, NetBSD, OpenBSD, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;mdadm&lt;/td&gt; 
   &lt;td&gt;Exposes statistics about devices in &lt;code&gt;/proc/mdstat&lt;/code&gt; (does nothing if no &lt;code&gt;/proc/mdstat&lt;/code&gt; present).&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;meminfo&lt;/td&gt; 
   &lt;td&gt;Exposes memory statistics.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netclass&lt;/td&gt; 
   &lt;td&gt;Exposes network interface info from &lt;code&gt;/sys/class/net/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netdev&lt;/td&gt; 
   &lt;td&gt;Exposes network interface statistics such as bytes transferred.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netisr&lt;/td&gt; 
   &lt;td&gt;Exposes netisr statistics&lt;/td&gt; 
   &lt;td&gt;FreeBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netstat&lt;/td&gt; 
   &lt;td&gt;Exposes network statistics from &lt;code&gt;/proc/net/netstat&lt;/code&gt;. This is the same information as &lt;code&gt;netstat -s&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nfs&lt;/td&gt; 
   &lt;td&gt;Exposes NFS client statistics from &lt;code&gt;/proc/net/rpc/nfs&lt;/code&gt;. This is the same information as &lt;code&gt;nfsstat -c&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nfsd&lt;/td&gt; 
   &lt;td&gt;Exposes NFS kernel server statistics from &lt;code&gt;/proc/net/rpc/nfsd&lt;/code&gt;. This is the same information as &lt;code&gt;nfsstat -s&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvme&lt;/td&gt; 
   &lt;td&gt;Exposes NVMe info from &lt;code&gt;/sys/class/nvme/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;os&lt;/td&gt; 
   &lt;td&gt;Expose OS release info from &lt;code&gt;/etc/os-release&lt;/code&gt; or &lt;code&gt;/usr/lib/os-release&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;powersupplyclass&lt;/td&gt; 
   &lt;td&gt;Exposes Power Supply statistics from &lt;code&gt;/sys/class/power_supply&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;pressure&lt;/td&gt; 
   &lt;td&gt;Exposes pressure stall statistics from &lt;code&gt;/proc/pressure/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux (kernel 4.20+ and/or &lt;a href="https://www.kernel.org/doc/html/latest/accounting/psi.html"&gt;CONFIG_PSI&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;rapl&lt;/td&gt; 
   &lt;td&gt;Exposes various statistics from &lt;code&gt;/sys/class/powercap&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;schedstat&lt;/td&gt; 
   &lt;td&gt;Exposes task scheduler statistics from &lt;code&gt;/proc/schedstat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;selinux&lt;/td&gt; 
   &lt;td&gt;Exposes SELinux statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;sockstat&lt;/td&gt; 
   &lt;td&gt;Exposes various statistics from &lt;code&gt;/proc/net/sockstat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;softnet&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/proc/net/softnet_stat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;stat&lt;/td&gt; 
   &lt;td&gt;Exposes various statistics from &lt;code&gt;/proc/stat&lt;/code&gt;. This includes boot time, forks and interrupts.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tapestats&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/sys/class/scsi_tape&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;textfile&lt;/td&gt; 
   &lt;td&gt;Exposes statistics read from local disk. The &lt;code&gt;--collector.textfile.directory&lt;/code&gt; flag must be set.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;thermal&lt;/td&gt; 
   &lt;td&gt;Exposes thermal statistics like &lt;code&gt;pmset -g therm&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Darwin&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;thermal_zone&lt;/td&gt; 
   &lt;td&gt;Exposes thermal zone &amp;amp; cooling device statistics from &lt;code&gt;/sys/class/thermal&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;time&lt;/td&gt; 
   &lt;td&gt;Exposes the current system time.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;timex&lt;/td&gt; 
   &lt;td&gt;Exposes selected adjtimex(2) system call stats.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;udp_queues&lt;/td&gt; 
   &lt;td&gt;Exposes UDP total lengths of the rx_queue and tx_queue from &lt;code&gt;/proc/net/udp&lt;/code&gt; and &lt;code&gt;/proc/net/udp6&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;uname&lt;/td&gt; 
   &lt;td&gt;Exposes system information as provided by the uname system call.&lt;/td&gt; 
   &lt;td&gt;Darwin, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vmstat&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/proc/vmstat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;watchdog&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/sys/class/watchdog&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xfs&lt;/td&gt; 
   &lt;td&gt;Exposes XFS runtime statistics.&lt;/td&gt; 
   &lt;td&gt;Linux (kernel 4.4+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;zfs&lt;/td&gt; 
   &lt;td&gt;Exposes &lt;a href="http://open-zfs.org/"&gt;ZFS&lt;/a&gt; performance statistics.&lt;/td&gt; 
   &lt;td&gt;FreeBSD, &lt;a href="http://zfsonlinux.org/"&gt;Linux&lt;/a&gt;, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Disabled by default&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;node_exporter&lt;/code&gt; also implements a number of collectors that are disabled by default. Reasons for this vary by collector, and may include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;High cardinality&lt;/li&gt; 
 &lt;li&gt;Prolonged runtime that exceeds the Prometheus &lt;code&gt;scrape_interval&lt;/code&gt; or &lt;code&gt;scrape_timeout&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Significant resource demands on the host&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can enable additional collectors as desired by adding them to your init system's or service supervisor's startup configuration for &lt;code&gt;node_exporter&lt;/code&gt; but caution is advised. Enable at most one at a time, testing first on a non-production system, then by hand on a single production node. When enabling additional collectors, you should carefully monitor the change by observing the &lt;code&gt; scrape_duration_seconds&lt;/code&gt; metric to ensure that collection completes and does not time out. In addition, monitor the &lt;code&gt;scrape_samples_post_metric_relabeling&lt;/code&gt; metric to see the changes in cardinality.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;OS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;buddyinfo&lt;/td&gt; 
   &lt;td&gt;Exposes statistics of memory fragments as reported by /proc/buddyinfo.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cgroups&lt;/td&gt; 
   &lt;td&gt;A summary of the number of active and enabled cgroups&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu_vulnerabilities&lt;/td&gt; 
   &lt;td&gt;Exposes CPU vulnerability information from sysfs.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;devstat&lt;/td&gt; 
   &lt;td&gt;Exposes device statistics&lt;/td&gt; 
   &lt;td&gt;Dragonfly, FreeBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;drm&lt;/td&gt; 
   &lt;td&gt;Expose GPU metrics using sysfs / DRM, &lt;code&gt;amdgpu&lt;/code&gt; is the only driver which exposes this information through DRM&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;drbd&lt;/td&gt; 
   &lt;td&gt;Exposes Distributed Replicated Block Device statistics (to version 8.4)&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ethtool&lt;/td&gt; 
   &lt;td&gt;Exposes network interface information and network driver statistics equivalent to &lt;code&gt;ethtool&lt;/code&gt;, &lt;code&gt;ethtool -S&lt;/code&gt;, and &lt;code&gt;ethtool -i&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;interrupts&lt;/td&gt; 
   &lt;td&gt;Exposes detailed interrupts statistics.&lt;/td&gt; 
   &lt;td&gt;Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ksmd&lt;/td&gt; 
   &lt;td&gt;Exposes kernel and system statistics from &lt;code&gt;/sys/kernel/mm/ksm&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;lnstat&lt;/td&gt; 
   &lt;td&gt;Exposes stats from &lt;code&gt;/proc/net/stat/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;logind&lt;/td&gt; 
   &lt;td&gt;Exposes session counts from &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/logind/"&gt;logind&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;meminfo_numa&lt;/td&gt; 
   &lt;td&gt;Exposes memory statistics from &lt;code&gt;/sys/devices/system/node/node[0-9]*/meminfo&lt;/code&gt;, &lt;code&gt;/sys/devices/system/node/node[0-9]*/numastat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;mountstats&lt;/td&gt; 
   &lt;td&gt;Exposes filesystem statistics from &lt;code&gt;/proc/self/mountstats&lt;/code&gt;. Exposes detailed NFS client statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;network_route&lt;/td&gt; 
   &lt;td&gt;Exposes the routing table as metrics&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;pcidevice&lt;/td&gt; 
   &lt;td&gt;Exposes pci devices' information including their link status and parent devices.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;perf&lt;/td&gt; 
   &lt;td&gt;Exposes perf based metrics (Warning: Metrics are dependent on kernel configuration and settings).&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;processes&lt;/td&gt; 
   &lt;td&gt;Exposes aggregate process statistics from &lt;code&gt;/proc&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;qdisc&lt;/td&gt; 
   &lt;td&gt;Exposes &lt;a href="https://en.wikipedia.org/wiki/Network_scheduler#Linux_kernel"&gt;queuing discipline&lt;/a&gt; statistics&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;slabinfo&lt;/td&gt; 
   &lt;td&gt;Exposes slab statistics from &lt;code&gt;/proc/slabinfo&lt;/code&gt;. Note that permission of &lt;code&gt;/proc/slabinfo&lt;/code&gt; is usually 0400, so set it appropriately.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;softirqs&lt;/td&gt; 
   &lt;td&gt;Exposes detailed softirq statistics from &lt;code&gt;/proc/softirqs&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;sysctl&lt;/td&gt; 
   &lt;td&gt;Expose sysctl values from &lt;code&gt;/proc/sys&lt;/code&gt;. Use &lt;code&gt;--collector.sysctl.include(-info)&lt;/code&gt; to configure.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;swap&lt;/td&gt; 
   &lt;td&gt;Expose swap information from &lt;code&gt;/proc/swaps&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;systemd&lt;/td&gt; 
   &lt;td&gt;Exposes service and system status from &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/"&gt;systemd&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tcpstat&lt;/td&gt; 
   &lt;td&gt;Exposes TCP connection status information from &lt;code&gt;/proc/net/tcp&lt;/code&gt; and &lt;code&gt;/proc/net/tcp6&lt;/code&gt;. (Warning: the current version has potential performance issues in high load situations.)&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;wifi&lt;/td&gt; 
   &lt;td&gt;Exposes WiFi device and station statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xfrm&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/proc/net/xfrm_stat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;zoneinfo&lt;/td&gt; 
   &lt;td&gt;Exposes NUMA memory zone metrics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;p&gt;These collectors are deprecated and will be removed in the next major release.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;OS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ntp&lt;/td&gt; 
   &lt;td&gt;Exposes local NTP daemon health to check &lt;a href="https://raw.githubusercontent.com/prometheus/node_exporter/master/docs/TIME.md"&gt;time&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;runit&lt;/td&gt; 
   &lt;td&gt;Exposes service status from &lt;a href="http://smarden.org/runit/"&gt;runit&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;supervisord&lt;/td&gt; 
   &lt;td&gt;Exposes service status from &lt;a href="http://supervisord.org/"&gt;supervisord&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Perf Collector&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;perf&lt;/code&gt; collector may not work out of the box on some Linux systems due to kernel configuration and security settings. To allow access, set the following &lt;code&gt;sysctl&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sysctl -w kernel.perf_event_paranoid=X
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;2 allow only user-space measurements (default since Linux 4.6).&lt;/li&gt; 
 &lt;li&gt;1 allow both kernel and user measurements (default before Linux 4.6).&lt;/li&gt; 
 &lt;li&gt;0 allow access to CPU-specific data but not raw tracepoint samples.&lt;/li&gt; 
 &lt;li&gt;-1 no restrictions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Depending on the configured value different metrics will be available, for most cases &lt;code&gt;0&lt;/code&gt; will provide the most complete set. For more information see &lt;a href="http://man7.org/linux/man-pages/man2/perf_event_open.2.html"&gt;&lt;code&gt;man 2 perf_event_open&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;By default, the &lt;code&gt;perf&lt;/code&gt; collector will only collect metrics of the CPUs that &lt;code&gt;node_exporter&lt;/code&gt; is running on (ie &lt;a href="https://golang.org/pkg/runtime/#NumCPU"&gt;&lt;code&gt;runtime.NumCPU&lt;/code&gt;&lt;/a&gt;. If this is insufficient (e.g. if you run &lt;code&gt;node_exporter&lt;/code&gt; with its CPU affinity set to specific CPUs), you can specify a list of alternate CPUs by using the &lt;code&gt;--collector.perf.cpus&lt;/code&gt; flag. For example, to collect metrics on CPUs 2-6, you would specify: &lt;code&gt;--collector.perf --collector.perf.cpus=2-6&lt;/code&gt;. The CPU configuration is zero indexed and can also take a stride value; e.g. &lt;code&gt;--collector.perf --collector.perf.cpus=1-10:5&lt;/code&gt; would collect on CPUs 1, 5, and 10.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;perf&lt;/code&gt; collector is also able to collect &lt;a href="https://www.kernel.org/doc/html/latest/core-api/tracepoint.html"&gt;tracepoint&lt;/a&gt; counts when using the &lt;code&gt;--collector.perf.tracepoint&lt;/code&gt; flag. Tracepoints can be found using &lt;a href="http://man7.org/linux/man-pages/man1/perf.1.html"&gt;&lt;code&gt;perf list&lt;/code&gt;&lt;/a&gt; or from debugfs. And example usage of this would be &lt;code&gt;--collector.perf.tracepoint="sched:sched_process_exec"&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Sysctl Collector&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;sysctl&lt;/code&gt; collector can be enabled with &lt;code&gt;--collector.sysctl&lt;/code&gt;. It supports exposing numeric sysctl values as metrics using the &lt;code&gt;--collector.sysctl.include&lt;/code&gt; flag and string values as info metrics by using the &lt;code&gt;--collector.sysctl.include-info&lt;/code&gt; flag. The flags can be repeated. For sysctl with multiple numeric values, an optional mapping can be given to expose each value as its own metric. Otherwise an &lt;code&gt;index&lt;/code&gt; label is used to identify the different fields.&lt;/p&gt; 
&lt;h4&gt;Examples&lt;/h4&gt; 
&lt;h5&gt;Numeric values&lt;/h5&gt; 
&lt;h6&gt;Single values&lt;/h6&gt; 
&lt;p&gt;Using &lt;code&gt;--collector.sysctl.include=vm.user_reserve_kbytes&lt;/code&gt;: &lt;code&gt;vm.user_reserve_kbytes = 131072&lt;/code&gt; -&amp;gt; &lt;code&gt;node_sysctl_vm_user_reserve_kbytes 131072&lt;/code&gt;&lt;/p&gt; 
&lt;h6&gt;Multiple values&lt;/h6&gt; 
&lt;p&gt;A sysctl can contain multiple values, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;net.ipv4.tcp_rmem = 4096	131072	6291456
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Using &lt;code&gt;--collector.sysctl.include=net.ipv4.tcp_rmem&lt;/code&gt; the collector will expose:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;node_sysctl_net_ipv4_tcp_rmem{index="0"} 4096
node_sysctl_net_ipv4_tcp_rmem{index="1"} 131072
node_sysctl_net_ipv4_tcp_rmem{index="2"} 6291456
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the indexes have defined meaning like in this case, the values can be mapped to multiple metrics by appending the mapping to the --collector.sysctl.include flag: Using &lt;code&gt;--collector.sysctl.include=net.ipv4.tcp_rmem:min,default,max&lt;/code&gt; the collector will expose:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;node_sysctl_net_ipv4_tcp_rmem_min 4096
node_sysctl_net_ipv4_tcp_rmem_default 131072
node_sysctl_net_ipv4_tcp_rmem_max 6291456
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;String values&lt;/h5&gt; 
&lt;p&gt;String values need to be exposed as info metric. The user selects them by using the &lt;code&gt;--collector.sysctl.include-info&lt;/code&gt; flag.&lt;/p&gt; 
&lt;h6&gt;Single values&lt;/h6&gt; 
&lt;p&gt;&lt;code&gt;kernel.core_pattern = core&lt;/code&gt; -&amp;gt; &lt;code&gt;node_sysctl_info{key="kernel.core_pattern_info", value="core"} 1&lt;/code&gt;&lt;/p&gt; 
&lt;h6&gt;Multiple values&lt;/h6&gt; 
&lt;p&gt;Given the following sysctl:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;kernel.seccomp.actions_avail = kill_process kill_thread trap errno trace log allow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Setting &lt;code&gt;--collector.sysctl.include-info=kernel.seccomp.actions_avail&lt;/code&gt; will yield:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;node_sysctl_info{key="kernel.seccomp.actions_avail", index="0", value="kill_process"} 1
node_sysctl_info{key="kernel.seccomp.actions_avail", index="1", value="kill_thread"} 1
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Textfile Collector&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;textfile&lt;/code&gt; collector is similar to the &lt;a href="https://github.com/prometheus/pushgateway"&gt;Pushgateway&lt;/a&gt;, in that it allows exporting of statistics from batch jobs. It can also be used to export static metrics, such as what role a machine has. The Pushgateway should be used for service-level metrics. The &lt;code&gt;textfile&lt;/code&gt; module is for metrics that are tied to a machine.&lt;/p&gt; 
&lt;p&gt;To use it, set the &lt;code&gt;--collector.textfile.directory&lt;/code&gt; flag on the &lt;code&gt;node_exporter&lt;/code&gt; commandline. The collector will parse all files in that directory matching the glob &lt;code&gt;*.prom&lt;/code&gt; using the &lt;a href="http://prometheus.io/docs/instrumenting/exposition_formats/"&gt;text format&lt;/a&gt;. &lt;strong&gt;Note:&lt;/strong&gt; Timestamps are not supported.&lt;/p&gt; 
&lt;p&gt;To atomically push completion time for a cron job:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;echo my_batch_job_completion_time $(date +%s) &amp;gt; /path/to/directory/my_batch_job.prom.$$
mv /path/to/directory/my_batch_job.prom.$$ /path/to/directory/my_batch_job.prom
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To statically set roles for a machine using labels:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;echo 'role{role="application_server"} 1' &amp;gt; /path/to/directory/role.prom.$$
mv /path/to/directory/role.prom.$$ /path/to/directory/role.prom
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Filtering enabled collectors&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;node_exporter&lt;/code&gt; will expose all metrics from enabled collectors by default. This is the recommended way to collect metrics to avoid errors when comparing metrics of different families.&lt;/p&gt; 
&lt;p&gt;For advanced use the &lt;code&gt;node_exporter&lt;/code&gt; can be passed an optional list of collectors to filter metrics. The parameters &lt;code&gt;collect[]&lt;/code&gt; and &lt;code&gt;exclude[]&lt;/code&gt; can be used multiple times (but cannot be combined). In Prometheus configuration you can use this syntax under the &lt;a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#%3Cscrape_config%3E"&gt;scrape config&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Collect only &lt;code&gt;cpu&lt;/code&gt; and &lt;code&gt;meminfo&lt;/code&gt; collector metrics:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  params:
    collect[]:
      - cpu
      - meminfo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Collect all enabled collector metrics but exclude &lt;code&gt;netdev&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  params:
    exclude[]:
      - netdev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This can be useful for having different Prometheus servers collect specific metrics from nodes.&lt;/p&gt; 
&lt;h2&gt;Development building and running&lt;/h2&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/dl/"&gt;Go compiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RHEL/CentOS: &lt;code&gt;glibc-static&lt;/code&gt; package.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Building:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/prometheus/node_exporter.git
cd node_exporter
make build
./node_exporter &amp;lt;flags&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see all available configuration flags:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./node_exporter -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running tests&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;TLS endpoint&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;EXPERIMENTAL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The exporter supports TLS via a new web configuration file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;./node_exporter --web.config.file=web-config.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/prometheus/exporter-toolkit/raw/master/docs/web-configuration.md"&gt;exporter-toolkit web-configuration&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lima-vm/lima</title>
      <link>https://github.com/lima-vm/lima</link>
      <description>&lt;p&gt;Linux virtual machines, with a focus on running containers&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://lima-vm.io/"&gt;[üåé&lt;strong&gt;Web site&lt;/strong&gt;]&lt;/a&gt; &lt;a href="https://lima-vm.io/docs/"&gt;[üìñ&lt;strong&gt;Documentation&lt;/strong&gt;]&lt;/a&gt; &lt;a href="https://slack.cncf.io"&gt;[üë§&lt;strong&gt;Slack (&lt;code&gt;#lima&lt;/code&gt;)&lt;/strong&gt;]&lt;/a&gt;&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="website/static/images/logo-dark.svg" /&gt; 
 &lt;img alt="Shows a stylized 'Lima' text in bold, modern font" src="https://raw.githubusercontent.com/lima-vm/lima/master/website/static/images/logo.svg?sanitize=true" width="400" /&gt; 
&lt;/picture&gt; 
&lt;h1&gt;Lima: Linux Machines&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://deepwiki.com/lima-vm/lima"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/6505"&gt;&lt;img src="https://www.bestpractices.dev/projects/6505/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/lima-vm/lima"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/lima-vm/lima/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lima-vm.io/"&gt;Lima&lt;/a&gt; launches Linux virtual machines with automatic file sharing and port forwarding (similar to WSL2).&lt;/p&gt; 
&lt;p&gt;The original goal of Lima was to promote &lt;a href="https://containerd.io"&gt;containerd&lt;/a&gt; including &lt;a href="https://github.com/containerd/nerdctl"&gt;nerdctl (contaiNERD ctl)&lt;/a&gt; to Mac users, but Lima can be used for non-container applications as well.&lt;/p&gt; 
&lt;p&gt;Lima also supports other container engines (Docker, Podman, Kubernetes, etc.) and non-macOS hosts (Linux, NetBSD, etc.).&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Set up (Homebrew):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install lima
limactl start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run Linux commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;lima uname -a
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run containers with containerd:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;lima nerdctl run --rm hello-world
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run containers with Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;limactl start template://docker
export DOCKER_HOST=$(limactl list docker --format 'unix://{{.Dir}}/sock/docker.sock')
docker run --rm hello-world
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run containers with Kubernetes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;limactl start template://k8s
export KUBECONFIG=$(limactl list k8s --format 'unix://{{.Dir}}/copied-from-guest/kubeconfig.yaml')
kubectl apply -f ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://lima-vm.io/docs/"&gt;https://lima-vm.io/docs/&lt;/a&gt; for the further information.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://lima-vm.io/docs/community/contributing/"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Developer Certificate of Origin (DCO)&lt;/strong&gt;: All commits must be signed off with &lt;code&gt;git commit -s&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Code licensing and pull request guidelines&lt;/li&gt; 
 &lt;li&gt;Testing requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;h3&gt;Adopters&lt;/h3&gt; 
&lt;p&gt;Container environments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rancherdesktop.io/"&gt;Rancher Desktop&lt;/a&gt;: Kubernetes and container management to the desktop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abiosoft/colima"&gt;Colima&lt;/a&gt;: Docker (and Kubernetes) on macOS with minimal setup&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/runfinch/finch"&gt;Finch&lt;/a&gt;: Finch is a command line client for local container development&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://podman-desktop.io/"&gt;Podman Desktop&lt;/a&gt;: Podman Desktop GUI has a plug-in for Lima virtual machines&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;GUI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unixorn/lima-xbar-plugin"&gt;Lima xbar plugin&lt;/a&gt;: &lt;a href="https://xbarapp.com/"&gt;xbar&lt;/a&gt; plugin to start/stop VMs from the menu bar and see their running status.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/afbjorklund/lima-gui"&gt;lima-gui&lt;/a&gt;: Qt GUI for Lima&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Communication channels&lt;/h3&gt; 
&lt;!-- Duplicated from https://lima-vm.io/docs/community/ --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lima-vm/lima/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;#lima&lt;/code&gt; channel in the CNCF Slack 
  &lt;ul&gt; 
   &lt;li&gt;New account: &lt;a href="https://slack.cncf.io/"&gt;https://slack.cncf.io/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Login: &lt;a href="https://cloud-native.slack.com/"&gt;https://cloud-native.slack.com/&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Zoom meetings (tentatively monthly) 
  &lt;ul&gt; 
   &lt;li&gt;Meeting notes &amp;amp; agenda proposals: &lt;a href="https://github.com/lima-vm/lima/discussions/categories/meetings"&gt;https://github.com/lima-vm/lima/discussions/categories/meetings&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Calendar: &lt;a href="https://zoom-lfx.platform.linuxfoundation.org/meetings/lima"&gt;https://zoom-lfx.platform.linuxfoundation.org/meetings/lima&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;Lima follows the &lt;a href="https://github.com/cncf/foundation/raw/main/code-of-conduct.md"&gt;CNCF Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;We are a &lt;a href="https://cncf.io/"&gt;Cloud Native Computing Foundation&lt;/a&gt; incubating project.&lt;/strong&gt;&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://www.cncf.io/wp-content/uploads/2022/07/cncf-white-logo.svg" /&gt; 
 &lt;img src="https://www.cncf.io/wp-content/uploads/2022/07/cncf-color-bg.svg?sanitize=true" width="300" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;The Linux Foundation¬Æ (TLF) has registered trademarks and uses trademarks. For a list of TLF trademarks, see &lt;a href="https://www.linuxfoundation.org/legal/trademark-usage"&gt;Trademark Usage&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>opentofu/opentofu</title>
      <link>https://github.com/opentofu/opentofu</link>
      <description>&lt;p&gt;OpenTofu lets you declaratively manage your cloud infrastructure.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenTofu&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://opentofu.org/"&gt;HomePage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opentofu.org/docs/intro/install"&gt;How to install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opentofu.org/slack"&gt;Join our Slack community!&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-dark.svg#gh-dark-mode-only" alt="" /&gt; &lt;img src="https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-light.svg#gh-light-mode-only" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bestpractices.dev/projects/10508"&gt;&lt;img src="https://www.bestpractices.dev/projects/10508/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OpenTofu is an OSS tool for building, changing, and versioning infrastructure safely and efficiently. OpenTofu can manage existing and popular service providers as well as custom in-house solutions.&lt;/p&gt; 
&lt;p&gt;The key features of OpenTofu are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Infrastructure as Code&lt;/strong&gt;: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Execution Plans&lt;/strong&gt;: OpenTofu has a "planning" step where it generates an execution plan. The execution plan shows what OpenTofu will do when you call apply. This lets you avoid any surprises when OpenTofu manipulates infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Resource Graph&lt;/strong&gt;: OpenTofu builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, OpenTofu builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Change Automation&lt;/strong&gt;: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what OpenTofu will change and in what order, avoiding many possible human errors.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting help and contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have a question? 
  &lt;ul&gt; 
   &lt;li&gt;Post it in &lt;a href="https://github.com/orgs/opentofu/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Open a &lt;a href="https://github.com/opentofu/opentofu/issues/new/choose"&gt;GitHub issue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Join the &lt;a href="https://opentofu.org/slack/"&gt;OpenTofu Slack&lt;/a&gt;!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Want to contribute? 
  &lt;ul&gt; 
   &lt;li&gt;Please read the &lt;a href="https://raw.githubusercontent.com/opentofu/opentofu/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Recurring Events 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://meet.google.com/xfm-cgms-has"&gt;Community Meetings&lt;/a&gt; on Wednesdays at 12:30 UTC at this link: &lt;a href="https://meet.google.com/xfm-cgms-has"&gt;https://meet.google.com/xfm-cgms-has&lt;/a&gt; (&lt;a href="https://calendar.google.com/calendar/event?eid=NDg0aWl2Y3U1aHFva3N0bGhyMHBhNzdpZmsgY18zZjJkZDNjMWZlMGVmNGU5M2VmM2ZjNDU2Y2EyZGQyMTlhMmU4ZmQ4NWY2YjQwNzUwYWYxNmMzZGYzNzBiZjkzQGc"&gt;üìÖ calendar link&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://meet.google.com/cry-houa-qbk"&gt;Technical Steering Committee Meetings&lt;/a&gt; every other Tuesday at 4pm UTC at this link: &lt;a href="https://meet.google.com/cry-houa-qbk"&gt;https://meet.google.com/cry-houa-qbk&lt;/a&gt; (&lt;a href="https://calendar.google.com/calendar/u/0/event?eid=M3JyMWtuYWptdXI0Zms4ZnJpNmppcDczb3RfMjAyNTA1MjdUMTYwMDAwWiBjXzNmMmRkM2MxZmUwZWY0ZTkzZWYzZmM0NTZjYTJkZDIxOWEyZThmZDg1ZjZiNDA3NTBhZjE2YzNkZjM3MGJmOTNAZw"&gt;üìÖ calendar link&lt;/a&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] For more OpenTofu events, subscribe to the &lt;a href="https://calendar.google.com/calendar/embed?src=c_3f2dd3c1fe0ef4e93ef3fc456ca2dd219a2e8fd85f6b40750af16c3df370bf93%40group.calendar.google.com"&gt;OpenTofu Events Calendar&lt;/a&gt;!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Reporting security vulnerabilities&lt;/h2&gt; 
&lt;p&gt;If you've found a vulnerability or a potential vulnerability in OpenTofu please follow &lt;a href="https://github.com/opentofu/opentofu/security/policy"&gt;Security Policy&lt;/a&gt;. We'll send a confirmation email to acknowledge your report, and we'll send an additional email when we've identified the issue positively or negatively.&lt;/p&gt; 
&lt;h2&gt;Reporting possible copyright issues&lt;/h2&gt; 
&lt;p&gt;If you believe you have found any possible copyright or intellectual property issues, please contact &lt;a href="mailto:liaison@opentofu.org"&gt;liaison@opentofu.org&lt;/a&gt;. We'll send a confirmation email to acknowledge your report.&lt;/p&gt; 
&lt;h2&gt;Registry Access&lt;/h2&gt; 
&lt;p&gt;In an effort to comply with applicable sanctions, we block access from specific countries of origin.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/opentofu/opentofu/raw/main/LICENSE"&gt;Mozilla Public License v2.0&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>distribution/distribution</title>
      <link>https://github.com/distribution/distribution</link>
      <description>&lt;p&gt;The toolkit to pack, ship, store, and deliver container content&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img style="align: center; padding-left: 10px; padding-right: 10px; padding-bottom: 10px;" width="238px" height="238px" src="https://raw.githubusercontent.com/distribution/distribution/main/distribution-logo.svg?sanitize=true" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/distribution/distribution/actions/workflows/build.yml?query=workflow%3Abuild"&gt;&lt;img src="https://github.com/distribution/distribution/workflows/build/badge.svg?branch=main&amp;amp;event=push" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/distribution/distribution"&gt;&lt;img src="https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/distribution/distribution/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache--2.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/distribution/distribution"&gt;&lt;img src="https://codecov.io/gh/distribution/distribution/branch/main/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fdistribution%2Fdistribution?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fdistribution%2Fdistribution.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/distribution/distribution/actions?query=workflow%3Aconformance"&gt;&lt;img src="https://github.com/distribution/distribution/workflows/conformance/badge.svg?sanitize=true" alt="OCI Conformance" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/distribution/distribution"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/distribution/distribution/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The toolset to pack, ship, store, and deliver content.&lt;/p&gt; 
&lt;p&gt;This repository's main product is the Open Source Registry implementation for storing and distributing container images and other content using the &lt;a href="https://github.com/opencontainers/distribution-spec"&gt;OCI Distribution Specification&lt;/a&gt;. The goal of this project is to provide a simple, secure, and scalable base for building a large scale registry solution or running a simple private registry. It is a core library for many registry operators including Docker Hub, GitHub Container Registry, GitLab Container Registry and DigitalOcean Container Registry, as well as the CNCF Harbor Project, and VMware Harbor Registry.&lt;/p&gt; 
&lt;p&gt;This repository contains the following components:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Component&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;registry&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;An implementation of the &lt;a href="https://github.com/opencontainers/distribution-spec"&gt;OCI Distribution Specification&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;libraries&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;A rich set of libraries for interacting with distribution components. Please see &lt;a href="https://pkg.go.dev/github.com/distribution/distribution"&gt;godoc&lt;/a&gt; for details. &lt;strong&gt;Note&lt;/strong&gt;: The interfaces for these libraries are &lt;strong&gt;unstable&lt;/strong&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;documentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Full documentation is available at &lt;a href="https://distribution.github.io/distribution/"&gt;https://distribution.github.io/distribution&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;How does this integrate with Docker, containerd, and other OCI client?&lt;/h3&gt; 
&lt;p&gt;Clients implement against the OCI specification and communicate with the registry using HTTP. This project contains a client implementation which is currently in use by Docker, however, it is deprecated for the &lt;a href="https://github.com/containerd/containerd/tree/master/remotes/docker"&gt;implementation in containerd&lt;/a&gt; and will not support new features.&lt;/p&gt; 
&lt;h3&gt;What are the long term goals of the Distribution project?&lt;/h3&gt; 
&lt;p&gt;The &lt;em&gt;Distribution&lt;/em&gt; project has the further long term goal of providing a secure tool chain for distributing content. The specifications, APIs and tools should be as useful with Docker as they are without.&lt;/p&gt; 
&lt;p&gt;Our goal is to design a professional grade and extensible content distribution system that allow users to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enjoy an efficient, secured and reliable way to store, manage, package and exchange content&lt;/li&gt; 
 &lt;li&gt;Hack/roll their own on top of healthy open-source components&lt;/li&gt; 
 &lt;li&gt;Implement their own home made solution through good specs, and solid extensions mechanism.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/distribution/distribution/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for details on how to contribute issues, fixes, and patches to this project. If you are contributing code, see the instructions for &lt;a href="https://raw.githubusercontent.com/distribution/distribution/main/BUILDING.md"&gt;building a development environment&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p&gt;For async communication and long running discussions please use issues and pull requests on the github repo. This will be the best place to discuss design and implementation.&lt;/p&gt; 
&lt;p&gt;For sync communication we have a #distribution channel in the &lt;a href="https://slack.cncf.io/"&gt;CNCF Slack&lt;/a&gt; that everyone is welcome to join and chat about development.&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;The distribution codebase is released under the &lt;a href="https://raw.githubusercontent.com/distribution/distribution/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;. The README.md file, and files in the "docs" folder are licensed under the Creative Commons Attribution 4.0 International License. You may obtain a copy of the license, titled CC-BY-4.0, at &lt;a href="http://creativecommons.org/licenses/by/4.0/"&gt;http://creativecommons.org/licenses/by/4.0/&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>temporalio/temporal</title>
      <link>https://github.com/temporalio/temporal</link>
      <description>&lt;p&gt;Temporal service&lt;/p&gt;&lt;hr&gt;&lt;div class="title-block" style="text-align: center;" align="center"&gt; 
 &lt;h1&gt;Temporal‚Äîdurable execution platform&lt;/h1&gt; 
 &lt;p&gt;&lt;img title="temporal logo" src="https://avatars.githubusercontent.com/u/56493103?s=320" width="320" height="320" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/temporalio/temporal/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/temporalio/temporal" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/temporalio/temporal/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/temporalio/temporal" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://app.codecov.io/gh/temporalio/temporal"&gt;&lt;img src="https://img.shields.io/badge/codecov-report-blue" alt="Code Coverage" /&gt;&lt;/a&gt; &lt;a href="https://community.temporal.io"&gt;&lt;img src="https://img.shields.io/static/v1?label=community&amp;amp;message=get%20help&amp;amp;color=informational" alt="Community" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/temporalio/temporal"&gt;&lt;img src="https://goreportcard.com/badge/github.com/temporalio/temporal" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/#introduction"&gt;Introduction&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/#getting-started"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/#contributing"&gt;Contributing&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://docs.temporal.io/"&gt;Temporal Docs&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://learn.temporal.io/courses/temporal_101/"&gt;Temporal 101&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Temporal is a durable execution platform that enables developers to build scalable applications without sacrificing productivity or reliability. The Temporal server executes units of application logic called Workflows in a resilient manner that automatically handles intermittent failures, and retries failed operations.&lt;/p&gt; 
&lt;p&gt;Temporal is a mature technology that originated as a fork of Uber's Cadence. It is developed by &lt;a href="https://temporal.io/"&gt;Temporal Technologies&lt;/a&gt;, a startup by the creators of Cadence.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/wIpz4ioK0gI" title="Getting to know Temporal"&gt;&lt;img src="https://github.com/temporalio/temporal/assets/251288/693d18b5-01de-4a3b-b47b-96347b84f610" alt="image" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Download and Start Temporal Server Locally&lt;/h3&gt; 
&lt;p&gt;Execute the following commands to start a pre-built image along with all the dependencies.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install temporal
temporal server start-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to &lt;a href="https://docs.temporal.io/cli/#installation"&gt;Temporal CLI&lt;/a&gt; documentation for more installation options.&lt;/p&gt; 
&lt;h3&gt;Run the Samples&lt;/h3&gt; 
&lt;p&gt;Clone or download samples for &lt;a href="https://github.com/temporalio/samples-go"&gt;Go&lt;/a&gt; or &lt;a href="https://github.com/temporalio/samples-java"&gt;Java&lt;/a&gt; and run them with the local Temporal server. We have a number of &lt;a href="https://github.com/temporalio/samples-java#helloworld"&gt;HelloWorld type scenarios&lt;/a&gt; available, as well as more advanced ones. Note that the sets of samples are currently different between Go and Java.&lt;/p&gt; 
&lt;h3&gt;Use CLI&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://docs.temporal.io/cli/"&gt;Temporal CLI&lt;/a&gt; to interact with the running Temporal server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;temporal operator namespace list
temporal workflow list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use Temporal Web UI&lt;/h3&gt; 
&lt;p&gt;Try &lt;a href="https://docs.temporal.io/web-ui"&gt;Temporal Web UI&lt;/a&gt; by opening &lt;a href="http://localhost:8233"&gt;http://localhost:8233&lt;/a&gt; for viewing your sample workflows executing on Temporal.&lt;/p&gt; 
&lt;h2&gt;Repository&lt;/h2&gt; 
&lt;p&gt;This repository contains the source code of the Temporal server. To implement Workflows, Activities and Workers, use one of the &lt;a href="https://docs.temporal.io/dev-guide/"&gt;supported languages&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We'd love your help in making Temporal great.&lt;/p&gt; 
&lt;p&gt;Helpful links to get started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/temporalio/proposals"&gt;work on or propose a new feature&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/docs/architecture/README.md"&gt;learn about the Temporal Server architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/CONTRIBUTING.md"&gt;learn how to build and run the Temporal Server locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/docs/development/testing.md"&gt;learn about Temporal Server testing tools and best practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;join the Temporal community &lt;a href="https://community.temporal.io"&gt;forum&lt;/a&gt; and &lt;a href="https://t.mp/slack"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/temporalio/temporal/raw/main/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>containerd/containerd</title>
      <link>https://github.com/containerd/containerd</link>
      <description>&lt;p&gt;An open and reliable container runtime&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cncf/artwork/master/projects/containerd/horizontal/color/containerd-horizontal-color.png#gh-light-mode-only" alt="containerd banner light mode" /&gt; &lt;img src="https://raw.githubusercontent.com/cncf/artwork/master/projects/containerd/horizontal/white/containerd-horizontal-white.png#gh-dark-mode-only" alt="containerd banner dark mode" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/containerd/containerd/v2"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/containerd/containerd/v2" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;a href="https://github.com/containerd/containerd/actions?query=workflow%3ACI+event%3Amerge_group"&gt;&lt;img src="https://github.com/containerd/containerd/actions/workflows/ci.yml/badge.svg?event=merge_group" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/containerd/containerd/actions?query=workflow%3ANightly"&gt;&lt;img src="https://github.com/containerd/containerd/workflows/Nightly/badge.svg?sanitize=true" alt="Nightlies" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/containerd/containerd/v2"&gt;&lt;img src="https://goreportcard.com/badge/github.com/containerd/containerd/v2" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1271"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/1271/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/containerd/containerd"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/containerd/containerd/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://github.com/containerd/containerd/actions/workflows/links.yml"&gt;&lt;img src="https://github.com/containerd/containerd/actions/workflows/links.yml/badge.svg?sanitize=true" alt="Check Links" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;containerd is an industry-standard container runtime with an emphasis on simplicity, robustness, and portability. It is available as a daemon for Linux and Windows, which can manage the complete container lifecycle of its host system: image transfer and storage, container execution and supervision, low-level storage and network attachments, etc.&lt;/p&gt; 
&lt;p&gt;containerd is a member of CNCF with &lt;a href="https://landscape.cncf.io/?selected=containerd"&gt;'graduated'&lt;/a&gt; status.&lt;/p&gt; 
&lt;p&gt;containerd is designed to be embedded into a larger system, rather than being used directly by developers or end-users.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/containerd/containerd/main/docs/historical/design/architecture.png" alt="architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Announcements&lt;/h2&gt; 
&lt;h3&gt;containerd v2.0 is now released!&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/containerd-2.0.md"&gt;&lt;code&gt;docs/containerd-2.0.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Now Recruiting&lt;/h3&gt; 
&lt;p&gt;We are a large inclusive OSS project that is welcoming help of any kind shape or form:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Documentation help is needed to make the product easier to consume and extend.&lt;/li&gt; 
 &lt;li&gt;We need OSS community outreach/organizing help to get the word out; manage and create messaging and educational content; and help with social media, community forums/groups, and google groups.&lt;/li&gt; 
 &lt;li&gt;We are actively inviting new &lt;a href="https://github.com/containerd/project/raw/main/GOVERNANCE.md#security-advisors"&gt;security advisors&lt;/a&gt; to join the team.&lt;/li&gt; 
 &lt;li&gt;New subprojects are being created, core and non-core that could use additional development help.&lt;/li&gt; 
 &lt;li&gt;Each of the &lt;a href="https://github.com/containerd"&gt;containerd projects&lt;/a&gt; has a list of issues currently being worked on or that need help resolving. 
  &lt;ul&gt; 
   &lt;li&gt;If the issue has not already been assigned to someone or has not made recent progress, and you are interested, please inquire.&lt;/li&gt; 
   &lt;li&gt;If you are interested in starting with a smaller/beginner-level issue, look for issues with an &lt;code&gt;exp/beginner&lt;/code&gt; tag, for example &lt;a href="https://github.com/containerd/containerd/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%2Fbeginner"&gt;containerd/containerd beginner issues.&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;See our documentation on &lt;a href="https://containerd.io"&gt;containerd.io&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/ops.md"&gt;for ops and admins&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/namespaces.md"&gt;namespaces&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/client-opts.md"&gt;client options&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To get started contributing to containerd, see &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested in trying out containerd see our example at &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/getting-started.md"&gt;Getting Started&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Nightly builds&lt;/h2&gt; 
&lt;p&gt;There are nightly builds available for download &lt;a href="https://github.com/containerd/containerd/actions?query=workflow%3ANightly"&gt;here&lt;/a&gt;. Binaries are generated from &lt;code&gt;main&lt;/code&gt; branch every night for &lt;code&gt;Linux&lt;/code&gt; and &lt;code&gt;Windows&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please be aware: nightly builds might have critical bugs, it's not recommended for use in production and no support provided.&lt;/p&gt; 
&lt;h2&gt;Kubernetes (k8s) CI Dashboard Group&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://testgrid.k8s.io/containerd"&gt;k8s CI dashboard group for containerd&lt;/a&gt; contains test results regarding the health of kubernetes when run against main and a number of containerd release branches.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://testgrid.k8s.io/containerd-periodic"&gt;containerd-periodics&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Runtime Requirements&lt;/h2&gt; 
&lt;p&gt;Runtime requirements for containerd are very minimal. Most interactions with the Linux and Windows container feature sets are handled via &lt;a href="https://github.com/opencontainers/runc"&gt;runc&lt;/a&gt; and/or OS-specific libraries (e.g. &lt;a href="https://github.com/Microsoft/hcsshim"&gt;hcsshim&lt;/a&gt; for Microsoft). The current required version of &lt;code&gt;runc&lt;/code&gt; is described in &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/RUNC.md"&gt;RUNC.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;There are specific features used by containerd core code and snapshotters that will require a minimum kernel version on Linux. With the understood caveat of distro kernel versioning, a reasonable starting point for Linux is a minimum 4.x kernel version.&lt;/p&gt; 
&lt;p&gt;The overlay filesystem snapshotter, used by default, uses features that were finalized in the 4.x kernel series. If you choose to use btrfs, there may be more flexibility in kernel version (minimum recommended is 3.18), but will require the btrfs kernel module and btrfs tools to be installed on your Linux distribution.&lt;/p&gt; 
&lt;p&gt;To use Linux checkpoint and restore features, you will need &lt;code&gt;criu&lt;/code&gt; installed on your system. See more details in &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/#checkpoint-and-restore"&gt;Checkpoint and Restore&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Build requirements for developers are listed in &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/BUILDING.md"&gt;BUILDING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Supported Registries&lt;/h2&gt; 
&lt;p&gt;Any registry which is compliant with the &lt;a href="https://github.com/opencontainers/distribution-spec"&gt;OCI Distribution Specification&lt;/a&gt; is supported by containerd.&lt;/p&gt; 
&lt;p&gt;For configuring registries, see &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/hosts.md"&gt;registry host configuration documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;For a detailed overview of containerd's core concepts and the features it supports, please refer to the &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/features.md"&gt;FEATURES.MD&lt;/a&gt; document.&lt;/p&gt; 
&lt;h3&gt;Releases and API Stability&lt;/h3&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/RELEASES.md"&gt;RELEASES.md&lt;/a&gt; for details on versioning and stability of containerd components.&lt;/p&gt; 
&lt;p&gt;Downloadable 64-bit Intel/AMD binaries of all official releases are available on our &lt;a href="https://github.com/containerd/containerd/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For other architectures and distribution support, you will find that many Linux distributions package their own containerd and provide it across several architectures, such as &lt;a href="https://launchpad.net/ubuntu/bionic/+package/containerd"&gt;Canonical's Ubuntu packaging&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Enabling command auto-completion&lt;/h4&gt; 
&lt;p&gt;Starting with containerd 1.4, the urfave client feature for auto-creation of bash and zsh autocompletion data is enabled. To use the autocomplete feature in a bash shell for example, source the autocomplete/ctr file in your &lt;code&gt;.bashrc&lt;/code&gt;, or manually like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ source ./contrib/autocomplete/ctr
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Distribution of &lt;code&gt;ctr&lt;/code&gt; autocomplete for bash and zsh&lt;/h4&gt; 
&lt;p&gt;For bash, copy the &lt;code&gt;contrib/autocomplete/ctr&lt;/code&gt; script into &lt;code&gt;/etc/bash_completion.d/&lt;/code&gt; and rename it to &lt;code&gt;ctr&lt;/code&gt;. The &lt;code&gt;zsh_autocomplete&lt;/code&gt; file is also available and can be used similarly for zsh users.&lt;/p&gt; 
&lt;p&gt;Provide documentation to users to &lt;code&gt;source&lt;/code&gt; this file into their shell if you don't place the autocomplete file in a location where it is automatically loaded for the user's shell environment.&lt;/p&gt; 
&lt;h3&gt;CRI&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;cri&lt;/code&gt; is a &lt;a href="https://containerd.io/"&gt;containerd&lt;/a&gt; plugin implementation of the Kubernetes &lt;a href="https://github.com/kubernetes/cri-api/raw/master/pkg/apis/runtime/v1/api.proto"&gt;container runtime interface (CRI)&lt;/a&gt;. With it, you are able to use containerd as the container runtime for a Kubernetes cluster.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/containerd/containerd/main/docs/cri/cri.png" alt="cri" /&gt;&lt;/p&gt; 
&lt;h4&gt;CRI Status&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;cri&lt;/code&gt; is a native plugin of containerd. Since containerd 1.1, the cri plugin is built into the release binaries and enabled by default.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;cri&lt;/code&gt; plugin has reached GA status, representing that it is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Feature complete&lt;/li&gt; 
 &lt;li&gt;Works with Kubernetes 1.10 and above&lt;/li&gt; 
 &lt;li&gt;Passes all &lt;a href="https://github.com/kubernetes/community/raw/master/contributors/devel/sig-node/cri-validation.md"&gt;CRI validation tests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Passes all &lt;a href="https://github.com/kubernetes/community/raw/master/contributors/devel/sig-node/e2e-node-tests.md"&gt;node e2e tests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Passes all &lt;a href="https://github.com/kubernetes/community/raw/master/contributors/devel/sig-testing/e2e-tests.md"&gt;e2e tests&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See results on the containerd k8s &lt;a href="https://testgrid.k8s.io/containerd"&gt;test dashboard&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Validating Your &lt;code&gt;cri&lt;/code&gt; Setup&lt;/h4&gt; 
&lt;p&gt;A Kubernetes incubator project, &lt;a href="https://github.com/kubernetes-sigs/cri-tools"&gt;cri-tools&lt;/a&gt;, includes programs for exercising CRI implementations. More importantly, cri-tools includes the program &lt;code&gt;critest&lt;/code&gt; which is used for running &lt;a href="https://github.com/kubernetes/community/raw/master/contributors/devel/sig-node/cri-validation.md"&gt;CRI Validation Testing&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;CRI Guides&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/contrib/ansible/README.md"&gt;Installing with Ansible and Kubeadm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/getting-started.md"&gt;For Non-Ansible Users, Preforming a Custom Installation Using the Release Tarball and Kubeadm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/cri/testing.md"&gt;CRI Plugin Testing Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/cri/crictl.md"&gt;Debugging Pods, Containers, and Images with &lt;code&gt;crictl&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/docs/cri/config.md"&gt;Configuring &lt;code&gt;cri&lt;/code&gt; Plugins&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/containerd/containerd/raw/main/docs/man/containerd-config.8.md"&gt;Configuring containerd&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Communication&lt;/h3&gt; 
&lt;p&gt;For async communication and long-running discussions please use issues and pull requests on the GitHub repo. This will be the best place to discuss design and implementation.&lt;/p&gt; 
&lt;p&gt;For sync communication catch us in the &lt;code&gt;#containerd&lt;/code&gt; and &lt;code&gt;#containerd-dev&lt;/code&gt; Slack channels on Cloud Native Computing Foundation's (CNCF) Slack - &lt;code&gt;cloud-native.slack.com&lt;/code&gt;. Everyone is welcome to join and chat. &lt;a href="https://slack.cncf.io"&gt;Get Invite to CNCF Slack.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Join our next community meeting hosted on Zoom. The schedule is posted on the &lt;a href="https://www.cncf.io/calendar/"&gt;CNCF Calendar&lt;/a&gt; (search 'containerd' to filter).&lt;/p&gt; 
&lt;h3&gt;Security audit&lt;/h3&gt; 
&lt;p&gt;Security audits for the containerd project are hosted on our website. Please see the &lt;a href="https://containerd.io/security/"&gt;security page at containerd.io&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Reporting security issues&lt;/h3&gt; 
&lt;p&gt;Please follow the instructions at &lt;a href="https://github.com/containerd/project/raw/main/SECURITY.md#reporting-a-vulnerability"&gt;containerd/project&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;The containerd codebase is released under the &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;. The README.md file and files in the "docs" folder are licensed under the Creative Commons Attribution 4.0 International License. You may obtain a copy of the license, titled CC-BY-4.0, at &lt;a href="http://creativecommons.org/licenses/by/4.0/"&gt;http://creativecommons.org/licenses/by/4.0/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Project details&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;containerd&lt;/strong&gt; is the primary open source project within the broader containerd GitHub organization. However, all projects within the repo have common maintainership, governance, and contributing guidelines which are stored in a &lt;code&gt;project&lt;/code&gt; repository commonly for all containerd projects.&lt;/p&gt; 
&lt;p&gt;Please find all these core project documents, including the:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/containerd/project/raw/main/GOVERNANCE.md"&gt;Project governance&lt;/a&gt;,&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/containerd/project/raw/main/MAINTAINERS"&gt;Maintainers&lt;/a&gt;,&lt;/li&gt; 
 &lt;li&gt;and &lt;a href="https://github.com/containerd/project/raw/main/CONTRIBUTING.md"&gt;Contributing guidelines&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;information in our &lt;a href="https://github.com/containerd/project"&gt;&lt;code&gt;containerd/project&lt;/code&gt;&lt;/a&gt; repository.&lt;/p&gt; 
&lt;h2&gt;Adoption&lt;/h2&gt; 
&lt;p&gt;Interested to see who is using containerd? Are you using containerd in a project? Please add yourself via pull request to our &lt;a href="https://raw.githubusercontent.com/containerd/containerd/main/ADOPTERS.md"&gt;ADOPTERS.md&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ava-labs/avalanchego</title>
      <link>https://github.com/ava-labs/avalanchego</link>
      <description>&lt;p&gt;Go implementation of an Avalanche node.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/ava-labs/avalanchego/master/resources/AvalancheLogoRed.png?raw=true" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;Node implementation for the &lt;a href="https://avax.network"&gt;Avalanche&lt;/a&gt; network - a blockchains platform with high throughput, and blazing fast transactions.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Avalanche is an incredibly lightweight protocol, so the minimum computer requirements are quite modest. Note that as network usage increases, hardware requirements may change.&lt;/p&gt; 
&lt;p&gt;The minimum recommended hardware specification for nodes connected to Mainnet is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU: Equivalent of 8 AWS vCPU&lt;/li&gt; 
 &lt;li&gt;RAM: 16 GiB&lt;/li&gt; 
 &lt;li&gt;Storage: 1 TiB 
  &lt;ul&gt; 
   &lt;li&gt;Nodes running for very long periods of time or nodes with custom configurations may observe higher storage requirements.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;OS: Ubuntu 22.04/24.04 or macOS &amp;gt;= 12&lt;/li&gt; 
 &lt;li&gt;Network: Reliable IPv4 or IPv6 network connection, with an open public port.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you plan to build AvalancheGo from source, you will also need the following software:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/doc/install"&gt;Go&lt;/a&gt; version &amp;gt;= 1.24.9&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gcc.gnu.org/"&gt;gcc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;g++&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Building From Source&lt;/h3&gt; 
&lt;h4&gt;Clone The Repository&lt;/h4&gt; 
&lt;p&gt;Clone the AvalancheGo repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone git@github.com:ava-labs/avalanchego.git
cd avalanchego
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will clone and checkout the &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; 
&lt;h4&gt;Building AvalancheGo&lt;/h4&gt; 
&lt;p&gt;Build AvalancheGo by running the build task:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./scripts/run_task.sh build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;avalanchego&lt;/code&gt; binary is now in the &lt;code&gt;build&lt;/code&gt; directory. To run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./build/avalanchego
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Binary Repository&lt;/h3&gt; 
&lt;p&gt;Install AvalancheGo using an &lt;code&gt;apt&lt;/code&gt; repository.&lt;/p&gt; 
&lt;h4&gt;Adding the APT Repository&lt;/h4&gt; 
&lt;p&gt;If you already have the APT repository added, you do not need to add it again.&lt;/p&gt; 
&lt;p&gt;To add the repository on Ubuntu, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo su -
wget -qO - https://downloads.avax.network/avalanchego.gpg.key | tee /etc/apt/trusted.gpg.d/avalanchego.asc
source /etc/os-release &amp;amp;&amp;amp; echo "deb https://downloads.avax.network/apt $UBUNTU_CODENAME main" &amp;gt; /etc/apt/sources.list.d/avalanche.list
exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installing the Latest Version&lt;/h4&gt; 
&lt;p&gt;After adding the APT repository, install &lt;code&gt;avalanchego&lt;/code&gt; by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt update
sudo apt install avalanchego
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Binary Install&lt;/h3&gt; 
&lt;p&gt;Download the &lt;a href="https://github.com/ava-labs/avalanchego/releases/latest"&gt;latest build&lt;/a&gt; for your operating system and architecture.&lt;/p&gt; 
&lt;p&gt;The Avalanche binary to be executed is named &lt;code&gt;avalanchego&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker Install&lt;/h3&gt; 
&lt;p&gt;Make sure Docker is installed on the machine - so commands like &lt;code&gt;docker run&lt;/code&gt; etc. are available.&lt;/p&gt; 
&lt;p&gt;Building the Docker image of latest &lt;code&gt;avalanchego&lt;/code&gt; branch can be done by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./scripts/run-task.sh build-image
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To check the built image, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker image ls
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The image should be tagged as &lt;code&gt;avaplatform/avalanchego:xxxxxxxx&lt;/code&gt;, where &lt;code&gt;xxxxxxxx&lt;/code&gt; is the shortened commit of the Avalanche source it was built from. To run the Avalanche node, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -ti -p 9650:9650 -p 9651:9651 avaplatform/avalanchego:xxxxxxxx /avalanchego/build/avalanchego
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running Avalanche&lt;/h2&gt; 
&lt;h3&gt;Connecting to Mainnet&lt;/h3&gt; 
&lt;p&gt;To connect to the Avalanche Mainnet, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./build/avalanchego
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see some pretty ASCII art and log messages.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;Ctrl+C&lt;/code&gt; to kill the node.&lt;/p&gt; 
&lt;h3&gt;Connecting to Fuji&lt;/h3&gt; 
&lt;p&gt;To connect to the Fuji Testnet, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./build/avalanchego --network-id=fuji
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Creating a Local Testnet&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://github.com/ava-labs/avalanche-cli"&gt;avalanche-cli&lt;/a&gt; is the easiest way to start a local network.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;avalanche network start
avalanche network status
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Bootstrapping&lt;/h2&gt; 
&lt;p&gt;A node needs to catch up to the latest network state before it can participate in consensus and serve API calls. This process (called bootstrapping) currently takes several days for a new node connected to Mainnet.&lt;/p&gt; 
&lt;p&gt;A node will not &lt;a href="https://build.avax.network/docs/api-reference/health-api"&gt;report healthy&lt;/a&gt; until it is done bootstrapping.&lt;/p&gt; 
&lt;p&gt;Improvements that reduce the amount of time it takes to bootstrap are under development.&lt;/p&gt; 
&lt;p&gt;The bottleneck during bootstrapping is typically database IO. Using a more powerful CPU or increasing the database IOPS on the computer running a node will decrease the amount of time bootstrapping takes.&lt;/p&gt; 
&lt;h2&gt;Generating Code&lt;/h2&gt; 
&lt;p&gt;AvalancheGo uses multiple tools to generate efficient and boilerplate code.&lt;/p&gt; 
&lt;h3&gt;Running protobuf codegen&lt;/h3&gt; 
&lt;p&gt;To regenerate the protobuf go code, run &lt;code&gt;scripts/run-task.sh generate-protobuf&lt;/code&gt; from the root of the repo.&lt;/p&gt; 
&lt;p&gt;This should only be necessary when upgrading protobuf versions or modifying .proto definition files.&lt;/p&gt; 
&lt;p&gt;To use this script, you must have &lt;a href="https://docs.buf.build/installation"&gt;buf&lt;/a&gt; (v1.31.0), protoc-gen-go (v1.33.0) and protoc-gen-go-grpc (v1.3.0) installed.&lt;/p&gt; 
&lt;p&gt;To install the buf dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.33.0
go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.3.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you have not already, you may need to add &lt;code&gt;$GOPATH/bin&lt;/code&gt; to your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export PATH="$PATH:$(go env GOPATH)/bin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you extract buf to ~/software/buf/bin, the following should work:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export PATH=$PATH:~/software/buf/bin/:~/go/bin
go get google.golang.org/protobuf/cmd/protoc-gen-go
go get google.golang.org/protobuf/cmd/protoc-gen-go-grpc
scripts/run_task.sh generate-protobuf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information, refer to the &lt;a href="https://grpc.io/docs/languages/go/quickstart/"&gt;GRPC Golang Quick Start Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Running mock codegen&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="CONTRIBUTING.md####Autogenerated-mocks"&gt;the Contributing document autogenerated mocks section&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Versioning&lt;/h2&gt; 
&lt;h3&gt;Version Semantics&lt;/h3&gt; 
&lt;p&gt;AvalancheGo is first and foremost a client for the Avalanche network. The versioning of AvalancheGo follows that of the Avalanche network.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;v0.x.x&lt;/code&gt; indicates a development network version.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;v1.x.x&lt;/code&gt; indicates a production network version.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vx.[Upgrade].x&lt;/code&gt; indicates the number of network upgrades that have occurred.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vx.x.[Patch]&lt;/code&gt; indicates the number of client upgrades that have occurred since the last network upgrade.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Library Compatibility Guarantees&lt;/h3&gt; 
&lt;p&gt;Because AvalancheGo's version denotes the network version, it is expected that interfaces exported by AvalancheGo's packages may change in &lt;code&gt;Patch&lt;/code&gt; version updates.&lt;/p&gt; 
&lt;h3&gt;API Compatibility Guarantees&lt;/h3&gt; 
&lt;p&gt;APIs exposed when running AvalancheGo will maintain backwards compatibility, unless the functionality is explicitly deprecated and announced when removed.&lt;/p&gt; 
&lt;h2&gt;Supported Platforms&lt;/h2&gt; 
&lt;p&gt;AvalancheGo can run on different platforms, with different support tiers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tier 1&lt;/strong&gt;: Fully supported by the maintainers, guaranteed to pass all tests including e2e and stress tests.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tier 2&lt;/strong&gt;: Passes all unit and integration tests but not necessarily e2e tests.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tier 3&lt;/strong&gt;: Builds but lightly tested (or not), considered &lt;em&gt;experimental&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Not supported&lt;/strong&gt;: May not build and not tested, considered &lt;em&gt;unsafe&lt;/em&gt;. To be supported in the future.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following table lists currently supported platforms and their corresponding AvalancheGo support tiers:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Architecture&lt;/th&gt; 
   &lt;th align="center"&gt;Operating system&lt;/th&gt; 
   &lt;th align="center"&gt;Support tier&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;amd64&lt;/td&gt; 
   &lt;td align="center"&gt;Linux&lt;/td&gt; 
   &lt;td align="center"&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;arm64&lt;/td&gt; 
   &lt;td align="center"&gt;Linux&lt;/td&gt; 
   &lt;td align="center"&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;arm64&lt;/td&gt; 
   &lt;td align="center"&gt;Darwin&lt;/td&gt; 
   &lt;td align="center"&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;amd64&lt;/td&gt; 
   &lt;td align="center"&gt;Darwin&lt;/td&gt; 
   &lt;td align="center"&gt;Not supported&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;amd64&lt;/td&gt; 
   &lt;td align="center"&gt;Windows&lt;/td&gt; 
   &lt;td align="center"&gt;Not supported&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;arm&lt;/td&gt; 
   &lt;td align="center"&gt;Linux&lt;/td&gt; 
   &lt;td align="center"&gt;Not supported&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;i386&lt;/td&gt; 
   &lt;td align="center"&gt;Linux&lt;/td&gt; 
   &lt;td align="center"&gt;Not supported&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To officially support a new platform, one must satisfy the following requirements:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;AvalancheGo continuous integration&lt;/th&gt; 
   &lt;th align="center"&gt;Tier 1&lt;/th&gt; 
   &lt;th align="center"&gt;Tier 2&lt;/th&gt; 
   &lt;th align="center"&gt;Tier 3&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Build passes&lt;/td&gt; 
   &lt;td align="center"&gt;‚úì&lt;/td&gt; 
   &lt;td align="center"&gt;‚úì&lt;/td&gt; 
   &lt;td align="center"&gt;‚úì&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Unit and integration tests pass&lt;/td&gt; 
   &lt;td align="center"&gt;‚úì&lt;/td&gt; 
   &lt;td align="center"&gt;‚úì&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;End-to-end and stress tests pass&lt;/td&gt; 
   &lt;td align="center"&gt;‚úì&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Security Bugs&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We and our community welcome responsible disclosures.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://raw.githubusercontent.com/ava-labs/avalanchego/master/SECURITY.md"&gt;Security Policy&lt;/a&gt; and &lt;a href="https://github.com/ava-labs/avalanchego/security/advisories"&gt;Security Advisories&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>containers/skopeo</title>
      <link>https://github.com/containers/skopeo</link>
      <description>&lt;p&gt;Work with remote images registries - retrieving information, images, signing content&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://cdn.rawgit.com/containers/skopeo/main/docs/skopeo.svg?sanitize=true" width="250" alt="Skopeo" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt; &lt;img src="https://img.shields.io/github/v/release/containers/skopeo" alt="GitHub release (latest SemVer)" /&gt; &lt;a href="https://goreportcard.com/report/github.com/containers/skopeo"&gt;&lt;img src="https://goreportcard.com/badge/github.com/containers/skopeo" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/10516"&gt;&lt;img src="https://www.bestpractices.dev/projects/10516/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;skopeo&lt;/code&gt; is a command line utility that performs various operations on container images and image repositories.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;skopeo&lt;/code&gt; does not require the user to be running as root to do most of its operations.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;skopeo&lt;/code&gt; does not require a daemon to be running to perform its operations.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;skopeo&lt;/code&gt; can work with &lt;a href="https://github.com/opencontainers/image-spec"&gt;OCI images&lt;/a&gt; as well as the original Docker v2 images.&lt;/p&gt; 
&lt;p&gt;Skopeo works with API V2 container image registries such as &lt;a href="https://docker.io"&gt;docker.io&lt;/a&gt; and &lt;a href="https://quay.io"&gt;quay.io&lt;/a&gt; registries, private registries, local directories and local OCI-layout directories. Skopeo can perform operations which consist of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Copying an image from and to various storage mechanisms. For example you can copy images from one registry to another, without requiring privilege.&lt;/li&gt; 
 &lt;li&gt;Inspecting a remote image showing its properties including its layers, without requiring you to pull the image to the host.&lt;/li&gt; 
 &lt;li&gt;Deleting an image from an image repository.&lt;/li&gt; 
 &lt;li&gt;Syncing an external image repository to an internal registry for air-gapped deployments.&lt;/li&gt; 
 &lt;li&gt;When required by the repository, skopeo can pass the appropriate credentials and certificates for authentication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Skopeo operates on the following image and repository types:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;containers-storage:docker-reference An image located in a local containers/storage image store. Both the location and image store are specified in /etc/containers/storage.conf. (This is the backend for &lt;a href="https://podman.io"&gt;Podman&lt;/a&gt;, &lt;a href="https://cri-o.io"&gt;CRI-O&lt;/a&gt;, &lt;a href="https://buildah.io"&gt;Buildah&lt;/a&gt; and friends)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dir:path An existing local directory path storing the manifest, layer tarballs and signatures as individual files. This is a non-standardized format, primarily useful for debugging or noninvasive container inspection.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;docker://docker-reference An image in a registry implementing the "Docker Registry HTTP API V2". By default, uses the authorization state in &lt;code&gt;$XDG_RUNTIME_DIR/containers/auth.json&lt;/code&gt;, which is set using &lt;code&gt;skopeo login&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;docker-archive:path[:docker-reference] An image is stored in a &lt;code&gt;docker save&lt;/code&gt;-formatted file. docker-reference is only used when creating such a file, and it must not contain a digest.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;docker-daemon:docker-reference An image docker-reference stored in the docker daemon internal storage. docker-reference must contain either a tag or a digest. Alternatively, when reading images, the format can also be docker-daemon:algo:digest (an image ID).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;oci:path:tag An image tag in a directory compliant with "Open Container Image Layout Specification" at path.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/install.md"&gt;Obtaining skopeo&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;For a detailed description how to install or build skopeo, see &lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/install.md"&gt;install.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Skopeo is also available as a Container Image on &lt;a href="https://quay.io/skopeo/stable"&gt;quay.io&lt;/a&gt;. For more information, see the &lt;a href="https://github.com/containers/image_build/raw/main/skopeo/README.md"&gt;Skopeo Image&lt;/a&gt; page.&lt;/p&gt; 
&lt;h2&gt;Inspecting a repository&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;skopeo&lt;/code&gt; is able to &lt;em&gt;inspect&lt;/em&gt; a repository on a container registry and fetch images layers. The &lt;em&gt;inspect&lt;/em&gt; command fetches the repository's manifest and it is able to show you a &lt;code&gt;docker inspect&lt;/code&gt;-like json output about a whole repository or a tag. This tool, in contrast to &lt;code&gt;docker inspect&lt;/code&gt;, helps you gather useful information about a repository or a tag before pulling it (using disk space). The inspect command can show you which tags are available for the given repository, the labels the image has, the creation date and operating system of the image and more.&lt;/p&gt; 
&lt;p&gt;Examples:&lt;/p&gt; 
&lt;h4&gt;Show properties of fedora:latest&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ skopeo inspect docker://registry.fedoraproject.org/fedora:latest
{
    "Name": "registry.fedoraproject.org/fedora",
    "Digest": "sha256:0f65bee641e821f8118acafb44c2f8fe30c2fc6b9a2b3729c0660376391aa117",
    "RepoTags": [
        "34-aarch64",
        "34",
        "latest",
        ...
    ],
    "Created": "2022-11-24T13:54:18Z",
    "DockerVersion": "1.10.1",
    "Labels": {
        "license": "MIT",
        "name": "fedora",
        "vendor": "Fedora Project",
        "version": "37"
    },
    "Architecture": "amd64",
    "Os": "linux",
    "Layers": [
        "sha256:2a0fc6bf62e155737f0ace6142ee686f3c471c1aab4241dc3128904db46288f0"
    ],
    "LayersData": [
        {
            "MIMEType": "application/vnd.docker.image.rootfs.diff.tar.gzip",
            "Digest": "sha256:2a0fc6bf62e155737f0ace6142ee686f3c471c1aab4241dc3128904db46288f0",
            "Size": 71355009,
            "Annotations": null
        }
    ],
    "Env": [
        "DISTTAG=f37container",
        "FGC=f37",
        "container=oci"
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Show container configuration from &lt;code&gt;fedora:latest&lt;/code&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ skopeo inspect --config docker://registry.fedoraproject.org/fedora:latest  | jq
{
  "created": "2020-04-29T06:48:16Z",
  "architecture": "amd64",
  "os": "linux",
  "config": {
    "Env": [
      "DISTTAG=f32container",
      "FGC=f32",
      "container=oci"
    ],
    "Cmd": [
      "/bin/bash"
    ],
    "Labels": {
      "license": "MIT",
      "name": "fedora",
      "vendor": "Fedora Project",
      "version": "32"
    }
  },
  "rootfs": {
    "type": "layers",
    "diff_ids": [
      "sha256:a4c0fa2b217d3fd63d51e55a6fd59432e543d499c0df2b1acd48fbe424f2ddd1"
    ]
  },
  "history": [
    {
      "created": "2020-04-29T06:48:16Z",
      "comment": "Created by Image Factory"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Show unverified image's digest&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ skopeo inspect docker://registry.fedoraproject.org/fedora:latest | jq '.Digest'
"sha256:655721ff613ee766a4126cb5e0d5ae81598e1b0c3bcf7017c36c4d72cb092fe9"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Copying images&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;skopeo&lt;/code&gt; can copy container images between various storage mechanisms, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Container registries&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The Quay, Docker Hub, OpenShift, GCR, Artifactory ...&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Container Storage backends&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/containers/storage"&gt;github.com/containers/storage&lt;/a&gt; (Backend for &lt;a href="https://podman.io"&gt;Podman&lt;/a&gt;, &lt;a href="https://cri-o.io"&gt;CRI-O&lt;/a&gt;, &lt;a href="https://buildah.io"&gt;Buildah&lt;/a&gt; and friends)&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Docker daemon storage&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Local directories&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Local OCI-layout directories&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ skopeo copy docker://quay.io/buildah/stable docker://registry.internal.company.com/buildah
$ skopeo copy oci:busybox_ocilayout:latest dir:existingemptydirectory
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Deleting images&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ skopeo delete docker://localhost:5000/imagename:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Syncing registries&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ skopeo sync --src docker --dest dir registry.example.com/busybox /media/usb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Authenticating to a registry&lt;/h2&gt; 
&lt;h4&gt;Private registries with authentication&lt;/h4&gt; 
&lt;p&gt;skopeo uses credentials from the --creds (for skopeo inspect|delete) or --src-creds|--dest-creds (for skopeo copy) flags, if set; otherwise it uses configuration set by skopeo login, podman login, buildah login, or docker login.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ skopeo login --username USER myregistrydomain.com:5000
Password:
$ skopeo inspect docker://myregistrydomain.com:5000/busybox
{"Tag":"latest","Digest":"sha256:473bb2189d7b913ed7187a33d11e743fdc2f88931122a44d91a301b64419f092","RepoTags":["latest"],"Comment":"","Created":"2016-01-15T18:06:41.282540103Z","ContainerConfig":{"Hostname":"aded96b43f48","Domainname":"","User":"","AttachStdin":false,"AttachStdout":false,"AttachStderr":false,"Tty":false,"OpenStdin":false,"StdinOnce":false,"Env":null,"Cmd":["/bin/sh","-c","#(nop) CMD [\"sh\"]"],"Image":"9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33","Volumes":null,"WorkingDir":"","Entrypoint":null,"OnBuild":null,"Labels":null},"DockerVersion":"1.8.3","Author":"","Config":{"Hostname":"aded96b43f48","Domainname":"","User":"","AttachStdin":false,"AttachStdout":false,"AttachStderr":false,"Tty":false,"OpenStdin":false,"StdinOnce":false,"Env":null,"Cmd":["sh"],"Image":"9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33","Volumes":null,"WorkingDir":"","Entrypoint":null,"OnBuild":null,"Labels":null},"Architecture":"amd64","Os":"linux"}
$ skopeo logout myregistrydomain.com:5000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using --creds directly&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ skopeo inspect --creds=testuser:testpassword docker://myregistrydomain.com:5000/busybox
{"Tag":"latest","Digest":"sha256:473bb2189d7b913ed7187a33d11e743fdc2f88931122a44d91a301b64419f092","RepoTags":["latest"],"Comment":"","Created":"2016-01-15T18:06:41.282540103Z","ContainerConfig":{"Hostname":"aded96b43f48","Domainname":"","User":"","AttachStdin":false,"AttachStdout":false,"AttachStderr":false,"Tty":false,"OpenStdin":false,"StdinOnce":false,"Env":null,"Cmd":["/bin/sh","-c","#(nop) CMD [\"sh\"]"],"Image":"9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33","Volumes":null,"WorkingDir":"","Entrypoint":null,"OnBuild":null,"Labels":null},"DockerVersion":"1.8.3","Author":"","Config":{"Hostname":"aded96b43f48","Domainname":"","User":"","AttachStdin":false,"AttachStdout":false,"AttachStderr":false,"Tty":false,"OpenStdin":false,"StdinOnce":false,"Env":null,"Cmd":["sh"],"Image":"9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33","Volumes":null,"WorkingDir":"","Entrypoint":null,"OnBuild":null,"Labels":null},"Architecture":"amd64","Os":"linux"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ skopeo copy --src-creds=testuser:testpassword docker://myregistrydomain.com:5000/private oci:local_oci_image
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; if you want to collaborate in the project.&lt;/p&gt; 
&lt;h2&gt;Commands&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-copy.1.md"&gt;skopeo-copy(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Copy an image (manifest, filesystem layers, signatures) from one location to another.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-delete.1.md"&gt;skopeo-delete(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Mark the image-name for later deletion by the registry's garbage collector.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-generate-sigstore-key.1.md"&gt;skopeo-generate-sigstore-key(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Generate a sigstore public/private key pair.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-inspect.1.md"&gt;skopeo-inspect(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Return low-level information about image-name in a registry.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-list-tags.1.md"&gt;skopeo-list-tags(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Return a list of tags for the transport-specific image repository.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-login.1.md"&gt;skopeo-login(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Login to a container registry.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-logout.1.md"&gt;skopeo-logout(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Logout of a container registry.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-manifest-digest.1.md"&gt;skopeo-manifest-digest(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Compute a manifest digest for a manifest-file and write it to standard output.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-standalone-sign.1.md"&gt;skopeo-standalone-sign(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Debugging tool - Sign an image locally without uploading.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-standalone-verify.1.md"&gt;skopeo-standalone-verify(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Debugging tool - Verify an image signature from local files.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/docs/skopeo-sync.1.md"&gt;skopeo-sync(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Synchronize images between registry repositories and local directories.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;skopeo is licensed under the Apache License, Version 2.0. See &lt;a href="https://raw.githubusercontent.com/containers/skopeo/main/LICENSE"&gt;LICENSE&lt;/a&gt; for the full license text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>opencontainers/runc</title>
      <link>https://github.com/opencontainers/runc</link>
      <description>&lt;p&gt;CLI tool for spawning and running containers according to the OCI specification&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;runc&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/opencontainers/runc"&gt;&lt;img src="https://goreportcard.com/badge/github.com/opencontainers/runc" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/opencontainers/runc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/opencontainers/runc.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/588"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/588/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://github.com/opencontainers/runc/actions?query=workflow%3Avalidate"&gt;&lt;img src="https://github.com/opencontainers/runc/workflows/validate/badge.svg?sanitize=true" alt="gha/validate" /&gt;&lt;/a&gt; &lt;a href="https://github.com/opencontainers/runc/actions?query=workflow%3Aci"&gt;&lt;img src="https://github.com/opencontainers/runc/workflows/ci/badge.svg?sanitize=true" alt="gha/ci" /&gt;&lt;/a&gt; &lt;a href="https://cirrus-ci.com/github/opencontainers/runc"&gt;&lt;img src="https://api.cirrus-ci.com/github/opencontainers/runc.svg?sanitize=true" alt="CirrusCI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; is a CLI tool for spawning and running containers on Linux according to the OCI specification.&lt;/p&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;p&gt;You can find official releases of &lt;code&gt;runc&lt;/code&gt; on the &lt;a href="https://github.com/opencontainers/runc/releases"&gt;release&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;All releases are signed by one of the keys listed in the &lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/runc.keyring"&gt;&lt;code&gt;runc.keyring&lt;/code&gt; file in the root of this repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;The reporting process and disclosure communications are outlined &lt;a href="https://github.com/opencontainers/org/raw/master/SECURITY.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Security Audit&lt;/h3&gt; 
&lt;p&gt;A third party security audit was performed by Cure53, you can see the full report &lt;a href="https://github.com/opencontainers/runc/raw/master/docs/Security-Audit.pdf"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; only supports Linux. See the header of &lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/go.mod"&gt;&lt;code&gt;go.mod&lt;/code&gt;&lt;/a&gt; for the minimally required Go version.&lt;/p&gt; 
&lt;h3&gt;Pre-Requisites&lt;/h3&gt; 
&lt;h4&gt;Utilities and Libraries&lt;/h4&gt; 
&lt;p&gt;In addition to Go, building &lt;code&gt;runc&lt;/code&gt; requires multiple utilities and libraries to be installed on your system.&lt;/p&gt; 
&lt;p&gt;On Ubuntu/Debian, you can install the required dependencies with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;apt update &amp;amp;&amp;amp; apt install -y make gcc linux-libc-dev libseccomp-dev pkg-config git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On CentOS/Fedora, you can install the required dependencies with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yum install -y make gcc kernel-headers libseccomp-devel pkg-config git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Alpine Linux, you can install the required dependencies with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;apk --update add bash make gcc libseccomp-dev musl-dev linux-headers git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The following dependencies are optional:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;libseccomp&lt;/code&gt; - only required if you enable seccomp support; to disable, see &lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/#build-tags"&gt;Build Tags&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# create a 'github.com/opencontainers' in your GOPATH/src
cd github.com/opencontainers
git clone https://github.com/opencontainers/runc
cd runc

make
sudo make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use &lt;code&gt;go get&lt;/code&gt; to install to your &lt;code&gt;GOPATH&lt;/code&gt;, assuming that you have a &lt;code&gt;github.com&lt;/code&gt; parent folder already created under &lt;code&gt;src&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/opencontainers/runc
cd $GOPATH/src/github.com/opencontainers/runc
make
sudo make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; will be installed to &lt;code&gt;/usr/local/sbin/runc&lt;/code&gt; on your system.&lt;/p&gt; 
&lt;h4&gt;Version string customization&lt;/h4&gt; 
&lt;p&gt;You can see the runc version by running &lt;code&gt;runc --version&lt;/code&gt;. You can append a custom string to the version using the &lt;code&gt;EXTRA_VERSION&lt;/code&gt; make variable when building, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make EXTRA_VERSION="+build-1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Bear in mind to include some separator for readability.&lt;/p&gt; 
&lt;h4&gt;Build Tags&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; supports optional build tags for compiling support of various features, with some of them enabled by default (see &lt;code&gt;BUILDTAGS&lt;/code&gt; in top-level &lt;code&gt;Makefile&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;To change build tags from the default, set the &lt;code&gt;BUILDTAGS&lt;/code&gt; variable for make, e.g. to disable seccomp:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make BUILDTAGS=""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To add some more build tags to the default set, use the &lt;code&gt;EXTRA_BUILDTAGS&lt;/code&gt; make variable, e.g. to disable checkpoint/restore:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make EXTRA_BUILDTAGS="runc_nocriu"
&lt;/code&gt;&lt;/pre&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Build Tag&lt;/th&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Enabled by Default&lt;/th&gt; 
   &lt;th&gt;Dependencies&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;seccomp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Syscall filtering using &lt;code&gt;libseccomp&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;yes&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;libseccomp&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;runc_nocriu&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Disables&lt;/strong&gt; runc checkpoint/restore.&lt;/td&gt; 
   &lt;td&gt;no&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;criu&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The following build tags were used earlier, but are now obsoleted:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;runc_nodmz&lt;/strong&gt; (since runc v1.2.1 runc dmz binary is dropped)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;nokmem&lt;/strong&gt; (since runc v1.0.0-rc94 kernel memory settings are ignored)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;apparmor&lt;/strong&gt; (since runc v1.0.0-rc93 the feature is always enabled)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;selinux&lt;/strong&gt; (since runc v1.0.0-rc93 the feature is always enabled)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Running the test suite&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; currently supports running its test suite via Docker. To run the suite just type &lt;code&gt;make test&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are additional make targets for running the tests outside of a container but this is not recommended as the tests are written with the expectation that they can write and remove anywhere.&lt;/p&gt; 
&lt;p&gt;You can run a specific test case by setting the &lt;code&gt;TESTFLAGS&lt;/code&gt; variable.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# make test TESTFLAGS="-run=SomeTestFunction"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can run a specific integration test by setting the &lt;code&gt;TESTPATH&lt;/code&gt; variable.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# make test TESTPATH="/checkpoint.bats"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can run a specific rootless integration test by setting the &lt;code&gt;ROOTLESS_TESTPATH&lt;/code&gt; variable.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# make test ROOTLESS_TESTPATH="/checkpoint.bats"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can run a test using your container engine's flags by setting &lt;code&gt;CONTAINER_ENGINE_BUILD_FLAGS&lt;/code&gt; and &lt;code&gt;CONTAINER_ENGINE_RUN_FLAGS&lt;/code&gt; variables.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# make test CONTAINER_ENGINE_BUILD_FLAGS="--build-arg http_proxy=http://yourproxy/" CONTAINER_ENGINE_RUN_FLAGS="-e http_proxy=http://yourproxy/"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Go Dependencies Management&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; uses &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;Go Modules&lt;/a&gt; for dependencies management. Please refer to &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;Go Modules&lt;/a&gt; for how to add or update new dependencies.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Update vendored dependencies
make vendor
# Verify all dependencies
make verify-dependencies
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using runc&lt;/h2&gt; 
&lt;p&gt;Please note that runc is a low level tool not designed with an end user in mind. It is mostly employed by other higher level container software.&lt;/p&gt; 
&lt;p&gt;Therefore, unless there is some specific use case that prevents the use of tools like Docker or Podman, it is not recommended to use runc directly.&lt;/p&gt; 
&lt;p&gt;If you still want to use runc, here's how.&lt;/p&gt; 
&lt;h3&gt;Creating an OCI Bundle&lt;/h3&gt; 
&lt;p&gt;In order to use runc you must have your container in the format of an OCI bundle. If you have Docker installed you can use its &lt;code&gt;export&lt;/code&gt; method to acquire a root filesystem from an existing Docker container.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# create the top most bundle directory
mkdir /mycontainer
cd /mycontainer

# create the rootfs directory
mkdir rootfs

# export busybox via Docker into the rootfs directory
docker export $(docker create busybox) | tar -C rootfs -xvf -
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After a root filesystem is populated you just generate a spec in the format of a &lt;code&gt;config.json&lt;/code&gt; file inside your bundle. &lt;code&gt;runc&lt;/code&gt; provides a &lt;code&gt;spec&lt;/code&gt; command to generate a base template spec that you are then able to edit. To find features and documentation for fields in the spec please refer to the &lt;a href="https://github.com/opencontainers/runtime-spec"&gt;specs&lt;/a&gt; repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;runc spec
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running Containers&lt;/h3&gt; 
&lt;p&gt;Assuming you have an OCI bundle from the previous step you can execute the container in two different ways.&lt;/p&gt; 
&lt;p&gt;The first way is to use the convenience command &lt;code&gt;run&lt;/code&gt; that will handle creating, starting, and deleting the container after it exits.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# run as root
cd /mycontainer
runc run mycontainerid
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you used the unmodified &lt;code&gt;runc spec&lt;/code&gt; template this should give you a &lt;code&gt;sh&lt;/code&gt; session inside the container.&lt;/p&gt; 
&lt;p&gt;The second way to start a container is using the specs lifecycle operations. This gives you more power over how the container is created and managed while it is running. This will also launch the container in the background so you will have to edit the &lt;code&gt;config.json&lt;/code&gt; to remove the &lt;code&gt;terminal&lt;/code&gt; setting for the simple examples below (see more details about &lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/docs/terminals.md"&gt;runc terminal handling&lt;/a&gt;). Your process field in the &lt;code&gt;config.json&lt;/code&gt; should look like this below with &lt;code&gt;"terminal": false&lt;/code&gt; and &lt;code&gt;"args": ["sleep", "5"]&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;        "process": {
                "terminal": false,
                "user": {
                        "uid": 0,
                        "gid": 0
                },
                "args": [
                        "sleep", "5"
                ],
                "env": [
                        "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                        "TERM=xterm"
                ],
                "cwd": "/",
                "capabilities": {
                        "bounding": [
                                "CAP_AUDIT_WRITE",
                                "CAP_KILL",
                                "CAP_NET_BIND_SERVICE"
                        ],
                        "effective": [
                                "CAP_AUDIT_WRITE",
                                "CAP_KILL",
                                "CAP_NET_BIND_SERVICE"
                        ],
                        "inheritable": [
                                "CAP_AUDIT_WRITE",
                                "CAP_KILL",
                                "CAP_NET_BIND_SERVICE"
                        ],
                        "permitted": [
                                "CAP_AUDIT_WRITE",
                                "CAP_KILL",
                                "CAP_NET_BIND_SERVICE"
                        ],
                        "ambient": [
                                "CAP_AUDIT_WRITE",
                                "CAP_KILL",
                                "CAP_NET_BIND_SERVICE"
                        ]
                },
                "rlimits": [
                        {
                                "type": "RLIMIT_NOFILE",
                                "hard": 1024,
                                "soft": 1024
                        }
                ],
                "noNewPrivileges": true
        },
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now we can go through the lifecycle operations in your shell.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# run as root
cd /mycontainer
runc create mycontainerid

# view the container is created and in the "created" state
runc list

# start the process inside the container
runc start mycontainerid

# after 5 seconds view that the container has exited and is now in the stopped state
runc list

# now delete the container
runc delete mycontainerid
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This allows higher level systems to augment the containers creation logic with setup of various settings after the container is created and/or before it is deleted. For example, the container's network stack is commonly set up after &lt;code&gt;create&lt;/code&gt; but before &lt;code&gt;start&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Rootless containers&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; has the ability to run containers without root privileges. This is called &lt;code&gt;rootless&lt;/code&gt;. You need to pass some parameters to &lt;code&gt;runc&lt;/code&gt; in order to run rootless containers. See below and compare with the previous version.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In order to use this feature, "User Namespaces" must be compiled and enabled in your kernel. There are various ways to do this depending on your distribution:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Confirm &lt;code&gt;CONFIG_USER_NS=y&lt;/code&gt; is set in your kernel configuration (normally found in &lt;code&gt;/proc/config.gz&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Arch/Debian: &lt;code&gt;echo 1 &amp;gt; /proc/sys/kernel/unprivileged_userns_clone&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;RHEL/CentOS 7: &lt;code&gt;echo 28633 &amp;gt; /proc/sys/user/max_user_namespaces&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run the following commands as an ordinary user:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Same as the first example
mkdir ~/mycontainer
cd ~/mycontainer
mkdir rootfs
docker export $(docker create busybox) | tar -C rootfs -xvf -

# The --rootless parameter instructs runc spec to generate a configuration for a rootless container, which will allow you to run the container as a non-root user.
runc spec --rootless

# The --root parameter tells runc where to store the container state. It must be writable by the user.
runc --root /tmp/runc run mycontainerid
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Supervisors&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; can be used with process supervisors and init systems to ensure that containers are restarted when they exit. An example systemd unit file looks something like this.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-systemd"&gt;[Unit]
Description=Start My Container

[Service]
Type=forking
ExecStart=/usr/local/sbin/runc run -d --pid-file /run/mycontainerid.pid mycontainerid
ExecStopPost=/usr/local/sbin/runc delete mycontainerid
WorkingDirectory=/mycontainer
PIDFile=/run/mycontainerid.pid

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;More documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/docs/spec-conformance.md"&gt;Spec conformance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/docs/cgroup-v2.md"&gt;cgroup v2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/docs/checkpoint-restore.md"&gt;Checkpoint and restore&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/docs/systemd.md"&gt;systemd cgroup driver&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/docs/terminals.md"&gt;Terminals and standard IO&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/docs/experimental.md"&gt;Experimental features&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The code and docs are released under the &lt;a href="https://raw.githubusercontent.com/opencontainers/runc/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>googleapis/genai-toolbox</title>
      <link>https://github.com/googleapis/genai-toolbox</link>
      <description>&lt;p&gt;MCP Toolbox for Databases is an open source MCP server for databases.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/logo.png" alt="logo" /&gt;&lt;/p&gt; 
&lt;h1&gt;MCP Toolbox for Databases&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://googleapis.github.io/genai-toolbox/"&gt;&lt;img src="https://img.shields.io/badge/docs-MCP_Toolbox-blue" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Dmm69peqjh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://medium.com/@mcp_toolbox"&gt;&lt;img src="https://img.shields.io/badge/Medium-12100E?style=flat&amp;amp;logo=medium&amp;amp;logoColor=white" alt="Medium" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/googleapis/genai-toolbox"&gt;&lt;img src="https://goreportcard.com/badge/github.com/googleapis/genai-toolbox" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MCP Toolbox for Databases is currently in beta, and may see breaking changes until the first stable release (v1.0).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MCP Toolbox for Databases is an open source MCP server for databases. It enables you to develop tools easier, faster, and more securely by handling the complexities such as connection pooling, authentication, and more.&lt;/p&gt; 
&lt;p&gt;This README provides a brief overview. For comprehensive details, see the &lt;a href="https://googleapis.github.io/genai-toolbox/"&gt;full documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This solution was originally named ‚ÄúGen AI Toolbox for Databases‚Äù as its initial development predated MCP, but was renamed to align with recently added MCP compatibility.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- TOC ignore:true --&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- TOC --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#why-toolbox"&gt;Why Toolbox?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#general-architecture"&gt;General Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#installing-the-server"&gt;Installing the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#running-the-server"&gt;Running the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#integrating-your-application"&gt;Integrating your application&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#using-toolbox-with-gemini-cli-extensions"&gt;Using Toolbox with Gemini CLI Extensions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#configuration"&gt;Configuration&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#sources"&gt;Sources&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#tools"&gt;Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#toolsets"&gt;Toolsets&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#versioning"&gt;Versioning&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#pre-100-versioning"&gt;Pre-1.0.0 Versioning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#post-100-versioning"&gt;Post-1.0.0 Versioning&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- /TOC --&gt; 
&lt;h2&gt;Why Toolbox?&lt;/h2&gt; 
&lt;p&gt;Toolbox helps you build Gen AI tools that let your agents access data in your database. Toolbox provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Simplified development&lt;/strong&gt;: Integrate tools to your agent in less than 10 lines of code, reuse tools between multiple agents or frameworks, and deploy new versions of tools more easily.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better performance&lt;/strong&gt;: Best practices such as connection pooling, authentication, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced security&lt;/strong&gt;: Integrated auth for more secure access to your data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end observability&lt;/strong&gt;: Out of the box metrics and tracing with built-in support for OpenTelemetry.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;‚ö° Supercharge Your Workflow with an AI Database Assistant ‚ö°&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Stop context-switching and let your AI assistant become a true co-developer. By &lt;a href="https://googleapis.github.io/genai-toolbox/how-to/connect-ide/"&gt;connecting your IDE to your databases with MCP Toolbox&lt;/a&gt;, you can delegate complex and time-consuming database tasks, allowing you to build faster and focus on what matters. This isn't just about code completion; it's about giving your AI the context it needs to handle the entire development lifecycle.&lt;/p&gt; 
&lt;p&gt;Here‚Äôs how it will save you time:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query in Plain English&lt;/strong&gt;: Interact with your data using natural language right from your IDE. Ask complex questions like, &lt;em&gt;"How many orders were delivered in 2024, and what items were in them?"&lt;/em&gt; without writing any SQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automate Database Management&lt;/strong&gt;: Simply describe your data needs, and let the AI assistant manage your database for you. It can handle generating queries, creating tables, adding indexes, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generate Context-Aware Code&lt;/strong&gt;: Empower your AI assistant to generate application code and tests with a deep understanding of your real-time database schema. This accelerates the development cycle by ensuring the generated code is directly usable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Slash Development Overhead&lt;/strong&gt;: Radically reduce the time spent on manual setup and boilerplate. MCP Toolbox helps streamline lengthy database configurations, repetitive code, and error-prone schema migrations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn &lt;a href="https://googleapis.github.io/genai-toolbox/how-to/connect-ide/"&gt;how to connect your AI tools (IDEs) to Toolbox using MCP&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;General Architecture&lt;/h2&gt; 
&lt;p&gt;Toolbox sits between your application's orchestration framework and your database, providing a control plane that is used to modify, distribute, or invoke tools. It simplifies the management of your tools by providing you with a centralized location to store and update tools, allowing you to share tools between agents and applications and update those tools without necessarily redeploying your application.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/docs/en/getting-started/introduction/architecture.png" alt="architecture" width="50%" /&gt; &lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Installing the server&lt;/h3&gt; 
&lt;p&gt;For the latest version, check the &lt;a href="https://github.com/googleapis/genai-toolbox/releases"&gt;releases page&lt;/a&gt; and use the following instructions for your OS and CPU architecture.&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Binary&lt;/summary&gt; 
 &lt;p&gt;To install Toolbox as a binary:&lt;/p&gt; 
 &lt;!-- {x-release-please-start-version} --&gt; 
 &lt;blockquote&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Linux (AMD64)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on Linux (AMD64):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.19.1
curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/linux/amd64/toolbox
chmod +x toolbox
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;macOS (Apple Silicon)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on macOS (Apple Silicon):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.19.1
curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/arm64/toolbox
chmod +x toolbox
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;macOS (Intel)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on macOS (Intel):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.19.1
curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/amd64/toolbox
chmod +x toolbox
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Windows (AMD64)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on Windows (AMD64):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-powershell"&gt;# see releases page for other versions
$VERSION = "0.19.1"
Invoke-WebRequest -Uri "https://storage.googleapis.com/genai-toolbox/v$VERSION/windows/amd64/toolbox.exe" -OutFile "toolbox.exe"
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Container image&lt;/summary&gt; You can also install Toolbox as a container: 
 &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.19.1
docker pull us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Homebrew&lt;/summary&gt; 
 &lt;p&gt;To install Toolbox using Homebrew on macOS or Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;brew install mcp-toolbox
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Compile from source&lt;/summary&gt; 
 &lt;p&gt;To install from source, ensure you have the latest version of &lt;a href="https://go.dev/doc/install"&gt;Go installed&lt;/a&gt;, and then run the following command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/googleapis/genai-toolbox@v0.19.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;!-- {x-release-please-end} --&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini CLI Extensions&lt;/summary&gt; 
 &lt;p&gt;To install Gemini CLI Extensions for MCP Toolbox, run the following command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;gemini extensions install https://github.com/gemini-cli-extensions/mcp-toolbox
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Running the server&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#configuration"&gt;Configure&lt;/a&gt; a &lt;code&gt;tools.yaml&lt;/code&gt; to define your tools, and then execute &lt;code&gt;toolbox&lt;/code&gt; to start the server:&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Binary&lt;/summary&gt; 
 &lt;p&gt;To run Toolbox from binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;./toolbox --tools-file "tools.yaml"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note&lt;br /&gt; Toolbox enables dynamic reloading by default. To disable, use the &lt;code&gt;--disable-reload&lt;/code&gt; flag.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Container image&lt;/summary&gt; 
 &lt;p&gt;To run the server after pulling the &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#installing-the-server"&gt;container image&lt;/a&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;export VERSION=0.11.0 # Use the version you pulled
docker run -p 5000:5000 \
-v $(pwd)/tools.yaml:/app/tools.yaml \
us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION \
--tools-file "/app/tools.yaml"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note&lt;br /&gt; The &lt;code&gt;-v&lt;/code&gt; flag mounts your local &lt;code&gt;tools.yaml&lt;/code&gt; into the container, and &lt;code&gt;-p&lt;/code&gt; maps the container's port &lt;code&gt;5000&lt;/code&gt; to your host's port &lt;code&gt;5000&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Source&lt;/summary&gt; 
 &lt;p&gt;To run the server directly from source, navigate to the project root directory and run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;go run .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note&lt;br /&gt; This command runs the project from source, and is more suitable for development and testing. It does &lt;strong&gt;not&lt;/strong&gt; compile a binary into your &lt;code&gt;$GOPATH&lt;/code&gt;. If you want to compile a binary instead, refer the &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/DEVELOPER.md#building-the-binary"&gt;Developer Documentation&lt;/a&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Homebrew&lt;/summary&gt; 
 &lt;p&gt;If you installed Toolbox using &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;, the &lt;code&gt;toolbox&lt;/code&gt; binary is available in your system path. You can start the server with the same command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;toolbox --tools-file "tools.yaml"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini CLI&lt;/summary&gt; 
 &lt;p&gt;Interact with your custom tools using natural language. Check &lt;a href="https://github.com/gemini-cli-extensions/mcp-toolbox"&gt;gemini-cli-extensions/mcp-toolbox&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;You can use &lt;code&gt;toolbox help&lt;/code&gt; for a full list of flags! To stop the server, send a terminate signal (&lt;code&gt;ctrl+c&lt;/code&gt; on most platforms).&lt;/p&gt; 
&lt;p&gt;For more detailed documentation on deploying to different environments, check out the resources in the &lt;a href="https://googleapis.github.io/genai-toolbox/how-to/"&gt;How-to section&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Integrating your application&lt;/h3&gt; 
&lt;p&gt;Once your server is up and running, you can load the tools into your application. See below the list of Client SDKs for using various frameworks:&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Python (&lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-python"&gt;Github&lt;/a&gt;)&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Core&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pypi.org/project/toolbox-core/"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install toolbox-core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from toolbox_core import ToolboxClient

# update the url to point to your server
async with ToolboxClient("http://127.0.0.1:5000") as client:

    # these tools can be passed to your application!
    tools = await client.load_toolset("toolset_name")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;For more detailed instructions on using the Toolbox Core SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pypi.org/project/toolbox-langchain/"&gt;Toolbox LangChain SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install toolbox-langchain
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from toolbox_langchain import ToolboxClient

# update the url to point to your server
async with ToolboxClient("http://127.0.0.1:5000") as client:

    # these tools can be passed to your application!
    tools = client.load_toolset()
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox LangChain SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-python/raw/main/packages/toolbox-langchain/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LlamaIndex&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pypi.org/project/toolbox-llamaindex/"&gt;Toolbox Llamaindex SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install toolbox-llamaindex
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from toolbox_llamaindex import ToolboxClient

# update the url to point to your server
async with ToolboxClient("http://127.0.0.1:5000") as client:

    # these tools can be passed to your application!
    tools = client.load_toolset()
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Llamaindex SDK, see the &lt;a href="https://github.com/googleapis/genai-toolbox-llamaindex-python/raw/main/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Javascript/Typescript (&lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-js"&gt;Github&lt;/a&gt;)&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Core&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/core"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/core';

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const tools = await client.loadToolset('toolsetName');
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Core SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-js/raw/main/packages/toolbox-core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/core"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/core';

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const toolboxTools = await client.loadToolset('toolsetName');

// Define the basics of the tool: name, description, schema and core logic
const getTool = (toolboxTool) =&amp;gt; tool(currTool, {
    name: toolboxTool.getName(),
    description: toolboxTool.getDescription(),
    schema: toolboxTool.getParamSchema()
});

// Use these tools in your Langchain/Langraph applications
const tools = toolboxTools.map(getTool);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Genkit&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/core"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/core';
import { genkit } from 'genkit';

// Initialise genkit
const ai = genkit({
    plugins: [
        googleAI({
            apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY
        })
    ],
    model: googleAI.model('gemini-2.0-flash'),
});

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const toolboxTools = await client.loadToolset('toolsetName');

// Define the basics of the tool: name, description, schema and core logic
const getTool = (toolboxTool) =&amp;gt; ai.defineTool({
    name: toolboxTool.getName(),
    description: toolboxTool.getDescription(),
    schema: toolboxTool.getParamSchema()
}, toolboxTool)

// Use these tools in your Genkit applications
const tools = toolboxTools.map(getTool);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Go (&lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-go"&gt;Github&lt;/a&gt;)&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Core&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "context"
)

func main() {
  // Make sure to add the error checks
  // update the url to point to your server
  URL := "http://127.0.0.1:5000";
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tools
  tools, err := client.LoadToolset("toolsetName", ctx)
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Go SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-go/raw/main/core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LangChain Go&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "encoding/json"

  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "github.com/tmc/langchaingo/llms"
)

func main() {
  // Make sure to add the error checks
  // update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Fetch the tool's input schema
  inputschema, err := tool.InputSchema()

  var paramsSchema map[string]any
  _ = json.Unmarshal(inputschema, &amp;amp;paramsSchema)

  // Use this tool with LangChainGo
  langChainTool := llms.Tool{
    Type: "function",
    Function: &amp;amp;llms.FunctionDefinition{
      Name:        tool.Name(),
      Description: tool.Description(),
      Parameters:  paramsSchema,
    },
  }
}

&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Genkit&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main
import (
  "context"
  "log"

  "github.com/firebase/genkit/go/genkit"
  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "github.com/googleapis/mcp-toolbox-sdk-go/tbgenkit"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()
  g := genkit.Init(ctx)

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Convert the tool using the tbgenkit package
  // Use this tool with Genkit Go
  genkitTool, err := tbgenkit.ToGenkitTool(tool, g)
  if err != nil {
    log.Fatalf("Failed to convert tool: %v\n", err)
  }
  log.Printf("Successfully converted tool: %s", genkitTool.Name())
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Go GenAI&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "encoding/json"

  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "google.golang.org/genai"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Fetch the tool's input schema
  inputschema, err := tool.InputSchema()

  var schema *genai.Schema
  _ = json.Unmarshal(inputschema, &amp;amp;schema)

  funcDeclaration := &amp;amp;genai.FunctionDeclaration{
    Name:        tool.Name(),
    Description: tool.Description(),
    Parameters:  schema,
  }

  // Use this tool with Go GenAI
  genAITool := &amp;amp;genai.Tool{
    FunctionDeclarations: []*genai.FunctionDeclaration{funcDeclaration},
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;OpenAI Go&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "encoding/json"

  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  openai "github.com/openai/openai-go"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Fetch the tool's input schema
  inputschema, err := tool.InputSchema()

  var paramsSchema openai.FunctionParameters
  _ = json.Unmarshal(inputschema, &amp;amp;paramsSchema)

  // Use this tool with OpenAI Go
  openAITool := openai.ChatCompletionToolParam{
    Function: openai.FunctionDefinitionParam{
      Name:        tool.Name(),
      Description: openai.String(tool.Description()),
      Parameters:  paramsSchema,
    },
  }

}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;ADK Go&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "github.com/googleapis/mcp-toolbox-sdk-go/tbadk"
  "context"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()
  client, err := tbadk.NewToolboxClient(URL)
  if err != nil {
    return fmt.Sprintln("Could not start Toolbox Client", err)
  }

  // Use this tool with ADK Go
  tool, err := client.LoadTool("toolName", ctx)
  if err != nil {
    return fmt.Sprintln("Could not load Toolbox Tool", err)
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Go SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-go/raw/main/core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt;
&lt;/details&gt;   
&lt;h3&gt;Using Toolbox with Gemini CLI Extensions&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/google-gemini/gemini-cli/raw/main/docs/extensions/index.md"&gt;Gemini CLI extensions&lt;/a&gt; provide tools to interact directly with your data sources from command line. Below is a list of Gemini CLI extensions that are built on top of &lt;strong&gt;Toolbox&lt;/strong&gt;. They allow you to interact with your data sources through pre-defined or custom tools with natural language. Click into the link to see detailed instructions on their usage.&lt;/p&gt; 
&lt;p&gt;To use &lt;strong&gt;custom&lt;/strong&gt; tools with Gemini CLI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/mcp-toolbox"&gt;MCP Toolbox&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use &lt;a href="https://googleapis.github.io/genai-toolbox/reference/prebuilt-tools/"&gt;prebuilt tools&lt;/a&gt; with Gemini CLI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/alloydb"&gt;AlloyDB for PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/alloydb-observability"&gt;AlloyDB for PostgreSQL Observability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/bigquery-data-analytics"&gt;BigQuery Data Analytics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/bigquery-conversational-analytics"&gt;BigQuery Conversational Analytics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-mysql"&gt;Cloud SQL for MySQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-mysql-observability"&gt;Cloud SQL for MySQL Observability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-postgresql"&gt;Cloud SQL for PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-postgresql-observability"&gt;Cloud SQL for PostgreSQL Observability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-sqlserver"&gt;Cloud SQL for SQL Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-sqlserver-observability"&gt;Cloud SQL for SQL Server Observability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/looker"&gt;Looker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/dataplex"&gt;Dataplex&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/mysql"&gt;MySQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/postgres"&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/spanner"&gt;Spanner&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/firestore-native"&gt;Firestore&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/sql-server"&gt;SQL Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;The primary way to configure Toolbox is through the &lt;code&gt;tools.yaml&lt;/code&gt; file. If you have multiple files, you can tell toolbox which to load with the &lt;code&gt;--tools-file tools.yaml&lt;/code&gt; flag.&lt;/p&gt; 
&lt;p&gt;You can find more detailed reference documentation to all resource types in the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/"&gt;Resources&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Sources&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;sources&lt;/code&gt; section of your &lt;code&gt;tools.yaml&lt;/code&gt; defines what data sources your Toolbox should have access to. Most tools will have at least one source to execute against.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;sources:
  my-pg-source:
    kind: postgres
    host: 127.0.0.1
    port: 5432
    database: toolbox_db
    user: toolbox_user
    password: my-password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on configuring different types of sources, see the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/sources"&gt;Sources&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;tools&lt;/code&gt; section of a &lt;code&gt;tools.yaml&lt;/code&gt; define the actions an agent can take: what kind of tool it is, which source(s) it affects, what parameters it uses, etc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;tools:
  search-hotels-by-name:
    kind: postgres-sql
    source: my-pg-source
    description: Search for hotels based on name.
    parameters:
      - name: name
        type: string
        description: The name of the hotel.
    statement: SELECT * FROM hotels WHERE name ILIKE '%' || $1 || '%';
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on configuring different types of tools, see the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/tools"&gt;Tools&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Toolsets&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;toolsets&lt;/code&gt; section of your &lt;code&gt;tools.yaml&lt;/code&gt; allows you to define groups of tools that you want to be able to load together. This can be useful for defining different groups based on agent or application.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;toolsets:
    my_first_toolset:
        - my_first_tool
        - my_second_tool
    my_second_toolset:
        - my_second_tool
        - my_third_tool
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can load toolsets by name:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# This will load all tools
all_tools = client.load_toolset()

# This will only load the tools listed in 'my_second_toolset'
my_second_toolset = client.load_toolset("my_second_toolset")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Versioning&lt;/h2&gt; 
&lt;p&gt;This project uses &lt;a href="https://semver.org/"&gt;semantic versioning&lt;/a&gt; (&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;). Since the project is in a pre-release stage (version &lt;code&gt;0.x.y&lt;/code&gt;), we follow the standard conventions for initial development:&lt;/p&gt; 
&lt;h3&gt;Pre-1.0.0 Versioning&lt;/h3&gt; 
&lt;p&gt;While the major version is &lt;code&gt;0&lt;/code&gt;, the public API should be considered unstable. The version will be incremented as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;0.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: The &lt;strong&gt;MINOR&lt;/strong&gt; version is incremented when we add new functionality or make breaking, incompatible API changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;0.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: The &lt;strong&gt;PATCH&lt;/strong&gt; version is incremented for backward-compatible bug fixes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Post-1.0.0 Versioning&lt;/h3&gt; 
&lt;p&gt;Once the project reaches a stable &lt;code&gt;1.0.0&lt;/code&gt; release, the versioning will follow the more common convention:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: Incremented for incompatible API changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: Incremented for new, backward-compatible functionality.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: Incremented for backward-compatible bug fixes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The public API that this applies to is the CLI associated with Toolbox, the interactions with official SDKs, and the definitions in the &lt;code&gt;tools.yaml&lt;/code&gt; file.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome. Please, see the &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;Please note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms. See &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/GQrFB3Ec3W"&gt;discord community&lt;/a&gt; to connect with our developers!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>grafana/mcp-grafana</title>
      <link>https://github.com/grafana/mcp-grafana</link>
      <description>&lt;p&gt;MCP server for Grafana&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Grafana MCP server&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/grafana/mcp-grafana/actions/workflows/unit.yml"&gt;&lt;img src="https://github.com/grafana/mcp-grafana/actions/workflows/unit.yml/badge.svg?sanitize=true" alt="Unit Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/grafana/mcp-grafana/actions/workflows/integration.yml"&gt;&lt;img src="https://github.com/grafana/mcp-grafana/actions/workflows/integration.yml/badge.svg?sanitize=true" alt="Integration Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/grafana/mcp-grafana/actions/workflows/e2e.yml"&gt;&lt;img src="https://github.com/grafana/mcp-grafana/actions/workflows/e2e.yml/badge.svg?sanitize=true" alt="E2E Tests" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/grafana/mcp-grafana"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/grafana/mcp-grafana.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://archestra.ai/mcp-catalog/grafana__mcp-grafana"&gt;&lt;img src="https://archestra.ai/mcp-catalog/api/badge/quality/grafana/mcp-grafana" alt="MCP Catalog" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://modelcontextprotocol.io/"&gt;Model Context Protocol&lt;/a&gt; (MCP) server for Grafana.&lt;/p&gt; 
&lt;p&gt;This provides access to your Grafana instance and the surrounding ecosystem.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Grafana version 9.0 or later&lt;/strong&gt; is required for full functionality. Some features, particularly datasource-related operations, may not work correctly with earlier versions due to missing API endpoints.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;The following features are currently available in MCP server. This list is for informational purposes only and does not represent a roadmap or commitment to future features.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Dashboards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Search for dashboards:&lt;/strong&gt; Find dashboards by title or other metadata&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get dashboard by UID:&lt;/strong&gt; Retrieve full dashboard details using its unique identifier. &lt;em&gt;Warning: Large dashboards can consume significant context window space.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get dashboard summary:&lt;/strong&gt; Get a compact overview of a dashboard including title, panel count, panel types, variables, and metadata without the full JSON to minimize context window usage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get dashboard property:&lt;/strong&gt; Extract specific parts of a dashboard using JSONPath expressions (e.g., &lt;code&gt;$.title&lt;/code&gt;, &lt;code&gt;$.panels[*].title&lt;/code&gt;) to fetch only needed data and reduce context window consumption&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update or create a dashboard:&lt;/strong&gt; Modify existing dashboards or create new ones. &lt;em&gt;Warning: Requires full dashboard JSON which can consume large amounts of context window space.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patch dashboard:&lt;/strong&gt; Apply specific changes to a dashboard without requiring the full JSON, significantly reducing context window usage for targeted modifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get panel queries and datasource info:&lt;/strong&gt; Get the title, query string, and datasource information (including UID and type, if available) from every panel in a dashboard&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Context Window Management&lt;/h4&gt; 
&lt;p&gt;The dashboard tools now include several strategies to manage context window usage effectively (&lt;a href="https://github.com/grafana/mcp-grafana/issues/101"&gt;issue #101&lt;/a&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;get_dashboard_summary&lt;/code&gt;&lt;/strong&gt; for dashboard overview and planning modifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;get_dashboard_property&lt;/code&gt;&lt;/strong&gt; with JSONPath when you only need specific dashboard parts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Avoid &lt;code&gt;get_dashboard_by_uid&lt;/code&gt;&lt;/strong&gt; unless you specifically need the complete dashboard JSON&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Datasources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List and fetch datasource information:&lt;/strong&gt; View all configured datasources and retrieve detailed information about each. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;em&gt;Supported datasource types: Prometheus, Loki.&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prometheus Querying&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query Prometheus:&lt;/strong&gt; Execute PromQL queries (supports both instant and range metric queries) against Prometheus datasources.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query Prometheus metadata:&lt;/strong&gt; Retrieve metric metadata, metric names, label names, and label values from Prometheus datasources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Loki Querying&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query Loki logs and metrics:&lt;/strong&gt; Run both log queries and metric queries using LogQL against Loki datasources.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query Loki metadata:&lt;/strong&gt; Retrieve label names, label values, and stream statistics from Loki datasources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Incidents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Search, create, and update incidents:&lt;/strong&gt; Manage incidents in Grafana Incident, including searching, creating, and adding activities to incidents.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Sift Investigations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List Sift investigations:&lt;/strong&gt; Retrieve a list of Sift investigations, with support for a limit parameter.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get Sift investigation:&lt;/strong&gt; Retrieve details of a specific Sift investigation by its UUID.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get Sift analyses:&lt;/strong&gt; Retrieve a specific analysis from a Sift investigation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Find error patterns in logs:&lt;/strong&gt; Detect elevated error patterns in Loki logs using Sift.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Find slow requests:&lt;/strong&gt; Detect slow requests using Sift (Tempo).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Alerting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List and fetch alert rule information:&lt;/strong&gt; View alert rules and their statuses (firing/normal/error/etc.) in Grafana.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List contact points:&lt;/strong&gt; View configured notification contact points in Grafana.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Grafana OnCall&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List and manage schedules:&lt;/strong&gt; View and manage on-call schedules in Grafana OnCall.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get shift details:&lt;/strong&gt; Retrieve detailed information about specific on-call shifts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get current on-call users:&lt;/strong&gt; See which users are currently on call for a schedule.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List teams and users:&lt;/strong&gt; View all OnCall teams and users.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List alert groups:&lt;/strong&gt; View and filter alert groups from Grafana OnCall by various criteria including state, integration, labels, and time range.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get alert group details:&lt;/strong&gt; Retrieve detailed information about a specific alert group by its ID.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Admin&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List teams:&lt;/strong&gt; View all configured teams in Grafana.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List Users:&lt;/strong&gt; View all users in an organization in Grafana.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Navigation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Generate deeplinks:&lt;/strong&gt; Create accurate deeplink URLs for Grafana resources instead of relying on LLM URL guessing. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Dashboard links:&lt;/strong&gt; Generate direct links to dashboards using their UID (e.g., &lt;code&gt;http://localhost:3000/d/dashboard-uid&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Panel links:&lt;/strong&gt; Create links to specific panels within dashboards with viewPanel parameter (e.g., &lt;code&gt;http://localhost:3000/d/dashboard-uid?viewPanel=5&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Explore links:&lt;/strong&gt; Generate links to Grafana Explore with pre-configured datasources (e.g., &lt;code&gt;http://localhost:3000/explore?left={"datasource":"prometheus-uid"}&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Time range support:&lt;/strong&gt; Add time range parameters to links (&lt;code&gt;from=now-1h&amp;amp;to=now&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Custom parameters:&lt;/strong&gt; Include additional query parameters like dashboard variables or refresh intervals&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Annotations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Get Annotations:&lt;/strong&gt; Query annotations with filters. Supports time range, dashboard UID, tags, and match mode.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create Annotation:&lt;/strong&gt; Create a new annotation on a dashboard or panel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create Graphite Annotation:&lt;/strong&gt; Create annotations using Graphite format (&lt;code&gt;what&lt;/code&gt;, &lt;code&gt;when&lt;/code&gt;, &lt;code&gt;tags&lt;/code&gt;, &lt;code&gt;data&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update Annotation:&lt;/strong&gt; Replace all fields of an existing annotation (full update).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patch Annotation:&lt;/strong&gt; Update only specific fields of an annotation (partial update).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get Annotation Tags:&lt;/strong&gt; List available annotation tags with optional filtering.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The list of tools is configurable, so you can choose which tools you want to make available to the MCP client. This is useful if you don't use certain functionality or if you don't want to take up too much of the context window. To disable a category of tools, use the &lt;code&gt;--disable-&amp;lt;category&amp;gt;&lt;/code&gt; flag when starting the server. For example, to disable the OnCall tools, use &lt;code&gt;--disable-oncall&lt;/code&gt;, or to disable navigation deeplink generation, use &lt;code&gt;--disable-navigation&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;RBAC Permissions&lt;/h4&gt; 
&lt;p&gt;Each tool requires specific RBAC permissions to function properly. When creating a service account for the MCP server, ensure it has the necessary permissions based on which tools you plan to use. The permissions listed are the minimum required actions - you may also need appropriate scopes (e.g., &lt;code&gt;datasources:*&lt;/code&gt;, &lt;code&gt;dashboards:*&lt;/code&gt;, &lt;code&gt;folders:*&lt;/code&gt;) depending on your use case.&lt;/p&gt; 
&lt;p&gt;Tip: If you're not familiar with Grafana RBAC or you want a quicker, simpler setup instead of configuring many granular scopes, you can assign a built-in role such as &lt;code&gt;Editor&lt;/code&gt; to the service account. The &lt;code&gt;Editor&lt;/code&gt; role grants broad read/write access that will allow most MCP server operations; it is less granular (and therefore less restrictive) than manually-applied scopes, so use it only when convenience is more important than strict least-privilege access.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Grafana Incident and Sift tools use basic Grafana roles instead of fine-grained RBAC permissions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Viewer role:&lt;/strong&gt; Required for read-only operations (list incidents, get investigations)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Editor role:&lt;/strong&gt; Required for write operations (create incidents, modify investigations)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about Grafana RBAC, see the &lt;a href="https://grafana.com/docs/grafana/latest/administration/roles-and-permissions/access-control/"&gt;official documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;RBAC Scopes&lt;/h4&gt; 
&lt;p&gt;Scopes define the specific resources that permissions apply to. Each action requires both the appropriate permission and scope combination.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Common Scope Patterns:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Broad access:&lt;/strong&gt; Use &lt;code&gt;*&lt;/code&gt; wildcards for organization-wide access&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;datasources:*&lt;/code&gt; - Access to all datasources&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;dashboards:*&lt;/code&gt; - Access to all dashboards&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;folders:*&lt;/code&gt; - Access to all folders&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;teams:*&lt;/code&gt; - Access to all teams&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Limited access:&lt;/strong&gt; Use specific UIDs or IDs to restrict access to individual resources&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt; - Access only to a specific Prometheus datasource&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt; - Access only to dashboard with UID &lt;code&gt;abc123&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;folders:uid:xyz789&lt;/code&gt; - Access only to folder with UID &lt;code&gt;xyz789&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;teams&lt;span&gt;üÜî&lt;/span&gt;5&lt;/code&gt; - Access only to team with ID &lt;code&gt;5&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;global.users&lt;span&gt;üÜî&lt;/span&gt;123&lt;/code&gt; - Access only to user with ID &lt;code&gt;123&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Full MCP server access:&lt;/strong&gt; Grant broad permissions for all tools&lt;/p&gt; &lt;pre&gt;&lt;code&gt;datasources:* (datasources:read, datasources:query)
dashboards:* (dashboards:read, dashboards:create, dashboards:write)
folders:* (for dashboard creation and alert rules)
teams:* (teams:read)
global.users:* (users:read)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Limited datasource access:&lt;/strong&gt; Only query specific Prometheus and Loki instances&lt;/p&gt; &lt;pre&gt;&lt;code&gt;datasources:uid:prometheus-prod (datasources:query)
datasources:uid:loki-prod (datasources:query)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dashboard-specific access:&lt;/strong&gt; Read only specific dashboards&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dashboards:uid:monitoring-dashboard (dashboards:read)
dashboards:uid:alerts-dashboard (dashboards:read)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Tool&lt;/th&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Required RBAC Permissions&lt;/th&gt; 
   &lt;th&gt;Required Scopes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_teams&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;List all teams&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;teams:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;teams:*&lt;/code&gt; or &lt;code&gt;teams&lt;span&gt;üÜî&lt;/span&gt;1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_users_by_org&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;List all users in an organization&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;users:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;global.users:*&lt;/code&gt; or &lt;code&gt;global.users&lt;span&gt;üÜî&lt;/span&gt;123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;search_dashboards&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Search&lt;/td&gt; 
   &lt;td&gt;Search for dashboards&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:*&lt;/code&gt; or &lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_dashboard_by_uid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Get a dashboard by uid&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;update_dashboard&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Update or create a new dashboard&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:create&lt;/code&gt;, &lt;code&gt;dashboards:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:*&lt;/code&gt;, &lt;code&gt;folders:*&lt;/code&gt; or &lt;code&gt;folders:uid:xyz789&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_dashboard_panel_queries&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Get panel title, queries, datasource UID and type from a dashboard&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_dashboard_property&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Extract specific parts of a dashboard using JSONPath expressions&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_dashboard_summary&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Get a compact summary of a dashboard without full JSON&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_datasources&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Datasources&lt;/td&gt; 
   &lt;td&gt;List datasources&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_datasource_by_uid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Datasources&lt;/td&gt; 
   &lt;td&gt;Get a datasource by uid&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_datasource_by_name&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Datasources&lt;/td&gt; 
   &lt;td&gt;Get a datasource by name&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:*&lt;/code&gt; or &lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;query_prometheus&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;Execute a query against a Prometheus datasource&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_prometheus_metric_metadata&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;List metric metadata&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_prometheus_metric_names&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;List available metric names&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_prometheus_label_names&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;List label names matching a selector&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_prometheus_label_values&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;List values for a specific label&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_incidents&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Incident&lt;/td&gt; 
   &lt;td&gt;List incidents in Grafana Incident&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;create_incident&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Incident&lt;/td&gt; 
   &lt;td&gt;Create an incident in Grafana Incident&lt;/td&gt; 
   &lt;td&gt;Editor role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;add_activity_to_incident&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Incident&lt;/td&gt; 
   &lt;td&gt;Add an activity item to an incident in Grafana Incident&lt;/td&gt; 
   &lt;td&gt;Editor role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_incident&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Incident&lt;/td&gt; 
   &lt;td&gt;Get a single incident by ID&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;query_loki_logs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Loki&lt;/td&gt; 
   &lt;td&gt;Query and retrieve logs using LogQL (either log or metric queries)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_loki_label_names&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Loki&lt;/td&gt; 
   &lt;td&gt;List all available label names in logs&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_loki_label_values&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Loki&lt;/td&gt; 
   &lt;td&gt;List values for a specific log label&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;query_loki_stats&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Loki&lt;/td&gt; 
   &lt;td&gt;Get statistics about log streams&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_alert_rules&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Alerting&lt;/td&gt; 
   &lt;td&gt;List alert rules&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;alert.rules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;folders:*&lt;/code&gt; or &lt;code&gt;folders:uid:alerts-folder&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_alert_rule_by_uid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Alerting&lt;/td&gt; 
   &lt;td&gt;Get alert rule by UID&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;alert.rules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;folders:uid:alerts-folder&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_contact_points&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Alerting&lt;/td&gt; 
   &lt;td&gt;List notification contact points&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;alert.notifications:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Global scope&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_oncall_schedules&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;List schedules from Grafana OnCall&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.schedules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_oncall_shift&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;Get details for a specific OnCall shift&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.schedules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_current_oncall_users&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;Get users currently on-call for a specific schedule&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.schedules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_oncall_teams&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;List teams from Grafana OnCall&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.user-settings:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_oncall_users&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;List users from Grafana OnCall&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.user-settings:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_alert_groups&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;List alert groups from Grafana OnCall with filtering options&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.alert-groups:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_alert_group&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;Get a specific alert group from Grafana OnCall by its ID&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.alert-groups:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_sift_investigation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Retrieve an existing Sift investigation by its UUID&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_sift_analysis&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Retrieve a specific analysis from a Sift investigation&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_sift_investigations&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Retrieve a list of Sift investigations with an optional limit&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;find_error_pattern_logs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Finds elevated error patterns in Loki logs.&lt;/td&gt; 
   &lt;td&gt;Editor role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;find_slow_requests&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Finds slow requests from the relevant tempo datasources.&lt;/td&gt; 
   &lt;td&gt;Editor role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_pyroscope_label_names&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pyroscope&lt;/td&gt; 
   &lt;td&gt;List label names matching a selector&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:pyroscope-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_pyroscope_label_values&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pyroscope&lt;/td&gt; 
   &lt;td&gt;List label values matching a selector for a label name&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:pyroscope-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_pyroscope_profile_types&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pyroscope&lt;/td&gt; 
   &lt;td&gt;List available profile types&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:pyroscope-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;fetch_pyroscope_profile&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pyroscope&lt;/td&gt; 
   &lt;td&gt;Fetches a profile in DOT format for analysis&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:pyroscope-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_assertions&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Asserts&lt;/td&gt; 
   &lt;td&gt;Get assertion summary for a given entity&lt;/td&gt; 
   &lt;td&gt;Plugin-specific permissions&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;generate_deeplink&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Navigation&lt;/td&gt; 
   &lt;td&gt;Generate accurate deeplink URLs for Grafana resources&lt;/td&gt; 
   &lt;td&gt;None (read-only URL generation)&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_annotations&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Fetch annotations with filters&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt; or &lt;code&gt;annotations&lt;span&gt;üÜî&lt;/span&gt;123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;create_annotation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Create a new annotation on a dashboard or panel&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;create_graphite_annotation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Create an annotation using Graphite format&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;update_annotation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Replace all fields of an annotation (full update)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;patch_annotation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Update only specific fields of an annotation (partial update)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_annotation_tags&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;List annotation tags with optional filtering&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;pre&gt;&lt;code&gt;                                          |
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;CLI Flags Reference&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;mcp-grafana&lt;/code&gt; binary supports various command-line flags for configuration:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Transport Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-t, --transport&lt;/code&gt;: Transport type (&lt;code&gt;stdio&lt;/code&gt;, &lt;code&gt;sse&lt;/code&gt;, or &lt;code&gt;streamable-http&lt;/code&gt;) - default: &lt;code&gt;stdio&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--address&lt;/code&gt;: The host and port for SSE/streamable-http server - default: &lt;code&gt;localhost:8000&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--base-path&lt;/code&gt;: Base path for the SSE/streamable-http server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--endpoint-path&lt;/code&gt;: Endpoint path for the streamable-http server - default: &lt;code&gt;/&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Debug and Logging:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt;: Enable debug mode for detailed HTTP request/response logging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Tool Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--enabled-tools&lt;/code&gt;: Comma-separated list of enabled categories - default: all categories enabled - example: "loki,datasources"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-search&lt;/code&gt;: Disable search tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-datasource&lt;/code&gt;: Disable datasource tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-incident&lt;/code&gt;: Disable incident tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-prometheus&lt;/code&gt;: Disable prometheus tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-write&lt;/code&gt;: Disable write tools (create/update operations)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-loki&lt;/code&gt;: Disable loki tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-alerting&lt;/code&gt;: Disable alerting tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-dashboard&lt;/code&gt;: Disable dashboard tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-oncall&lt;/code&gt;: Disable oncall tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-asserts&lt;/code&gt;: Disable asserts tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-sift&lt;/code&gt;: Disable sift tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-admin&lt;/code&gt;: Disable admin tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-pyroscope&lt;/code&gt;: Disable pyroscope tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-navigation&lt;/code&gt;: Disable navigation tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Read-Only Mode&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;--disable-write&lt;/code&gt; flag provides a way to run the MCP server in read-only mode, preventing any write operations to your Grafana instance. This is useful for scenarios where you want to provide safe, read-only access such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Using service accounts with limited read-only permissions&lt;/li&gt; 
 &lt;li&gt;Providing AI assistants with observability data without modification capabilities&lt;/li&gt; 
 &lt;li&gt;Running in production environments where write access should be restricted&lt;/li&gt; 
 &lt;li&gt;Testing and development scenarios where you want to prevent accidental modifications&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When &lt;code&gt;--disable-write&lt;/code&gt; is enabled, the following write operations are disabled:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Dashboard Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;update_dashboard&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Folder Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;create_folder&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Incident Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;create_incident&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;add_activity_to_incident&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Alerting Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;create_alert_rule&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;update_alert_rule&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;delete_alert_rule&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Annotation Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;create_annotation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;create_graphite_annotation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;update_annotation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;patch_annotation&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Sift Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;find_error_pattern_logs&lt;/code&gt; (creates investigations)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;find_slow_requests&lt;/code&gt; (creates investigations)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All read operations remain available, allowing you to query dashboards, run PromQL/LogQL queries, list resources, and retrieve data.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Client TLS Configuration (for Grafana connections):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--tls-cert-file&lt;/code&gt;: Path to TLS certificate file for client authentication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-key-file&lt;/code&gt;: Path to TLS private key file for client authentication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-ca-file&lt;/code&gt;: Path to TLS CA certificate file for server verification&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-skip-verify&lt;/code&gt;: Skip TLS certificate verification (insecure)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Server TLS Configuration (streamable-http transport only):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--server.tls-cert-file&lt;/code&gt;: Path to TLS certificate file for server HTTPS&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--server.tls-key-file&lt;/code&gt;: Path to TLS private key file for server HTTPS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;This MCP server works with both local Grafana instances and Grafana Cloud. For Grafana Cloud, use your instance URL (e.g., &lt;code&gt;https://myinstance.grafana.net&lt;/code&gt;) instead of &lt;code&gt;http://localhost:3000&lt;/code&gt; in the configuration examples below.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;If using service account token authentication, create a service account in Grafana with enough permissions to use the tools you want to use, generate a service account token, and copy it to the clipboard for use in the configuration file. Follow the &lt;a href="https://grafana.com/docs/grafana/latest/administration/service-accounts/#add-a-token-to-a-service-account-in-grafana"&gt;Grafana service account documentation&lt;/a&gt; for details on creating service account tokens. Tip: If you're not comfortable configuring fine-grained RBAC scopes, a simpler (but less restrictive) option is to assign the built-in &lt;code&gt;Editor&lt;/code&gt; role to the service account. This grants broad read/write access that covers most MCP server operations ‚Äî use it when convenience outweighs strict least-privilege requirements.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The environment variable &lt;code&gt;GRAFANA_API_KEY&lt;/code&gt; is deprecated and will be removed in a future version. Please migrate to using &lt;code&gt;GRAFANA_SERVICE_ACCOUNT_TOKEN&lt;/code&gt; instead. The old variable name will continue to work for backward compatibility but will show deprecation warnings.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Multi-Organization Support&lt;/h3&gt; 
&lt;p&gt;You can specify which organization to interact with using either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Environment variable:&lt;/strong&gt; Set &lt;code&gt;GRAFANA_ORG_ID&lt;/code&gt; to the numeric organization ID&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP header:&lt;/strong&gt; Set &lt;code&gt;X-Grafana-Org-Id&lt;/code&gt; when using SSE or streamable HTTP transports (header takes precedence over environment variable - meaning you can set a default org as well).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When an organization ID is provided, the MCP server will set the &lt;code&gt;X-Grafana-Org-Id&lt;/code&gt; header on all requests to Grafana, ensuring that operations are performed within the specified organization context.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example with organization ID:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "mcp-grafana",
      "args": [],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",
        "GRAFANA_USERNAME": "&amp;lt;your username&amp;gt;",
        "GRAFANA_PASSWORD": "&amp;lt;your password&amp;gt;",
        "GRAFANA_ORG_ID": "2"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;You have several options to install &lt;code&gt;mcp-grafana&lt;/code&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker image&lt;/strong&gt;: Use the pre-built Docker image from Docker Hub.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: The Docker image's entrypoint is configured to run the MCP server in SSE mode by default, but most users will want to use STDIO mode for direct integration with AI assistants like Claude Desktop:&lt;/p&gt; 
    &lt;ol&gt; 
     &lt;li&gt;&lt;strong&gt;STDIO Mode&lt;/strong&gt;: For stdio mode you must explicitly override the default with &lt;code&gt;-t stdio&lt;/code&gt; and include the &lt;code&gt;-i&lt;/code&gt; flag to keep stdin open:&lt;/li&gt; 
    &lt;/ol&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull mcp/grafana
# For local Grafana:
docker run --rm -i -e GRAFANA_URL=http://localhost:3000 -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; mcp/grafana -t stdio
# For Grafana Cloud:
docker run --rm -i -e GRAFANA_URL=https://myinstance.grafana.net -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; mcp/grafana -t stdio
&lt;/code&gt;&lt;/pre&gt; 
    &lt;ol start="2"&gt; 
     &lt;li&gt;&lt;strong&gt;SSE Mode&lt;/strong&gt;: In this mode, the server runs as an HTTP server that clients connect to. You must expose port 8000 using the &lt;code&gt;-p&lt;/code&gt; flag:&lt;/li&gt; 
    &lt;/ol&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull mcp/grafana
docker run --rm -p 8000:8000 -e GRAFANA_URL=http://localhost:3000 -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; mcp/grafana
&lt;/code&gt;&lt;/pre&gt; 
    &lt;ol start="3"&gt; 
     &lt;li&gt;&lt;strong&gt;Streamable HTTP Mode&lt;/strong&gt;: In this mode, the server operates as an independent process that can handle multiple client connections. You must expose port 8000 using the &lt;code&gt;-p&lt;/code&gt; flag: For this mode you must explicitly override the default with &lt;code&gt;-t streamable-http&lt;/code&gt;&lt;/li&gt; 
    &lt;/ol&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull mcp/grafana
docker run --rm -p 8000:8000 -e GRAFANA_URL=http://localhost:3000 -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; mcp/grafana -t streamable-http
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For HTTPS streamable HTTP mode with server TLS certificates:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull mcp/grafana
docker run --rm -p 8443:8443 \
  -v /path/to/certs:/certs:ro \
  -e GRAFANA_URL=http://localhost:3000 \
  -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; \
  mcp/grafana \
  -t streamable-http \
  -addr :8443 \
  --server.tls-cert-file /certs/server.crt \
  --server.tls-key-file /certs/server.key
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download binary&lt;/strong&gt;: Download the latest release of &lt;code&gt;mcp-grafana&lt;/code&gt; from the &lt;a href="https://github.com/grafana/mcp-grafana/releases"&gt;releases page&lt;/a&gt; and place it in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Build from source&lt;/strong&gt;: If you have a Go toolchain installed you can also build and install it from source, using the &lt;code&gt;GOBIN&lt;/code&gt; environment variable to specify the directory where the binary should be installed. This should also be in your &lt;code&gt;PATH&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;GOBIN="$HOME/go/bin" go install github.com/grafana/mcp-grafana/cmd/mcp-grafana@latest
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deploy to Kubernetes using Helm&lt;/strong&gt;: use the &lt;a href="https://github.com/grafana/helm-charts/tree/main/charts/grafana-mcp"&gt;Helm chart from the Grafana helm-charts repository&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;helm repo add grafana https://grafana.github.io/helm-charts
helm install --set grafana.apiKey=&amp;lt;Grafana_ApiKey&amp;gt; --set grafana.url=&amp;lt;GrafanaUrl&amp;gt; my-release grafana/grafana-mcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Add the server configuration to your client configuration file. For example, for Claude Desktop:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;If using the binary:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "mcp-grafana",
      "args": [],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",  // Or "https://myinstance.grafana.net" for Grafana Cloud
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;",
        // If using username/password authentication
        "GRAFANA_USERNAME": "&amp;lt;your username&amp;gt;",
        "GRAFANA_PASSWORD": "&amp;lt;your password&amp;gt;",
        // Optional: specify organization ID for multi-org support
        "GRAFANA_ORG_ID": "1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: if you see &lt;code&gt;Error: spawn mcp-grafana ENOENT&lt;/code&gt; in Claude Desktop, you need to specify the full path to &lt;code&gt;mcp-grafana&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;If using Docker:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "docker",
      "args": [
        "run",
        "--rm",
        "-i",
        "-e",
        "GRAFANA_URL",
        "-e",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN",
        "mcp/grafana",
        "-t",
        "stdio"
      ],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",  // Or "https://myinstance.grafana.net" for Grafana Cloud
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;",
        // If using username/password authentication
        "GRAFANA_USERNAME": "&amp;lt;your username&amp;gt;",
        "GRAFANA_PASSWORD": "&amp;lt;your password&amp;gt;",
        // Optional: specify organization ID for multi-org support
        "GRAFANA_ORG_ID": "1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: The &lt;code&gt;-t stdio&lt;/code&gt; argument is essential here because it overrides the default SSE mode in the Docker image.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Using VSCode with remote MCP server&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you're using VSCode and running the MCP server in SSE mode (which is the default when using the Docker image without overriding the transport), make sure your &lt;code&gt;.vscode/settings.json&lt;/code&gt; includes the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"mcp": {
  "servers": {
    "grafana": {
      "type": "sse",
      "url": "http://localhost:8000/sse"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For HTTPS streamable HTTP mode with server TLS certificates:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"mcp": {
  "servers": {
    "grafana": {
      "type": "sse",
      "url": "https://localhost:8443/sse"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debug Mode&lt;/h3&gt; 
&lt;p&gt;You can enable debug mode for the Grafana transport by adding the &lt;code&gt;-debug&lt;/code&gt; flag to the command. This will provide detailed logging of HTTP requests and responses between the MCP server and the Grafana API, which can be helpful for troubleshooting.&lt;/p&gt; 
&lt;p&gt;To use debug mode with the Claude Desktop configuration, update your config as follows:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If using the binary:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "mcp-grafana",
      "args": ["-debug"],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",  // Or "https://myinstance.grafana.net" for Grafana Cloud
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;If using Docker:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "docker",
      "args": [
        "run",
        "--rm",
        "-i",
        "-e",
        "GRAFANA_URL",
        "-e",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN",
        "mcp/grafana",
        "-t",
        "stdio",
        "-debug"
      ],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",  // Or "https://myinstance.grafana.net" for Grafana Cloud
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: As with the standard configuration, the &lt;code&gt;-t stdio&lt;/code&gt; argument is required to override the default SSE mode in the Docker image.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;TLS Configuration&lt;/h3&gt; 
&lt;p&gt;If your Grafana instance is behind mTLS or requires custom TLS certificates, you can configure the MCP server to use custom certificates. The server supports the following TLS configuration options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--tls-cert-file&lt;/code&gt;: Path to TLS certificate file for client authentication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-key-file&lt;/code&gt;: Path to TLS private key file for client authentication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-ca-file&lt;/code&gt;: Path to TLS CA certificate file for server verification&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-skip-verify&lt;/code&gt;: Skip TLS certificate verification (insecure, use only for testing)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Example with client certificate authentication:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "mcp-grafana",
      "args": [
        "--tls-cert-file",
        "/path/to/client.crt",
        "--tls-key-file",
        "/path/to/client.key",
        "--tls-ca-file",
        "/path/to/ca.crt"
      ],
      "env": {
        "GRAFANA_URL": "https://secure-grafana.example.com",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example with Docker:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "docker",
      "args": [
        "run",
        "--rm",
        "-i",
        "-v",
        "/path/to/certs:/certs:ro",
        "-e",
        "GRAFANA_URL",
        "-e",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN",
        "mcp/grafana",
        "-t",
        "stdio",
        "--tls-cert-file",
        "/certs/client.crt",
        "--tls-key-file",
        "/certs/client.key",
        "--tls-ca-file",
        "/certs/ca.crt"
      ],
      "env": {
        "GRAFANA_URL": "https://secure-grafana.example.com",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The TLS configuration is applied to all HTTP clients used by the MCP server, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The main Grafana OpenAPI client&lt;/li&gt; 
 &lt;li&gt;Prometheus datasource clients&lt;/li&gt; 
 &lt;li&gt;Loki datasource clients&lt;/li&gt; 
 &lt;li&gt;Incident management clients&lt;/li&gt; 
 &lt;li&gt;Sift investigation clients&lt;/li&gt; 
 &lt;li&gt;Alerting clients&lt;/li&gt; 
 &lt;li&gt;Asserts clients&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Direct CLI Usage Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;For testing with self-signed certificates:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./mcp-grafana --tls-skip-verify -debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With client certificate authentication:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./mcp-grafana \
  --tls-cert-file /path/to/client.crt \
  --tls-key-file /path/to/client.key \
  --tls-ca-file /path/to/ca.crt \
  -debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With custom CA certificate only:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./mcp-grafana --tls-ca-file /path/to/ca.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Programmatic Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you're using this library programmatically, you can also create TLS-enabled context functions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Using struct literals
tlsConfig := &amp;amp;mcpgrafana.TLSConfig{
    CertFile: "/path/to/client.crt",
    KeyFile:  "/path/to/client.key",
    CAFile:   "/path/to/ca.crt",
}
grafanaConfig := mcpgrafana.GrafanaConfig{
    Debug:     true,
    TLSConfig: tlsConfig,
}
contextFunc := mcpgrafana.ComposedStdioContextFunc(grafanaConfig)

// Or inline
grafanaConfig := mcpgrafana.GrafanaConfig{
    Debug: true,
    TLSConfig: &amp;amp;mcpgrafana.TLSConfig{
        CertFile: "/path/to/client.crt",
        KeyFile:  "/path/to/client.key",
        CAFile:   "/path/to/ca.crt",
    },
}
contextFunc := mcpgrafana.ComposedStdioContextFunc(grafanaConfig)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Server TLS Configuration (Streamable HTTP Transport Only)&lt;/h3&gt; 
&lt;p&gt;When using the streamable HTTP transport (&lt;code&gt;-t streamable-http&lt;/code&gt;), you can configure the MCP server to serve HTTPS instead of HTTP. This is useful when you need to secure the connection between your MCP client and the server itself.&lt;/p&gt; 
&lt;p&gt;The server supports the following TLS configuration options for the streamable HTTP transport:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--server.tls-cert-file&lt;/code&gt;: Path to TLS certificate file for server HTTPS (required for TLS)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--server.tls-key-file&lt;/code&gt;: Path to TLS private key file for server HTTPS (required for TLS)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These flags are completely separate from the client TLS flags documented above. The client TLS flags configure how the MCP server connects to Grafana, while these server TLS flags configure how clients connect to the MCP server when using streamable HTTP transport.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example with HTTPS streamable HTTP server:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./mcp-grafana \
  -t streamable-http \
  --server.tls-cert-file /path/to/server.crt \
  --server.tls-key-file /path/to/server.key \
  -addr :8443
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This would start the MCP server on HTTPS port 8443. Clients would then connect to &lt;code&gt;https://localhost:8443/&lt;/code&gt; instead of &lt;code&gt;http://localhost:8000/&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docker example with server TLS:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -p 8443:8443 \
  -v /path/to/certs:/certs:ro \
  -e GRAFANA_URL=http://localhost:3000 \
  -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; \
  mcp/grafana \
  -t streamable-http \
  -addr :8443 \
  --server.tls-cert-file /certs/server.crt \
  --server.tls-key-file /certs/server.key
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Health Check Endpoint&lt;/h3&gt; 
&lt;p&gt;When using the SSE (&lt;code&gt;-t sse&lt;/code&gt;) or streamable HTTP (&lt;code&gt;-t streamable-http&lt;/code&gt;) transports, the MCP server exposes a health check endpoint at &lt;code&gt;/healthz&lt;/code&gt;. This endpoint can be used by load balancers, monitoring systems, or orchestration platforms to verify that the server is running and accepting connections.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Endpoint:&lt;/strong&gt; &lt;code&gt;GET /healthz&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Response:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Status Code: &lt;code&gt;200 OK&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Body: &lt;code&gt;ok&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Example usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For streamable HTTP or SSE transport on default port
curl http://localhost:8000/healthz

# With custom address
curl http://localhost:9090/healthz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The health check endpoint is only available when using SSE or streamable HTTP transports. It is not available when using the stdio transport (&lt;code&gt;-t stdio&lt;/code&gt;), as stdio does not expose an HTTP server.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Grafana Version Compatibility&lt;/h3&gt; 
&lt;p&gt;If you encounter the following error when using datasource-related tools:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;get datasource by uid : [GET /datasources/uid/{uid}][400] getDataSourceByUidBadRequest {"message":"id is invalid"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This typically indicates that you are using a Grafana version earlier than 9.0. The &lt;code&gt;/datasources/uid/{uid}&lt;/code&gt; API endpoint was introduced in Grafana 9.0, and datasource operations will fail on earlier versions.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Upgrade your Grafana instance to version 9.0 or later to resolve this issue.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please open an issue or submit a pull request if you have any suggestions or improvements.&lt;/p&gt; 
&lt;p&gt;This project is written in Go. Install Go following the instructions for your platform.&lt;/p&gt; 
&lt;p&gt;To run the server locally in STDIO mode (which is the default for local development), use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run the server locally in SSE mode, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go run ./cmd/mcp-grafana --transport sse
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also run the server using the SSE transport inside a custom built Docker image. Just like the published Docker image, this custom image's entrypoint defaults to SSE mode. To build the image, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make build-image
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And to run the image in SSE mode (the default), use:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -it --rm -p 8000:8000 mcp-grafana:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you need to run it in STDIO mode instead, override the transport setting:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -it --rm mcp-grafana:latest -t stdio
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;p&gt;There are three types of tests available:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Unit Tests (no external dependencies required):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test-unit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also run unit tests with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Integration Tests (requires docker containers to be up and running):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test-integration
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Cloud Tests (requires cloud Grafana instance and credentials):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test-cloud
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Cloud tests are automatically configured in CI. For local development, you'll need to set up your own Grafana Cloud instance and credentials.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;More comprehensive integration tests will require a Grafana instance to be running locally on port 3000; you can start one with Docker Compose:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The integration tests can be run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're adding more tools, please add integration tests for them. The existing tests should be a good starting point.&lt;/p&gt; 
&lt;h3&gt;Linting&lt;/h3&gt; 
&lt;p&gt;To lint the code, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make lint
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This includes a custom linter that checks for unescaped commas in &lt;code&gt;jsonschema&lt;/code&gt; struct tags. The commas in &lt;code&gt;description&lt;/code&gt; fields must be escaped with &lt;code&gt;\\,&lt;/code&gt; to prevent silent truncation. You can run just this linter with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make lint-jsonschema
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/grafana/mcp-grafana/main/internal/linter/jsonschema/README.md"&gt;JSONSchema Linter documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/grafana/mcp-grafana/main/LICENSE"&gt;Apache License, Version 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gorilla/mux</title>
      <link>https://github.com/gorilla/mux</link>
      <description>&lt;p&gt;Package gorilla/mux is a powerful HTTP router and URL matcher for building Go web servers with ü¶ç&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;gorilla/mux&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/gorilla/mux/actions/workflows/test.yml/badge.svg?sanitize=true" alt="testing" /&gt; &lt;a href="https://codecov.io/github/gorilla/mux"&gt;&lt;img src="https://codecov.io/github/gorilla/mux/branch/main/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/gorilla/mux"&gt;&lt;img src="https://godoc.org/github.com/gorilla/mux?status.svg?sanitize=true" alt="godoc" /&gt;&lt;/a&gt; &lt;a href="https://sourcegraph.com/github.com/gorilla/mux?badge"&gt;&lt;img src="https://sourcegraph.com/github.com/gorilla/mux/-/badge.svg?sanitize=true" alt="sourcegraph" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/gorilla/.github/assets/53367916/d92caabf-98e0-473e-bfbf-ab554ba435e5" alt="Gorilla Logo" /&gt;&lt;/p&gt; 
&lt;p&gt;Package &lt;code&gt;gorilla/mux&lt;/code&gt; implements a request router and dispatcher for matching incoming requests to their respective handler.&lt;/p&gt; 
&lt;p&gt;The name mux stands for "HTTP request multiplexer". Like the standard &lt;code&gt;http.ServeMux&lt;/code&gt;, &lt;code&gt;mux.Router&lt;/code&gt; matches incoming requests against a list of registered routes and calls a handler for the route that matches the URL or other conditions. The main features are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;It implements the &lt;code&gt;http.Handler&lt;/code&gt; interface so it is compatible with the standard &lt;code&gt;http.ServeMux&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Requests can be matched based on URL host, path, path prefix, schemes, header and query values, HTTP methods or using custom matchers.&lt;/li&gt; 
 &lt;li&gt;URL hosts, paths and query values can have variables with an optional regular expression.&lt;/li&gt; 
 &lt;li&gt;Registered URLs can be built, or "reversed", which helps maintaining references to resources.&lt;/li&gt; 
 &lt;li&gt;Routes can be used as subrouters: nested routes are only tested if the parent route matches. This is useful to define groups of routes that share common conditions like a host, a path prefix or other repeated attributes. As a bonus, this optimizes request matching.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#install"&gt;Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#matching-routes"&gt;Matching Routes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#static-files"&gt;Static Files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#serving-single-page-applications"&gt;Serving Single Page Applications&lt;/a&gt; (e.g. React, Vue, Ember.js, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#registered-urls"&gt;Registered URLs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#walking-routes"&gt;Walking Routes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#graceful-shutdown"&gt;Graceful Shutdown&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#middleware"&gt;Middleware&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#handling-cors-requests"&gt;Handling CORS Requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#testing-handlers"&gt;Testing Handlers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#full-example"&gt;Full Example&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;With a &lt;a href="https://golang.org/doc/install#testing"&gt;correctly configured&lt;/a&gt; Go toolchain:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go get -u github.com/gorilla/mux
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Let's start registering a couple of URL paths and handlers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func main() {
    r := mux.NewRouter()
    r.HandleFunc("/", HomeHandler)
    r.HandleFunc("/products", ProductsHandler)
    r.HandleFunc("/articles", ArticlesHandler)
    http.Handle("/", r)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here we register three routes mapping URL paths to handlers. This is equivalent to how &lt;code&gt;http.HandleFunc()&lt;/code&gt; works: if an incoming request URL matches one of the paths, the corresponding handler is called passing (&lt;code&gt;http.ResponseWriter&lt;/code&gt;, &lt;code&gt;*http.Request&lt;/code&gt;) as parameters.&lt;/p&gt; 
&lt;p&gt;Paths can have variables. They are defined using the format &lt;code&gt;{name}&lt;/code&gt; or &lt;code&gt;{name:pattern}&lt;/code&gt;. If a regular expression pattern is not defined, the matched variable will be anything until the next slash. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
r.HandleFunc("/products/{key}", ProductHandler)
r.HandleFunc("/articles/{category}/", ArticlesCategoryHandler)
r.HandleFunc("/articles/{category}/{id:[0-9]+}", ArticleHandler)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The names are used to create a map of route variables which can be retrieved calling &lt;code&gt;mux.Vars()&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func ArticlesCategoryHandler(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    w.WriteHeader(http.StatusOK)
    fmt.Fprintf(w, "Category: %v\n", vars["category"])
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And this is all you need to know about the basic usage. More advanced options are explained below.&lt;/p&gt; 
&lt;h3&gt;Matching Routes&lt;/h3&gt; 
&lt;p&gt;Routes can also be restricted to a domain or subdomain. Just define a host pattern to be matched. They can also have variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
// Only matches if domain is "www.example.com".
r.Host("www.example.com")
// Matches a dynamic subdomain.
r.Host("{subdomain:[a-z]+}.example.com")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are several other matchers that can be added. To match path prefixes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r.PathPrefix("/products/")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...or HTTP methods:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r.Methods("GET", "POST")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...or URL schemes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r.Schemes("https")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...or header values:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r.Headers("X-Requested-With", "XMLHttpRequest")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...or query values:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r.Queries("key", "value")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...or to use a custom matcher function:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r.MatcherFunc(func(r *http.Request, rm *RouteMatch) bool {
    return r.ProtoMajor == 0
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...and finally, it is possible to combine several matchers in a single route:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r.HandleFunc("/products", ProductsHandler).
  Host("www.example.com").
  Methods("GET").
  Schemes("http")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Routes are tested in the order they were added to the router. If two routes match, the first one wins:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
r.HandleFunc("/specific", specificHandler)
r.PathPrefix("/").Handler(catchAllHandler)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Setting the same matching conditions again and again can be boring, so we have a way to group several routes that share the same requirements. We call it "subrouting".&lt;/p&gt; 
&lt;p&gt;For example, let's say we have several URLs that should only match when the host is &lt;code&gt;www.example.com&lt;/code&gt;. Create a route for that host and get a "subrouter" from it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
s := r.Host("www.example.com").Subrouter()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then register routes in the subrouter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;s.HandleFunc("/products/", ProductsHandler)
s.HandleFunc("/products/{key}", ProductHandler)
s.HandleFunc("/articles/{category}/{id:[0-9]+}", ArticleHandler)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The three URL paths we registered above will only be tested if the domain is &lt;code&gt;www.example.com&lt;/code&gt;, because the subrouter is tested first. This is not only convenient, but also optimizes request matching. You can create subrouters combining any attribute matchers accepted by a route.&lt;/p&gt; 
&lt;p&gt;Subrouters can be used to create domain or path "namespaces": you define subrouters in a central place and then parts of the app can register its paths relatively to a given subrouter.&lt;/p&gt; 
&lt;p&gt;There's one more thing about subroutes. When a subrouter has a path prefix, the inner routes use it as base for their paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
s := r.PathPrefix("/products").Subrouter()
// "/products/"
s.HandleFunc("/", ProductsHandler)
// "/products/{key}/"
s.HandleFunc("/{key}/", ProductHandler)
// "/products/{key}/details"
s.HandleFunc("/{key}/details", ProductDetailsHandler)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Static Files&lt;/h3&gt; 
&lt;p&gt;Note that the path provided to &lt;code&gt;PathPrefix()&lt;/code&gt; represents a "wildcard": calling &lt;code&gt;PathPrefix("/static/").Handler(...)&lt;/code&gt; means that the handler will be passed any request that matches "/static/*". This makes it easy to serve static files with mux:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func main() {
    var dir string

    flag.StringVar(&amp;amp;dir, "dir", ".", "the directory to serve files from. Defaults to the current dir")
    flag.Parse()
    r := mux.NewRouter()

    // This will serve files under http://localhost:8000/static/&amp;lt;filename&amp;gt;
    r.PathPrefix("/static/").Handler(http.StripPrefix("/static/", http.FileServer(http.Dir(dir))))

    srv := &amp;amp;http.Server{
        Handler:      r,
        Addr:         "127.0.0.1:8000",
        // Good practice: enforce timeouts for servers you create!
        WriteTimeout: 15 * time.Second,
        ReadTimeout:  15 * time.Second,
    }

    log.Fatal(srv.ListenAndServe())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Serving Single Page Applications&lt;/h3&gt; 
&lt;p&gt;Most of the time it makes sense to serve your SPA on a separate web server from your API, but sometimes it's desirable to serve them both from one place. It's possible to write a simple handler for serving your SPA (for use with React Router's &lt;a href="https://reacttraining.com/react-router/web/api/BrowserRouter"&gt;BrowserRouter&lt;/a&gt; for example), and leverage mux's powerful routing for your API endpoints.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"encoding/json"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"time"

	"github.com/gorilla/mux"
)

// spaHandler implements the http.Handler interface, so we can use it
// to respond to HTTP requests. The path to the static directory and
// path to the index file within that static directory are used to
// serve the SPA in the given static directory.
type spaHandler struct {
	staticPath string
	indexPath  string
}

// ServeHTTP inspects the URL path to locate a file within the static dir
// on the SPA handler. If a file is found, it will be served. If not, the
// file located at the index path on the SPA handler will be served. This
// is suitable behavior for serving an SPA (single page application).
func (h spaHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	// Join internally call path.Clean to prevent directory traversal
	path := filepath.Join(h.staticPath, r.URL.Path)

	// check whether a file exists or is a directory at the given path
	fi, err := os.Stat(path)
	if os.IsNotExist(err) || fi.IsDir() {
		// file does not exist or path is a directory, serve index.html
		http.ServeFile(w, r, filepath.Join(h.staticPath, h.indexPath))
		return
	}

	if err != nil {
		// if we got an error (that wasn't that the file doesn't exist) stating the
		// file, return a 500 internal server error and stop
		http.Error(w, err.Error(), http.StatusInternalServerError)
        return
	}

	// otherwise, use http.FileServer to serve the static file
	http.FileServer(http.Dir(h.staticPath)).ServeHTTP(w, r)
}

func main() {
	router := mux.NewRouter()

	router.HandleFunc("/api/health", func(w http.ResponseWriter, r *http.Request) {
		// an example API handler
		json.NewEncoder(w).Encode(map[string]bool{"ok": true})
	})

	spa := spaHandler{staticPath: "build", indexPath: "index.html"}
	router.PathPrefix("/").Handler(spa)

	srv := &amp;amp;http.Server{
		Handler: router,
		Addr:    "127.0.0.1:8000",
		// Good practice: enforce timeouts for servers you create!
		WriteTimeout: 15 * time.Second,
		ReadTimeout:  15 * time.Second,
	}

	log.Fatal(srv.ListenAndServe())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Registered URLs&lt;/h3&gt; 
&lt;p&gt;Now let's see how to build registered URLs.&lt;/p&gt; 
&lt;p&gt;Routes can be named. All routes that define a name can have their URLs built, or "reversed". We define a name calling &lt;code&gt;Name()&lt;/code&gt; on a route. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
r.HandleFunc("/articles/{category}/{id:[0-9]+}", ArticleHandler).
  Name("article")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build a URL, get the route and call the &lt;code&gt;URL()&lt;/code&gt; method, passing a sequence of key/value pairs for the route variables. For the previous route, we would do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;url, err := r.Get("article").URL("category", "technology", "id", "42")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...and the result will be a &lt;code&gt;url.URL&lt;/code&gt; with the following path:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"/articles/technology/42"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This also works for host and query value variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
r.Host("{subdomain}.example.com").
  Path("/articles/{category}/{id:[0-9]+}").
  Queries("filter", "{filter}").
  HandlerFunc(ArticleHandler).
  Name("article")

// url.String() will be "http://news.example.com/articles/technology/42?filter=gorilla"
url, err := r.Get("article").URL("subdomain", "news",
                                 "category", "technology",
                                 "id", "42",
                                 "filter", "gorilla")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;All variables defined in the route are required, and their values must conform to the corresponding patterns. These requirements guarantee that a generated URL will always match a registered route -- the only exception is for explicitly defined "build-only" routes which never match.&lt;/p&gt; 
&lt;p&gt;Regex support also exists for matching Headers within a route. For example, we could do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r.HeadersRegexp("Content-Type", "application/(text|json)")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...and the route will match both requests with a Content-Type of &lt;code&gt;application/json&lt;/code&gt; as well as &lt;code&gt;application/text&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;There's also a way to build only the URL host or path for a route: use the methods &lt;code&gt;URLHost()&lt;/code&gt; or &lt;code&gt;URLPath()&lt;/code&gt; instead. For the previous route, we would do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// "http://news.example.com/"
host, err := r.Get("article").URLHost("subdomain", "news")

// "/articles/technology/42"
path, err := r.Get("article").URLPath("category", "technology", "id", "42")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And if you use subrouters, host and path defined separately can be built as well:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
s := r.Host("{subdomain}.example.com").Subrouter()
s.Path("/articles/{category}/{id:[0-9]+}").
  HandlerFunc(ArticleHandler).
  Name("article")

// "http://news.example.com/articles/technology/42"
url, err := r.Get("article").URL("subdomain", "news",
                                 "category", "technology",
                                 "id", "42")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find all the required variables for a given route when calling &lt;code&gt;URL()&lt;/code&gt;, the method &lt;code&gt;GetVarNames()&lt;/code&gt; is available:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
r.Host("{domain}").
    Path("/{group}/{item_id}").
    Queries("some_data1", "{some_data1}").
    Queries("some_data2", "{some_data2}").
    Name("article")

// Will print [domain group item_id some_data1 some_data2] &amp;lt;nil&amp;gt;
fmt.Println(r.Get("article").GetVarNames())

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Walking Routes&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;Walk&lt;/code&gt; function on &lt;code&gt;mux.Router&lt;/code&gt; can be used to visit all of the routes that are registered on a router. For example, the following prints all of the registered routes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"fmt"
	"net/http"
	"strings"

	"github.com/gorilla/mux"
)

func handler(w http.ResponseWriter, r *http.Request) {
	return
}

func main() {
	r := mux.NewRouter()
	r.HandleFunc("/", handler)
	r.HandleFunc("/products", handler).Methods("POST")
	r.HandleFunc("/articles", handler).Methods("GET")
	r.HandleFunc("/articles/{id}", handler).Methods("GET", "PUT")
	r.HandleFunc("/authors", handler).Queries("surname", "{surname}")
	err := r.Walk(func(route *mux.Route, router *mux.Router, ancestors []*mux.Route) error {
		pathTemplate, err := route.GetPathTemplate()
		if err == nil {
			fmt.Println("ROUTE:", pathTemplate)
		}
		pathRegexp, err := route.GetPathRegexp()
		if err == nil {
			fmt.Println("Path regexp:", pathRegexp)
		}
		queriesTemplates, err := route.GetQueriesTemplates()
		if err == nil {
			fmt.Println("Queries templates:", strings.Join(queriesTemplates, ","))
		}
		queriesRegexps, err := route.GetQueriesRegexp()
		if err == nil {
			fmt.Println("Queries regexps:", strings.Join(queriesRegexps, ","))
		}
		methods, err := route.GetMethods()
		if err == nil {
			fmt.Println("Methods:", strings.Join(methods, ","))
		}
		fmt.Println()
		return nil
	})

	if err != nil {
		fmt.Println(err)
	}

	http.Handle("/", r)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Graceful Shutdown&lt;/h3&gt; 
&lt;p&gt;Go 1.8 introduced the ability to &lt;a href="https://golang.org/doc/go1.8#http_shutdown"&gt;gracefully shutdown&lt;/a&gt; a &lt;code&gt;*http.Server&lt;/code&gt;. Here's how to do that alongside &lt;code&gt;mux&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "context"
    "flag"
    "log"
    "net/http"
    "os"
    "os/signal"
    "time"

    "github.com/gorilla/mux"
)

func main() {
    var wait time.Duration
    flag.DurationVar(&amp;amp;wait, "graceful-timeout", time.Second * 15, "the duration for which the server gracefully wait for existing connections to finish - e.g. 15s or 1m")
    flag.Parse()

    r := mux.NewRouter()
    // Add your routes as needed

    srv := &amp;amp;http.Server{
        Addr:         "0.0.0.0:8080",
        // Good practice to set timeouts to avoid Slowloris attacks.
        WriteTimeout: time.Second * 15,
        ReadTimeout:  time.Second * 15,
        IdleTimeout:  time.Second * 60,
        Handler: r, // Pass our instance of gorilla/mux in.
    }

    // Run our server in a goroutine so that it doesn't block.
    go func() {
        if err := srv.ListenAndServe(); err != nil {
            log.Println(err)
        }
    }()

    c := make(chan os.Signal, 1)
    // We'll accept graceful shutdowns when quit via SIGINT (Ctrl+C)
    // SIGKILL, SIGQUIT or SIGTERM (Ctrl+/) will not be caught.
    signal.Notify(c, os.Interrupt)

    // Block until we receive our signal.
    &amp;lt;-c

    // Create a deadline to wait for.
    ctx, cancel := context.WithTimeout(context.Background(), wait)
    defer cancel()
    // Doesn't block if no connections, but will otherwise wait
    // until the timeout deadline.
    srv.Shutdown(ctx)
    // Optionally, you could run srv.Shutdown in a goroutine and block on
    // &amp;lt;-ctx.Done() if your application should wait for other services
    // to finalize based on context cancellation.
    log.Println("shutting down")
    os.Exit(0)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Middleware&lt;/h3&gt; 
&lt;p&gt;Mux supports the addition of middlewares to a &lt;a href="https://godoc.org/github.com/gorilla/mux#Router"&gt;Router&lt;/a&gt;, which are executed in the order they are added if a match is found, including its subrouters. Middlewares are (typically) small pieces of code which take one request, do something with it, and pass it down to another middleware or the final handler. Some common use cases for middleware are request logging, header manipulation, or &lt;code&gt;ResponseWriter&lt;/code&gt; hijacking.&lt;/p&gt; 
&lt;p&gt;Mux middlewares are defined using the de facto standard type:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type MiddlewareFunc func(http.Handler) http.Handler
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Typically, the returned handler is a closure which does something with the http.ResponseWriter and http.Request passed to it, and then calls the handler passed as parameter to the MiddlewareFunc. This takes advantage of closures being able access variables from the context where they are created, while retaining the signature enforced by the receivers.&lt;/p&gt; 
&lt;p&gt;A very basic middleware which logs the URI of the request being handled could be written as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func loggingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Do stuff here
        log.Println(r.RequestURI)
        // Call the next handler, which can be another middleware in the chain, or the final handler.
        next.ServeHTTP(w, r)
    })
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Middlewares can be added to a router using &lt;code&gt;Router.Use()&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
r.HandleFunc("/", handler)
r.Use(loggingMiddleware)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A more complex authentication middleware, which maps session token to users, could be written as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Define our struct
type authenticationMiddleware struct {
	tokenUsers map[string]string
}

// Initialize it somewhere
func (amw *authenticationMiddleware) Populate() {
	amw.tokenUsers["00000000"] = "user0"
	amw.tokenUsers["aaaaaaaa"] = "userA"
	amw.tokenUsers["05f717e5"] = "randomUser"
	amw.tokenUsers["deadbeef"] = "user0"
}

// Middleware function, which will be called for each request
func (amw *authenticationMiddleware) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        token := r.Header.Get("X-Session-Token")

        if user, found := amw.tokenUsers[token]; found {
        	// We found the token in our map
        	log.Printf("Authenticated user %s\n", user)
        	// Pass down the request to the next middleware (or final handler)
        	next.ServeHTTP(w, r)
        } else {
        	// Write an error and stop the handler chain
        	http.Error(w, "Forbidden", http.StatusForbidden)
        }
    })
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;r := mux.NewRouter()
r.HandleFunc("/", handler)

amw := authenticationMiddleware{tokenUsers: make(map[string]string)}
amw.Populate()

r.Use(amw.Middleware)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: The handler chain will be stopped if your middleware doesn't call &lt;code&gt;next.ServeHTTP()&lt;/code&gt; with the corresponding parameters. This can be used to abort a request if the middleware writer wants to. Middlewares &lt;em&gt;should&lt;/em&gt; write to &lt;code&gt;ResponseWriter&lt;/code&gt; if they &lt;em&gt;are&lt;/em&gt; going to terminate the request, and they &lt;em&gt;should not&lt;/em&gt; write to &lt;code&gt;ResponseWriter&lt;/code&gt; if they &lt;em&gt;are not&lt;/em&gt; going to terminate it.&lt;/p&gt; 
&lt;h3&gt;Handling CORS Requests&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://godoc.org/github.com/gorilla/mux#CORSMethodMiddleware"&gt;CORSMethodMiddleware&lt;/a&gt; intends to make it easier to strictly set the &lt;code&gt;Access-Control-Allow-Methods&lt;/code&gt; response header.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You will still need to use your own CORS handler to set the other CORS headers such as &lt;code&gt;Access-Control-Allow-Origin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The middleware will set the &lt;code&gt;Access-Control-Allow-Methods&lt;/code&gt; header to all the method matchers (e.g. &lt;code&gt;r.Methods(http.MethodGet, http.MethodPut, http.MethodOptions)&lt;/code&gt; -&amp;gt; &lt;code&gt;Access-Control-Allow-Methods: GET,PUT,OPTIONS&lt;/code&gt;) on a route&lt;/li&gt; 
 &lt;li&gt;If you do not specify any methods, then:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Important&lt;/em&gt;: there must be an &lt;code&gt;OPTIONS&lt;/code&gt; method matcher for the middleware to set the headers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Here is an example of using &lt;code&gt;CORSMethodMiddleware&lt;/code&gt; along with a custom &lt;code&gt;OPTIONS&lt;/code&gt; handler to set all the required CORS headers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"net/http"
	"github.com/gorilla/mux"
)

func main() {
    r := mux.NewRouter()

    // IMPORTANT: you must specify an OPTIONS method matcher for the middleware to set CORS headers
    r.HandleFunc("/foo", fooHandler).Methods(http.MethodGet, http.MethodPut, http.MethodPatch, http.MethodOptions)
    r.Use(mux.CORSMethodMiddleware(r))
    
    http.ListenAndServe(":8080", r)
}

func fooHandler(w http.ResponseWriter, r *http.Request) {
    w.Header().Set("Access-Control-Allow-Origin", "*")
    if r.Method == http.MethodOptions {
        return
    }

    w.Write([]byte("foo"))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And an request to &lt;code&gt;/foo&lt;/code&gt; using something like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl localhost:8080/foo -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Would look like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;*   Trying ::1...
* TCP_NODELAY set
* Connected to localhost (::1) port 8080 (#0)
&amp;gt; GET /foo HTTP/1.1
&amp;gt; Host: localhost:8080
&amp;gt; User-Agent: curl/7.59.0
&amp;gt; Accept: */*
&amp;gt; 
&amp;lt; HTTP/1.1 200 OK
&amp;lt; Access-Control-Allow-Methods: GET,PUT,PATCH,OPTIONS
&amp;lt; Access-Control-Allow-Origin: *
&amp;lt; Date: Fri, 28 Jun 2019 20:13:30 GMT
&amp;lt; Content-Length: 3
&amp;lt; Content-Type: text/plain; charset=utf-8
&amp;lt; 
* Connection #0 to host localhost left intact
foo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing Handlers&lt;/h3&gt; 
&lt;p&gt;Testing handlers in a Go web application is straightforward, and &lt;em&gt;mux&lt;/em&gt; doesn't complicate this any further. Given two files: &lt;code&gt;endpoints.go&lt;/code&gt; and &lt;code&gt;endpoints_test.go&lt;/code&gt;, here's how we'd test an application using &lt;em&gt;mux&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;First, our simple HTTP handler:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// endpoints.go
package main

func HealthCheckHandler(w http.ResponseWriter, r *http.Request) {
    // A very simple health check.
    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(http.StatusOK)

    // In the future we could report back on the status of our DB, or our cache
    // (e.g. Redis) by performing a simple PING, and include them in the response.
    io.WriteString(w, `{"alive": true}`)
}

func main() {
    r := mux.NewRouter()
    r.HandleFunc("/health", HealthCheckHandler)

    log.Fatal(http.ListenAndServe("localhost:8080", r))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Our test code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// endpoints_test.go
package main

import (
    "net/http"
    "net/http/httptest"
    "testing"
)

func TestHealthCheckHandler(t *testing.T) {
    // Create a request to pass to our handler. We don't have any query parameters for now, so we'll
    // pass 'nil' as the third parameter.
    req, err := http.NewRequest("GET", "/health", nil)
    if err != nil {
        t.Fatal(err)
    }

    // We create a ResponseRecorder (which satisfies http.ResponseWriter) to record the response.
    rr := httptest.NewRecorder()
    handler := http.HandlerFunc(HealthCheckHandler)

    // Our handlers satisfy http.Handler, so we can call their ServeHTTP method
    // directly and pass in our Request and ResponseRecorder.
    handler.ServeHTTP(rr, req)

    // Check the status code is what we expect.
    if status := rr.Code; status != http.StatusOK {
        t.Errorf("handler returned wrong status code: got %v want %v",
            status, http.StatusOK)
    }

    // Check the response body is what we expect.
    expected := `{"alive": true}`
    if rr.Body.String() != expected {
        t.Errorf("handler returned unexpected body: got %v want %v",
            rr.Body.String(), expected)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the case that our routes have &lt;a href="https://raw.githubusercontent.com/gorilla/mux/main/#examples"&gt;variables&lt;/a&gt;, we can pass those in the request. We could write &lt;a href="https://dave.cheney.net/2013/06/09/writing-table-driven-tests-in-go"&gt;table-driven tests&lt;/a&gt; to test multiple possible route variables as needed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// endpoints.go
func main() {
    r := mux.NewRouter()
    // A route with a route variable:
    r.HandleFunc("/metrics/{type}", MetricsHandler)

    log.Fatal(http.ListenAndServe("localhost:8080", r))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Our test file, with a table-driven test of &lt;code&gt;routeVariables&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// endpoints_test.go
func TestMetricsHandler(t *testing.T) {
    tt := []struct{
        routeVariable string
        shouldPass bool
    }{
        {"goroutines", true},
        {"heap", true},
        {"counters", true},
        {"queries", true},
        {"adhadaeqm3k", false},
    }

    for _, tc := range tt {
        path := fmt.Sprintf("/metrics/%s", tc.routeVariable)
        req, err := http.NewRequest("GET", path, nil)
        if err != nil {
            t.Fatal(err)
        }

        rr := httptest.NewRecorder()
	
	// To add the vars&amp;nbsp;to the context, 
	// we need to create&amp;nbsp;a router through which we can&amp;nbsp;pass the request.
	router := mux.NewRouter()
        router.HandleFunc("/metrics/{type}", MetricsHandler)
        router.ServeHTTP(rr, req)

        // In this case, our MetricsHandler returns a non-200 response
        // for a route variable it doesn't know about.
        if rr.Code == http.StatusOK &amp;amp;&amp;amp; !tc.shouldPass {
            t.Errorf("handler should have failed on routeVariable %s: got %v want %v",
                tc.routeVariable, rr.Code, http.StatusOK)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Full Example&lt;/h2&gt; 
&lt;p&gt;Here's a complete, runnable example of a small &lt;code&gt;mux&lt;/code&gt; based server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "net/http"
    "log"
    "github.com/gorilla/mux"
)

func YourHandler(w http.ResponseWriter, r *http.Request) {
    w.Write([]byte("Gorilla!\n"))
}

func main() {
    r := mux.NewRouter()
    // Routes consist of a path and a handler function.
    r.HandleFunc("/", YourHandler)

    // Bind to a port and pass our router in
    log.Fatal(http.ListenAndServe(":8000", r))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;BSD licensed. See the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gruntwork-io/terragrunt</title>
      <link>https://github.com/gruntwork-io/terragrunt</link>
      <description>&lt;p&gt;Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Terragrunt&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://gruntwork.io/?ref=repo_terragrunt"&gt;&lt;img src="https://img.shields.io/badge/maintained%20by-gruntwork.io-%235849a6.svg?sanitize=true" alt="Maintained by Gruntwork.io" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/gruntwork-io/terragrunt"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gruntwork-io/terragrunt" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/gruntwork-io/terragrunt"&gt;&lt;img src="https://godoc.org/github.com/gruntwork-io/terragrunt?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/tofu-%3E%3D1.6.0-blue.svg?sanitize=true" alt="OpenTofu Version" /&gt; &lt;img src="https://img.shields.io/badge/tf-%3E%3D0.12.0-blue.svg?sanitize=true" alt="Terraform Version" /&gt;&lt;/p&gt; 
&lt;p&gt;Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in &lt;a href="https://opentofu.org"&gt;OpenTofu&lt;/a&gt;/&lt;a href="https://www.terraform.io"&gt;Terraform&lt;/a&gt; to scale.&lt;/p&gt; 
&lt;p&gt;Please see the following for more info, including install instructions and complete documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://terragrunt.gruntwork.io"&gt;Terragrunt Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://terragrunt.gruntwork.io/docs/getting-started/quick-start/"&gt;Getting started with Terragrunt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://terragrunt.gruntwork.io/docs"&gt;Terragrunt Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://terragrunt.gruntwork.io/docs/community/contributing"&gt;Contributing to Terragrunt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gruntwork.io/support/"&gt;Commercial Support&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Join the Discord!&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href="https://discord.gg/YENaT9h8jh"&gt;our community&lt;/a&gt; for discussions, support, and contributions:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/YENaT9h8jh"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/YENaT9h8jh" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This code is released under the MIT License. See &lt;a href="https://raw.githubusercontent.com/gruntwork-io/terragrunt/main/LICENSE.txt"&gt;LICENSE.txt&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>onsi/ginkgo</title>
      <link>https://github.com/onsi/ginkgo</link>
      <description>&lt;p&gt;A Modern Testing Framework for Go&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://onsi.github.io/ginkgo/images/ginkgo.png" alt="Ginkgo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/onsi/ginkgo/actions?query=workflow%3Atest+branch%3Amaster"&gt;&lt;img src="https://github.com/onsi/ginkgo/actions/workflows/test.yml/badge.svg?branch=master" alt="test" /&gt;&lt;/a&gt; | &lt;a href="https://onsi.github.io/ginkgo/"&gt;Ginkgo Docs&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Ginkgo&lt;/h1&gt; 
&lt;p&gt;Ginkgo is a mature testing framework for Go designed to help you write expressive specs. Ginkgo builds on top of Go's &lt;code&gt;testing&lt;/code&gt; foundation and is complemented by the &lt;a href="https://github.com/onsi/gomega"&gt;Gomega&lt;/a&gt; matcher library. Together, Ginkgo and Gomega let you express the intent behind your specs clearly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    . "github.com/onsi/ginkgo/v2"
    . "github.com/onsi/gomega"
    ...
)

var _ = Describe("Checking books out of the library", Label("library"), func() {
    var library *libraries.Library
    var book *books.Book
    var valjean *users.User
    BeforeEach(func() {
        library = libraries.NewClient()
        book = &amp;amp;books.Book{
            Title: "Les Miserables",
            Author: "Victor Hugo",
        }
        valjean = users.NewUser("Jean Valjean")
    })

    When("the library has the book in question", func() {
        BeforeEach(func(ctx SpecContext) {
            Expect(library.Store(ctx, book)).To(Succeed())
        })

        Context("and the book is available", func() {
            It("lends it to the reader", func(ctx SpecContext) {
                Expect(valjean.Checkout(ctx, library, "Les Miserables")).To(Succeed())
                Expect(valjean.Books()).To(ContainElement(book))
                Expect(library.UserWithBook(ctx, book)).To(Equal(valjean))
            }, SpecTimeout(time.Second * 5))
        })

        Context("but the book has already been checked out", func() {
            var javert *users.User
            BeforeEach(func(ctx SpecContext) {
                javert = users.NewUser("Javert")
                Expect(javert.Checkout(ctx, library, "Les Miserables")).To(Succeed())
            })

            It("tells the user", func(ctx SpecContext) {
                err := valjean.Checkout(ctx, library, "Les Miserables")
                Expect(err).To(MatchError("Les Miserables is currently checked out"))
            }, SpecTimeout(time.Second * 5))

            It("lets the user place a hold and get notified later", func(ctx SpecContext) {
                Expect(valjean.Hold(ctx, library, "Les Miserables")).To(Succeed())
                Expect(valjean.Holds(ctx)).To(ContainElement(book))

                By("when Javert returns the book")
                Expect(javert.Return(ctx, library, book)).To(Succeed())

                By("it eventually informs Valjean")
                notification := "Les Miserables is ready for pick up"
                Eventually(ctx, valjean.Notifications).Should(ContainElement(notification))

                Expect(valjean.Checkout(ctx, library, "Les Miserables")).To(Succeed())
                Expect(valjean.Books(ctx)).To(ContainElement(book))
                Expect(valjean.Holds(ctx)).To(BeEmpty())
            }, SpecTimeout(time.Second * 10))
        })  
    })

    When("the library does not have the book in question", func() {
        It("tells the reader the book is unavailable", func(ctx SpecContext) {
            err := valjean.Checkout(ctx, library, "Les Miserables")
            Expect(err).To(MatchError("Les Miserables is not in the library catalog"))
        }, SpecTimeout(time.Second * 5))
    })
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Jump to the &lt;a href="https://onsi.github.io/ginkgo/"&gt;docs&lt;/a&gt; to learn more. It's easy to &lt;a href="https://onsi.github.io/ginkgo/#bootstrapping-a-suite"&gt;bootstrap&lt;/a&gt; and start writing your &lt;a href="https://onsi.github.io/ginkgo/#adding-specs-to-a-suite"&gt;first specs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have a question, comment, bug report, feature request, etc. please open a &lt;a href="https://github.com/onsi/ginkgo/issues/new"&gt;GitHub issue&lt;/a&gt;, or visit the &lt;a href="https://app.slack.com/client/T029RQSE6/CQQ50BBNW"&gt;Ginkgo Slack channel&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Capabilities&lt;/h2&gt; 
&lt;p&gt;Whether writing basic unit specs, complex integration specs, or even performance specs - Ginkgo gives you an expressive Domain-Specific Language (DSL) that will be familiar to users coming from frameworks such as &lt;a href="https://github.com/Quick/Quick"&gt;Quick&lt;/a&gt;, &lt;a href="https://rspec.info"&gt;RSpec&lt;/a&gt;, &lt;a href="https://jasmine.github.io"&gt;Jasmine&lt;/a&gt;, and &lt;a href="https://lunarmodules.github.io/busted/"&gt;Busted&lt;/a&gt;. This style of testing is sometimes referred to as "Behavior-Driven Development" (BDD) though Ginkgo's utility extends beyond acceptance-level testing.&lt;/p&gt; 
&lt;p&gt;With Ginkgo's DSL you can use nestable &lt;a href="https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes"&gt;&lt;code&gt;Describe&lt;/code&gt;, &lt;code&gt;Context&lt;/code&gt; and &lt;code&gt;When&lt;/code&gt; container nodes&lt;/a&gt; to help you organize your specs. &lt;a href="https://onsi.github.io/ginkgo/#extracting-common-setup-beforeeach"&gt;&lt;code&gt;BeforeEach&lt;/code&gt; and &lt;code&gt;AfterEach&lt;/code&gt; setup nodes&lt;/a&gt; for setup and cleanup. &lt;a href="https://onsi.github.io/ginkgo/#spec-subjects-it"&gt;&lt;code&gt;It&lt;/code&gt; and &lt;code&gt;Specify&lt;/code&gt; subject nodes&lt;/a&gt; that hold your assertions. &lt;a href="https://onsi.github.io/ginkgo/#suite-setup-and-cleanup-beforesuite-and-aftersuite"&gt;&lt;code&gt;BeforeSuite&lt;/code&gt; and &lt;code&gt;AfterSuite&lt;/code&gt; nodes&lt;/a&gt; to prep for and cleanup after a suite... and &lt;a href="https://onsi.github.io/ginkgo/#writing-specs"&gt;much more!&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;At runtime, Ginkgo can run your specs in reproducibly &lt;a href="https://onsi.github.io/ginkgo/#spec-randomization"&gt;random order&lt;/a&gt; and has sophisticated support for &lt;a href="https://onsi.github.io/ginkgo/#spec-parallelization"&gt;spec parallelization&lt;/a&gt;. In fact, running specs in parallel is as easy as&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ginkgo -p
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By following &lt;a href="https://onsi.github.io/ginkgo/#patterns-for-parallel-integration-specs"&gt;established patterns for writing parallel specs&lt;/a&gt; you can build even large, complex integration suites that parallelize cleanly and run performantly. And you don't have to worry about your spec suite hanging or leaving a mess behind - Ginkgo provides a per-node &lt;code&gt;context.Context&lt;/code&gt; and the capability to interrupt the spec after a set period of time - and then clean up.&lt;/p&gt; 
&lt;p&gt;As your suites grow Ginkgo helps you keep your specs organized with &lt;a href="https://onsi.github.io/ginkgo/#spec-labels"&gt;labels&lt;/a&gt; and lets you easily run &lt;a href="https://onsi.github.io/ginkgo/#filtering-specs"&gt;subsets of specs&lt;/a&gt;, either &lt;a href="https://onsi.github.io/ginkgo/#focused-specs"&gt;programmatically&lt;/a&gt; or on the &lt;a href="https://onsi.github.io/ginkgo/#combining-filters"&gt;command line&lt;/a&gt;. And Ginkgo's reporting infrastructure generates machine-readable output in a &lt;a href="https://onsi.github.io/ginkgo/#generating-machine-readable-reports"&gt;variety of formats&lt;/a&gt; &lt;em&gt;and&lt;/em&gt; allows you to build your own &lt;a href="https://onsi.github.io/ginkgo/#generating-reports-programmatically"&gt;custom reporting infrastructure&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Ginkgo ships with &lt;code&gt;ginkgo&lt;/code&gt;, a &lt;a href="https://onsi.github.io/ginkgo/#ginkgo-cli-overview"&gt;command line tool&lt;/a&gt; with support for generating, running, filtering, and profiling Ginkgo suites. You can even have Ginkgo automatically run your specs when it detects a change with &lt;code&gt;ginkgo watch&lt;/code&gt;, enabling rapid feedback loops during test-driven development.&lt;/p&gt; 
&lt;p&gt;And that's just Ginkgo! &lt;a href="https://onsi.github.io/gomega/"&gt;Gomega&lt;/a&gt; brings a rich, mature, family of &lt;a href="https://onsi.github.io/gomega/#provided-matchers"&gt;assertions and matchers&lt;/a&gt; to your suites. With Gomega you can easily mix &lt;a href="https://onsi.github.io/ginkgo/#patterns-for-asynchronous-testing"&gt;synchronous and asynchronous assertions&lt;/a&gt; in your specs. You can even build your own set of expressive domain-specific matchers quickly and easily by composing Gomega's &lt;a href="https://onsi.github.io/ginkgo/#building-custom-matchers"&gt;existing building blocks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Happy Testing!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Ginkgo is MIT-Licensed&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/onsi/ginkgo/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Sponsors commit to a &lt;a href="https://github.com/sponsors/onsi"&gt;sponsorship&lt;/a&gt; for a year. If you're an organization that makes use of Ginkgo please consider becoming a sponsor!&lt;/p&gt; 
&lt;p style="font-size:21px; color:black;"&gt;Browser testing via &lt;a href="https://www.lambdatest.com/" target="_blank"&gt; &lt;img src="https://www.lambdatest.com/blue-logo.png" style="vertical-align: middle;" width="250" height="45" /&gt; &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>