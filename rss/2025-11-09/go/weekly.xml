<rss version="2.0">
  <channel>
    <title>GitHub Go Weekly Trending</title>
    <description>Weekly Trending of Go in GitHub</description>
    <pubDate>Sat, 08 Nov 2025 01:45:33 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>cloudwego/eino</title>
      <link>https://github.com/cloudwego/eino</link>
      <description>&lt;p&gt;The ultimate LLM/AI application development framework in Golang.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Eino&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/badges/.badges/main/coverage.svg?sanitize=true" alt="coverage" /&gt; &lt;a href="https://github.com/cloudwego/eino/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/cloudwego/eino" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://www.cloudwego.io/"&gt;&lt;img src="https://img.shields.io/website?up_message=cloudwego&amp;amp;url=https%3A%2F%2Fwww.cloudwego.io%2F" alt="WebSite" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudwego/eino/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/cloudwego/eino" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/cloudwego/eino"&gt;&lt;img src="https://goreportcard.com/badge/github.com/cloudwego/eino" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudwego/kitex/eino"&gt;&lt;img src="https://img.shields.io/github/issues/cloudwego/eino" alt="OpenIssue" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudwego/eino/issues?q=is%3Aissue+is%3Aclosed"&gt;&lt;img src="https://img.shields.io/github/issues-closed/cloudwego/eino" alt="ClosedIssue" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/cloudwego/eino" alt="Stars" /&gt; &lt;img src="https://img.shields.io/github/forks/cloudwego/eino" alt="Forks" /&gt;&lt;/p&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/cloudwego/eino/main/README.zh_CN.md"&gt;中文&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Eino['aino]&lt;/strong&gt; (pronounced similarly to "I know") aims to be the ultimate LLM application development framework in Golang. Drawing inspirations from many excellent LLM application development frameworks in the open-source community such as LangChain &amp;amp; LlamaIndex, etc., as well as learning from cutting-edge research and real world applications, Eino offers an LLM application development framework that emphasizes on simplicity, scalability, reliability and effectiveness that better aligns with Golang programming conventions.&lt;/p&gt; 
&lt;p&gt;What Eino provides are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a carefully curated list of &lt;strong&gt;component&lt;/strong&gt; abstractions and implementations that can be easily reused and combined to build LLM applications&lt;/li&gt; 
 &lt;li&gt;a powerful &lt;strong&gt;composition&lt;/strong&gt; framework that does the heavy lifting of strong type checking, stream processing, concurrency management, aspect injection, option assignment, etc. for the user.&lt;/li&gt; 
 &lt;li&gt;a set of meticulously designed &lt;strong&gt;API&lt;/strong&gt; that obsesses on simplicity and clarity.&lt;/li&gt; 
 &lt;li&gt;an ever-growing collection of best practices in the form of bundled &lt;strong&gt;flows&lt;/strong&gt; and &lt;strong&gt;examples&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;a useful set of tools that covers the entire development cycle, from visualized development and debugging to online tracing and evaluation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With the above arsenal, Eino can standardize, simplify, and improve efficiency at different stages of the AI application development cycle: &lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/eino_concept.jpeg" alt="" /&gt;&lt;/p&gt; 
&lt;h1&gt;A quick walkthrough&lt;/h1&gt; 
&lt;p&gt;Use a component directly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;model, _ := openai.NewChatModel(ctx, config) // create an invokable LLM instance
message, _ := model.Generate(ctx, []*Message{
    SystemMessage("you are a helpful assistant."),
    UserMessage("what does the future AI App look like?")})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Of course, you can do that, Eino provides lots of useful components to use out of the box. But you can do more by using orchestration, for three reasons:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;orchestration encapsulates common patterns of LLM application.&lt;/li&gt; 
 &lt;li&gt;orchestration solves the difficult problem of processing stream response by the LLM.&lt;/li&gt; 
 &lt;li&gt;orchestration handles type safety, concurrency management, aspect injection and option assignment for you.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Eino provides three set of APIs for orchestration&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th&gt;Characteristics and usage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chain&lt;/td&gt; 
   &lt;td&gt;Simple chained directed graph that can only go forward.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Graph&lt;/td&gt; 
   &lt;td&gt;Cyclic or Acyclic directed graph. Powerful and flexible.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Workflow&lt;/td&gt; 
   &lt;td&gt;Acyclic graph that supports data mapping at struct field level.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Let's create a simple chain: a ChatTemplate followed by a ChatModel.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/simple_chain.png" alt="" /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;chain, _ := NewChain[map[string]any, *Message]().
           AppendChatTemplate(prompt).
           AppendChatModel(model).
           Compile(ctx)

chain.Invoke(ctx, map[string]any{"query": "what's your name?"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now let's create a graph that uses a ChatModel to generate answer or tool calls, then uses a ToolsNode to execute those tools if needed.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/tool_call_graph.png" alt="" /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;graph := NewGraph[map[string]any, *schema.Message]()

_ = graph.AddChatTemplateNode("node_template", chatTpl)
_ = graph.AddChatModelNode("node_model", chatModel)
_ = graph.AddToolsNode("node_tools", toolsNode)
_ = graph.AddLambdaNode("node_converter", takeOne)

_ = graph.AddEdge(START, "node_template")
_ = graph.AddEdge("node_template", "node_model")
_ = graph.AddBranch("node_model", branch)
_ = graph.AddEdge("node_tools", "node_converter")
_ = graph.AddEdge("node_converter", END)

compiledGraph, err := graph.Compile(ctx)
if err != nil {
return err
}
out, err := compiledGraph.Invoke(ctx, map[string]any{"query":"Beijing's weather this weekend"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now let's create a workflow that flexibly maps input &amp;amp; output at the field level:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/simple_workflow.png" alt="" /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;type Input1 struct {
    Input string
}

type Output1 struct {
    Output string
}

type Input2 struct {
    Role schema.RoleType
}

type Output2 struct {
    Output string
}

type Input3 struct {
    Query string
    MetaData string
}

var (
    ctx context.Context
    m model.BaseChatModel
    lambda1 func(context.Context, Input1) (Output1, error)
    lambda2 func(context.Context, Input2) (Output2, error)
    lambda3 func(context.Context, Input3) (*schema.Message, error)
)

wf := NewWorkflow[[]*schema.Message, *schema.Message]()
wf.AddChatModelNode("model", m).AddInput(START)
wf.AddLambdaNode("lambda1", InvokableLambda(lambda1)).
    AddInput("model", MapFields("Content", "Input"))
wf.AddLambdaNode("lambda2", InvokableLambda(lambda2)).
    AddInput("model", MapFields("Role", "Role"))
wf.AddLambdaNode("lambda3", InvokableLambda(lambda3)).
    AddInput("lambda1", MapFields("Output", "Query")).
    AddInput("lambda2", MapFields("Output", "MetaData"))
wf.End().AddInput("lambda3")
runnable, err := wf.Compile(ctx)
if err != nil {
    return err
}
our, err := runnable.Invoke(ctx, []*schema.Message{
    schema.UserMessage("kick start this workflow!"),
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now let's create a 'ReAct' agent: A ChatModel binds to Tools. It receives input Messages and decides independently whether to call the Tool or output the final result. The execution result of the Tool will again become the input Message for the ChatModel and serve as the context for the next round of independent judgment.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/react.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;We provide a complete implementation for ReAct Agent out of the box in the &lt;code&gt;flow&lt;/code&gt; package. Check out the code here: &lt;a href="https://github.com/cloudwego/eino/raw/main/flow/agent/react/react.go"&gt;flow/agent/react&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Our implementation of ReAct Agent uses Eino's &lt;strong&gt;graph orchestration&lt;/strong&gt; exclusively, which provides the following benefits out of the box:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Type checking: it makes sure the two nodes' input and output types match at compile time.&lt;/li&gt; 
 &lt;li&gt;Stream processing: concatenates message stream before passing to chatModel and toolsNode if needed, and copies the stream into callback handlers.&lt;/li&gt; 
 &lt;li&gt;Concurrency management: the shared state can be safely read and written because the StatePreHandler is concurrency safe.&lt;/li&gt; 
 &lt;li&gt;Aspect injection: injects callback aspects before and after the execution of ChatModel if the specified ChatModel implementation hasn't injected itself.&lt;/li&gt; 
 &lt;li&gt;Option assignment: call options are assigned either globally, to specific component type or to specific node.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, you could easily extend the compiled graph with callbacks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;handler := NewHandlerBuilder().
  OnStartFn(
    func(ctx context.Context, info *RunInfo, input CallbackInput) context.Context) {
        log.Infof("onStart, runInfo: %v, input: %v", info, input)
    }).
  OnEndFn(
    func(ctx context.Context, info *RunInfo, output CallbackOutput) context.Context) {
        log.Infof("onEnd, runInfo: %v, out: %v", info, output)
    }).
  Build()
  
compiledGraph.Invoke(ctx, input, WithCallbacks(handler))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or you could easily assign options to different nodes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;// assign to All nodes
compiledGraph.Invoke(ctx, input, WithCallbacks(handler))

// assign only to ChatModel nodes
compiledGraph.Invoke(ctx, input, WithChatModelOption(WithTemperature(0.5))

// assign only to node_1
compiledGraph.Invoke(ctx, input, WithCallbacks(handler).DesignateNode("node_1"))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Key Features&lt;/h1&gt; 
&lt;h2&gt;Rich Components&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Encapsulates common building blocks into &lt;strong&gt;component abstractions&lt;/strong&gt;, each have multiple &lt;strong&gt;component implementations&lt;/strong&gt; that are ready to be used out of the box.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;component abstractions such as ChatModel, Tool, ChatTemplate, Retriever, Document Loader, Lambda, etc.&lt;/li&gt; 
   &lt;li&gt;each component type has an interface of its own: defined Input &amp;amp; Output Type, defined Option type, and streaming paradigms that make sense.&lt;/li&gt; 
   &lt;li&gt;implementations are transparent. Abstractions are all you care about when orchestrating components together.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Implementations can be nested and captures complex business logic.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ReAct Agent, MultiQueryRetriever, Host MultiAgent, etc. They consist of multiple components and non-trivial business logic.&lt;/li&gt; 
   &lt;li&gt;They are still transparent from the outside. A MultiQueryRetriever can be used anywhere that accepts a Retriever.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Powerful Orchestration&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data flows from Retriever / Document Loaders / ChatTemplate to ChatModel, then flows to Tools and parsed as Final Answer. This directed, controlled flow of data through multiple components can be implemented through &lt;strong&gt;graph orchestration&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Component instances are graph nodes, and edges are data flow channels.&lt;/li&gt; 
 &lt;li&gt;Graph orchestration is powerful and flexible enough to implement complex business logic: 
  &lt;ul&gt; 
   &lt;li&gt;type checking, stream processing, concurrency management, aspect injection and option assignment are handled by the framework.&lt;/li&gt; 
   &lt;li&gt;branch out execution at runtime, read and write global state, or do field level data mapping using workflow(currently in alpha stage).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Complete Stream Processing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stream processing is important because ChatModel outputs chunks of messages in real time as it generates them. It's especially important with orchestration because more components need to handle streaming data.&lt;/li&gt; 
 &lt;li&gt;Eino automatically &lt;strong&gt;concatenates&lt;/strong&gt; stream chunks for downstream nodes that only accepts non-stream input, such as ToolsNode.&lt;/li&gt; 
 &lt;li&gt;Eino automatically &lt;strong&gt;boxes&lt;/strong&gt; non stream into stream when stream is needed during graph execution.&lt;/li&gt; 
 &lt;li&gt;Eino automatically &lt;strong&gt;merges&lt;/strong&gt; multiple streams as they converge into a single downward node.&lt;/li&gt; 
 &lt;li&gt;Eino automatically &lt;strong&gt;copies&lt;/strong&gt; stream as they fan out to different downward node, or is passed to callback handlers.&lt;/li&gt; 
 &lt;li&gt;Orchestration elements such as &lt;strong&gt;branch&lt;/strong&gt; and &lt;strong&gt;state handlers&lt;/strong&gt; are also stream aware.&lt;/li&gt; 
 &lt;li&gt;With these streaming processing abilities, the streaming paradigms of components themselves become transparent to the user.&lt;/li&gt; 
 &lt;li&gt;A compiled Graph can run with 4 different streaming paradigms:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Streaming Paradigm&lt;/th&gt; 
   &lt;th&gt;Explanation&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Invoke&lt;/td&gt; 
   &lt;td&gt;Accepts non-stream type I and returns non-stream type O&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stream&lt;/td&gt; 
   &lt;td&gt;Accepts non-stream type I and returns stream type StreamReader[O]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Collect&lt;/td&gt; 
   &lt;td&gt;Accepts stream type StreamReader[I] and returns non-stream type O&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Transform&lt;/td&gt; 
   &lt;td&gt;Accepts stream type StreamReader[I] and returns stream type StreamReader[O]&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Highly Extensible Aspects (Callbacks)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Aspects handle cross-cutting concerns such as logging, tracing, metrics, etc., as well as exposing internal details of component implementations.&lt;/li&gt; 
 &lt;li&gt;Five aspects are supported: &lt;strong&gt;OnStart, OnEnd, OnError, OnStartWithStreamInput, OnEndWithStreamOutput&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Developers can easily create custom callback handlers, add them during graph run via options, and they will be invoked during graph run.&lt;/li&gt; 
 &lt;li&gt;Graph can also inject aspects to those component implementations that do not support callbacks on their own.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Eino Framework Structure&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/eino_framework.jpeg" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;The Eino framework consists of several parts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Eino(this repo): Contains Eino's type definitions, streaming mechanism, component abstractions, orchestration capabilities, aspect mechanisms, etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/cloudwego/eino-ext"&gt;EinoExt&lt;/a&gt;: Component implementations, callback handlers implementations, component usage examples, and various tools such as evaluators, prompt optimizers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/cloudwego/eino-ext/tree/main/devops"&gt;Eino Devops&lt;/a&gt;: visualized developing, visualized debugging etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/cloudwego/eino-examples"&gt;EinoExamples&lt;/a&gt; is the repo containing example applications and best practices for Eino.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Detailed Documentation&lt;/h2&gt; 
&lt;p&gt;For learning and using Eino, we provide a comprehensive Eino User Manual to help you quickly understand the concepts in Eino and master the skills of developing AI applications based on Eino. Start exploring through the &lt;a href="https://www.cloudwego.io/zh/docs/eino/"&gt;Eino User Manual&lt;/a&gt; now!&lt;/p&gt; 
&lt;p&gt;For a quick introduction to building AI applications with Eino, we recommend starting with &lt;a href="https://www.cloudwego.io/zh/docs/eino/quick_start/"&gt;Eino: Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go 1.18 and above.&lt;/li&gt; 
 &lt;li&gt;Eino relies on &lt;a href="https://github.com/getkin/kin-openapi"&gt;kin-openapi&lt;/a&gt; 's OpenAPI JSONSchema implementation. In order to remain compatible with Go 1.18, we have fixed kin-openapi's version to be v0.118.0.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you discover a potential security issue in this project, or think you may have discovered a security issue, we ask that you notify Bytedance Security via our &lt;a href="https://security.bytedance.com/src"&gt;security center&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/cloudwego/eino/main/sec@bytedance.com"&gt;vulnerability reporting email&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please do &lt;strong&gt;not&lt;/strong&gt; create a public GitHub issue.&lt;/p&gt; 
&lt;h2&gt;Contact US&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;How to become a member: &lt;a href="https://github.com/cloudwego/community/raw/main/COMMUNITY_MEMBERSHIP.md"&gt;COMMUNITY MEMBERSHIP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Issues: &lt;a href="https://github.com/cloudwego/eino/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Lark: Scan the QR code below with &lt;a href="https://www.feishu.cn/en/"&gt;Register Feishu&lt;/a&gt; to join our CloudWeGo/eino user group.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;    &lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/lark_group_zh.png" alt="LarkGroup" width="200" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/cloudwego/eino/main/LICENSE-APACHE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>prometheus/alertmanager</title>
      <link>https://github.com/prometheus/alertmanager</link>
      <description>&lt;p&gt;Prometheus Alertmanager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Alertmanager &lt;a href="https://circleci.com/gh/prometheus/alertmanager"&gt;&lt;img src="https://circleci.com/gh/prometheus/alertmanager/tree/main.svg?style=shield" alt="CircleCI" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;&lt;img src="https://quay.io/repository/prometheus/alertmanager/status" alt="Docker Repository on Quay" title="Docker Repository on Quay" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;&lt;img src="https://img.shields.io/docker/pulls/prom/alertmanager.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct &lt;a href="https://prometheus.io/docs/alerting/latest/configuration/#receiver"&gt;receiver integrations&lt;/a&gt; such as email, PagerDuty, OpsGenie, or many other &lt;a href="https://prometheus.io/docs/operating/integrations/#alertmanager-webhook-receiver"&gt;mechanisms&lt;/a&gt; thanks to the webhook receiver. It also takes care of silencing and inhibition of alerts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://prometheus.io/docs/alerting/alertmanager/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;There are various ways of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Precompiled binaries&lt;/h3&gt; 
&lt;p&gt;Precompiled binaries for released versions are available in the &lt;a href="https://prometheus.io/download/"&gt;&lt;em&gt;download&lt;/em&gt; section&lt;/a&gt; on &lt;a href="https://prometheus.io"&gt;prometheus.io&lt;/a&gt;. Using the latest production release binary is the recommended way of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Docker images&lt;/h3&gt; 
&lt;p&gt;Docker images are available on &lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;Quay.io&lt;/a&gt; or &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can launch an Alertmanager container for trying it out with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ docker run --name alertmanager -d -p 127.0.0.1:9093:9093 quay.io/prometheus/alertmanager
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alertmanager will now be reachable at &lt;a href="http://localhost:9093/"&gt;http://localhost:9093/&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling the binary&lt;/h3&gt; 
&lt;p&gt;You can either &lt;code&gt;go install&lt;/code&gt; it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/...@latest
# cd $GOPATH/src/github.com/prometheus/alertmanager
$ alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or clone the repository and build manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ mkdir -p $GOPATH/src/github.com/prometheus
$ cd $GOPATH/src/github.com/prometheus
$ git clone https://github.com/prometheus/alertmanager.git
$ cd alertmanager
$ make build
$ ./alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also build just one of the binaries in this repo by passing a name to the build function:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make build BINARIES=amtool
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;This is an example configuration that should cover most relevant aspects of the new YAML configuration format. The full documentation of the configuration can be found &lt;a href="https://prometheus.io/docs/alerting/configuration/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;global:
  # The smarthost and SMTP sender used for mail notifications.
  smtp_smarthost: 'localhost:25'
  smtp_from: 'alertmanager@example.org'

# The root route on which each incoming alert enters.
route:
  # The root route must not have any matchers as it is the entry point for
  # all alerts. It needs to have a receiver configured so alerts that do not
  # match any of the sub-routes are sent to someone.
  receiver: 'team-X-mails'

  # The labels by which incoming alerts are grouped together. For example,
  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
  # be batched into a single group.
  #
  # To aggregate by all possible labels use '...' as the sole label name.
  # This effectively disables aggregation entirely, passing through all
  # alerts as-is. This is unlikely to be what you want, unless you have
  # a very low alert volume or your upstream notification system performs
  # its own grouping. Example: group_by: [...]
  group_by: ['alertname', 'cluster']

  # When a new group of alerts is created by an incoming alert, wait at
  # least 'group_wait' to send the initial notification.
  # This way ensures that you get multiple alerts for the same group that start
  # firing shortly after another are batched together on the first
  # notification.
  group_wait: 30s

  # When the first notification was sent, wait 'group_interval' to send a batch
  # of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait 'repeat_interval' to
  # resend them.
  repeat_interval: 3h

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  # The child route trees.
  routes:
  # This route performs a regular expression match on alert labels to
  # catch alerts that are related to a list of services.
  - matchers:
    - service=~"^(foo1|foo2|baz)$"
    receiver: team-X-mails

    # The service has a sub-route for critical alerts, any alerts
    # that do not match, i.e. severity != critical, fall-back to the
    # parent node and are sent to 'team-X-mails'
    routes:
    - matchers:
      - severity="critical"
      receiver: team-X-pager

  - matchers:
    - service="files"
    receiver: team-Y-mails

    routes:
    - matchers:
      - severity="critical"
      receiver: team-Y-pager

  # This route handles all alerts coming from a database service. If there's
  # no team to handle it, it defaults to the DB team.
  - matchers:
    - service="database"

    receiver: team-DB-pager
    # Also group alerts by affected database.
    group_by: [alertname, cluster, database]

    routes:
    - matchers:
      - owner="team-X"
      receiver: team-X-pager

    - matchers:
      - owner="team-Y"
      receiver: team-Y-pager


# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
inhibit_rules:
- source_matchers:
    - severity="critical"
  target_matchers:
    - severity="warning"
  # Apply inhibition if the alertname is the same.
  # CAUTION: 
  #   If all label names listed in `equal` are missing 
  #   from both the source and target alerts,
  #   the inhibition rule will apply!
  equal: ['alertname']


receivers:
- name: 'team-X-mails'
  email_configs:
  - to: 'team-X+alerts@example.org, team-Y+alerts@example.org'

- name: 'team-X-pager'
  email_configs:
  - to: 'team-X+alerts-critical@example.org'
  pagerduty_configs:
  - routing_key: &amp;lt;team-X-key&amp;gt;

- name: 'team-Y-mails'
  email_configs:
  - to: 'team-Y+alerts@example.org'

- name: 'team-Y-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-Y-key&amp;gt;

- name: 'team-DB-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-DB-key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;p&gt;The current Alertmanager API is version 2. This API is fully generated via the &lt;a href="https://github.com/OAI/OpenAPI-Specification/raw/master/versions/2.0.md"&gt;OpenAPI project&lt;/a&gt; and &lt;a href="https://github.com/go-swagger/go-swagger/"&gt;Go Swagger&lt;/a&gt; with the exception of the HTTP handlers themselves. The API specification can be found in &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;api/v2/openapi.yaml&lt;/a&gt;. A HTML rendered version can be accessed &lt;a href="http://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;here&lt;/a&gt;. Clients can be easily generated via any OpenAPI generator for all major languages.&lt;/p&gt; 
&lt;p&gt;APIv2 is accessed via the &lt;code&gt;/api/v2&lt;/code&gt; prefix. APIv1 was deprecated in &lt;code&gt;0.16.0&lt;/code&gt; and is removed as of version &lt;code&gt;0.27.0&lt;/code&gt;. The v2 &lt;code&gt;/status&lt;/code&gt; endpoint would be &lt;code&gt;/api/v2/status&lt;/code&gt;. If &lt;code&gt;--web.route-prefix&lt;/code&gt; is set then API routes are prefixed with that as well, so &lt;code&gt;--web.route-prefix=/alertmanager/&lt;/code&gt; would relate to &lt;code&gt;/alertmanager/api/v2/status&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;amtool&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; is a cli tool for interacting with the Alertmanager API. It is bundled with all releases of Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;Alternatively you can install with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/amtool@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;p&gt;View all currently firing alerts:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool alert
Alertname        Starts At                Summary
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View all currently firing alerts with extended output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to viewing alerts, you can use the rich query syntax provided by Alertmanager:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert query alertname="Test_Alert"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query instance=~".+1"
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query alertname=~"Test.*" instance=~".+1"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Silence an alert:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence add alertname=Test_Alert
b3ede22e-ca14-4aa0-932c-ca2f3445f926

$ amtool silence add alertname="Test_Alert" instance=~".+0"
e48cb58a-0b17-49ba-b734-3585139b1d25
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query
ID                                    Matchers              Ends At                  Created By  Comment
b3ede22e-ca14-4aa0-932c-ca2f3445f926  alertname=Test_Alert  2017-08-02 19:54:50 UTC  kellel

$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire a silence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire b3ede22e-ca14-4aa0-932c-ca2f3445f926
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences matching a query:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel

$ amtool silence expire $(amtool silence query -q instance=~".+0")

$ amtool silence query instance=~".+0"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire $(amtool silence query -q)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try out how a template works. Let's say you have this in your configuration file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;templates:
  - '/foo/bar/*.tmpl'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can test out how a template would look like with example by using this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;amtool template render --template.glob='/foo/bar/*.tmpl' --template.text='{{ template "slack.default.markdown.v1" . }}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows a configuration file to specify some options for convenience. The default configuration file paths are &lt;code&gt;$HOME/.config/amtool/config.yml&lt;/code&gt; or &lt;code&gt;/etc/amtool/config.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;An example configuration file might look like the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Define the path that `amtool` can find your `alertmanager` instance
alertmanager.url: "http://localhost:9093"

# Override the default author. (unset defaults to your username)
author: me@example.com

# Force amtool to give you an error if you don't include a comment on a silence
comment_required: true

# Set a default output format. (unset defaults to simple)
output: extended

# Set a default receiver
receiver: team-X-pager
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Routes&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows you to visualize the routes of your configuration in form of text tree view. Also you can use it to test the routing by passing it label set of an alert and it prints out all receivers the alert would match ordered and separated by &lt;code&gt;,&lt;/code&gt;. (If you use &lt;code&gt;--verify.receivers&lt;/code&gt; amtool returns error code 1 on mismatch)&lt;/p&gt; 
&lt;p&gt;Example of usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# View routing tree of remote Alertmanager
$ amtool config routes --alertmanager.url=http://localhost:9090

# Test if alert matches expected receiver
$ amtool config routes test --config.file=doc/examples/simple.yml --tree --verify.receivers=team-X-pager service=database owner=team-X
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;High Availability&lt;/h2&gt; 
&lt;p&gt;Alertmanager's high availability is in production use at many companies and is enabled by default.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Both UDP and TCP are needed in alertmanager 0.15 and higher for the cluster to work.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you are using a firewall, make sure to whitelist the clustering port for both protocols.&lt;/li&gt; 
  &lt;li&gt;If you are running in a container, make sure to expose the clustering port for both protocols.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To create a highly available cluster of the Alertmanager the instances need to be configured to communicate with each other. This is configured using the &lt;code&gt;--cluster.*&lt;/code&gt; flags.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.listen-address&lt;/code&gt; string: cluster listen address (default "0.0.0.0:9094"; empty string disables HA mode)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.advertise-address&lt;/code&gt; string: cluster advertise address&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer&lt;/code&gt; value: initial peers (repeat flag for each additional peer)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer-timeout&lt;/code&gt; value: peer timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peers-resolve-timeout&lt;/code&gt; value: peers resolve timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.gossip-interval&lt;/code&gt; value: cluster message propagation speed (default "200ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.pushpull-interval&lt;/code&gt; value: lower values will increase convergence speeds at expense of bandwidth (default "1m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.settle-timeout&lt;/code&gt; value: maximum time to wait for cluster connections to settle before evaluating notifications.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.tcp-timeout&lt;/code&gt; value: timeout value for tcp connections, reads and writes (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-timeout&lt;/code&gt; value: time to wait for ack before marking node unhealthy (default "500ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-interval&lt;/code&gt; value: interval between random node probes (default "1s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-interval&lt;/code&gt; value: interval between attempting to reconnect to lost peers (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-timeout&lt;/code&gt; value: length of time to attempt to reconnect to a lost peer (default: "6h0m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.label&lt;/code&gt; value: the label is an optional string to include on each packet and stream. It uniquely identifies the cluster and prevents cross-communication issues when sending gossip messages (default:"")&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The chosen port in the &lt;code&gt;cluster.listen-address&lt;/code&gt; flag is the port that needs to be specified in the &lt;code&gt;cluster.peer&lt;/code&gt; flag of the other peers.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;cluster.advertise-address&lt;/code&gt; flag is required if the instance doesn't have an IP address that is part of &lt;a href="https://tools.ietf.org/html/rfc6890"&gt;RFC 6890&lt;/a&gt; with a default route.&lt;/p&gt; 
&lt;p&gt;To start a cluster of three peers on your local machine use &lt;a href="https://github.com/mattn/goreman"&gt;&lt;code&gt;goreman&lt;/code&gt;&lt;/a&gt; and the Procfile within this repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;goreman start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To point your Prometheus 1.4, or later, instance to multiple Alertmanagers, configure them in your &lt;code&gt;prometheus.yml&lt;/code&gt; configuration file, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager1:9093
      - alertmanager2:9093
      - alertmanager3:9093
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Do not load balance traffic between Prometheus and its Alertmanagers, but instead point Prometheus to a list of all Alertmanagers. The Alertmanager implementation expects all alerts to be sent to all Alertmanagers to ensure high availability.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Turn off high availability&lt;/h3&gt; 
&lt;p&gt;If running Alertmanager in high availability mode is not desired, setting &lt;code&gt;--cluster.listen-address=&lt;/code&gt; prevents Alertmanager from listening to incoming peer requests.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Check the &lt;a href="https://github.com/prometheus/prometheus/raw/main/CONTRIBUTING.md"&gt;Prometheus contributing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To contribute to the user interface, refer to &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/ui/app/CONTRIBUTING.md"&gt;ui/app/CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/prometheus/alertmanager/main/doc/arch.svg?sanitize=true" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0, see &lt;a href="https://github.com/prometheus/alertmanager/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>drakkan/sftpgo</title>
      <link>https://github.com/drakkan/sftpgo</link>
      <description>&lt;p&gt;Full-featured and highly configurable SFTP, HTTP/S, FTP/S and WebDAV server - S3, Google Cloud Storage, Azure Blob&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SFTPGo&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/drakkan/sftpgo/workflows/CI/badge.svg"&gt;&lt;img src="https://github.com/drakkan/sftpgo/workflows/CI/badge.svg?sanitize=true" alt="CI Status" /&gt;&lt;/a&gt; &lt;a href="https://www.gnu.org/licenses/agpl-3.0"&gt;&lt;img src="https://img.shields.io/badge/License-AGPLv3-blue.svg?sanitize=true" alt="License: AGPL-3.0-only" /&gt;&lt;/a&gt; &lt;a href="https://github.com/avelino/awesome-go"&gt;&lt;img src="https://awesome.re/mentioned-badge.svg?sanitize=true" alt="Mentioned in Awesome Go" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Full-featured and highly configurable event-driven file transfer solution. Server protocols: SFTP, HTTP/S, FTP/S, WebDAV. Storage backends: local filesystem, encrypted local filesystem, S3 (compatible) Object Storage, Google Cloud Storage, Azure Blob Storage, other SFTP servers.&lt;/p&gt; 
&lt;p&gt;With SFTPGo you can leverage local and cloud storage backends for exchanging and storing files internally or with business partners using the same tools and processes you are already familiar with.&lt;/p&gt; 
&lt;p&gt;The WebAdmin UI allows to easily create and manage your users, folders, groups and other resources.&lt;/p&gt; 
&lt;p&gt;The WebClient UI allows end users to change their credentials, browse and manage their files in the browser and setup two-factor authentication which works with Microsoft Authenticator, Google Authenticator, Authy and other compatible apps.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;SFTPGo remains committed to open source. The core features are freely available and maintained. If you rely on SFTPGo in your projects, consider becoming a &lt;a href="https://github.com/sponsors/drakkan"&gt;sponsor&lt;/a&gt; to help ensure its long-term sustainability.&lt;/p&gt; 
&lt;p&gt;Your sponsorship helps cover maintenance, security updates and ongoing development of the open-source edition.&lt;/p&gt; 
&lt;h3&gt;Thank you to our sponsors&lt;/h3&gt; 
&lt;h4&gt;Platinum sponsors&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://www.aledade.com/"&gt;&lt;img src="https://raw.githubusercontent.com/drakkan/sftpgo/main/img/Aledade_logo.png" alt="Aledade logo" width="202" height="70" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.jumptrading.com/"&gt;&lt;img src="https://raw.githubusercontent.com/drakkan/sftpgo/main/img/jumptrading.png" alt="Jump Trading logo" width="362" height="63" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://wpengine.com/"&gt;&lt;img src="https://raw.githubusercontent.com/drakkan/sftpgo/main/img/wpengine.png" alt="WP Engine logo" width="331" height="63" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Silver sponsors&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://idcs.ip-paris.fr/"&gt;&lt;img src="https://raw.githubusercontent.com/drakkan/sftpgo/main/img/IDCS.png" alt="IDCS logo" width="212" height="51" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Bronze sponsors&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://www.7digital.com/"&gt;&lt;img src="https://raw.githubusercontent.com/drakkan/sftpgo/main/img/7digital.png" alt="7digital logo" width="178" height="56" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://servinga.com/"&gt;&lt;img src="https://raw.githubusercontent.com/drakkan/sftpgo/main/img/servinga.png" alt="servinga logo" width="258" height="56" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.reui.io/"&gt;&lt;img src="https://raw.githubusercontent.com/drakkan/sftpgo/main/img/reui.png" alt="ReUI logo" width="151" height="56" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;The open-source version of SFTPGo is free to use under the terms of its &lt;a href="https://raw.githubusercontent.com/drakkan/sftpgo/main/#license"&gt;license&lt;/a&gt;. We are proud to provide a robust and fully functional edition that meets the needs of many production environments.&lt;/p&gt; 
&lt;p&gt;While we do not offer direct free support, community support is available. You can use &lt;a href="https://github.com/drakkan/sftpgo/discussions"&gt;GitHub Discussions&lt;/a&gt; to ask questions, share feedback and engage with other users of the project.&lt;/p&gt; 
&lt;p&gt;If you require guaranteed support, expert guidance, or advanced features, consider using SFTPGo Enterprise: a commercially licensed edition of SFTPGo that extends the open source version with enterprise-only features and full support.&lt;/p&gt; 
&lt;p&gt;SFTPGo Enterprise is available in two deployment options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;On-premises: Deploy on your own infrastructure with full control and commercial-grade support. More details: &lt;a href="https://sftpgo.com/on-premises"&gt;sftpgo.com/on-premises&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fully managed SaaS: Let us handle the infrastructure. Ideal for teams that want a secure, scalable, and maintenance-free setup with full support included. More details: &lt;a href="https://sftpgo.com/saas"&gt;sftpgo.com/saas&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;You can explore all supported features and configuration options at &lt;a href="https://docs.sftpgo.com/"&gt;docs.sftpgo.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can select the version you're using from the top-left corner of the documentation site. If you're using the open-source edition, please make sure to switch to the corresponding documentation. The "Enterprise" docs, shown by default, include features that may only be available in the licensed edition or our SaaS offerings.&lt;/p&gt; 
&lt;h2&gt;Internationalization&lt;/h2&gt; 
&lt;p&gt;The translations are available via &lt;a href="https://crowdin.com/project/sftpgo"&gt;Crowdin&lt;/a&gt;, who have granted us an open source license.&lt;/p&gt; 
&lt;p&gt;Before start translating please take a look at our contribution &lt;a href="https://sftpgo.github.io/latest/web-interfaces/#internationalization"&gt;guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Release Cadence&lt;/h2&gt; 
&lt;p&gt;SFTPGo follows a feature-driven release cycle rather than a fixed, time-based schedule. Currently, our primary development efforts are focused on the &lt;a href="https://docs.sftpgo.com/enterprise/#enterprise-edition"&gt;Enterprise edition&lt;/a&gt;, which benefits from a faster release cadence and receives major new features (see &lt;a href="https://docs.sftpgo.com/enterprise/changelog/"&gt;changelog&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;This open-source version of SFTPGo remains maintained and will continue to receive bug fixes and essential updates. However, not all enhancements introduced in the Enterprise edition will be available.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;SFTPGo makes use of the third party libraries listed inside &lt;a href="https://raw.githubusercontent.com/drakkan/sftpgo/main/go.mod"&gt;go.mod&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We are very grateful to all the people who contributed with ideas and/or pull requests.&lt;/p&gt; 
&lt;p&gt;Thank you to &lt;a href="https://www.ysura.com/"&gt;ysura&lt;/a&gt; for granting us stable access to a test AWS S3 account.&lt;/p&gt; 
&lt;p&gt;Thank you to &lt;a href="https://keenthemes.com/"&gt;KeenThemes&lt;/a&gt; for granting us a custom license to use their amazing &lt;a href="https://keenthemes.com/bootstrap-templates"&gt;themes&lt;/a&gt; for the SFTPGo WebAdmin and WebClient user interfaces, across both the Open Source and Open Core versions.&lt;/p&gt; 
&lt;p&gt;Thank you to &lt;a href="https://crowdin.com/"&gt;Crowdin&lt;/a&gt; for granting us an Open Source License.&lt;/p&gt; 
&lt;p&gt;Thank you to &lt;a href="https://www.incode.it/"&gt;Incode&lt;/a&gt; for helping us to improve the UI/UX.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;SFTPGo source code is licensed under the GNU AGPL-3.0-only with &lt;a href="https://raw.githubusercontent.com/drakkan/sftpgo/main/NOTICE"&gt;additional terms&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://keenthemes.com/bootstrap-templates"&gt;theme&lt;/a&gt; used in WebAdmin and WebClient user interfaces is proprietary, this means:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;KeenThemes HTML/CSS/JS components are allowed for use only within the SFTPGo product and restricted to be used in a resealable HTML template that can compete with KeenThemes products anyhow.&lt;/li&gt; 
 &lt;li&gt;The SFTPGo WebAdmin and WebClient user interfaces (HTML, CSS and JS components) based on this theme are allowed for use only within the SFTPGo product and therefore cannot be used in derivative works/products without an explicit grant from the &lt;a href="mailto:support@sftpgo.com"&gt;SFTPGo Team&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More information about &lt;a href="https://sftpgo.com/compliance.html"&gt;compliance&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We do not provide legal advice. If you have questions about license compliance or whether your use case is permitted under the license terms, please consult your legal team.&lt;/p&gt; 
&lt;h2&gt;Copyright&lt;/h2&gt; 
&lt;p&gt;Copyright (C) 2019 - 2025 Nicola Murino&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenCSGs/csghub-server</title>
      <link>https://github.com/OpenCSGs/csghub-server</link>
      <description>&lt;p&gt;csghub-server is the backend server for CSGHub which helps user to manage datasets, modes, and also run Model Inference, Finetune and Application Spaces.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;&lt;a href="https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/README_en.md"&gt;English&lt;/a&gt; ∙ &lt;a href="https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/README_cn.md"&gt;简体中文&lt;/a&gt; ∙ &lt;a href="https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/README_ja.md"&gt;日本語&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;CSGHub Server&lt;/code&gt; is a part of the open source and reliable large model assets management platform - &lt;a href="https://github.com/OpenCSGs/CSGHub/"&gt;CSGHub&lt;/a&gt;. It focuses on management of models、datasets and other LLM assets through REST API。&lt;/p&gt; 
&lt;h2&gt;Key Features：&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creation and Management of users and orgnizations&lt;/li&gt; 
 &lt;li&gt;Auto-tagging of model and dataset labels&lt;/li&gt; 
 &lt;li&gt;Search for users, organizations, models, and data&lt;/li&gt; 
 &lt;li&gt;Online preview of dataset files, like &lt;code&gt;.parquet&lt;/code&gt; file&lt;/li&gt; 
 &lt;li&gt;Content moderation for both text and image&lt;/li&gt; 
 &lt;li&gt;Download of individual files, including LFS files&lt;/li&gt; 
 &lt;li&gt;Tracking of model and dataset activity data, such as downloads and likes volume&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;In order to help users to quickly understand the features and usage of CSGHub, we have recorded a demo video. You can watch this video to get a quick understanding of the main features and operation procedures of this program.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CSGHub Demo video is as blew，you can also check it at &lt;a href="https://www.youtube.com/watch?v=SFDISpqowXs"&gt;YouTube&lt;/a&gt; or &lt;a href="https://www.bilibili.com/video/BV12T4y187bv/"&gt;Bilibili&lt;/a&gt; 
  &lt;video width="658" height="432" src="https://github-production-user-asset-6210df.s3.amazonaws.com/3232817/296556812-205d07f2-de9d-4a7f-b3f5-83514a71453e.mp4"&gt;&lt;/video&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please visit the &lt;a href="https://portal.opencsg.com/models"&gt;OpenCSG website&lt;/a&gt; to experience the powerful management features.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;System resource requirements: 4c CPU/8GB memory&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Please install Docker yourself. This project has been tested in Ubuntu22 environment.&lt;/p&gt; 
&lt;p&gt;You can quickly deploy the localized &lt;code&gt;CSGHub Server&lt;/code&gt; service through docker-compose:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# The API token should be at least 128 characters long, and HTTP requests to csghub-server require the API token to be sent as a Bearer token for authentication.
export STARHUB_SERVER_API_TOKEN=&amp;lt;API token&amp;gt;
mkdir -m 777 gitea minio_data
curl -L https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/docker-compose.yml -o docker-compose.yml
docker-compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Start CSGHub Server Services Locally&lt;/h2&gt; 
&lt;p&gt;CSGHub supports TOML format for config files. When starting any service from the command line, you can specify the config file with the &lt;code&gt;--config&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go run cmd/csghub-server/main.go start server --config local.toml
go run cmd/csghub-server/main.go deploy runner --config local.toml
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We provide an &lt;a href="https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/common/config/config.toml.example"&gt;example config file&lt;/a&gt;, you can rename it, modify as needed and use. All available configurations are defined in &lt;a href="https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/common/config/config.go"&gt;this Go file&lt;/a&gt;. The TOML configuration uses snake_case naming convention, and names automatically map to corresponding struct field names.&lt;/p&gt; 
&lt;h2&gt;Technical Architecture&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/docs/csghub_server-arch.png" alt="csghub-server architecture" width="800px" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Extensible and customizable&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports different git servers, such as Gitea, GitLab, etc.&lt;/li&gt; 
 &lt;li&gt;Supports flexible configuration of the LFS storage system, and you can choose to use local or any third-party cloud storage service that is compatible with the S3 protocol.&lt;/li&gt; 
 &lt;li&gt;Enable content moderation on demand, and choose any third-party content moderation service.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Support more Git Servers: Currently supports Gitea, and plans to support mainstream Git repositories in the future.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Git LFS: Git LFS supports large files, and supports Git command operations and online download through the Web UI.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; DataSet online viewer: Data set preview, supports the Top20/TopN loading preview of LFS format data sets.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Model/Dataset AutoTag: Supports custom metadata and automatic extraction of model/dataset tags.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; S3 Protocol Support: Supports S3 (MinIO) storage protocol, providing higher reliability and storage cost-effectiveness.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Model format convert: Conversion of mainstream model formats.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Model oneclick deploy: Supports integration with OpenCSG llm-inference, one-click to start model inference.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;We use the Apache 2.0 license, the content of which is detailed in the &lt;code&gt;LICENSE&lt;/code&gt; file.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you wish to contribute, please follow the &lt;a href="https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/docs/en/contributing.md"&gt;Contribution Guidelines&lt;/a&gt;. We are very excited about your contributions!&lt;/p&gt; 
&lt;p&gt;Before you begin development, we highly recommend checking out our &lt;a href="https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/contribute/"&gt;Backend Developer Guides&lt;/a&gt;, which provide helpful information to ensure a smooth development process.&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;This project is based on open source projects such as Gin, DuckDB, minio, and Gitea. We would like to express our sincere gratitude to them for their open source contributions!&lt;/p&gt; 
&lt;h3&gt;CONTACT WITH US&lt;/h3&gt; 
&lt;p&gt;If you meet any problem during usage, you can contact with us by any following way:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;initiate an issue in github&lt;/li&gt; 
 &lt;li&gt;join our WeChat group by scaning wechat helper qrcode&lt;/li&gt; 
 &lt;li&gt;join our offical discord channel: &lt;a href="https://discord.gg/bXnu4C9BkR"&gt;OpenCSG Discord Channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;join our slack workspace:&lt;a href="https://join.slack.com/t/opencsghq/shared_invite/zt-2fmtem7hs-s_RmMeoOIoF1qzslql2q~A"&gt;OpenCSG Slack Channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="display:inline-block"&gt; 
 &lt;img src="https://github.com/OpenCSGs/csghub/raw/main/docs/images/wechat-assistant-new.png" width="200" /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
 &lt;img src="https://github.com/OpenCSGs/csghub/raw/main/docs/images/discord-qrcode.png" width="200" /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
 &lt;img src="https://github.com/OpenCSGs/csghub/raw/main/docs/images/slack-qrcode.png" width="200" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VictoriaMetrics/VictoriaMetrics</title>
      <link>https://github.com/VictoriaMetrics/VictoriaMetrics</link>
      <description>&lt;p&gt;VictoriaMetrics: fast, cost-effective monitoring solution and time series database&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VictoriaMetrics&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaMetrics?sort=semver&amp;amp;label=&amp;amp;filter=!*-victorialogs&amp;amp;logo=github&amp;amp;labelColor=gray&amp;amp;color=gray&amp;amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Freleases%2Flatest" alt="Latest Release" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/victoriametrics/victoria-metrics?label=&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;labelColor=2496ED&amp;amp;color=2496ED&amp;amp;link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-metrics" alt="Docker Pulls" /&gt; &lt;a href="https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaMetrics"&gt;&lt;img src="https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaMetrics?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics" alt="Go Report" /&gt;&lt;/a&gt; &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml/badge.svg?branch=master&amp;amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Factions" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://app.codecov.io/gh/VictoriaMetrics/VictoriaMetrics"&gt;&lt;img src="https://codecov.io/gh/VictoriaMetrics/VictoriaMetrics/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaMetrics" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/VictoriaMetrics/VictoriaMetrics?labelColor=green&amp;amp;label=&amp;amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Fblob%2Fmaster%2FLICENSE" alt="License" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/Join-4A154B?logo=slack&amp;amp;link=https%3A%2F%2Fslack.victoriametrics.com" alt="Slack" /&gt; &lt;a href="https://x.com/VictoriaMetrics/"&gt;&lt;img src="https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&amp;amp;label=Follow&amp;amp;color=black&amp;amp;logo=x&amp;amp;labelColor=black&amp;amp;link=https%3A%2F%2Fx.com%2FVictoriaMetrics" alt="X" /&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/VictoriaMetrics/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&amp;amp;label=Join&amp;amp;labelColor=red&amp;amp;logoColor=white&amp;amp;logo=reddit&amp;amp;link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics" alt="Reddit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source srcset="docs/victoriametrics/logo_white.webp" media="(prefers-color-scheme: dark)" /&gt; 
 &lt;source srcset="docs/victoriametrics/logo.webp" media="(prefers-color-scheme: light)" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/VictoriaMetrics/VictoriaMetrics/master/docs/victoriametrics/logo.webp" width="300" alt="VictoriaMetrics logo" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;VictoriaMetrics is a fast, cost-saving, and scalable solution for monitoring and managing time series data. It delivers high performance and reliability, making it an ideal choice for businesses of all sizes.&lt;/p&gt; 
&lt;p&gt;Here are some resources and information about VictoriaMetrics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://docs.victoriametrics.com"&gt;docs.victoriametrics.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Case studies: &lt;a href="https://docs.victoriametrics.com/victoriametrics/casestudies/"&gt;Grammarly, Roblox, Wix,...&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Available: &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest"&gt;Binary releases&lt;/a&gt;, docker images &lt;a href="https://hub.docker.com/r/victoriametrics/victoria-metrics/"&gt;Docker Hub&lt;/a&gt; and &lt;a href="https://quay.io/repository/victoriametrics/victoria-metrics"&gt;Quay&lt;/a&gt;, &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics"&gt;Source code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Deployment types: &lt;a href="https://docs.victoriametrics.com/"&gt;Single-node version&lt;/a&gt;, &lt;a href="https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/"&gt;Cluster version&lt;/a&gt;, and &lt;a href="https://docs.victoriametrics.com/victoriametrics/enterprise/"&gt;Enterprise version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Changelog: &lt;a href="https://docs.victoriametrics.com/victoriametrics/changelog/"&gt;CHANGELOG&lt;/a&gt;, and &lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-upgrade-victoriametrics"&gt;How to upgrade&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community: &lt;a href="https://slack.victoriametrics.com/"&gt;Slack&lt;/a&gt;, &lt;a href="https://x.com/VictoriaMetrics"&gt;X (Twitter)&lt;/a&gt;, &lt;a href="https://www.linkedin.com/company/victoriametrics/"&gt;LinkedIn&lt;/a&gt;, &lt;a href="https://www.youtube.com/@VictoriaMetrics"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Yes, we open-source both the single-node VictoriaMetrics and the cluster version.&lt;/p&gt; 
&lt;h2&gt;Prominent features&lt;/h2&gt; 
&lt;p&gt;VictoriaMetrics is optimized for timeseries data, even when old time series are constantly replaced by new ones at a high rate, it offers a lot of features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Long-term storage for Prometheus&lt;/strong&gt; or as a drop-in replacement for Prometheus and Graphite in Grafana.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Powerful stream aggregation&lt;/strong&gt;: Can be used as a StatsD alternative.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ideal for big data&lt;/strong&gt;: Works well with large amounts of time series data from APM, Kubernetes, IoT sensors, connected cars, industrial telemetry, financial data and various &lt;a href="https://docs.victoriametrics.com/victoriametrics/enterprise/"&gt;Enterprise workloads&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query language&lt;/strong&gt;: Supports both PromQL and the more performant MetricsQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to setup&lt;/strong&gt;: No dependencies, single &lt;a href="https://medium.com/@valyala/stripping-dependency-bloat-in-victoriametrics-docker-image-983fb5912b0d"&gt;small binary&lt;/a&gt;, configuration through command-line flags, but the default is also fine-tuned; backup and restore with &lt;a href="https://medium.com/@valyala/how-victoriametrics-makes-instant-snapshots-for-multi-terabyte-time-series-data-e1f3fb0e0282"&gt;instant snapshots&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Global query view&lt;/strong&gt;: Multiple Prometheus instances or any other data sources may ingest data into VictoriaMetrics and queried via a single query.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Various Protocols&lt;/strong&gt;: Support metric scraping, ingestion and backfilling in various protocol. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-scrape-prometheus-exporters-such-as-node-exporter"&gt;Prometheus exporters&lt;/a&gt;, &lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/prometheus/"&gt;Prometheus remote write API&lt;/a&gt;, &lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-prometheus-exposition-format"&gt;Prometheus exposition format&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/influxdb/"&gt;InfluxDB line protocol&lt;/a&gt; over HTTP, TCP and UDP.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/graphite/#ingesting"&gt;Graphite plaintext protocol&lt;/a&gt; with &lt;a href="https://graphite.readthedocs.io/en/latest/tags.html#carbon"&gt;tags&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-telnet"&gt;OpenTSDB put message&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-http"&gt;HTTP OpenTSDB /api/put requests&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-json-line-format"&gt;JSON line format&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-csv-data"&gt;Arbitrary CSV data&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-native-format"&gt;Native binary format&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/datadog/"&gt;DataDog agent or DogStatsD&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/newrelic/#sending-data-from-agent"&gt;NewRelic infrastructure agent&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#sending-data-via-opentelemetry"&gt;OpenTelemetry metrics format&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NFS-based storages&lt;/strong&gt;: Supports storing data on NFS-based storages such as Amazon EFS, Google Filestore.&lt;/li&gt; 
 &lt;li&gt;And many other features such as metrics relabeling, cardinality limiter, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Enterprise version&lt;/h2&gt; 
&lt;p&gt;In addition, the Enterprise version includes extra features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anomaly detection&lt;/strong&gt;: Automation and simplification of your alerting rules, covering complex anomalies found in metrics data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backup automation&lt;/strong&gt;: Automates regular backup procedures.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple retentions&lt;/strong&gt;: Reducing storage costs by specifying different retentions for different datasets.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Downsampling&lt;/strong&gt;: Reducing storage costs and increasing performance for queries over historical data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stable releases&lt;/strong&gt; with long-term support lines (&lt;a href="https://docs.victoriametrics.com/victoriametrics/lts-releases/"&gt;LTS&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive support&lt;/strong&gt;: First-class consulting, feature requests and technical support provided by the core VictoriaMetrics dev team.&lt;/li&gt; 
 &lt;li&gt;Many other features, which you can read about on &lt;a href="https://docs.victoriametrics.com/victoriametrics/enterprise/"&gt;the Enterprise page&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="mailto:info@victoriametrics.com"&gt;Contact us&lt;/a&gt; if you need enterprise support for VictoriaMetrics. Or you can request a free trial license &lt;a href="https://victoriametrics.com/products/enterprise/trial/"&gt;here&lt;/a&gt;, downloaded Enterprise binaries are available at &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest"&gt;Github Releases&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We strictly apply security measures in everything we do. VictoriaMetrics has achieved security certifications for Database Software Development and Software-Based Monitoring Services. See &lt;a href="https://victoriametrics.com/security/"&gt;Security page&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;Some good benchmarks VictoriaMetrics achieved:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Minimal memory footprint&lt;/strong&gt;: handling millions of unique timeseries with &lt;a href="https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893"&gt;10x less RAM&lt;/a&gt; than InfluxDB, up to &lt;a href="https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f"&gt;7x less RAM&lt;/a&gt; than Prometheus, Thanos or Cortex.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Highly scalable and performance&lt;/strong&gt; for &lt;a href="https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b"&gt;data ingestion&lt;/a&gt; and &lt;a href="https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4"&gt;querying&lt;/a&gt;, &lt;a href="https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893"&gt;20x outperforms&lt;/a&gt; InfluxDB and TimescaleDB.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High data compression&lt;/strong&gt;: &lt;a href="https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4"&gt;70x more data points&lt;/a&gt; may be stored into limited storage than TimescaleDB, &lt;a href="https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f"&gt;7x less storage&lt;/a&gt; space is required than Prometheus, Thanos or Cortex.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reducing storage costs&lt;/strong&gt;: &lt;a href="https://docs.victoriametrics.com/victoriametrics/casestudies/#grammarly"&gt;10x more effective&lt;/a&gt; than Graphite according to the Grammarly case study.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A single-node VictoriaMetrics&lt;/strong&gt; can replace medium-sized clusters built with competing solutions such as Thanos, M3DB, Cortex, InfluxDB or TimescaleDB. See &lt;a href="https://medium.com/@valyala/comparing-thanos-to-victoriametrics-cluster-b193bea1683"&gt;VictoriaMetrics vs Thanos&lt;/a&gt;, &lt;a href="https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae"&gt;Measuring vertical scalability&lt;/a&gt;, &lt;a href="https://promcon.io/2019-munich/talks/remote-write-storage-wars/"&gt;Remote write storage wars - PromCon 2019&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimized for storage&lt;/strong&gt;: &lt;a href="https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b"&gt;Works well with high-latency IO&lt;/a&gt; and low IOPS (HDD and network storage in AWS, Google Cloud, Microsoft Azure, etc.).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community and contributions&lt;/h2&gt; 
&lt;p&gt;Feel free asking any questions regarding VictoriaMetrics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://slack.victoriametrics.com/"&gt;Slack Inviter&lt;/a&gt; and &lt;a href="https://victoriametrics.slack.com/"&gt;Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/VictoriaMetrics/"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/company/victoriametrics/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/VictoriaMetrics/"&gt;Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/VictoriaMetrics_en"&gt;Telegram-en&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/VictoriaMetrics_ru1"&gt;Telegram-ru&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@victoriametrics/"&gt;Mastodon&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you like VictoriaMetrics and want to contribute, then please &lt;a href="https://docs.victoriametrics.com/victoriametrics/contributing/"&gt;read these docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;VictoriaMetrics Logo&lt;/h2&gt; 
&lt;p&gt;The provided &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/raw/master/VM_logo.zip"&gt;ZIP file&lt;/a&gt; contains three folders with different logo orientations. Each folder includes the following file types:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JPEG: Preview files&lt;/li&gt; 
 &lt;li&gt;PNG: Preview files with transparent background&lt;/li&gt; 
 &lt;li&gt;AI: Adobe Illustrator files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;VictoriaMetrics Logo Usage Guidelines&lt;/h3&gt; 
&lt;h4&gt;Font&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Font Used: Lato Black&lt;/li&gt; 
 &lt;li&gt;Download here: &lt;a href="https://fonts.google.com/specimen/Lato"&gt;Lato Font&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Color Palette&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Black &lt;a href="https://www.color-hex.com/color/000000"&gt;#000000&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Purple &lt;a href="https://www.color-hex.com/color/4d0e82"&gt;#4d0e82&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Orange &lt;a href="https://www.color-hex.com/color/ff2e00"&gt;#ff2e00&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;White &lt;a href="https://www.color-hex.com/color/ffffff"&gt;#ffffff&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Logo Usage Rules&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Only use the Lato Black font as specified.&lt;/li&gt; 
 &lt;li&gt;Maintain sufficient clear space around the logo for visibility.&lt;/li&gt; 
 &lt;li&gt;Do not modify the spacing, alignment, or positioning of design elements.&lt;/li&gt; 
 &lt;li&gt;You may resize the logo as needed, but ensure all proportions remain intact.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Thank you for your cooperation!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kgateway-dev/kgateway</title>
      <link>https://github.com/kgateway-dev/kgateway</link>
      <description>&lt;p&gt;The Cloud-Native API Gateway and AI Gateway&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo-dark.svg" alt="kgateway" width="400" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg" alt="kgateway" width="400" /&gt; 
  &lt;img alt="kgateway" src="https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; &lt;br /&gt; An Envoy-Powered, Kubernetes-Native API Gateway &lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://bestpractices.coreinfrastructure.org/projects/10534"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/10534/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;About kgateway&lt;/h2&gt; 
&lt;p&gt;Kgateway is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;An ingress/edge router for Kubernetes&lt;/strong&gt;: Powered by &lt;a href="https://www.envoyproxy.io"&gt;Envoy&lt;/a&gt; and programmed with the &lt;a href="https://gateway-api.sigs.k8s.io/"&gt;Gateway API&lt;/a&gt;, kgateway is a world-leading Cloud Native ingress.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;An advanced API gateway&lt;/strong&gt;: Aggregate web APIs and apply key functions like authentication, authorization and rate limiting in one place&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A better waypoint proxy for &lt;a href="https://ambientmesh.io/"&gt;ambient mesh&lt;/a&gt;&lt;/strong&gt;: Use the same stack for east-west management as you do for north-south.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;An AI gateway for securing LLM usage&lt;/strong&gt;: Protect applications, models, and data from inappropriate access or use, whether you're producing or consuming. Manage traffic to LLM providers, and enrich prompts at a system level.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;An LLM Gateway utilizing the &lt;a href="https://gateway-api-inference-extension.sigs.k8s.io/"&gt;Inference Extension&lt;/a&gt; project&lt;/strong&gt;: Intelligently route to AI inference workloads and LLMs in your Kubernetes environment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A model context protocol (MCP) gateway&lt;/strong&gt;: Federate MCP tool servers into a single, scalable and secure endpoint.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A migration engine for hybrid apps&lt;/strong&gt;: Route to backends implemented as microservices, serverless functions or legacy apps. This can help you gradually migrate from legacy code to microservices and serverless, add new functionalities using cloud-native technologies while maintaining a legacy codebase or allow different teams in an organization to choose different architectures.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Kgateway is feature-rich, fast, and flexible. It excels in function-level routing, supports legacy apps, microservices and serverless, offers robust discovery capabilities, integrates seamlessly with open-source projects, and is designed to support hybrid applications with various technologies, architectures, protocols, and clouds.&lt;/p&gt; 
&lt;p&gt;The project was previously known as Gloo, and has been &lt;a href="https://www.solo.io/blog/announcing-gloo-1-0-a-production-ready-envoy-based-api-gateway"&gt;production-ready since 2019&lt;/a&gt;. Please see &lt;a href="https://github.com/kgateway-dev/kgateway/issues/10363"&gt;the migration plan&lt;/a&gt; for more information and the current status of the change from Gloo to kgateway.&lt;/p&gt; 
&lt;h2&gt;Get involved&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kgateway.dev/slack/"&gt;Join us on our Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kgateway.dev/docs"&gt;Check out the docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kgateway.dev/blog/"&gt;Read the kgateway blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kgateway-dev/community"&gt;Learn more about the community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@kgateway-dev"&gt;Watch a video on our YouTube channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://x.com/kgatewaydev"&gt;X&lt;/a&gt;, &lt;a href="https://bsky.app/profile/kgateway.dev"&gt;Bluesky&lt;/a&gt;, &lt;a href="https://mastodon.social/@kgateway"&gt;Mastodon&lt;/a&gt; or &lt;a href="https://www.linkedin.com/company/kgateway/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing to kgateway&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/kgateway-dev/kgateway/main/devel/contributing/README.md"&gt;devel/contributing/README.md&lt;/a&gt; as a starting point for contributing to the project.&lt;/p&gt; 
&lt;h2&gt;Releasing kgateway&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/kgateway-dev/kgateway/main/devel/contributing/releasing.md"&gt;devel/contributing/releasing.md&lt;/a&gt; as a starting point for understanding releases of the project.&lt;/p&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;p&gt;Kgateway would not be possible without the valuable open source work of projects in the community. We would like to extend a special thank-you to &lt;a href="https://www.envoyproxy.io"&gt;Envoy&lt;/a&gt;, upon whose shoulders we stand.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/kgateway-dev/kgateway/main/SECURITY.md"&gt;SECURITY.md&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/cncf/artwork/main/other/cncf-sandbox/horizontal/color/cncf-sandbox-horizontal-color.svg?sanitize=true" width="300" alt="Cloud Native Computing Foundation logo" /&gt; 
 &lt;p&gt;kgateway is a &lt;a href="https://cncf.io"&gt;Cloud Native Computing Foundation&lt;/a&gt; sandbox project.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>moby/moby</title>
      <link>https://github.com/moby/moby</link>
      <description>&lt;p&gt;The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Moby Project&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/moby/moby/v2"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/moby/moby/v2" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/license/moby/moby" alt="GitHub License" /&gt; &lt;a href="https://goreportcard.com/report/github.com/moby/moby/v2"&gt;&lt;img src="https://goreportcard.com/badge/github.com/moby/moby/v2" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/moby/moby"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/moby/moby/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/10989"&gt;&lt;img src="https://www.bestpractices.dev/projects/10989/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/moby/moby/master/docs/static_files/moby-project-logo.png" alt="Moby Project logo" title="The Moby Project" /&gt;&lt;/p&gt; 
&lt;p&gt;Moby is an open-source project created by Docker to enable and accelerate software containerization.&lt;/p&gt; 
&lt;p&gt;It provides a "Lego set" of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas. Components include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.&lt;/p&gt; 
&lt;h2&gt;Principles&lt;/h2&gt; 
&lt;p&gt;Moby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience. It is open to the community to help set its direction.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modular: the project includes lots of components that have well-defined functions and APIs that work together.&lt;/li&gt; 
 &lt;li&gt;Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.&lt;/li&gt; 
 &lt;li&gt;Usable security: Moby provides secure defaults without compromising usability.&lt;/li&gt; 
 &lt;li&gt;Developer focused: The APIs are intended to be functional and useful to build powerful tools. They are not necessarily intended as end user tools but as components aimed at developers. Documentation and UX is aimed at developers not end users.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Audience&lt;/h2&gt; 
&lt;p&gt;The Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers. It is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.&lt;/p&gt; 
&lt;h2&gt;Relationship with Docker&lt;/h2&gt; 
&lt;p&gt;The components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project. New projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product. However, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.&lt;/p&gt; 
&lt;p&gt;The Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful. The releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; and &lt;a href="https://www.mirantis.com/software/mirantis-container-runtime/"&gt;Mirantis Container Runtime&lt;/a&gt; are the appropriate products for these use cases.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Legal&lt;/h1&gt; 
&lt;p&gt;&lt;em&gt;Brought to you courtesy of our legal counsel. For more context, please see the &lt;a href="https://github.com/moby/moby/raw/master/NOTICE"&gt;NOTICE&lt;/a&gt; document in this repo.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Use and transfer of Moby may be subject to certain restrictions by the United States and other governments.&lt;/p&gt; 
&lt;p&gt;It is your responsibility to ensure that your use and/or transfer does not violate applicable laws.&lt;/p&gt; 
&lt;p&gt;For more information, please see &lt;a href="https://www.bis.doc.gov"&gt;https://www.bis.doc.gov&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Licensing&lt;/h1&gt; 
&lt;p&gt;Moby is licensed under the Apache License, Version 2.0. See &lt;a href="https://github.com/moby/moby/raw/master/LICENSE"&gt;LICENSE&lt;/a&gt; for the full license text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>juanfont/headscale</title>
      <link>https://github.com/juanfont/headscale</link>
      <description>&lt;p&gt;An open source, self-hosted implementation of the Tailscale control server&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juanfont/headscale/main/docs/logo/headscale3_header_stacked_left.png" alt="headscale logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/juanfont/headscale/actions/workflows/test.yml/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/p&gt; 
&lt;p&gt;An open source, self-hosted implementation of the Tailscale control server.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/c84AZQhmpx"&gt;Discord server&lt;/a&gt; for a chat.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Always select the same GitHub tag as the released version you use to ensure you have the correct example configuration. The &lt;code&gt;main&lt;/code&gt; branch might contain unreleased changes. The documentation is available for stable and development versions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://headscale.net/stable/"&gt;Documentation for the stable version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://headscale.net/development/"&gt;Documentation for the development version&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is Tailscale&lt;/h2&gt; 
&lt;p&gt;Tailscale is &lt;a href="https://tailscale.com/"&gt;a modern VPN&lt;/a&gt; built on top of &lt;a href="https://www.wireguard.com/"&gt;Wireguard&lt;/a&gt;. It &lt;a href="https://tailscale.com/blog/how-tailscale-works/"&gt;works like an overlay network&lt;/a&gt; between the computers of your networks - using &lt;a href="https://tailscale.com/blog/how-nat-traversal-works/"&gt;NAT traversal&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Everything in Tailscale is Open Source, except the GUI clients for proprietary OS (Windows and macOS/iOS), and the control server.&lt;/p&gt; 
&lt;p&gt;The control server works as an exchange point of Wireguard public keys for the nodes in the Tailscale network. It assigns the IP addresses of the clients, creates the boundaries between each user, enables sharing machines between users, and exposes the advertised routes of your nodes.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://tailscale.com/kb/1136/tailnet/"&gt;Tailscale network (tailnet)&lt;/a&gt; is private network which Tailscale assigns to a user in terms of private users or an organisation.&lt;/p&gt; 
&lt;h2&gt;Design goal&lt;/h2&gt; 
&lt;p&gt;Headscale aims to implement a self-hosted, open source alternative to the &lt;a href="https://tailscale.com/"&gt;Tailscale&lt;/a&gt; control server. Headscale's goal is to provide self-hosters and hobbyists with an open-source server they can use for their projects and labs. It implements a narrow scope, a &lt;em&gt;single&lt;/em&gt; Tailscale network (tailnet), suitable for a personal use, or a small open-source organisation.&lt;/p&gt; 
&lt;h2&gt;Supporting Headscale&lt;/h2&gt; 
&lt;p&gt;If you like &lt;code&gt;headscale&lt;/code&gt; and find it useful, there is a sponsorship and donation buttons available in the repo.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://headscale.net/stable/about/features/"&gt;"Features" in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Client OS support&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://headscale.net/stable/about/clients/"&gt;"Client and operating system support" in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Running headscale&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Please note that we do not support nor encourage the use of reverse proxies and container to run Headscale.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Please have a look at the &lt;a href="https://headscale.net/stable/"&gt;&lt;code&gt;documentation&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Talks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fosdem 2023 (video): &lt;a href="https://fosdem.org/2023/schedule/event/goheadscale/"&gt;Headscale: How we are using integration testing to reimplement Tailscale&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;presented by Juan Font Alonso and Kristoffer Dalby&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is not associated with Tailscale Inc.&lt;/p&gt; 
&lt;p&gt;However, one of the active maintainers for Headscale &lt;a href="https://tailscale.com/blog/opensource"&gt;is employed by Tailscale&lt;/a&gt; and he is allowed to spend work hours contributing to the project. Contributions from this maintainer are reviewed by other maintainers.&lt;/p&gt; 
&lt;p&gt;The maintainers work together on setting the direction for the project. The underlying principle is to serve the community of self-hosters, enthusiasts and hobbyists - while having a sustainable project.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/juanfont/headscale/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;To contribute to headscale you would need the latest version of &lt;a href="https://golang.org"&gt;Go&lt;/a&gt; and &lt;a href="https://buf.build"&gt;Buf&lt;/a&gt; (Protobuf generator).&lt;/p&gt; 
&lt;p&gt;We recommend using &lt;a href="https://nixos.org/"&gt;Nix&lt;/a&gt; to setup a development environment. This can be done with &lt;code&gt;nix develop&lt;/code&gt;, which will install the tools and give you a shell. This guarantees that you will have the same dev env as &lt;code&gt;headscale&lt;/code&gt; maintainers.&lt;/p&gt; 
&lt;h3&gt;Code style&lt;/h3&gt; 
&lt;p&gt;To ensure we have some consistency with a growing number of contributions, this project has adopted linting and style/formatting rules:&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;Go&lt;/strong&gt; code is linted with &lt;a href="https://golangci-lint.run"&gt;&lt;code&gt;golangci-lint&lt;/code&gt;&lt;/a&gt; and formatted with &lt;a href="https://github.com/segmentio/golines"&gt;&lt;code&gt;golines&lt;/code&gt;&lt;/a&gt; (width 88) and &lt;a href="https://github.com/mvdan/gofumpt"&gt;&lt;code&gt;gofumpt&lt;/code&gt;&lt;/a&gt;. Please configure your editor to run the tools while developing and make sure to run &lt;code&gt;make lint&lt;/code&gt; and &lt;code&gt;make fmt&lt;/code&gt; before committing any code.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;Proto&lt;/strong&gt; code is linted with &lt;a href="https://docs.buf.build/lint/overview"&gt;&lt;code&gt;buf&lt;/code&gt;&lt;/a&gt; and formatted with &lt;a href="https://clang.llvm.org/docs/ClangFormat.html"&gt;&lt;code&gt;clang-format&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;rest&lt;/strong&gt; (Markdown, YAML, etc) is formatted with &lt;a href="https://prettier.io"&gt;&lt;code&gt;prettier&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;code&gt;.golangci.yaml&lt;/code&gt; and &lt;code&gt;Makefile&lt;/code&gt; to see the specific configuration.&lt;/p&gt; 
&lt;h3&gt;Install development tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go&lt;/li&gt; 
 &lt;li&gt;Buf&lt;/li&gt; 
 &lt;li&gt;Protobuf tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Install and activate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;nix develop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing and building&lt;/h3&gt; 
&lt;p&gt;Some parts of the project require the generation of Go code from Protobuf (if changes are made in &lt;code&gt;proto/&lt;/code&gt;) and it must be (re-)generated with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make generate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Please check in changes from &lt;code&gt;gen/&lt;/code&gt; in a separate commit to make it easier to review.&lt;/p&gt; 
&lt;p&gt;To run the tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build the program:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development workflow&lt;/h3&gt; 
&lt;p&gt;We recommend using Nix for dependency management to ensure you have all required tools. If you prefer to manage dependencies yourself, you can use Make directly:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;With Nix (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;nix develop
make test
make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;With your own dependencies:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Makefile will warn you if any required tools are missing and suggest running &lt;code&gt;nix develop&lt;/code&gt;. Run &lt;code&gt;make help&lt;/code&gt; to see all available targets.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/juanfont/headscale/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=juanfont/headscale" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ArvinLovegood/go-stock</title>
      <link>https://github.com/ArvinLovegood/go-stock</link>
      <description>&lt;p&gt;🦄🦄🦄AI赋能股票分析：AI加持的股票分析/选股工具。股票行情获取，AI热点资讯分析，AI资金/财务分析，涨跌报警推送。支持A股，港股，美股。支持市场整体/个股情绪分析，AI辅助选股等。数据全部保留在本地。支持DeepSeek，OpenAI， Ollama，LMStudio，AnythingLLM，硅基流动，火山方舟，阿里云百炼等平台或模型。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;go-stock : 基于大语言模型的AI赋能股票分析工具&lt;/h1&gt; 
&lt;h2&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/appicon.png" alt="go-stock" /&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/v/release/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases&amp;amp;link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases" alt="GitHub Release" /&gt; &lt;a href="https://github.com/ArvinLovegood/go-stock"&gt;&lt;img src="https://img.shields.io/github/stars/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://gitee.com/arvinlovegood_admin/go-stock"&gt;&lt;img src="https://gitee.com/arvinlovegood_admin/go-stock/badge/star.svg?theme=dark" alt="star" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;🌟公众号&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/%E6%89%AB%E7%A0%81_%E6%90%9C%E7%B4%A2%E8%81%94%E5%90%88%E4%BC%A0%E6%92%AD%E6%A0%B7%E5%BC%8F-%E7%99%BD%E8%89%B2%E7%89%88.png" alt="扫码_搜索联合传播样式-白色版.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;📈 交流群&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;QQ交流群：&lt;a href="http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&amp;amp;k=0YQ8qD3exahsD4YLNhzQTWe5ssstWC89&amp;amp;authKey=usOMMRFtIQDC%2FYcatHYapcxQbJ7PwXPHK9OypTXWzNjAq%2FRVvQu9bj2lRgb%2BSZ3p&amp;amp;noverify=0&amp;amp;group_code=491605333"&gt;点击链接加入群聊【go-stock交流群】：491605333(定期清理，随缘入群)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;✨ 简介&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;本项目基于Wails和NaiveUI开发，结合AI大模型构建的股票分析工具。&lt;/li&gt; 
 &lt;li&gt;目前已支持A股，港股，美股，未来计划加入基金，ETF等支持。&lt;/li&gt; 
 &lt;li&gt;支持市场整体/个股情绪分析，K线技术指标分析等功能。&lt;/li&gt; 
 &lt;li&gt;本项目仅供娱乐，不喜勿喷，AI分析股票结果仅供学习研究，投资有风险，请谨慎使用。&lt;/li&gt; 
 &lt;li&gt;开发环境主要基于Windows10+，其他平台未测试或功能受限。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📦 立即体验&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;安装版：&lt;a href="https://github.com/ArvinLovegood/go-stock/releases"&gt;go-stock-amd64-installer.exe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;绿色版：&lt;a href="https://github.com/ArvinLovegood/go-stock/releases"&gt;go-stock-windows-amd64.exe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MACOS绿色版：&lt;a href="https://github.com/ArvinLovegood/go-stock/releases"&gt;go-stock-darwin-universal&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;💬 支持大模型/平台&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;模型&lt;/th&gt; 
   &lt;th&gt;状态&lt;/th&gt; 
   &lt;th&gt;备注&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://platform.openai.com/"&gt;OpenAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;可接入任何 OpenAI 接口格式模型&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://ollama.com/"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;本地大模型运行平台&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lmstudio.ai/"&gt;LMStudio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;本地大模型运行平台&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://anythingllm.com/"&gt;AnythingLLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;本地知识库&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.deepseek.com/"&gt;DeepSeek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;deepseek-reasoner,deepseek-chat&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cloud.siliconflow.cn/i/foufCerk"&gt;大模型聚合平台&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;如：&lt;a href="https://share.302.ai/1KUpfG"&gt;302.AI&lt;/a&gt;，&lt;a href="https://cloud.siliconflow.cn/i/foufCerk"&gt;硅基流动&lt;/a&gt;，&lt;a href="https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;amp;ac=DSASUQY5&amp;amp;rc=IJSE43PZ"&gt;火山方舟&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;span style="color: #568DF4;"&gt;各位亲爱的朋友们，如果您对这个项目感兴趣，请先给我一个&lt;i style="color: #EA2626;"&gt;star&lt;/i&gt;吧，谢谢！&lt;/span&gt;💕&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;302.AI：新用户使用邀请码注册，即可领取 $1 测试额度！&lt;a href="https://share.302.ai/1KUpfG"&gt;注册链接&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;火山方舟：新用户每个模型注册即送50万tokens，&lt;a href="https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;amp;ac=DSASUQY5&amp;amp;rc=IJSE43PZ"&gt;注册链接&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;硅基流动(siliconflow)，注册即送2000万Tokens，&lt;a href="https://cloud.siliconflow.cn/i/foufCerk"&gt;注册链接&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tushare大数据开放社区,免费提供各类金融数据,助力行业和量化研究(注意：Tushare只需要120积分即可，注册完成个人资料补充即可得120积分！！！)，&lt;a href="https://tushare.pro/register?reg=701944"&gt;注册链接&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;软件快速迭代开发中,请大家优先测试和使用最新发布的版本。&lt;/li&gt; 
 &lt;li&gt;欢迎大家提出宝贵的建议，欢迎提issue,PR。当然更欢迎&lt;a href="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/#%E9%83%BD%E5%88%92%E5%88%B0%E8%BF%99%E4%BA%86%E5%A6%82%E6%9E%9C%E6%88%91%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%AF%B9%E6%82%A8%E6%9C%89%E5%B8%AE%E5%8A%A9%E8%AF%B7%E8%B5%9E%E5%8A%A9%E6%88%91%E5%90%A7"&gt;赞助我&lt;/a&gt;。💕&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;支持开源💕计划&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;赞助计划&lt;/th&gt; 
   &lt;th&gt;赞助等级&lt;/th&gt; 
   &lt;th align="left"&gt;权益说明&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;每月 0 RMB&lt;/td&gt; 
   &lt;td&gt;vip0&lt;/td&gt; 
   &lt;td align="left"&gt;🌟 全部功能,软件自动更新(从GitHub下载),自行解决github平台网络问题。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;每月赞助 18.8 RMB&lt;br /&gt;每年赞助 120 RMB&lt;/td&gt; 
   &lt;td&gt;vip1&lt;/td&gt; 
   &lt;td align="left"&gt;💕 全部功能,软件自动更新(从CDN下载),更新快速便捷。AI配置指导，提示词参考等&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;每月赞助 28.8 RMB&lt;br /&gt;每年赞助 240 RMB&lt;/td&gt; 
   &lt;td&gt;vip2&lt;/td&gt; 
   &lt;td align="left"&gt;💕 💕 vip1全部功能,赠送硅基流动AI分析服务&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;每月赞助 X RMB&lt;/td&gt; 
   &lt;td&gt;vipX&lt;/td&gt; 
   &lt;td align="left"&gt;🧩 更多计划，视go-stock开源项目发展情况而定...(承接GitHub项目README广告推广💖)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🧩 重大功能开发计划&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;功能说明&lt;/th&gt; 
   &lt;th&gt;状态&lt;/th&gt; 
   &lt;th&gt;备注&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;股票分析知识库&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;未来计划&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ai智能选股&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;Ai智能选股功能(市场行情-》AI总结/AI智能体功能)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ETF支持&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;ETF数据支持 (目前可以查看净值和估值)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;美股支持&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;美股数据支持&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;港股支持&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;港股数据支持&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;多轮对话&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;AI分析后可继续对话提问&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;自定义AI分析提问模板&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;可配置的提问模板 &lt;a href="https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha"&gt;v2025.2.12.7-alpha&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;不再强制依赖Chrome浏览器&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;默认使用edge浏览器抓取新闻资讯&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;👀 更新日志&lt;/h2&gt; 
&lt;h3&gt;2025.07.08 实现软件自动更新功能&lt;/h3&gt; 
&lt;h3&gt;2025.07.07 卡片添加迷你分时图&lt;/h3&gt; 
&lt;h3&gt;2025.07.05 MacOs支持&lt;/h3&gt; 
&lt;h3&gt;2025.07.01 AI分析集成工具函数，AI分析将更加智能&lt;/h3&gt; 
&lt;h3&gt;2025.06.30 添加指标选股功能&lt;/h3&gt; 
&lt;h3&gt;2025.06.27 添加财经日历和重大事件时间轴功能&lt;/h3&gt; 
&lt;h3&gt;2025.06.25 添加热门股票、事件和话题功能&lt;/h3&gt; 
&lt;h3&gt;2025.06.18 更新内置股票基础数据,软件内实时市场资讯信息提醒，添加行业研究功能&lt;/h3&gt; 
&lt;h3&gt;2025.06.15 添加公司公告信息搜索/查看功能&lt;/h3&gt; 
&lt;h3&gt;2025.06.15 添加个股研报到弹出菜单&lt;/h3&gt; 
&lt;h3&gt;2025.06.13 添加个股研报功能&lt;/h3&gt; 
&lt;h3&gt;2025.06.12 添加龙虎榜功能，新增行业排名分类&lt;/h3&gt; 
&lt;h3&gt;2025.05.30 优化股票分时图显示&lt;/h3&gt; 
&lt;h3&gt;2025.05.20 修复财联社电报获取问题&lt;/h3&gt; 
&lt;h3&gt;2025.05.16 优化资金趋势图表组件&lt;/h3&gt; 
&lt;h3&gt;2025.05.15 重构应用加载和数据初始化逻辑，添加股票资金趋势功能，资金趋势图表增加主力当日净流入数据并优化展示效果&lt;/h3&gt; 
&lt;h3&gt;2025.05.14 添加个股资金流向功能，排行榜增加股票行情K线图弹窗&lt;/h3&gt; 
&lt;h3&gt;2025.05.13 添加行业排名功能&lt;/h3&gt; 
&lt;h3&gt;2025.05.09 添加A股盘口数据解析和展示功能&lt;/h3&gt; 
&lt;h3&gt;2025.05.07 优化分时图的展示&lt;/h3&gt; 
&lt;h3&gt;2025.04.29 补全港股/美股基础数据，优化港股股价延迟问题，优化初始化逻辑&lt;/h3&gt; 
&lt;h3&gt;2025.04.25 市场资讯支持AI分析和总结：让AI帮你读市场！&lt;/h3&gt; 
&lt;h3&gt;2025.04.24 新增市场行情模块：即时掌握全球市场行情资讯/动态，从此再也不用偷摸去各大财经网站啦。go-stock一键帮你搞定！&lt;/h3&gt; 
&lt;h3&gt;2025.04.22 优化K线图展示，支持拉伸放大，看得更舒服啦！&lt;/h3&gt; 
&lt;h3&gt;2025.04.21 港股，美股K线数据获取优化&lt;/h3&gt; 
&lt;h3&gt;2025.04.01 优化部分设置选项，避免重启软件&lt;/h3&gt; 
&lt;h3&gt;2025.03.31 优化数据爬取&lt;/h3&gt; 
&lt;h3&gt;2025.03.30 AI自动定时分析功能&lt;/h3&gt; 
&lt;h3&gt;2025.03.29 多提示词模板管理，AI分析时支持选择不同提示词模板&lt;/h3&gt; 
&lt;h3&gt;2025.03.28 AI分析结果保存为markdown文件时，支持保存位置目录选择&lt;/h3&gt; 
&lt;h3&gt;2025.03.15 自定义爬虫使用的浏览器路径配置&lt;/h3&gt; 
&lt;h3&gt;2025.03.14 优化编译构建，大幅减少编译后的程序文件大小&lt;/h3&gt; 
&lt;h3&gt;2025.03.09 基金估值和净值监控查看&lt;/h3&gt; 
&lt;h3&gt;2025.03.06 项目社区分享功能&lt;/h3&gt; 
&lt;h3&gt;2025.02.28 美股数据支持&lt;/h3&gt; 
&lt;h3&gt;2025.02.23 弹幕功能，盯盘不再孤单，无聊划个水！😎&lt;/h3&gt; 
&lt;h3&gt;2025.02.22 港股数据支持(目前有延迟)&lt;/h3&gt; 
&lt;h3&gt;2025.02.16 AI分析后可继续对话提问&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.16.1-alpha"&gt;v2025.2.16.1-alpha&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025.02.12 可配置的提问模板&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha"&gt;v2025.2.12.7-alpha&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🦄 重大更新&lt;/h2&gt; 
&lt;h3&gt;BIG NEWS !!! 重大更新！！！&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025.04.25 市场资讯支持AI分析和总结：让AI帮你读市场！ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/img.png" alt="img.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;2025.04.24 新增市场行情模块：即时掌握全球市场行情资讯/动态，从此再也不用偷摸去各大财经网站啦。go-stock一键帮你搞定！ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img13.png" alt="img.png" /&gt; &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_13.png" alt="img_13.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_14.png" alt="img_14.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;2025.01.17 新增AI大模型分析股票功能 &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img.png" alt="img_5.png" /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📸 功能截图&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_6.png" alt="img_1.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;设置&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_4.png" alt="img_12.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;成本设置&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_7.png" alt="img.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;日K&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_12.png" alt="img_12.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;分时&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_9.png" alt="img_3.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;钉钉报警通知&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_5.png" alt="img_4.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;AI分析股票&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img.png" alt="img_5.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;版本信息提示&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_11.png" alt="img_11.png" /&gt;&lt;/p&gt; 
&lt;h2&gt;💕 感谢以下项目&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.naiveui.com/"&gt;NaiveUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wails.io/"&gt;Wails&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vuejs.org/"&gt;Vue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vitejs.dev/"&gt;Vite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tushare.pro/register?reg=701944"&gt;Tushare&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;😘 赞助我&lt;/h2&gt; 
&lt;h3&gt;都划到这了，如果我的项目对您有帮助，请赞助我吧！😊😊😊&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;支付宝&lt;/th&gt; 
   &lt;th&gt;微信&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/alipay.jpg" alt="alipay.jpg" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/wxpay.jpg" alt="wxpay.jpg" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;⭐ Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#ArvinLovegood/go-stock&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=ArvinLovegood/go-stock&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🤖 状态&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/40b07d415a42c2264a18c4fe1b6f182ff1470687.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;🐳 关于技术支持申明&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;本软件基于开源技术构建，使用Wails、NaiveUI、Vue、AI大模型等开源项目。 技术上如有问题，可以先向对应的开源社区请求帮助。&lt;/li&gt; 
 &lt;li&gt;开源不易，本人精力和时间有限，如需一对一技术支持，请先赞助。联系微信(备注 技术支持)：ArvinLovegood&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/wx.jpg" width="301px" height="402px" alt="ArvinLovegood" /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;技术支持方式&lt;/th&gt; 
   &lt;th align="center"&gt;赞助(元)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;加 QQ：506808970，微信：ArvinLovegood&lt;/td&gt; 
   &lt;td align="center"&gt;100/次&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;长期技术支持（不限次数，新功能优先体验等）&lt;/td&gt; 
   &lt;td align="center"&gt;5000&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>glanceapp/glance</title>
      <link>https://github.com/glanceapp/glance</link>
      <description>&lt;p&gt;A self-hosted dashboard that puts all your feeds in one place&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/logo.png" /&gt;&lt;/p&gt; 
&lt;h1 align="center"&gt;Glance&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/#installation"&gt;Install&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/configuration.md#configuring-glance"&gt;Configuration&lt;/a&gt; • &lt;a href="https://discord.com/invite/7KQ7Xa9kJd"&gt;Discord&lt;/a&gt; • &lt;a href="https://github.com/sponsors/glanceapp"&gt;Sponsor&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/glanceapp/community-widgets"&gt;Community widgets&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/preconfigured-pages.md"&gt;Preconfigured pages&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/themes.md"&gt;Themes&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;A lightweight, highly customizable dashboard that displays&lt;br /&gt; your feeds in a beautiful, streamlined interface&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/images/readme-main-image.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Various widgets&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;RSS feeds&lt;/li&gt; 
 &lt;li&gt;Subreddit posts&lt;/li&gt; 
 &lt;li&gt;Hacker News posts&lt;/li&gt; 
 &lt;li&gt;Weather forecasts&lt;/li&gt; 
 &lt;li&gt;YouTube channel uploads&lt;/li&gt; 
 &lt;li&gt;Twitch channels&lt;/li&gt; 
 &lt;li&gt;Market prices&lt;/li&gt; 
 &lt;li&gt;Docker containers status&lt;/li&gt; 
 &lt;li&gt;Server stats&lt;/li&gt; 
 &lt;li&gt;Custom widgets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/configuration.md#configuring-glance"&gt;and many more...&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Fast and lightweight&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Low memory usage&lt;/li&gt; 
 &lt;li&gt;Few dependencies&lt;/li&gt; 
 &lt;li&gt;Minimal vanilla JS&lt;/li&gt; 
 &lt;li&gt;Single &amp;lt;20mb binary available for multiple OSs &amp;amp; architectures and just as small Docker container&lt;/li&gt; 
 &lt;li&gt;Uncached pages usually load within ~1s (depending on internet speed and number of widgets)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tons of customizability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Different layouts&lt;/li&gt; 
 &lt;li&gt;As many pages/tabs as you need&lt;/li&gt; 
 &lt;li&gt;Numerous configuration options for each widget&lt;/li&gt; 
 &lt;li&gt;Multiple styles for some widgets&lt;/li&gt; 
 &lt;li&gt;Custom CSS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Optimized for mobile devices&lt;/h3&gt; 
&lt;p&gt;Because you'll want to take it with you on the go.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/images/mobile-preview.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;Themeable&lt;/h3&gt; 
&lt;p&gt;Easily create your own theme by tweaking a few numbers or choose from one of the &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/themes.md"&gt;already available themes&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/images/themes-example.png" alt="" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Configuration is done through YAML files, to learn more about how the layout works, how to add more pages and how to configure widgets, visit the &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/configuration.md#configuring-glance"&gt;configuration documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Preview example configuration file&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;pages:
  - name: Home
    columns:
      - size: small
        widgets:
          - type: calendar
            first-day-of-week: monday

          - type: rss
            limit: 10
            collapse-after: 3
            cache: 12h
            feeds:
              - url: https://selfh.st/rss/
                title: selfh.st
                limit: 4
              - url: https://ciechanow.ski/atom.xml
              - url: https://www.joshwcomeau.com/rss.xml
                title: Josh Comeau
              - url: https://samwho.dev/rss.xml
              - url: https://ishadeed.com/feed.xml
                title: Ahmad Shadeed

          - type: twitch-channels
            channels:
              - theprimeagen
              - j_blow
              - piratesoftware
              - cohhcarnage
              - christitustech
              - EJ_SA

      - size: full
        widgets:
          - type: group
            widgets:
              - type: hacker-news
              - type: lobsters

          - type: videos
            channels:
              - UCXuqSBlHAE6Xw-yeJA0Tunw # Linus Tech Tips
              - UCR-DXc1voovS8nhAvccRZhg # Jeff Geerling
              - UCsBjURrPoezykLs9EqgamOA # Fireship
              - UCBJycsmduvYEL83R_U4JriQ # Marques Brownlee
              - UCHnyfMqiRRG1u-2MsSQLbXA # Veritasium

          - type: group
            widgets:
              - type: reddit
                subreddit: technology
                show-thumbnails: true
              - type: reddit
                subreddit: selfhosted
                show-thumbnails: true

      - size: small
        widgets:
          - type: weather
            location: London, United Kingdom
            units: metric
            hour-format: 12h

          - type: markets
            markets:
              - symbol: SPY
                name: S&amp;amp;P 500
              - symbol: BTC-USD
                name: Bitcoin
              - symbol: NVDA
                name: NVIDIA
              - symbol: AAPL
                name: Apple
              - symbol: MSFT
                name: Microsoft

          - type: releases
            cache: 1d
            repositories:
              - glanceapp/glance
              - go-gitea/gitea
              - immich-app/immich
              - syncthing/syncthing
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Choose one of the following methods:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Docker compose using provided directory structure (recommended)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Create a new directory called &lt;code&gt;glance&lt;/code&gt; as well as the template files within it by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir glance &amp;amp;&amp;amp; cd glance &amp;amp;&amp;amp; curl -sL https://github.com/glanceapp/docker-compose-template/archive/refs/heads/main.tar.gz | tar -xzf - --strip-components 2
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/glanceapp/docker-compose-template/tree/main/root"&gt;click here to view the files that will be created&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;Then, edit the following files as desired:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker-compose.yml&lt;/code&gt; to configure the port, volumes and other containery things&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/home.yml&lt;/code&gt; to configure the widgets or layout of the home page&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/glance.yml&lt;/code&gt; if you want to change the theme or add more pages&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Other files you may want to edit&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; to configure environment variables that will be available inside configuration files&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;assets/user.css&lt;/code&gt; to add custom CSS&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;p&gt;When ready, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you encounter any issues, you can check the logs by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose logs
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Docker compose manual&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Create a &lt;code&gt;docker-compose.yml&lt;/code&gt; file with the following contents:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  glance:
    container_name: glance
    image: glanceapp/glance
    restart: unless-stopped
    volumes:
      - ./config:/app/config
    ports:
      - 8080:8080
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Then, create a new directory called &lt;code&gt;config&lt;/code&gt; and download the example starting &lt;a href="https://github.com/glanceapp/glance/raw/main/docs/glance.yml"&gt;&lt;code&gt;glance.yml&lt;/code&gt;&lt;/a&gt; file into it by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir config &amp;amp;&amp;amp; wget -O config/glance.yml https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Feel free to edit the &lt;code&gt;glance.yml&lt;/code&gt; file to your liking, and when ready run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you encounter any issues, you can check the logs by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker logs glance
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Manual binary installation&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Precompiled binaries are available for Linux, Windows and macOS (x86, x86_64, ARM and ARM64 architectures).&lt;/p&gt; 
 &lt;h3&gt;Linux&lt;/h3&gt; 
 &lt;p&gt;Visit the &lt;a href="https://github.com/glanceapp/glance/releases/latest"&gt;latest release page&lt;/a&gt; for available binaries. You can place the binary in &lt;code&gt;/opt/glance/&lt;/code&gt; and have it start with your server via a &lt;a href="https://linuxhandbook.com/create-systemd-services/"&gt;systemd service&lt;/a&gt;. By default, when running the binary, it will look for a &lt;code&gt;glance.yml&lt;/code&gt; file in the directory it's placed in. To specify a different path for the config file, use the &lt;code&gt;--config&lt;/code&gt; option:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;/opt/glance/glance --config /etc/glance.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To grab a starting template for the config file, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;wget https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Windows&lt;/h3&gt; 
 &lt;p&gt;Download and extract the executable from the &lt;a href="https://github.com/glanceapp/glance/releases/latest"&gt;latest release&lt;/a&gt; (most likely the file called &lt;code&gt;glance-windows-amd64.zip&lt;/code&gt; if you're on a 64-bit system) and place it in a folder of your choice. Then, create a new text file called &lt;code&gt;glance.yml&lt;/code&gt; in the same folder and paste the content from &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml"&gt;here&lt;/a&gt; in it. You should then be able to run the executable and access the dashboard by visiting &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser.&lt;/p&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Other&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Glance can also be installed through the following 3rd party channels:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://community-scripts.github.io/ProxmoxVE/scripts?id=glance"&gt;Proxmox VE Helper Script&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://search.nixos.org/packages?channel=unstable&amp;amp;show=glance"&gt;NixOS package&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://coolify.io/docs/services/glance/"&gt;Coolify.io&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Common issues&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Requests timing out&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The most common cause of this is when using Pi-Hole, AdGuard Home or other ad-blocking DNS services, which by default have a fairly low rate limit. Depending on the number of widgets you have in a single page, this limit can very easily be exceeded. To fix this, increase the rate limit in the settings of your DNS service.&lt;/p&gt; 
 &lt;p&gt;If using Podman, in some rare cases the timeout can be caused by an unknown issue, in which case it may be resolved by adding the following to the bottom of your &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;networks:
  podman:
    external: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Broken layout for markets, bookmarks or other widgets&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;This is almost always caused by the browser extension Dark Reader. To fix this, disable dark mode for the domain where Glance is hosted.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;cannot unmarshal !!map into []glance.page&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The most common cause of this is having a &lt;code&gt;pages&lt;/code&gt; key in your &lt;code&gt;glance.yml&lt;/code&gt; and then also having a &lt;code&gt;pages&lt;/code&gt; key inside one of your included pages. To fix this, remove the &lt;code&gt;pages&lt;/code&gt; key from the top of your included pages.&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Does the information on the page update automatically?&lt;/strong&gt;&lt;/summary&gt; No, a page refresh is required to update the information. Some things do dynamically update where it makes sense, like the clock widget and the relative time showing how long ago something happened. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;How frequently do widgets update?&lt;/strong&gt;&lt;/summary&gt; No requests are made periodically in the background, information is only fetched upon loading the page and then cached. The default cache lifetime is different for each widget and can be configured. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Can I create my own widgets?&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Yes, there are multiple ways to create custom widgets:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;iframe&lt;/code&gt; widget - allows you to embed things from other websites&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;html&lt;/code&gt; widget - allows you to insert your own static HTML&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;extension&lt;/code&gt; widget - fetch HTML from a URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;custom-api&lt;/code&gt; widget - fetch JSON from a URL and render it using custom HTML&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Can I change the title of a widget?&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Yes, the title of all widgets can be changed by specifying the &lt;code&gt;title&lt;/code&gt; property in the widget's configuration:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;- type: rss
  title: My custom title

- type: markets
  title: My custom title

- type: videos
  title: My custom title

# and so on for all widgets...
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Feature requests&lt;/h2&gt; 
&lt;p&gt;New feature suggestions are always welcome and will be considered, though please keep in mind that some of them may be out of scope for what the project is trying to achieve (or is reasonably capable of). If you have an idea for a new feature and would like to share it, you can do so &lt;a href="https://github.com/glanceapp/glance/issues/new?template=feature_request.yml"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Feature requests are tagged with one of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glanceapp/glance/labels/roadmap"&gt;Roadmap&lt;/a&gt; - will be implemented in a future release&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glanceapp/glance/labels/backlog"&gt;Backlog&lt;/a&gt; - may be implemented in the future but needs further feedback or interest from the community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glanceapp/glance/labels/icebox"&gt;Icebox&lt;/a&gt; - no plans to implement as it doesn't currently align with the project's goals or capabilities, may be revised at a later date&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Building from source&lt;/h2&gt; 
&lt;p&gt;Choose one of the following methods:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build binary with Go&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Requirements: &lt;a href="https://go.dev/dl/"&gt;Go&lt;/a&gt; &amp;gt;= v1.23&lt;/p&gt; 
 &lt;p&gt;To build the project for your current OS and architecture, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;go build -o build/glance .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build for a specific OS and architecture, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;GOOS=linux GOARCH=amd64 go build -o build/glance .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;a href="https://go.dev/doc/install/source#:~:text=$GOOS%20and%20$GOARCH"&gt;&lt;em&gt;click here for a full list of GOOS and GOARCH combinations&lt;/em&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Alternatively, if you just want to run the app without creating a binary, like when you're testing out changes, you can run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;go run .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build project and Docker image with Docker&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Requirements: &lt;a href="https://docs.docker.com/engine/install/"&gt;Docker&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;To build the project and image using just Docker, run:&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;(replace &lt;code&gt;owner&lt;/code&gt; with your name or organization)&lt;/em&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t owner/glance:latest .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you wish to push the image to a registry (by default Docker Hub), run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker push owner/glance:latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Contributing guidelines&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Before working on a new feature it's preferable to submit a feature request first and state that you'd like to implement it yourself&lt;/li&gt; 
 &lt;li&gt;Please don't submit PRs for feature requests that are either in the roadmap&lt;sup&gt;[1]&lt;/sup&gt;, backlog&lt;sup&gt;[2]&lt;/sup&gt; or icebox&lt;sup&gt;[3]&lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;dev&lt;/code&gt; for the base branch if you're adding new features or fixing bugs, otherwise use &lt;code&gt;main&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Avoid introducing new dependencies&lt;/li&gt; 
 &lt;li&gt;Avoid making backwards-incompatible configuration changes&lt;/li&gt; 
 &lt;li&gt;Avoid introducing new colors or hard-coding colors, use the standard &lt;code&gt;primary&lt;/code&gt;, &lt;code&gt;positive&lt;/code&gt; and &lt;code&gt;negative&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For icons, try to use &lt;a href="https://heroicons.com/"&gt;heroicons&lt;/a&gt; where applicable&lt;/li&gt; 
 &lt;li&gt;Provide a screenshot of the changes if UI related where possible&lt;/li&gt; 
 &lt;li&gt;No &lt;code&gt;package.json&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;&lt;sup&gt;[1] [2] [3]&lt;/sup&gt;&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;[1] The feature likely already has work put into it that may conflict with your implementation&lt;/p&gt; 
 &lt;p&gt;[2] The demand, implementation or functionality for this feature is not yet clear&lt;/p&gt; 
 &lt;p&gt;[3] No plans to add this feature for the time being&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Thank you&lt;/h2&gt; 
&lt;p&gt;To all the people who were generous enough to &lt;a href="https://github.com/sponsors/glanceapp"&gt;sponsor&lt;/a&gt; the project and to everyone who has contributed in any way, be it PRs, submitting issues, helping others in the discussions or Discord server, creating guides and tools or just mentioning Glance on social media. Your support is greatly appreciated and helps keep the project going.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>trufflesecurity/trufflehog</title>
      <link>https://github.com/trufflesecurity/trufflehog</link>
      <description>&lt;p&gt;Find, verify, and analyze leaked credentials&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img alt="GoReleaser Logo" src="https://storage.googleapis.com/trufflehog-static-sources/pixel_pig.png" height="140" /&gt; &lt;/p&gt;
&lt;h2 align="center"&gt;TruffleHog&lt;/h2&gt; 
&lt;p align="center"&gt;Find leaked credentials.&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/trufflesecurity/trufflehog/v3"&gt;&lt;img src="https://goreportcard.com/badge/github.com/trufflesecurity/trufflehog/v3" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL--3.0-brightgreen" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/pkg/detectors"&gt;&lt;img src="https://img.shields.io/github/directory-file-count/trufflesecurity/truffleHog/pkg/detectors?label=Total%20Detectors&amp;amp;type=dir" alt="Total Detectors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;&lt;span&gt;🔎&lt;/span&gt; &lt;em&gt;Now Scanning&lt;/em&gt;&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/assets/scanning_logos.svg?sanitize=true" /&gt; 
 &lt;p&gt;&lt;strong&gt;...and more&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;To learn more about TruffleHog and its features and capabilities, visit our &lt;a href="https://trufflesecurity.com/trufflehog?gclid=CjwKCAjwouexBhAuEiwAtW_Zx5IW87JNj97Ci7heFnA5ar6-DuNzT2Y5nIl9DuZ-FOUqx0Qg3vb9nxoClcEQAvD_BwE"&gt;product page&lt;/a&gt;.&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;&lt;span&gt;🌐&lt;/span&gt; TruffleHog Enterprise&lt;/h1&gt; 
&lt;p&gt;Are you interested in continuously monitoring &lt;strong&gt;Git, Jira, Slack, Confluence, Microsoft Teams, Sharepoint, and more..&lt;/strong&gt; for credentials? We have an enterprise product that can help! Learn more at &lt;a href="https://trufflesecurity.com/trufflehog-enterprise"&gt;https://trufflesecurity.com/trufflehog-enterprise&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We take the revenue from the enterprise product to fund more awesome open source projects that the whole community can benefit from.&lt;/p&gt;  
&lt;h1&gt;What is TruffleHog 🐽&lt;/h1&gt; 
&lt;p&gt;TruffleHog is the most powerful secrets &lt;strong&gt;Discovery, Classification, Validation,&lt;/strong&gt; and &lt;strong&gt;Analysis&lt;/strong&gt; tool. In this context, secret refers to a credential a machine uses to authenticate itself to another machine. This includes API keys, database passwords, private encryption keys, and more...&lt;/p&gt; 
&lt;h2&gt;Discovery 🔍&lt;/h2&gt; 
&lt;p&gt;TruffleHog can look for secrets in many places including Git, chats, wikis, logs, API testing platforms, object stores, filesystems and more&lt;/p&gt; 
&lt;h2&gt;Classification 📁&lt;/h2&gt; 
&lt;p&gt;TruffleHog classifies over 800 secret types, mapping them back to the specific identity they belong to. Is it an AWS secret? Stripe secret? Cloudflare secret? Postgres password? SSL Private key? Sometimes it's hard to tell looking at it, so TruffleHog classifies everything it finds.&lt;/p&gt; 
&lt;h2&gt;Validation ✅&lt;/h2&gt; 
&lt;p&gt;For every secret TruffleHog can classify, it can also log in to confirm if that secret is live or not. This step is critical to know if there’s an active present danger or not.&lt;/p&gt; 
&lt;h2&gt;Analysis 🔬&lt;/h2&gt; 
&lt;p&gt;For the 20 some of the most commonly leaked out credential types, instead of sending one request to check if the secret can log in, TruffleHog can send many requests to learn everything there is to know about the secret. Who created it? What resources can it access? What permissions does it have on those resources?&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;📢&lt;/span&gt; Join Our Community&lt;/h1&gt; 
&lt;p&gt;Have questions? Feedback? Jump into Slack or Discord and hang out with us.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://join.slack.com/t/trufflehog-community/shared_invite/zt-pw2qbi43-Aa86hkiimstfdKH9UCpPzQ"&gt;Slack Community&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.gg/8Hzbrnkr7E"&gt;Secret Scanning Discord&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;📺&lt;/span&gt; Demo&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://storage.googleapis.com/truffle-demos/non-interactive.svg?sanitize=true" alt="GitHub scanning demo" /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it -v "$PWD:/pwd" trufflesecurity/trufflehog:latest github --org=trufflesecurity
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;&lt;span&gt;💾&lt;/span&gt; Installation&lt;/h1&gt; 
&lt;p&gt;Several options are available for you:&lt;/p&gt; 
&lt;h3&gt;MacOS users&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install trufflehog
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker:&lt;/h3&gt; 
&lt;p&gt;&lt;sub&gt;&lt;i&gt;&lt;em&gt;Ensure Docker engine is running before executing the following commands:&lt;/em&gt;&lt;/i&gt;&lt;/sub&gt;&lt;/p&gt; 
&lt;h4&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Unix&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it -v "$PWD:/pwd" trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows Command Prompt&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it -v "%cd:/=\%:/pwd" trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows PowerShell&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it -v "${PWD}:/pwd" trufflesecurity/trufflehog github --repo https://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;M1 and M2 Mac&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --platform linux/arm64 --rm -it -v "$PWD:/pwd" trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Binary releases&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;Download and unpack from https://github.com/trufflesecurity/trufflehog/releases
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Compile from source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/trufflesecurity/trufflehog.git
cd trufflehog; go install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using installation script&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using installation script, verify checksum signature (requires cosign to be installed)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -v -b /usr/local/bin
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using installation script to install a specific version&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin &amp;lt;ReleaseTag like v3.56.0&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;&lt;span&gt;🔐&lt;/span&gt; Verifying the artifacts&lt;/h1&gt; 
&lt;p&gt;Checksums are applied to all artifacts, and the resulting checksum file is signed using cosign.&lt;/p&gt; 
&lt;p&gt;You need the following tool to verify signature:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.sigstore.dev/cosign/system_config/installation/"&gt;Cosign&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Verification steps are as follows:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Download the artifact files you want, and the following files from the &lt;a href="https://github.com/trufflesecurity/trufflehog/releases"&gt;releases&lt;/a&gt; page.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;trufflehog_{version}_checksums.txt&lt;/li&gt; 
   &lt;li&gt;trufflehog_{version}_checksums.txt.pem&lt;/li&gt; 
   &lt;li&gt;trufflehog_{version}_checksums.txt.sig&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Verify the signature:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;cosign verify-blob &amp;lt;path to trufflehog_{version}_checksums.txt&amp;gt; \
--certificate &amp;lt;path to trufflehog_{version}_checksums.txt.pem&amp;gt; \
--signature &amp;lt;path to trufflehog_{version}_checksums.txt.sig&amp;gt; \
--certificate-identity-regexp 'https://github\.com/trufflesecurity/trufflehog/\.github/workflows/.+' \
--certificate-oidc-issuer "https://token.actions.githubusercontent.com"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Once the signature is confirmed as valid, you can proceed to validate that the SHA256 sums align with the downloaded artifact:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sha256sum --ignore-missing -c trufflehog_{version}_checksums.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Replace &lt;code&gt;{version}&lt;/code&gt; with the downloaded files version&lt;/p&gt; 
&lt;p&gt;Alternatively, if you are using the installation script, pass &lt;code&gt;-v&lt;/code&gt; option to perform signature verification. This requires Cosign binary to be installed prior to running the installation script.&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;🚀&lt;/span&gt; Quick Start&lt;/h1&gt; 
&lt;h2&gt;1: Scan a repo for only verified secrets&lt;/h2&gt; 
&lt;p&gt;Command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog git https://github.com/trufflesecurity/test_keys --results=verified
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expected output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;🐷🔑🐷  TruffleHog. Unearth your secrets. 🐷🔑🐷

Found verified result 🐷🔑
Detector Type: AWS
Decoder Type: PLAIN
Raw result: AKIAYVP4CIPPERUVIFXG
Line: 4
Commit: fbc14303ffbf8fb1c2c1914e8dda7d0121633aca
File: keys
Email: counter &amp;lt;counter@counters-MacBook-Air.local&amp;gt;
Repository: https://github.com/trufflesecurity/test_keys
Timestamp: 2022-06-16 10:17:40 -0700 PDT
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;2: Scan a GitHub Org for only verified secrets&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog github --org=trufflesecurity --results=verified
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3: Scan a GitHub Repo for only verified secrets and get JSON output&lt;/h2&gt; 
&lt;p&gt;Command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog git https://github.com/trufflesecurity/test_keys --results=verified --json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expected output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{"SourceMetadata":{"Data":{"Git":{"commit":"fbc14303ffbf8fb1c2c1914e8dda7d0121633aca","file":"keys","email":"counter \u003ccounter@counters-MacBook-Air.local\u003e","repository":"https://github.com/trufflesecurity/test_keys","timestamp":"2022-06-16 10:17:40 -0700 PDT","line":4}}},"SourceID":0,"SourceType":16,"SourceName":"trufflehog - git","DetectorType":2,"DetectorName":"AWS","DecoderName":"PLAIN","Verified":true,"Raw":"AKIAYVP4CIPPERUVIFXG","Redacted":"AKIAYVP4CIPPERUVIFXG","ExtraData":{"account":"595918472158","arn":"arn:aws:iam::595918472158:user/canarytokens.com@@mirux23ppyky6hx3l6vclmhnj","user_id":"AIDAYVP4CIPPJ5M54LRCY"},"StructuredData":null}
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4: Scan a GitHub Repo + its Issues and Pull Requests&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog github --repo=https://github.com/trufflesecurity/test_keys --issue-comments --pr-comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;5: Scan an S3 bucket for high-confidence results (verified + unknown)&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --bucket=&amp;lt;bucket name&amp;gt; --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;6: Scan S3 buckets using IAM Roles&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --role-arn=&amp;lt;iam role arn&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;7: Scan a Github Repo using SSH authentication in Docker&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -v "$HOME/.ssh:/root/.ssh:ro" trufflesecurity/trufflehog:latest git ssh://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;8: Scan individual files or directories&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog filesystem path/to/file1.txt path/to/file2.txt path/to/dir
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;9: Scan a local git repo&lt;/h2&gt; 
&lt;p&gt;Clone the git repo. For example &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/git@github.com:trufflesecurity/test_keys.git"&gt;test keys&lt;/a&gt; repo.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ git clone git@github.com:trufflesecurity/test_keys.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run trufflehog from the parent directory (outside the git repo).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ trufflehog git file://test_keys --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To guard against malicious git configs in local scanning (see CVE-2025-41390), TruffleHog clones local git repositories to a temporary directory prior to scanning. This follows &lt;a href="https://git-scm.com/docs/git#_security"&gt;Git's security best practices&lt;/a&gt;. If you want to specify a custom path to clone the repository to (instead of tmp), you can use the &lt;code&gt;--clone-path&lt;/code&gt; flag. If you'd like to skip the local cloning process and scan the repository directly (only do this for trusted repos), you can use the &lt;code&gt;--trust-local-git-config&lt;/code&gt; flag.&lt;/p&gt; 
&lt;h2&gt;10: Scan GCS buckets for only verified secrets&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog gcs --project-id=&amp;lt;project-ID&amp;gt; --cloud-environment --results=verified
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;11: Scan a Docker image for only verified secrets&lt;/h2&gt; 
&lt;p&gt;Use the &lt;code&gt;--image&lt;/code&gt; flag multiple times to scan multiple images.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# to scan from a remote registry
trufflehog docker --image trufflesecurity/secrets --results=verified

# to scan from the local docker daemon
trufflehog docker --image docker://new_image:tag --results=verified

# to scan from an image saved as a tarball
trufflehog docker --image file://path_to_image.tar --results=verified
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;12: Scan in CI&lt;/h2&gt; 
&lt;p&gt;Set the &lt;code&gt;--since-commit&lt;/code&gt; flag to your default branch that people merge into (ex: "main"). Set the &lt;code&gt;--branch&lt;/code&gt; flag to your PR's branch name (ex: "feature-1"). Depending on the CI/CD platform you use, this value can be pulled in dynamically (ex: &lt;a href="https://circleci.com/docs/variables/"&gt;CIRCLE_BRANCH in Circle CI&lt;/a&gt; and &lt;a href="https://docs.travis-ci.com/user/environment-variables/"&gt;TRAVIS_PULL_REQUEST_BRANCH in Travis CI&lt;/a&gt;). If the repo is cloned and the target branch is already checked out during the CI/CD workflow, then &lt;code&gt;--branch HEAD&lt;/code&gt; should be sufficient. The &lt;code&gt;--fail&lt;/code&gt; flag will return an 183 error code if valid credentials are found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog git file://. --since-commit main --branch feature-1 --results=verified,unknown --fail
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;13: Scan a Postman workspace&lt;/h2&gt; 
&lt;p&gt;Use the &lt;code&gt;--workspace-id&lt;/code&gt;, &lt;code&gt;--collection-id&lt;/code&gt;, &lt;code&gt;--environment&lt;/code&gt; flags multiple times to scan multiple targets.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog postman --token=&amp;lt;postman api token&amp;gt; --workspace-id=&amp;lt;workspace id&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;14: Scan a Jenkins server&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog jenkins --url https://jenkins.example.com --username admin --password admin
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;15: Scan an Elasticsearch server&lt;/h2&gt; 
&lt;h3&gt;Scan a Local Cluster&lt;/h3&gt; 
&lt;p&gt;There are two ways to authenticate to a local cluster with TruffleHog: (1) username and password, (2) service token.&lt;/p&gt; 
&lt;h4&gt;Connect to a local cluster with username and password&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --username truffle --password hog
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Connect to a local cluster with a service token&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --service-token ‘AAEWVaWM...Rva2VuaSDZ’
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scan an Elastic Cloud Cluster&lt;/h3&gt; 
&lt;p&gt;To scan a cluster on Elastic Cloud, you’ll need a Cloud ID and API key.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog elasticsearch \
  --cloud-id 'search-prod:dXMtY2Vx...YjM1ODNlOWFiZGRlNjI0NA==' \
  --api-key 'MlVtVjBZ...ZSYlduYnF1djh3NG5FQQ=='
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;16. Scan a GitHub Repository for Cross Fork Object References and Deleted Commits&lt;/h2&gt; 
&lt;p&gt;The following command will enumerate deleted and hidden commits on a GitHub repository and then scan them for secrets. This is an alpha release feature.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog github-experimental --repo https://github.com/&amp;lt;USER&amp;gt;/&amp;lt;REPO&amp;gt;.git --object-discovery
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to the normal TruffleHog output, the &lt;code&gt;--object-discovery&lt;/code&gt; flag creates two files in a new &lt;code&gt;$HOME/.trufflehog&lt;/code&gt; directory: &lt;code&gt;valid_hidden.txt&lt;/code&gt; and &lt;code&gt;invalid.txt&lt;/code&gt;. These are used to track state during commit enumeration, as well as to provide users with a complete list of all hidden and deleted commits (&lt;code&gt;valid_hidden.txt&lt;/code&gt;). If you'd like to automatically remove these files after scanning, please add the flag &lt;code&gt;--delete-cached-data&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Enumerating all valid commits on a repository using this method takes between 20 minutes and a few hours, depending on the size of your repository. We added a progress bar to keep you updated on how long the enumeration will take. The actual secret scanning runs extremely fast.&lt;/p&gt; 
&lt;p&gt;For more information on Cross Fork Object References, please &lt;a href="https://trufflesecurity.com/blog/anyone-can-access-deleted-and-private-repo-data-github"&gt;read our blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;17. Scan Hugging Face&lt;/h2&gt; 
&lt;h3&gt;Scan a Hugging Face Model, Dataset or Space&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog huggingface --model &amp;lt;model_id&amp;gt; --space &amp;lt;space_id&amp;gt; --dataset &amp;lt;dataset_id&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scan all Models, Datasets and Spaces belonging to a Hugging Face Organization or User&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog huggingface --org &amp;lt;orgname&amp;gt; --user &amp;lt;username&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(Optionally) When scanning an organization or user, you can skip an entire class of resources with &lt;code&gt;--skip-models&lt;/code&gt;, &lt;code&gt;--skip-datasets&lt;/code&gt;, &lt;code&gt;--skip-spaces&lt;/code&gt; OR a particular resource with &lt;code&gt;--ignore-models &amp;lt;model_id&amp;gt;&lt;/code&gt;, &lt;code&gt;--ignore-datasets &amp;lt;dataset_id&amp;gt;&lt;/code&gt;, &lt;code&gt;--ignore-spaces &amp;lt;space_id&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Scan Discussion and PR Comments&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog huggingface --model &amp;lt;model_id&amp;gt; --include-discussions --include-prs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;18. Scan stdin Input&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;aws s3 cp s3://example/gzipped/data.gz - | gunzip -c | trufflehog stdin
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;&lt;span&gt;❓&lt;/span&gt; FAQ&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;All I see is &lt;code&gt;🐷🔑🐷 TruffleHog. Unearth your secrets. 🐷🔑🐷&lt;/code&gt; and the program exits, what gives? 
  &lt;ul&gt; 
   &lt;li&gt;That means no secrets were detected&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Why is the scan taking a long time when I scan a GitHub org 
  &lt;ul&gt; 
   &lt;li&gt;Unauthenticated GitHub scans have rate limits. To improve your rate limits, include the &lt;code&gt;--token&lt;/code&gt; flag with a personal access token&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;It says a private key was verified, what does that mean? 
  &lt;ul&gt; 
   &lt;li&gt;A verified result means TruffleHog confirmed the credential is valid by testing it against the service's API. For private keys, we've confirmed the key can be used live for SSH or SSL authentication. Check out our Driftwood blog post to learn more &lt;a href="https://trufflesecurity.com/blog/driftwood-know-if-private-keys-are-sensitive/"&gt;Blog post&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Is there an easy way to ignore specific secrets? 
  &lt;ul&gt; 
   &lt;li&gt;If the scanned source &lt;a href="https://github.com/trufflesecurity/trufflehog/raw/d6375ba92172fd830abb4247cca15e3176448c5d/pkg/engine/engine.go#L358-L365"&gt;supports line numbers&lt;/a&gt;, then you can add a &lt;code&gt;trufflehog:ignore&lt;/code&gt; comment on the line containing the secret to ignore that secrets.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;span&gt;📰&lt;/span&gt; What's new in v3?&lt;/h1&gt; 
&lt;p&gt;TruffleHog v3 is a complete rewrite in Go with many new powerful features.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We've &lt;strong&gt;added over 700 credential detectors that support active verification against their respective APIs&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;We've also added native &lt;strong&gt;support for scanning GitHub, GitLab, Docker, filesystems, S3, GCS, Circle CI and Travis CI&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instantly verify private keys&lt;/strong&gt; against millions of github users and &lt;strong&gt;billions&lt;/strong&gt; of TLS certificates using our &lt;a href="https://trufflesecurity.com/blog/driftwood"&gt;Driftwood&lt;/a&gt; technology.&lt;/li&gt; 
 &lt;li&gt;Scan binaries, documents, and other file formats&lt;/li&gt; 
 &lt;li&gt;Available as a GitHub Action and a pre-commit hook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is credential verification?&lt;/h2&gt; 
&lt;p&gt;For every potential credential that is detected, we've painstakingly implemented programmatic verification against the API that we think it belongs to. Verification eliminates false positives and provides three result statuses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;verified&lt;/strong&gt;: Credential confirmed as valid and active by API testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;unverified&lt;/strong&gt;: Credential detected but not confirmed valid (may be invalid, expired, or verification disabled)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;unknown&lt;/strong&gt;: Verification attempted but failed due to errors, such as a network or API failure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, the &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/pkg/detectors/aws/aws.go"&gt;AWS credential detector&lt;/a&gt; performs a &lt;code&gt;GetCallerIdentity&lt;/code&gt; API call against the AWS API to verify if an AWS credential is active.&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;📝&lt;/span&gt; Usage&lt;/h1&gt; 
&lt;p&gt;TruffleHog has a sub-command for each source of data that you may want to scan:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;git&lt;/li&gt; 
 &lt;li&gt;github&lt;/li&gt; 
 &lt;li&gt;gitlab&lt;/li&gt; 
 &lt;li&gt;docker&lt;/li&gt; 
 &lt;li&gt;s3&lt;/li&gt; 
 &lt;li&gt;filesystem (files and directories)&lt;/li&gt; 
 &lt;li&gt;syslog&lt;/li&gt; 
 &lt;li&gt;circleci&lt;/li&gt; 
 &lt;li&gt;travisci&lt;/li&gt; 
 &lt;li&gt;gcs (Google Cloud Storage)&lt;/li&gt; 
 &lt;li&gt;postman&lt;/li&gt; 
 &lt;li&gt;jenkins&lt;/li&gt; 
 &lt;li&gt;elasticsearch&lt;/li&gt; 
 &lt;li&gt;stdin&lt;/li&gt; 
 &lt;li&gt;multi-scan&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each subcommand can have options that you can see with the &lt;code&gt;--help&lt;/code&gt; flag provided to the sub command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ trufflehog git --help
usage: TruffleHog git [&amp;lt;flags&amp;gt;] &amp;lt;uri&amp;gt;

Find credentials in git repositories.

Flags:
  -h, --help                Show context-sensitive help (also try --help-long and --help-man).
      --log-level=0         Logging verbosity on a scale of 0 (info) to 5 (trace). Can be disabled with "-1".
      --profile             Enables profiling and sets a pprof and fgprof server on :18066.
  -j, --json                Output in JSON format.
      --json-legacy         Use the pre-v3.0 JSON format. Only works with git, gitlab, and github sources.
      --github-actions      Output in GitHub Actions format.
      --concurrency=20           Number of concurrent workers.
      --no-verification     Don't verify the results.
      --results=RESULTS          Specifies which type(s) of results to output: verified (confirmed valid by API), unknown (verification failed due to error), unverified (detected but not verified), filtered_unverified (unverified but would have been filtered out). Defaults to all types.
      --allow-verification-overlap
                                 Allow verification of similar credentials across detectors
      --filter-unverified   Only output first unverified result per chunk per detector if there are more than one results.
      --filter-entropy=FILTER-ENTROPY
                                 Filter unverified results with Shannon entropy. Start with 3.0.
      --config=CONFIG            Path to configuration file.
      --print-avg-detector-time
                                 Print the average time spent on each detector.
      --no-update           Don't check for updates.
      --fail                Exit with code 183 if results are found.
      --verifier=VERIFIER ...    Set custom verification endpoints.
      --custom-verifiers-only   Only use custom verification endpoints.
      --archive-max-size=ARCHIVE-MAX-SIZE
                                 Maximum size of archive to scan. (Byte units eg. 512B, 2KB, 4MB)
      --archive-max-depth=ARCHIVE-MAX-DEPTH
                                 Maximum depth of archive to scan.
      --archive-timeout=ARCHIVE-TIMEOUT
                                 Maximum time to spend extracting an archive.
      --include-detectors="all"  Comma separated list of detector types to include. Protobuf name or IDs may be used, as well as ranges.
      --exclude-detectors=EXCLUDE-DETECTORS
                                 Comma separated list of detector types to exclude. Protobuf name or IDs may be used, as well as ranges. IDs defined here take precedence over the include list.
      --version             Show application version.
  -i, --include-paths=INCLUDE-PATHS
                                 Path to file with newline separated regexes for files to include in scan.
  -x, --exclude-paths=EXCLUDE-PATHS
                                 Path to file with newline separated regexes for files to exclude in scan.
      --exclude-globs=EXCLUDE-GLOBS
                                 Comma separated list of globs to exclude in scan. This option filters at the `git log` level, resulting in faster scans.
      --since-commit=SINCE-COMMIT
                                 Commit to start scan from.
      --branch=BRANCH            Branch to scan.
      --max-depth=MAX-DEPTH      Maximum depth of commits to scan.
      --bare                Scan bare repository (e.g. useful while using in pre-receive hooks)

Args:
  &amp;lt;uri&amp;gt;  Git repository URL. https://, file://, or ssh:// schema expected.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For example, to scan a &lt;code&gt;git&lt;/code&gt; repository, start with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;trufflehog git https://github.com/trufflesecurity/trufflehog.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;TruffleHog supports defining &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/#regex-detector-alpha"&gt;custom regex detectors&lt;/a&gt; and multiple sources in a configuration file provided via the &lt;code&gt;--config&lt;/code&gt; flag. The regex detectors can be used with any subcommand, while the sources defined in configuration are only for the &lt;code&gt;multi-scan&lt;/code&gt; subcommand.&lt;/p&gt; 
&lt;p&gt;The configuration format for sources can be found on Truffle Security's &lt;a href="https://docs.trufflesecurity.com/scan-data-for-secrets"&gt;source configuration documentation page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Example GitHub source configuration and &lt;a href="https://docs.trufflesecurity.com/github#Fvm1I"&gt;options reference&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;sources:
- connection:
    '@type': type.googleapis.com/sources.GitHub
    repositories:
    - https://github.com/trufflesecurity/test_keys.git
    unauthenticated: {}
  name: example config scan
  type: SOURCE_TYPE_GITHUB
  verify: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You may define multiple connections under the &lt;code&gt;sources&lt;/code&gt; key (see above), and TruffleHog will scan all of the sources concurrently.&lt;/p&gt; 
&lt;h2&gt;S3&lt;/h2&gt; 
&lt;p&gt;The S3 source supports assuming IAM roles for scanning in addition to IAM users. This makes it easier for users to scan multiple AWS accounts without needing to rely on hardcoded credentials for each account.&lt;/p&gt; 
&lt;p&gt;The IAM identity that TruffleHog uses initially will need to have &lt;code&gt;AssumeRole&lt;/code&gt; privileges as a principal in the &lt;a href="https://aws.amazon.com/blogs/security/how-to-use-trust-policies-with-iam-roles/"&gt;trust policy&lt;/a&gt; of each IAM role to assume.&lt;/p&gt; 
&lt;p&gt;To scan a specific bucket using locally set credentials or instance metadata if on an EC2 instance:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --bucket=&amp;lt;bucket-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To scan a specific bucket using an assumed role:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --bucket=&amp;lt;bucket-name&amp;gt; --role-arn=&amp;lt;iam-role-arn&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Multiple roles can be passed as separate arguments. The following command will attempt to scan every bucket each role has permissions to list in the S3 API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --role-arn=&amp;lt;iam-role-arn-1&amp;gt; --role-arn=&amp;lt;iam-role-arn-2&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Exit Codes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;0: No errors and no results were found.&lt;/li&gt; 
 &lt;li&gt;1: An error was encountered. Sources may not have completed scans.&lt;/li&gt; 
 &lt;li&gt;183: No errors were encountered, but results were found. Will only be returned if &lt;code&gt;--fail&lt;/code&gt; flag is used.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) TruffleHog Github Action&lt;/h2&gt; 
&lt;h3&gt;General Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;on:
  push:
    branches:
      - main
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    - name: Secret Scanning
      uses: trufflesecurity/trufflehog@main
      with:
        extra_args: --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the example config above, we're scanning for live secrets in all PRs and Pushes to &lt;code&gt;main&lt;/code&gt;. Only code changes in the referenced commits are scanned. If you'd like to scan an entire branch, please see the "Advanced Usage" section below.&lt;/p&gt; 
&lt;h3&gt;Shallow Cloning&lt;/h3&gt; 
&lt;p&gt;If you're incorporating TruffleHog into a standalone workflow and aren't running any other CI/CD tooling alongside TruffleHog, then we recommend using &lt;a href="https://git-scm.com/docs/git-clone#Documentation/git-clone.txt---depthltdepthgt"&gt;Shallow Cloning&lt;/a&gt; to speed up your workflow. Here's an example of how to do it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;...
      - shell: bash
        run: |
          if [ "${{ github.event_name }}" == "push" ]; then
            echo "depth=$(($(jq length &amp;lt;&amp;lt;&amp;lt; '${{ toJson(github.event.commits) }}') + 2))" &amp;gt;&amp;gt; $GITHUB_ENV
            echo "branch=${{ github.ref_name }}" &amp;gt;&amp;gt; $GITHUB_ENV
          fi
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            echo "depth=$((${{ github.event.pull_request.commits }}+2))" &amp;gt;&amp;gt; $GITHUB_ENV
            echo "branch=${{ github.event.pull_request.head.ref }}" &amp;gt;&amp;gt; $GITHUB_ENV
          fi
      - uses: actions/checkout@v3
        with:
          ref: ${{env.branch}}
          fetch-depth: ${{env.depth}}
      - uses: trufflesecurity/trufflehog@main
        with:
          extra_args: --results=verified,unknown
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Depending on the event type (push or PR), we calculate the number of commits present. Then we add 2, so that we can reference a base commit before our code changes. We pass that integer value to the &lt;code&gt;fetch-depth&lt;/code&gt; flag in the checkout action in addition to the relevant branch. Now our checkout process should be much shorter.&lt;/p&gt; 
&lt;h3&gt;Canary detection&lt;/h3&gt; 
&lt;p&gt;TruffleHog statically detects &lt;a href="https://canarytokens.org/"&gt;https://canarytokens.org/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/trufflesecurity/trufflehog/assets/52866392/74ace530-08c5-4eaf-a169-84a73e328f6f" alt="image" /&gt;&lt;/p&gt; 
&lt;h3&gt;Advanced Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;- name: TruffleHog
  uses: trufflesecurity/trufflehog@main
  with:
    # Repository path
    path:
    # Start scanning from here (usually main branch).
    base:
    # Scan commits until here (usually dev branch).
    head: # optional
    # Extra args to be passed to the trufflehog cli.
    extra_args: --log-level=2 --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you'd like to specify specific &lt;code&gt;base&lt;/code&gt; and &lt;code&gt;head&lt;/code&gt; refs, you can use the &lt;code&gt;base&lt;/code&gt; argument (&lt;code&gt;--since-commit&lt;/code&gt; flag in TruffleHog CLI) and the &lt;code&gt;head&lt;/code&gt; argument (&lt;code&gt;--branch&lt;/code&gt; flag in the TruffleHog CLI). We only recommend using these arguments for very specific use cases, where the default behavior does not work.&lt;/p&gt; 
&lt;h4&gt;Advanced Usage: Scan entire branch&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;- name: scan-push
        uses: trufflesecurity/trufflehog@main
        with:
          base: ""
          head: ${{ github.ref_name }}
          extra_args: --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;TruffleHog GitLab CI&lt;/h2&gt; 
&lt;h3&gt;Example Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;stages:
  - security

security-secrets:
  stage: security
  allow_failure: false
  image: alpine:latest
  variables:
    SCAN_PATH: "." # Set the relative path in the repo to scan
  before_script:
    - apk add --no-cache git curl jq
    - curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin
  script:
    - trufflehog filesystem "$SCAN_PATH" --results=verified,unknown --fail --json | jq
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the example pipeline above, we're scanning for live secrets in all repository directories and files. This job runs only when the pipeline source is a merge request event, meaning it's triggered when a new merge request is created.&lt;/p&gt; 
&lt;h2&gt;Pre-commit Hook&lt;/h2&gt; 
&lt;p&gt;TruffleHog can be used in a pre-commit hook to prevent credentials from leaking before they ever leave your computer.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/PreCommit.md"&gt;pre-commit hook documentation&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Regex Detector (alpha)&lt;/h2&gt; 
&lt;p&gt;TruffleHog supports detection and verification of custom regular expressions. For detection, at least one &lt;strong&gt;regular expression&lt;/strong&gt; and &lt;strong&gt;keyword&lt;/strong&gt; is required. A &lt;strong&gt;keyword&lt;/strong&gt; is a fixed literal string identifier that appears in or around the regex to be detected. To allow maximum flexibility for verification, a webhook is used containing the regular expression matches.&lt;/p&gt; 
&lt;p&gt;TruffleHog will send a JSON POST request containing the regex matches to a configured webhook endpoint. If the endpoint responds with a &lt;code&gt;200 OK&lt;/code&gt; response status code, the secret is considered verified. If verification fails due to network/API errors, the result is marked as unknown.&lt;/p&gt; 
&lt;p&gt;Custom Detectors support a few different filtering mechanisms: entropy, regex targeting the entire match, regex targeting the captured secret, and excluded word lists checked against the secret (captured group if present, entire match if capture group is not present). Note that if your custom detector has multiple &lt;code&gt;regex&lt;/code&gt; set (in this example &lt;code&gt;hogID&lt;/code&gt;, and &lt;code&gt;hogToken&lt;/code&gt;), then the filters get applied to each regex. &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/examples/generic_with_filters.yml"&gt;Here&lt;/a&gt; is an example of a custom detector using these filters.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; This feature is alpha and subject to change.&lt;/p&gt; 
&lt;h3&gt;Regex Detector Example&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/pkg/custom_detectors/CUSTOM_DETECTORS.md"&gt;Here&lt;/a&gt; is how to setup a custom regex detector with verification server.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;🔍&lt;/span&gt; Analyze&lt;/h2&gt; 
&lt;p&gt;TruffleHog supports running a deeper analysis of a credential to view its permissions and the resources it has access to.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog analyze
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;&lt;span&gt;❤️&lt;/span&gt; Contributors&lt;/h1&gt; 
&lt;p&gt;This project exists thanks to all the people who contribute. [&lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt;].&lt;/p&gt; 
&lt;a href="https://github.com/trufflesecurity/trufflehog/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=trufflesecurity/trufflehog" /&gt; &lt;/a&gt; 
&lt;h1&gt;&lt;span&gt;💻&lt;/span&gt; Contributing&lt;/h1&gt; 
&lt;p&gt;Contributions are very welcome! Please see our &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/CONTRIBUTING.md"&gt;contribution guidelines first&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We no longer accept contributions to TruffleHog v2, but that code is available in the &lt;code&gt;v2&lt;/code&gt; branch.&lt;/p&gt; 
&lt;h2&gt;Adding new secret detectors&lt;/h2&gt; 
&lt;p&gt;We have published some &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/hack/docs/Adding_Detectors_external.md"&gt;documentation and tooling to get started on adding new secret detectors&lt;/a&gt;. Let's improve detection together!&lt;/p&gt; 
&lt;h1&gt;Use as a library&lt;/h1&gt; 
&lt;p&gt;Currently, trufflehog is in heavy development and no guarantees can be made on the stability of the public APIs at this time.&lt;/p&gt; 
&lt;h1&gt;License Change&lt;/h1&gt; 
&lt;p&gt;Since v3.0, TruffleHog is released under a AGPL 3 license, included in &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt;. TruffleHog v3.0 uses none of the previous codebase, but care was taken to preserve backwards compatibility on the command line interface. The work previous to this release is still available licensed under GPL 2.0 in the history of this repository and the previous package releases and tags. A completed CLA is required for us to accept contributions going forward.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cloudflare/cloudflared</title>
      <link>https://github.com/cloudflare/cloudflared</link>
      <description>&lt;p&gt;Cloudflare Tunnel client (formerly Argo Tunnel)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Cloudflare Tunnel client&lt;/h1&gt; 
&lt;p&gt;Contains the command-line client for Cloudflare Tunnel, a tunneling daemon that proxies traffic from the Cloudflare network to your origins. This daemon sits between Cloudflare network and your origin (e.g. a webserver). Cloudflare attracts client requests and sends them to you via this daemon, without requiring you to poke holes on your firewall --- your origin can remain as closed as possible. Extensive documentation can be found in the &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel"&gt;Cloudflare Tunnel section&lt;/a&gt; of the Cloudflare Docs. All usages related with proxying to your origins are available under &lt;code&gt;cloudflared tunnel help&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also use &lt;code&gt;cloudflared&lt;/code&gt; to access Tunnel origins (that are protected with &lt;code&gt;cloudflared tunnel&lt;/code&gt;) for TCP traffic at Layer 4 (i.e., not HTTP/websocket), which is relevant for use cases such as SSH, RDP, etc. Such usages are available under &lt;code&gt;cloudflared access help&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can instead use &lt;a href="https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/"&gt;WARP client&lt;/a&gt; to access private origins behind Tunnels for Layer 4 traffic without requiring &lt;code&gt;cloudflared access&lt;/code&gt; commands on the client side.&lt;/p&gt; 
&lt;h2&gt;Before you get started&lt;/h2&gt; 
&lt;p&gt;Before you use Cloudflare Tunnel, you'll need to complete a few steps in the Cloudflare dashboard: you need to add a website to your Cloudflare account. Note that today it is possible to use Tunnel without a website (e.g. for private routing), but for legacy reasons this requirement is still necessary:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://developers.cloudflare.com/fundamentals/manage-domains/add-site/"&gt;Add a website to Cloudflare&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.cloudflare.com/dns/zone-setups/full-setup/setup/"&gt;Change your domain nameservers to Cloudflare&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Installing &lt;code&gt;cloudflared&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;Downloads are available as standalone binaries, a Docker image, and Debian, RPM, and Homebrew packages. You can also find releases &lt;a href="https://github.com/cloudflare/cloudflared/releases"&gt;here&lt;/a&gt; on the &lt;code&gt;cloudflared&lt;/code&gt; GitHub repository.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/downloads/#macos"&gt;install on macOS&lt;/a&gt; via Homebrew or by downloading the &lt;a href="https://github.com/cloudflare/cloudflared/releases"&gt;latest Darwin amd64 release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Binaries, Debian, and RPM packages for Linux &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/downloads/#linux"&gt;can be found here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;A Docker image of &lt;code&gt;cloudflared&lt;/code&gt; is &lt;a href="https://hub.docker.com/r/cloudflare/cloudflared"&gt;available on DockerHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;You can install on Windows machines with the &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/downloads/#windows"&gt;steps here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;To build from source, install the required version of go, mentioned in the &lt;a href="https://raw.githubusercontent.com/cloudflare/cloudflared/master/#development"&gt;Development&lt;/a&gt; section below. Then you can run &lt;code&gt;make cloudflared&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;User documentation for Cloudflare Tunnel can be found at &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/"&gt;https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Creating Tunnels and routing traffic&lt;/h2&gt; 
&lt;p&gt;Once installed, you can authenticate &lt;code&gt;cloudflared&lt;/code&gt; into your Cloudflare account and begin creating Tunnels to serve traffic to your origins.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a Tunnel with &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/get-started/"&gt;these instructions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Route traffic to that Tunnel: 
  &lt;ul&gt; 
   &lt;li&gt;Via public &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/routing-to-tunnel/dns/"&gt;DNS records in Cloudflare&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Or via a public hostname guided by a &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/routing-to-tunnel/public-load-balancers/"&gt;Cloudflare Load Balancer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Or from &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/"&gt;WARP client private traffic&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;TryCloudflare&lt;/h2&gt; 
&lt;p&gt;Want to test Cloudflare Tunnel before adding a website to Cloudflare? You can do so with TryCloudflare using the documentation &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/do-more-with-tunnels/trycloudflare/"&gt;available here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deprecated versions&lt;/h2&gt; 
&lt;p&gt;Cloudflare currently supports versions of cloudflared that are &lt;strong&gt;within one year&lt;/strong&gt; of the most recent release. Breaking changes unrelated to feature availability may be introduced that will impact versions released more than one year ago. You can read more about upgrading cloudflared in our &lt;a href="https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/downloads/update-cloudflared/"&gt;developer documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For example, as of January 2023 Cloudflare will support cloudflared version 2023.1.1 to cloudflared 2022.1.1.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.gnu.org/software/make/"&gt;GNU Make&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://capnproto.org/install.html"&gt;capnp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/install"&gt;go &amp;gt;= 1.24&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Optional tools: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/zombiezen.com/go/capnproto2/capnpc-go"&gt;capnpc-go&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/golang.org/x/tools/cmd/goimports"&gt;goimports&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/golangci/golangci-lint"&gt;golangci-lint&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/go.uber.org/mock"&gt;gomocks&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;p&gt;To build cloudflared locally run &lt;code&gt;make cloudflared&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Test&lt;/h3&gt; 
&lt;p&gt;To locally run the tests run &lt;code&gt;make test&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Linting&lt;/h3&gt; 
&lt;p&gt;To format the code and keep a good code quality use &lt;code&gt;make fmt&lt;/code&gt; and &lt;code&gt;make lint&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Mocks&lt;/h3&gt; 
&lt;p&gt;After changes on interfaces you might need to regenerate the mocks, so run &lt;code&gt;make mock&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>open-telemetry/opentelemetry-collector-contrib</title>
      <link>https://github.com/open-telemetry/opentelemetry-collector-contrib</link>
      <description>&lt;p&gt;Contrib repository for the OpenTelemetry Collector&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://opentelemetry.io/docs/collector/getting-started/"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/CONTRIBUTING.md"&gt;Getting Involved&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;Getting In Touch&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain"&gt; &lt;img alt="Build Status" src="https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib"&gt; &lt;img alt="Go Report Card" src="https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/"&gt; &lt;img alt="Codecov Status" src="https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/releases"&gt; &lt;img alt="GitHub release (latest by date including pre-releases)" src="https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;img alt="Beta" src="https://img.shields.io/badge/status-beta-informational?style=for-the-badge&amp;amp;logo=data:image/png;base64,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" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/docs/vision.md"&gt;Vision&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/docs/observability.md"&gt;Observability&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/docs/security-best-practices.md"&gt;Security&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;/strong&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;OpenTelemetry Collector Contrib&lt;/h1&gt; 
&lt;p&gt;This is a repository for OpenTelemetry Collector components that are not suitable for the &lt;a href="https://github.com/open-telemetry/opentelemetry-collector"&gt;core repository&lt;/a&gt; of the collector.&lt;/p&gt; 
&lt;p&gt;The official distributions, core and contrib, are available as part of the &lt;a href="https://github.com/open-telemetry/opentelemetry-collector-releases"&gt;opentelemetry-collector-releases&lt;/a&gt; repository. Some of the components in this repository are part of the "core" distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the "contrib" distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder"&gt;OpenTelemetry Collector Builder&lt;/a&gt;, using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.&lt;/p&gt; 
&lt;p&gt;Each component has its own support levels, as defined in the following sections. For each signal that a component supports, there's a stability level, setting the right expectations. It is possible then that a component will be &lt;strong&gt;Stable&lt;/strong&gt; for traces but &lt;strong&gt;Alpha&lt;/strong&gt; for metrics and &lt;strong&gt;Development&lt;/strong&gt; for logs.&lt;/p&gt; 
&lt;h2&gt;Stability levels&lt;/h2&gt; 
&lt;p&gt;Stability level for components in this repository follow the &lt;a href="https://github.com/open-telemetry/opentelemetry-collector#stability-levels"&gt;definitions&lt;/a&gt; from the OpenTelemetry Collector repository.&lt;/p&gt; 
&lt;h2&gt;Gated features&lt;/h2&gt; 
&lt;p&gt;Some features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle"&gt;lifecycle stages&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Each component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group &lt;a href="https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer"&gt;@open-telemetry/collector-contrib-maintainer&lt;/a&gt;, or by specific vendors. See the individual README files for information about the specific components.&lt;/p&gt; 
&lt;p&gt;The OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.&lt;/p&gt; 
&lt;p&gt;Even though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector-contrib/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/codeboten"&gt;Alex Boten&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrzej-stencel"&gt;Andrzej Stencel&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atoulme"&gt;Antoine Toulme&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bogdandrutu"&gt;Bogdan Drutu&lt;/a&gt;, Snowflake&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmitryax"&gt;Dmitrii Anoshin&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/edmocosta"&gt;Edmo Vamerlatti Costa&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evan-bradley"&gt;Evan Bradley&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mx-psi"&gt;Pablo Baeyens&lt;/a&gt;, DataDog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MovieStoreGuy"&gt;Sean Marciniak&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TylerHelmuth"&gt;Tyler Helmuth&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/songy23"&gt;Yang Song&lt;/a&gt;, DataDog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the maintainer role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#maintainer"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/axw"&gt;Andrew Wilkins&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArthurSens"&gt;Arthur Silva Sens&lt;/a&gt;, Grafana Labs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/braydonk"&gt;Braydon Kains&lt;/a&gt;, Google&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChrsMark"&gt;Christos Markou&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crobert-1"&gt;Curtis Robert&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dashpole"&gt;David Ashpole&lt;/a&gt;, Google&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mwear"&gt;Matt Wear&lt;/a&gt;, Lightstep&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pjanotti"&gt;Paulo Janotti&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dehaansa"&gt;Sam DeHaan&lt;/a&gt;, Grafana Labs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/VihasMakwana"&gt;Vihas Makwana&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fatsheep9146"&gt;Ziqi Zhao&lt;/a&gt;, Alibaba&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the approver role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#approver"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frzifus"&gt;Benedikt Bongartz&lt;/a&gt;, Red Hat&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bogdan-st"&gt;Bogdan Stancu&lt;/a&gt;, Adobe&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/constanca-m"&gt;Constança Manteigas&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/douglascamata"&gt;Douglas Camata&lt;/a&gt;, Coralogix&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bacherfl"&gt;Florian Bacher&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/iblancasa"&gt;Israel Blancas&lt;/a&gt;, Coralogix&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jamesmoessis"&gt;James Moessis&lt;/a&gt;, Atlassian&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JaredTan95"&gt;Jared Tan&lt;/a&gt;, DaoCloud&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Frapschen"&gt;Murphy Chen&lt;/a&gt;, DaoCloud&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/odubajDT"&gt;Ondrej Dubaj&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rogercoll"&gt;Roger Coll&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;Actively seeking contributors to triage issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the triager role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#triager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djaglowski"&gt;Daniel Jaglowski&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jpkrohling"&gt;Juraci Paixão Kröhling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tigrannajaryan"&gt;Tigran Najaryan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aneurysm9"&gt;Anthony Mirabella&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bryan-aguilar"&gt;Bryan Aguilar&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pmm-sumo"&gt;Przemek Maciolek&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kovrus"&gt;Ruslan Kovalov&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alolita"&gt;Alolita Sharma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gbbr"&gt;Gabriel Aszalos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gouthamve"&gt;Goutham Veeramachaneni&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/punya"&gt;Punya Biswal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flands"&gt;Steve Flanders&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;No Over-Representation&lt;/h3&gt; 
&lt;p&gt;A community member cannot be promoted to be a Collector contrib maintainer if, after their promotion, the resulting maintainers group has more than one-fourth (25%) of the members affiliated with the same employer. Job changes and similar events might result in over-representation, and no new maintainers from the same company can be promoted until representation is balanced again. In the event of confusion or concern, the OpenTelemetry Collector SIG will defer to the CNCF definition of "same employer".&lt;/p&gt; 
&lt;h2&gt;PRs and Reviews&lt;/h2&gt; 
&lt;p&gt;When creating a PR please follow the process &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews"&gt;described here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;New PRs will be automatically associated with the reviewers based on &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector-contrib/main/.github/CODEOWNERS"&gt;CODEOWNERS&lt;/a&gt;. PRs will be also automatically assigned to one of the maintainers or approvers for facilitation.&lt;/p&gt; 
&lt;p&gt;The facilitator is responsible for helping the PR author and reviewers to make progress or if progress cannot be made for closing the PR.&lt;/p&gt; 
&lt;p&gt;If the reviewers do not have approval rights the facilitator is also responsible for the official approval that is required for the PR to be merged and if the facilitator is a maintainer they are responsible for merging the PR as well.&lt;/p&gt; 
&lt;p&gt;The facilitator is not required to perform a thorough review, but they are encouraged to enforce Collector best practices and consistency across the codebase and component behavior. The facilitators will typically rely on codeowner's detailed review of the code when making the final approval decision.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="官方网站" src="https://img.shields.io/badge/官方网站-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="微信对话开放平台" src="https://img.shields.io/badge/微信对话开放平台-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.1.3-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;简体中文&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;日本語&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;💡 WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;📌 Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🔒 Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🏗️ Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/pipeline.jpg" alt="weknora-pipeline.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;🎯 Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🔍 Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🧠 Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔧 Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;⚡ Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎯 User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔒 Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📊 Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🧩 Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;✅ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;✅ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;✅ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;✅ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;✅ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;✅ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;✅ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;✅ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;✅ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, suitable for both developers and business users&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;h3&gt;🛠 Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📦 Installation&lt;/h3&gt; 
&lt;h4&gt;① Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;② Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;③ Start the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start all services (Ollama + backend containers)
./scripts/start_all.sh
# Or
make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;③ Start the services (backup)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start ollama services (Optional)
ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;

# Start the service
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;④ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;🌐 Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔌 Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔗 Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1️⃣ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2️⃣ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🔧 Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ①② and go directly to steps ③④.&lt;/p&gt; 
&lt;h3&gt;① Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;② Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;③ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;④ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On first access, it will automatically redirect to the initialization configuration page. After configuration is complete, it will automatically redirect to the knowledge base page. Please follow the page instructions to complete model configuration.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/config.png" alt="Configuration Page" /&gt;&lt;/p&gt; 
&lt;h2&gt;📱 Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Upload&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledges.png" alt="Knowledge Upload Interface" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Q&amp;amp;A Entry&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/qa.png" alt="Q&amp;amp;A Entry Interface" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Rich Text &amp;amp; Image Responses&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/answer.png" alt="Rich Answer Interface" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for dragging and dropping various documents, automatically identifying document structures and extracting core knowledge to establish indexes. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/graph2.png" alt="Knowledge Graph View 1" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/graph1.png" alt="Knowledge Graph View 2" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;h3&gt;MCP Server Integration Effects&lt;/h3&gt; 
&lt;img width="950" height="2063" alt="MCP Server Integration Demo" src="https://github.com/user-attachments/assets/09111ec8-0489-415c-969d-aa3835778e14" /&gt; 
&lt;h2&gt;📘 API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/API.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🧭 Developer Guide&lt;/h2&gt; 
&lt;h3&gt;📁 Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
├── cmd/         # Main entry point
├── internal/    # Core business logic
├── config/      # Configuration files
├── migrations/  # DB migration scripts
├── scripts/     # Shell scripts
├── services/    # Microservice logic
├── frontend/    # Frontend app
└── docs/        # Project documentation
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;🔧 Common Commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Wipe all data from DB (use with caution)
make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;🎯 How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;🐛 &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;✨ &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;📚 &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;🧪 &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;🎨 &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📋 Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🎨 Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📝 Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;👥 Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;📈 Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>grafana/mimir</title>
      <link>https://github.com/grafana/mimir</link>
      <description>&lt;p&gt;Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Grafana Mimir&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/grafana/mimir/main/images/logo.png" alt="Grafana Mimir logo" width="400" /&gt;&lt;/p&gt; 
&lt;p&gt;Grafana Mimir is an open source software project that provides a scalable long-term storage for &lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt;. Some of the core strengths of Grafana Mimir include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to install and maintain:&lt;/strong&gt; Grafana Mimir’s extensive documentation, tutorials, and deployment tooling make it quick to get started. Using its monolithic mode, you can get Grafana Mimir up and running with just one binary and no additional dependencies. Once deployed, the best-practice dashboards, alerts, and runbooks packaged with Grafana Mimir make it easy to monitor the health of the system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Massive scalability:&lt;/strong&gt; You can run Grafana Mimir's horizontally-scalable architecture across multiple machines, resulting in the ability to process orders of magnitude more time series than a single Prometheus instance. Internal testing shows that Grafana Mimir handles up to 1 billion active time series.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Global view of metrics:&lt;/strong&gt; Grafana Mimir enables you to run queries that aggregate series from multiple Prometheus instances, giving you a global view of your systems. Its query engine extensively parallelizes query execution, so that even the highest-cardinality queries complete with blazing speed.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cheap, durable metric storage:&lt;/strong&gt; Grafana Mimir uses object storage for long-term data storage, allowing it to take advantage of this ubiquitous, cost-effective, high-durability technology. It is compatible with multiple object store implementations, including AWS S3, Google Cloud Storage, Azure Blob Storage, OpenStack Swift, as well as any S3-compatible object storage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High availability:&lt;/strong&gt; Grafana Mimir replicates incoming metrics, ensuring that no data is lost in the event of machine failure. Its horizontally scalable architecture also means that it can be restarted, upgraded, or downgraded with zero downtime, which means no interruptions to metrics ingestion or querying.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Natively multi-tenant:&lt;/strong&gt; Grafana Mimir’s multi-tenant architecture enables you to isolate data and queries from independent teams or business units, making it possible for these groups to share the same cluster. Advanced limits and quality-of-service controls ensure that capacity is shared fairly among tenants.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Migrating to Grafana Mimir&lt;/h2&gt; 
&lt;p&gt;If you're migrating to Grafana Mimir, refer to the following documents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-thanos-or-prometheus/"&gt;Migrating from Thanos or Prometheus to Grafana Mimir&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-cortex/"&gt;Migrating from Cortex to Grafana Mimir&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Deploying Grafana Mimir&lt;/h2&gt; 
&lt;p&gt;For information about how to deploy Grafana Mimir, refer to &lt;a href="https://grafana.com/docs/mimir/latest/operators-guide/deploy-grafana-mimir/"&gt;Deploy Grafana Mimir&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;If you’re new to Grafana Mimir, read the &lt;a href="https://grafana.com/docs/mimir/latest/get-started/"&gt;Get started guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Before deploying Grafana Mimir in a production environment, read:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/operators-guide/architecture/"&gt;An overview of Grafana Mimir’s architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/operators-guide/configure/"&gt;Configure Grafana Mimir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/operators-guide/run-production-environment/"&gt;Run Grafana Mimir in production&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Refer to the following links to access Grafana Mimir documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/"&gt;Latest release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/next/"&gt;Upcoming release&lt;/a&gt;, at the tip of the &lt;code&gt;main&lt;/code&gt; branch&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;To contribute to Grafana Mimir, refer to &lt;a href="https://github.com/grafana/mimir/tree/main/docs/internal/contributing"&gt;Contributing to Grafana Mimir&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Join the Grafana Mimir discussion&lt;/h2&gt; 
&lt;p&gt;If you have any questions or feedback regarding Grafana Mimir, join the &lt;a href="https://github.com/grafana/mimir/discussions"&gt;Grafana Mimir Discussion&lt;/a&gt;. Alternatively, consider joining the monthly &lt;a href="https://docs.google.com/document/d/1E4jJcGicvLTyMEY6cUFFZUg_I8ytrBuW8r5yt1LyMv4"&gt;Grafana Mimir Community Call&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your feedback is always welcome, and you can also share it via the &lt;a href="https://slack.grafana.com/"&gt;&lt;code&gt;#mimir&lt;/code&gt; Slack channel&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Grafana Mimir is distributed under &lt;a href="https://raw.githubusercontent.com/grafana/mimir/main/LICENSE"&gt;AGPL-3.0-only&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>charmbracelet/glow</title>
      <link>https://github.com/charmbracelet/glow</link>
      <description>&lt;p&gt;Render markdown on the CLI, with pizzazz! 💅🏻&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Glow&lt;/h1&gt; 
&lt;p&gt;Render markdown on the CLI, with &lt;em&gt;pizzazz&lt;/em&gt;!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://stuff.charm.sh/glow/glow-banner-github.gif" alt="Glow Logo" /&gt; &lt;a href="https://github.com/charmbracelet/glow/releases"&gt;&lt;img src="https://img.shields.io/github/release/charmbracelet/glow.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/charmbracelet/glow?tab=doc"&gt;&lt;img src="https://godoc.org/github.com/golang/gddo?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/charmbracelet/glow/actions"&gt;&lt;img src="https://github.com/charmbracelet/glow/workflows/build/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/charmbracelet/glow"&gt;&lt;img src="https://goreportcard.com/badge/charmbracelet/glow" alt="Go ReportCard" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/c2246366-f84b-4847-b431-32a61ca07b74" width="800" alt="Glow UI Demo" /&gt; &lt;/p&gt; 
&lt;h2&gt;What is it?&lt;/h2&gt; 
&lt;p&gt;Glow is a terminal based markdown reader designed from the ground up to bring out the beauty—and power—of the CLI.&lt;/p&gt; 
&lt;p&gt;Use it to discover markdown files, read documentation directly on the command line. Glow will find local markdown files in subdirectories or a local Git repository.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Package Manager&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS or Linux
brew install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (with MacPorts)
sudo port install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Arch Linux (btw)
pacman -S glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Void Linux
xbps-install -S glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Nix shell
nix-shell -p glow --command glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# FreeBSD
pkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Solus
eopkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Windows (with Chocolatey, Scoop, or Winget)
choco install glow
scoop install glow
winget install charmbracelet.glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Android (with termux)
pkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu (Snapcraft)
sudo snap install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Debian/Ubuntu
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo "deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *" | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;amp;&amp;amp; sudo apt install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fedora/RHEL
echo '[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key' | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or download a binary from the &lt;a href="https://github.com/charmbracelet/glow/releases"&gt;releases&lt;/a&gt; page. MacOS, Linux, Windows, FreeBSD and OpenBSD binaries are available, as well as Debian, RPM, and Alpine packages. ARM builds are also available for macOS, Linux, FreeBSD and OpenBSD.&lt;/p&gt; 
&lt;h3&gt;Go&lt;/h3&gt; 
&lt;p&gt;Or just install it with &lt;code&gt;go&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/charmbracelet/glow/v2@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build (requires Go 1.21+)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/charmbracelet/glow.git
cd glow
go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;The TUI&lt;/h2&gt; 
&lt;p&gt;Simply run &lt;code&gt;glow&lt;/code&gt; without arguments to start the textual user interface and browse local. Glow will find local markdown files in the current directory and below or, if you’re in a Git repository, Glow will search the repo.&lt;/p&gt; 
&lt;p&gt;Markdown files can be read with Glow's high-performance pager. Most of the keystrokes you know from &lt;code&gt;less&lt;/code&gt; are the same, but you can press &lt;code&gt;?&lt;/code&gt; to list the hotkeys.&lt;/p&gt; 
&lt;h2&gt;The CLI&lt;/h2&gt; 
&lt;p&gt;In addition to a TUI, Glow has a CLI for working with Markdown. To format a document use a markdown source as the primary argument:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Read from file
glow README.md

# Read from stdin
echo "[Glow](https://github.com/charmbracelet/glow)" | glow -

# Fetch README from GitHub / GitLab
glow github.com/charmbracelet/glow

# Fetch markdown from HTTP
glow https://host.tld/file.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Word Wrapping&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;-w&lt;/code&gt; flag lets you set a maximum width at which the output will be wrapped:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -w 60
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Paging&lt;/h3&gt; 
&lt;p&gt;CLI output can be displayed in your preferred pager with the &lt;code&gt;-p&lt;/code&gt; flag. This defaults to the ANSI-aware &lt;code&gt;less -r&lt;/code&gt; if &lt;code&gt;$PAGER&lt;/code&gt; is not explicitly set.&lt;/p&gt; 
&lt;h3&gt;Styles&lt;/h3&gt; 
&lt;p&gt;You can choose a style with the &lt;code&gt;-s&lt;/code&gt; flag. When no flag is provided &lt;code&gt;glow&lt;/code&gt; tries to detect your terminal's current background color and automatically picks either the &lt;code&gt;dark&lt;/code&gt; or the &lt;code&gt;light&lt;/code&gt; style for you.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -s [dark|light]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively you can also supply a custom JSON stylesheet:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -s mystyle.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For additional usage details see:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/charmbracelet/glamour/raw/master/styles/gallery/README.md"&gt;Glamour Style Section&lt;/a&gt; to find more styles. Or &lt;a href="https://github.com/charmbracelet/glamour/tree/master/styles"&gt;make your own&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;The Config File&lt;/h2&gt; 
&lt;p&gt;If you find yourself supplying the same flags to &lt;code&gt;glow&lt;/code&gt; all the time, it's probably a good idea to create a config file. Run &lt;code&gt;glow config&lt;/code&gt;, which will open it in your favorite $EDITOR. Alternatively you can manually put a file named &lt;code&gt;glow.yml&lt;/code&gt; in the default config path of you platform. If you're not sure where that is, please refer to &lt;code&gt;glow --help&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here's an example config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# style name or JSON path (default "auto")
style: "light"
# mouse wheel support (TUI-mode only)
mouse: true
# use pager to display markdown
pager: true
# at which column should we word wrap?
width: 80
# show all files, including hidden and ignored.
all: false
# show line numbers (TUI-mode only)
showLineNumbers: false
# preserve newlines in the output
preserveNewLines: false
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/charmbracelet/glow/contribute"&gt;contributing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;We’d love to hear your thoughts on this project. Feel free to drop us a note!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/charmcli"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@charmcli"&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.sh/chat"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/glow/raw/master/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Part of &lt;a href="https://charm.sh"&gt;Charm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://charm.sh/"&gt;&lt;img alt="The Charm logo" src="https://stuff.charm.sh/charm-badge.jpg" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Charm热爱开源 • Charm loves open source&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>weaviate/weaviate</title>
      <link>https://github.com/weaviate/weaviate</link>
      <description>&lt;p&gt;Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of a cloud-native database​.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Weaviate &lt;img alt="Weaviate logo" src="https://weaviate.io/img/site/weaviate-logo-light.png" width="148" align="right" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/weaviate/weaviate"&gt;&lt;img src="https://img.shields.io/github/stars/weaviate/weaviate?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/weaviate/weaviate"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/weaviate/weaviate.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://github.com/weaviate/weaviate/actions/workflows/.github/workflows/pull_requests.yaml"&gt;&lt;img src="https://github.com/weaviate/weaviate/actions/workflows/.github/workflows/pull_requests.yaml/badge.svg?branch=main" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/weaviate/weaviate"&gt;&lt;img src="https://goreportcard.com/badge/github.com/weaviate/weaviate" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/weaviate/weaviate"&gt;&lt;img src="https://codecov.io/gh/weaviate/weaviate/branch/main/graph/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://weaviate.io/slack"&gt;&lt;img src="https://img.shields.io/badge/slack--channel-blue?logo=slack" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Weaviate&lt;/strong&gt; is an open-source, cloud-native vector database that stores both objects and vectors, enabling semantic search at scale. It combines vector similarity search with keyword filtering, retrieval-augmented generation (RAG), and reranking in a single query interface. Common use cases include RAG systems, semantic and image search, recommendation engines, chatbots, and content classification.&lt;/p&gt; 
&lt;p&gt;Weaviate supports two approaches to store vectors: automatic vectorization at import using &lt;a href="https://docs.weaviate.io/weaviate/model-providers"&gt;integrated models&lt;/a&gt; (OpenAI, Cohere, HuggingFace, and others) or direct import of &lt;a href="https://docs.weaviate.io/weaviate/starter-guides/custom-vectors"&gt;pre-computed vector embeddings&lt;/a&gt;. Production deployments benefit from built-in multi-tenancy, replication, RBAC authorization, and &lt;a href="https://raw.githubusercontent.com/weaviate/weaviate/main/#weaviate-features"&gt;many other features&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started quickly, have a look at one of these tutorials:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/quickstart"&gt;Quickstart - Weaviate Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/quickstart/local"&gt;Quickstart - local Docker instance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Weaviate offers multiple installation and deployment options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/deploy/installation-guides/docker-installation"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/deploy/installation-guides/k8s-installation"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://console.weaviate.cloud"&gt;Weaviate Cloud&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.weaviate.io/deploy"&gt;installation docs&lt;/a&gt; for more deployment options, such as &lt;a href="https://docs.weaviate.io/deploy/installation-guides/aws-marketplace"&gt;AWS&lt;/a&gt; and &lt;a href="https://docs.weaviate.io/deploy/installation-guides/gcp-marketplace"&gt;GCP&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;You can easily start Weaviate and a local vector embedding model with &lt;a href="https://docs.docker.com/desktop/"&gt;Docker&lt;/a&gt;. Create a &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;services:
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.32.2
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      ENABLE_MODULES: text2vec-model2vec
      MODEL2VEC_INFERENCE_API: http://text2vec-model2vec:8080

  # A lightweight embedding model that will generate vectors from objects during import
  text2vec-model2vec:
    image: cr.weaviate.io/semitechnologies/model2vec-inference:minishlab-potion-base-32M
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start Weaviate and the embedding service with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the Python client (or use another &lt;a href="https://raw.githubusercontent.com/weaviate/weaviate/main/#client-libraries-and-apis"&gt;client library&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U weaviate-client
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The following Python example shows how easy it is to populate a Weaviate database with data, create vector embeddings and perform semantic search:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import weaviate
from weaviate.classes.config import Configure, DataType, Property

# Connect to Weaviate
client = weaviate.connect_to_local()

# Create a collection
client.collections.create(
    name="Article",
    properties=[Property(name="content", data_type=DataType.TEXT)],
    vector_config=Configure.Vectors.text2vec_model2vec(),  # Use a vectorizer to generate embeddings during import
    # vector_config=Configure.Vectors.self_provided()  # If you want to import your own pre-generated embeddings
)

# Insert objects and generate embeddings
articles = client.collections.get("Article")
articles.data.insert_many(
    [
        {"content": "Vector databases enable semantic search"},
        {"content": "Machine learning models generate embeddings"},
        {"content": "Weaviate supports hybrid search capabilities"},
    ]
)

# Perform semantic search
results = articles.query.near_text(query="Search objects by meaning", limit=1)
print(results.objects[0])

client.close()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This example uses the &lt;code&gt;Model2Vec&lt;/code&gt; vectorizer, but you can choose any other &lt;a href="https://docs.weaviate.io/weaviate/model-providers"&gt;embedding model provider&lt;/a&gt; or &lt;a href="https://docs.weaviate.io/weaviate/starter-guides/custom-vectors"&gt;bring your own pre-generated vectors&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Client libraries and APIs&lt;/h2&gt; 
&lt;p&gt;Weaviate provides client libraries for several programming languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/typescript"&gt;JavaScript/TypeScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/java"&gt;Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;C# (🚧 Coming soon 🚧)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are also additional &lt;a href="https://docs.weaviate.io/weaviate/client-libraries/community"&gt;community-maintained libraries&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Weaviate exposes &lt;a href="https://docs.weaviate.io/weaviate/api/rest"&gt;REST API&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/weaviate/api/grpc"&gt;gRPC API&lt;/a&gt;, and &lt;a href="https://docs.weaviate.io/weaviate/api/graphql"&gt;GraphQL API&lt;/a&gt; to communicate with the database server.&lt;/p&gt; 
&lt;h2&gt;Weaviate features&lt;/h2&gt; 
&lt;p&gt;These features enable you to build AI-powered applications:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;⚡ Fast Search Performance&lt;/strong&gt;: Perform complex semantic &lt;a href="https://docs.weaviate.io/weaviate/search/similarity"&gt;searches&lt;/a&gt; over billions of vectors in milliseconds. Weaviate's architecture is built in Go for speed and reliability, ensuring your AI applications are highly responsive even under heavy load. See our &lt;a href="https://docs.weaviate.io/weaviate/benchmarks/ann"&gt;ANN benchmarks&lt;/a&gt; for more info.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔌 Flexible Vectorization&lt;/strong&gt;: Seamlessly vectorize data at import time with &lt;a href="https://docs.weaviate.io/weaviate/model-providers"&gt;integrated vectorizers&lt;/a&gt; from OpenAI, Cohere, HuggingFace, Google, and more. Or you can import &lt;a href="https://docs.weaviate.io/weaviate/starter-guides/custom-vectors"&gt;your own vector embeddings&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔍 Advanced Hybrid &amp;amp; Image Search&lt;/strong&gt;: Combine the power of semantic search with traditional &lt;a href="https://docs.weaviate.io/weaviate/search/bm25"&gt;keyword (BM25) search&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/weaviate/search/image"&gt;image search&lt;/a&gt; and &lt;a href="https://docs.weaviate.io/weaviate/search/filters"&gt;advanced filtering&lt;/a&gt; to get the best results with a single API call.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🤖 Integrated RAG &amp;amp; Reranking&lt;/strong&gt;: Go beyond simple retrieval with built-in &lt;a href="https://docs.weaviate.io/weaviate/search/generative"&gt;generative search (RAG)&lt;/a&gt; and &lt;a href="https://docs.weaviate.io/weaviate/search/rerank"&gt;reranking&lt;/a&gt; capabilities. Power sophisticated Q&amp;amp;A systems, chatbots, and summarizers directly from your database without additional tooling.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;📈 Production-Ready &amp;amp; Scalable&lt;/strong&gt;: Weaviate is built for mission-critical applications. Go from rapid prototyping to production at scale with native support for &lt;a href="https://docs.weaviate.io/deploy/configuration/horizontal-scaling"&gt;horizontal scaling&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/weaviate/manage-collections/multi-tenancy"&gt;multi-tenancy&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/deploy/configuration/replication"&gt;replication&lt;/a&gt;, and fine-grained &lt;a href="https://docs.weaviate.io/weaviate/configuration/rbac"&gt;role-based access control (RBAC)&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;💰 Cost-Efficient Operations&lt;/strong&gt;: Radically lower resource consumption and operational costs with built-in &lt;a href="https://docs.weaviate.io/weaviate/configuration/compression"&gt;vector compression&lt;/a&gt;. Vector quantization and multi-vector encoding reduce memory usage with minimal impact on search performance.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a complete list of all functionalities, visit the &lt;a href="https://docs.weaviate.io"&gt;official Weaviate documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Useful resources&lt;/h2&gt; 
&lt;h3&gt;Demo projects &amp;amp; recipes&lt;/h3&gt; 
&lt;p&gt;These demos are working applications that highlight some of Weaviate's capabilities. Their source code is available on GitHub.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://elysia.weaviate.io"&gt;Elysia&lt;/a&gt; (&lt;a href="https://github.com/weaviate/elysia"&gt;GitHub&lt;/a&gt;): Elysia is a decision tree based agentic system which intelligently decides what tools to use, what results have been obtained, whether it should continue the process or whether its goal has been completed.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://verba.weaviate.io"&gt;Verba&lt;/a&gt; (&lt;a href="https://github.com/weaviate/verba"&gt;GitHub&lt;/a&gt;): A community-driven open-source application designed to offer an end-to-end, streamlined, and user-friendly interface for Retrieval-Augmented Generation (RAG) out of the box.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://healthsearch.weaviate.io"&gt;Healthsearch&lt;/a&gt; (&lt;a href="https://github.com/weaviate/healthsearch-demo"&gt;GitHub&lt;/a&gt;): An open-source project aimed at showcasing the potential of leveraging user-written reviews and queries to retrieve supplement products based on specific health effects.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://awesome-moviate.weaviate.io/"&gt;Awesome-Moviate&lt;/a&gt; (&lt;a href="https://github.com/weaviate-tutorials/awesome-moviate"&gt;GitHub&lt;/a&gt;): A movie search and recommendation engine that allows keyword-based (BM25), semantic, and hybrid searches.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We also maintain extensive repositories of &lt;strong&gt;Jupyter Notebooks&lt;/strong&gt; and &lt;strong&gt;TypeScript code snippets&lt;/strong&gt; that cover how to use Weaviate features and integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/weaviate/recipes/"&gt;Weaviate Python Recipes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/weaviate/recipes-ts/"&gt;Weaviate TypeScript Recipes&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Blog posts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/what-is-a-vector-database"&gt;What is a Vector Database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/vector-search-explained"&gt;What is Vector Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/hybrid-search-explained"&gt;What is Hybrid Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/how-to-choose-an-embedding-model"&gt;How to Choose an Embedding Model&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/introduction-to-rag"&gt;What is RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/rag-evaluation"&gt;RAG Evaluation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/advanced-rag"&gt;Advanced RAG Techniques&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/multimodal-rag"&gt;What is Multimodal RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/what-is-agentic-rag"&gt;What is Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/graph-rag"&gt;What is Graph RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/late-interaction-overview"&gt;Overview of Late Interaction Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrations&lt;/h3&gt; 
&lt;p&gt;Weaviate integrates with many external services:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Integrations&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/cloud-hyperscalers"&gt;Cloud Hyperscalers&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Large-scale computing and storage&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/cloud-hyperscalers/aws"&gt;AWS&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/cloud-hyperscalers/google"&gt;Google&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure"&gt;Compute Infrastructure&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Run and scale containerized applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure/modal"&gt;Modal&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure/replicate"&gt;Replicate&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure/replicated"&gt;Replicated&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/data-platforms"&gt;Data Platforms&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Data ingestion and web scraping&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/data-platforms/airbyte"&gt;Airbyte&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/aryn"&gt;Aryn&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/boomi"&gt;Boomi&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/box"&gt;Box&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/confluent"&gt;Confluent&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/astronomer"&gt;Astronomer&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/context-data"&gt;Context Data&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/databricks"&gt;Databricks&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/firecrawl"&gt;Firecrawl&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/ibm"&gt;IBM&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/unstructured"&gt;Unstructured&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks"&gt;LLM and Agent Frameworks&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Build agents and generative AI applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/agno"&gt;Agno&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/composio"&gt;Composio&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/crewai"&gt;CrewAI&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/dspy"&gt;DSPy&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/dynamiq"&gt;Dynamiq&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/haystack"&gt;Haystack&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/langchain"&gt;LangChain&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/llamaindex"&gt;LlamaIndex&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/n8n"&gt;N8n&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/semantic-kernel"&gt;Semantic Kernel&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/operations"&gt;Operations&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Tools for monitoring and analyzing generative AI workflows&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/operations/aimon"&gt;AIMon&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/arize"&gt;Arize&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/cleanlab"&gt;Cleanlab&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/comet"&gt;Comet&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/deepeval"&gt;DeepEval&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/langtrace"&gt;Langtrace&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/langwatch"&gt;LangWatch&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/nomic"&gt;Nomic&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/patronus"&gt;Patronus AI&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/ragas"&gt;Ragas&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/trulens"&gt;TruLens&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/wandb"&gt;Weights &amp;amp; Biases&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and appreciate contributions! Please see our &lt;a href="https://docs.weaviate.io/contributor-guide"&gt;Contributor guide&lt;/a&gt; for the development setup, code style guidelines, testing requirements and the pull request process.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://weaviate.io/slack"&gt;Slack community&lt;/a&gt; or &lt;a href="https://forum.weaviate.io/"&gt;Community forum&lt;/a&gt; to discuss ideas and get help.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;BSD 3-Clause License. See &lt;a href="https://raw.githubusercontent.com/weaviate/weaviate/main/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>open-telemetry/opentelemetry-collector</title>
      <link>https://github.com/open-telemetry/opentelemetry-collector</link>
      <description>&lt;p&gt;OpenTelemetry Collector&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://opentelemetry.io/docs/collector/getting-started/"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md"&gt;Getting Involved&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;Getting In Touch&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain"&gt; &lt;img alt="Build Status" src="https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector"&gt; &lt;img alt="Go Report Card" src="https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/"&gt; &lt;img alt="Codecov Status" src="https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/releases"&gt; &lt;img alt="GitHub release (latest by date including pre-releases)" src="https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://www.bestpractices.dev/projects/8404"&gt;&lt;img src="https://www.bestpractices.dev/projects/8404/badge" /&gt; &lt;/a&gt; &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;amp;can=1&amp;amp;q=proj:opentelemetry"&gt; &lt;img alt="Fuzzing Status" src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/vision.md"&gt;Vision&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://opentelemetry.io/docs/collector/configuration/"&gt;Configuration&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector"&gt;Monitoring&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/security-best-practices.md"&gt;Security&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://pkg.go.dev/go.opentelemetry.io/collector"&gt;Package&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;&lt;img src="https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png" alt="OpenTelemetry Icon" width="45" height="" /&gt; OpenTelemetry Collector&lt;/h1&gt; 
&lt;p&gt;The OpenTelemetry Collector offers a vendor-agnostic implementation on how to receive, process and export telemetry data. In addition, it removes the need to run, operate and maintain multiple agents/collectors in order to support open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to multiple open-source or commercial back-ends.&lt;/p&gt; 
&lt;p&gt;Objectives:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.&lt;/li&gt; 
 &lt;li&gt;Performant: Highly stable and performant under varying loads and configurations.&lt;/li&gt; 
 &lt;li&gt;Observable: An exemplar of an observable service.&lt;/li&gt; 
 &lt;li&gt;Extensible: Customizable without touching the core code.&lt;/li&gt; 
 &lt;li&gt;Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The OpenTelemetry Collector SIG is present at the &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;#otel-collector&lt;/a&gt; channel on the CNCF Slack and &lt;a href="https://github.com/open-telemetry/community#implementation-sigs"&gt;meets once a week&lt;/a&gt; via video calls. Everyone is invited to join those calls, which typically serves the following purposes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;meet the humans behind the project&lt;/li&gt; 
 &lt;li&gt;get an opinion about specific proposals&lt;/li&gt; 
 &lt;li&gt;look for a sponsor for a proposed component after trying already via GitHub and Slack&lt;/li&gt; 
 &lt;li&gt;get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We rotate our video calls between three time slots, in order to allow everyone to join at least once every three meetings. The rotation order is as follows:&lt;/p&gt; 
&lt;p&gt;Tuesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=1700"&gt;17:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Wednesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=0900"&gt;09:00 PT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=0500"&gt;05:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points. Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to identify who would be the other contributors interested on that topic and in which timezones they are.&lt;/p&gt; 
&lt;p&gt;Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous calls and don't want them to feel excluded.&lt;/p&gt; 
&lt;h2&gt;Supported OTLP version&lt;/h2&gt; 
&lt;p&gt;This code base is currently built against using OTLP protocol v1.5.0, considered Stable. &lt;a href="https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition"&gt;See the OpenTelemetry Protocol Stability definition here.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stability levels&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/component-stability.md"&gt;Stability Levels and versioning&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Compatibility&lt;/h2&gt; 
&lt;p&gt;When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as &lt;a href="https://go.dev/doc/devel/release#policy"&gt;defined by the Go team&lt;/a&gt;. Removing support for an unsupported Go version is not considered a breaking change.&lt;/p&gt; 
&lt;p&gt;Support for Go versions on the OpenTelemetry Collector is updated as follows:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will add build and tests steps for the new Go minor version.&lt;/li&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will remove support for Go version &lt;code&gt;N-2&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.&lt;/p&gt; 
&lt;h2&gt;Verifying the images signatures&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To verify a signed artifact or blob, first &lt;a href="https://docs.sigstore.dev/cosign/system_config/installation/"&gt;install Cosign&lt;/a&gt;, then follow the instructions below.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We are signing the images &lt;code&gt;otel/opentelemetry-collector&lt;/code&gt; and &lt;code&gt;otel/opentelemetry-collector-contrib&lt;/code&gt; using &lt;a href="https://github.com/sigstore/cosign"&gt;sigstore cosign&lt;/a&gt; tool and to verify the signatures you can run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&amp;lt;RELEASE_TAG&amp;gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;RELEASE_TAG&amp;gt;&lt;/code&gt;: is the release that you want to validate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;&lt;/code&gt;: is the image that you want to check&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=","Payload":{"body":"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","integratedTime":1712809120,"logIndex":84797936,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}},{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=","Payload":{"body":"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","integratedTime":1712809122,"logIndex":84797940,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] We started signing the images with release &lt;code&gt;v0.95.0&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Here is a list of community roles with current and previous members:&lt;/p&gt; 
&lt;h3&gt;Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/codeboten"&gt;Alex Boten&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bogdandrutu"&gt;Bogdan Drutu&lt;/a&gt;, Snowflake&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmitryax"&gt;Dmitrii Anoshin&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mx-psi"&gt;Pablo Baeyens&lt;/a&gt;, DataDog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the maintainer role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#maintainer"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/axw"&gt;Andrew Wilkins&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atoulme"&gt;Antoine Toulme&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmathieu"&gt;Damien Mathieu&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evan-bradley"&gt;Evan Bradley&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jade-guiton-dd"&gt;Jade Guiton&lt;/a&gt;, Datadog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jmacd"&gt;Joshua MacDonald&lt;/a&gt;, Microsoft&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TylerHelmuth"&gt;Tyler Helmuth&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/songy23"&gt;Yang Song&lt;/a&gt;, Datadog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the approver role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#approver"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In addition to what is described at the organization-level, the SIG Collector requires all core approvers to take part in rotating the role of the &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/release.md#release-manager"&gt;release manager&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrzej-stencel"&gt;Andrzej Stencel&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sincejune"&gt;Chao Weng&lt;/a&gt;, AppDynamics&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/VihasMakwana"&gt;Vihas Makwana&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;Actively seeking contributors to triage issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the triager role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#triager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pjanotti"&gt;Paulo Janotti&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tigrannajaryan"&gt;Tigran Najaryan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aneurysm9"&gt;Anthony Mirabella&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djaglowski"&gt;Daniel Jaglowski&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/james-bebbington"&gt;James Bebbington&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jrcamp"&gt;Jay Camp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jpkrohling"&gt;Juraci Paixão Kröhling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nilebox"&gt;Nail Islamov&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/owais"&gt;Owais Lone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rghetia"&gt;Rahul Patel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sjkaris"&gt;Steven Karis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alolita"&gt;Alolita Sharma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrewhsu"&gt;Andrew Hsu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/punya"&gt;Punya Biswal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flands"&gt;Steve Flanders&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Thanks to all of our contributors!&lt;/h3&gt; 
&lt;a href="https://github.com/open-telemetry/opentelemetry-collector/graphs/contributors"&gt; &lt;img alt="Repo contributors" src="https://contrib.rocks/image?repo=open-telemetry/opentelemetry-collector" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-seaweedfs-s3-on-aws"&gt;Quick Start SeaweedFS S3 on AWS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -mserver="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h2&gt;Quick Start SeaweedFS S3 on AWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setup fast production-ready &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc"&gt;SeaweedFS S3 on AWS with cloudformation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook’s Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook’s Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -mserver="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -mserver="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2023-10-16[102354]-l70a.csv.zst"                                                                                                                                                                                               
Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 4m59s.
 * Throughput: 6.19 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 5m0s.
 * Throughput: 279.85 MiB/s, 27.99 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 5m0s.
 * Throughput: 89.86 MiB/s, 8.99 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 5m0s.
 * Throughput: 18.63 obj/s

Cluster Total: 369.74 MiB/s, 61.79 obj/s, 0 errors over 5m0s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see segmented request statistics, use the --analyze.v parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;warp analyze --analyze.v warp-mixed-2023-10-16[102354]-l70a.csv.zst
18642 operations loaded... Done!
Mixed operations.
----------------------------------------
Operation: DELETE - total: 1854, 10.0%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 6.19 obj/s

Requests considered: 1855:
 * Avg: 104ms, 50%: 30ms, 90%: 207ms, 99%: 1.355s, Fastest: 1ms, Slowest: 4.613s, StdDev: 320ms

----------------------------------------
Operation: GET - total: 8388, 45.3%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.12 +0500 +05
 * Throughput: 279.77 MiB/s, 27.98 obj/s

Requests considered: 8389:
 * Avg: 221ms, 50%: 106ms, 90%: 492ms, 99%: 1.739s, Fastest: 8ms, Slowest: 8.633s, StdDev: 383ms
 * TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 171ms, 99th: 669ms, Worst: 4.783s StdDev: 163ms
 * First Access: Avg: 240ms, 50%: 105ms, 90%: 511ms, 99%: 2.08s, Fastest: 12ms, Slowest: 8.633s, StdDev: 480ms
 * First Access TTFB: Avg: 88ms, Best: 2ms, 25th: 24ms, Median: 38ms, 75th: 64ms, 90th: 179ms, 99th: 919ms, Worst: 4.783s StdDev: 199ms
 * Last Access: Avg: 219ms, 50%: 106ms, 90%: 463ms, 99%: 1.782s, Fastest: 9ms, Slowest: 8.633s, StdDev: 416ms
 * Last Access TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 161ms, 99th: 657ms, Worst: 4.783s StdDev: 176ms

----------------------------------------
Operation: PUT - total: 2688, 14.5%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 89.83 MiB/s, 8.98 obj/s

Requests considered: 2689:
 * Avg: 1.165s, 50%: 878ms, 90%: 2.015s, 99%: 5.74s, Fastest: 99ms, Slowest: 8.264s, StdDev: 968ms

----------------------------------------
Operation: STAT - total: 5586, 30.2%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.113 +0500 +05
 * Throughput: 18.63 obj/s

Requests considered: 5587:
 * Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 80ms, Fastest: 0s, Slowest: 245ms, StdDev: 17ms
 * First Access: Avg: 14ms, 50%: 10ms, 90%: 33ms, 99%: 69ms, Fastest: 0s, Slowest: 203ms, StdDev: 16ms
 * Last Access: Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 74ms, Fastest: 0s, Slowest: 203ms, StdDev: 17ms

Cluster Total: 369.64 MiB/s, 61.77 obj/s, 0 errors over 5m0s.
Total Errors:0.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mudler/LocalAI</title>
      <link>https://github.com/mudler/LocalAI</link>
      <description>&lt;p&gt;🤖 The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;img width="300" src="https://raw.githubusercontent.com/mudler/LocalAI/master/core/http/static/logo.png" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/go-skynet/LocalAI/fork" target="blank"&gt; &lt;img src="https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/stargazers" target="blank"&gt; &lt;img src="https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/pulls" target="blank"&gt; &lt;img src="https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI pull-requests" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/releases"&gt; &lt;img src="https://img.shields.io/github/release/go-skynet/LocalAI?&amp;amp;label=Latest&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://hub.docker.com/r/localai/localai" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker" alt="LocalAI Docker hub" /&gt; &lt;/a&gt; &lt;a href="https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;amp;tag=latest" target="blank"&gt; &lt;img src="https://img.shields.io/badge/quay.io-images-important.svg?" alt="LocalAI Quay.io" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://twitter.com/LocalAI_API" target="blank"&gt; &lt;img src="https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=white&amp;amp;label=LocalAI_API" alt="Follow LocalAI_API" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy" target="blank"&gt; &lt;img src="https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;amp;theme=default-inverted" alt="Join LocalAI Discord Community" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/5539" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/5539" alt="mudler%2FLocalAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;💡&lt;/span&gt; Get help - &lt;a href="https://localai.io/faq/"&gt;❓FAQ&lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/discussions"&gt;💭Discussions&lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy"&gt;&lt;span&gt;💬&lt;/span&gt; Discord&lt;/a&gt; &lt;a href="https://localai.io/"&gt;&lt;span&gt;📖&lt;/span&gt; Documentation website&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://localai.io/basics/getting_started/"&gt;💻 Quickstart&lt;/a&gt; &lt;a href="https://models.localai.io/"&gt;🖼️ Models&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;🚀 Roadmap&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;🛫 Examples&lt;/a&gt; Try on &lt;a href="https://t.me/localaiofficial_bot"&gt;&lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;amp;logo=telegram&amp;amp;logoColor=white" alt="Telegram" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg?sanitize=true" alt="tests" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Build and Release" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg?sanitize=true" alt="build container images" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg?sanitize=true" alt="Bump dependencies" /&gt;&lt;/a&gt;&lt;a href="https://artifacthub.io/packages/search?repo=localai"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;LocalAI&lt;/strong&gt; is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by &lt;a href="https://github.com/mudler"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📚🆕 Local Stack Family&lt;/h2&gt; 
&lt;p&gt;🆕 LocalAI is now part of a comprehensive suite of AI tools designed to work together:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="300" alt="LocalAGI Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="300" alt="LocalRecall Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Talk Interface&lt;/th&gt; 
   &lt;th&gt;Generate Audio&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Models Overview&lt;/th&gt; 
   &lt;th&gt;Generate Images&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_gallery.png" alt="Screenshot 2025-03-31 at 12-01-20 LocalAI - Models" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_image.png" alt="Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chat Interface&lt;/th&gt; 
   &lt;th&gt;Home&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_chat.png" alt="Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_home.png" alt="Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Login&lt;/th&gt; 
   &lt;th&gt;Swarm&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_login.png" alt="Screenshot 2025-03-31 at 12-09-59 " /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_p2p.png" alt="Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;💻 Quickstart&lt;/h2&gt; 
&lt;p&gt;Run the installer script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
curl https://localai.io/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more installation options, see &lt;a href="https://localai.io/docs/advanced/installer/"&gt;Installer Options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS Download:&lt;/h3&gt; 
&lt;a href="https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg"&gt; &lt;img src="https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Download LocalAI for macOS" /&gt; &lt;/a&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: the DMGs are not signed by Apple as quarantined. See &lt;a href="https://github.com/mudler/LocalAI/issues/6268"&gt;https://github.com/mudler/LocalAI/issues/6268&lt;/a&gt; for a workaround, fix is tracked here: &lt;a href="https://github.com/mudler/LocalAI/issues/6244"&gt;https://github.com/mudler/LocalAI/issues/6244&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Or run with docker:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;💡 Docker Run vs Docker Start&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker run&lt;/code&gt; creates and starts a new container. If a container with the same name already exists, this command will fail.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;docker start&lt;/code&gt; starts an existing container that was previously created with &lt;code&gt;docker run&lt;/code&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you've already run LocalAI before and want to start it again, use: &lt;code&gt;docker start -i local-ai&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;CPU only image:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;NVIDIA GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AMD GPU Images (ROCm):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Intel GPU Images (oneAPI):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Vulkan GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AIO Images (pre-downloaded models):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information about the AIO images and pre-downloaded models, see &lt;a href="https://localai.io/basics/container/"&gt;Container Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To load models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⚡ &lt;strong&gt;Automatic Backend Detection&lt;/strong&gt;: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see &lt;a href="https://localai.io/features/gpu-acceleration/#automatic-backend-detection"&gt;GPU Acceleration&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more information, see &lt;a href="https://localai.io/basics/getting_started/index.html"&gt;💻 Getting started&lt;/a&gt;, if you are interested in our roadmap items and future enhancements, you can see the &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;Issues labeled as Roadmap here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📰 Latest project news&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;October 2025: 🔌 &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; support added for agentic capabilities with external tools&lt;/li&gt; 
 &lt;li&gt;September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.&lt;/li&gt; 
 &lt;li&gt;August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with &lt;code&gt;development&lt;/code&gt; suffix in the gallery ): &lt;a href="https://github.com/mudler/LocalAI/pull/6049"&gt;https://github.com/mudler/LocalAI/pull/6049&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6119"&gt;https://github.com/mudler/LocalAI/pull/6119&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6121"&gt;https://github.com/mudler/LocalAI/pull/6121&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6060"&gt;https://github.com/mudler/LocalAI/pull/6060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July/August 2025: 🔍 &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt; added to the API featuring &lt;a href="https://github.com/roboflow/rf-detr"&gt;rf-detr&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v3.2.0"&gt;Read the release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;Backend management&lt;/a&gt; has been added. Attention: extras images are going to be deprecated from the next release! Read &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;the backend management PR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5466"&gt;Audio input&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/5396"&gt;Reranking&lt;/a&gt; in llama.cpp backend, &lt;a href="https://github.com/mudler/LocalAI/pull/5392"&gt;Realtime API&lt;/a&gt;, Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).&lt;/li&gt; 
 &lt;li&gt;May 2025: Important: image name changes &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v2.29.0"&gt;See release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apr 2025: Rebrand, WebUI enhancements&lt;/li&gt; 
 &lt;li&gt;Apr 2025: &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt; join the LocalAI family stack.&lt;/li&gt; 
 &lt;li&gt;Apr 2025: WebUI overhaul, AIO images updates&lt;/li&gt; 
 &lt;li&gt;Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images&lt;/li&gt; 
 &lt;li&gt;Jan 2025: LocalAI model release: &lt;a href="https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3"&gt;https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3&lt;/a&gt;, SANA support in diffusers: &lt;a href="https://github.com/mudler/LocalAI/pull/4603"&gt;https://github.com/mudler/LocalAI/pull/4603&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dec 2024: stablediffusion.cpp backend (ggml) added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4289"&gt;https://github.com/mudler/LocalAI/pull/4289&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Bark.cpp backend added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4287"&gt;https://github.com/mudler/LocalAI/pull/4287&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Voice activity detection models (&lt;strong&gt;VAD&lt;/strong&gt;) added to the API: &lt;a href="https://github.com/mudler/LocalAI/pull/4204"&gt;https://github.com/mudler/LocalAI/pull/4204&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oct 2024: examples moved to &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;LocalAI-examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Aug 2024: 🆕 FLUX-1, &lt;a href="https://explorer.localai.io"&gt;P2P Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2024: 🔥🔥 🆕 P2P Dashboard, LocalAI Federated mode and AI Swarms: &lt;a href="https://github.com/mudler/LocalAI/pull/2723"&gt;https://github.com/mudler/LocalAI/pull/2723&lt;/a&gt;. P2P Global community pools: &lt;a href="https://github.com/mudler/LocalAI/issues/3113"&gt;https://github.com/mudler/LocalAI/issues/3113&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: 🔥🔥 Decentralized P2P llama.cpp: &lt;a href="https://github.com/mudler/LocalAI/pull/2343"&gt;https://github.com/mudler/LocalAI/pull/2343&lt;/a&gt; (peer2peer llama.cpp!) 👉 Docs &lt;a href="https://localai.io/features/distribute/"&gt;https://localai.io/features/distribute/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: 🔥🔥 Distributed inferencing: &lt;a href="https://github.com/mudler/LocalAI/pull/2324"&gt;https://github.com/mudler/LocalAI/pull/2324&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 2024: Reranker API: &lt;a href="https://github.com/mudler/LocalAI/pull/2121"&gt;https://github.com/mudler/LocalAI/pull/2121&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Roadmap items: &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;List of issues&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🚀 &lt;a href="https://localai.io/features/"&gt;Features&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🧩 &lt;a href="https://localai.io/backends/"&gt;Backend Gallery&lt;/a&gt;: Install/remove backends on the fly, powered by OCI images — fully customizable and API-driven.&lt;/li&gt; 
 &lt;li&gt;📖 &lt;a href="https://localai.io/features/text-generation/"&gt;Text generation with GPTs&lt;/a&gt; (&lt;code&gt;llama.cpp&lt;/code&gt;, &lt;code&gt;transformers&lt;/code&gt;, &lt;code&gt;vllm&lt;/code&gt; ... &lt;a href="https://localai.io/model-compatibility/index.html#model-compatibility-table"&gt;&lt;span&gt;📖&lt;/span&gt; and more&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;🗣 &lt;a href="https://localai.io/features/text-to-audio/"&gt;Text to Audio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🔈 &lt;a href="https://localai.io/features/audio-to-text/"&gt;Audio to Text&lt;/a&gt; (Audio transcription with &lt;code&gt;whisper.cpp&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;🎨 &lt;a href="https://localai.io/features/image-generation"&gt;Image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🔥 &lt;a href="https://localai.io/features/openai-functions/"&gt;OpenAI-alike tools API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🧠 &lt;a href="https://localai.io/features/embeddings/"&gt;Embeddings generation for vector databases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;✍️ &lt;a href="https://localai.io/features/constrained_grammars/"&gt;Constrained grammars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🖼️ &lt;a href="https://localai.io/models/"&gt;Download Models directly from Huggingface &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🥽 &lt;a href="https://localai.io/features/gpt-vision/"&gt;Vision API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🔍 &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📈 &lt;a href="https://localai.io/features/reranker/"&gt;Reranker API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🆕🖧 &lt;a href="https://localai.io/features/distribute/"&gt;P2P Inferencing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🆕🔌 &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; - Agentic capabilities with external tools and &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI's Agentic capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🔊 Voice activity detection (Silero-VAD support)&lt;/li&gt; 
 &lt;li&gt;🌍 Integrated WebUI!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🧩 Supported Backends &amp;amp; Acceleration&lt;/h2&gt; 
&lt;p&gt;LocalAI supports a comprehensive range of AI backends with multiple acceleration options:&lt;/p&gt; 
&lt;h3&gt;Text Generation &amp;amp; Language Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM inference in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel SYCL, Vulkan, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast LLM inference with PagedAttention&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;transformers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace transformers framework&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;exllama2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GPTQ inference library&lt;/td&gt; 
   &lt;td&gt;CUDA 12&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon LLM inference&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX-VLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon Vision-Language Models&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Audio &amp;amp; Speech Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;whisper.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Whisper in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;faster-whisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast Whisper with CTranslate2&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-audio generation&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark-cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;C++ implementation of Bark&lt;/td&gt; 
   &lt;td&gt;CUDA, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;coqui&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Advanced TTS with 1100+ languages&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kokoro&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight TTS model&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;chatterbox&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Production-grade TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;piper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast neural TTS system&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kitten-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Kitten TTS models&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;silero-vad&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;neutts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-speech with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Image &amp;amp; Video Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;stablediffusion.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Stable Diffusion in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;diffusers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace diffusion models&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Specialized AI Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rfdetr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time object detection&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rerankers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document reranking API&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;local-store&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Vector database&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;huggingface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace API integration&lt;/td&gt; 
   &lt;td&gt;API-based&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Acceleration Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Acceleration Type&lt;/th&gt; 
   &lt;th&gt;Supported Backends&lt;/th&gt; 
   &lt;th&gt;Hardware Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 11&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rerankers, bark, chatterbox&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 12&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AMD ROCm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts&lt;/td&gt; 
   &lt;td&gt;AMD Graphics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Intel oneAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark&lt;/td&gt; 
   &lt;td&gt;Intel Arc, Intel iGPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apple Metal&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp&lt;/td&gt; 
   &lt;td&gt;Apple M1/M2/M3+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vulkan&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion&lt;/td&gt; 
   &lt;td&gt;Cross-platform GPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;CPU Optimized&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All backends&lt;/td&gt; 
   &lt;td&gt;AVX/AVX2/AVX512, quantization support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;🔗 Community and integrations&lt;/h3&gt; 
&lt;p&gt;Build and deploy custom containers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sozercan/aikit"&gt;https://github.com/sozercan/aikit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;WebUIs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jirubizu/localai-admin"&gt;https://github.com/Jirubizu/localai-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/LocalAI-frontend"&gt;https://github.com/go-skynet/LocalAI-frontend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) &lt;a href="https://github.com/reid41/QA-Pilot"&gt;https://github.com/reid41/QA-Pilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Agentic Libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/cogito"&gt;https://github.com/mudler/cogito&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCPs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/MCPs"&gt;https://github.com/mudler/MCPs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model galleries&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/model-gallery"&gt;https://github.com/go-skynet/model-gallery&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Voice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richiejp/VoxInput"&gt;https://github.com/richiejp/VoxInput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm chart &lt;a href="https://github.com/go-skynet/helm-charts"&gt;https://github.com/go-skynet/helm-charts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VSCode extension &lt;a href="https://github.com/badgooooor/localai-vscode-plugin"&gt;https://github.com/badgooooor/localai-vscode-plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Langchain: &lt;a href="https://python.langchain.com/docs/integrations/providers/localai/"&gt;https://python.langchain.com/docs/integrations/providers/localai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Terminal utility &lt;a href="https://github.com/djcopley/ShellOracle"&gt;https://github.com/djcopley/ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local Smart assistant &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Home Assistant &lt;a href="https://github.com/sammcj/homeassistant-localai"&gt;https://github.com/sammcj/homeassistant-localai&lt;/a&gt; / &lt;a href="https://github.com/drndos/hass-openai-custom-conversation"&gt;https://github.com/drndos/hass-openai-custom-conversation&lt;/a&gt; / &lt;a href="https://github.com/valentinfrlch/ha-gpt4vision"&gt;https://github.com/valentinfrlch/ha-gpt4vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/discord"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/slack"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) &lt;a href="https://github.com/reid41/shell-pilot"&gt;https://github.com/reid41/shell-pilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram bot &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot"&gt;https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Another Telegram Bot &lt;a href="https://github.com/JackBekket/Hellper"&gt;https://github.com/JackBekket/Hellper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Auto-documentation &lt;a href="https://github.com/JackBekket/Reflexia"&gt;https://github.com/JackBekket/Reflexia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github bot which answer on issues, with code and documentation as context &lt;a href="https://github.com/JackBekket/GitHelper"&gt;https://github.com/JackBekket/GitHelper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github Actions: &lt;a href="https://github.com/marketplace/actions/start-localai"&gt;https://github.com/marketplace/actions/start-localai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Examples: &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/"&gt;https://github.com/mudler/LocalAI/tree/master/examples/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔗 Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/advanced/fine-tuning/"&gt;LLM finetuning guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/build/index.html"&gt;How to build locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes"&gt;How to install in Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/integrations/"&gt;Projects integrating LocalAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://io.midori-ai.xyz/howtos/"&gt;How tos section&lt;/a&gt; (curated by our community)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;📖&lt;/span&gt; 🎥 &lt;a href="https://localai.io/basics/news/#media-blogs-social"&gt;Media, Blogs, Social&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.suse.com/c/running-ai-locally/"&gt;Run Visual studio code with LocalAI (SUSE)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🆕 &lt;a href="https://mudler.pm/posts/local-ai-jetson-nano-devkit/"&gt;Run LocalAI on Jetson Nano Devkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/"&gt;Run LocalAI on AWS EKS with Pulumi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance"&gt;Run LocalAI on AWS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/smart-slackbot-for-teams/"&gt;Create a slackbot for teams and OSS projects that answer to documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PKrDNuJ_dfE"&gt;LocalAI meets k8sgpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/localai-question-answering/"&gt;Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65"&gt;Tutorial to use k8sgpt with LocalAI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/go-skynet/LocalAI}},
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;❤️ Sponsors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Do you find LocalAI useful?&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Support the project by becoming &lt;a href="https://github.com/sponsors/mudler"&gt;a backer or sponsor&lt;/a&gt;. Your logo will show up here with a link to your website.&lt;/p&gt; 
&lt;p&gt;A huge thank you to our generous sponsors who support this project covering CI expenses, and our &lt;a href="https://github.com/sponsors/mudler"&gt;Sponsor list&lt;/a&gt;:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.spectrocloud.com/" target="blank"&gt; &lt;img height="200" src="https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962" /&gt; &lt;/a&gt; &lt;a href="https://www.premai.io/" target="blank"&gt; &lt;img height="200" src="https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6" /&gt; &lt;br /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;🌟 Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#go-skynet/LocalAI&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=go-skynet/LocalAI&amp;amp;type=Date" alt="LocalAI Star history Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📖 License&lt;/h2&gt; 
&lt;p&gt;LocalAI is a community-driven project created by &lt;a href="https://github.com/mudler/"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;MIT - Author Ettore Di Giacinto &lt;a href="mailto:mudler@localai.io"&gt;mudler@localai.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🙇 Acknowledgements&lt;/h2&gt; 
&lt;p&gt;LocalAI couldn't have been built without the help of great software already available from the community. Thank you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cornelk/llama-go"&gt;https://github.com/cornelk/llama-go&lt;/a&gt; for the initial ideas&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/antimatter15/alpaca.cpp"&gt;https://github.com/antimatter15/alpaca.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EdVince/Stable-Diffusion-NCNN"&gt;https://github.com/EdVince/Stable-Diffusion-NCNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;https://github.com/ggerganov/whisper.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rhasspy/piper"&gt;https://github.com/rhasspy/piper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🤗 Contributors&lt;/h2&gt; 
&lt;p&gt;This is a community project, a special thanks to our contributors! 🤗 &lt;a href="https://github.com/go-skynet/LocalAI/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=go-skynet/LocalAI" /&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rclone/rclone</title>
      <link>https://github.com/rclone/rclone</link>
      <description>&lt;p&gt;"rsync for cloud storage" - Google Drive, S3, Dropbox, Backblaze B2, One Drive, Swift, Hubic, Wasabi, Google Cloud Storage, Azure Blob, Azure Files, Yandex Files&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://rclone.org/#gh-light-mode-only"&gt;&lt;img src="https://rclone.org/img/logo_on_light__horizontal_color.svg?sanitize=true" width="50%" alt="rclone logo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- markdownlint-disable-next-line no-inline-html --&gt; 
&lt;p&gt;&lt;a href="https://rclone.org/#gh-dark-mode-only"&gt;&lt;img src="https://rclone.org/img/logo_on_dark__horizontal_color.svg?sanitize=true" width="50%" alt="rclone logo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://rclone.org"&gt;Website&lt;/a&gt; | &lt;a href="https://rclone.org/docs/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://rclone.org/downloads/"&gt;Download&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/rclone/rclone/master/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; | &lt;a href="https://rclone.org/changelog/"&gt;Changelog&lt;/a&gt; | &lt;a href="https://rclone.org/install/"&gt;Installation&lt;/a&gt; | &lt;a href="https://forum.rclone.org/"&gt;Forum&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rclone/rclone/actions?query=workflow%3Abuild"&gt;&lt;img src="https://github.com/rclone/rclone/workflows/build/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/rclone/rclone"&gt;&lt;img src="https://goreportcard.com/badge/github.com/rclone/rclone" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/rclone/rclone"&gt;&lt;img src="https://godoc.org/github.com/rclone/rclone?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/rclone/rclone"&gt;&lt;img src="https://img.shields.io/docker/pulls/rclone/rclone" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Rclone&lt;/h1&gt; 
&lt;p&gt;Rclone &lt;em&gt;("rsync for cloud storage")&lt;/em&gt; is a command-line program to sync files and directories to and from different cloud storage providers.&lt;/p&gt; 
&lt;h2&gt;Storage providers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;1Fichier &lt;a href="https://rclone.org/fichier/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Akamai Netstorage &lt;a href="https://rclone.org/netstorage/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Alibaba Cloud (Aliyun) Object Storage System (OSS) &lt;a href="https://rclone.org/s3/#alibaba-oss"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Amazon S3 &lt;a href="https://rclone.org/s3/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ArvanCloud Object Storage (AOS) &lt;a href="https://rclone.org/s3/#arvan-cloud-object-storage-aos"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Backblaze B2 &lt;a href="https://rclone.org/b2/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Box &lt;a href="https://rclone.org/box/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ceph &lt;a href="https://rclone.org/s3/#ceph"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;China Mobile Ecloud Elastic Object Storage (EOS) &lt;a href="https://rclone.org/s3/#china-mobile-ecloud-eos"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Cloudflare R2 &lt;a href="https://rclone.org/s3/#cloudflare-r2"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Citrix ShareFile &lt;a href="https://rclone.org/sharefile/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Cubbit DS3 &lt;a href="https://rclone.org/s3/#Cubbit"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DigitalOcean Spaces &lt;a href="https://rclone.org/s3/#digitalocean-spaces"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Digi Storage &lt;a href="https://rclone.org/koofr/#digi-storage"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dreamhost &lt;a href="https://rclone.org/s3/#dreamhost"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dropbox &lt;a href="https://rclone.org/dropbox/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Enterprise File Fabric &lt;a href="https://rclone.org/filefabric/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Exaba &lt;a href="https://rclone.org/s3/#exaba"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fastmail Files &lt;a href="https://rclone.org/webdav/#fastmail-files"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;FileLu &lt;a href="https://rclone.org/filelu/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Files.com &lt;a href="https://rclone.org/filescom/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;FlashBlade &lt;a href="https://rclone.org/s3/#pure-storage-flashblade"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;FTP &lt;a href="https://rclone.org/ftp/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GoFile &lt;a href="https://rclone.org/gofile/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Google Cloud Storage &lt;a href="https://rclone.org/googlecloudstorage/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Google Drive &lt;a href="https://rclone.org/drive/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Google Photos &lt;a href="https://rclone.org/googlephotos/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HDFS (Hadoop Distributed Filesystem) &lt;a href="https://rclone.org/hdfs/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hetzner Object Storage &lt;a href="https://rclone.org/s3/#hetzner"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hetzner Storage Box &lt;a href="https://rclone.org/sftp/#hetzner-storage-box"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HiDrive &lt;a href="https://rclone.org/hidrive/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HTTP &lt;a href="https://rclone.org/http/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Huawei Cloud Object Storage Service(OBS) &lt;a href="https://rclone.org/s3/#huawei-obs"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;iCloud Drive &lt;a href="https://rclone.org/iclouddrive/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ImageKit &lt;a href="https://rclone.org/imagekit/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Internet Archive &lt;a href="https://rclone.org/internetarchive/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Jottacloud &lt;a href="https://rclone.org/jottacloud/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;IBM COS S3 &lt;a href="https://rclone.org/s3/#ibm-cos-s3"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Intercolo Object Storage &lt;a href="https://rclone.org/s3/#intercolo"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;IONOS Cloud &lt;a href="https://rclone.org/s3/#ionos"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Koofr &lt;a href="https://rclone.org/koofr/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Leviia Object Storage &lt;a href="https://rclone.org/s3/#leviia"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Liara Object Storage &lt;a href="https://rclone.org/s3/#liara-object-storage"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Linkbox &lt;a href="https://rclone.org/linkbox"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Linode Object Storage &lt;a href="https://rclone.org/s3/#linode"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Magalu Object Storage &lt;a href="https://rclone.org/s3/#magalu"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Mail.ru Cloud &lt;a href="https://rclone.org/mailru/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Memset Memstore &lt;a href="https://rclone.org/swift/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MEGA &lt;a href="https://rclone.org/mega/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MEGA S4 Object Storage &lt;a href="https://rclone.org/s3/#mega"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Memory &lt;a href="https://rclone.org/memory/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Microsoft Azure Blob Storage &lt;a href="https://rclone.org/azureblob/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Microsoft Azure Files Storage &lt;a href="https://rclone.org/azurefiles/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Microsoft OneDrive &lt;a href="https://rclone.org/onedrive/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Minio &lt;a href="https://rclone.org/s3/#minio"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Nextcloud &lt;a href="https://rclone.org/webdav/#nextcloud"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Blomp Cloud Storage &lt;a href="https://rclone.org/swift/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;OpenDrive &lt;a href="https://rclone.org/opendrive/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;OpenStack Swift &lt;a href="https://rclone.org/swift/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oracle Cloud Storage &lt;a href="https://rclone.org/swift/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oracle Object Storage &lt;a href="https://rclone.org/oracleobjectstorage/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Outscale &lt;a href="https://rclone.org/s3/#outscale"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;OVHcloud Object Storage (Swift) &lt;a href="https://rclone.org/swift/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;OVHcloud Object Storage (S3-compatible) &lt;a href="https://rclone.org/s3/#ovhcloud"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ownCloud &lt;a href="https://rclone.org/webdav/#owncloud"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;pCloud &lt;a href="https://rclone.org/pcloud/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Petabox &lt;a href="https://rclone.org/s3/#petabox"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;PikPak &lt;a href="https://rclone.org/pikpak/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Pixeldrain &lt;a href="https://rclone.org/pixeldrain/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;premiumize.me &lt;a href="https://rclone.org/premiumizeme/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;put.io &lt;a href="https://rclone.org/putio/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Proton Drive &lt;a href="https://rclone.org/protondrive/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QingStor &lt;a href="https://rclone.org/qingstor/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Qiniu Cloud Object Storage (Kodo) &lt;a href="https://rclone.org/s3/#qiniu"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Rabata Cloud Storage &lt;a href="https://rclone.org/s3/#Rabata"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Quatrix &lt;a href="https://rclone.org/quatrix/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Rackspace Cloud Files &lt;a href="https://rclone.org/swift/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RackCorp Object Storage &lt;a href="https://rclone.org/s3/#RackCorp"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;rsync.net &lt;a href="https://rclone.org/sftp/#rsync-net"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Scaleway &lt;a href="https://rclone.org/s3/#scaleway"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Seafile &lt;a href="https://rclone.org/seafile/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Seagate Lyve Cloud &lt;a href="https://rclone.org/s3/#lyve"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SeaweedFS &lt;a href="https://rclone.org/s3/#seaweedfs"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Selectel Object Storage &lt;a href="https://rclone.org/s3/#selectel"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Servercore Object Storage &lt;a href="https://rclone.org/s3/#servercore"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SFTP &lt;a href="https://rclone.org/sftp/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SMB / CIFS &lt;a href="https://rclone.org/smb/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spectra Logic &lt;a href="https://rclone.org/s3/#spectralogic"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;StackPath &lt;a href="https://rclone.org/s3/#stackpath"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Storj &lt;a href="https://rclone.org/storj/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SugarSync &lt;a href="https://rclone.org/sugarsync/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Synology C2 Object Storage &lt;a href="https://rclone.org/s3/#synology-c2"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tencent Cloud Object Storage (COS) &lt;a href="https://rclone.org/s3/#tencent-cos"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Uloz.to &lt;a href="https://rclone.org/ulozto/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Wasabi &lt;a href="https://rclone.org/s3/#wasabi"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WebDAV &lt;a href="https://rclone.org/webdav/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Yandex Disk &lt;a href="https://rclone.org/yandex/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Zoho WorkDrive &lt;a href="https://rclone.org/zoho/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Zata.ai &lt;a href="https://rclone.org/s3/#Zata"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The local filesystem &lt;a href="https://rclone.org/local/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please see &lt;a href="https://rclone.org/overview/"&gt;the full list of all storage providers and their features&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Virtual storage providers&lt;/h3&gt; 
&lt;p&gt;These backends adapt or modify other storage providers&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Alias: rename existing remotes &lt;a href="https://rclone.org/alias/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Archive: read archive files &lt;a href="https://rclone.org/archive/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Cache: cache remotes (DEPRECATED) &lt;a href="https://rclone.org/cache/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chunker: split large files &lt;a href="https://rclone.org/chunker/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Combine: combine multiple remotes into a directory tree &lt;a href="https://rclone.org/combine/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Compress: compress files &lt;a href="https://rclone.org/compress/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Crypt: encrypt files &lt;a href="https://rclone.org/crypt/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hasher: hash files &lt;a href="https://rclone.org/hasher/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Union: join multiple remotes to work together &lt;a href="https://rclone.org/union/"&gt;&lt;span&gt;📄&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MD5/SHA-1 hashes checked at all times for file integrity&lt;/li&gt; 
 &lt;li&gt;Timestamps preserved on files&lt;/li&gt; 
 &lt;li&gt;Partial syncs supported on a whole file basis&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/commands/rclone_copy/"&gt;Copy&lt;/a&gt; mode to just copy new/changed files&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/commands/rclone_sync/"&gt;Sync&lt;/a&gt; (one way) mode to make a directory identical&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/bisync/"&gt;Bisync&lt;/a&gt; (two way) to keep two directories in sync bidirectionally&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/commands/rclone_check/"&gt;Check&lt;/a&gt; mode to check for file hash equality&lt;/li&gt; 
 &lt;li&gt;Can sync to and from network, e.g. two different cloud accounts&lt;/li&gt; 
 &lt;li&gt;Optional large file chunking (&lt;a href="https://rclone.org/chunker/"&gt;Chunker&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Optional transparent compression (&lt;a href="https://rclone.org/compress/"&gt;Compress&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Optional encryption (&lt;a href="https://rclone.org/crypt/"&gt;Crypt&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Optional FUSE mount (&lt;a href="https://rclone.org/commands/rclone_mount/"&gt;rclone mount&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Multi-threaded downloads to local disk&lt;/li&gt; 
 &lt;li&gt;Can &lt;a href="https://rclone.org/commands/rclone_serve/"&gt;serve&lt;/a&gt; local or remote files over HTTP/WebDAV/FTP/SFTP/DLNA&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation &amp;amp; documentation&lt;/h2&gt; 
&lt;p&gt;Please see the &lt;a href="https://rclone.org/"&gt;rclone website&lt;/a&gt; for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/install/"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/docs/"&gt;Documentation &amp;amp; configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/changelog/"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/faq/"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/overview/"&gt;Storage providers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://forum.rclone.org/"&gt;Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;...and more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Downloads&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/downloads/"&gt;https://rclone.org/downloads/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This is free software under the terms of the MIT license (check the &lt;a href="https://raw.githubusercontent.com/rclone/rclone/master/COPYING"&gt;COPYING file&lt;/a&gt; included in this package).&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>