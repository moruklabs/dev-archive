<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Thu, 15 Jan 2026 01:41:35 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>anomalyco/opencode</title>
      <link>https://github.com/anomalyco/opencode</link>
      <description>&lt;p&gt;The open source coding agent.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://opencode.ai"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-light.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/anomalyco/opencode/dev/packages/console/app/src/asset/logo-ornate-light.svg?sanitize=true" alt="OpenCode logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;The open source AI coding agent.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://opencode.ai/discord"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;amp;label=discord" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/opencode-ai"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/opencode-ai?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/anomalyco/opencode/actions/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/anomalyco/opencode/publish.yml?style=flat-square&amp;amp;branch=dev" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencode.ai"&gt;&lt;img src="https://raw.githubusercontent.com/anomalyco/opencode/dev/packages/web/src/assets/lander/screenshot.png" alt="OpenCode Terminal UI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
scoop bucket add extras; scoop install extras/opencode  # Windows
choco install opencode             # Windows
brew install anomalyco/tap/opencode # macOS and Linux (recommended, always up to date)
brew install opencode              # macOS and Linux (official brew formula, updated less)
paru -S opencode-bin               # Arch Linux
mise use -g opencode               # Any OS
nix run nixpkgs#opencode           # or github:anomalyco/opencode for latest dev branch
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Remove versions older than 0.1.x before installing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Desktop App (BETA)&lt;/h3&gt; 
&lt;p&gt;OpenCode is also available as a desktop application. Download directly from the &lt;a href="https://github.com/anomalyco/opencode/releases"&gt;releases page&lt;/a&gt; or &lt;a href="https://opencode.ai/download"&gt;opencode.ai/download&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Apple Silicon)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-aarch64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Intel)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-x64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-windows-x64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, or AppImage&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (Homebrew)
brew install --cask opencode-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installation Directory&lt;/h4&gt; 
&lt;p&gt;The install script respects the following priority order for the installation path:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;$OPENCODE_INSTALL_DIR&lt;/code&gt; - Custom installation directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$XDG_BIN_DIR&lt;/code&gt; - XDG Base Directory Specification compliant path&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/bin&lt;/code&gt; - Standard user binary directory (if exists or can be created)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.opencode/bin&lt;/code&gt; - Default fallback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Agents&lt;/h3&gt; 
&lt;p&gt;OpenCode includes two built-in agents you can switch between with the &lt;code&gt;Tab&lt;/code&gt; key.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;build&lt;/strong&gt; - Default, full access agent for development work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;plan&lt;/strong&gt; - Read-only agent for analysis and code exploration 
  &lt;ul&gt; 
   &lt;li&gt;Denies file edits by default&lt;/li&gt; 
   &lt;li&gt;Asks permission before running bash commands&lt;/li&gt; 
   &lt;li&gt;Ideal for exploring unfamiliar codebases or planning changes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, included is a &lt;strong&gt;general&lt;/strong&gt; subagent for complex searches and multistep tasks. This is used internally and can be invoked using &lt;code&gt;@general&lt;/code&gt; in messages.&lt;/p&gt; 
&lt;p&gt;Learn more about &lt;a href="https://opencode.ai/docs/agents"&gt;agents&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;For more info on how to configure OpenCode &lt;a href="https://opencode.ai/docs"&gt;&lt;strong&gt;head over to our docs&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;If you're interested in contributing to OpenCode, please read our &lt;a href="https://raw.githubusercontent.com/anomalyco/opencode/dev/CONTRIBUTING.md"&gt;contributing docs&lt;/a&gt; before submitting a pull request.&lt;/p&gt; 
&lt;h3&gt;Building on OpenCode&lt;/h3&gt; 
&lt;p&gt;If you are working on a project that's related to OpenCode and is using "opencode" as a part of its name; for example, "opencode-dashboard" or "opencode-mobile", please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in any way.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;h4&gt;How is this different from Claude Code?&lt;/h4&gt; 
&lt;p&gt;It's very similar to Claude Code in terms of capability. Here are the key differences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100% open source&lt;/li&gt; 
 &lt;li&gt;Not coupled to any provider. Although we recommend the models we provide through &lt;a href="https://opencode.ai/zen"&gt;OpenCode Zen&lt;/a&gt;; OpenCode can be used with Claude, OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.&lt;/li&gt; 
 &lt;li&gt;Out of the box LSP support&lt;/li&gt; 
 &lt;li&gt;A focus on TUI. OpenCode is built by neovim users and the creators of &lt;a href="https://terminal.shop"&gt;terminal.shop&lt;/a&gt;; we are going to push the limits of what's possible in the terminal.&lt;/li&gt; 
 &lt;li&gt;A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Join our community&lt;/strong&gt; &lt;a href="https://discord.gg/opencode"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/opencode"&gt;X.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hacksider/Deep-Live-Cam</title>
      <link>https://github.com/hacksider/Deep-Live-Cam</link>
      <description>&lt;p&gt;real time face swap and one-click video deepfake with only a single image&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Deep-Live-Cam 2.0.1c&lt;/h1&gt; 
&lt;p align="center"&gt; Real-time face swap and video deepfake with a single click and only a single image. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/11395" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11395" alt="hacksider%2FDeep-Live-Cam | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif" alt="Demo GIF" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.&lt;/p&gt; 
&lt;p&gt;We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ethical Use: Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.&lt;/p&gt; 
&lt;p&gt;Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.&lt;/p&gt; 
&lt;h2&gt;Exclusive v2.4 Quick Start - Pre-built (Windows/Mac Silicon)&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/Download.png" width="285" height="77" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;h5&gt;This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you'll receive special priority support.&lt;/h5&gt; &lt;h6&gt;These Pre-builts are perfect for non-technical users or those who don't have time to, or can't manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually.&lt;/h6&gt; &lt;h2&gt;TLDR; Live Deepfake in just 3 Clicks&lt;/h2&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6" alt="easysteps" /&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Select a face&lt;/li&gt; 
  &lt;li&gt;Select which camera to use&lt;/li&gt; 
  &lt;li&gt;Press live!&lt;/li&gt; 
 &lt;/ol&gt; &lt;h2&gt;Features &amp;amp; Uses - Everything is in real-time&lt;/h2&gt; &lt;h3&gt;Mouth Mask&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Retain your original mouth for accurate movement using Mouth Mask&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif" alt="resizable-gif" /&gt; &lt;/p&gt; &lt;h3&gt;Face Mapping&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Use different faces on multiple subjects simultaneously&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif" alt="face_mapping_source" /&gt; &lt;/p&gt; &lt;h3&gt;Your Movie, Your Face&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Watch movies with any face in real-time&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif" alt="movie" /&gt; &lt;/p&gt; &lt;h3&gt;Live Show&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Run Live shows and performances&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif" alt="show" /&gt; &lt;/p&gt; &lt;h3&gt;Memes&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Create Your Most Viral Meme Yet&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif" alt="show" width="450" /&gt; &lt;br /&gt; &lt;sub&gt;Created using Many Faces feature in Deep-Live-Cam&lt;/sub&gt; &lt;/p&gt; &lt;h3&gt;Omegle&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Surprise people on Omegle&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; 
  &lt;video src="https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0" width="450" controls&gt;&lt;/video&gt; &lt;/p&gt; &lt;h2&gt;Installation (Manual)&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;
&lt;details&gt;
 &lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;summary&gt;Click to see the process&lt;/summary&gt; &lt;h3&gt;Installation&lt;/h3&gt; &lt;p&gt;This is more likely to work on your computer but will be slower as it utilizes the CPU.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;1. Set up Your Platform&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python (3.11 recommended)&lt;/li&gt; 
   &lt;li&gt;pip&lt;/li&gt; 
   &lt;li&gt;git&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OlNWCpFdVMA"&gt;ffmpeg&lt;/a&gt; - &lt;code&gt;iex (irm ffmpeg.tc.ht)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Visual Studio 2022 Runtimes (Windows)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;strong&gt;2. Clone the Repository&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/hacksider/Deep-Live-Cam.git
cd Deep-Live-Cam
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Download the Models&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth"&gt;GFPGANv1.4&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx"&gt;inswapper_128_fp16.onnx&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Place these files in the "&lt;strong&gt;models&lt;/strong&gt;" folder.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4. Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We highly recommend using a &lt;code&gt;venv&lt;/code&gt; to avoid issues.&lt;/p&gt; 
 &lt;p&gt;For Windows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Ensure you use the installed Python 3.10
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) requires specific setup:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Python 3.11 (specific version is important)
brew install python@3.11

# Install tkinter package (required for the GUI)
brew install python-tk@3.10

# Create and activate virtual environment with Python 3.11
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;** In case something goes wrong and you need to reinstall the virtual environment **&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Deactivate the virtual environment
rm -rf venv

# Reinstall the virtual environment
python -m venv venv
source venv/bin/activate

# install the dependencies again
pip install -r requirements.txt

# gfpgan and basicsrs issue fix
pip install git+https://github.com/xinntao/BasicSR.git@master
pip uninstall gfpgan -y
pip install git+https://github.com/TencentARC/GFPGAN.git@master
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Run:&lt;/strong&gt; If you don't have a GPU, you can run Deep-Live-Cam using &lt;code&gt;python run.py&lt;/code&gt;. Note that initial execution will download models (~300MB).&lt;/p&gt; 
 &lt;h3&gt;GPU Acceleration&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;CUDA Execution Provider (Nvidia)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/cuda-12-8-0-download-archive"&gt;CUDA Toolkit 12.8.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/rdp/cudnn-archive"&gt;cuDNN v8.9.7 for CUDA 12.x&lt;/a&gt; (required for onnxruntime-gpu): 
   &lt;ul&gt; 
    &lt;li&gt;Download cuDNN v8.9.7 for CUDA 12.x&lt;/li&gt; 
    &lt;li&gt;Make sure the cuDNN bin directory is in your system PATH&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider cuda
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Silicon)&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) specific installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Make sure you've completed the macOS setup above using Python 3.10.&lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage (important: specify Python 3.10):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3.10 run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important Notes for macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;You &lt;strong&gt;must&lt;/strong&gt; use Python 3.10, not newer versions like 3.11 or 3.13&lt;/li&gt; 
  &lt;li&gt;Always run with &lt;code&gt;python3.10&lt;/code&gt; command not just &lt;code&gt;python&lt;/code&gt; if you have multiple Python versions installed&lt;/li&gt; 
  &lt;li&gt;If you get error about &lt;code&gt;_tkinter&lt;/code&gt; missing, reinstall the tkinter package: &lt;code&gt;brew reinstall python-tk@3.10&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;If you get model loading errors, check that your models are in the correct folder&lt;/li&gt; 
  &lt;li&gt;If you encounter conflicts with other Python versions, consider uninstalling them: &lt;pre&gt;&lt;code class="language-bash"&gt;# List all installed Python versions
brew list | grep python

# Uninstall conflicting versions if needed
brew uninstall --ignore-dependencies python@3.11 python@3.13

# Keep only Python 3.11
brew cleanup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Legacy)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;DirectML Execution Provider (Windows)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider directml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;OpenVINO‚Ñ¢ Execution Provider (Intel)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider openvino
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Image/Video Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Choose a source face image and a target image/video.&lt;/li&gt; 
 &lt;li&gt;Click "Start".&lt;/li&gt; 
 &lt;li&gt;The output will be saved in a directory named after the target video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Webcam Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Select a source face image.&lt;/li&gt; 
 &lt;li&gt;Click "Live".&lt;/li&gt; 
 &lt;li&gt;Wait for the preview to appear (10-30 seconds).&lt;/li&gt; 
 &lt;li&gt;Use a screen capture tool like OBS to stream.&lt;/li&gt; 
 &lt;li&gt;To change the face, select a new source image.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command Line Arguments (Unmaintained)&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --map-faces                                              map source target faces
  --mouth-mask                                             mask the mouth region
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program's version number and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.&lt;/p&gt; 
&lt;h2&gt;Press&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We are always open to criticism and are ready to improve, that's why we didn't cherry-pick anything.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/"&gt;&lt;em&gt;"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger"&lt;/em&gt;&lt;/a&gt; - Ars Technica&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/"&gt;&lt;em&gt;"Thanks Deep Live Cam, shapeshifters are among us now"&lt;/em&gt;&lt;/a&gt; - Dataconomy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story"&gt;&lt;em&gt;"This free AI tool lets you become anyone during video-calls"&lt;/em&gt;&lt;/a&gt; - NewsBytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying"&gt;&lt;em&gt;"OK, this viral AI live stream software is truly terrifying"&lt;/em&gt;&lt;/a&gt; - Creative Bloq&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/"&gt;&lt;em&gt;"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo"&lt;/em&gt;&lt;/a&gt; - PetaPixel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.techeblog.com/deep-live-cam-ai-transform-face/"&gt;&lt;em&gt;"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included"&lt;/em&gt;&lt;/a&gt; - TechEBlog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/"&gt;&lt;em&gt;"An AI tool that "makes you look like anyone" during a video call is going viral online"&lt;/em&gt;&lt;/a&gt; - Telegrafi&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts"&gt;&lt;em&gt;"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts"&lt;/em&gt;&lt;/a&gt; - Emerge&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/"&gt;&lt;em&gt;"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces"&lt;/em&gt;&lt;/a&gt; - Digital Music News&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/"&gt;&lt;em&gt;"This real-time webcam deepfake tool raises alarms about the future of identity theft"&lt;/em&gt;&lt;/a&gt; - DIYPhotography&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?time_continue=1074&amp;amp;v=py4Tc-Y8BcY"&gt;&lt;em&gt;"That's Crazy, Oh God. That's Fucking Freaky Dude... That's So Wild Dude"&lt;/em&gt;&lt;/a&gt; - SomeOrdinaryGamers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;amp;t=2686"&gt;&lt;em&gt;"Alright look look look, now look chat, we can do any face we want to look like chat"&lt;/em&gt;&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wnCghLjqv3s&amp;amp;t=551s"&gt;&lt;em&gt;"They do a pretty good job matching poses, expression and even the lighting"&lt;/em&gt;&lt;/a&gt; - TechLinked (LTT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html"&gt;&lt;em&gt;"Als Sean Connery an der Redaktionskonferenz teilnahm"&lt;/em&gt;&lt;/a&gt; - Golem.de (German)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/JbUPRmXRUtE?t=3964"&gt;&lt;em&gt;"What the F&lt;/em&gt;**! Why do I look like Vinny Jr? I look exactly like Vinny Jr!? No, this shit is crazy! Bro This is F*** Crazy! "*&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ffmpeg.org/"&gt;ffmpeg&lt;/a&gt;: for making video-related operations easy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/henryruhs"&gt;Henry&lt;/a&gt;: One of the major contributor in this repo&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepinsight"&gt;deepinsight&lt;/a&gt;: for their &lt;a href="https://github.com/deepinsight/insightface"&gt;insightface&lt;/a&gt; project which provided a well-made library and models. Please be reminded that the &lt;a href="https://github.com/deepinsight/insightface?tab=readme-ov-file#license"&gt;use of the model is for non-commercial research purposes only&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/havok2-htwo"&gt;havok2-htwo&lt;/a&gt;: for sharing the code for webcam&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GosuDRM"&gt;GosuDRM&lt;/a&gt;: for the open version of roop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pereiraroland26"&gt;pereiraroland26&lt;/a&gt;: Multiple faces support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vic4key"&gt;vic4key&lt;/a&gt;: For supporting/contributing to this project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kier007"&gt;kier007&lt;/a&gt;: for improving the user experience&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qitianai"&gt;qitianai&lt;/a&gt;: for multi-lingual support&lt;/li&gt; 
 &lt;li&gt;and &lt;a href="https://github.com/hacksider/Deep-Live-Cam/graphs/contributors"&gt;all developers&lt;/a&gt; behind libraries used in this project.&lt;/li&gt; 
 &lt;li&gt;Footnote: Please be informed that the base author of the code is &lt;a href="https://github.com/s0md3v/roop"&gt;s0md3v&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All the wonderful users who helped make this project go viral by starring the repo ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/hacksider/Deep-Live-Cam/stargazers"&gt;&lt;img src="https://reporoster.com/stars/hacksider/Deep-Live-Cam" alt="Stargazers" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Stars to the Moon üöÄ&lt;/h2&gt; 
&lt;a href="https://star-history.com/#hacksider/deep-live-cam&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>OpenBMB/ChatDev</title>
      <link>https://github.com/OpenBMB/ChatDev</link>
      <description>&lt;p&gt;ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatDev 2.0 - DevAll&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/frontend/public/media/logo.png" alt="DevAll Logo" width="500" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;A Zero-Code Multi-Agent Platform for Developing Everything&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; „Äê&lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README-zh.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;p align="center"&gt; „Äêüìö &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developers&lt;/a&gt; | üë• &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#primary-contributors"&gt;Contributors&lt;/a&gt;ÔΩú‚≠êÔ∏è &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;ChatDev 1.0 (Legacy)&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;h2&gt;üìñ Overview&lt;/h2&gt; 
&lt;p&gt;ChatDev has evolved from a specialized software development multi-agent system into a comprehensive multi-agent orchestration platform.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/main"&gt;&lt;strong&gt;ChatDev 2.0 (DevAll)&lt;/strong&gt;&lt;/a&gt; is a &lt;strong&gt;Zero-Code Multi-Agent Platform&lt;/strong&gt; for "Developing Everything". It empowers users to rapidly build and execute customized multi-agent systems through simple configuration. No coding is required‚Äîusers can define agents, workflows, and tasks to orchestrate complex scenarios such as data visualization, 3D generation, and deep research.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;strong&gt;ChatDev 1.0 (Legacy)&lt;/strong&gt;&lt;/a&gt; operates as a &lt;strong&gt;Virtual Software Company&lt;/strong&gt;. It utilizes various intelligent agents (e.g., CEO, CTO, Programmer) participating in specialized functional seminars to automate the entire software development life cycle‚Äîincluding designing, coding, testing, and documenting. It serves as the foundational paradigm for communicative agent collaboration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéâ News&lt;/h2&gt; 
&lt;p&gt;‚Ä¢ &lt;strong&gt;Jan 07, 2026: üöÄ We are excited to announce the official release of ChatDev 2.0 (DevAll)!&lt;/strong&gt; This version introduces a zero-code multi-agent orchestration platform. The classic ChatDev (v1.x) has been moved to the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;code&gt;chatdev1.0&lt;/code&gt;&lt;/a&gt; branch for maintenance. More details about ChatDev 2.0 can be found on &lt;a href="https://x.com/OpenBMB/status/2008916790399701335"&gt;our official post&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Old News&lt;/summary&gt; 
 &lt;p&gt;‚Ä¢Sep 24, 2025: üéâ Our paper &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt; has been accepted to NeurIPS 2025. The implementation is available in the &lt;code&gt;puppeteer&lt;/code&gt; branch of this repository.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢May 26, 2025: üéâ We propose a novel puppeteer-style paradigm for multi-agent collaboration among large language model based agents. By leveraging a learnable central orchestrator optimized with reinforcement learning, our method dynamically activates and sequences agents to construct efficient, context-aware reasoning paths. This approach not only improves reasoning quality but also reduces computational costs, enabling scalable and adaptable multi-agent cooperation in complex tasks. See our paper in &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/puppeteer.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 25, 2024: üéâTo foster development in LLM-powered multi-agent collaborationü§ñü§ñ and related fields, the ChatDev team has curated a collection of seminal papersüìÑ presented in a &lt;a href="https://github.com/OpenBMB/ChatDev/tree/main/MultiAgentEbook"&gt;open-source&lt;/a&gt; interactive e-booküìö format. Now you can explore the latest advancements on the &lt;a href="https://thinkwee.top/multiagent_ebook"&gt;Ebook Website&lt;/a&gt; and download the &lt;a href="https://github.com/OpenBMB/ChatDev/raw/main/MultiAgentEbook/papers.csv"&gt;paper list&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ebook.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 12, 2024: We introduced Multi-Agent Collaboration Networks (MacNet) üéâ, which utilize directed acyclic graphs to facilitate effective task-oriented collaboration among agents through linguistic interactions ü§ñü§ñ. MacNet supports co-operation across various topologies and among more than a thousand agents without exceeding context limits. More versatile and scalable, MacNet can be considered as a more advanced version of ChatDev's chain-shaped topology. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2406.07155"&gt;https://arxiv.org/abs/2406.07155&lt;/a&gt;. This technique has been incorporated into the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/macnet"&gt;macnet&lt;/a&gt; branch, enhancing support for diverse organizational structures and offering richer solutions beyond software development (e.g., logical reasoning, data analysis, story generation, and more).&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/macnet.png" width="500" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ May 07, 2024, we introduced "Iterative Experience Refinement" (IER), a novel method where instructor and assistant agents enhance shortcut-oriented experiences to efficiently adapt to new tasks. This approach encompasses experience acquisition, utilization, propagation and elimination across a series of tasks and making the pricess shorter and efficient. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2405.04219"&gt;https://arxiv.org/abs/2405.04219&lt;/a&gt;, and this technique will soon be incorporated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ier.png" width="220" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ January 25, 2024: We have integrated Experiential Co-Learning Module into ChatDev. Please see the &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#co-tracking"&gt;Experiential Co-Learning Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ December 28, 2023: We present Experiential Co-Learning, an innovative approach where instructor and assistant agents accumulate shortcut-oriented experiences to effectively solve new tasks, reducing repetitive errors and enhancing efficiency. Check out our preprint paper at &lt;a href="https://arxiv.org/abs/2312.17025"&gt;https://arxiv.org/abs/2312.17025&lt;/a&gt; and this technique will soon be integrated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ecl.png" width="860" /&gt; &lt;/p&gt; ‚Ä¢ November 15, 2023: We launched ChatDev as a SaaS platform that enables software developers and innovative entrepreneurs to build software efficiently at a very low cost and remove the barrier to entry. Try it out at https://chatdev.modelbest.cn/. 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/saas.png" width="560" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ November 2, 2023: ChatDev is now supported with a new feature: incremental development, which allows agents to develop upon existing codes. Try &lt;code&gt;--config "incremental" --path "[source_code_directory_path]"&lt;/code&gt; to start it.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/increment.png" width="700" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ October 26, 2023: ChatDev is now supported with Docker for safe execution (thanks to contribution from &lt;a href="https://github.com/ManindraDeMel"&gt;ManindraDeMel&lt;/a&gt;). Please see &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#docker-start"&gt;Docker Start Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/docker.png" width="400" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 25, 2023: The &lt;strong&gt;Git&lt;/strong&gt; mode is now available, enabling the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt; to utilize Git for version control. To enable this feature, simply set &lt;code&gt;"git_management"&lt;/code&gt; to &lt;code&gt;"True"&lt;/code&gt; in &lt;code&gt;ChatChainConfig.json&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#git-mode"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/github.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 20, 2023: The &lt;strong&gt;Human-Agent-Interaction&lt;/strong&gt; mode is now available! You can get involved with the ChatDev team by playing the role of reviewer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/reviewer.png" height="20" /&gt; and making suggestions to the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt;; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Human"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#human-agent-interaction"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/Gomoku_HumanAgentInteraction_20230920135038"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/Human_intro.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 1, 2023: The &lt;strong&gt;Art&lt;/strong&gt; mode is available now! You can activate the designer agent &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/designer.png" height="20" /&gt; to generate images used in the software; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Art"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#art"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/gomokugameArtExample_THUNLP_20230831122822"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 28, 2023: The system is publicly available.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 17, 2023: The v1.0.0 version was ready for release.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 30, 2023: Users can customize ChatChain, Phasea and Role settings. Additionally, both online Log mode and replay mode are now supported.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 16, 2023: The &lt;a href="https://arxiv.org/abs/2307.07924"&gt;preprint paper&lt;/a&gt; associated with this project was published.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ June 30, 2023: The initial version of the ChatDev repository was released.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;üìã Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OS&lt;/strong&gt;: macOS / Linux / WSL / Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt;: 3.12+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: 18+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Package Manager&lt;/strong&gt;: &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Backend Dependencies&lt;/strong&gt; (Python managed by &lt;code&gt;uv&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Frontend Dependencies&lt;/strong&gt; (Vite + Vue 3):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend &amp;amp;&amp;amp; npm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;‚ö°Ô∏è Run the Application&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Backend&lt;/strong&gt; :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Run from the project root
uv run python server_main.py --port 6400 --reload
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Frontend&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
VITE_API_BASE_URL=http://localhost:6400 npm run dev
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Then access the Web Console at &lt;strong&gt;&lt;a href="http://localhost:5173"&gt;http://localhost:5173&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;üí° Tip&lt;/strong&gt;: If the frontend fails to connect to the backend, the default port &lt;code&gt;6400&lt;/code&gt; may already be occupied. Please switch both services to an available port, for example:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: start with &lt;code&gt;--port 6401&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: set &lt;code&gt;VITE_API_BASE_URL=http://localhost:6401&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üîë Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Environment Variables&lt;/strong&gt;: Create a &lt;code&gt;.env&lt;/code&gt; file in the project root.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Keys&lt;/strong&gt;: Set &lt;code&gt;API_KEY&lt;/code&gt; and &lt;code&gt;BASE_URL&lt;/code&gt; in &lt;code&gt;.env&lt;/code&gt; for your LLM provider.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;YAML placeholders&lt;/strong&gt;: Use &lt;code&gt;${VAR}&lt;/code&gt;Ôºàe.g., &lt;code&gt;${API_KEY}&lt;/code&gt;Ôºâin configuration files to reference these variables.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° How to Use&lt;/h2&gt; 
&lt;h3&gt;üñ•Ô∏è Web Console&lt;/h3&gt; 
&lt;p&gt;The DevAll interface provides a seamless experience for both construction and execution&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tutorial&lt;/strong&gt;: Comprehensive step-by-step guides and documentation integrated directly into the platform to help you get started quickly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/tutorial-en.png" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Workflow&lt;/strong&gt;: A visual canvas to design your multi-agent systems. Configure node parameters, define context flows, and orchestrate complex agent interactions with drag-and-drop ease.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/workflow.gif" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Launch&lt;/strong&gt;: Initiate workflows, monitor real-time logs, inspect intermediate artifacts, and provide human-in-the-loop feedback.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/launch.gif" /&gt; 
&lt;h3&gt;üß∞ Python SDK&lt;/h3&gt; 
&lt;p&gt;For automation and batch processing, use our lightweight Python SDK to execute workflows programmatically and retrieve results directly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from runtime.sdk import run_workflow

# Execute a workflow and get the final node message
result = run_workflow(
    yaml_file="yaml_instance/demo.yaml",
    task_prompt="Summarize the attached document in one sentence.",
    attachments=["/path/to/document.pdf"],
    variables={"API_KEY": "sk-xxxx"} # Override .env variables if needed
)

if result.final_message:
    print(f"Output: {result.final_message.text_content()}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a id="developers"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è For Developers&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;For secondary development and extensions, please proceed with this section.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Extend DevAll with new nodes, providers, and tools. The project is organized into a modular structure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Systems&lt;/strong&gt;: &lt;code&gt;server/&lt;/code&gt; hosts the FastAPI backend, while &lt;code&gt;runtime/&lt;/code&gt; manages agent abstraction and tool execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestration&lt;/strong&gt;: &lt;code&gt;workflow/&lt;/code&gt; handles the multi-agent logic, driven by configurations in &lt;code&gt;entity/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: &lt;code&gt;frontend/&lt;/code&gt; contains the Vue 3 Web Console.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensibility&lt;/strong&gt;: &lt;code&gt;functions/&lt;/code&gt; is the place for custom Python tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Relevant reference documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/index.md"&gt;Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Core Modules&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/workflow_authoring.md"&gt;Workflow Authoring&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/memory.md"&gt;Memory&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/tooling/index.md"&gt;Tooling&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåü Featured Workflows&lt;/h2&gt; 
&lt;p&gt;We provide robust, out-of-the-box templates for common scenarios. All runnable workflow configs are located in &lt;code&gt;yaml_instance/&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Demos&lt;/strong&gt;: Files named &lt;code&gt;demo_*.yaml&lt;/code&gt; showcase specific features or modules.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Implementations&lt;/strong&gt;: Files named directly (e.g., &lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;) are full in-house or recreated workflows. As follows:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Workflow Collection&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Category&lt;/th&gt; 
   &lt;th align="left"&gt;Workflow&lt;/th&gt; 
   &lt;th align="left"&gt;Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìà Data Visualization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;data_visualization_basic.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;data_visualization_enhanced.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/data_analysis/data_analysis.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Create 4‚Äì6 high-quality PNG charts for my large real-estate transactions dataset."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üõ†Ô∏è 3D Generation&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;(Requires &lt;a href="https://www.blender.org/"&gt;Blender&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/ahujasid/blender-mcp"&gt;blender-mcp&lt;/a&gt;)&lt;/em&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;blender_3d_builder_simple.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_3d_builder_hub.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_scientific_illustration.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/3d_generation/3d.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please build a Christmas tree."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéÆ Game Dev&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;GameDev_v1.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/game_development/game.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please help me design and develop a Tank Battle game."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìö Deep Research&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;deep_research_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/deep_research/deep_research.gif" width="85%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Research about recent advances in the field of LLM-based agent RL"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéì Teach Video&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;teach_video.yaml&lt;/code&gt; (Please run command &lt;code&gt;uv add manim&lt;/code&gt; before running this workflow)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/video_generation/video.gif" width="140%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"ËÆ≤‰∏Ä‰∏ã‰ªÄ‰πàÊòØÂá∏‰ºòÂåñ"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üí° Usage Guide&lt;/h3&gt; 
&lt;p&gt;For those implementations, you can use the &lt;strong&gt;Launch&lt;/strong&gt; tab to execute them.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Select&lt;/strong&gt;: Choose a workflow in the &lt;strong&gt;Launch&lt;/strong&gt; tab.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt;: Upload necessary files (e.g., &lt;code&gt;.csv&lt;/code&gt; for data analysis) if required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt&lt;/strong&gt;: Enter your request (e.g., &lt;em&gt;"Visualize the sales trends"&lt;/em&gt; or &lt;em&gt;"Design a snake game"&lt;/em&gt;).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding new workflow templates, or sharing high-quality cases/artifacts produced by DevAll, your help is much appreciated. Feel free to contribute by submitting &lt;strong&gt;Issues&lt;/strong&gt; or &lt;strong&gt;Pull Requests&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;By contributing to DevAll, you'll be recognized in our &lt;strong&gt;Contributors&lt;/strong&gt; list below. Check out our &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developer Guide&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;h3&gt;üë• Contributors&lt;/h3&gt; 
&lt;h4&gt;Primary Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/NA-Wen"&gt;&lt;img src="https://github.com/NA-Wen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;NA-Wen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/zxrys"&gt;&lt;img src="https://github.com/zxrys.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zxrys&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/swugi"&gt;&lt;img src="https://github.com/swugi.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;swugi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/huatl98"&gt;&lt;img src="https://github.com/huatl98.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;huatl98&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/shiowen"&gt;&lt;img src="https://github.com/shiowen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shiowen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/kilo2127"&gt;&lt;img src="https://github.com/kilo2127.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;kilo2127&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/AckerlyLau"&gt;&lt;img src="https://github.com/AckerlyLau.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;AckerlyLau&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ü§ù Acknowledgments&lt;/h2&gt; 
&lt;p&gt;&lt;a href="http://nlp.csai.tsinghua.edu.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/thunlp.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://modelbest.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/modelbest.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/AgentVerse/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/agentverse.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/RepoAgent"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/repoagent.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://app.commanddash.io/agent?github=https://github.com/OpenBMB/ChatDev"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/CommandDash.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/www.teachmaster.cn"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/teachmaster.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OpenBMB/AppCopilot"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/appcopilot.png" height="50pt" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîé Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@article{chatdev,
    title = {ChatDev: Communicative Agents for Software Development},
    author = {Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2307.07924},
    url = {https://arxiv.org/abs/2307.07924},
    year = {2023}
}

@article{colearning,
    title = {Experiential Co-Learning of Software-Developing Agents},
    author = {Chen Qian and Yufan Dang and Jiahao Li and Wei Liu and Zihao Xie and Yifei Wang and Weize Chen and Cheng Yang and Xin Cong and Xiaoyin Che and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2312.17025},
    url = {https://arxiv.org/abs/2312.17025},
    year = {2023}
}

@article{macnet,
    title={Scaling Large-Language-Model-based Multi-Agent Collaboration},
    author={Chen Qian and Zihao Xie and Yifei Wang and Wei Liu and Yufan Dang and Zhuoyun Du and Weize Chen and Cheng Yang and Zhiyuan Liu and Maosong Sun}
    journal={arXiv preprint arXiv:2406.07155},
    url = {https://arxiv.org/abs/2406.07155},
    year={2024}
}

@article{iagents,
    title={Autonomous Agents for Collaborative Task under Information Asymmetry},
    author={Wei Liu and Chenxi Wang and Yifei Wang and Zihao Xie and Rennai Qiu and Yufan Dnag and Zhuoyun Du and Weize Chen and Cheng Yang and Chen Qian},
    journal={arXiv preprint arXiv:2406.14928},
    url = {https://arxiv.org/abs/2406.14928},
    year={2024}
}

@article{puppeteer,
      title={Multi-Agent Collaboration via Evolving Orchestration}, 
      author={Yufan Dang and Chen Qian and Xueheng Luo and Jingru Fan and Zihao Xie and Ruijie Shi and Weize Chen and Cheng Yang and Xiaoyin Che and Ye Tian and Xuantang Xiong and Lei Han and Zhiyuan Liu and Maosong Sun},
      journal={arXiv preprint arXiv:2505.19591},
      url={https://arxiv.org/abs/2505.19591},
      year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üì¨ Contact&lt;/h2&gt; 
&lt;p&gt;If you have any questions, feedback, or would like to get in touch, please feel free to reach out to us via email at &lt;a href="mailto:qianc62@gmail.com"&gt;qianc62@gmail.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>obra/superpowers</title>
      <link>https://github.com/obra/superpowers</link>
      <description>&lt;p&gt;Claude Code superpowers: core skills library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Superpowers&lt;/h1&gt; 
&lt;p&gt;Superpowers is a complete software development workflow for your coding agents, built on top of a set of composable "skills" and some initial instructions that make sure your agent uses them.&lt;/p&gt; 
&lt;h2&gt;How it works&lt;/h2&gt; 
&lt;p&gt;It starts from the moment you fire up your coding agent. As soon as it sees that you're building something, it &lt;em&gt;doesn't&lt;/em&gt; just jump into trying to write code. Instead, it steps back and asks you what you're really trying to do.&lt;/p&gt; 
&lt;p&gt;Once it's teased a spec out of the conversation, it shows it to you in chunks short enough to actually read and digest.&lt;/p&gt; 
&lt;p&gt;After you've signed off on the design, your agent puts together an implementation plan that's clear enough for an enthusiastic junior engineer with poor taste, no judgement, no project context, and an aversion to testing to follow. It emphasizes true red/green TDD, YAGNI (You Aren't Gonna Need It), and DRY.&lt;/p&gt; 
&lt;p&gt;Next up, once you say "go", it launches a &lt;em&gt;subagent-driven-development&lt;/em&gt; process, having agents work through each engineering task, inspecting and reviewing their work, and continuing forward. It's not uncommon for Claude to be able to work autonomously for a couple hours at a time without deviating from the plan you put together.&lt;/p&gt; 
&lt;p&gt;There's a bunch more to it, but that's the core of the system. And because the skills trigger automatically, you don't need to do anything special. Your coding agent just has Superpowers.&lt;/p&gt; 
&lt;h2&gt;Sponsorship&lt;/h2&gt; 
&lt;p&gt;If Superpowers has helped you do stuff that makes money and you are so inclined, I'd greatly appreciate it if you'd consider &lt;a href="https://github.com/sponsors/obra"&gt;sponsoring my opensource work&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thanks!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jesse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Installation differs by platform. Claude Code has a built-in plugin system. Codex and OpenCode require manual setup.&lt;/p&gt; 
&lt;h3&gt;Claude Code (via Plugin Marketplace)&lt;/h3&gt; 
&lt;p&gt;In Claude Code, register the marketplace first:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin marketplace add obra/superpowers-marketplace
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install the plugin from this marketplace:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin install superpowers@superpowers-marketplace
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Verify Installation&lt;/h3&gt; 
&lt;p&gt;Check that commands appear:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/help
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# Should see:
# /superpowers:brainstorm - Interactive design refinement
# /superpowers:write-plan - Create implementation plan
# /superpowers:execute-plan - Execute plan in batches
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Codex&lt;/h3&gt; 
&lt;p&gt;Tell Codex:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.codex/INSTALL.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Detailed docs:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/obra/superpowers/main/docs/README.codex.md"&gt;docs/README.codex.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;OpenCode&lt;/h3&gt; 
&lt;p&gt;Tell OpenCode:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.opencode/INSTALL.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Detailed docs:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/obra/superpowers/main/docs/README.opencode.md"&gt;docs/README.opencode.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;The Basic Workflow&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;brainstorming&lt;/strong&gt; - Activates before writing code. Refines rough ideas through questions, explores alternatives, presents design in sections for validation. Saves design document.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;using-git-worktrees&lt;/strong&gt; - Activates after design approval. Creates isolated workspace on new branch, runs project setup, verifies clean test baseline.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;writing-plans&lt;/strong&gt; - Activates with approved design. Breaks work into bite-sized tasks (2-5 minutes each). Every task has exact file paths, complete code, verification steps.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;subagent-driven-development&lt;/strong&gt; or &lt;strong&gt;executing-plans&lt;/strong&gt; - Activates with plan. Dispatches fresh subagent per task with two-stage review (spec compliance, then code quality), or executes in batches with human checkpoints.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;test-driven-development&lt;/strong&gt; - Activates during implementation. Enforces RED-GREEN-REFACTOR: write failing test, watch it fail, write minimal code, watch it pass, commit. Deletes code written before tests.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;requesting-code-review&lt;/strong&gt; - Activates between tasks. Reviews against plan, reports issues by severity. Critical issues block progress.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;finishing-a-development-branch&lt;/strong&gt; - Activates when tasks complete. Verifies tests, presents options (merge/PR/keep/discard), cleans up worktree.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;The agent checks for relevant skills before any task.&lt;/strong&gt; Mandatory workflows, not suggestions.&lt;/p&gt; 
&lt;h2&gt;What's Inside&lt;/h2&gt; 
&lt;h3&gt;Skills Library&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;test-driven-development&lt;/strong&gt; - RED-GREEN-REFACTOR cycle (includes testing anti-patterns reference)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Debugging&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;systematic-debugging&lt;/strong&gt; - 4-phase root cause process (includes root-cause-tracing, defense-in-depth, condition-based-waiting techniques)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;verification-before-completion&lt;/strong&gt; - Ensure it's actually fixed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Collaboration&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;brainstorming&lt;/strong&gt; - Socratic design refinement&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;writing-plans&lt;/strong&gt; - Detailed implementation plans&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;executing-plans&lt;/strong&gt; - Batch execution with checkpoints&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;dispatching-parallel-agents&lt;/strong&gt; - Concurrent subagent workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;requesting-code-review&lt;/strong&gt; - Pre-review checklist&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;receiving-code-review&lt;/strong&gt; - Responding to feedback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;using-git-worktrees&lt;/strong&gt; - Parallel development branches&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;finishing-a-development-branch&lt;/strong&gt; - Merge/PR decision workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;subagent-driven-development&lt;/strong&gt; - Fast iteration with two-stage review (spec compliance, then code quality)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Meta&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;writing-skills&lt;/strong&gt; - Create new skills following best practices (includes testing methodology)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;using-superpowers&lt;/strong&gt; - Introduction to the skills system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Test-Driven Development&lt;/strong&gt; - Write tests first, always&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Systematic over ad-hoc&lt;/strong&gt; - Process over guessing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complexity reduction&lt;/strong&gt; - Simplicity as primary goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evidence over claims&lt;/strong&gt; - Verify before declaring success&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more: &lt;a href="https://blog.fsck.com/2025/10/09/superpowers/"&gt;Superpowers for Claude Code&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Skills live directly in this repository. To contribute:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a branch for your skill&lt;/li&gt; 
 &lt;li&gt;Follow the &lt;code&gt;writing-skills&lt;/code&gt; skill for creating and testing new skills&lt;/li&gt; 
 &lt;li&gt;Submit a PR&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;code&gt;skills/writing-skills/SKILL.md&lt;/code&gt; for the complete guide.&lt;/p&gt; 
&lt;h2&gt;Updating&lt;/h2&gt; 
&lt;p&gt;Skills update automatically when you update the plugin:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin update superpowers
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License - see LICENSE file for details&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/obra/superpowers/issues"&gt;https://github.com/obra/superpowers/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Marketplace&lt;/strong&gt;: &lt;a href="https://github.com/obra/superpowers-marketplace"&gt;https://github.com/obra/superpowers-marketplace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-code</title>
      <link>https://github.com/anthropics/claude-code</link>
      <description>&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square" alt="" /&gt; &lt;a href="https://www.npmjs.com/package/@anthropic-ai/claude-code"&gt;&lt;img src="https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square" alt="npm" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn more in the &lt;a href="https://code.claude.com/docs/en/overview"&gt;official documentation&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/anthropics/claude-code/main/demo.gif" /&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Installation via npm is deprecated. Use one of the recommended methods below.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more installation options, uninstall steps, and troubleshooting, see the &lt;a href="https://code.claude.com/docs/en/setup"&gt;setup documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install Claude Code:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;MacOS/Linux (Recommended):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://claude.ai/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Homebrew (MacOS/Linux):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;brew install --cask claude-code
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Windows (Recommended):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://claude.ai/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;WinGet (Windows):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;winget install Anthropic.ClaudeCode
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NPM (Deprecated):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g @anthropic-ai/claude-code
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to your project directory and run &lt;code&gt;claude&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;This repository includes several Claude Code plugins that extend functionality with custom commands and agents. See the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-code/main/plugins/README.md"&gt;plugins directory&lt;/a&gt; for detailed documentation on available plugins.&lt;/p&gt; 
&lt;h2&gt;Reporting Bugs&lt;/h2&gt; 
&lt;p&gt;We welcome your feedback. Use the &lt;code&gt;/bug&lt;/code&gt; command to report issues directly within Claude Code, or file a &lt;a href="https://github.com/anthropics/claude-code/issues"&gt;GitHub issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Connect on Discord&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://anthropic.com/discord"&gt;Claude Developers Discord&lt;/a&gt; to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.&lt;/p&gt; 
&lt;h2&gt;Data collection, usage, and retention&lt;/h2&gt; 
&lt;p&gt;When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the &lt;code&gt;/bug&lt;/code&gt; command.&lt;/p&gt; 
&lt;h3&gt;How we use your data&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://code.claude.com/docs/en/data-usage"&gt;data usage policies&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Privacy safeguards&lt;/h3&gt; 
&lt;p&gt;We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.&lt;/p&gt; 
&lt;p&gt;For full details, please review our &lt;a href="https://www.anthropic.com/legal/commercial-terms"&gt;Commercial Terms of Service&lt;/a&gt; and &lt;a href="https://www.anthropic.com/legal/privacy"&gt;Privacy Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MiroMindAI/MiroThinker</title>
      <link>https://github.com/MiroMindAI/MiroThinker</link>
      <description>&lt;p&gt;MiroThinker is an open-source search agent model, built for tool-augmented reasoning and real-world information seeking, aiming to match the deep research experience of OpenAI Deep Research and Gemini Deep Research.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/assets/miro_thinker.png" width="55%" alt="MiroThinker" /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://dr.miromind.ai/"&gt;&lt;img src="https://img.shields.io/badge/Demo-FFB300?style=for-the-badge&amp;amp;logo=airplayvideo&amp;amp;logoColor=white" alt="DEMO" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v15"&gt;&lt;img src="https://img.shields.io/badge/Models-5EDDD2?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="MODELS" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2511.11793"&gt;&lt;img src="https://img.shields.io/badge/Paper-B31B1B?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white" alt="Paper" /&gt;&lt;/a&gt; &lt;a href="https://miromind.ai/#blog"&gt;&lt;img src="https://img.shields.io/badge/Blog-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="Blog" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"&gt;&lt;img src="https://img.shields.io/badge/Data-0040A1?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="DATA" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/MiroMindAI"&gt;&lt;img src="https://img.shields.io/badge/Github-24292F?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GITHUB" /&gt;&lt;/a&gt; &lt;a href="https://miromind.ai/"&gt;&lt;img src="https://img.shields.io/badge/Website-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="WEBSITE" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/GPqEnkzQZd"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="DISCORD" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/refs/heads/main/assets/miromind_wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white" alt="WeChat" /&gt;&lt;/a&gt; &lt;a href="https://www.xiaohongshu.com/user/profile/5e353bd80000000001000239"&gt;&lt;img src="https://img.shields.io/badge/RedNote-FF2442?style=for-the-badge&amp;amp;logo=revoltdotchat&amp;amp;logoColor=white" alt="RedNote" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üöÄ &lt;a href="https://dr.miromind.ai/"&gt;Try our Demo!&lt;/a&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;MiroThinker&lt;/strong&gt; is MiroMind's Flagship Research Agent Model. It is an open-source search model designed to advance tool-augmented reasoning and information-seeking capabilities, enabling complex real-world research workflows across diverse challenges.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The project currently comprises four key components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí° &lt;strong&gt;MiroThinker&lt;/strong&gt;: An open-source search &lt;strong&gt;model&lt;/strong&gt; that natively supports tool-assisted reasoning, achieving leading performance across multiple benchmarks (e.g., HLE, HLE-Text-2158, HLE-Text-500, BrowseComp, BrowseComp-ZH, GAIA, XBench-DeepSearch, FutureX, and Frames). See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-quick-start"&gt;Quick Start&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;MiroFlow&lt;/strong&gt;: An open-source research agent framework that offers reproducible state-of-the-art performance across multiple benchmarks. See &lt;a href="https://github.com/MiroMindAI/MiroFlow"&gt;MiroFlow&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;MiroVerse&lt;/strong&gt;: A premium open-source training dataset with 147k samples supporting research agent training. See &lt;a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"&gt;MiroVerse&lt;/a&gt; on HuggingFace.&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;MiroTrain / MiroRL&lt;/strong&gt;: Training infrastructure that supports stable and efficient training for research agent models. See &lt;a href="https://github.com/MiroMindAI/MiroTrain"&gt;MiroTrain&lt;/a&gt; and &lt;a href="https://github.com/MiroMindAI/MiroRL"&gt;MiroRL&lt;/a&gt; for details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìã Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üì∞ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-news--updates"&gt;News &amp;amp; Updates&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìù &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-performance-on-benchmarks"&gt;Performance on Benchmarks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìä &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-benchmark-evaluation"&gt;Benchmark Evaluation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî¨ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-trace-collection"&gt;Trace Collection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ùì &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-faq--troubleshooting"&gt;FAQ &amp;amp; Troubleshooting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìÑ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üôè &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì∞ News &amp;amp; Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;[2026-01-05]&lt;/strong&gt; üéâüéâ We release &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v15"&gt;MiroThinker-v1.5&lt;/a&gt;, a world-leading open-source search agent. &lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-30B"&gt;MiroThinker-v1.5-30B&lt;/a&gt; surpasses Kimi-K2-Thinking on BrowseComp-ZH at much lower cost, using only 1/30 of the parameters. &lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-235B"&gt;MiroThinker-v1.5-235B&lt;/a&gt; scores 39.2% on HLE-Text, 69.8% on BrowseComp, 71.5% on BrowseComp-ZH, and 80.8% on GAIA-Val-165, setting a new state-of-the-art among search agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-11-13]&lt;/strong&gt; üéâ &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v10"&gt;MiroThinker-v1.0&lt;/a&gt; is now released! Introducing &lt;strong&gt;interactive scaling&lt;/strong&gt; as a third dimension of performance improvement, MiroThinker v1.0 supports 256K context window and up to 600 tool calls per task. Available in 8B, 30B, and 72B parameter scales, achieving 37.7%, 47.1%, 55.6%, and 81.9% on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Text-103, respectively. See &lt;a href="https://arxiv.org/abs/2511.11793"&gt;Technical Report&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-09-11]&lt;/strong&gt; MiroThinker-72B-Preview ranked 4th in this week's FutureX benchmark. See &lt;a href="https://futurex-ai.github.io/"&gt;FutureX&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìú Click to expand older updates&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-09-08]&lt;/strong&gt; &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v02"&gt;MiroThinker-v0.2&lt;/a&gt; is now released, achieving open-source SOTA performance across multiple benchmarks, including HLE (17.8%), HLE-Text-Only (19.1%), BrowseComp-EN (17.2%), BrowseComp-ZH (29.4%), XBench-DeepSearch (56.0%), and Frames (74.8%).&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-09-07]&lt;/strong&gt; We supported more benchmarks, including &lt;a href="https://arxiv.org/abs/2504.19314"&gt;BrowseComp-ZH&lt;/a&gt;, &lt;a href="https://xbench.org/agi/aisearch"&gt;XBench-DeepSearch&lt;/a&gt;, and &lt;a href="https://futurex-ai.github.io/"&gt;FutureX&lt;/a&gt;. We plan to add more benchmarks in the future.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-08-22]&lt;/strong&gt; Introducing streamlined deployment options for MiroThinker models with optimized resource usage and faster startup times. Experience the interactive demo: &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/apps/gradio-demo"&gt;üöÄ Try Gradio Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-08-08]&lt;/strong&gt; &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v01-689301b6d0563321862d44a1"&gt;MiroThinker-v0.1&lt;/a&gt; released. Models, framework, and data are now fully open-sourced!&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üìù Introduction&lt;/h2&gt; 
&lt;h3&gt;MiroThinker-v1.5&lt;/h3&gt; 
&lt;p&gt;MiroThinker v1.5 is the world-leading open-source search agent that advances tool-augmented reasoning through &lt;strong&gt;interactive scaling&lt;/strong&gt; ‚Äî training the model to handle deeper and more frequent agent-environment interactions as a third dimension of performance improvement, beyond model size and context length.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/mirothinker_v1.5_framework.png" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ MiroThinker v1.5 supports a 256K context window, long-horizon reasoning, and deep multi-step analysis.&lt;/li&gt; 
 &lt;li&gt;üîß Handles up to 400 tool calls per task ‚Äî a substantial improvement over previous open-source research agents.&lt;/li&gt; 
 &lt;li&gt;üì¶ Released in 30B and 235B parameter scales, accompanied by a comprehensive suite of tools and workflows to flexibly support diverse research settings and compute budgets.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;Model Name&lt;/th&gt; 
    &lt;th align="center"&gt;Base Model&lt;/th&gt; 
    &lt;th align="center"&gt;Max Context&lt;/th&gt; 
    &lt;th align="center"&gt;Max Tool Calls&lt;/th&gt; 
    &lt;th align="center"&gt;HF Link&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;MiroThinker-v1.5-30B&lt;/td&gt; 
    &lt;td align="center"&gt;Qwen3-30B-A3B-Thinking-2507&lt;/td&gt; 
    &lt;td align="center"&gt;256K&lt;/td&gt; 
    &lt;td align="center"&gt;400&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-30B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;MiroThinker-v1.5-235B&lt;/td&gt; 
    &lt;td align="center"&gt;Qwen3-235B-A22B-Thinking-2507&lt;/td&gt; 
    &lt;td align="center"&gt;256K&lt;/td&gt; 
    &lt;td align="center"&gt;400&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-235B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;MiroThinker v1.5 demonstrates strong general-research performance across a broad range of benchmarks, achieving&amp;nbsp;39.2%,&amp;nbsp;69.8%, 71.5%, and&amp;nbsp;80.8%&amp;nbsp;on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Val-165, respectively. These results surpass previous open-source agents and set the new world-leading BrowseComp performance.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/mirothinker_v1.5_browsecomp.png" alt="image" /&gt;&lt;/p&gt; 
&lt;h3&gt;MiroThinker-v1.0&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v1.0 details&lt;/summary&gt; 
 &lt;p&gt;Unlike previous agents that scale only model size or context length, MiroThinker v1.0 introduces &lt;strong&gt;interactive scaling&lt;/strong&gt; at the model level, systematically training the model to handle deeper and more frequent agent‚Äìenvironment interactions as a third dimension of performance improvement. Interactive scaling leverages environment feedback and external information acquisition to correct errors and refine trajectories.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v1.0_Overall.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;‚ú® Key Features&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üöÄ &lt;strong&gt;256K Context Window&lt;/strong&gt;: Supports long-horizon reasoning and deep multi-step analysis&lt;/li&gt; 
  &lt;li&gt;üîß &lt;strong&gt;600 Tool Calls&lt;/strong&gt;: Handles up to 600 tool calls per task ‚Äî a substantial improvement over previous open-source research agents&lt;/li&gt; 
  &lt;li&gt;üì¶ &lt;strong&gt;Multiple Scales&lt;/strong&gt;: Released in 8B, 30B, and 72B parameter scales, accompanied by a comprehensive suite of tools and workflows to flexibly support diverse research settings and compute budgets&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="center"&gt;Model Name&lt;/th&gt; 
     &lt;th align="center"&gt;Base Model&lt;/th&gt; 
     &lt;th align="center"&gt;Max Context&lt;/th&gt; 
     &lt;th align="center"&gt;Max Tool Calls&lt;/th&gt; 
     &lt;th align="center"&gt;HF Link&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-v1.0-8B&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;256K&lt;/td&gt; 
     &lt;td align="center"&gt;600&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-8B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-v1.0-30B&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-30B-A3B-Thinking-2507&lt;/td&gt; 
     &lt;td align="center"&gt;256K&lt;/td&gt; 
     &lt;td align="center"&gt;600&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-30B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-v1.0-72B&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen2.5-72B-Instruct&lt;/td&gt; 
     &lt;td align="center"&gt;256K&lt;/td&gt; 
     &lt;td align="center"&gt;600&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-72B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;p&gt;MiroThinker v1.0 demonstrates strong general-research performance across a broad range of benchmarks, achieving &lt;strong&gt;37.7%&lt;/strong&gt;, &lt;strong&gt;47.1%&lt;/strong&gt;, &lt;strong&gt;55.6%&lt;/strong&gt;, and &lt;strong&gt;81.9%&lt;/strong&gt; on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Text-103, respectively. These results surpass previous open-source agents and narrow the gap with commercial counterparts such as &lt;strong&gt;GPT-5-high&lt;/strong&gt;.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v1.0_Performance_1.png" width="100%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.2&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.2 details&lt;/summary&gt; 
 &lt;p&gt;In this new version, we introduced three key improvements:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üìö &lt;strong&gt;Richer training data&lt;/strong&gt; from both English and Chinese sources, yielding significant gains in benchmark performance and generalization&lt;/li&gt; 
  &lt;li&gt;üéØ &lt;strong&gt;Unified DPO training&lt;/strong&gt; with a single preference dataset across all models&lt;/li&gt; 
  &lt;li&gt;üìè &lt;strong&gt;Extended context length&lt;/strong&gt; from 40k to 64k for more challenging multi-turn tool-use tasks&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Compared to v0.1, MiroThinker v0.2 delivers consistent gains across benchmarks. For example, scores improved from &lt;strong&gt;57.3 ‚Üí 64.1&lt;/strong&gt; on &lt;strong&gt;GAIA-Text-103&lt;/strong&gt; and from &lt;strong&gt;17.0 ‚Üí 29.4&lt;/strong&gt; on &lt;strong&gt;BrowseComp-ZH&lt;/strong&gt;, reflecting substantial advancements in the model‚Äôs general research agent capabilities.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="center"&gt;Model Name&lt;/th&gt; 
     &lt;th align="center"&gt;Base Model&lt;/th&gt; 
     &lt;th align="center"&gt;Max Context&lt;/th&gt; 
     &lt;th align="center"&gt;HF Link&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-4B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-4B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-4B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-4B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-4B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-4B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.1&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.1 details&lt;/summary&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/assets/gaia_text_103.png" width="98%" alt="MiroFlow Performance on GAIA-Validation" /&gt; 
  &lt;p&gt;&lt;strong&gt;Performance of Open-Source Models on GAIA-Validation Benchmark.&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;We have released the &lt;strong&gt;MiroThinker v0.1&lt;/strong&gt; series, including both SFT and DPO variants at parameter scales of &lt;strong&gt;8B&lt;/strong&gt;, &lt;strong&gt;14B&lt;/strong&gt;, and &lt;strong&gt;32B&lt;/strong&gt;. Notably, MiroThinker v0.1 achieves &lt;strong&gt;state-of-the-art performance&lt;/strong&gt; among open-source models on the &lt;a href="https://huggingface.co/datasets/gaia-benchmark/GAIA"&gt;GAIA benchmark&lt;/a&gt;, a rigorous evaluation suite for advanced agentic capabilities, demonstrating its strength in long-context, decision-intensive, and real-world task scenarios.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="center"&gt;Model Name&lt;/th&gt; 
     &lt;th align="center"&gt;Base Model&lt;/th&gt; 
     &lt;th align="center"&gt;Max Context&lt;/th&gt; 
     &lt;th align="center"&gt;HF Link&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-SFT-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-SFT-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-DPO-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-DPO-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-SFT-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-SFT-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-DPO-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-DPO-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-SFT-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-SFT-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-DPO-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-DPO-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ú® Key Features&lt;/h2&gt; 
&lt;h3&gt;ü§ñ &lt;strong&gt;MiroThinker-Optimized Framework&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîì &lt;strong&gt;Fully Open-Source Agent Framework&lt;/strong&gt;: Complete transparency with open framework and open models&lt;/li&gt; 
 &lt;li&gt;üîó &lt;strong&gt;Tool Integration&lt;/strong&gt;: Seamless integration with external tools and APIs&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;Trace Collection&lt;/strong&gt;: Comprehensive logging and analysis of agent interactions with elapsed time and estimated completion time displayed in minutes. Ready for SFT and DPO&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Benchmark Evaluation&lt;/strong&gt;: Extensive testing across multiple benchmark datasets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìä &lt;strong&gt;Comprehensive Benchmark Suite&lt;/strong&gt;&lt;/h3&gt; 
&lt;details open&gt; 
 &lt;summary&gt;üìã Click to expand benchmark list&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;GAIA Validation&lt;/strong&gt;: A benchmark for General AI Assistants. (&lt;a href="https://arxiv.org/abs/2311.12983"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GAIA-Text-103&lt;/strong&gt;: A subset of GAIA Validation for text-only tasks. (&lt;a href="https://arxiv.org/abs/2505.22648"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HLE&lt;/strong&gt;: Humanity's Last Exam. (&lt;a href="https://arxiv.org/abs/2501.14249"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HLE-Text-2158&lt;/strong&gt;: A subset of HLE for text-only tasks. (&lt;a href="https://arxiv.org/abs/2501.14249"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HLE-Text-500&lt;/strong&gt;: A subset of HLE for text-only tasks, created by &lt;a href="https://arxiv.org/pdf/2504.21776"&gt;WebThinker&lt;/a&gt;. (&lt;a href="https://arxiv.org/pdf/2504.21776"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;BrowseComp-EN&lt;/strong&gt;: Web browsing and comprehension tasks. (&lt;a href="https://arxiv.org/abs/2504.12516"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;BrowseComp-ZH&lt;/strong&gt;: A Chinese version of BrowseComp. (&lt;a href="https://arxiv.org/abs/2504.19314"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;WebWalkerQA&lt;/strong&gt;: Web navigation and question answering. (&lt;a href="https://arxiv.org/abs/2501.07572"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Frames&lt;/strong&gt;: Factuality, Retrieval, And reasoning MEasurement Set. (&lt;a href="https://arxiv.org/abs/2409.12941"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;XBench-DeepSearch&lt;/strong&gt;: A benchmark for deep research agents. (&lt;a href="https://xbench.org/agi/aisearch"&gt;website&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;FutureX&lt;/strong&gt;: A live benchmark designed for predicting unknown future. (&lt;a href="https://futurex-ai.github.io/"&gt;website&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;SEAL-0&lt;/strong&gt;: A benchmark for evaluating LLMs on conflicting-evidence web questions. (&lt;a href="https://arxiv.org/abs/2506.01062"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;AIME2025&lt;/strong&gt;: American Invitational Mathematics Examination 2025. (&lt;a href="https://artificialanalysis.ai/evaluations/aime-2025"&gt;website&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;DeepSearchQA&lt;/strong&gt;: Google's Deep Search Question Answering benchmark. (&lt;a href="https://arxiv.org/abs/2505.20827"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üìà Performance on Benchmarks&lt;/h2&gt; 
&lt;h3&gt;MiroThinker-v1.5&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To prevent potential information leakage (e.g., searching benchmark answers from HuggingFace), access to HuggingFace has been explicitly disabled in these tools.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We further perform canary string testing on the tool outputs of all trajectories and disregard any trajectory found to be contaminated, treating it as an incorrect answer.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div&gt; 
 &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/mirothinker_v1.5_performance.png" width="100%" alt="MiroThinker" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;MiroThinker-v1.0&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v1.0 details&lt;/summary&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://github.com/user-attachments/assets/108a2105-4e1d-499e-a001-4713a03fd8ac" width="100%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.2&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.2 details&lt;/summary&gt; 
 &lt;h4&gt;Comparison with SOTA Research Agents&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v0.2_Performance_2.png" width="90%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;GAIA Benchmark&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v0.2_Performance_1.png" width="80%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.1&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.1 details&lt;/summary&gt; 
 &lt;h4&gt;GAIA Benchmark&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;&lt;strong&gt;Method&lt;/strong&gt;&lt;/th&gt; 
     &lt;th align="center"&gt;Text-103&lt;br /&gt;Best Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;Text-103&lt;br /&gt;Pass@1 (Avg@8)&lt;/th&gt; 
     &lt;th align="center"&gt;Val-165&lt;br /&gt;Best Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;Val-165&lt;br /&gt;Pass@1 (Avg@8)&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;üîπ‚Äî‚Äî 7B/8B Models ‚Äî‚Äî&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Search-o1-7B&lt;/td&gt; 
     &lt;td align="center"&gt;17.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;R1-Searcher-7B&lt;/td&gt; 
     &lt;td align="center"&gt;20.4&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-7B&lt;/td&gt; 
     &lt;td align="center"&gt;31.0&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-7B&lt;/td&gt; 
     &lt;td align="center"&gt;37.9&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;CK-Pro-8B&lt;/td&gt; 
     &lt;td align="center"&gt;40.3&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;32.7&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;44.7&lt;/td&gt; 
     &lt;td align="center"&gt;40.1&lt;/td&gt; 
     &lt;td align="center"&gt;34.6&lt;/td&gt; 
     &lt;td align="center"&gt;31.8&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;46.6&lt;/td&gt; 
     &lt;td align="center"&gt;42.1&lt;/td&gt; 
     &lt;td align="center"&gt;37.6&lt;/td&gt; 
     &lt;td align="center"&gt;33.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;46.6&lt;/td&gt; 
     &lt;td align="center"&gt;44.8&lt;/td&gt; 
     &lt;td align="center"&gt;37.0&lt;/td&gt; 
     &lt;td align="center"&gt;35.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;50.5&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;46.7&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;38.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;35.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;üîπ‚Äî‚Äî 14B Models ‚Äî‚Äî&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-14B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;47.6&lt;/td&gt; 
     &lt;td align="center"&gt;44.4&lt;/td&gt; 
     &lt;td align="center"&gt;37.0&lt;/td&gt; 
     &lt;td align="center"&gt;34.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;49.5&lt;/td&gt; 
     &lt;td align="center"&gt;47.5&lt;/td&gt; 
     &lt;td align="center"&gt;41.8&lt;/td&gt; 
     &lt;td align="center"&gt;39.8&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-14B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;46.6&lt;/td&gt; 
     &lt;td align="center"&gt;42.4&lt;/td&gt; 
     &lt;td align="center"&gt;39.2&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;52.4&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;48.5&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;45.5&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;42.0&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;üîπ‚Äî‚Äî 32B Models ‚Äî‚Äî&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;31.1&lt;/td&gt; 
     &lt;td align="center"&gt;26.7&lt;/td&gt; 
     &lt;td align="center"&gt;29.7&lt;/td&gt; 
     &lt;td align="center"&gt;26.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Search-o1-32B&lt;/td&gt; 
     &lt;td align="center"&gt;28.2&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebThinker-32B-RL&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-QwQ-32B&lt;/td&gt; 
     &lt;td align="center"&gt;51.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-32B&lt;/td&gt; 
     &lt;td align="center"&gt;53.2&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebShaper-QwQ-32B&lt;/td&gt; 
     &lt;td align="center"&gt;53.3&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;55.3&lt;/td&gt; 
     &lt;td align="center"&gt;51.3&lt;/td&gt; 
     &lt;td align="center"&gt;44.9&lt;/td&gt; 
     &lt;td align="center"&gt;42.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;58.3&lt;/td&gt; 
     &lt;td align="center"&gt;54.2&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;45.8&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;57.3&lt;/td&gt; 
     &lt;td align="center"&gt;54.1&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;45.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;60.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;57.9&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;50.9&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;48.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Following the practices of WebThinker, WebAgents, and CognitiveKernel, we report the Best Pass@1, the highest score across three runs, which often reflects stronger performance, though it may exhibit some variability. To provide a more stable measure, we additionally report Pass@1 (Avg@8), which offers greater consistency at the cost of slightly lower scores.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;For consistency with prior open-source works, we evaluate GAIA-Text-103 using the WebAgents LLM-as-a-Judge template, and report results on GAIA-Val-165 using the official GAIA scorer script.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;By default, we use open-source tools wherever possible, except for the code tool &lt;a href="https://github.com/e2b-dev/E2B"&gt;E2B&lt;/a&gt; and the Google search tool &lt;a href="https://serper.dev/"&gt;Serper&lt;/a&gt;. We use &lt;a href="https://huggingface.co/openai/whisper-large-v3-turbo"&gt;Whisper&lt;/a&gt;, &lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct"&gt;Qwen2.5-VL-72B-Instruct&lt;/a&gt;, and &lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507"&gt;Qwen3-235B-A22B-Thinking-2507&lt;/a&gt; in our implementation. The framework can be easily extended to other open-source tools of your choice.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Replacing these open-source tools with commercial alternatives can yield performance gains. Commercial tools were mainly used for multimodal capabilities and certain complex reasoning subtasks. The majority of tasks, including planning, browsing, refinement, navigation, and more, were handled by our models.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;More Benchmarks&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;Method&lt;/th&gt; 
     &lt;th align="center"&gt;HLE&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;Frames&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;BrowseComp&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;BrowseComp-ZH&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;WebWalkerQA&lt;br /&gt;Pass@1&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;OpenAI Deep Research&lt;/td&gt; 
     &lt;td align="center"&gt;26.6&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;51.5&lt;/td&gt; 
     &lt;td align="center"&gt;42.9&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Gemini Deep Research&lt;/td&gt; 
     &lt;td align="center"&gt;26.9&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Kimi-Researcher&lt;/td&gt; 
     &lt;td align="center"&gt;26.9&lt;/td&gt; 
     &lt;td align="center"&gt;78.8&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-7B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;36.0&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-7B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;6.7&lt;/td&gt; 
     &lt;td align="center"&gt;14.2&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;58.0&lt;/td&gt; 
     &lt;td align="center"&gt;5.5&lt;/td&gt; 
     &lt;td align="center"&gt;9.3&lt;/td&gt; 
     &lt;td align="center"&gt;41.3&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;64.4&lt;/td&gt; 
     &lt;td align="center"&gt;8.7&lt;/td&gt; 
     &lt;td align="center"&gt;13.6&lt;/td&gt; 
     &lt;td align="center"&gt;45.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebThinker-32B-RL&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;46.5&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-QwQ-32B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;3.8&lt;/td&gt; 
     &lt;td align="center"&gt;18.0&lt;/td&gt; 
     &lt;td align="center"&gt;47.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-32B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;10.5&lt;/td&gt; 
     &lt;td align="center"&gt;25.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebShaper-32B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;51.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;10.2&lt;/td&gt; 
     &lt;td align="center"&gt;70.4&lt;/td&gt; 
     &lt;td align="center"&gt;10.6&lt;/td&gt; 
     &lt;td align="center"&gt;13.8&lt;/td&gt; 
     &lt;td align="center"&gt;45.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;11.8&lt;/td&gt; 
     &lt;td align="center"&gt;71.7&lt;/td&gt; 
     &lt;td align="center"&gt;13.0&lt;/td&gt; 
     &lt;td align="center"&gt;17.0&lt;/td&gt; 
     &lt;td align="center"&gt;49.3&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;MiroThinker‚Äôs performance was tested with this repository and open-source tools; other models‚Äô results are from their papers and official sites.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;As &lt;a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"&gt;MiroVerse-v0.1&lt;/a&gt; mainly contains English data, the model‚Äôs Chinese capability is limited. We plan to add more Chinese data to improve performance in the next version.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêç &lt;strong&gt;Python 3.10+&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;üì¶ &lt;strong&gt;uv package manager&lt;/strong&gt; (&lt;a href="https://github.com/astral-sh/uv"&gt;Installation guide&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üîë &lt;strong&gt;Required API keys&lt;/strong&gt; (see configuration section below)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/MiroMindAI/MiroThinker
cd MiroThinker

# Setup environment
cd apps/miroflow-agent
uv sync

# Configure API keys
cp .env.example .env
# Edit .env with your API keys (SERPER_API_KEY, JINA_API_KEY, E2B_API_KEY, etc.)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìù Environment Variables&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#tool-configuration"&gt;Tool Configuration&lt;/a&gt; section for required API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Tool Configuration&lt;/h3&gt; 
&lt;h4&gt;Minimal Configuration for MiroThinker v1.5 and v1.0&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Server&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Tools Provided&lt;/th&gt; 
   &lt;th align="left"&gt;Required Environment Variables&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;tool-python&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Execution environment and file management (E2B sandbox)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;create_sandbox&lt;/code&gt;, &lt;code&gt;run_command&lt;/code&gt;, &lt;code&gt;run_python_code&lt;/code&gt;, &lt;code&gt;upload_file_from_local_to_sandbox&lt;/code&gt;, &lt;code&gt;download_file_from_sandbox_to_local&lt;/code&gt;, &lt;code&gt;download_file_from_internet_to_sandbox&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;E2B_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;search_and_scrape_webpage&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Google search via Serper API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;google_search&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;jina_scrape_llm_summary&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Web scraping with LLM-based information extraction&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;scrape_and_extract_info&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_BASE_URL&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_MODEL_NAME&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Minimal &lt;code&gt;.env&lt;/code&gt; configuration example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Required for MiroThinker v1.5 and v1.0 (minimal setup)
SERPER_API_KEY=your_serper_key
SERPER_BASE_URL="https://google.serper.dev"
JINA_API_KEY=your_jina_key
JINA_BASE_URL="https://r.jina.ai"
E2B_API_KEY=your_e2b_key

# Required for jina_scrape_llm_summary
# Note: Summary LLM can be a small model (e.g., Qwen3-14B or GPT-5-Nano)
# The choice has minimal impact on performance, use what's most convenient
SUMMARY_LLM_BASE_URL="https://your_summary_llm_base_url/v1/chat/completions"
SUMMARY_LLM_MODEL_NAME=your_llm_model_name  # e.g., "Qwen/Qwen3-14B" or "gpt-5-nano"
SUMMARY_LLM_API_KEY=your_llm_api_key  # Optional, depends on LLM provider

# Required for benchmark evaluation (LLM-as-a-Judge)
OPENAI_API_KEY=your_openai_key  # Required for running benchmark evaluations
OPENAI_BASE_URL="https://api.openai.com/v1"  # Optional, defaults to OpenAI's API
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Why this is minimal&lt;/strong&gt;: These 3 MCP servers cover the core capabilities needed for research tasks: web search, content extraction, and code execution. All other servers are optional enhancements.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ü§ñ Summary LLM&lt;/strong&gt;: The &lt;code&gt;SUMMARY_LLM&lt;/code&gt; can be a small model like Qwen3-14B or GPT-5-Nano. The choice has minimal impact on overall performance, use whichever is most convenient for your setup.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üìä For Benchmark Evaluation&lt;/strong&gt;: If you plan to run benchmark evaluations, you also need &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; (and optionally &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt;) for LLM-as-a-Judge functionality used in evaluation scripts.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üñºÔ∏è For GAIA Multimodal Tasks&lt;/strong&gt;: GAIA-Val-165 includes tasks with image/audio/video files. Since MiroThinker is a text-only LLM, GPT-4o is used to pre-process these files into text descriptions. The same &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is used for both this preprocessing and LLM-as-a-Judge.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üìñ For more details&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/libs/miroflow-tools/README.md"&gt;MiroFlow Tools README&lt;/a&gt; for complete documentation of all available tools.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Click to expand additional available tools&lt;/summary&gt; 
 &lt;p&gt;The following optional tools are available but were not used in MiroThinker v1.5 and v1.0 evaluation:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Server Name&lt;/th&gt; 
    &lt;th align="left"&gt;Type&lt;/th&gt; 
    &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-vqa&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Vision processing using Claude&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-vqa-os&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Vision processing (open-source alternative)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-transcribe&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Audio transcription using OpenAI&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-transcribe-os&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Audio transcription using Whisper&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-reasoning&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Reasoning engine using Claude&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-reasoning-os&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Reasoning engine (open-source alternative)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-reading&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Document reading using MarkItDown&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-google-search&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Web search using Google + scraping&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-sogou-search&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Web search using Sogou (Chinese)&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;üìñ Local Deployment&lt;/strong&gt;: For instructions on deploying open-source tools (&lt;code&gt;tool-vqa-os&lt;/code&gt;, &lt;code&gt;tool-transcribe-os&lt;/code&gt;, &lt;code&gt;tool-reasoning-os&lt;/code&gt;) locally, see &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/assets/LOCAL-TOOL-DEPLOYMENT.md"&gt;Local Tool Deployment Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/libs/miroflow-tools/README.md"&gt;MiroFlow Tools README&lt;/a&gt; for complete documentation of all available tools.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h4&gt;Pre-configured Agent Settings&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;apps/miroflow-agent/conf/agent/&lt;/code&gt; directory contains several pre-configured agent settings. Each configuration uses different tools and requires corresponding environment variables in your &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Recommended&lt;/strong&gt;: For MiroThinker v1.5, use &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; (with context management, recommended for most tasks) or &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (only used for BrowseComp and BrowseComp-ZH). For v1.0, use &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt; (with context management). All use minimal configuration with only 3 MCP servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Configuration&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Max Turns&lt;/th&gt; 
   &lt;th align="left"&gt;Context Retention&lt;/th&gt; 
   &lt;th align="left"&gt;Required Environment Variables&lt;/th&gt; 
   &lt;th align="left"&gt;Recommended For&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt;&lt;/strong&gt; ‚≠ê&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent with context management&lt;/td&gt; 
   &lt;td align="left"&gt;200&lt;/td&gt; 
   &lt;td align="left"&gt;Keep 5 most recent&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;, &lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;, &lt;code&gt;E2B_API_KEY&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_BASE_URL&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_MODEL_NAME&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.5 (recommended for most tasks)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt;&lt;/strong&gt; ‚≠ê&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent with context management&lt;/td&gt; 
   &lt;td align="left"&gt;400&lt;/td&gt; 
   &lt;td align="left"&gt;Keep 5 most recent&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.5 (for BrowseComp &amp;amp; BrowseComp-ZH)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.5&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent for MiroThinker v1.5&lt;/td&gt; 
   &lt;td align="left"&gt;600&lt;/td&gt; 
   &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.5&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent with context management&lt;/td&gt; 
   &lt;td align="left"&gt;600&lt;/td&gt; 
   &lt;td align="left"&gt;Keep 5 most recent&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.0&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.0&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent for MiroThinker v1.0&lt;/td&gt; 
   &lt;td align="left"&gt;600&lt;/td&gt; 
   &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.0&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand legacy configurations (v0.1/v0.2)&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Configuration&lt;/th&gt; 
    &lt;th align="left"&gt;Description&lt;/th&gt; 
    &lt;th align="left"&gt;Max Turns&lt;/th&gt; 
    &lt;th align="left"&gt;Context Retention&lt;/th&gt; 
    &lt;th align="left"&gt;Required Environment Variables&lt;/th&gt; 
    &lt;th align="left"&gt;Recommended For&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;multi_agent&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Multi-agent with commercial tools (v0.1/v0.2)&lt;/td&gt; 
    &lt;td align="left"&gt;50&lt;/td&gt; 
    &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;E2B_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_BASE_URL&lt;/code&gt;, &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt;, &lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;, &lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;v0.1/v0.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;multi_agent_os&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Multi-agent with open-source tools (v0.1/v0.2)&lt;/td&gt; 
    &lt;td align="left"&gt;50&lt;/td&gt; 
    &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;E2B_API_KEY&lt;/code&gt;, &lt;code&gt;VISION_API_KEY&lt;/code&gt;, &lt;code&gt;VISION_BASE_URL&lt;/code&gt;, &lt;code&gt;VISION_MODEL_NAME&lt;/code&gt;, &lt;code&gt;WHISPER_API_KEY&lt;/code&gt;, &lt;code&gt;WHISPER_BASE_URL&lt;/code&gt;, &lt;code&gt;WHISPER_MODEL_NAME&lt;/code&gt;, &lt;code&gt;REASONING_API_KEY&lt;/code&gt;, &lt;code&gt;REASONING_BASE_URL&lt;/code&gt;, &lt;code&gt;REASONING_MODEL_NAME&lt;/code&gt;, &lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;, &lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;v0.1/v0.2&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Note&lt;/strong&gt;: All environment variables are listed in &lt;code&gt;apps/miroflow-agent/.env.example&lt;/code&gt;. Copy it to &lt;code&gt;.env&lt;/code&gt; and fill in the values for the tools you plan to use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Creating Custom Tool Configurations&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Click to expand custom tool configuration guide&lt;/summary&gt; 
 &lt;p&gt;You can create your own YAML configuration file to freely combine MCP servers. Here's how:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Create a new YAML file&lt;/strong&gt; in &lt;code&gt;apps/miroflow-agent/conf/agent/&lt;/code&gt;:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# conf/agent/my_custom_config.yaml
defaults:
  - default
  - _self_

main_agent:
  tools:
    - tool-python                    # Execution environment
    - search_and_scrape_webpage      # Google search
    - jina_scrape_llm_summary        # Web scraping with LLM
    - tool-vqa                       # Vision processing (optional)
    - tool-transcribe                # Audio processing (optional)
    - tool-reasoning                 # Reasoning engine (optional)
    - tool-reading                   # Document reading (optional)
  max_turns: 400  # Maximum number of turns

sub_agents:
  agent-browsing:  # Optional sub-agent
    tools:
      - tool-google-search
      - tool-vqa
      - tool-reading
      - tool-python
    max_turns: 50

keep_tool_result: -1  # Context retention budget: -1 keeps all tool results, or specify K to keep only the K most recent tool responses
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;üí° Context Retention Strategy&lt;/strong&gt;: The &lt;code&gt;keep_tool_result&lt;/code&gt; parameter implements a &lt;strong&gt;recency-based context retention&lt;/strong&gt; strategy. In the standard ReAct paradigm, all tool outputs are retained in the message history, which can lead to inefficient context utilization. Empirically, we observe that the model's subsequent actions depend primarily on recent observations rather than distant ones. This strategy retains only the most recent K tool responses (where K is the &lt;code&gt;keep_tool_result&lt;/code&gt; value) while preserving the complete sequence of thoughts and actions.&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;Benefits:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‚úÖ Preserves the reasoning and action trace&lt;/li&gt; 
   &lt;li&gt;‚úÖ Focuses the model's attention on the most contextually relevant observations&lt;/li&gt; 
   &lt;li&gt;‚úÖ Frees additional context space for extended reasoning and deeper tool-use trajectories&lt;/li&gt; 
   &lt;li&gt;‚úÖ Does not lead to performance degradation while allowing more context space for interactive scaling&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Set &lt;code&gt;keep_tool_result: -1&lt;/code&gt; to keep all tool results, or specify a positive integer K (e.g., &lt;code&gt;keep_tool_result: 5&lt;/code&gt;) to keep only the K most recent tool responses.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;&lt;strong&gt;Use your custom configuration&lt;/strong&gt; when running evaluations:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent
uv run main.py llm=qwen-3 agent=my_custom_config llm.base_url=https://your_base_url/v1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure environment variables&lt;/strong&gt; in &lt;code&gt;.env&lt;/code&gt; based on the tools you use.&lt;/p&gt; &lt;p&gt;All available environment variables are listed in &lt;code&gt;apps/miroflow-agent/.env.example&lt;/code&gt;. Copy it to &lt;code&gt;.env&lt;/code&gt; and configure the variables according to your chosen configuration:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent
cp .env.example .env
# Edit .env with your actual API keys
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;For MiroThinker v1.5&lt;/strong&gt; (&lt;code&gt;mirothinker_v1.5_keep5_max200.yaml&lt;/code&gt;, &lt;code&gt;mirothinker_v1.5_keep5_max400.yaml&lt;/code&gt;, or &lt;code&gt;mirothinker_v1.5.yaml&lt;/code&gt;) and &lt;strong&gt;v1.0&lt;/strong&gt; (&lt;code&gt;mirothinker_v1.0_keep5.yaml&lt;/code&gt; or &lt;code&gt;mirothinker_v1.0.yaml&lt;/code&gt;), see the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#minimal-configuration-for-mirothinker-v15-and-v10"&gt;Minimal Configuration&lt;/a&gt; section above for the complete configuration example.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;For other configurations&lt;/strong&gt;, refer to the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#pre-configured-agent-settings"&gt;Pre-configured Agent Settings&lt;/a&gt; table above to see which environment variables are required.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîë Click to expand optional API keys&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# API for LLM-as-a-Judge (for benchmark testing, required for benchmark evaluation)
OPENAI_API_KEY=your_openai_key
OPENAI_BASE_URL="https://api.openai.com/v1"  # Optional, defaults to OpenAI's API

# API for Open-Source Audio Transcription Tool (for benchmark testing, optional)
WHISPER_MODEL_NAME="openai/whisper-large-v3-turbo"
WHISPER_API_KEY=your_whisper_key
WHISPER_BASE_URL="https://your_whisper_base_url/v1"

# API for Open-Source VQA Tool (for benchmark testing, optional)
VISION_MODEL_NAME="Qwen/Qwen2.5-VL-72B-Instruct"
VISION_API_KEY=your_vision_key
VISION_BASE_URL="https://your_vision_base_url/v1/chat/completions"

# API for Open-Source Reasoning Tool (for benchmark testing, optional)
REASONING_MODEL_NAME="Qwen/Qwen3-235B-A22B-Thinking-2507"
REASONING_API_KEY=your_reasoning_key
REASONING_BASE_URL="https://your_reasoning_base_url/v1/chat/completions"

# API for Claude Sonnet 3.7 as Commercial Tools (optional)
ANTHROPIC_API_KEY=your_anthropic_key

# API for Sogou Search (optional)
TENCENTCLOUD_SECRET_ID=your_tencent_cloud_secret_id
TENCENTCLOUD_SECRET_KEY=your_tencent_cloud_secret_key

# API for Summary LLM (can use small models like Qwen3-14B or GPT-5-Nano)
SUMMARY_LLM_BASE_URL="https://your_summary_llm_base_url/v1/chat/completions"
SUMMARY_LLM_MODEL_NAME=your_summary_llm_model_name  # e.g., "Qwen/Qwen3-14B" or "gpt-5-nano"
SUMMARY_LLM_API_KEY=your_summary_llm_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Serve the MiroThinker Model&lt;/h3&gt; 
&lt;h4&gt;Option 1 (Recommended): Serve with SGLang or vLLM&lt;/h4&gt; 
&lt;p&gt;Use SGLang to serve MiroThinker models at port 61002:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;NUM_GPUS=4
PORT=61002

# Downloading model from HF (v1.5 recommended)
MODEL_PATH=miromind-ai/MiroThinker-v1.5-30B

# Or use v1.0
# MODEL_PATH=miromind-ai/MiroThinker-v1.0-30B

python3 -m sglang.launch_server \
    --model-path $MODEL_PATH \
    --tp $NUM_GPUS \
    --dp 1 \
    --host 0.0.0.0 \
    --port $PORT \
    --trust-remote-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìç Server URL&lt;/strong&gt;: This will start a server at &lt;code&gt;http://0.0.0.0:$PORT&lt;/code&gt;. Use this as your server base URL (e.g., &lt;code&gt;http://0.0.0.0:61002/v1&lt;/code&gt;).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Option 2: Quantized Light-Weight Options&lt;/h4&gt; 
&lt;p&gt;We also provide comprehensive guidance for serving MiroThinker models using CPU-optimized and GPU-accelerated quantization techniques, along with detailed analysis and guidelines for deployment with llama.cpp, Ollama, SGLang, and other inference frameworks.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìñ Complete Guide&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/apps/gradio-demo/"&gt;Deployment Documentation&lt;/a&gt; for detailed deployment instructions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Run Your First Task&lt;/h3&gt; 
&lt;p&gt;After setting up the environment and starting your model server, run &lt;code&gt;main.py&lt;/code&gt; to test with a default question: &lt;em&gt;"What is the title of today's arxiv paper in computer science?"&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent

# Using MiroThinker models (requires your own model server)
uv run python main.py llm=qwen-3 agent=mirothinker_v1.5_keep5_max200 llm.base_url=http://localhost:61002/v1

# Or using Claude (requires ANTHROPIC_API_KEY in .env)
uv run python main.py llm=claude-3-7 agent=single_agent_keep5

# Or using GPT-5 (requires OPENAI_API_KEY in .env)
uv run python main.py llm=gpt-5 agent=single_agent_keep5
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To customize your question&lt;/strong&gt;, edit &lt;code&gt;main.py&lt;/code&gt; line 32:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;task_description = "Your custom question here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The agent will search the web, execute code if needed, and provide an answer with sources.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìñ More details&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/apps/miroflow-agent/README.md"&gt;apps/miroflow-agent/README.md&lt;/a&gt; for available configurations and troubleshooting.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìä Benchmark Evaluation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For researchers who want to reproduce our benchmark results or evaluate on standard benchmarks.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Download Benchmark Data&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd MiroThinker  # Back to project root
wget https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/data_20251115_password_protected.zip
unzip data_20251115_password_protected.zip
# Password: pf4*
rm data_20251115_password_protected.zip
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run Benchmark Evaluation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For MiroThinker v1.5, use &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; (with context management), &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (with context management), or &lt;code&gt;mirothinker_v1.5&lt;/code&gt; configurations. For v1.0, use &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt; (with context management) or &lt;code&gt;mirothinker_v1.0&lt;/code&gt; configurations.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Available Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can customize the evaluation by setting the following environment variables before running the script:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Parameter&lt;/th&gt; 
   &lt;th align="left"&gt;Default&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;LLM_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"MiroThinker-Models"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Model name identifier&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"https://your-api.com/v1"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Base URL of your model server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;NUM_RUNS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Varies by benchmark&lt;/td&gt; 
   &lt;td align="left"&gt;Number of evaluation runs (3 for most benchmarks, 8 for GAIA/XBench/FutureX/SEAL-0, 32 for AIME2025)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;LLM_PROVIDER&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"qwen"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;LLM provider (e.g., &lt;code&gt;qwen&lt;/code&gt;, &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;anthropic&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;AGENT_SET&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"mirothinker_v1.5_keep5_max200"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Agent configuration (e.g., &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt;, &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt;, &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;MAX_CONTEXT_LENGTH&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;262144&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Maximum context length (256K)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;MAX_CONCURRENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Maximum concurrent tasks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;PASS_AT_K&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Pass@K evaluation metric&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TEMPERATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sampling temperature&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"xxx"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API key for the model server&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Example Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# Basic usage with v1.5 (recommended)
NUM_RUNS=8 LLM_MODEL="MiroThinker-v1.5-30B" BASE_URL="https://your-api.com/v1" bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# Or with v1.0
# NUM_RUNS=8 LLM_MODEL="MiroThinker-v1.0-30B" BASE_URL="https://your-api.com/v1" bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# Customize number of runs and agent configuration (v1.5 with context management)
LLM_MODEL="MiroThinker-v1.5-30B" \
BASE_URL="https://your-api.com/v1" \
NUM_RUNS=8 \
AGENT_SET="mirothinker_v1.5_keep5_max200" \
bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# Or with v1.0 configuration (with context management)
# LLM_MODEL="MiroThinker-v1.0-30B" \
# BASE_URL="https://your-api.com/v1" \
# NUM_RUNS=8 \
# AGENT_SET="mirothinker_v1.0_keep5" \
# bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;details open&gt; 
 &lt;summary&gt;üìã Click to expand all benchmark commands&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Important for MiroThinker v1.5&lt;/strong&gt;: To reproduce our reported results, you must set the correct &lt;code&gt;AGENT_SET&lt;/code&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;BrowseComp &amp;amp; BrowseComp-ZH&lt;/strong&gt;: Use &lt;code&gt;AGENT_SET="mirothinker_v1.5_keep5_max400"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;All other benchmarks&lt;/strong&gt;: Use &lt;code&gt;AGENT_SET="mirothinker_v1.5_keep5_max200"&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# HLE
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_hle.sh

# HLE-Text-2158
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_hle-text-2158.sh

# HLE-Text-500
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_hle-text-500.sh

# GAIA-Text-103
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# GAIA-Validation (GAIA-Val-165)
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_gaia-validation.sh

# BrowseComp-EN (‚ö†Ô∏è use max400)
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max400" bash scripts/run_evaluate_multiple_runs_browsecomp.sh

# BrowseComp-ZH (‚ö†Ô∏è use max400)
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max400" bash scripts/run_evaluate_multiple_runs_browsecomp_zh.sh

# WebWalkerQA
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_webwalkerqa.sh

# XBench-DeepSearch
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_xbench_deepsearch.sh

# FRAMES
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_frames.sh

# SEAL-0
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_seal-0.sh

# FutureX
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_futurex.sh

# AIME2025
NUM_RUNS=32 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_aime2025.sh

# DeepSearchQA
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_deepsearchqa.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;3. &lt;strong&gt;Monitor evaluation progress&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìä Click to expand progress monitoring commands&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# For HLE
python benchmarks/check_progress/check_progress_hle.py /path/to/evaluation/logs

# For HLE-Text-2158
python benchmarks/check_progress/check_progress_hle-text-2158.py /path/to/evaluation/logs

# For HLE-Text-500
python benchmarks/check_progress/check_progress_hle-text-500.py /path/to/evaluation/logs

# For BrowseComp-EN
python benchmarks/check_progress/check_progress_browsecomp.py /path/to/evaluation/logs

# For BrowseComp-ZH
python benchmarks/check_progress/check_progress_browsecomp_zh.py /path/to/evaluation/logs

# For GAIA-Validation
python benchmarks/check_progress/check_progress_gaia-validation.py /path/to/evaluation/logs

# For GAIA-Text-103
python benchmarks/check_progress/check_progress_gaia-validation-text-103.py /path/to/evaluation/logs

# For WebWalkerQA
python benchmarks/check_progress/check_progress_webwalkerqa.py /path/to/evaluation/logs

# For Frames
python benchmarks/check_progress/check_progress_frames.py /path/to/evaluation/logs

# For XBench-DeepSearch
python benchmarks/check_progress/check_progress_xbench_deepsearch.py /path/to/evaluation/logs

# For SEAL-0
python benchmarks/check_progress/check_progress_seal-0.py /path/to/evaluation/logs

# For AIME2025
python benchmarks/check_progress/check_progress_aime2025.py /path/to/evaluation/logs

# For DeepSearchQA
python benchmarks/check_progress/check_progress_deepsearchqa.py /path/to/evaluation/logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;üî¨ Trace Collection&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìã Click to expand trace collection commands&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/collect-trace

# Collect Traces for SFT
bash scripts/collect_trace_claude37.sh
bash scripts/collect_trace_gpt5.sh

# Collect Traces for DPO
bash scripts/collect_trace_qwen3.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ùì FAQ &amp;amp; Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Common Issues&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Click to expand troubleshooting guide&lt;/summary&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Which version should I use?&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; We recommend &lt;strong&gt;MiroThinker v1.5&lt;/strong&gt; ‚≠ê with the minimal configuration:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;v1.5&lt;/strong&gt; ‚≠ê: Latest version with 256K context, world-leading performance. Use config (with context management): 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; (up to 200 turns, recommended for most tasks)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (up to 400 turns, only used for BrowseComp and BrowseComp-ZH)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: How do I get API keys?&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; You need these keys for minimal setup:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;SERPER_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://serper.dev/"&gt;Serper.dev&lt;/a&gt; (Google search API)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;JINA_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://jina.ai/"&gt;Jina.ai&lt;/a&gt; (Web scraping)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;E2B_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://e2b.dev/"&gt;E2B.dev&lt;/a&gt; (Code execution sandbox)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;SUMMARY_LLM_API_KEY&lt;/strong&gt;: Your LLM API credentials (for content summarization). Can be a small model like Qwen3-14B or GPT-5-Nano‚Äîthe choice has minimal impact on performance.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;OPENAI_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://platform.openai.com/"&gt;OpenAI&lt;/a&gt; (Required for benchmark evaluation, used for LLM-as-a-Judge)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;OPENAI_BASE_URL&lt;/strong&gt;: Optional, defaults to &lt;code&gt;https://api.openai.com/v1&lt;/code&gt;. Can be changed to use OpenAI-compatible APIs.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Model server connection errors&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Common issues:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Check base URL format&lt;/strong&gt;: Should end with &lt;code&gt;/v1&lt;/code&gt; (e.g., &lt;code&gt;https://your-api.com/v1&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Verify API key&lt;/strong&gt;: Ensure &lt;code&gt;API_KEY&lt;/code&gt; is set correctly in environment or script&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Check server status&lt;/strong&gt;: Make sure your model server is running and accessible&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Network issues&lt;/strong&gt;: Verify firewall/network settings allow connections&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Evaluation script fails to run&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Troubleshooting steps:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Check working directory&lt;/strong&gt;: Make sure you're in &lt;code&gt;apps/miroflow-agent&lt;/code&gt; directory&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Verify environment&lt;/strong&gt;: Run &lt;code&gt;uv sync&lt;/code&gt; to ensure dependencies are installed&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Check .env file&lt;/strong&gt;: Ensure all required environment variables are set&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Review logs&lt;/strong&gt;: Check &lt;code&gt;logs/&lt;/code&gt; directory for detailed error messages&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Verify data path&lt;/strong&gt;: Ensure benchmark data is downloaded and in correct location&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Out of memory errors&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Solutions:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Reduce context length&lt;/strong&gt;: Set &lt;code&gt;MAX_CONTEXT_LENGTH&lt;/code&gt; to a smaller value (e.g., 131072 for 128K)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Use context management with fewer turns&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;For v1.5: Use &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; or &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (with context management)&lt;/li&gt; 
    &lt;li&gt;For v1.0: Use &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt; (with context management)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Reduce concurrent tasks&lt;/strong&gt;: Set &lt;code&gt;MAX_CONCURRENT&lt;/code&gt; to a smaller number (e.g., 5)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Use smaller model&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;For v1.5: Try 30B instead of 235B&lt;/li&gt; 
    &lt;li&gt;For v1.0: Try 8B or 30B instead of 72B&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Tool execution errors&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Common fixes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;E2B errors&lt;/strong&gt;: Verify &lt;code&gt;E2B_API_KEY&lt;/code&gt; is valid and account has credits&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Serper errors&lt;/strong&gt;: Check &lt;code&gt;SERPER_API_KEY&lt;/code&gt; and rate limits&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Jina errors&lt;/strong&gt;: Verify &lt;code&gt;JINA_API_KEY&lt;/code&gt; and &lt;code&gt;JINA_BASE_URL&lt;/code&gt; are correct&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;LLM summarization errors&lt;/strong&gt;: Check &lt;code&gt;SUMMARY_LLM_*&lt;/code&gt; variables and model availability&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: How to monitor long-running evaluations?&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Use the progress monitoring scripts:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent
python benchmarks/check_progress/check_progress_&amp;lt;benchmark_name&amp;gt;.py /path/to/logs
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The scripts show completion status, elapsed time, and estimated remaining time.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Getting Help&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Documentation&lt;/strong&gt;: Check &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/libs/miroflow-tools/README.md"&gt;MiroFlow Tools README&lt;/a&gt; for tool details&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;Discord&lt;/strong&gt;: Join our &lt;a href="https://discord.com/invite/GPqEnkzQZd"&gt;Discord community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Issues&lt;/strong&gt;: Report bugs on &lt;a href="https://github.com/MiroMindAI/MiroThinker/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìß &lt;strong&gt;Contact&lt;/strong&gt;: Visit &lt;a href="https://miromind.ai/"&gt;our website&lt;/a&gt; for more information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;p&gt;We extend our sincere gratitude to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üèÜ &lt;strong&gt;Benchmark Contributors&lt;/strong&gt; for the comprehensive evaluation datasets&lt;/li&gt; 
 &lt;li&gt;üåç &lt;strong&gt;Open Source Community&lt;/strong&gt; for the tools and libraries that make this possible&lt;/li&gt; 
 &lt;li&gt;üë• &lt;strong&gt;All Contributors&lt;/strong&gt; who have helped make MiroThinker better&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/MiroMindAI/MiroThinker/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=MiroMindAI/MiroThinker" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Join our community and help us build the future of AI agents!&lt;/p&gt; 
&lt;h3&gt;References&lt;/h3&gt; 
&lt;p&gt;If you find this project useful in your research, please consider citing:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@article{miromind2025mirothinker,
  title={MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling},
  author={MiroMind Team and Bai, Song and Bing, Lidong and Chen, Carson and Chen, Guanzheng and Chen, Yuntao and Chen, Zhe and Chen, Ziyi and Dai, Jifeng and Dong, Xuan and others},
  journal={arXiv preprint arXiv:2511.11793},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#MiroMindAI/MiroThinker&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=MiroMindAI/MiroThinker&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>memvid/memvid</title>
      <link>https://github.com/memvid/memvid</link>
      <description>&lt;p&gt;Memory layer for AI Agents. Replace complex RAG pipelines with a serverless, single-file memory layer. Give your agents instant retrieval and long-term memory.&lt;/p&gt;&lt;hr&gt;&lt;img width="2000" height="524" alt="Social Cover (9)" src="https://github.com/user-attachments/assets/cf66f045-c8be-494b-b696-b8d7e4fb709c" /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/memvid/memvid/main/docs/i18n/README.es.md"&gt;üá™üá∏ Espa√±ol&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/memvid/memvid/main/docs/i18n/README.fr.md"&gt;üá´üá∑ Fran√ßais&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/memvid/memvid/main/docs/i18n/README.so.md"&gt;üá∏üá¥ Soomaali&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/memvid/memvid/main/docs/i18n/README.ar.md"&gt;üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;Memvid is a single-file memory layer for AI agents with instant retrieval and long-term memory.&lt;/strong&gt;&lt;br /&gt; Persistent, versioned, and portable memory, without databases. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.memvid.com"&gt;Website&lt;/a&gt; ¬∑ &lt;a href="https://sandbox.memvid.com"&gt;Try Sandbox&lt;/a&gt; ¬∑ &lt;a href="https://docs.memvid.com"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://github.com/memvid/memvid/discussions"&gt;Discussions&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://crates.io/crates/memvid-core"&gt;&lt;img src="https://img.shields.io/crates/v/memvid-core?style=flat-square&amp;amp;logo=rust" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/memvid-core"&gt;&lt;img src="https://img.shields.io/docsrs/memvid-core?style=flat-square&amp;amp;logo=docs.rs" alt="docs.rs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/memvid/memvid/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square" alt="License" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/memvid/memvid/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/memvid/memvid?style=flat-square&amp;amp;logo=github" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/memvid/memvid/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/memvid/memvid?style=flat-square&amp;amp;logo=github" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/memvid/memvid/issues"&gt;&lt;img src="https://img.shields.io/github/issues/memvid/memvid?style=flat-square&amp;amp;logo=github" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/2mynS7fcK7"&gt;&lt;img src="https://img.shields.io/discord/1442910055233224745?style=flat-square&amp;amp;logo=discord&amp;amp;label=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/17293" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/17293" alt="memvid%2Fmemvid | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" &lt; a /&gt; &lt;/a&gt;&lt;/p&gt;
&lt;a href="https://trendshift.io/repositories/17293" target="_blank"&gt; &lt;h2 align="center"&gt;‚≠êÔ∏è Leave a STAR to support the project ‚≠êÔ∏è&lt;/h2&gt; &lt;p&gt;&lt;/p&gt; &lt;h2&gt;What is Memvid?&lt;/h2&gt; &lt;p&gt;Memvid is a portable AI memory system that packages your data, embeddings, search structure, and metadata into a single file.&lt;/p&gt; &lt;p&gt;Instead of running complex RAG pipelines or server-based vector databases, Memvid enables fast retrieval directly from the file.&lt;/p&gt; &lt;p&gt;The result is a model-agnostic, infrastructure-free memory layer that gives AI agents persistent, long-term memory they can carry anywhere.&lt;/p&gt; 
 &lt;hr /&gt; &lt;h2&gt;What are Smart Frames?&lt;/h2&gt; &lt;p&gt;Memvid draws inspiration from video encoding, not to store video, but to &lt;strong&gt;organize AI memory as an append-only, ultra-efficient sequence of Smart Frames.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;A Smart Frame is an immutable unit that stores content along with timestamps, checksums and basic metadata. Frames are grouped in a way that allows efficient compression, indexing, and parallel reads.&lt;/p&gt; &lt;p&gt;This frame-based design enables:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Append-only writes without modifying or corrupting existing data&lt;/li&gt; 
  &lt;li&gt;Queries over past memory states&lt;/li&gt; 
  &lt;li&gt;Timeline-style inspection of how knowledge evolves&lt;/li&gt; 
  &lt;li&gt;Crash safety through committed, immutable frames&lt;/li&gt; 
  &lt;li&gt;Efficient compression using techniques adapted from video encoding&lt;/li&gt; 
 &lt;/ul&gt; &lt;p&gt;The result is a single file that behaves like a rewindable memory timeline for AI systems.&lt;/p&gt; 
 &lt;hr /&gt; &lt;h2&gt;Core Concepts&lt;/h2&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Living Memory Engine&lt;/strong&gt; Continuously append, branch, and evolve memory across sessions.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Capsule Context (&lt;code&gt;.mv2&lt;/code&gt;)&lt;/strong&gt; Self-contained, shareable memory capsules with rules and expiry.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Time-Travel Debugging&lt;/strong&gt; Rewind, replay, or branch any memory state.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Smart Recall&lt;/strong&gt; Sub-5ms local memory access with predictive caching.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Codec Intelligence&lt;/strong&gt; Auto-selects and upgrades compression over time.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; &lt;h2&gt;Use Cases&lt;/h2&gt; &lt;p&gt;Memvid is a portable, serverless memory layer that gives AI agents persistent memory and fast recall. Because it's model-agnostic, multi-modal, and works fully offline, developers are using Memvid across a wide range of real-world applications.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Long-Running AI Agents&lt;/li&gt; 
  &lt;li&gt;Enterprise Knowledge Bases&lt;/li&gt; 
  &lt;li&gt;Offline-First AI Systems&lt;/li&gt; 
  &lt;li&gt;Codebase Understanding&lt;/li&gt; 
  &lt;li&gt;Customer Support Agents&lt;/li&gt; 
  &lt;li&gt;Workflow Automation&lt;/li&gt; 
  &lt;li&gt;Sales and Marketing Copilots&lt;/li&gt; 
  &lt;li&gt;Personal Knowledge Assistants&lt;/li&gt; 
  &lt;li&gt;Medical, Legal, and Financial Agents&lt;/li&gt; 
  &lt;li&gt;Auditable and Debuggable AI Workflows&lt;/li&gt; 
  &lt;li&gt;Custom Applications&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; &lt;h2&gt;SDKs &amp;amp; CLI&lt;/h2&gt; &lt;p&gt;Use Memvid in your preferred language:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Package&lt;/th&gt; 
    &lt;th&gt;Install&lt;/th&gt; 
    &lt;th&gt;Links&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;CLI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;npm install -g memvid-cli&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://www.npmjs.com/package/memvid-cli"&gt;&lt;img src="https://img.shields.io/npm/v/memvid-cli?style=flat-square" alt="npm" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Node.js SDK&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;npm install @memvid/sdk&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://www.npmjs.com/package/@memvid/sdk"&gt;&lt;img src="https://img.shields.io/npm/v/@memvid/sdk?style=flat-square" alt="npm" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Python SDK&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pip install memvid-sdk&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://pypi.org/project/memvid-sdk/"&gt;&lt;img src="https://img.shields.io/pypi/v/memvid-sdk?style=flat-square" alt="PyPI" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Rust&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;cargo add memvid-core&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://crates.io/crates/memvid-core"&gt;&lt;img src="https://img.shields.io/crates/v/memvid-core?style=flat-square" alt="Crates.io" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;hr /&gt; &lt;h2&gt;Installation (Rust)&lt;/h2&gt; &lt;h3&gt;Requirements&lt;/h3&gt; &lt;/a&gt;
&lt;ul&gt;
 &lt;a href="https://trendshift.io/repositories/17293" target="_blank"&gt; &lt;li&gt;&lt;strong&gt;Rust 1.85.0+&lt;/strong&gt; ‚Äî Install from &lt;a href="https://rustup.rs"&gt;rustup.rs&lt;/a&gt;&lt;/li&gt;&lt;/a&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Add to Your Project&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
memvid-core = "2.0"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Feature Flags&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;lex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Full-text search with BM25 ranking (Tantivy)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pdf_extract&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pure Rust PDF text extraction&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Vector similarity search (HNSW + local text embeddings via ONNX)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clip&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;CLIP visual embeddings for image search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;whisper&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Audio transcription with Whisper&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;temporal_track&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Natural language date parsing ("last Tuesday")&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;parallel_segments&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Multi-threaded ingestion&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;encryption&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Password-based encryption capsules (.mv2e)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Enable features as needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
memvid-core = { version = "2.0", features = ["lex", "vec", "temporal_track"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use memvid_core::{Memvid, PutOptions, SearchRequest};

fn main() -&amp;gt; memvid_core::Result&amp;lt;()&amp;gt; {
    // Create a new memory file
    let mut mem = Memvid::create("knowledge.mv2")?;

    // Add documents with metadata
    let opts = PutOptions::builder()
        .title("Meeting Notes")
        .uri("mv2://meetings/2024-01-15")
        .tag("project", "alpha")
        .build();
    mem.put_bytes_with_options(b"Q4 planning discussion...", opts)?;
    mem.commit()?;

    // Search
    let response = mem.search(SearchRequest {
        query: "planning".into(),
        top_k: 10,
        snippet_chars: 200,
        ..Default::default()
    })?;

    for hit in response.hits {
        println!("{}: {}", hit.title.unwrap_or_default(), hit.text);
    }

    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Build&lt;/h2&gt; 
&lt;p&gt;Clone the repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/memvid/memvid.git
cd memvid
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build in debug mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build in release mode (optimized):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build with specific features:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo build --release --features "lex,vec,temporal_track"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Run Tests&lt;/h2&gt; 
&lt;p&gt;Run all tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run tests with output:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo test -- --nocapture
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run a specific test:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo test test_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run integration tests only:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo test --test lifecycle
cargo test --test search
cargo test --test mutation
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;examples/&lt;/code&gt; directory contains working examples:&lt;/p&gt; 
&lt;h3&gt;Basic Usage&lt;/h3&gt; 
&lt;p&gt;Demonstrates create, put, search, and timeline operations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --example basic_usage
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;PDF Ingestion&lt;/h3&gt; 
&lt;p&gt;Ingest and search PDF documents (uses the "Attention Is All You Need" paper):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --example pdf_ingestion
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;CLIP Visual Search&lt;/h3&gt; 
&lt;p&gt;Image search using CLIP embeddings (requires &lt;code&gt;clip&lt;/code&gt; feature):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --example clip_visual_search --features clip
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Whisper Transcription&lt;/h3&gt; 
&lt;p&gt;Audio transcription (requires &lt;code&gt;whisper&lt;/code&gt; feature):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --example test_whisper --features whisper
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Text Embedding Models&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;vec&lt;/code&gt; feature includes local text embedding support using ONNX models. Before using local text embeddings, you need to download the model files manually.&lt;/p&gt; 
&lt;h3&gt;Quick Start: BGE-small (Recommended)&lt;/h3&gt; 
&lt;p&gt;Download the default BGE-small model (384 dimensions, fast and efficient):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p ~/.cache/memvid/text-models

# Download ONNX model
curl -L 'https://huggingface.co/BAAI/bge-small-en-v1.5/resolve/main/onnx/model.onnx' \
  -o ~/.cache/memvid/text-models/bge-small-en-v1.5.onnx

# Download tokenizer
curl -L 'https://huggingface.co/BAAI/bge-small-en-v1.5/resolve/main/tokenizer.json' \
  -o ~/.cache/memvid/text-models/bge-small-en-v1.5_tokenizer.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Available Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Dimensions&lt;/th&gt; 
   &lt;th&gt;Size&lt;/th&gt; 
   &lt;th&gt;Best For&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bge-small-en-v1.5&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;384&lt;/td&gt; 
   &lt;td&gt;~120MB&lt;/td&gt; 
   &lt;td&gt;Default, fast&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bge-base-en-v1.5&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;~420MB&lt;/td&gt; 
   &lt;td&gt;Better quality&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nomic-embed-text-v1.5&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;~530MB&lt;/td&gt; 
   &lt;td&gt;Versatile tasks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;gte-large&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;1024&lt;/td&gt; 
   &lt;td&gt;~1.3GB&lt;/td&gt; 
   &lt;td&gt;Highest quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Other Models&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;BGE-base&lt;/strong&gt; (768 dimensions):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -L 'https://huggingface.co/BAAI/bge-base-en-v1.5/resolve/main/onnx/model.onnx' \
  -o ~/.cache/memvid/text-models/bge-base-en-v1.5.onnx
curl -L 'https://huggingface.co/BAAI/bge-base-en-v1.5/resolve/main/tokenizer.json' \
  -o ~/.cache/memvid/text-models/bge-base-en-v1.5_tokenizer.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Nomic&lt;/strong&gt; (768 dimensions):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -L 'https://huggingface.co/nomic-ai/nomic-embed-text-v1.5/resolve/main/onnx/model.onnx' \
  -o ~/.cache/memvid/text-models/nomic-embed-text-v1.5.onnx
curl -L 'https://huggingface.co/nomic-ai/nomic-embed-text-v1.5/resolve/main/tokenizer.json' \
  -o ~/.cache/memvid/text-models/nomic-embed-text-v1.5_tokenizer.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;GTE-large&lt;/strong&gt; (1024 dimensions):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -L 'https://huggingface.co/thenlper/gte-large/resolve/main/onnx/model.onnx' \
  -o ~/.cache/memvid/text-models/gte-large.onnx
curl -L 'https://huggingface.co/thenlper/gte-large/resolve/main/tokenizer.json' \
  -o ~/.cache/memvid/text-models/gte-large_tokenizer.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage in Code&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use memvid_core::text_embed::{LocalTextEmbedder, TextEmbedConfig};
use memvid_core::types::embedding::EmbeddingProvider;

// Use default model (BGE-small)
let config = TextEmbedConfig::default();
let embedder = LocalTextEmbedder::new(config)?;

let embedding = embedder.embed_text("hello world")?;
assert_eq!(embedding.len(), 384);

// Use different model
let config = TextEmbedConfig::bge_base();
let embedder = LocalTextEmbedder::new(config)?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;code&gt;examples/text_embedding.rs&lt;/code&gt; for a complete example with similarity computation and search ranking.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;File Format&lt;/h2&gt; 
&lt;p&gt;Everything lives in a single &lt;code&gt;.mv2&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Header (4KB)               ‚îÇ  Magic, version, capacity
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Embedded WAL (1-64MB)      ‚îÇ  Crash recovery
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Data Segments              ‚îÇ  Compressed frames
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Lex Index                  ‚îÇ  Tantivy full-text
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Vec Index                  ‚îÇ  HNSW vectors
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Time Index                 ‚îÇ  Chronological ordering
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ TOC (Footer)               ‚îÇ  Segment offsets
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;No &lt;code&gt;.wal&lt;/code&gt;, &lt;code&gt;.lock&lt;/code&gt;, &lt;code&gt;.shm&lt;/code&gt;, or sidecar files. Ever.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/memvid/memvid/main/MV2_SPEC.md"&gt;MV2_SPEC.md&lt;/a&gt; for the complete file format specification.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Have questions or feedback? Email: &lt;a href="mailto:contact@memvid.com"&gt;contact@memvid.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Drop a ‚≠ê to show support&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0 ‚Äî see the &lt;a href="https://raw.githubusercontent.com/memvid/memvid/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ChromeDevTools/chrome-devtools-mcp</title>
      <link>https://github.com/ChromeDevTools/chrome-devtools-mcp</link>
      <description>&lt;p&gt;Chrome DevTools for coding agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Chrome DevTools MCP&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://npmjs.org/package/chrome-devtools-mcp"&gt;&lt;img src="https://img.shields.io/npm/v/chrome-devtools-mcp.svg?sanitize=true" alt="npm chrome-devtools-mcp package" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;chrome-devtools-mcp&lt;/code&gt; lets your coding agent (such as Gemini, Claude, Cursor or Copilot) control and inspect a live Chrome browser. It acts as a Model-Context-Protocol (MCP) server, giving your AI coding assistant access to the full power of Chrome DevTools for reliable automation, in-depth debugging, and performance analysis.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md"&gt;Tool reference&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/CHANGELOG.md"&gt;Changelog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/troubleshooting.md"&gt;Troubleshooting&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/design-principles.md"&gt;Design Principles&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Key features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Get performance insights&lt;/strong&gt;: Uses &lt;a href="https://github.com/ChromeDevTools/devtools-frontend"&gt;Chrome DevTools&lt;/a&gt; to record traces and extract actionable performance insights.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced browser debugging&lt;/strong&gt;: Analyze network requests, take screenshots and check the browser console.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable automation&lt;/strong&gt;. Uses &lt;a href="https://github.com/puppeteer/puppeteer"&gt;puppeteer&lt;/a&gt; to automate actions in Chrome and automatically wait for action results.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimers&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;chrome-devtools-mcp&lt;/code&gt; exposes content of the browser instance to the MCP clients allowing them to inspect, debug, and modify any data in the browser or DevTools. Avoid sharing sensitive or personal information that you don't want to share with MCP clients.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; v20.19 or a newer &lt;a href="https://github.com/nodejs/Release#release-schedule"&gt;latest maintenance LTS&lt;/a&gt; version.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.google.com/chrome/"&gt;Chrome&lt;/a&gt; current stable version or newer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/"&gt;npm&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Add the following config to your MCP client:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": ["-y", "chrome-devtools-mcp@latest"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; Using &lt;code&gt;chrome-devtools-mcp@latest&lt;/code&gt; ensures that your MCP client will always use the latest version of the Chrome DevTools MCP server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;MCP Client configuration&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Amp&lt;/summary&gt; Follow https://ampcode.com/manual#mcp and use the config provided above. You can also install the Chrome DevTools MCP server using the CLI: 
 &lt;pre&gt;&lt;code class="language-bash"&gt;amp mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Antigravity&lt;/summary&gt; 
 &lt;p&gt;To use the Chrome DevTools MCP server follow the instructions from &lt;a href="https://antigravity.google/docs/mcp"&gt;Antigravity's docs&lt;/a&gt;&lt;a&gt;&lt;/a&gt; to install a custom MCP server. Add the following config to the MCP servers config:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--browser-url=http://127.0.0.1:9222",
        "-y"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This will make the Chrome DevTools MCP server automatically connect to the browser that Antigravity is using. If you are not using port 9222, make sure to adjust accordingly.&lt;/p&gt; 
 &lt;p&gt;Chrome DevTools MCP will not start the browser instance automatically using this approach as as the Chrome DevTools MCP server runs in Antigravity's built-in browser. If the browser is not already running, you have to start it first by clicking the Chrome icon at the top right corner.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Claude Code&lt;/summary&gt; Use the Claude Code CLI to add the Chrome DevTools MCP server (
 &lt;a href="https://code.claude.com/docs/en/mcp"&gt;guide&lt;/a&gt;): 
 &lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add chrome-devtools --scope user npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Cline&lt;/summary&gt; Follow https://docs.cline.bot/mcp/configuring-mcp-servers and use the config provided above. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Codex&lt;/summary&gt; Follow the 
 &lt;a href="https://github.com/openai/codex/raw/main/docs/advanced.md#model-context-protocol-mcp"&gt;configure MCP guide&lt;/a&gt; using the standard config from above. You can also install the Chrome DevTools MCP server using the Codex CLI: 
 &lt;pre&gt;&lt;code class="language-bash"&gt;codex mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;On Windows 11&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Configure the Chrome install location and increase the startup timeout by updating &lt;code&gt;.codex/config.toml&lt;/code&gt; and adding the following &lt;code&gt;env&lt;/code&gt; and &lt;code&gt;startup_timeout_ms&lt;/code&gt; parameters:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;[mcp_servers.chrome-devtools]
command = "cmd"
args = [
    "/c",
    "npx",
    "-y",
    "chrome-devtools-mcp@latest",
]
env = { SystemRoot="C:\\Windows", PROGRAMFILES="C:\\Program Files" }
startup_timeout_ms = 20_000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Copilot CLI&lt;/summary&gt; 
 &lt;p&gt;Start Copilot CLI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;copilot
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Start the dialog to add a new MCP server by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;/mcp add
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Configure the following fields and press &lt;code&gt;CTRL+S&lt;/code&gt; to save the configuration:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Server name:&lt;/strong&gt; &lt;code&gt;chrome-devtools&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Server Type:&lt;/strong&gt; &lt;code&gt;[1] Local&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Command:&lt;/strong&gt; &lt;code&gt;npx -y chrome-devtools-mcp@latest&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Copilot / VS Code&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Click the button to install:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://vscode.dev/redirect/mcp/install?name=io.github.ChromeDevTools%2Fchrome-devtools-mcp&amp;amp;config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22chrome-devtools-mcp%22%5D%2C%22env%22%3A%7B%7D%7D"&gt;&lt;img src="https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&amp;amp;label=Install%20Server&amp;amp;color=0098FF" alt="Install in VS Code" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522io.github.ChromeDevTools%252Fchrome-devtools-mcp%2522%252C%2522config%2522%253A%257B%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522chrome-devtools-mcp%2522%255D%252C%2522env%2522%253A%257B%257D%257D%257D"&gt;&lt;img src="https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&amp;amp;label=Install%20Server&amp;amp;color=24bfa5" alt="Install in VS Code Insiders" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Or install manually:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Follow the MCP install &lt;a href="https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server"&gt;guide&lt;/a&gt;, with the standard config from above. You can also install the Chrome DevTools MCP server using the VS Code CLI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;code --add-mcp '{"name":"io.github.ChromeDevTools/chrome-devtools-mcp","command":"npx","args":["-y","chrome-devtools-mcp"],"env":{}}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Cursor&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Click the button to install:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://cursor.com/en/install-mcp?name=chrome-devtools&amp;amp;config=eyJjb21tYW5kIjoibnB4IC15IGNocm9tZS1kZXZ0b29scy1tY3BAbGF0ZXN0In0%3D"&gt;&lt;img src="https://cursor.com/deeplink/mcp-install-dark.svg?sanitize=true" alt="Install in Cursor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Or install manually:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Go to &lt;code&gt;Cursor Settings&lt;/code&gt; -&amp;gt; &lt;code&gt;MCP&lt;/code&gt; -&amp;gt; &lt;code&gt;New MCP Server&lt;/code&gt;. Use the config provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Factory CLI&lt;/summary&gt; Use the Factory CLI to add the Chrome DevTools MCP server (
 &lt;a href="https://docs.factory.ai/cli/configuration/mcp"&gt;guide&lt;/a&gt;): 
 &lt;pre&gt;&lt;code class="language-bash"&gt;droid mcp add chrome-devtools "npx -y chrome-devtools-mcp@latest"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini CLI&lt;/summary&gt; Install the Chrome DevTools MCP server using the Gemini CLI. 
 &lt;p&gt;&lt;strong&gt;Project wide:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;gemini mcp add chrome-devtools npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Globally:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;gemini mcp add -s user chrome-devtools npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Alternatively, follow the &lt;a href="https://github.com/google-gemini/gemini-cli/raw/main/docs/tools/mcp-server.md#how-to-set-up-your-mcp-server"&gt;MCP guide&lt;/a&gt; and use the standard config from above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini Code Assist&lt;/summary&gt; Follow the 
 &lt;a href="https://cloud.google.com/gemini/docs/codeassist/use-agentic-chat-pair-programmer#configure-mcp-servers"&gt;configure MCP guide&lt;/a&gt; using the standard config from above. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;JetBrains AI Assistant &amp;amp; Junie&lt;/summary&gt; 
 &lt;p&gt;Go to &lt;code&gt;Settings | Tools | AI Assistant | Model Context Protocol (MCP)&lt;/code&gt; -&amp;gt; &lt;code&gt;Add&lt;/code&gt;. Use the config provided above. The same way chrome-devtools-mcp can be configured for JetBrains Junie in &lt;code&gt;Settings | Tools | Junie | MCP Settings&lt;/code&gt; -&amp;gt; &lt;code&gt;Add&lt;/code&gt;. Use the config provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Kiro&lt;/summary&gt; 
 &lt;p&gt;In &lt;strong&gt;Kiro Settings&lt;/strong&gt;, go to &lt;code&gt;Configure MCP&lt;/code&gt; &amp;gt; &lt;code&gt;Open Workspace or User MCP Config&lt;/code&gt; &amp;gt; Use the configuration snippet provided above.&lt;/p&gt; 
 &lt;p&gt;Or, from the IDE &lt;strong&gt;Activity Bar&lt;/strong&gt; &amp;gt; &lt;code&gt;Kiro&lt;/code&gt; &amp;gt; &lt;code&gt;MCP Servers&lt;/code&gt; &amp;gt; &lt;code&gt;Click Open MCP Config&lt;/code&gt;. Use the configuration snippet provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenCode&lt;/summary&gt; 
 &lt;p&gt;Add the following configuration to your &lt;code&gt;opencode.json&lt;/code&gt; file. If you don't have one, create it at &lt;code&gt;~/.config/opencode/opencode.json&lt;/code&gt; (&lt;a href="https://opencode.ai/docs/mcp-servers"&gt;guide&lt;/a&gt;):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://opencode.ai/config.json",
  "mcp": {
    "chrome-devtools": {
      "type": "local",
      "command": ["npx", "-y", "chrome-devtools-mcp@latest"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qoder&lt;/summary&gt; 
 &lt;p&gt;In &lt;strong&gt;Qoder Settings&lt;/strong&gt;, go to &lt;code&gt;MCP Server&lt;/code&gt; &amp;gt; &lt;code&gt;+ Add&lt;/code&gt; &amp;gt; Use the configuration snippet provided above.&lt;/p&gt; 
 &lt;p&gt;Alternatively, follow the &lt;a href="https://docs.qoder.com/user-guide/chat/model-context-protocol"&gt;MCP guide&lt;/a&gt; and use the standard config from above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qoder CLI&lt;/summary&gt; 
 &lt;p&gt;Install the Chrome DevTools MCP server using the Qoder CLI (&lt;a href="https://docs.qoder.com/cli/using-cli#mcp-servsers"&gt;guide&lt;/a&gt;):&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Project wide:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;qodercli mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Globally:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;qodercli mcp add -s user chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Visual Studio&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Click the button to install:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://vs-open.link/mcp-install?%7B%22name%22%3A%22chrome-devtools%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22chrome-devtools-mcp%40latest%22%5D%7D"&gt;&lt;img src="https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&amp;amp;logoColor=white" alt="Install in Visual Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Warp&lt;/summary&gt; 
 &lt;p&gt;Go to &lt;code&gt;Settings | AI | Manage MCP Servers&lt;/code&gt; -&amp;gt; &lt;code&gt;+ Add&lt;/code&gt; to &lt;a href="https://docs.warp.dev/knowledge-and-collaboration/mcp#adding-an-mcp-server"&gt;add an MCP Server&lt;/a&gt;. Use the config provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Windsurf&lt;/summary&gt; Follow the 
 &lt;a href="https://docs.windsurf.com/windsurf/cascade/mcp#mcp-config-json"&gt;configure MCP guide&lt;/a&gt; using the standard config from above. 
&lt;/details&gt; 
&lt;h3&gt;Your first prompt&lt;/h3&gt; 
&lt;p&gt;Enter the following prompt in your MCP Client to check if everything is working:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Check the performance of https://developers.chrome.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Your MCP client should open the browser and record a performance trace.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; The MCP server will start the browser automatically once the MCP client uses a tool that requires a running browser instance. Connecting to the Chrome DevTools MCP server on its own will not automatically start the browser.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Tools&lt;/h2&gt; 
&lt;p&gt;If you run into any issues, checkout our &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/troubleshooting.md"&gt;troubleshooting guide&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- BEGIN AUTO GENERATED TOOLS --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Input automation&lt;/strong&gt; (8 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#click"&gt;&lt;code&gt;click&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#drag"&gt;&lt;code&gt;drag&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#fill"&gt;&lt;code&gt;fill&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#fill_form"&gt;&lt;code&gt;fill_form&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#handle_dialog"&gt;&lt;code&gt;handle_dialog&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#hover"&gt;&lt;code&gt;hover&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#press_key"&gt;&lt;code&gt;press_key&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#upload_file"&gt;&lt;code&gt;upload_file&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Navigation automation&lt;/strong&gt; (6 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#close_page"&gt;&lt;code&gt;close_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#list_pages"&gt;&lt;code&gt;list_pages&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#navigate_page"&gt;&lt;code&gt;navigate_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#new_page"&gt;&lt;code&gt;new_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#select_page"&gt;&lt;code&gt;select_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#wait_for"&gt;&lt;code&gt;wait_for&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Emulation&lt;/strong&gt; (2 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#emulate"&gt;&lt;code&gt;emulate&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#resize_page"&gt;&lt;code&gt;resize_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; (3 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#performance_analyze_insight"&gt;&lt;code&gt;performance_analyze_insight&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#performance_start_trace"&gt;&lt;code&gt;performance_start_trace&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#performance_stop_trace"&gt;&lt;code&gt;performance_stop_trace&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network&lt;/strong&gt; (2 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#get_network_request"&gt;&lt;code&gt;get_network_request&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#list_network_requests"&gt;&lt;code&gt;list_network_requests&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debugging&lt;/strong&gt; (5 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#evaluate_script"&gt;&lt;code&gt;evaluate_script&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#get_console_message"&gt;&lt;code&gt;get_console_message&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#list_console_messages"&gt;&lt;code&gt;list_console_messages&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#take_screenshot"&gt;&lt;code&gt;take_screenshot&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#take_snapshot"&gt;&lt;code&gt;take_snapshot&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END AUTO GENERATED TOOLS --&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;The Chrome DevTools MCP server supports the following configuration option:&lt;/p&gt; 
&lt;!-- BEGIN AUTO GENERATED OPTIONS --&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--autoConnect&lt;/code&gt;/ &lt;code&gt;--auto-connect&lt;/code&gt;&lt;/strong&gt; If specified, automatically connects to a browser (Chrome 145+) running in the user data directory identified by the channel param. Requires remote debugging being enabled in Chrome here: chrome://inspect/#remote-debugging.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--browserUrl&lt;/code&gt;/ &lt;code&gt;--browser-url&lt;/code&gt;, &lt;code&gt;-u&lt;/code&gt;&lt;/strong&gt; Connect to a running, debuggable Chrome instance (e.g. &lt;code&gt;http://127.0.0.1:9222&lt;/code&gt;). For more details see: &lt;a href="https://github.com/ChromeDevTools/chrome-devtools-mcp#connecting-to-a-running-chrome-instance"&gt;https://github.com/ChromeDevTools/chrome-devtools-mcp#connecting-to-a-running-chrome-instance&lt;/a&gt;.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--wsEndpoint&lt;/code&gt;/ &lt;code&gt;--ws-endpoint&lt;/code&gt;, &lt;code&gt;-w&lt;/code&gt;&lt;/strong&gt; WebSocket endpoint to connect to a running Chrome instance (e.g., ws://127.0.0.1:9222/devtools/browser/
   &lt;id&gt;
    ). Alternative to --browserUrl.
   &lt;/id&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--wsHeaders&lt;/code&gt;/ &lt;code&gt;--ws-headers&lt;/code&gt;&lt;/strong&gt; Custom headers for WebSocket connection in JSON format (e.g., '{"Authorization":"Bearer token"}'). Only works with --wsEndpoint.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--headless&lt;/code&gt;&lt;/strong&gt; Whether to run in headless (no UI) mode.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--executablePath&lt;/code&gt;/ &lt;code&gt;--executable-path&lt;/code&gt;, &lt;code&gt;-e&lt;/code&gt;&lt;/strong&gt; Path to custom Chrome executable.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--isolated&lt;/code&gt;&lt;/strong&gt; If specified, creates a temporary user-data-dir that is automatically cleaned up after the browser is closed. Defaults to false.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--userDataDir&lt;/code&gt;/ &lt;code&gt;--user-data-dir&lt;/code&gt;&lt;/strong&gt; Path to the user data directory for Chrome. Default is $HOME/.cache/chrome-devtools-mcp/chrome-profile$CHANNEL_SUFFIX_IF_NON_STABLE&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--channel&lt;/code&gt;&lt;/strong&gt; Specify a different Chrome channel that should be used. The default is the stable channel version.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Choices:&lt;/strong&gt; &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;canary&lt;/code&gt;, &lt;code&gt;beta&lt;/code&gt;, &lt;code&gt;dev&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--logFile&lt;/code&gt;/ &lt;code&gt;--log-file&lt;/code&gt;&lt;/strong&gt; Path to a file to write debug logs to. Set the env variable &lt;code&gt;DEBUG&lt;/code&gt; to &lt;code&gt;*&lt;/code&gt; to enable verbose logs. Useful for submitting bug reports.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--viewport&lt;/code&gt;&lt;/strong&gt; Initial viewport size for the Chrome instances started by the server. For example, &lt;code&gt;1280x720&lt;/code&gt;. In headless mode, max size is 3840x2160px.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--proxyServer&lt;/code&gt;/ &lt;code&gt;--proxy-server&lt;/code&gt;&lt;/strong&gt; Proxy server configuration for Chrome passed as --proxy-server when launching the browser. See &lt;a href="https://www.chromium.org/developers/design-documents/network-settings/"&gt;https://www.chromium.org/developers/design-documents/network-settings/&lt;/a&gt; for details.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--acceptInsecureCerts&lt;/code&gt;/ &lt;code&gt;--accept-insecure-certs&lt;/code&gt;&lt;/strong&gt; If enabled, ignores errors relative to self-signed and expired certificates. Use with caution.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--chromeArg&lt;/code&gt;/ &lt;code&gt;--chrome-arg&lt;/code&gt;&lt;/strong&gt; Additional arguments for Chrome. Only applies when Chrome is launched by chrome-devtools-mcp.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; array&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--ignoreDefaultChromeArg&lt;/code&gt;/ &lt;code&gt;--ignore-default-chrome-arg&lt;/code&gt;&lt;/strong&gt; Explicitly disable default arguments for Chrome. Only applies when Chrome is launched by chrome-devtools-mcp.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; array&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--categoryEmulation&lt;/code&gt;/ &lt;code&gt;--category-emulation&lt;/code&gt;&lt;/strong&gt; Set to false to exclude tools related to emulation.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--categoryPerformance&lt;/code&gt;/ &lt;code&gt;--category-performance&lt;/code&gt;&lt;/strong&gt; Set to false to exclude tools related to performance.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--categoryNetwork&lt;/code&gt;/ &lt;code&gt;--category-network&lt;/code&gt;&lt;/strong&gt; Set to false to exclude tools related to network.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END AUTO GENERATED OPTIONS --&gt; 
&lt;p&gt;Pass them via the &lt;code&gt;args&lt;/code&gt; property in the JSON configuration. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--channel=canary",
        "--headless=true",
        "--isolated=true"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting via WebSocket with custom headers&lt;/h3&gt; 
&lt;p&gt;You can connect directly to a Chrome WebSocket endpoint and include custom headers (e.g., for authentication):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--wsEndpoint=ws://127.0.0.1:9222/devtools/browser/&amp;lt;id&amp;gt;",
        "--wsHeaders={\"Authorization\":\"Bearer YOUR_TOKEN\"}"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To get the WebSocket endpoint from a running Chrome instance, visit &lt;code&gt;http://127.0.0.1:9222/json/version&lt;/code&gt; and look for the &lt;code&gt;webSocketDebuggerUrl&lt;/code&gt; field.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;npx chrome-devtools-mcp@latest --help&lt;/code&gt; to see all available configuration options.&lt;/p&gt; 
&lt;h2&gt;Concepts&lt;/h2&gt; 
&lt;h3&gt;User data directory&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;chrome-devtools-mcp&lt;/code&gt; starts a Chrome's stable channel instance using the following user data directory:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Linux / macOS: &lt;code&gt;$HOME/.cache/chrome-devtools-mcp/chrome-profile-$CHANNEL&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Windows: &lt;code&gt;%HOMEPATH%/.cache/chrome-devtools-mcp/chrome-profile-$CHANNEL&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The user data directory is not cleared between runs and shared across all instances of &lt;code&gt;chrome-devtools-mcp&lt;/code&gt;. Set the &lt;code&gt;isolated&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt; to use a temporary user data dir instead which will be cleared automatically after the browser is closed.&lt;/p&gt; 
&lt;h3&gt;Connecting to a running Chrome instance&lt;/h3&gt; 
&lt;p&gt;By default, the Chrome DevTools MCP server will start a new Chrome instance with a dedicated profile. This might not be ideal in all situations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you would like to maintain the same application state when alternating between manual site testing and agent-driven testing.&lt;/li&gt; 
 &lt;li&gt;When the MCP needs to sign into a website. Some accounts may prevent sign-in when the browser is controlled via WebDriver (the default launch mechanism for the Chrome DevTools MCP server).&lt;/li&gt; 
 &lt;li&gt;If you're running your LLM inside a sandboxed environment, but you would like to connect to a Chrome instance that runs outside the sandbox.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In these cases, start Chrome first and let the Chrome DevTools MCP server connect to it. There are two ways to do so:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic connection (available in Chrome 144)&lt;/strong&gt;: best for sharing state between manual and agent-driven testing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manual connection via remote debugging port&lt;/strong&gt;: best when running inside a sandboxed environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Automatically connecting to a running Chrome instance&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Set up remote debugging in Chrome&lt;/p&gt; 
&lt;p&gt;In Chrome (&amp;gt;= M144), do the following to set up remote debugging:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;chrome://inspect/#remote-debugging&lt;/code&gt; to enable remote debugging.&lt;/li&gt; 
 &lt;li&gt;Follow the dialog UI to allow or disallow incoming debugging connections.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Configure Chrome DevTools MCP server to automatically connect to a running Chrome Instance&lt;/p&gt; 
&lt;p&gt;To connect the &lt;code&gt;chrome-devtools-mcp&lt;/code&gt; server to the running Chrome instance, use &lt;code&gt;--autoConnect&lt;/code&gt; command line argument for the MCP server.&lt;/p&gt; 
&lt;p&gt;The following code snippet is an example configuration for gemini-cli:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": ["chrome-devtools-mcp@latest", "--autoConnect", "--channel=beta"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: you have to specify &lt;code&gt;--channel=beta&lt;/code&gt; until Chrome M144 has reached the stable channel.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Test your setup&lt;/p&gt; 
&lt;p&gt;Make sure your browser is running. Open gemini-cli and run the following prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-none"&gt;Check the performance of https://developers.chrome.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; The &lt;code&gt;autoConnect&lt;/code&gt; option requires the user to start Chrome. If the user has multiple active profiles, the MCP server will connect to the default profile (as determined by Chrome). The MCP server has access to all open windows for the selected profile.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The Chrome DevTools MCP server will try to connect to your running Chrome instance. It shows a dialog asking for user permission.&lt;/p&gt; 
&lt;p&gt;Clicking &lt;strong&gt;Allow&lt;/strong&gt; results in the Chrome DevTools MCP server opening &lt;a href="http://developers.chrome.com"&gt;developers.chrome.com&lt;/a&gt; and taking a performance trace.&lt;/p&gt; 
&lt;h4&gt;Manual connection using port forwarding&lt;/h4&gt; 
&lt;p&gt;You can connect to a running Chrome instance by using the &lt;code&gt;--browser-url&lt;/code&gt; option. This is useful if you are running the MCP server in a sandboxed environment that does not allow starting a new Chrome instance.&lt;/p&gt; 
&lt;p&gt;Here is a step-by-step guide on how to connect to a running Chrome instance:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 1: Configure the MCP client&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Add the &lt;code&gt;--browser-url&lt;/code&gt; option to your MCP client configuration. The value of this option should be the URL of the running Chrome instance. &lt;code&gt;http://127.0.0.1:9222&lt;/code&gt; is a common default.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--browser-url=http://127.0.0.1:9222"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 2: Start the Chrome browser&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;br /&gt; Enabling the remote debugging port opens up a debugging port on the running browser instance. Any application on your machine can connect to this port and control the browser. Make sure that you are not browsing any sensitive websites while the debugging port is open.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Start the Chrome browser with the remote debugging port enabled. Make sure to close any running Chrome instances before starting a new one with the debugging port enabled. The port number you choose must be the same as the one you specified in the &lt;code&gt;--browser-url&lt;/code&gt; option in your MCP client configuration.&lt;/p&gt; 
&lt;p&gt;For security reasons, &lt;a href="https://developer.chrome.com/blog/remote-debugging-port"&gt;Chrome requires you to use a non-default user data directory&lt;/a&gt; when enabling the remote debugging port. You can specify a custom directory using the &lt;code&gt;--user-data-dir&lt;/code&gt; flag. This ensures that your regular browsing profile and data are not exposed to the debugging session.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --remote-debugging-port=9222 --user-data-dir=/tmp/chrome-profile-stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Linux&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/usr/bin/google-chrome --remote-debugging-port=9222 --user-data-dir=/tmp/chrome-profile-stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;"C:\Program Files\Google\Chrome\Application\chrome.exe" --remote-debugging-port=9222 --user-data-dir="%TEMP%\chrome-profile-stable"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 3: Test your setup&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;After configuring the MCP client and starting the Chrome browser, you can test your setup by running a simple prompt in your MCP client:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Check the performance of https://developers.chrome.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Your MCP client should connect to the running Chrome instance and receive a performance report.&lt;/p&gt; 
&lt;p&gt;If you hit VM-to-host port forwarding issues, see the ‚ÄúRemote debugging between virtual machine (VM) and host fails‚Äù section in &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/troubleshooting.md#remote-debugging-between-virtual-machine-vm-and-host-fails"&gt;&lt;code&gt;docs/troubleshooting.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more details on remote debugging, see the &lt;a href="https://developer.chrome.com/docs/devtools/remote-debugging/"&gt;Chrome DevTools documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Known limitations&lt;/h2&gt; 
&lt;h3&gt;Operating system sandboxes&lt;/h3&gt; 
&lt;p&gt;Some MCP clients allow sandboxing the MCP server using macOS Seatbelt or Linux containers. If sandboxes are enabled, &lt;code&gt;chrome-devtools-mcp&lt;/code&gt; is not able to start Chrome that requires permissions to create its own sandboxes. As a workaround, either disable sandboxing for &lt;code&gt;chrome-devtools-mcp&lt;/code&gt; in your MCP client or use &lt;code&gt;--browser-url&lt;/code&gt; to connect to a Chrome instance that you start manually outside of the MCP client sandbox.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Lissy93/web-check</title>
      <link>https://github.com/Lissy93/web-check</link>
      <description>&lt;p&gt;üïµÔ∏è‚Äç‚ôÇÔ∏è All-in-one OSINT tool for analysing any website&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Web-Check&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://i.ibb.co/q1gZN2p/web-check-logo.png" width="96" /&gt;&lt;br /&gt; &lt;b&gt;&lt;i&gt;Comprehensive, on-demand open source intelligence for any website&lt;/i&gt;&lt;/b&gt; &lt;br /&gt; &lt;b&gt;üåê &lt;a href="https://web-check.xyz/"&gt;web-check.xyz&lt;/a&gt;&lt;/b&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;sup&gt;Kindly supported by:&lt;/sup&gt;&lt;br /&gt; &lt;a href="https://terminaltrove.com/?utm_campaign=github&amp;amp;utm_medium=referral&amp;amp;utm_content=web-check&amp;amp;utm_source=wcgh"&gt; &lt;img src="https://i.ibb.co/8jrrcZ0/IMG-7210.jpg" width="300" alt="Terminal Trove" /&gt; &lt;br /&gt; &lt;strong&gt;The $HOME of all things in the terminal.&lt;/strong&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://terminaltrove.com/newsletter?utm_campaign=github&amp;amp;utm_medium=referral&amp;amp;utm_content=web-check&amp;amp;utm_source=wcgh"&gt; &lt;sub&gt;Find your next CLI / TUI tool and more at Terminal Trove,&lt;/sub&gt; &lt;br /&gt; &lt;sup&gt;Get updates on new tools on our newsletter.&lt;/sup&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;sup&gt;Kindly supported by:&lt;/sup&gt;&lt;br /&gt; &lt;a href="https://go.warp.dev/web-check"&gt;&lt;b&gt;Warp&lt;/b&gt;, built for coding with multiple AI agents&lt;/a&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://go.warp.dev/web-check"&gt;&lt;img width="640" src="https://github.com/warpdotdev/brand-assets/raw/main/Github/Sponsor/Warp-Github-LG-02.png?raw=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h4&gt;Contents&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#about"&gt;About&lt;/a&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#screenshot"&gt;Screenshot&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#live-demo"&gt;Live Demo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#mirror"&gt;Mirror&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#usage"&gt;Usage&lt;/a&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#deployment"&gt;Deployment&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#deploying---option-1-netlify"&gt;Option#1: Netlify&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#deploying---option-2-vercel"&gt;Option#2: Vercel&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#deploying---option-3-docker"&gt;Option#3: Docker&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#deploying---option-4-from-source"&gt;Option#4: Source&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#configuring"&gt;Configuration Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#developing"&gt;Developer Setup&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#community"&gt;Community&lt;/a&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#reporting-bugs"&gt;Bugs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#supporting"&gt;Support&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#license"&gt;License&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Get an insight into the inner-workings of a given website: uncover potential attack vectors, analyse server architecture, view security configurations, and learn what technologies a site is using.&lt;/p&gt; 
&lt;p&gt;Currently the dashboard will show: IP info, SSL chain, DNS records, cookies, headers, domain info, search crawl rules, page map, server location, redirect ledger, open ports, traceroute, DNS security extensions, site performance, trackers, associated hostnames, carbon footprint. Stay tuned, as I'll add more soon!&lt;/p&gt; 
&lt;p&gt;The aim is to help you easily understand, optimize and secure your website.&lt;/p&gt; 
&lt;h3&gt;Screenshot&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Expand Screenshot&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://web-check.as93.net/"&gt;&lt;img src="https://raw.githubusercontent.com/Lissy93/web-check/master/.github/screenshots/web-check-screenshot1.png" alt="Screenshot" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;a href="https://github.com/Lissy93/web-check/tree/master/.github/screenshots"&gt;&lt;img src="https://i.ibb.co/r0jXN6s/web-check.png" alt="Screenshot" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Live Demo&lt;/h3&gt; 
&lt;p&gt;A hosted version can be accessed at: &lt;strong&gt;&lt;a href="https://web-check.as93.net"&gt;web-check.as93.net&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Mirror&lt;/h3&gt; 
&lt;p&gt;The source for this repo is mirrored to CodeBerg, available at: &lt;strong&gt;&lt;a href="https://codeberg.org/alicia/web-check"&gt;codeberg.org/alicia/web-check&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Status&lt;/h3&gt; 
&lt;p&gt;Build &amp;amp; Deploys: &lt;a href="https://app.netlify.com/sites/web-check/deploys"&gt;&lt;img src="https://api.netlify.com/api/v1/badges/c43453c1-5333-4df7-889b-c1d2b52183c0/deploy-status" alt="Netlify Status" /&gt;&lt;/a&gt; &lt;a href="https://vercel.com/as93/web-check/"&gt;&lt;img src="https://therealsujitk-vercel-badge.vercel.app/?app=web-check-ten" alt="Vercel Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Lissy93/web-check/actions/workflows/docker.yml"&gt;&lt;img src="https://github.com/Lissy93/web-check/actions/workflows/docker.yml/badge.svg?sanitize=true" alt="üê≥ Build + Publish Docker Image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Lissy93/web-check/actions/workflows/deploy-aws.yml"&gt;&lt;img src="https://github.com/Lissy93/web-check/actions/workflows/deploy-aws.yml/badge.svg?sanitize=true" alt="üöÄ Deploy to AWS" /&gt;&lt;/a&gt; &lt;br /&gt; Repo Management &amp;amp; Miscellaneous: &lt;a href="https://github.com/Lissy93/web-check/actions/workflows/mirror.yml"&gt;&lt;img src="https://github.com/Lissy93/web-check/actions/workflows/mirror.yml/badge.svg?sanitize=true" alt="ü™û Mirror to Codeberg" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Lissy93/web-check/actions/workflows/credits.yml"&gt;&lt;img src="https://github.com/Lissy93/web-check/actions/workflows/credits.yml/badge.svg?sanitize=true" alt="üíì Inserts Contributors &amp;amp; Sponsors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Click to expand / collapse section&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;sup&gt;&lt;strong&gt;Note&lt;/strong&gt; &lt;em&gt;this list needs updating, many more jobs have been added since...&lt;/em&gt;&lt;/sup&gt;&lt;/p&gt; 
 &lt;p&gt;The following section outlines the core features, and briefly explains why this data might be useful for you to know, as well as linking to further resources for learning more.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;IP Info&lt;/b&gt;&lt;/summary&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;An IP address (Internet Protocol address) is a numerical label assigned to each device connected to a network / the internet. The IP associated with a given domain can be found by querying the Domain Name System (DNS) for the domain's A (address) record.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Finding the IP of a given server is the first step to conducting further investigations, as it allows us to probe the server for additional info. Including creating a detailed map of a target's network infrastructure, pinpointing the physical location of a server, identifying the hosting service, and even discovering other domains that are hosted on the same IP address.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.digitalocean.com/community/tutorials/understanding-ip-addresses-subnets-and-cidr-notation-for-networking"&gt;Understanding IP Addresses&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/IP_address"&gt;IP Addresses - Wiki&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc791"&gt;RFC-791 Internet Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://whatismyipaddress.com/"&gt;whatismyipaddress.com&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;SSL Chain&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/kB7LsV1/wc-ssl.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;SSL certificates are digital certificates that authenticate the identity of a website or server, enable secure encrypted communication (HTTPS), and establish trust between clients and servers. A valid SSL certificate is required for a website to be able to use the HTTPS protocol, and encrypt user + site data in transit. SSL certificates are issued by Certificate Authorities (CAs), which are trusted third parties that verify the identity and legitimacy of the certificate holder.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;SSL certificates not only provide the assurance that data transmission to and from the website is secure, but they also provide valuable OSINT data. Information from an SSL certificate can include the issuing authority, the domain name, its validity period, and sometimes even organization details. This can be useful for verifying the authenticity of a website, understanding its security setup, or even for discovering associated subdomains or other services.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Transport_Layer_Security"&gt;TLS - Wiki&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.cloudflare.com/learning/ssl/what-is-ssl/"&gt;What is SSL (via Cloudflare learning)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc8446"&gt;RFC-8446 - TLS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.sslshopper.com/ssl-checker.html"&gt;SSL Checker&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;DNS Records&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/7Q1kMwM/wc-dns.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This task involves looking up the DNS records associated with a specific domain. DNS is a system that translates human-readable domain names into IP addresses that computers use to communicate. Various types of DNS records exist, including A (address), MX (mail exchange), NS (name server), CNAME (canonical name), and TXT (text), among others.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Extracting DNS records can provide a wealth of information in an OSINT investigation. For example, A and AAAA records can disclose IP addresses associated with a domain, potentially revealing the location of servers. MX records can give clues about a domain's email provider. TXT records are often used for various administrative purposes and can sometimes inadvertently leak internal information. Understanding a domain's DNS setup can also be useful in understanding how its online infrastructure is built and managed.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.cloudflare.com/learning/dns/dns-records/"&gt;What are DNS records? (via Cloudflare learning)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/List_of_DNS_record_types"&gt;DNS Record Types&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc1035"&gt;RFC-1035 - DNS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://mxtoolbox.com/DNSLookup.aspx"&gt;DNS Lookup (via MxToolbox)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Cookies&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/TTQ6DtP/wc-cookies.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;The Cookies task involves examining the HTTP cookies set by the target website. Cookies are small pieces of data stored on the user's computer by the web browser while browsing a website. They hold a modest amount of data specific to a particular client and website, such as site preferences, the state of the user's session, or tracking information.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Cookies can disclose information about how the website tracks and interacts with its users. For instance, session cookies can reveal how user sessions are managed, and tracking cookies can hint at what kind of tracking or analytics frameworks are being used. Additionally, examining cookie policies and practices can offer insights into the site's security settings and compliance with privacy regulations.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies"&gt;HTTP Cookie Docs (Mozilla)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.cloudflare.com/learning/privacy/what-are-cookies/"&gt;What are Cookies (via Cloudflare Learning)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/06-Session_Management_Testing/02-Testing_for_Cookies_Attributes"&gt;Testing for Cookie Attributes (OWASP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc6265"&gt;RFC-6265 - Coolies&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Crawl Rules&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/KwQCjPf/wc-robots.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Robots.txt is a file found (usually) at the root of a domain, and is used to implement the Robots Exclusion Protocol (REP) to indicate which pages should be ignored by which crawlers and bots. It's good practice to avoid search engine crawlers from over-loading your site, but should not be used to keep pages out of search results (use the noindex meta tag or header instead).&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;It's often useful to check the robots.txt file during an investigation, as it can sometimes disclose the directories and pages that the site owner doesn't want to be indexed, potentially because they contain sensitive information, or reveal the existence of otherwise hidden or unlinked directories. Additionally, understanding crawl rules may offer insights into a website's SEO strategies.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://developers.google.com/search/docs/advanced/robots/intro"&gt;Google Search Docs - Robots.txt&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://moz.com/learn/seo/robotstxt"&gt;Learn about robots.txt (via Moz.com)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/rfc9309/"&gt;RFC-9309 - Robots Exclusion Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard"&gt;Robots.txt - wiki&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Headers&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/t3xcwP1/wc-headers.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;The Headers task involves extracting and interpreting the HTTP headers sent by the target website during the request-response cycle. HTTP headers are key-value pairs sent at the start of an HTTP response, or before the actual data. Headers contain important directives for how to handle the data being transferred, including cache policies, content types, encoding, server information, security policies, and more.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Analyzing HTTP headers can provide significant insights in an OSINT investigation. Headers can reveal specific server configurations, chosen technologies, caching directives, and various security settings. This information can help to determine a website's underlying technology stack, server-side security measures, potential vulnerabilities, and general operational practices.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers"&gt;HTTP Headers - Docs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc7231#section-7"&gt;RFC-7231 Section 7 - Headers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/List_of_HTTP_header_fields"&gt;List of header response fields&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://owasp.org/www-project-secure-headers/"&gt;OWASP Secure Headers Project&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Quality Metrics&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/Kqg8rx7/wc-quality.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Using Lighthouse, the Quality Metrics task measures the performance, accessibility, best practices, and SEO of the target website. This returns a simple checklist of 100 core metrics, along with a score for each category, to gauge the overall quality of a given site.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Useful for assessing a site's technical health, SEO issues, identify vulnerabilities, and ensure compliance with standards.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://developer.chrome.com/docs/lighthouse/"&gt;Lighthouse Docs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://developers.google.com/speed"&gt;Google Page Speed Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.w3.org/WAI/test-evaluate/"&gt;W3 Accessibility Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://search.google.com/search-console"&gt;Google Search Console&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.seobility.net/en/seocheck/"&gt;SEO Checker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.pwabuilder.com/"&gt;PWA Builder&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Server Location&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/cXH2hfR/wc-location.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;The Server Location task determines the physical location of the server hosting a given website based on its IP address. This is done by looking up the IP in a location database, which maps the IP to a lat + long of known data centers and ISPs. From the latitude and longitude, it's then possible to show additional contextual info, like a pin on the map, along with address, flag, time zone, currency, etc.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Knowing the server location is a good first step in better understanding a website. For site owners this aids in optimizing content delivery, ensuring compliance with data residency requirements, and identifying potential latency issues that may impact user experience in specific geographical regions. And for security researcher, assess the risk posed by specific regions or jurisdictions regarding cyber threats and regulations.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://geobytes.com/iplocator/"&gt;IP Locator&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Internet_geolocation"&gt;Internet Geolocation - Wiki&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Associated Hosts&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/25j1sT7/wc-hosts.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This task involves identifying and listing all domains and subdomains (hostnames) that are associated with the website's primary domain. This process often involves DNS enumeration to discover any linked domains and hostnames, as well as looking at known DNS records.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;During an investigation, understanding the full scope of a target's web presence is critical. Associated domains could lead to uncovering related projects, backup sites, development/test sites, or services linked to the main site. These can sometimes provide additional information or potential security vulnerabilities. A comprehensive list of associated domains and hostnames can also give an overview of the organization's structure and online footprint.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/DNS_enumeration"&gt;DNS Enumeration - Wiki&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://owasp.org/www-project-web-security-testing-guide/latest/4-Web_Application_Security_Testing/01-Information_Gathering/04-Enumerate_Applications_on_Webserver"&gt;OWASP - Enumerate Applications on Webserver&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://dnsdumpster.com/"&gt;DNS Enumeration - DNS Dumpster&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://subdomainfinder.c99.nl/"&gt;Subdomain Finder&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Redirect Chain&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/hVVrmwh/wc-redirects.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This task traces the sequence of HTTP redirects that occur from the original URL to the final destination URL. An HTTP redirect is a response with a status code that advises the client to go to another URL. Redirects can occur for several reasons, such as URL normalization (directing to the www version of the site), enforcing HTTPS, URL shorteners, or forwarding users to a new site location.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Understanding the redirect chain can be useful for several reasons. From a security perspective, long or complicated redirect chains can be a sign of potential security risks, such as unencrypted redirects in the chain. Additionally, redirects can impact website performance and SEO, as each redirect introduces additional round-trip-time (RTT). For OSINT, understanding the redirect chain can help identify relationships between different domains or reveal the use of certain technologies or hosting providers.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections"&gt;HTTP Redirects - MDN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/URL_redirection"&gt;URL Redirection - Wiki&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ahrefs.com/blog/301-redirects/"&gt;301 Redirects explained&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;TXT Records&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/wyt21QN/wc-txt-records.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;TXT records are a type of DNS record that provides text information to sources outside your domain. They can be used for a variety of purposes, such as verifying domain ownership, ensuring email security, and even preventing unauthorized changes to your website.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;The TXT records often reveal which external services and technologies are being used with a given domain. They may reveal details about the domain's email configuration, the use of specific services like Google Workspace or Microsoft 365, or security measures in place such as SPF and DKIM. Understanding these details can give an insight into the technologies used by the organization, their email security practices, and potential vulnerabilities.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.cloudflare.com/learning/dns/dns-records/dns-txt-record/"&gt;TXT Records (via Cloudflare Learning)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/TXT_record"&gt;TXT Records - Wiki&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc1464"&gt;RFC-1464 - TXT Records&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://mxtoolbox.com/TXTLookup.aspx"&gt;TXT Record Lookup (via MxToolbox)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Server Status&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/V9CNLBK/wc-status.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Checks if a server is online and responding to requests.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Open Ports&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/F8D1hmf/wc-ports.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Open ports on a server are endpoints of communication which are available for establishing connections with clients. Each port corresponds to a specific service or protocol, such as HTTP (port 80), HTTPS (port 443), FTP (port 21), etc. The open ports on a server can be determined using techniques such as port scanning.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Knowing which ports are open on a server can provide information about the services running on that server, useful for understanding the potential vulnerabilities of the system, or for understanding the nature of the services the server is providing.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers"&gt;List of TCP &amp;amp; UDP Port Numbers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://nmap.org/book/man-port-scanning-basics.html"&gt;NMAP - Port Scanning Basics&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Traceroute&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/M59qgxP/wc-trace-route.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Traceroute is a network diagnostic tool used to track in real-time the pathway taken by a packet of information from one system to another. It records each hop along the route, providing details about the IPs of routers and the delay at each point.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;In OSINT investigations, traceroute can provide insights about the routing paths and geography of the network infrastructure supporting a website or service. This can help to identify network bottlenecks, potential censorship or manipulation of network traffic, and give an overall sense of the network's structure and efficiency. Additionally, the IP addresses collected during the traceroute may provide additional points of inquiry for further OSINT investigation.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Carbon Footprint&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/5v6fSyw/Screenshot-from-2023-07-29-19-07-50.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This task calculates the estimated carbon footprint of a website. It's based on the amount of data being transferred and processed, and the energy usage of the servers that host and deliver the website. The larger the website and the more complex its features, the higher its carbon footprint is likely to be.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;From an OSINT perspective, understanding a website's carbon footprint doesn't directly provide insights into its internal workings or the organization behind it. However, it can still be valuable data in broader analyses, especially in contexts where environmental impact is a consideration. For example, it can be useful for activists, researchers, or ethical hackers who are interested in the sustainability of digital infrastructure, and who want to hold organizations accountable for their environmental impact.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.websitecarbon.com/"&gt;WebsiteCarbon - Carbon Calculator&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.thegreenwebfoundation.org/"&gt;The Green Web Foundation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ecofriendlyweb.org/"&gt;The Eco Friendly Web Alliance&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.reset.org/"&gt;Reset.org&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.wired.co.uk/article/internet-carbon-footprint"&gt;Your website is killing the planet - via Wired&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Server Info&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/Mk1jx32/wc-server.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This task retrieves various pieces of information about the server hosting the target website. This can include the server type (e.g., Apache, Nginx), the hosting provider, the Autonomous System Number (ASN), and more. The information is usually obtained through a combination of IP address lookups and analysis of HTTP response headers.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;In an OSINT context, server information can provide valuable clues about the organization behind a website. For instance, the choice of hosting provider could suggest the geographical region in which the organization operates, while the server type could hint at the technologies used by the organization. The ASN could also be used to find other domains hosted by the same organization.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Whois Lookup&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/89WLp14/wc-domain.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This task retrieves Whois records for the target domain. Whois records are a rich source of information, including the name and contact information of the domain registrant, the domain's creation and expiration dates, the domain's nameservers, and more. The information is usually obtained through a query to a Whois database server.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;In an OSINT context, Whois records can provide valuable clues about the entity behind a website. They can show when the domain was first registered and when it's set to expire, which could provide insights into the operational timeline of the entity. The contact information, though often redacted or anonymized, can sometimes lead to additional avenues of investigation. The nameservers could also be used to link together multiple domains owned by the same entity.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Domain Info&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/89WLp14/wc-domain.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This task retrieves Whois records for the target domain. Whois records are a rich source of information, including the name and contact information of the domain registrant, the domain's creation and expiration dates, the domain's nameservers, and more. The information is usually obtained through a query to a Whois database server.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;In an OSINT context, Whois records can provide valuable clues about the entity behind a website. They can show when the domain was first registered and when it's set to expire, which could provide insights into the operational timeline of the entity. The contact information, though often redacted or anonymized, can sometimes lead to additional avenues of investigation. The nameservers could also be used to link together multiple domains owned by the same entity.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;DNS Security Extensions&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/J54zVmQ/wc-dnssec.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Without DNSSEC, it's possible for MITM attackers to spoof records and lead users to phishing sites. This is because the DNS system includes no built-in methods to verify that the response to the request was not forged, or that any other part of the process wasn‚Äôt interrupted by an attacker. The DNS Security Extensions (DNSSEC) secures DNS lookups by signing your DNS records using public keys, so browsers can detect if the response has been tampered with. Another solution to this issue is DoH (DNS over HTTPS) and DoT (DNS over TLD).&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;DNSSEC information provides insight into an organization's level of cybersecurity maturity and potential vulnerabilities, particularly around DNS spoofing and cache poisoning. If no DNS secururity (DNSSEC, DoH, DoT, etc) is implemented, this may provide an entry point for an attacker.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Site Features&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/gP4P6kp/wc-features.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Checks which core features are present on a site. If a feature as marked as dead, that means it's not being actively used at load time&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;This is useful to understand what a site is capable of, and what technologies to look for&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;HTTP Strict Transport Security&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/k253fq4/Screenshot-from-2023-07-17-20-10-52.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;HTTP Strict Transport Security (HSTS) is a web security policy mechanism that helps protect websites against protocol downgrade attacks and cookie hijacking. A website can be included in the HSTS preload list by conforming to a set of requirements and then submitting itself to the list.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;There are several reasons why it's important for a site to be HSTS enabled: 1. User bookmarks or manually types &lt;a href="http://example.com"&gt;http://example.com&lt;/a&gt; and is subject to a man-in-the-middle attacker HSTS automatically redirects HTTP requests to HTTPS for the target domain 2. Web application that is intended to be purely HTTPS inadvertently contains HTTP links or serves content over HTTP HSTS automatically redirects HTTP requests to HTTPS for the target domain 3. A man-in-the-middle attacker attempts to intercept traffic from a victim user using an invalid certificate and hopes the user will accept the bad certificate HSTS does not allow a user to override the invalid certificate message&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
   &lt;li&gt;[undefined](function link() { [native code] })&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;DNS Server&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/tKpL8F9/Screenshot-from-2023-08-12-15-43-12.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This check determines the DNS server(s) that the requested URL / IP resolves to. Also fires off a rudimentary check to see if the DNS server supports DoH, and weather it's vulnerable to DNS cache poisoning.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Tech Stack&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/bBQSQNz/Screenshot-from-2023-08-12-15-43-46.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Checks what technologies a site is built with. This is done by fetching and parsing the site, then comparing it against a bit list of RegEx maintained by Wappalyzer to identify the unique fingerprints that different technologies leave.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Identifying a website's tech stack aids in evaluating its security by exposing potential vulnerabilities, informs competitive analyses and development decisions, and can guide tailored marketing strategies. Ethical application of this knowledge is crucial to avoid harmful activities like data theft or unauthorized intrusion.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/wappalyzer/wappalyzer/tree/master/src/technologies"&gt;Wappalyzer fingerprints&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://builtwith.com/"&gt;BuiltWith - Check what tech a site is using&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Listed Pages&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/GtrCQYq/Screenshot-from-2023-07-21-12-28-38.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This job finds and parses a site's listed sitemap. This file lists public sub-pages on the site, which the author wishes to be crawled by search engines. Sitemaps help with SEO, but are also useful for seeing all a sites public content at a glance.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Understand the structure of a site's public-facing content, and for site-owners, check that you're site's sitemap is accessible, parsable and contains everything you wish it to.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://developers.google.com/search/docs/crawling-indexing/sitemaps/overview"&gt;Learn about Sitemaps&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.sitemaps.org/protocol.html"&gt;Sitemap XML spec&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.conductor.com/academy/xml-sitemap/"&gt;Sitemap tutorial&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Security.txt&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/tq1FT5r/Screenshot-from-2023-07-24-20-31-21.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;The security.txt file tells researchers how they can responsibly disclose any security issues found on your site. The standard was proposed in RFC 9116, and specifies that this file should include a point of contact (email address), as well as optionally other info, like a link to the security disclosure policy, PGP key, proffered language, policy expiry and more. The file should be located at the root of your domain, either at /security.txt or /.well-known/security.txt.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;This is important, as without a defined point of contact a security researcher may be unable to report a critical security issue, or may use insecure or possibly public channels to do so. From an OSINT perspective, you may also glean info about a site including their posture on security, their CSAF provider, and meta data from the PGP public key.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://securitytxt.org/"&gt;securitytxt.org&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc9116"&gt;RFC-9116 Proposal&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/rfc9116/"&gt;RFC-9116 History&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Security.txt"&gt;Security.txt (Wikipedia)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.cloudflare.com/.well-known/security.txt"&gt;Example security.txt (Cloudflare)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pieterbakker.com/implementing-security-txt/"&gt;Tutorial for creating security.txt (Pieter Bakker)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Linked Pages&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/LtK14XR/Screenshot-from-2023-07-29-11-16-44.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Displays all internal and external links found on a site, identified by the href attributes attached to anchor elements.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;For site owners, this is useful for diagnosing SEO issues, improving the site structure, understanding how content is inter-connected. External links can show partnerships, dependencies, and potential reputation risks. From a security standpoint, the outbound links can help identify any potential malicious or compromised sites the website is unknowingly linking to. Analyzing internal links can aid in understanding the site's structure and potentially uncover hidden or vulnerable pages which are not intended to be public. And for an OSINT investigator, it can aid in building a comprehensive understanding of the target, uncovering related entities, resources, or even potential hidden parts of the site.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://validator.w3.org/checklink"&gt;W3C Link Checker&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Social Tags&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/4srTT1w/Screenshot-from-2023-07-29-11-15-27.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Websites can include certain meta tags, that tell search engines and social media platforms what info to display. This usually includes a title, description, thumbnail, keywords, author, social accounts, etc.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Adding this data to your site will boost SEO, and as an OSINT researcher it can be useful to understand how a given web app describes itself&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://socialsharepreview.com/"&gt;SocialSharePreview.com&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://css-tricks.com/essential-meta-tags-social-media/"&gt;The guide to social meta tags&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.dev/learn/html/metadata/"&gt;Web.dev metadata tags&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ogp.me/"&gt;Open Graph Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://developer.twitter.com/en/docs/twitter-for-websites/cards/overview/abouts-cards"&gt;Twitter Cards&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://developers.facebook.com/docs/sharing/webmasters"&gt;Facebook Open Graph&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Email Configuration&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/yqhwx5G/Screenshot-from-2023-07-29-18-22-20.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;DMARC (Domain-based Message Authentication, Reporting &amp;amp; Conformance): DMARC is an email authentication protocol that works with SPF and DKIM to prevent email spoofing and phishing. It allows domain owners to specify how to handle unauthenticated mail via a published policy in DNS, and provides a way for receiving mail servers to send feedback about emails' compliance to the sender. BIMI (Brand Indicators for Message Identification): BIMI is an emerging email standard that enables organizations to display a logo in their customers' email clients automatically. BIMI ties the logo to the domain's DMARC record, providing another level of visual assurance to recipients that the email is legitimate. DKIM (DomainKeys Identified Mail): DKIM is an email security standard designed to make sure that messages were not altered in transit between the sending and recipient servers. It uses digital signatures linked to the domain of the sender to verify the sender and ensure message integrity. SPF (Sender Policy Framework): SPF is an email authentication method designed to prevent email spoofing. It specifies which mail servers are authorized to send email on behalf of a domain by creating a DNS record. This helps protect against spam by providing a way for receiving mail servers to check that incoming mail from a domain comes from a host authorized by that domain's administrators.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;This information is helpful for researchers as it helps assess a domain's email security posture, uncover potential vulnerabilities, and verify the legitimacy of emails for phishing detection. These details can also provide insight into the hosting environment, potential service providers, and the configuration patterns of a target organization, assisting in investigative efforts.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.cloudflare.com/learning/email-security/dmarc-dkim-spf/"&gt;Intro to DMARC, DKIM, and SPF (via Cloudflare)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://easydmarc.com/tools/domain-scanner"&gt;EasyDMARC Domain Scanner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://mxtoolbox.com/"&gt;MX Toolbox&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc7208"&gt;RFC-7208 - SPF&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc6376"&gt;RFC-6376 - DKIM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc7489"&gt;RFC-7489 - DMARC&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bimigroup.org/"&gt;BIMI Group&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Firewall Detection&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/MfcxQt2/Screenshot-from-2023-08-12-15-40-52.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;A WAF or web application firewall helps protect web applications by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web applications from attacks such as cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection, among others.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;It's useful to understand if a site is using a WAF, and which firewall software / service it is using, as this provides an insight into the sites protection against several attack vectors, but also may reveal vulnerabilities in the firewall itself.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.cloudflare.com/learning/ddos/glossary/web-application-firewall-waf/"&gt;What is a WAF (via Cloudflare Learning)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://owasp.org/www-community/Web_Application_Firewall"&gt;OWASP - Web Application Firewalls&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://owasp.org/www-pdf-archive/Best_Practices_Guide_WAF_v104.en.pdf"&gt;Web Application Firewall Best Practices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Web_application_firewall"&gt;WAF - Wiki&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;HTTP Security Features&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/LP05HMV/Screenshot-from-2023-08-12-15-40-28.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Correctly configured security HTTP headers adds a layer of protection against common attacks to your site. The main headers to be aware of are: HTTP Strict Transport Security (HSTS): Enforces the use of HTTPS, mitigating man-in-the-middle attacks and protocol downgrade attempts. Content Security Policy (CSP): Constrains web page resources to prevent cross-site scripting and data injection attacks. X-Content-Type-Options: Prevents browsers from MIME-sniffing a response away from the declared content type, curbing MIME-type confusion attacks. X-Frame-Options: Protects users from clickjacking attacks by controlling whether a browser should render the page in a &lt;code&gt;&amp;lt;frame&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;iframe&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;embed&amp;gt;&lt;/code&gt;, or &lt;code&gt;&amp;lt;object&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Reviewing security headers is important, as it offers insights into a site's defensive posture and potential vulnerabilities, enabling proactive mitigation and ensuring compliance with security best practices.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://owasp.org/www-project-secure-headers/"&gt;OWASP Secure Headers Project&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://cheatsheetseries.owasp.org/cheatsheets/HTTP_Headers_Cheat_Sheet.html"&gt;HTTP Header Cheatsheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://content-security-policy.com/"&gt;content-security-policy.com&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://resourcepolicy.fyi/"&gt;resourcepolicy.fyi&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://securityheaders.com/"&gt;HTTP Security Headers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://observatory.mozilla.org/"&gt;Mozilla Observatory&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP"&gt;CSP Docs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security"&gt;HSTS Docs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options"&gt;X-Content-Type-Options Docs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options"&gt;X-Frame-Options Docs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-XSS-Protection"&gt;X-XSS-Protection Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Archive History&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/nB9szT1/Screenshot-from-2023-08-14-22-31-16.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Fetches full history of archives from the Wayback machine&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;This is useful for understanding the history of a site, and how it has changed over time. It can also be useful for finding old versions of a site, or for finding content that has been removed.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://archive.org/web/"&gt;Wayback Machine&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Global Ranking&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/nkbczgb/Screenshot-from-2023-08-14-22-02-40.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This check shows the global rank of the requested site. This is only accurate for websites which are in the top 100 million list. We're using data from the Tranco project (see below), which collates the top sites on the web from Umbrella, Majestic, Quantcast, the Chrome User Experience Report and Cloudflare Radar.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Knowing a websites overall global rank can be useful for understanding the scale of the site, and for comparing it to other sites. It can also be useful for understanding the relative popularity of a site, and for identifying potential trends.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://tranco-list.eu/"&gt;Tranco List&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://tranco-list.eu/assets/tranco-ndss19.pdf"&gt;Tranco Research Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Block Detection&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/M5JSXbW/Screenshot-from-2023-08-26-12-12-43.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Checks access to the URL using 10+ of the most popular privacy, malware and parental control blocking DNS servers.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://threatjammer.com/osint-lists"&gt;ThreatJammer Lists&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Malware &amp;amp; Phishing Detection&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/hYgy621/Screenshot-from-2023-08-26-12-07-47.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;Checks if a site appears in several common malware and phishing lists, to determine it's threat level.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Knowing if a site is listed as a threat by any of these services can be useful for understanding the reputation of a site, and for identifying potential trends.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://urlhaus-api.abuse.ch/"&gt;URLHaus&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.phishtank.com/"&gt;PhishTank&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;TLS Cipher Suites&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/6ydtH5R/Screenshot-from-2023-08-26-12-09-58.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;These are combinations of cryptographic algorithms used by the server to establish a secure connection. It includes the key exchange algorithm, bulk encryption algorithm, MAC algorithm, and PRF (pseudorandom function).&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;This is important info to test for from a security perspective. Because a cipher suite is only as secure as the algorithms that it contains. If the version of encryption or authentication algorithm in a cipher suite have known vulnerabilities the cipher suite and TLS connection may then vulnerable to a downgrade or other attack&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/rbsec/sslscan"&gt;sslscan2 CLI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://nmap.org/nsedoc/scripts/ssl-enum-ciphers.html"&gt;ssl-enum-ciphers (NPMAP script)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;TLS Security Config&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/FmksZJt/Screenshot-from-2023-08-26-12-12-09.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This uses guidelines from Mozilla's TLS Observatory to check the security of the TLS configuration. It checks for bad configurations, which may leave the site vulnerable to attack, as well as giving advice on how to fix. It will also give suggestions around outdated and modern TLS configs&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;Understanding issues with a site's TLS configuration will help you address potential vulnerabilities, and ensure the site is using the latest and most secure TLS configuration.&lt;/p&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;TLS Handshake Simulation&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/F7qRZkh/Screenshot-from-2023-08-26-12-11-28.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This simulates how different clients (browsers, operating systems) would perform a TLS handshake with the server. It helps identify compatibility issues and insecure configurations.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;h6&gt;Useful Links&lt;/h6&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/"&gt;TLS Handshakes (via Cloudflare Learning)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.ssllabs.com/ssltest/"&gt;SSL Test (via SSL Labs)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;Screenshot&lt;/b&gt;&lt;/summary&gt; 
  &lt;img width="300" src="https://i.ibb.co/2F0x8kP/Screenshot-from-2023-07-29-18-34-48.png" align="right" /&gt; 
  &lt;h6&gt;Description&lt;/h6&gt; 
  &lt;p&gt;This check takes a screenshot of webpage that the requested URL / IP resolves to, and displays it.&lt;/p&gt; 
  &lt;h6&gt;Use Cases&lt;/h6&gt; 
  &lt;p&gt;This may be useful to see what a given website looks like, free of the constraints of your browser, IP, or location.&lt;/p&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;p&gt;Read more here: &lt;strong&gt;&lt;a href="https://web-check.xyz/about"&gt;web-check.xyz/about&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Deployment&lt;/h3&gt; 
&lt;h3&gt;Deploying - Option #1: Netlify&lt;/h3&gt; 
&lt;p&gt;Click the button below, to deploy to Netlify üëá&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.netlify.com/start/deploy?repository=https://github.com/lissy93/web-check"&gt;&lt;img src="https://img.shields.io/badge/Deploy-Netlify-%2330c8c9?style=for-the-badge&amp;amp;logo=netlify&amp;amp;labelColor=1e0e41" alt="Deploy to Netlify" title="Deploy Web-Check to Netlify, via 1-Click Script" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Deploying - Option #2: Vercel&lt;/h3&gt; 
&lt;p&gt;Click the button below, to deploy to Vercel üëá&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flissy93%2Fweb-check&amp;amp;project-name=web-check&amp;amp;repository-name=web-check-fork&amp;amp;demo-title=Web-Check%20Demo&amp;amp;demo-description=Check%20out%20web-check.xyz%20to%20see%20a%20live%20demo%20of%20this%20application%20running.&amp;amp;demo-url=https%3A%2F%2Fweb-check.xyz&amp;amp;demo-image=https%3A%2F%2Fraw.githubusercontent.com%2FLissy93%2Fweb-check%2Fmaster%2F.github%2Fscreenshots%2Fweb-check-screenshot10.png"&gt;&lt;img src="https://img.shields.io/badge/Deploy-Vercel-%23ffffff?style=for-the-badge&amp;amp;logo=vercel&amp;amp;labelColor=1e0e41" alt="Deploy with Vercel" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Deploying - Option #3: Docker&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;docker run -p 3000:3000 lissy93/web-check&lt;/code&gt;, then open &lt;a href="http://localhost:3000"&gt;&lt;code&gt;localhost:3000&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Docker Options&lt;/summary&gt; 
 &lt;p&gt;You can get the Docker image from:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;DockerHub: &lt;a href="https://hub.docker.com/r/lissy93/web-check"&gt;&lt;code&gt;lissy93/web-check&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;GHCR: &lt;a href="https://github.com/Lissy93/web-check/pkgs/container/web-check"&gt;&lt;code&gt;ghcr.io/lissy93/web-check&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Or build the image yourself by cloning the repo and running &lt;code&gt;docker build -t web-check .&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Deploying - Option #4: From Source&lt;/h3&gt; 
&lt;p&gt;Install the prerequisites listed in the &lt;a href="https://raw.githubusercontent.com/Lissy93/web-check/master/#developing"&gt;Developing&lt;/a&gt; section, then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Lissy93/web-check.git  # Download the code from GitHub
cd web-check                                        # Navigate into the project dir
yarn install                                        # Install the NPM dependencies
yarn build                                          # Build the app for production
yarn serve                                          # Start the app (API and GUI)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Configuring&lt;/h3&gt; 
&lt;p&gt;By default, no configuration is needed.&lt;/p&gt; 
&lt;p&gt;But there are some optional environmental variables that you can set to give you access to some additional checks, or to increase rate-limits for some checks that use external APIs.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;API Keys &amp;amp; Credentials&lt;/strong&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
   &lt;th&gt;Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GOOGLE_CLOUD_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A Google API key (&lt;a href="https://cloud.google.com/api-gateway/docs/authenticate-api-keys"&gt;get here&lt;/a&gt;). This can be used to return quality metrics for a site&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;REACT_APP_SHODAN_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A Shodan API key (&lt;a href="https://account.shodan.io/"&gt;get here&lt;/a&gt;). This will show associated host names for a given domain&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;REACT_APP_WHO_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A WhoAPI key (&lt;a href="https://whoapi.com/"&gt;get here&lt;/a&gt;). This will show more comprehensive WhoIs records than the default job&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;small&gt;Full / Upcoming Vals&lt;/small&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;GOOGLE_CLOUD_API_KEY&lt;/code&gt; - A Google API key (&lt;a href="https://cloud.google.com/api-gateway/docs/authenticate-api-keys"&gt;get here&lt;/a&gt;). This can be used to return quality metrics for a site&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;REACT_APP_SHODAN_API_KEY&lt;/code&gt; - A Shodan API key (&lt;a href="https://account.shodan.io/"&gt;get here&lt;/a&gt;). This will show associated host names for a given domain&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;REACT_APP_WHO_API_KEY&lt;/code&gt; - A WhoAPI key (&lt;a href="https://whoapi.com/"&gt;get here&lt;/a&gt;). This will show more comprehensive WhoIs records than the default job&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;SECURITY_TRAILS_API_KEY&lt;/code&gt; - A Security Trails API key (&lt;a href="https://securitytrails.com/corp/api"&gt;get here&lt;/a&gt;). This will show org info associated with the IP&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;CLOUDMERSIVE_API_KEY&lt;/code&gt; - API key for Cloudmersive (&lt;a href="https://account.cloudmersive.com/"&gt;get here&lt;/a&gt;). This will show known threats associated with the IP&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;TRANCO_USERNAME&lt;/code&gt; - A Tranco email (&lt;a href="https://tranco-list.eu/"&gt;get here&lt;/a&gt;). This will show the rank of a site, based on traffic&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;TRANCO_API_KEY&lt;/code&gt; - A Tranco API key (&lt;a href="https://tranco-list.eu/"&gt;get here&lt;/a&gt;). This will show the rank of a site, based on traffic&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;URL_SCAN_API_KEY&lt;/code&gt; - A URLScan API key (&lt;a href="https://urlscan.io/"&gt;get here&lt;/a&gt;). This will fetch miscalanious info about a site&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;BUILT_WITH_API_KEY&lt;/code&gt; - A BuiltWith API key (&lt;a href="https://api.builtwith.com/"&gt;get here&lt;/a&gt;). This will show the main features of a site&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;TORRENT_IP_API_KEY&lt;/code&gt; - A torrent API key (&lt;a href="https://iknowwhatyoudownload.com/en/api/"&gt;get here&lt;/a&gt;). This will show torrents downloaded by an IP&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;Configuration Settings&lt;/strong&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
   &lt;th&gt;Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port to serve the API, when running server.js (e.g. &lt;code&gt;3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;API_ENABLE_RATE_LIMIT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable rate-limiting for the /api endpoints (e.g. &lt;code&gt;true&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;API_TIMEOUT_LIMIT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The timeout limit for API requests, in milliseconds (e.g. &lt;code&gt;10000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;API_CORS_ORIGIN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable CORS, by setting your allowed hostname(s) here (e.g. &lt;code&gt;example.com&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CHROME_PATH&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The path the Chromium executable (e.g. &lt;code&gt;/usr/bin/chromium&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DISABLE_GUI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disable the GUI, and only serve the API (e.g. &lt;code&gt;false&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;REACT_APP_API_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The endpoint for the API, either local or remote (e.g. &lt;code&gt;/api&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;All values are optional.&lt;/p&gt; 
&lt;p&gt;You can add these as environmental variables. Either put them directly into an &lt;code&gt;.env&lt;/code&gt; file in the projects root, or via the Netlify / Vercel UI, or by passing to the Docker container with the --env flag, or using your own environmental variable management system&lt;/p&gt; 
&lt;p&gt;Note that keys that are prefixed with &lt;code&gt;REACT_APP_&lt;/code&gt; are used client-side, and as such they must be scoped correctly with minimum privileges, since may be made visible when intercepting browser &amp;lt;-&amp;gt; server network requests&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Developing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repo, &lt;code&gt;git clone git@github.com:Lissy93/web-check.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Cd into it, &lt;code&gt;cd web-check&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies: &lt;code&gt;yarn&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Start the dev server, with &lt;code&gt;yarn dev&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You'll need &lt;a href="https://nodejs.org/en"&gt;Node.js&lt;/a&gt; (V 18.16.1 or later) installed, plus &lt;a href="https://yarnpkg.com/getting-started/install"&gt;yarn&lt;/a&gt; as well as &lt;a href="https://git-scm.com/"&gt;git&lt;/a&gt;. Some checks also require &lt;code&gt;chromium&lt;/code&gt;, &lt;code&gt;traceroute&lt;/code&gt; and &lt;code&gt;dns&lt;/code&gt; to be installed within your environment. These jobs will just be skipped if those packages aren't present.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Contributions of any kind are very welcome, and would be much appreciated. For Code of Conduct, see &lt;a href="https://www.contributor-covenant.org/version/2/1/code_of_conduct/"&gt;Contributor Convent&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started, fork the repo, make your changes, add, commit and push the code, then come back here to open a pull request. If you're new to GitHub or open source, &lt;a href="https://www.freecodecamp.org/news/how-to-make-your-first-pull-request-on-github-3#let-s-make-our-first-pull-request-"&gt;this guide&lt;/a&gt; or the &lt;a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request"&gt;git docs&lt;/a&gt; may help you get started, but feel free to reach out if you need any support.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Lissy93/web-check/compare"&gt;&lt;img src="https://img.shields.io/badge/Submit_a_PR-GitHub-%23060606?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=fff" alt="Submit a PR" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Reporting Bugs&lt;/h3&gt; 
&lt;p&gt;If you've found something that doesn't work as it should, or would like to suggest a new feature, then go ahead and raise a ticket on GitHub. For bugs, please outline the steps needed to reproduce, and include relevant info like system info and resulting logs.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Lissy93/web-check/issues/new/choose"&gt;&lt;img src="https://img.shields.io/badge/Raise_an_Issue-GitHub-%23060606?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=fff" alt="Raise an Issue" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Supporting&lt;/h3&gt; 
&lt;p&gt;The app will remain 100% free and open source. But due to the amount of traffic that the hosted instance gets, the lambda function usage is costing about $25/month. Any help with covering the costs via GitHub Sponsorship would be much appreciated. It's thanks to the support of the community that this project is able to be freely available for everyone :)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/Lissy93"&gt;&lt;img src="https://img.shields.io/badge/Sponsor_on_GitHub-Lissy93-%23ff4dda?style=for-the-badge&amp;amp;logo=githubsponsors&amp;amp;logoColor=ff4dda" alt="Sponsor Lissy93 on GitHub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;p&gt;Credit to the following users for contributing to Web-Check&lt;/p&gt; 
&lt;!-- readme: contributors -start --&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/Lissy93"&gt; &lt;img src="https://avatars.githubusercontent.com/u/1862727?v=4" width="80;" alt="Lissy93" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Alicia Sykes&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/liss-bot"&gt; &lt;img src="https://avatars.githubusercontent.com/u/87835202?v=4" width="80;" alt="liss-bot" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Alicia Bot&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/n0a"&gt; &lt;img src="https://avatars.githubusercontent.com/u/14150948?v=4" width="80;" alt="n0a" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Denis Simonov&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/muni106"&gt; &lt;img src="https://avatars.githubusercontent.com/u/65845442?v=4" width="80;" alt="muni106" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Mounir Samite&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/ChrisCarini"&gt; &lt;img src="https://avatars.githubusercontent.com/u/6374067?v=4" width="80;" alt="ChrisCarini" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Chris Carini&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/bolens"&gt; &lt;img src="https://avatars.githubusercontent.com/u/1218380?v=4" width="80;" alt="bolens" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Michael Bolens&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/HeroGamers"&gt; &lt;img src="https://avatars.githubusercontent.com/u/15278940?v=4" width="80;" alt="HeroGamers" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Marcus Sand&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/jinnabaalu"&gt; &lt;img src="https://avatars.githubusercontent.com/u/11784253?v=4" width="80;" alt="jinnabaalu" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Jinna Baalu&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/GreyXor"&gt; &lt;img src="https://avatars.githubusercontent.com/u/79602273?v=4" width="80;" alt="GreyXor" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;GreyXor&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/brianteeman"&gt; &lt;img src="https://avatars.githubusercontent.com/u/1296369?v=4" width="80;" alt="brianteeman" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Brian Teeman&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/vitalykarasik"&gt; &lt;img src="https://avatars.githubusercontent.com/u/7628795?v=4" width="80;" alt="vitalykarasik" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Vitaly Karasik&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/Its-Just-Nans"&gt; &lt;img src="https://avatars.githubusercontent.com/u/56606507?v=4" width="80;" alt="Its-Just-Nans" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;n4n5&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/robinson"&gt; &lt;img src="https://avatars.githubusercontent.com/u/237874?v=4" width="80;" alt="robinson" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Lth&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/abhishekMuge"&gt; &lt;img src="https://avatars.githubusercontent.com/u/49590582?v=4" width="80;" alt="abhishekMuge" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Abhishek Muge&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/UlisesGascon"&gt; &lt;img src="https://avatars.githubusercontent.com/u/5110813?v=4" width="80;" alt="UlisesGascon" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Ulises Gasc√≥n&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/PhiRequiem"&gt; &lt;img src="https://avatars.githubusercontent.com/u/1323576?v=4" width="80;" alt="PhiRequiem" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;PhiRequiem&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/ntaiko"&gt; &lt;img src="https://avatars.githubusercontent.com/u/108784453?v=4" width="80;" alt="ntaiko" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Nikolaos G. Ntaiko&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/Myzel394"&gt; &lt;img src="https://avatars.githubusercontent.com/u/50424412?v=4" width="80;" alt="Myzel394" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Myzel394&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/murrple-1"&gt; &lt;img src="https://avatars.githubusercontent.com/u/5559656?v=4" width="80;" alt="murrple-1" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Murray Christopherson&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/t3chn0m4g3"&gt; &lt;img src="https://avatars.githubusercontent.com/u/4318452?v=4" width="80;" alt="t3chn0m4g3" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Marco Ochse&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/treatmesubj"&gt; &lt;img src="https://avatars.githubusercontent.com/u/39680353?v=4" width="80;" alt="treatmesubj" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;John Hupperts&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/eltociear"&gt; &lt;img src="https://avatars.githubusercontent.com/u/22633385?v=4" width="80;" alt="eltociear" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Ikko Eltociear Ashimine&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/Gertje823"&gt; &lt;img src="https://avatars.githubusercontent.com/u/36937387?v=4" width="80;" alt="Gertje823" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Gertje823&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/epreston"&gt; &lt;img src="https://avatars.githubusercontent.com/u/347224?v=4" width="80;" alt="epreston" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Ed Preston&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/dimitri-kandassamy"&gt; &lt;img src="https://avatars.githubusercontent.com/u/21193806?v=4" width="80;" alt="dimitri-kandassamy" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Dimitri Kandassamy&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/0xflotus"&gt; &lt;img src="https://avatars.githubusercontent.com/u/26602940?v=4" width="80;" alt="0xflotus" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;0xflotus&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
 &lt;tbody&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;!-- readme: contributors -end --&gt; 
&lt;h3&gt;Sponsors&lt;/h3&gt; 
&lt;p&gt;Huge thanks to these wonderful people, who sponsor me on GitHub, their support helps cover the costs required to keep Web-Check and my other projects free for everyone. Consider joining them, by &lt;a href="https://github.com/sponsors/Lissy93"&gt;sponsoring me on GitHub&lt;/a&gt; if you're able.&lt;/p&gt; 
&lt;!-- readme: sponsors -start --&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/vincentkoc"&gt; &lt;img src="https://avatars.githubusercontent.com/u/25068?v=4" width="80;" alt="vincentkoc" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Vincent Koc&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/AnandChowdhary"&gt; &lt;img src="https://avatars.githubusercontent.com/u/2841780?u=747e554b3a7f12eb20b7910e1c87d817844f714f&amp;amp;v=4" width="80;" alt="AnandChowdhary" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Anand Chowdhary&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/shrippen"&gt; &lt;img src="https://avatars.githubusercontent.com/u/2873570?v=4" width="80;" alt="shrippen" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Shrippen&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/bile0026"&gt; &lt;img src="https://avatars.githubusercontent.com/u/5022496?u=aec96ad173c0ea9baaba93807efa8a848af6595c&amp;amp;v=4" width="80;" alt="bile0026" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Zach Biles&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/UlisesGascon"&gt; &lt;img src="https://avatars.githubusercontent.com/u/5110813?u=3c41facd8aa26154b9451de237c34b0f78d672a5&amp;amp;v=4" width="80;" alt="UlisesGascon" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Ulises Gasc√≥n&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/digitalarche"&gt; &lt;img src="https://avatars.githubusercontent.com/u/6546135?u=564756d7f44ab2206819eb3148f6d822673f5066&amp;amp;v=4" width="80;" alt="digitalarche" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Digital Archeology&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/InDieTasten"&gt; &lt;img src="https://avatars.githubusercontent.com/u/7047377?u=8d8f8017628b38bc46dcbf3620e194b01d3fb2d1&amp;amp;v=4" width="80;" alt="InDieTasten" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;InDieTasten&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/araguaci"&gt; &lt;img src="https://avatars.githubusercontent.com/u/7318668?v=4" width="80;" alt="araguaci" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Araguaci&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/bmcgonag"&gt; &lt;img src="https://avatars.githubusercontent.com/u/7346620?u=2a0f9284f3e12ac1cc15288c254d1ec68a5081e8&amp;amp;v=4" width="80;" alt="bmcgonag" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Brian McGonagill&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/arcestia"&gt; &lt;img src="https://avatars.githubusercontent.com/u/7936962?v=4" width="80;" alt="arcestia" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Laurensius Jeffrey&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/vlad-tim"&gt; &lt;img src="https://avatars.githubusercontent.com/u/11474041?u=eee43705b54d2ec9f51fc4fcce5ad18dd17c87e4&amp;amp;v=4" width="80;" alt="vlad-tim" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Vlad&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/helixzz"&gt; &lt;img src="https://avatars.githubusercontent.com/u/12218889?u=d06d0c103dfbdb99450623064f7da3c5a3675fb6&amp;amp;v=4" width="80;" alt="helixzz" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;HeliXZz&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/mryesiller"&gt; &lt;img src="https://avatars.githubusercontent.com/u/24632172?u=0d20f2d615158f87cd60a3398d3efb026c32f291&amp;amp;v=4" width="80;" alt="mryesiller" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;G√∂ksel Ye≈üiller&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/sushibait"&gt; &lt;img src="https://avatars.githubusercontent.com/u/26634535?v=4" width="80;" alt="sushibait" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Shiverme Timbers&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/getumbrel"&gt; &lt;img src="https://avatars.githubusercontent.com/u/59408891?v=4" width="80;" alt="getumbrel" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Umbrel&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/OlliVHH"&gt; &lt;img src="https://avatars.githubusercontent.com/u/84959562?v=4" width="80;" alt="OlliVHH" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;HamburgerJung&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/frankdez93"&gt; &lt;img src="https://avatars.githubusercontent.com/u/87549420?v=4" width="80;" alt="frankdez93" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Frankdez93&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/terminaltrove"&gt; &lt;img src="https://avatars.githubusercontent.com/u/121595180?v=4" width="80;" alt="terminaltrove" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Terminal Trove&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/st617"&gt; &lt;img src="https://avatars.githubusercontent.com/u/128325650?v=4" width="80;" alt="st617" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;st617&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/hudsonrock-partnerships"&gt; &lt;img src="https://avatars.githubusercontent.com/u/163282900?u=5f2667f7fe5d284ac7a2da6b0800ea8970b0fcbf&amp;amp;v=4" width="80;" alt="hudsonrock-partnerships" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;hudsonrock-partnerships&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/CarterPerez-dev"&gt; &lt;img src="https://avatars.githubusercontent.com/u/188120068?v=4" width="80;" alt="CarterPerez-dev" /&gt; &lt;br /&gt; &lt;sub&gt;&lt;b&gt;Carter Perez&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
 &lt;tbody&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;!-- readme: sponsors -end --&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;a href="https://github.com/Lissy93/web-check"&gt;Lissy93/Web-Check&lt;/a&gt;&lt;/strong&gt; is licensed under &lt;a href="https://github.com/Lissy93/web-check/raw/HEAD/LICENSE"&gt;MIT&lt;/a&gt; ¬© &lt;a href="https://aliciasykes.com"&gt;Alicia Sykes&lt;/a&gt; 2023.&lt;/em&gt;&lt;br /&gt; &lt;sup align="right"&gt;For information, see &lt;a href="https://tldrlegal.com/license/mit-license"&gt;TLDR Legal &amp;gt; MIT&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Expand License&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;The MIT License (MIT)
Copyright (c) Alicia Sykes &amp;lt;alicia@omg.com&amp;gt; 

Permission is hereby granted, free of charge, to any person obtaining a copy 
of this software and associated documentation files (the "Software"), to deal 
in the Software without restriction, including without limitation the rights 
to use, copy, modify, merge, publish, distribute, sub-license, and/or sell 
copies of the Software, and to permit persons to whom the Software is furnished 
to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included install 
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANT ABILITY, FITNESS FOR A
PARTICULAR PURPOSE AND NON INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2FLissy93%2Fweb-check?ref=badge_large&amp;amp;issueType=license"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2FLissy93%2Fweb-check.svg?type=large&amp;amp;issueType=license" alt="View Dependency Licenses &amp;amp; SBOM on FOSSA" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;!-- License + Copyright --&gt; 
&lt;p align="center"&gt; &lt;i&gt;¬© &lt;a href="https://aliciasykes.com"&gt;Alicia Sykes&lt;/a&gt; 2023&lt;/i&gt;&lt;br /&gt; &lt;i&gt;Licensed under &lt;a href="https://gist.github.com/Lissy93/143d2ee01ccc5c052a17"&gt;MIT&lt;/a&gt;&lt;/i&gt;&lt;br /&gt; &lt;a href="https://github.com/lissy93"&gt;&lt;img src="https://i.ibb.co/4KtpYxb/octocat-clean-mini.png" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;sup&gt;Thanks for visiting :)&lt;/sup&gt; &lt;/p&gt; 
&lt;!-- Dinosaurs are Awesome --&gt; 
&lt;!-- 
                        . - ~ ~ ~ - .
      ..     _      .-~               ~-.
     //|     \ `..~                      `.
    || |      }  }              /       \  \
(\   \\ \~^..'                 |         }  \
 \`.-~  o      /       }       |        /    \
 (__          |       /        |       /      `.
  `- - ~ ~ -._|      /_ - ~ ~ ^|      /- _      `.
              |     /          |     /     ~-.     ~- _
              |_____|          |_____|         ~ - . _ _~_-_
--&gt;</description>
    </item>
    
    <item>
      <title>frankbria/ralph-claude-code</title>
      <link>https://github.com/frankbria/ralph-claude-code</link>
      <description>&lt;p&gt;Autonomous AI development loop for Claude Code with intelligent exit detection&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ralph for Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/frankbria/ralph-claude-code/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/frankbria/ralph-claude-code/actions/workflows/test.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-0.9.9-blue" alt="Version" /&gt; &lt;img src="https://img.shields.io/badge/tests-308%20passing-green" alt="Tests" /&gt; &lt;a href="https://github.com/frankbria/ralph-claude-code/issues"&gt;&lt;img src="https://img.shields.io/github/issues/frankbria/ralph-claude-code" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hesreallyhim/awesome-claude-code"&gt;&lt;img src="https://awesome.re/mentioned-badge.svg?sanitize=true" alt="Mentioned in Awesome Claude Code" /&gt;&lt;/a&gt; &lt;a href="https://x.com/FrankBria18044"&gt;&lt;img src="https://img.shields.io/twitter/follow/FrankBria18044?style=social" alt="Follow on X" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Autonomous AI development loop with intelligent exit detection and rate limiting&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Ralph is an implementation of the Geoffrey Huntley's technique for Claude Code that enables continuous autonomous development cycles he named after &lt;a href="https://ghuntley.com/ralph/"&gt;Ralph Wiggum&lt;/a&gt;. It enables continuous autonomous development cycles where Claude Code iteratively improves your project until completion, with built-in safeguards to prevent infinite loops and API overuse.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Install once, use everywhere&lt;/strong&gt; - Ralph becomes a global command available in any directory.&lt;/p&gt; 
&lt;h2&gt;Project Status&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Version&lt;/strong&gt;: v0.9.9 - Active Development &lt;strong&gt;Core Features&lt;/strong&gt;: Working and tested &lt;strong&gt;Test Coverage&lt;/strong&gt;: 308 tests, 100% pass rate&lt;/p&gt; 
&lt;h3&gt;What's Working Now&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Autonomous development loops with intelligent exit detection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dual-condition exit gate&lt;/strong&gt;: Requires BOTH completion indicators AND explicit EXIT_SIGNAL&lt;/li&gt; 
 &lt;li&gt;Rate limiting with hourly reset (100 calls/hour, configurable)&lt;/li&gt; 
 &lt;li&gt;Circuit breaker with advanced error detection (prevents runaway loops)&lt;/li&gt; 
 &lt;li&gt;Response analyzer with semantic understanding and two-stage error filtering&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON output format support with automatic fallback to text parsing&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session continuity with &lt;code&gt;--continue&lt;/code&gt; flag for context preservation&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session expiration with configurable timeout (default: 24 hours)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modern CLI flags: &lt;code&gt;--output-format&lt;/code&gt;, &lt;code&gt;--allowed-tools&lt;/code&gt;, &lt;code&gt;--no-continue&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Multi-line error matching for accurate stuck loop detection&lt;/li&gt; 
 &lt;li&gt;5-hour API limit handling with user prompts&lt;/li&gt; 
 &lt;li&gt;tmux integration for live monitoring&lt;/li&gt; 
 &lt;li&gt;PRD import functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD pipeline with GitHub Actions&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dedicated uninstall script for clean removal&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;308 passing tests across 11 test files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Recent Improvements&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.9 - EXIT_SIGNAL Gate &amp;amp; Uninstall Script&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed premature exit bug: completion indicators now require Claude's explicit &lt;code&gt;EXIT_SIGNAL: true&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Added dual-condition check preventing exits when Claude reports work in progress&lt;/li&gt; 
 &lt;li&gt;Added &lt;code&gt;response_analyzer.sh&lt;/code&gt; fix to respect explicit EXIT_SIGNAL over heuristics&lt;/li&gt; 
 &lt;li&gt;Added dedicated &lt;code&gt;uninstall.sh&lt;/code&gt; script for clean Ralph removal&lt;/li&gt; 
 &lt;li&gt;Session expiration with configurable timeout (default: 24 hours)&lt;/li&gt; 
 &lt;li&gt;Added 32 new tests for EXIT_SIGNAL behavior and session expiration&lt;/li&gt; 
 &lt;li&gt;Test count: 308 (up from 276)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.8 - Modern CLI for PRD Import&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modernized &lt;code&gt;ralph_import.sh&lt;/code&gt; to use Claude Code CLI JSON output format&lt;/li&gt; 
 &lt;li&gt;JSON output format support with &lt;code&gt;--output-format json&lt;/code&gt; for structured responses&lt;/li&gt; 
 &lt;li&gt;Enhanced error handling with structured JSON error messages&lt;/li&gt; 
 &lt;li&gt;Improved file verification with JSON-derived status information&lt;/li&gt; 
 &lt;li&gt;Backward compatibility with older CLI versions (automatic text fallback)&lt;/li&gt; 
 &lt;li&gt;Added 11 new tests for modern CLI features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.7 - Session Lifecycle Management&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Complete session lifecycle management with automatic reset triggers&lt;/li&gt; 
 &lt;li&gt;Session auto-reset on: circuit breaker open, manual interrupt, project completion&lt;/li&gt; 
 &lt;li&gt;Added &lt;code&gt;--reset-session&lt;/code&gt; CLI flag for manual session reset&lt;/li&gt; 
 &lt;li&gt;Session history tracking (last 50 transitions) for debugging&lt;/li&gt; 
 &lt;li&gt;Added 26 new tests for session continuity features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.6 - JSON Output &amp;amp; Session Management&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extended &lt;code&gt;parse_json_response()&lt;/code&gt; to support Claude Code CLI JSON format&lt;/li&gt; 
 &lt;li&gt;Added session management functions: &lt;code&gt;store_session_id()&lt;/code&gt;, &lt;code&gt;get_last_session_id()&lt;/code&gt;, &lt;code&gt;should_resume_session()&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Cross-platform epoch time utilities in date_utils.sh&lt;/li&gt; 
 &lt;li&gt;Added 16 new tests covering Claude CLI format and session management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.5 - PRD Import Tests&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added 22 comprehensive tests for &lt;code&gt;ralph_import.sh&lt;/code&gt; PRD conversion script&lt;/li&gt; 
 &lt;li&gt;Tests cover: file format support, output file creation, project naming, error handling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.4 - Project Setup Tests&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added 36 comprehensive tests for &lt;code&gt;setup.sh&lt;/code&gt; project initialization script&lt;/li&gt; 
 &lt;li&gt;Tests cover: directory creation, template copying, git initialization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.3 - Installation Tests&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added 14 comprehensive tests for &lt;code&gt;install.sh&lt;/code&gt; global installation script&lt;/li&gt; 
 &lt;li&gt;Tests cover: directory creation, command installation, dependency detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.2 - Prompt File Fix&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed critical bug: replaced non-existent &lt;code&gt;--prompt-file&lt;/code&gt; CLI flag with &lt;code&gt;-p&lt;/code&gt; flag&lt;/li&gt; 
 &lt;li&gt;Modern CLI mode now correctly passes prompt content via &lt;code&gt;-p "$(cat file)"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Added error handling for missing prompt files in &lt;code&gt;build_claude_command()&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.1 - Modern CLI Commands (Phase 1.1)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JSON output format support with &lt;code&gt;--output-format json&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;Session continuity using &lt;code&gt;--continue&lt;/code&gt; flag for cross-loop context&lt;/li&gt; 
 &lt;li&gt;Tool permissions via &lt;code&gt;--allowed-tools&lt;/code&gt; flag&lt;/li&gt; 
 &lt;li&gt;CI/CD pipeline with kcov coverage reporting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.0 - Circuit Breaker Enhancements&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed multi-line error matching in stuck loop detection&lt;/li&gt; 
 &lt;li&gt;Eliminated JSON field false positives (e.g., &lt;code&gt;"is_error": false&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Added two-stage error filtering for accurate detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;In Progress&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Expanding test coverage&lt;/li&gt; 
 &lt;li&gt;Log rotation functionality&lt;/li&gt; 
 &lt;li&gt;Dry-run mode&lt;/li&gt; 
 &lt;li&gt;Configuration file support (.ralphrc)&lt;/li&gt; 
 &lt;li&gt;Metrics and analytics tracking&lt;/li&gt; 
 &lt;li&gt;Desktop notifications&lt;/li&gt; 
 &lt;li&gt;Git backup and rollback system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Timeline to v1.0&lt;/strong&gt;: ~4 weeks | &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md"&gt;Full roadmap&lt;/a&gt; | &lt;strong&gt;Contributions welcome!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Autonomous Development Loop&lt;/strong&gt; - Continuously executes Claude Code with your project requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Exit Detection&lt;/strong&gt; - Dual-condition check requiring BOTH completion indicators AND explicit EXIT_SIGNAL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Continuity&lt;/strong&gt; - Preserves context across loop iterations with automatic session management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Expiration&lt;/strong&gt; - Configurable timeout (default: 24 hours) with automatic session reset&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rate Limiting&lt;/strong&gt; - Built-in API call management with hourly limits and countdown timers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;5-Hour API Limit Handling&lt;/strong&gt; - Detects Claude's 5-hour usage limit and offers wait/exit options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live Monitoring&lt;/strong&gt; - Real-time dashboard showing loop status, progress, and logs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task Management&lt;/strong&gt; - Structured approach with prioritized task lists and progress tracking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Project Templates&lt;/strong&gt; - Quick setup for new projects with best-practice structure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Logging&lt;/strong&gt; - Detailed execution logs with timestamps and status tracking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Timeouts&lt;/strong&gt; - Set execution timeout for Claude Code operations (1-120 minutes)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Verbose Progress Mode&lt;/strong&gt; - Optional detailed progress updates during execution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Response Analyzer&lt;/strong&gt; - AI-powered analysis of Claude Code responses with semantic understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Circuit Breaker&lt;/strong&gt; - Advanced error detection with two-stage filtering, multi-line error matching, and automatic recovery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD Integration&lt;/strong&gt; - GitHub Actions workflow with automated testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clean Uninstall&lt;/strong&gt; - Dedicated uninstall script for complete removal&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Ralph has two phases: &lt;strong&gt;one-time installation&lt;/strong&gt; and &lt;strong&gt;per-project setup&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;INSTALL ONCE              USE MANY TIMES
+-----------------+          +----------------------+
| ./install.sh    |    -&amp;gt;    | ralph-setup project1 |
|                 |          | ralph-setup project2 |
| Adds global     |          | ralph-setup project3 |
| commands        |          | ...                  |
+-----------------+          +----------------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Phase 1: Install Ralph (One Time Only)&lt;/h3&gt; 
&lt;p&gt;Install Ralph globally on your system:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/frankbria/ralph-claude-code.git
cd ralph-claude-code
./install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This adds &lt;code&gt;ralph&lt;/code&gt;, &lt;code&gt;ralph-monitor&lt;/code&gt;, and &lt;code&gt;ralph-setup&lt;/code&gt; commands to your PATH.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You only need to do this once per system. After installation, you can delete the cloned repository if desired.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Phase 2: Initialize New Projects (Per Project)&lt;/h3&gt; 
&lt;p&gt;For each new project you want Ralph to work on:&lt;/p&gt; 
&lt;h4&gt;Option A: Import Existing PRD/Specifications&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Convert existing PRD/specs to Ralph format (recommended)
ralph-import my-requirements.md my-project
cd my-project

# Review and adjust the generated files:
# - PROMPT.md (Ralph instructions)
# - @fix_plan.md (task priorities)
# - specs/requirements.md (technical specs)

# Start autonomous development
ralph --monitor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option B: Manual Project Setup&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create blank Ralph project
ralph-setup my-awesome-project
cd my-awesome-project

# Configure your project requirements manually
# Edit PROMPT.md with your project goals
# Edit specs/ with detailed specifications
# Edit @fix_plan.md with initial priorities

# Start autonomous development
ralph --monitor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ongoing Usage (After Setup)&lt;/h3&gt; 
&lt;p&gt;Once Ralph is installed and your project is initialized:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to any Ralph project and run:
ralph --monitor              # Integrated tmux monitoring (recommended)

# Or use separate terminals:
ralph                        # Terminal 1: Ralph loop
ralph-monitor               # Terminal 2: Live monitor dashboard
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Uninstalling Ralph&lt;/h3&gt; 
&lt;p&gt;To completely remove Ralph from your system:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the uninstall script
./uninstall.sh

# Or if you deleted the repo, download and run:
curl -sL https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/uninstall.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;Ralph operates on a simple but powerful cycle:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Read Instructions&lt;/strong&gt; - Loads &lt;code&gt;PROMPT.md&lt;/code&gt; with your project requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Execute Claude Code&lt;/strong&gt; - Runs Claude Code with current context and priorities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Track Progress&lt;/strong&gt; - Updates task lists and logs execution results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluate Completion&lt;/strong&gt; - Checks for exit conditions and project completion signals&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repeat&lt;/strong&gt; - Continues until project is complete or limits are reached&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Intelligent Exit Detection&lt;/h3&gt; 
&lt;p&gt;Ralph uses a &lt;strong&gt;dual-condition check&lt;/strong&gt; to prevent premature exits during productive iterations:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Exit requires BOTH conditions:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;completion_indicators &amp;gt;= 2&lt;/code&gt; (heuristic detection from natural language patterns)&lt;/li&gt; 
 &lt;li&gt;Claude's explicit &lt;code&gt;EXIT_SIGNAL: true&lt;/code&gt; in the RALPH_STATUS block&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example behavior:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Loop 5: Claude outputs "Phase complete, moving to next feature"
        ‚Üí completion_indicators: 3 (high confidence from patterns)
        ‚Üí EXIT_SIGNAL: false (Claude says more work needed)
        ‚Üí Result: CONTINUE (respects Claude's explicit intent)

Loop 8: Claude outputs "All tasks complete, project ready"
        ‚Üí completion_indicators: 4
        ‚Üí EXIT_SIGNAL: true (Claude confirms done)
        ‚Üí Result: EXIT with "project_complete"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Other exit conditions:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All tasks in &lt;code&gt;@fix_plan.md&lt;/code&gt; marked complete&lt;/li&gt; 
 &lt;li&gt;Multiple consecutive "done" signals from Claude Code&lt;/li&gt; 
 &lt;li&gt;Too many test-focused loops (indicating feature completeness)&lt;/li&gt; 
 &lt;li&gt;Claude API 5-hour usage limit reached (with user prompt to wait or exit)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Importing Existing Requirements&lt;/h2&gt; 
&lt;p&gt;Ralph can convert existing PRDs, specifications, or requirement documents into the proper Ralph format using Claude Code.&lt;/p&gt; 
&lt;h3&gt;Supported Formats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Markdown&lt;/strong&gt; (.md) - Product requirements, technical specs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text files&lt;/strong&gt; (.txt) - Plain text requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON&lt;/strong&gt; (.json) - Structured requirement data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Word documents&lt;/strong&gt; (.docx) - Business requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PDFs&lt;/strong&gt; (.pdf) - Design documents, specifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Any text-based format&lt;/strong&gt; - Ralph will intelligently parse the content&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Convert a markdown PRD
ralph-import product-requirements.md my-app

# Convert a text specification
ralph-import requirements.txt webapp

# Convert a JSON API spec
ralph-import api-spec.json backend-service

# Let Ralph auto-name the project from filename
ralph-import design-doc.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;What Gets Generated&lt;/h3&gt; 
&lt;p&gt;Ralph-import creates a complete project with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PROMPT.md&lt;/strong&gt; - Converted into Ralph development instructions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;@fix_plan.md&lt;/strong&gt; - Requirements broken down into prioritized tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;specs/requirements.md&lt;/strong&gt; - Technical specifications extracted from your document&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard Ralph structure&lt;/strong&gt; - All necessary directories and template files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The conversion is intelligent and preserves your original requirements while making them actionable for autonomous development.&lt;/p&gt; 
&lt;h3&gt;Modern CLI Features (v0.9.8)&lt;/h3&gt; 
&lt;p&gt;Ralph-import uses modern Claude Code CLI features for improved reliability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;JSON Output Format&lt;/strong&gt;: Structured responses enable precise parsing of conversion results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Fallback&lt;/strong&gt;: Gracefully handles older CLI versions with text-based parsing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Error Reporting&lt;/strong&gt;: Extracts specific error messages and codes from JSON responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Tracking&lt;/strong&gt;: Captures session IDs for potential continuation of interrupted conversions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These features require Claude Code CLI version 2.0.76 or later. Older versions will work with standard text output.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;h3&gt;Rate Limiting &amp;amp; Circuit Breaker&lt;/h3&gt; 
&lt;p&gt;Ralph includes intelligent rate limiting and circuit breaker functionality:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Default: 100 calls per hour
ralph --calls 50

# With integrated monitoring
ralph --monitor --calls 50

# Check current usage
ralph --status
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The circuit breaker automatically:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detects API errors and rate limit issues with advanced two-stage filtering&lt;/li&gt; 
 &lt;li&gt;Opens circuit after 3 loops with no progress or 5 loops with same errors&lt;/li&gt; 
 &lt;li&gt;Eliminates false positives from JSON fields containing "error"&lt;/li&gt; 
 &lt;li&gt;Accurately detects stuck loops with multi-line error matching&lt;/li&gt; 
 &lt;li&gt;Gradually recovers with half-open monitoring state&lt;/li&gt; 
 &lt;li&gt;Provides detailed error tracking and logging with state history&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Claude API 5-Hour Limit&lt;/h3&gt; 
&lt;p&gt;When Claude's 5-hour usage limit is reached, Ralph:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Detects the limit error automatically&lt;/li&gt; 
 &lt;li&gt;Prompts you to choose: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Option 1&lt;/strong&gt;: Wait 60 minutes for the limit to reset (with countdown timer)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Option 2&lt;/strong&gt;: Exit gracefully (or auto-exits after 30-second timeout)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Prevents endless retry loops that waste time&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Custom Prompts&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use custom prompt file
ralph --prompt my_custom_instructions.md

# With integrated monitoring
ralph --monitor --prompt my_custom_instructions.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Execution Timeouts&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Set Claude Code execution timeout (default: 15 minutes)
ralph --timeout 30  # 30-minute timeout for complex tasks

# With monitoring and custom timeout
ralph --monitor --timeout 60  # 60-minute timeout

# Short timeout for quick iterations
ralph --verbose --timeout 5  # 5-minute timeout with progress
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Verbose Mode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Enable detailed progress updates during execution
ralph --verbose

# Combine with other options
ralph --monitor --verbose --timeout 30
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Session Continuity&lt;/h3&gt; 
&lt;p&gt;Ralph maintains session context across loop iterations for improved coherence:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Sessions are enabled by default with --continue flag
ralph --monitor                 # Uses session continuity

# Start fresh without session context
ralph --no-continue             # Isolated iterations

# Reset session manually (clears context)
ralph --reset-session           # Clears current session

# Check session status
cat .ralph_session              # View current session file
cat .ralph_session_history      # View session transition history
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Session Auto-Reset Triggers:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Circuit breaker opens (stagnation detected)&lt;/li&gt; 
 &lt;li&gt;Manual interrupt (Ctrl+C / SIGINT)&lt;/li&gt; 
 &lt;li&gt;Project completion (graceful exit)&lt;/li&gt; 
 &lt;li&gt;Manual circuit breaker reset (&lt;code&gt;--reset-circuit&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Session expiration (default: 24 hours)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sessions are persisted to &lt;code&gt;.ralph_session&lt;/code&gt; with a configurable expiration (default: 24 hours). The last 50 session transitions are logged to &lt;code&gt;.ralph_session_history&lt;/code&gt; for debugging.&lt;/p&gt; 
&lt;h3&gt;Exit Thresholds&lt;/h3&gt; 
&lt;p&gt;Modify these variables in &lt;code&gt;~/.ralph/ralph_loop.sh&lt;/code&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Exit Detection Thresholds:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;MAX_CONSECUTIVE_TEST_LOOPS=3     # Exit after 3 test-only loops
MAX_CONSECUTIVE_DONE_SIGNALS=2   # Exit after 2 "done" signals
TEST_PERCENTAGE_THRESHOLD=30     # Flag if 30%+ loops are test-only
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Circuit Breaker Thresholds:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CB_NO_PROGRESS_THRESHOLD=3       # Open circuit after 3 loops with no file changes
CB_SAME_ERROR_THRESHOLD=5        # Open circuit after 5 loops with repeated errors
CB_OUTPUT_DECLINE_THRESHOLD=70   # Open circuit if output declines by &amp;gt;70%
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Indicators with EXIT_SIGNAL Gate:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;completion_indicators&lt;/th&gt; 
   &lt;th&gt;EXIT_SIGNAL&lt;/th&gt; 
   &lt;th&gt;Result&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;gt;= 2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Exit&lt;/strong&gt; ("project_complete")&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;gt;= 2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Continue&lt;/strong&gt; (Claude still working)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;gt;= 2&lt;/td&gt; 
   &lt;td&gt;missing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Continue&lt;/strong&gt; (defaults to false)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;lt; 2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Continue&lt;/strong&gt; (threshold not met)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Project Structure&lt;/h2&gt; 
&lt;p&gt;Ralph creates a standardized structure for each project:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;my-project/
‚îú‚îÄ‚îÄ PROMPT.md           # Main development instructions for Ralph
‚îú‚îÄ‚îÄ @fix_plan.md        # Prioritized task list (@ prefix = Ralph control file)
‚îú‚îÄ‚îÄ @AGENT.md           # Build and run instructions
‚îú‚îÄ‚îÄ specs/              # Project specifications and requirements
‚îÇ   ‚îî‚îÄ‚îÄ stdlib/         # Standard library specifications
‚îú‚îÄ‚îÄ src/                # Source code implementation
‚îú‚îÄ‚îÄ examples/           # Usage examples and test cases
‚îú‚îÄ‚îÄ logs/               # Ralph execution logs
‚îî‚îÄ‚îÄ docs/generated/     # Auto-generated documentation
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Best Practices&lt;/h2&gt; 
&lt;h3&gt;Writing Effective Prompts&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Be Specific&lt;/strong&gt; - Clear requirements lead to better results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prioritize&lt;/strong&gt; - Use &lt;code&gt;@fix_plan.md&lt;/code&gt; to guide Ralph's focus&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Set Boundaries&lt;/strong&gt; - Define what's in/out of scope&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Include Examples&lt;/strong&gt; - Show expected inputs/outputs&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Project Specifications&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Place detailed requirements in &lt;code&gt;specs/&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;@fix_plan.md&lt;/code&gt; for prioritized task tracking&lt;/li&gt; 
 &lt;li&gt;Keep &lt;code&gt;@AGENT.md&lt;/code&gt; updated with build instructions&lt;/li&gt; 
 &lt;li&gt;Document key decisions and architecture&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Monitoring Progress&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;ralph-monitor&lt;/code&gt; for live status updates&lt;/li&gt; 
 &lt;li&gt;Check logs in &lt;code&gt;logs/&lt;/code&gt; for detailed execution history&lt;/li&gt; 
 &lt;li&gt;Monitor &lt;code&gt;status.json&lt;/code&gt; for programmatic access&lt;/li&gt; 
 &lt;li&gt;Watch for exit condition signals&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bash 4.0+&lt;/strong&gt; - For script execution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Code CLI&lt;/strong&gt; - &lt;code&gt;npm install -g @anthropic-ai/claude-code&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;tmux&lt;/strong&gt; - Terminal multiplexer for integrated monitoring (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;jq&lt;/strong&gt; - JSON processing for status tracking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Git&lt;/strong&gt; - Version control (projects are initialized as git repos)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard Unix tools&lt;/strong&gt; - grep, date, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Testing Requirements (Development)&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/TESTING.md"&gt;TESTING.md&lt;/a&gt; for the comprehensive testing guide.&lt;/p&gt; 
&lt;p&gt;If you want to run the test suite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install BATS testing framework
npm install -g bats bats-support bats-assert

# Run all tests (308 tests)
npm test

# Run specific test suites
bats tests/unit/test_rate_limiting.bats
bats tests/unit/test_exit_detection.bats
bats tests/unit/test_json_parsing.bats
bats tests/unit/test_cli_modern.bats
bats tests/unit/test_cli_parsing.bats
bats tests/unit/test_session_continuity.bats
bats tests/integration/test_loop_execution.bats
bats tests/integration/test_prd_import.bats
bats tests/integration/test_project_setup.bats
bats tests/integration/test_installation.bats

# Run error detection and circuit breaker tests
./tests/test_error_detection.sh
./tests/test_stuck_loop_detection.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Current test status:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;308 tests&lt;/strong&gt; across 11 test files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% pass rate&lt;/strong&gt; (308/308 passing)&lt;/li&gt; 
 &lt;li&gt;Comprehensive unit and integration tests&lt;/li&gt; 
 &lt;li&gt;Specialized tests for JSON parsing, CLI flags, circuit breaker, EXIT_SIGNAL behavior, and installation workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note on Coverage&lt;/strong&gt;: Bash code coverage measurement with kcov has fundamental limitations when tracing subprocess executions. Test pass rate (100%) is the quality gate. See &lt;a href="https://github.com/bats-core/bats-core/issues/15"&gt;bats-core#15&lt;/a&gt; for details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Installing tmux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu/Debian
sudo apt-get install tmux

# macOS
brew install tmux

# CentOS/RHEL
sudo yum install tmux
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Monitoring and Debugging&lt;/h2&gt; 
&lt;h3&gt;Live Dashboard&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Integrated tmux monitoring (recommended)
ralph --monitor

# Manual monitoring in separate terminal
ralph-monitor
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Shows real-time:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Current loop count and status&lt;/li&gt; 
 &lt;li&gt;API calls used vs. limit&lt;/li&gt; 
 &lt;li&gt;Recent log entries&lt;/li&gt; 
 &lt;li&gt;Rate limit countdown&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;tmux Controls:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Ctrl+B&lt;/code&gt; then &lt;code&gt;D&lt;/code&gt; - Detach from session (keeps Ralph running)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Ctrl+B&lt;/code&gt; then &lt;code&gt;‚Üê/‚Üí&lt;/code&gt; - Switch between panes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tmux list-sessions&lt;/code&gt; - View active sessions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tmux attach -t &amp;lt;session-name&amp;gt;&lt;/code&gt; - Reattach to session&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Status Checking&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# JSON status output
ralph --status

# Manual log inspection
tail -f logs/ralph.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Common Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Rate Limits&lt;/strong&gt; - Ralph automatically waits and displays countdown&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;5-Hour API Limit&lt;/strong&gt; - Ralph detects and prompts for user action (wait or exit)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stuck Loops&lt;/strong&gt; - Check &lt;code&gt;@fix_plan.md&lt;/code&gt; for unclear or conflicting tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Early Exit&lt;/strong&gt; - Review exit thresholds if Ralph stops too soon&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Premature Exit&lt;/strong&gt; - Check if Claude is setting &lt;code&gt;EXIT_SIGNAL: false&lt;/code&gt; (Ralph now respects this)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Execution Timeouts&lt;/strong&gt; - Increase &lt;code&gt;--timeout&lt;/code&gt; value for complex operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Missing Dependencies&lt;/strong&gt; - Ensure Claude Code CLI and tmux are installed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;tmux Session Lost&lt;/strong&gt; - Use &lt;code&gt;tmux list-sessions&lt;/code&gt; and &lt;code&gt;tmux attach&lt;/code&gt; to reconnect&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Expired&lt;/strong&gt; - Sessions expire after 24 hours by default; use &lt;code&gt;--reset-session&lt;/code&gt; to start fresh&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Ralph is actively seeking contributors! We're working toward v1.0.0 with clear priorities and a detailed roadmap.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for the complete contributor guide&lt;/strong&gt; including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Getting started and setup instructions&lt;/li&gt; 
 &lt;li&gt;Development workflow and commit conventions&lt;/li&gt; 
 &lt;li&gt;Code style guidelines&lt;/li&gt; 
 &lt;li&gt;Testing requirements (100% pass rate mandatory)&lt;/li&gt; 
 &lt;li&gt;Pull request process and code review guidelines&lt;/li&gt; 
 &lt;li&gt;Quality standards and checklists&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fork and clone
git clone https://github.com/YOUR_USERNAME/ralph-claude-code.git
cd ralph-claude-code

# Install dependencies and run tests
npm install
npm test  # All 308 tests must pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Priority Contribution Areas&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Test Implementation&lt;/strong&gt; - Help expand test coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Development&lt;/strong&gt; - Log rotation, dry-run mode, config files, metrics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt; - Tutorials, troubleshooting guides, examples&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-World Testing&lt;/strong&gt; - Use Ralph, report bugs, share feedback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Every contribution matters&lt;/strong&gt; - from fixing typos to implementing major features!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Inspired by the &lt;a href="https://ghuntley.com/ralph/"&gt;Ralph technique&lt;/a&gt; created by Geoffrey Huntley&lt;/li&gt; 
 &lt;li&gt;Built for &lt;a href="https://claude.ai/code"&gt;Claude Code&lt;/a&gt; by Anthropic&lt;/li&gt; 
 &lt;li&gt;Community feedback and contributions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://claude.ai/code"&gt;Claude Code&lt;/a&gt; - The AI coding assistant that powers Ralph&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paul-gauthier/aider"&gt;Aider&lt;/a&gt; - Original Ralph technique implementation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Command Reference&lt;/h2&gt; 
&lt;h3&gt;Installation Commands (Run Once)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./install.sh              # Install Ralph globally
./uninstall.sh            # Remove Ralph from system (dedicated script)
./install.sh uninstall    # Alternative: Remove Ralph from system
./install.sh --help       # Show installation help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ralph Loop Options&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ralph [OPTIONS]
  -h, --help              Show help message
  -c, --calls NUM         Set max calls per hour (default: 100)
  -p, --prompt FILE       Set prompt file (default: PROMPT.md)
  -s, --status            Show current status and exit
  -m, --monitor           Start with tmux session and live monitor
  -v, --verbose           Show detailed progress updates during execution
  -t, --timeout MIN       Set Claude Code execution timeout in minutes (1-120, default: 15)
  --output-format FORMAT  Set output format: json (default) or text
  --allowed-tools TOOLS   Set allowed Claude tools (default: Write,Bash(git *),Read)
  --no-continue           Disable session continuity (start fresh each loop)
  --reset-circuit         Reset the circuit breaker
  --circuit-status        Show circuit breaker status
  --reset-session         Reset session state manually
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Project Commands (Per Project)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ralph-setup project-name     # Create new Ralph project
ralph-import prd.md project  # Convert PRD/specs to Ralph project
ralph --monitor              # Start with integrated monitoring
ralph --status               # Check current loop status
ralph --verbose              # Enable detailed progress updates
ralph --timeout 30           # Set 30-minute execution timeout
ralph --calls 50             # Limit to 50 API calls per hour
ralph --reset-session        # Reset session state manually
ralph-monitor                # Manual monitoring dashboard
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;tmux Session Management&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;tmux list-sessions        # View active Ralph sessions
tmux attach -t &amp;lt;name&amp;gt;     # Reattach to detached session
# Ctrl+B then D           # Detach from session (keeps running)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Development Roadmap&lt;/h2&gt; 
&lt;p&gt;Ralph is under active development with a clear path to v1.0.0. See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md"&gt;IMPLEMENTATION_PLAN.md&lt;/a&gt; for the complete roadmap.&lt;/p&gt; 
&lt;h3&gt;Current Status: v0.9.9&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;What's Delivered:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Core loop functionality with intelligent exit detection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dual-condition exit gate&lt;/strong&gt; (completion indicators + EXIT_SIGNAL)&lt;/li&gt; 
 &lt;li&gt;Rate limiting (100 calls/hour) and circuit breaker pattern&lt;/li&gt; 
 &lt;li&gt;Response analyzer with semantic understanding&lt;/li&gt; 
 &lt;li&gt;308 comprehensive tests (100% pass rate)&lt;/li&gt; 
 &lt;li&gt;tmux integration and live monitoring&lt;/li&gt; 
 &lt;li&gt;PRD import functionality with modern CLI JSON parsing&lt;/li&gt; 
 &lt;li&gt;Installation system and project templates&lt;/li&gt; 
 &lt;li&gt;Modern CLI commands with JSON output support&lt;/li&gt; 
 &lt;li&gt;CI/CD pipeline with GitHub Actions&lt;/li&gt; 
 &lt;li&gt;Comprehensive installation test suite&lt;/li&gt; 
 &lt;li&gt;Session lifecycle management with auto-reset triggers&lt;/li&gt; 
 &lt;li&gt;Session expiration with configurable timeout&lt;/li&gt; 
 &lt;li&gt;Dedicated uninstall script&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Test Coverage Breakdown:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Unit Tests: 164 (CLI parsing, JSON, exit detection, rate limiting, session continuity)&lt;/li&gt; 
 &lt;li&gt;Integration Tests: 144 (loop execution, edge cases, installation, project setup, PRD import)&lt;/li&gt; 
 &lt;li&gt;Test Files: 11&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Path to v1.0.0 (~4 weeks)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Enhanced Testing&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Installation and setup workflow tests&lt;/li&gt; 
 &lt;li&gt;tmux integration tests&lt;/li&gt; 
 &lt;li&gt;Monitor dashboard tests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Core Features&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Log rotation functionality&lt;/li&gt; 
 &lt;li&gt;Dry-run mode&lt;/li&gt; 
 &lt;li&gt;Configuration file support - .ralphrc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Advanced Features &amp;amp; Polish&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Metrics and analytics tracking&lt;/li&gt; 
 &lt;li&gt;Desktop notifications&lt;/li&gt; 
 &lt;li&gt;Git backup and rollback system&lt;/li&gt; 
 &lt;li&gt;End-to-end tests&lt;/li&gt; 
 &lt;li&gt;Final documentation and release prep&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_STATUS.md"&gt;IMPLEMENTATION_STATUS.md&lt;/a&gt; for detailed progress tracking.&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;p&gt;Ralph is seeking contributors! See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for the complete guide. Priority areas:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Test Implementation&lt;/strong&gt; - Help expand test coverage (&lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md"&gt;see plan&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Development&lt;/strong&gt; - Log rotation, dry-run mode, config files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt; - Usage examples, tutorials, troubleshooting guides&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug Reports&lt;/strong&gt; - Real-world usage feedback and edge cases&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Ready to let AI build your project?&lt;/strong&gt; Start with &lt;code&gt;./install.sh&lt;/code&gt; and let Ralph take it from there!&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#frankbria/ralph-claude-code&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=frankbria/ralph-claude-code&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>bytedance/UI-TARS-desktop</title>
      <link>https://github.com/bytedance/UI-TARS-desktop</link>
      <description>&lt;p&gt;The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;img alt="Agent TARS Banner" src="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/images/tars.png" /&gt; 
&lt;/picture&gt; 
&lt;br /&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/README.zh-CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/13584"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13584" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;b&gt;TARS&lt;sup&gt;*&lt;/sup&gt;&lt;/b&gt; is a Multimodal AI Agent stack, currently shipping two projects: &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS-desktop&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="50%" align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt;&lt;/th&gt; 
   &lt;th width="50%" align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS-desktop&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br /&gt; &lt;br /&gt; It primarily ships with a &lt;a href="https://agent-tars.com/guide/basic/cli.html" target="_blank"&gt;CLI&lt;/a&gt; and &lt;a href="https://agent-tars.com/guide/basic/web-ui.html" target="_blank"&gt;Web UI&lt;/a&gt; for usage. It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href="https://agent-tars.com/guide/basic/mcp.html" target="_blank"&gt;MCP&lt;/a&gt; tools. &lt;/td&gt; 
   &lt;td align="left"&gt; &lt;b&gt;UI-TARS Desktop&lt;/b&gt; is a desktop application that provides a native GUI Agent based on the &lt;a href="https://github.com/bytedance/UI-TARS" target="_blank"&gt;UI-TARS&lt;/a&gt; model. &lt;br /&gt; &lt;br /&gt; It primarily ships a &lt;a href="https://github.com/bytedance/UI-TARS-desktop/raw/main/docs/quick-start.md#get-model-and-run-local-operator" target="_blank"&gt;local&lt;/a&gt; and &lt;a href="https://github.com/bytedance/UI-TARS-desktop/raw/main/docs/quick-start.md#run-remote-operator" target="_blank"&gt;remote&lt;/a&gt; computer as well as browser operators. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt; 
&lt;!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#news"&gt;News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#showcase"&gt;Showcase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#core-features"&gt;Core Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS Desktop&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#showcase-1"&gt;Showcase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#quick-start-1"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-11-05]&lt;/strong&gt; üéâ We're excited to announce the release of &lt;a href="https://github.com/bytedance/UI-TARS-desktop/releases/tag/v0.3.0"&gt;Agent TARS CLI v0.3.0&lt;/a&gt;! This version brings streaming support for multiple tools (shell commands, multi-file structured display), runtime settings with timing statistics for tool calls and deep thinking, Event Stream Viewer for data flow tracking and debugging. Additionally, it features exclusive support for &lt;a href="https://github.com/agent-infra/sandbox"&gt;AIO agent Sandbox&lt;/a&gt; as isolated all-in-one tools execution environment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-06-25]&lt;/strong&gt; We released a Agent TARS Beta and Agent TARS CLI - &lt;a href="https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html"&gt;Introducing Agent TARS Beta&lt;/a&gt;, a multimodal AI agent that aims to explore a work form that is closer to human-like task completion through rich multimodal capabilities (such as GUI Agent, Vision) and seamless integration with various real-world tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-06-12]&lt;/strong&gt; - üéÅ We are thrilled to announce the release of UI-TARS Desktop v0.2.0! This update introduces two powerful new features: &lt;strong&gt;Remote Computer Operator&lt;/strong&gt; and &lt;strong&gt;Remote Browser Operator&lt;/strong&gt;‚Äîboth completely free. No configuration required: simply click to remotely control any computer or browser, and experience a new level of convenience and intelligence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-04-17]&lt;/strong&gt; - üéâ We're thrilled to announce the release of new UI-TARS Desktop application v0.1.0, featuring a redesigned Agent UI. The application enhances the computer using experience, introduces new browser operation features, and supports &lt;a href="https://seed-tars.com/1.5"&gt;the advanced UI-TARS-1.5 model&lt;/a&gt; for improved performance and precise control.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-02-20]&lt;/strong&gt; - üì¶ Introduced &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/sdk.md"&gt;UI TARS SDK&lt;/a&gt;, is a powerful cross-platform toolkit for building GUI automation agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-01-23]&lt;/strong&gt; - üöÄ We updated the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/deployment.md#cloud-deployment"&gt;Cloud Deployment&lt;/a&gt;&lt;/strong&gt; section in the ‰∏≠ÊñáÁâà: &lt;a href="https://bytedance.sg.larkoffice.com/docx/TCcudYwyIox5vyxiSDLlgIsTgWf#U94rdCxzBoJMLex38NPlHL21gNb"&gt;GUIÊ®°ÂûãÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/a&gt; with new information related to the ModelScope platform. You can now use the ModelScope platform for deployment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Agent TARS&lt;/h2&gt; 
&lt;p&gt; &lt;a href="https://npmjs.com/package/@agent-tars/cli?activeTab=readme"&gt;&lt;img src="https://img.shields.io/npm/v/@agent-tars/cli?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=3B82F6&amp;amp;logo=npm&amp;amp;logoColor=white" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://npmcharts.com/compare/@agent-tars/cli?minimal=true"&gt;&lt;img src="https://img.shields.io/npm/dm/@agent-tars/cli.svg?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=0EA5E9&amp;amp;logo=npm&amp;amp;logoColor=white" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://nodejs.org/en/about/previous-releases"&gt;&lt;img src="https://img.shields.io/node/v/@agent-tars/cli.svg?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=06B6D4&amp;amp;logo=node.js&amp;amp;logoColor=white" alt="node version" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/HnKcSBgTVx"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord Community" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/agent_tars"&gt;&lt;img src="https://img.shields.io/badge/Twitter-Follow%20%40agent__tars-1DA1F2?style=for-the-badge&amp;amp;logo=twitter&amp;amp;logoColor=white" alt="Official Twitter" /&gt;&lt;/a&gt; &lt;a href="https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=deen76f4-ea3c-4964-93a3-78f126f39651"&gt;&lt;img src="https://img.shields.io/badge/È£û‰π¶Áæ§-Âä†ÂÖ•‰∫§ÊµÅÁæ§-00D4AA?style=for-the-badge&amp;amp;logo=lark&amp;amp;logoColor=white" alt="È£û‰π¶‰∫§ÊµÅÁæ§" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/bytedance/UI-TARS-desktop"&gt;&lt;img src="https://img.shields.io/badge/DeepWiki-Ask%20AI-8B5CF6?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br /&gt; &lt;br /&gt; It primarily ships with a &lt;a href="https://agent-tars.com/guide/basic/cli.html" target="_blank"&gt;CLI&lt;/a&gt; and &lt;a href="https://agent-tars.com/guide/basic/web-ui.html" target="_blank"&gt;Web UI&lt;/a&gt; for usage. It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href="https://agent-tars.com/guide/basic/mcp.html" target="_blank"&gt;MCP&lt;/a&gt; tools.&lt;/p&gt; 
&lt;h3&gt;Showcase&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Please help me book the earliest flight from San Jose to New York on September 1st and the last return flight on September 6th on Priceline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8"&gt;https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="50%" align="center"&gt;Booking Hotel&lt;/th&gt; 
   &lt;th width="50%" align="center"&gt;Generate Chart with extra MCP Servers&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/a9fd72d0-01bb-4233-aa27-ca95194bbce9" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;I am in Los Angeles from September 1st to September 6th, with a budget of $5,000. Please help me book a Ritz-Carlton hotel closest to the airport on booking.com and compile a transportation guide for me&lt;/i&gt; &lt;/td&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;Draw me a chart of Hangzhou's weather for one month&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For more use cases, please check out &lt;a href="https://github.com/bytedance/UI-TARS-desktop/issues/842"&gt;#842&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Core Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üñ±Ô∏è &lt;strong&gt;One-Click Out-of-the-box CLI&lt;/strong&gt; - Supports both &lt;strong&gt;headful&lt;/strong&gt; &lt;a href="https://agent-tars.com/guide/basic/web-ui.html"&gt;Web UI&lt;/a&gt; and &lt;strong&gt;headless&lt;/strong&gt; &lt;a href="https://agent-tars.com/guide/advanced/server.html"&gt;server&lt;/a&gt;) &lt;a href="https://agent-tars.com/guide/basic/cli.html"&gt;execution&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Hybrid Browser Agent&lt;/strong&gt; - Control browsers using &lt;a href="https://agent-tars.com/guide/basic/browser.html#visual-grounding"&gt;GUI Agent&lt;/a&gt;, &lt;a href="https://agent-tars.com/guide/basic/browser.html#dom"&gt;DOM&lt;/a&gt;, or a hybrid strategy.&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Event Stream&lt;/strong&gt; - Protocol-driven Event Stream drives &lt;a href="https://agent-tars.com/beta#context-engineering"&gt;Context Engineering&lt;/a&gt; and &lt;a href="https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html#easy-to-build-applications"&gt;Agent UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üß∞ &lt;strong&gt;MCP Integration&lt;/strong&gt; - The kernel is built on MCP and also supports mounting &lt;a href="https://agent-tars.com/guide/basic/mcp.html"&gt;MCP Servers&lt;/a&gt; to connect to real-world tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;img alt="Agent TARS CLI" src="https://agent-tars.com/agent-tars-cli.png" /&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch with `npx`.
npx @agent-tars/cli@latest

# Install globally, required Node.js &amp;gt;= 22
npm install @agent-tars/cli@latest -g

# Run with your preferred model provider
agent-tars --provider volcengine --model doubao-1-5-thinking-vision-pro-250428 --apiKey your-api-key
agent-tars --provider anthropic --model claude-3-7-sonnet-latest --apiKey your-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit the comprehensive &lt;a href="https://agent-tars.com/guide/get-started/quick-start.html"&gt;Quick Start&lt;/a&gt; guide for detailed setup instructions.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üåü &lt;strong&gt;Explore Agent TARS Universe&lt;/strong&gt; üåü&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="20%" align="center"&gt;Category&lt;/th&gt; 
   &lt;th width="30%" align="center"&gt;Resource Link&lt;/th&gt; 
   &lt;th width="50%" align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üè† &lt;strong&gt;Central Hub&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com"&gt; &lt;img src="https://img.shields.io/badge/Visit-Website-4F46E5?style=for-the-badge&amp;amp;logo=globe&amp;amp;logoColor=white" alt="Website" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Your gateway to Agent TARS ecosystem&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üìö &lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/guide/get-started/quick-start.html"&gt; &lt;img src="https://img.shields.io/badge/Get-Started-06B6D4?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Quick Start" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Zero to hero in 5 minutes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üöÄ &lt;strong&gt;What's New&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/beta"&gt; &lt;img src="https://img.shields.io/badge/Read-Blog-F59E0B?style=for-the-badge&amp;amp;logo=rss&amp;amp;logoColor=white" alt="Blog" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Discover cutting-edge features &amp;amp; vision&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üõ†Ô∏è &lt;strong&gt;Developer Zone&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/guide/get-started/introduction.html"&gt; &lt;img src="https://img.shields.io/badge/View-Docs-10B981?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Docs" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Master every command &amp;amp; features&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üéØ &lt;strong&gt;Showcase&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/bytedance/UI-TARS-desktop/issues/842"&gt; &lt;img src="https://img.shields.io/badge/View-Examples-8B5CF6?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="Examples" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;View use cases built by the official and community&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üîß &lt;strong&gt;Reference&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/api/"&gt; &lt;img src="https://img.shields.io/badge/API-Reference-EF4444?style=for-the-badge&amp;amp;logo=book&amp;amp;logoColor=white" alt="API" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Complete technical reference&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;h2&gt;UI-TARS Desktop&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img alt="UI-TARS" width="260" src="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/apps/ui-tars/resources/icon.png" /&gt; &lt;/p&gt; 
&lt;p&gt;UI-TARS Desktop is a native GUI agent for your local computer, driven by &lt;a href="https://github.com/bytedance/UI-TARS"&gt;UI-TARS&lt;/a&gt; and Seed-1.5-VL/1.6 series models.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &amp;nbsp;&amp;nbsp; üìë &lt;a href="https://arxiv.org/abs/2501.12326"&gt;Paper&lt;/a&gt; &amp;nbsp;&amp;nbsp; | ü§ó &lt;a href="https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B"&gt;Hugging Face Models&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü´® &lt;a href="https://discord.gg/pTXwYVjfcs"&gt;Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü§ñ &lt;a href="https://www.modelscope.cn/collections/UI-TARS-bccb56fa1ef640"&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;br /&gt; üñ•Ô∏è Desktop Application &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; üëì &lt;a href="https://github.com/web-infra-dev/midscene"&gt;Midscene (use in browser)&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;Showcase&lt;/h3&gt; 
&lt;!-- // FIXME: Choose only two demo, one local computer and one remote computer showcase. --&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Instruction&lt;/th&gt; 
   &lt;th align="center"&gt;Local Operator&lt;/th&gt; 
   &lt;th align="center"&gt;Remote Operator&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Please help me open the autosave feature of VS Code and delay AutoSave operations for 500 milliseconds in the VS Code setting.&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/01e49b69-7070-46c8-b3e3-2aaaaec71800" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Could you help me check the latest open issue of the UI-TARS-Desktop project on GitHub?&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/3d159f54-d24a-4268-96c0-e149607e9199" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/072fb72d-7394-4bfa-95f5-4736e29f7e58" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ Natural language control powered by Vision-Language Model&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Screenshot and visual recognition support&lt;/li&gt; 
 &lt;li&gt;üéØ Precise mouse and keyboard control&lt;/li&gt; 
 &lt;li&gt;üíª Cross-platform support (Windows/MacOS/Browser)&lt;/li&gt; 
 &lt;li&gt;üîÑ Real-time feedback and status display&lt;/li&gt; 
 &lt;li&gt;üîê Private and secure - fully local processing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/quick-start.md"&gt;Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our paper and code useful in your research, please consider giving a star &lt;span&gt;‚≠ê&lt;/span&gt; and citation &lt;span&gt;üìù&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@article{qin2025ui,
  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},
  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},
  journal={arXiv preprint arXiv:2501.12326},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>NevaMind-AI/memU</title>
      <link>https://github.com/NevaMind-AI/memU</link>
      <description>&lt;p&gt;Memory infrastructure for LLMs and AI agents&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/banner.png" alt="MemU Banner" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;MemU&lt;/h1&gt; 
 &lt;h3&gt;A Future-Oriented Agentic Memory System&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/memu-py"&gt;&lt;img src="https://badge.fury.io/py/memu-py.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.13+-blue.svg?sanitize=true" alt="Python 3.13+" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/memu"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Chat-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/memU_ai"&gt;&lt;img src="https://img.shields.io/badge/Twitter-Follow-1DA1F2?logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/17374" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/17374" alt="NevaMind-AI%2FmemU | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;MemU is an agentic memory framework for LLM and AI agent backends. It receives &lt;strong&gt;multimodal inputs&lt;/strong&gt; (conversations, documents, images), extracts them into structured memory, and organizes them into a &lt;strong&gt;hierarchical file system&lt;/strong&gt; that supports both &lt;strong&gt;embedding-based (RAG)&lt;/strong&gt; and &lt;strong&gt;non-embedding (LLM)&lt;/strong&gt; retrieval.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠êÔ∏è Star the repository&lt;/h2&gt; 
&lt;img width="100%" src="https://github.com/NevaMind-AI/memU/raw/main/assets/star.gif" /&gt; If you find memU useful or interesting, a GitHub Star ‚≠êÔ∏è would be greatly appreciated. 
&lt;hr /&gt; 
&lt;p&gt;MemU is collaborating with four open-source projects to launch the 2026 New Year Challenge. üéâBetween January 8‚Äì18, contributors can submit PRs to memU and earn cash rewards, community recognition, and platform credits. üéÅ&lt;a href="https://discord.gg/KaWy6SBAsx"&gt;Learn more &amp;amp; get involved&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Core Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üóÇÔ∏è &lt;strong&gt;Hierarchical File System&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Three-layer architecture: Resource ‚Üí Item ‚Üí Category with full traceability&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîç &lt;strong&gt;Dual Retrieval Methods&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RAG (embedding-based) for speed, LLM (non-embedding) for deep semantic understanding&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üé® &lt;strong&gt;Multimodal Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process conversations, documents, images, audio, and video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîÑ &lt;strong&gt;Self-Evolving Memory&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Memory structure adapts and improves based on usage patterns&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üóÇÔ∏è Hierarchical File System&lt;/h2&gt; 
&lt;p&gt;MemU organizes memory using a &lt;strong&gt;three-layer architecture&lt;/strong&gt; inspired by hierarchical storage systems:&lt;/p&gt; 
&lt;img width="100%" alt="structure" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/structure.png" /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Layer&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Resource&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Raw multimodal data warehouse&lt;/td&gt; 
   &lt;td&gt;JSON conversations, text documents, images, videos&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Item&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Discrete extracted memory units&lt;/td&gt; 
   &lt;td&gt;Individual preferences, skills, opinions, habits&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Category&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Aggregated textual memory with summaries&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;preferences.md&lt;/code&gt;, &lt;code&gt;work_life.md&lt;/code&gt;, &lt;code&gt;relationships.md&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Key Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full Traceability&lt;/strong&gt;: Track from raw data ‚Üí items ‚Üí categories and back&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Progressive Summarization&lt;/strong&gt;: Each layer provides increasingly abstracted views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Organization&lt;/strong&gt;: Categories evolve based on content patterns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üé® Multimodal Support&lt;/h2&gt; 
&lt;p&gt;MemU processes diverse content types into unified memory:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Modality&lt;/th&gt; 
   &lt;th&gt;Input&lt;/th&gt; 
   &lt;th&gt;Processing&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;conversation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;JSON chat logs&lt;/td&gt; 
   &lt;td&gt;Extract preferences, opinions, habits, relationships&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;document&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Text files (.txt, .md)&lt;/td&gt; 
   &lt;td&gt;Extract knowledge, skills, facts&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;image&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;PNG, JPG, etc.&lt;/td&gt; 
   &lt;td&gt;Vision model extracts visual concepts and descriptions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;video&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Video files&lt;/td&gt; 
   &lt;td&gt;Frame extraction + vision analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;audio&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Audio files&lt;/td&gt; 
   &lt;td&gt;Transcription + text processing&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;All modalities are unified into the same three-layer hierarchy, enabling cross-modal retrieval.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Option 1: Cloud Version&lt;/h3&gt; 
&lt;p&gt;Try MemU instantly without any setup:&lt;/p&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://memu.so"&gt;memu.so&lt;/a&gt;&lt;/strong&gt; - Hosted cloud service with full API access&lt;/p&gt; 
&lt;p&gt;For enterprise deployment and custom solutions, contact &lt;strong&gt;&lt;a href="mailto:info@nevamind.ai"&gt;info@nevamind.ai&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Cloud API (v3)&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Base URL&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;https://api.memu.so&lt;/code&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Auth&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Authorization: Bearer YOUR_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Endpoint&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/memorize&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register a memorization task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GET&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/memorize/status/{task_id}&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Get task status&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/categories&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;List memory categories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/retrieve&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Retrieve memories (semantic search)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;üìö &lt;strong&gt;&lt;a href="https://memu.pro/docs#cloud-version"&gt;Full API Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Option 2: Self-Hosted&lt;/h3&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Basic Example&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Requirements&lt;/strong&gt;: Python 3.13+ and an OpenAI API key&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Test with In-Memory Storage&lt;/strong&gt; (no database required):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
cd tests
python test_inmemory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Test with PostgreSQL Storage&lt;/strong&gt; (requires pgvector):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector
docker run -d \
  --name memu-postgres \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=memu \
  -p 5432:5432 \
  pgvector/pgvector:pg16

# Run the test
export OPENAI_API_KEY=your_api_key
cd tests
python test_postgres.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Both examples demonstrate the complete workflow:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Memorize&lt;/strong&gt;: Process a conversation file and extract structured memory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Retrieve (RAG)&lt;/strong&gt;: Fast embedding-based search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Retrieve (LLM)&lt;/strong&gt;: Deep semantic understanding search&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/tests/test_inmemory.py"&gt;&lt;code&gt;tests/test_inmemory.py&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/tests/test_postgres.py"&gt;&lt;code&gt;tests/test_postgres.py&lt;/code&gt;&lt;/a&gt; for the full source code.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Custom LLM and Embedding Providers&lt;/h3&gt; 
&lt;p&gt;MemU supports custom LLM and embedding providers beyond OpenAI. Configure them via &lt;code&gt;llm_profiles&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memu import MemUService

service = MemUService(
    llm_profiles={
        # Default profile for LLM operations
        "default": {
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": "your_api_key",
            "chat_model": "qwen3-max",
            "client_backend": "sdk"  # "sdk" or "http"
        },
        # Separate profile for embeddings
        "embedding": {
            "base_url": "https://api.voyageai.com/v1",
            "api_key": "your_voyage_api_key",
            "embed_model": "voyage-3.5-lite"
        }
    },
    # ... other configuration
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìñ Core APIs&lt;/h2&gt; 
&lt;h3&gt;&lt;code&gt;memorize()&lt;/code&gt; - Extract and Store Memory&lt;/h3&gt; 
&lt;p&gt;Processes input resources and extracts structured memory:&lt;/p&gt; 
&lt;img width="100%" alt="memorize" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/memorize.png" /&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result = await service.memorize(
    resource_url="path/to/file.json",  # File path or URL
    modality="conversation",            # conversation | document | image | video | audio
    user={"user_id": "123"}             # Optional: scope to a user
)

# Returns:
{
    "resource": {...},      # Stored resource metadata
    "items": [...],         # Extracted memory items
    "categories": [...]     # Updated category summaries
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;retrieve()&lt;/code&gt; - Query Memory&lt;/h3&gt; 
&lt;p&gt;Retrieves relevant memory based on queries. MemU supports &lt;strong&gt;two retrieval strategies&lt;/strong&gt;:&lt;/p&gt; 
&lt;img width="100%" alt="retrieve" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/retrieve.png" /&gt; 
&lt;h4&gt;RAG-based Retrieval (&lt;code&gt;method="rag"&lt;/code&gt;)&lt;/h4&gt; 
&lt;p&gt;Fast &lt;strong&gt;embedding vector search&lt;/strong&gt; using cosine similarity:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Fast&lt;/strong&gt;: Pure vector computation&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Scalable&lt;/strong&gt;: Efficient for large memory stores&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Returns scores&lt;/strong&gt;: Each result includes similarity score&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;LLM-based Retrieval (&lt;code&gt;method="llm"&lt;/code&gt;)&lt;/h4&gt; 
&lt;p&gt;Deep &lt;strong&gt;semantic understanding&lt;/strong&gt; through direct LLM reasoning:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Deep understanding&lt;/strong&gt;: LLM comprehends context and nuance&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Query rewriting&lt;/strong&gt;: Automatically refines query at each tier&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Adaptive&lt;/strong&gt;: Stops early when sufficient information is found&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Comparison&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;RAG&lt;/th&gt; 
   &lt;th&gt;LLM&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Speed&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚ö° Fast&lt;/td&gt; 
   &lt;td&gt;üê¢ Slower&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üí∞ Low&lt;/td&gt; 
   &lt;td&gt;üí∞üí∞ Higher&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Semantic depth&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medium&lt;/td&gt; 
   &lt;td&gt;Deep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Tier 2 scope&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All items&lt;/td&gt; 
   &lt;td&gt;Only items in relevant categories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;With similarity scores&lt;/td&gt; 
   &lt;td&gt;Ranked by LLM reasoning&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Both methods support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Context-aware rewriting&lt;/strong&gt;: Resolves pronouns using conversation history&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Progressive search&lt;/strong&gt;: Categories ‚Üí Items ‚Üí Resources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sufficiency checking&lt;/strong&gt;: Stops when enough information is retrieved&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result = await service.retrieve(
    queries=[
        {"role": "user", "content": {"text": "What are their preferences?"}},
        {"role": "user", "content": {"text": "Tell me about work habits"}}
    ],
    where={"user_id": "123"}  # Optional: scope filter
)

# Returns:
{
    "categories": [...],     # Relevant categories (with scores for RAG)
    "items": [...],          # Relevant memory items
    "resources": [...],      # Related raw resources
    "next_step_query": "..." # Rewritten query for follow-up (if applicable)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Scope Filtering&lt;/strong&gt;: Use &lt;code&gt;where&lt;/code&gt; to filter by user model fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;where={"user_id": "123"}&lt;/code&gt; - exact match&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;where={"agent_id__in": ["1", "2"]}&lt;/code&gt; - match any in list&lt;/li&gt; 
 &lt;li&gt;Omit &lt;code&gt;where&lt;/code&gt; to retrieve across all scopes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìö &lt;strong&gt;For complete API documentation&lt;/strong&gt;, see &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/docs/SERVICE_API.md"&gt;SERVICE_API.md&lt;/a&gt; - includes all methods, CRUD operations, pipeline configuration, and configuration types.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° Use Cases&lt;/h2&gt; 
&lt;h3&gt;Example 1: Conversation Memory&lt;/h3&gt; 
&lt;p&gt;Extract and organize memory from multi-turn conversations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_1_conversation_memory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Processes multiple conversation JSON files&lt;/li&gt; 
 &lt;li&gt;Extracts memory items (preferences, habits, opinions, relationships)&lt;/li&gt; 
 &lt;li&gt;Generates category markdown files (&lt;code&gt;preferences.md&lt;/code&gt;, &lt;code&gt;work_life.md&lt;/code&gt;, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Personal AI assistants, customer support bots, social chatbots&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Example 2: Skill Extraction from Logs&lt;/h3&gt; 
&lt;p&gt;Extract skills and lessons learned from agent execution logs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_2_skill_extraction.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Processes agent logs sequentially&lt;/li&gt; 
 &lt;li&gt;Extracts actions, outcomes, and lessons learned&lt;/li&gt; 
 &lt;li&gt;Demonstrates &lt;strong&gt;incremental learning&lt;/strong&gt; - memory evolves with each file&lt;/li&gt; 
 &lt;li&gt;Generates evolving skill guides (&lt;code&gt;log_1.md&lt;/code&gt; ‚Üí &lt;code&gt;log_2.md&lt;/code&gt; ‚Üí &lt;code&gt;skill.md&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; DevOps teams, agent self-improvement, knowledge management&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Example 3: Multimodal Memory&lt;/h3&gt; 
&lt;p&gt;Process diverse content types into unified memory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_3_multimodal_memory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Processes documents and images together&lt;/li&gt; 
 &lt;li&gt;Extracts memory from different content types&lt;/li&gt; 
 &lt;li&gt;Unifies into cross-modal categories (&lt;code&gt;technical_documentation&lt;/code&gt;, &lt;code&gt;visual_diagrams&lt;/code&gt;, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Documentation systems, learning platforms, research tools&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìä Performance&lt;/h2&gt; 
&lt;p&gt;MemU achieves &lt;strong&gt;92.09% average accuracy&lt;/strong&gt; on the Locomo benchmark across all reasoning tasks.&lt;/p&gt; 
&lt;img width="100%" alt="benchmark" src="https://github.com/user-attachments/assets/6fec4884-94e5-4058-ad5c-baac3d7e76d9" /&gt; 
&lt;p&gt;View detailed experimental data: &lt;a href="https://github.com/NevaMind-AI/memU-experiment"&gt;memU-experiment&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üß© Ecosystem&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Repository&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU"&gt;memU&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Core algorithm engine&lt;/td&gt; 
   &lt;td&gt;Embed AI memory into your product&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU-server"&gt;memU-server&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Backend service with CRUD, user system, RBAC&lt;/td&gt; 
   &lt;td&gt;Self-host a memory backend&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU-ui"&gt;memU-ui&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Visual dashboard&lt;/td&gt; 
   &lt;td&gt;Ready-to-use memory console&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Links:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;a href="https://app.memu.so/quick-start"&gt;Try MemU Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìö &lt;a href="https://memu.pro/docs"&gt;API Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://discord.gg/memu"&gt;Discord Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Partners&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework"&gt;&lt;img src="https://avatars.githubusercontent.com/u/113095513?s=200&amp;amp;v=4" alt="Ten" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://openagents.org"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/openagents.png" alt="OpenAgents" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/milvus-io/milvus"&gt;&lt;img src="https://miro.medium.com/v2/resize:fit:2400/1*-VEGyAgcIBD62XtZWavy8w.png" alt="Milvus" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://xroute.ai/"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/xroute.png" alt="xRoute" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://jaaz.app/"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/jazz.png" alt="Jazz" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Buddie-AI/Buddie"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/buddie.png" alt="Buddie" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/bytebase/bytebase"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/bytebase.png" alt="Bytebase" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/LazyAGI/LazyLLM"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/LazyLLM.png" alt="LazyLLM" height="40" style="margin: 10px;" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù How to Contribute&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding features, or improving documentation, your help is appreciated.&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;p&gt;To start contributing to MemU, you'll need to set up your development environment:&lt;/p&gt; 
&lt;h4&gt;Prerequisites&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.13+&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (Python package manager)&lt;/li&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Setup Development Environment&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Fork and clone the repository
git clone https://github.com/YOUR_USERNAME/memU.git
cd memU

# 2. Install development dependencies
make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;make install&lt;/code&gt; command will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment using &lt;code&gt;uv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install all project dependencies&lt;/li&gt; 
 &lt;li&gt;Set up pre-commit hooks for code quality checks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Running Quality Checks&lt;/h4&gt; 
&lt;p&gt;Before submitting your contribution, ensure your code passes all quality checks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make check
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;make check&lt;/code&gt; command runs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lock file verification&lt;/strong&gt;: Ensures &lt;code&gt;pyproject.toml&lt;/code&gt; consistency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-commit hooks&lt;/strong&gt;: Lints code with Ruff, formats with Black&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type checking&lt;/strong&gt;: Runs &lt;code&gt;mypy&lt;/code&gt; for static type analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependency analysis&lt;/strong&gt;: Uses &lt;code&gt;deptry&lt;/code&gt; to find obsolete dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing Guidelines&lt;/h3&gt; 
&lt;p&gt;For detailed contribution guidelines, code standards, and development practices, please see &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick tips:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a new branch for each feature or bug fix&lt;/li&gt; 
 &lt;li&gt;Write clear commit messages&lt;/li&gt; 
 &lt;li&gt;Add tests for new functionality&lt;/li&gt; 
 &lt;li&gt;Update documentation as needed&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;make check&lt;/code&gt; before pushing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/LICENSE.txt"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåç Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/NevaMind-AI/memU/issues"&gt;Report bugs &amp;amp; request features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;a href="https://discord.com/invite/hQZntfGsbJ"&gt;Join the community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;X (Twitter)&lt;/strong&gt;: &lt;a href="https://x.com/memU_ai"&gt;Follow @memU_ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contact&lt;/strong&gt;: &lt;a href="mailto:info@nevamind.ai"&gt;info@nevamind.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Star us on GitHub&lt;/strong&gt; to get notified about new releases!&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>