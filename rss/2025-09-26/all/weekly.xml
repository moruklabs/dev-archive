<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Thu, 25 Sep 2025 01:42:22 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>tldraw/tldraw</title>
      <link>https://github.com/tldraw/tldraw</link>
      <description>&lt;p&gt;very good whiteboard SDK / infinite canvas SDK&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;tldraw&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://deepwiki.com/tldraw/tldraw"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Welcome to the public monorepo for &lt;a href="https://github.com/tldraw/tldraw"&gt;tldraw&lt;/a&gt;. tldraw is a library for creating infinite canvas experiences in React. It's the software behind the digital whiteboard &lt;a href="https://tldraw.com"&gt;tldraw.com&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read the docs and learn more at &lt;a href="https://tldraw.dev"&gt;tldraw.dev&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Learn about &lt;a href="https://github.com/tldraw/tldraw#License"&gt;our license&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://tldraw.dev/#pricing"&gt;Click here&lt;/a&gt; to learn about our license and pricing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm i tldraw
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-tsx"&gt;import { Tldraw } from 'tldraw'
import 'tldraw/tldraw.css'

export default function App() {
	return (
		&amp;lt;div style={{ position: 'fixed', inset: 0 }}&amp;gt;
			&amp;lt;Tldraw /&amp;gt;
		&amp;lt;/div&amp;gt;
	)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Learn more at &lt;a href="https://tldraw.dev"&gt;tldraw.dev&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Local development&lt;/h2&gt; 
&lt;p&gt;The local development server will run our examples app. The basic example will show any changes you've made to the codebase.&lt;/p&gt; 
&lt;p&gt;To run the local development server, first clone this repo.&lt;/p&gt; 
&lt;p&gt;Enable &lt;a href="https://nodejs.org/api/corepack.html"&gt;corepack&lt;/a&gt; to make sure you have the right version of &lt;code&gt;yarn&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm i -g corepack
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yarn
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start the local development server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yarn dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open the example project at &lt;code&gt;localhost:5420&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Tips for AIs&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Are you an AI agent?&lt;/strong&gt; If so, this monorepo has special &lt;code&gt;CONTEXT.md&lt;/code&gt; files found throughout the repository that you can use to quickly build context while you work. Use your own tools to find and read these files, or use our helpful &lt;code&gt;context&lt;/code&gt; script to locate and log the contents of the most relevant files.&lt;/p&gt; 
&lt;p&gt;To get started quickly, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yarn context
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will find and display the nearest CONTEXT.md file to help you understand the codebase. The &lt;code&gt;context&lt;/code&gt; script supports several options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yarn context&lt;/code&gt; - Show path to nearest CONTEXT.md from current directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn context ./foo/bar/baz.ts&lt;/code&gt; - Show path to nearest CONTEXT.md for a specific file or directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn context -v&lt;/code&gt; or &lt;code&gt;--verbose&lt;/code&gt; - Show full content of nearest CONTEXT.md&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn context -r&lt;/code&gt; or &lt;code&gt;--recursive&lt;/code&gt; - Find all CONTEXT.md files in the repository&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The tldraw SDK is provided under the &lt;a href="https://github.com/tldraw/tldraw/raw/main/LICENSE.md"&gt;tldraw license&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can use the tldraw SDK in commercial or non-commercial projects so long as you preserve the "Made with tldraw" watermark on the canvas. To remove the watermark, you can purchase a &lt;a href="https://tldraw.dev#pricing"&gt;business license&lt;/a&gt;. Visit &lt;a href="https://tldraw.dev"&gt;tldraw.dev&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;Copyright (c) 2024-present tldraw Inc. The tldraw name and logo are trademarks of tldraw. Please see our &lt;a href="https://github.com/tldraw/tldraw/raw/main/TRADEMARKS.md"&gt;trademark guidelines&lt;/a&gt; for info on acceptable usage.&lt;/p&gt; 
&lt;h2&gt;Distributions&lt;/h2&gt; 
&lt;p&gt;You can find tldraw on npm &lt;a href="https://www.npmjs.com/package/@tldraw/tldraw?activeTab=versions"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Please see our &lt;a href="https://github.com/tldraw/tldraw/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;. Found a bug? Please &lt;a href="https://github.com/tldraw/tldraw/issues/new"&gt;submit an issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Have questions, comments or feedback? &lt;a href="https://discord.tldraw.com/?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=sociallink"&gt;Join our discord&lt;/a&gt;. For the latest news and release notes, visit &lt;a href="https://tldraw.dev"&gt;tldraw.dev&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/tldraw/tldraw/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=tldraw/tldraw&amp;amp;max=400&amp;amp;columns=20" width="100%" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#tldraw/tldraw"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=tldraw/tldraw&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=tldraw/tldraw&amp;amp;type=Date" /&gt; 
  &lt;img src="https://api.star-history.com/svg?repos=tldraw/tldraw&amp;amp;type=Date" alt="Star History Chart" width="100%" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Find us on Twitter/X at &lt;a href="https://twitter.com/tldraw"&gt;@tldraw&lt;/a&gt;. You can contact us by email at &lt;a href="mailto:hello@tldraw.com"&gt;hello@tldraw.com&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fmtlib/fmt</title>
      <link>https://github.com/fmtlib/fmt</link>
      <description>&lt;p&gt;A modern formatting library&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/576385/156254208-f5b743a9-88cf-439d-b0c0-923d53e8d551.png" alt="{fmt}" width="25%" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Alinux"&gt;&lt;img src="https://github.com/fmtlib/fmt/workflows/linux/badge.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Amacos"&gt;&lt;img src="https://github.com/fmtlib/fmt/workflows/macos/badge.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Awindows"&gt;&lt;img src="https://github.com/fmtlib/fmt/workflows/windows/badge.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?%0Acolspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20%0ASummary&amp;amp;q=proj%3Dfmt&amp;amp;can=1"&gt;&lt;img src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/fmt.svg?sanitize=true" alt="fmt is continuously fuzzed at oss-fuzz" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/8880"&gt;&lt;img src="https://www.bestpractices.dev/projects/8880/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/fmtlib/fmt"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/fmtlib/fmt/badge" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/fmt"&gt;&lt;img src="https://img.shields.io/badge/stackoverflow-fmt-blue.svg?sanitize=true" alt="Ask questions at StackOverflow with the tag fmt" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;{fmt}&lt;/strong&gt; is an open-source formatting library providing a fast and safe alternative to C stdio and C++ iostreams.&lt;/p&gt; 
&lt;p&gt;If you like this project, please consider donating to one of the funds that help victims of the war in Ukraine: &lt;a href="https://www.stopputin.net/"&gt;https://www.stopputin.net/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fmt.dev"&gt;Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hackingcpp.com/cpp/libs/fmt.html"&gt;Cheat Sheets&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Q&amp;amp;A: ask questions on &lt;a href="https://stackoverflow.com/questions/tagged/fmt"&gt;StackOverflow with the tag fmt&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Try {fmt} in &lt;a href="https://godbolt.org/z/8Mx1EW73v"&gt;Compiler Explorer&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Simple &lt;a href="https://fmt.dev/latest/api/"&gt;format API&lt;/a&gt; with positional arguments for localization&lt;/li&gt; 
 &lt;li&gt;Implementation of &lt;a href="https://en.cppreference.com/w/cpp/utility/format"&gt;C++20 std::format&lt;/a&gt; and &lt;a href="https://en.cppreference.com/w/cpp/io/print"&gt;C++23 std::print&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fmt.dev/latest/syntax/"&gt;Format string syntax&lt;/a&gt; similar to Python's &lt;a href="https://docs.python.org/3/library/stdtypes.html#str.format"&gt;format&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fast IEEE 754 floating-point formatter with correct rounding, shortness and round-trip guarantees using the &lt;a href="https://github.com/jk-jeon/dragonbox"&gt;Dragonbox&lt;/a&gt; algorithm&lt;/li&gt; 
 &lt;li&gt;Portable Unicode support&lt;/li&gt; 
 &lt;li&gt;Safe &lt;a href="https://fmt.dev/latest/api/#printf-formatting"&gt;printf implementation&lt;/a&gt; including the POSIX extension for positional arguments&lt;/li&gt; 
 &lt;li&gt;Extensibility: &lt;a href="https://fmt.dev/latest/api/#formatting-user-defined-types"&gt;support for user-defined types&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;High performance: faster than common standard library implementations of &lt;code&gt;(s)printf&lt;/code&gt;, iostreams, &lt;code&gt;to_string&lt;/code&gt; and &lt;code&gt;to_chars&lt;/code&gt;, see &lt;a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#speed-tests"&gt;Speed tests&lt;/a&gt; and &lt;a href="http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html"&gt;Converting a hundred million integers to strings per second&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Small code size both in terms of source code with the minimum configuration consisting of just three files, &lt;code&gt;base.h&lt;/code&gt;, &lt;code&gt;format.h&lt;/code&gt; and &lt;code&gt;format-inl.h&lt;/code&gt;, and compiled code; see &lt;a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#compile-time-and-code-bloat"&gt;Compile time and code bloat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Reliability: the library has an extensive set of &lt;a href="https://github.com/fmtlib/fmt/tree/master/test"&gt;tests&lt;/a&gt; and is &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?colspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20Summary&amp;amp;q=proj%3Dfmt&amp;amp;can=1"&gt;continuously fuzzed&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Safety: the library is fully type-safe, errors in format strings can be reported at compile time, automatic memory management prevents buffer overflow errors&lt;/li&gt; 
 &lt;li&gt;Ease of use: small self-contained code base, no external dependencies, permissive MIT &lt;a href="https://github.com/fmtlib/fmt/raw/master/LICENSE"&gt;license&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fmt.dev/latest/#portability"&gt;Portability&lt;/a&gt; with consistent output across platforms and support for older compilers&lt;/li&gt; 
 &lt;li&gt;Clean warning-free codebase even on high warning levels such as &lt;code&gt;-Wall -Wextra -pedantic&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Locale independence by default&lt;/li&gt; 
 &lt;li&gt;Optional header-only configuration enabled with the &lt;code&gt;FMT_HEADER_ONLY&lt;/code&gt; macro&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://fmt.dev"&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h1&gt;Examples&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Print to stdout&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/Tevcjh"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/base.h&amp;gt;

int main() {
  fmt::print("Hello, world!\n");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Format a string&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/oK8h33"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::string s = fmt::format("The answer is {}.", 42);
// s == "The answer is 42."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Format a string using positional arguments&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/Yn7Txe"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::string s = fmt::format("I'd rather be {1} than {0}.", "right", "happy");
// s == "I'd rather be happy than right."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Print dates and times&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/c31ExdY3W"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/chrono.h&amp;gt;

int main() {
  auto now = std::chrono::system_clock::now();
  fmt::print("Date and time: {}\n", now);
  fmt::print("Time: {:%H:%M}\n", now);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Date and time: 2023-12-26 19:10:31.557195597
Time: 19:10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Print a container&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/MxM1YqjE7"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;vector&amp;gt;
#include &amp;lt;fmt/ranges.h&amp;gt;

int main() {
  std::vector&amp;lt;int&amp;gt; v = {1, 2, 3};
  fmt::print("{}\n", v);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[1, 2, 3]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Check a format string at compile time&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::string s = fmt::format("{:d}", "I am not a number");
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This gives a compile-time error in C++20 because &lt;code&gt;d&lt;/code&gt; is an invalid format specifier for a string.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Write a file from a single thread&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/os.h&amp;gt;

int main() {
  auto out = fmt::output_file("guide.txt");
  out.print("Don't {}", "Panic");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This can be &lt;a href="http://www.zverovich.net/2020/08/04/optimal-file-buffer-size.html"&gt;5 to 9 times faster than fprintf&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Print with colors and text styles&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/color.h&amp;gt;

int main() {
  fmt::print(fg(fmt::color::crimson) | fmt::emphasis::bold,
             "Hello, {}!\n", "world");
  fmt::print(fg(fmt::color::floral_white) | bg(fmt::color::slate_gray) |
             fmt::emphasis::underline, "Olá, {}!\n", "Mundo");
  fmt::print(fg(fmt::color::steel_blue) | fmt::emphasis::italic,
             "你好{}！\n", "世界");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Output on a modern terminal with Unicode support:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/fmtlib/fmt/assets/%0A576385/2a93c904-d6fa-4aa6-b453-2618e1c327d7" alt="image" /&gt;&lt;/p&gt; 
&lt;h1&gt;Benchmarks&lt;/h1&gt; 
&lt;h2&gt;Speed tests&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Library&lt;/th&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Run Time, s&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;libc&lt;/td&gt; 
   &lt;td&gt;printf&lt;/td&gt; 
   &lt;td&gt;0.91&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;libc++&lt;/td&gt; 
   &lt;td&gt;std::ostream&lt;/td&gt; 
   &lt;td&gt;2.49&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;{fmt} 9.1&lt;/td&gt; 
   &lt;td&gt;fmt::print&lt;/td&gt; 
   &lt;td&gt;0.74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Boost Format 1.80&lt;/td&gt; 
   &lt;td&gt;boost::format&lt;/td&gt; 
   &lt;td&gt;6.26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Folly Format&lt;/td&gt; 
   &lt;td&gt;folly::format&lt;/td&gt; 
   &lt;td&gt;1.87&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;{fmt} is the fastest of the benchmarked methods, ~20% faster than &lt;code&gt;printf&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The above results were generated by building &lt;code&gt;tinyformat_test.cpp&lt;/code&gt; on macOS 12.6.1 with &lt;code&gt;clang++ -O3 -DNDEBUG -DSPEED_TEST -DHAVE_FORMAT&lt;/code&gt;, and taking the best of three runs. In the test, the format string &lt;code&gt;"%0.10f:%04d:%+g:%s:%p:%c:%%\n"&lt;/code&gt; or equivalent is filled 2,000,000 times with output sent to &lt;code&gt;/dev/null&lt;/code&gt;; for further details refer to the &lt;a href="https://github.com/fmtlib/format-benchmark/raw/master/src/tinyformat-test.cc"&gt;source&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;{fmt} is up to 20-30x faster than &lt;code&gt;std::ostringstream&lt;/code&gt; and &lt;code&gt;sprintf&lt;/code&gt; on IEEE754 &lt;code&gt;float&lt;/code&gt; and &lt;code&gt;double&lt;/code&gt; formatting (&lt;a href="https://github.com/fmtlib/dtoa-benchmark"&gt;dtoa-benchmark&lt;/a&gt;) and faster than &lt;a href="https://github.com/google/double-conversion"&gt;double-conversion&lt;/a&gt; and &lt;a href="https://github.com/ulfjack/ryu"&gt;ryu&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fmt.dev/unknown_mac64_clang12.0.html"&gt;&lt;img src="https://user-images.githubusercontent.com/576385/95684665-11719600-0ba8-11eb-8e5b-972ff4e49428.png" alt="image" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compile time and code bloat&lt;/h2&gt; 
&lt;p&gt;The script &lt;a href="https://github.com/fmtlib/format-benchmark/raw/master/bloat-test.py"&gt;bloat-test.py&lt;/a&gt; from &lt;a href="https://github.com/fmtlib/format-benchmark"&gt;format-benchmark&lt;/a&gt; tests compile time and code bloat for nontrivial projects. It generates 100 translation units and uses &lt;code&gt;printf()&lt;/code&gt; or its alternative five times in each to simulate a medium-sized project. The resulting executable size and compile time (Apple clang version 15.0.0 (clang-1500.1.0.2.5), macOS Sonoma, best of three) is shown in the following tables.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Optimized build (-O3)&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Compile Time, s&lt;/th&gt; 
   &lt;th&gt;Executable size, KiB&lt;/th&gt; 
   &lt;th&gt;Stripped size, KiB&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;printf&lt;/td&gt; 
   &lt;td&gt;1.6&lt;/td&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;IOStreams&lt;/td&gt; 
   &lt;td&gt;25.9&lt;/td&gt; 
   &lt;td&gt;98&lt;/td&gt; 
   &lt;td&gt;84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fmt 83652df&lt;/td&gt; 
   &lt;td&gt;4.8&lt;/td&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tinyformat&lt;/td&gt; 
   &lt;td&gt;29.1&lt;/td&gt; 
   &lt;td&gt;161&lt;/td&gt; 
   &lt;td&gt;136&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Boost Format&lt;/td&gt; 
   &lt;td&gt;55.0&lt;/td&gt; 
   &lt;td&gt;530&lt;/td&gt; 
   &lt;td&gt;317&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;{fmt} is fast to compile and is comparable to &lt;code&gt;printf&lt;/code&gt; in terms of per-call binary size (within a rounding error on this system).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Non-optimized build&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Compile Time, s&lt;/th&gt; 
   &lt;th&gt;Executable size, KiB&lt;/th&gt; 
   &lt;th&gt;Stripped size, KiB&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;printf&lt;/td&gt; 
   &lt;td&gt;1.4&lt;/td&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;IOStreams&lt;/td&gt; 
   &lt;td&gt;23.4&lt;/td&gt; 
   &lt;td&gt;92&lt;/td&gt; 
   &lt;td&gt;68&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;{fmt} 83652df&lt;/td&gt; 
   &lt;td&gt;4.4&lt;/td&gt; 
   &lt;td&gt;89&lt;/td&gt; 
   &lt;td&gt;85&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tinyformat&lt;/td&gt; 
   &lt;td&gt;24.5&lt;/td&gt; 
   &lt;td&gt;204&lt;/td&gt; 
   &lt;td&gt;161&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Boost Format&lt;/td&gt; 
   &lt;td&gt;36.4&lt;/td&gt; 
   &lt;td&gt;831&lt;/td&gt; 
   &lt;td&gt;462&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;code&gt;libc&lt;/code&gt;, &lt;code&gt;lib(std)c++&lt;/code&gt;, and &lt;code&gt;libfmt&lt;/code&gt; are all linked as shared libraries to compare formatting function overhead only. Boost Format is a header-only library so it doesn't provide any linkage options.&lt;/p&gt; 
&lt;h2&gt;Running the tests&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://fmt.dev/latest/get-started/#building-from-source"&gt;Building the library&lt;/a&gt; for instructions on how to build the library and run the unit tests.&lt;/p&gt; 
&lt;p&gt;Benchmarks reside in a separate repository, &lt;a href="https://github.com/fmtlib/format-benchmark"&gt;format-benchmarks&lt;/a&gt;, so to run the benchmarks you first need to clone this repository and generate Makefiles with CMake:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ git clone --recursive https://github.com/fmtlib/format-benchmark.git
$ cd format-benchmark
$ cmake .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the speed test:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make speed-test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or the bloat test:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make bloat-test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Migrating code&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://clang.llvm.org/extra/clang-tidy/"&gt;clang-tidy&lt;/a&gt; v18 provides the &lt;a href="https://clang.llvm.org/extra/clang-tidy/checks/modernize/use-std-print.html"&gt;modernize-use-std-print&lt;/a&gt; check that is capable of converting occurrences of &lt;code&gt;printf&lt;/code&gt; and &lt;code&gt;fprintf&lt;/code&gt; to &lt;code&gt;fmt::print&lt;/code&gt; if configured to do so. (By default it converts to &lt;code&gt;std::print&lt;/code&gt;.)&lt;/p&gt; 
&lt;h1&gt;Notable projects using this library&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://play0ad.com/"&gt;0 A.D.&lt;/a&gt;: a free, open-source, cross-platform real-time strategy game&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ampl/mp"&gt;AMPL/MP&lt;/a&gt;: an open-source library for mathematical programming&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apple/foundationdb"&gt;Apple's FoundationDB&lt;/a&gt;: an open-source, distributed, transactional key-value store&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aseprite/aseprite"&gt;Aseprite&lt;/a&gt;: animated sprite editor &amp;amp; pixel art tool&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.aviobook.aero/en"&gt;AvioBook&lt;/a&gt;: a comprehensive aircraft operations suite&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://battle.net/"&gt;Blizzard Battle.net&lt;/a&gt;: an online gaming platform&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://celestia.space/"&gt;Celestia&lt;/a&gt;: real-time 3D visualization of space&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ceph.com/"&gt;Ceph&lt;/a&gt;: a scalable distributed storage system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ccache.dev/"&gt;ccache&lt;/a&gt;: a compiler cache&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ClickHouse/ClickHouse"&gt;ClickHouse&lt;/a&gt;: an analytical database management system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.contextvision.com/"&gt;ContextVision&lt;/a&gt;: medical imaging software&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/contour-terminal/contour/"&gt;Contour&lt;/a&gt;: a modern terminal emulator&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cuauv.org/"&gt;CUAUV&lt;/a&gt;: Cornell University's autonomous underwater vehicle&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://drake.mit.edu/"&gt;Drake&lt;/a&gt;: a planning, control, and analysis toolbox for nonlinear dynamical systems (MIT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/envoyproxy/envoy"&gt;Envoy&lt;/a&gt;: C++ L7 proxy and communication bus (Lyft)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fivem.net/"&gt;FiveM&lt;/a&gt;: a modification framework for GTA V&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MengRao/fmtlog"&gt;fmtlog&lt;/a&gt;: a performant fmtlib-style logging library with latency in nanoseconds&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebook/folly"&gt;Folly&lt;/a&gt;: Facebook open-source library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gemrb.org/"&gt;GemRB&lt;/a&gt;: a portable open-source implementation of Bioware's Infinity Engine&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://store.steampowered.com/app/1247360/Grand_Mountain_Adventure/"&gt;Grand Mountain Adventure&lt;/a&gt;: a beautiful open-world ski &amp;amp; snowboarding game&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pvpgn/pvpgn-server"&gt;HarpyWar/pvpgn&lt;/a&gt;: Player vs Player Gaming Network with tweaks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kbengine/kbengine"&gt;KBEngine&lt;/a&gt;: an open-source MMOG server engine&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://keypirinha.com/"&gt;Keypirinha&lt;/a&gt;: a semantic launcher for Windows&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kodi.tv/"&gt;Kodi&lt;/a&gt; (formerly xbmc): home theater software&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kth.cash/"&gt;Knuth&lt;/a&gt;: high-performance Bitcoin full-node&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/contour-terminal/libunicode/"&gt;libunicode&lt;/a&gt;: a modern C++17 Unicode library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mariadb.org/"&gt;MariaDB&lt;/a&gt;: relational database management system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/verona"&gt;Microsoft Verona&lt;/a&gt;: research programming language for concurrent ownership&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mongodb.com/"&gt;MongoDB&lt;/a&gt;: distributed document database&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/duckie/mongo_smasher"&gt;MongoDB Smasher&lt;/a&gt;: a small tool to generate randomized datasets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openspaceproject.com/"&gt;OpenSpace&lt;/a&gt;: an open-source astrovisualization framework&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.polserver.com/"&gt;PenUltima Online (POL)&lt;/a&gt;: an MMO server, compatible with most Ultima Online clients&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/pytorch"&gt;PyTorch&lt;/a&gt;: an open-source machine learning library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quasardb.net/"&gt;quasardb&lt;/a&gt;: a distributed, high-performance, associative database&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/odygrd/quill"&gt;Quill&lt;/a&gt;: asynchronous low-latency logging library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ravijanjam/qkw"&gt;QKW&lt;/a&gt;: generalizing aliasing to simplify navigation, and execute complex multi-line terminal command sequences&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HunanTV/redis-cerberus"&gt;redis-cerberus&lt;/a&gt;: a Redis cluster proxy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vectorized.io/redpanda"&gt;redpanda&lt;/a&gt;: a 10x faster Kafka® replacement for mission-critical systems written in C++&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://rpclib.net/"&gt;rpclib&lt;/a&gt;: a modern C++ msgpack-RPC server and client library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.salesforce.com/analytics-cloud/overview/"&gt;Salesforce Analytics Cloud&lt;/a&gt;: business intelligence software&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.scylladb.com/"&gt;Scylla&lt;/a&gt;: a Cassandra-compatible NoSQL data store that can handle 1 million transactions per second on a single server&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.seastar-project.org/"&gt;Seastar&lt;/a&gt;: an advanced, open-source C++ framework for high-performance server applications on modern hardware&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gabime/spdlog"&gt;spdlog&lt;/a&gt;: super fast C++ logging library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.stellar.org/"&gt;Stellar&lt;/a&gt;: financial platform&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.touchsurgery.com/"&gt;Touch Surgery&lt;/a&gt;: surgery simulator&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TrinityCore/TrinityCore"&gt;TrinityCore&lt;/a&gt;: open-source MMORPG framework&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://userver.tech/"&gt;🐙 userver framework&lt;/a&gt;: open-source asynchronous framework with a rich set of abstractions and database drivers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/terminal"&gt;Windows Terminal&lt;/a&gt;: the new Windows terminal&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/search?q=fmtlib&amp;amp;type=Code"&gt;More...&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you are aware of other projects using this library, please let me know by &lt;a href="mailto:victor.zverovich@gmail.com"&gt;email&lt;/a&gt; or by submitting an &lt;a href="https://github.com/fmtlib/fmt/issues"&gt;issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Motivation&lt;/h1&gt; 
&lt;p&gt;So why yet another formatting library?&lt;/p&gt; 
&lt;p&gt;There are plenty of methods for doing this task, from standard ones like the printf family of function and iostreams to Boost Format and FastFormat libraries. The reason for creating a new library is that every existing solution that I found either had serious issues or didn't provide all the features I needed.&lt;/p&gt; 
&lt;h2&gt;printf&lt;/h2&gt; 
&lt;p&gt;The good thing about &lt;code&gt;printf&lt;/code&gt; is that it is pretty fast and readily available being a part of the C standard library. The main drawback is that it doesn't support user-defined types. &lt;code&gt;printf&lt;/code&gt; also has safety issues although they are somewhat mitigated with &lt;a href="https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html"&gt;__attribute__ ((format (printf, ...))&lt;/a&gt; in GCC. There is a POSIX extension that adds positional arguments required for &lt;a href="https://en.wikipedia.org/wiki/Internationalization_and_localization"&gt;i18n&lt;/a&gt; to &lt;code&gt;printf&lt;/code&gt; but it is not a part of C99 and may not be available on some platforms.&lt;/p&gt; 
&lt;h2&gt;iostreams&lt;/h2&gt; 
&lt;p&gt;The main issue with iostreams is best illustrated with an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::cout &amp;lt;&amp;lt; std::setprecision(2) &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; 1.23456 &amp;lt;&amp;lt; "\n";
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;which is a lot of typing compared to printf:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;printf("%.2f\n", 1.23456);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Matthew Wilson, the author of FastFormat, called this "chevron hell". iostreams don't support positional arguments by design.&lt;/p&gt; 
&lt;p&gt;The good part is that iostreams support user-defined types and are safe although error handling is awkward.&lt;/p&gt; 
&lt;h2&gt;Boost Format&lt;/h2&gt; 
&lt;p&gt;This is a very powerful library that supports both &lt;code&gt;printf&lt;/code&gt;-like format strings and positional arguments. Its main drawback is performance. According to various benchmarks, it is much slower than other methods considered here. Boost Format also has excessive build times and severe code bloat issues (see &lt;a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#benchmarks"&gt;Benchmarks&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;FastFormat&lt;/h2&gt; 
&lt;p&gt;This is an interesting library that is fast, safe and has positional arguments. However, it has significant limitations, citing its author:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Three features that have no hope of being accommodated within the current design are:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Leading zeros (or any other non-space padding)&lt;/li&gt; 
  &lt;li&gt;Octal/hexadecimal encoding&lt;/li&gt; 
  &lt;li&gt;Runtime width/alignment specification&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;It is also quite big and has a heavy dependency, on STLSoft, which might be too restrictive for use in some projects.&lt;/p&gt; 
&lt;h2&gt;Boost Spirit.Karma&lt;/h2&gt; 
&lt;p&gt;This is not a formatting library but I decided to include it here for completeness. As iostreams, it suffers from the problem of mixing verbatim text with arguments. The library is pretty fast, but slower on integer formatting than &lt;code&gt;fmt::format_to&lt;/code&gt; with format string compilation on Karma's own benchmark, see &lt;a href="http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html"&gt;Converting a hundred million integers to strings per second&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;{fmt} is distributed under the MIT &lt;a href="https://github.com/fmtlib/fmt/raw/master/LICENSE"&gt;license&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Documentation License&lt;/h1&gt; 
&lt;p&gt;The &lt;a href="https://fmt.dev/latest/syntax/"&gt;Format String Syntax&lt;/a&gt; section in the documentation is based on the one from Python &lt;a href="https://docs.python.org/3/library/string.html#module-string"&gt;string module documentation&lt;/a&gt;. For this reason, the documentation is distributed under the Python Software Foundation license available in &lt;a href="https://raw.github.com/fmtlib/fmt/master/doc/python-license.txt"&gt;doc/python-license.txt&lt;/a&gt;. It only applies if you distribute the documentation of {fmt}.&lt;/p&gt; 
&lt;h1&gt;Maintainers&lt;/h1&gt; 
&lt;p&gt;The {fmt} library is maintained by Victor Zverovich (&lt;a href="https://github.com/vitaut"&gt;vitaut&lt;/a&gt;) with contributions from many other people. See &lt;a href="https://github.com/fmtlib/fmt/graphs/contributors"&gt;Contributors&lt;/a&gt; and &lt;a href="https://github.com/fmtlib/fmt/releases"&gt;Releases&lt;/a&gt; for some of the names. Let us know if your contribution is not listed or mentioned incorrectly and we'll make it right.&lt;/p&gt; 
&lt;h1&gt;Security Policy&lt;/h1&gt; 
&lt;p&gt;To report a security issue, please disclose it at &lt;a href="https://github.com/fmtlib/fmt/security/advisories/new"&gt;security advisory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is maintained by a team of volunteers on a reasonable-effort basis. As such, please give us at least &lt;em&gt;90&lt;/em&gt; days to work on a fix before public exposure.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LazyVim/LazyVim</title>
      <link>https://github.com/LazyVim/LazyVim</link>
      <description>&lt;p&gt;Neovim config for the lazy&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/292349/213446185-2db63fd5-8c84-459c-9f04-e286382d6e80.png" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://lazyvim.github.io/installation"&gt;Install&lt;/a&gt; · &lt;a href="https://lazyvim.github.io/configuration"&gt;Configure&lt;/a&gt; · &lt;a href="https://lazyvim.github.io"&gt;Docs&lt;/a&gt; &lt;/h4&gt; 
&lt;div align="center"&gt;
 &lt;p&gt; &lt;a href="https://github.com/LazyVim/LazyVim/releases/latest"&gt; &lt;img alt="Latest release" src="https://img.shields.io/github/v/release/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=C9CBFF&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41&amp;amp;include_prerelease&amp;amp;sort=semver" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/pulse"&gt; &lt;img alt="Last commit" src="https://img.shields.io/github/last-commit/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=8bd5ca&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/raw/main/LICENSE"&gt; &lt;img alt="License" src="https://img.shields.io/github/license/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=ee999f&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/stargazers"&gt; &lt;img alt="Stars" src="https://img.shields.io/github/stars/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=c69ff5&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/issues"&gt; &lt;img alt="Issues" src="https://img.shields.io/github/issues/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=bilibili&amp;amp;color=F5E0DC&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim"&gt; &lt;img alt="Repo Size" src="https://img.shields.io/github/repo-size/LazyVim/LazyVim?color=%23DDB6F2&amp;amp;label=SIZE&amp;amp;logo=codesandbox&amp;amp;style=for-the-badge&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=folke"&gt; &lt;img alt="follow on Twitter" src="https://img.shields.io/twitter/follow/folke?style=for-the-badge&amp;amp;logo=twitter&amp;amp;color=8aadf3&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;/p&gt;
&lt;/div&gt; 
&lt;p&gt;LazyVim is a Neovim setup powered by &lt;a href="https://github.com/folke/lazy.nvim"&gt;💤 lazy.nvim&lt;/a&gt; to make it easy to customize and extend your config. Rather than having to choose between starting from scratch or using a pre-made distro, LazyVim offers the best of both worlds - the flexibility to tweak your config as needed, along with the convenience of a pre-configured setup.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/292349/211285846-0b7bb3bf-0462-4029-b64c-4ee1d037fc1c.png" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/292349/213447056-92290767-ea16-430c-8727-ce994c93e9cc.png" alt="image" /&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🔥 Transform your Neovim into a full-fledged IDE&lt;/li&gt; 
 &lt;li&gt;💤 Easily customize and extend your config with &lt;a href="https://github.com/folke/lazy.nvim"&gt;lazy.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🚀 Blazingly fast&lt;/li&gt; 
 &lt;li&gt;🧹 Sane default settings for options, autocmds, and keymaps&lt;/li&gt; 
 &lt;li&gt;📦 Comes with a wealth of plugins pre-configured and ready to use&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;⚡️ Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neovim &amp;gt;= &lt;strong&gt;0.11.2&lt;/strong&gt; (needs to be built with &lt;strong&gt;LuaJIT&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;Git &amp;gt;= &lt;strong&gt;2.19.0&lt;/strong&gt; (for partial clones support)&lt;/li&gt; 
 &lt;li&gt;a &lt;a href="https://www.nerdfonts.com/"&gt;Nerd Font&lt;/a&gt; &lt;strong&gt;&lt;em&gt;(optional)&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;a &lt;strong&gt;C&lt;/strong&gt; compiler for &lt;code&gt;nvim-treesitter&lt;/code&gt;. See &lt;a href="https://github.com/nvim-treesitter/nvim-treesitter#requirements"&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;p&gt;You can find a starter template for &lt;strong&gt;LazyVim&lt;/strong&gt; &lt;a href="https://github.com/LazyVim/starter"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Try it with Docker&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;docker run -w /root -it --rm alpine:edge sh -uelic '
  apk add git lazygit fzf curl neovim ripgrep alpine-sdk --update
  git clone https://github.com/LazyVim/starter ~/.config/nvim
  cd ~/.config/nvim
  nvim
'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Install the &lt;a href="https://github.com/LazyVim/starter"&gt;LazyVim Starter&lt;/a&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Make a backup of your current Neovim files:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;mv ~/.config/nvim ~/.config/nvim.bak
mv ~/.local/share/nvim ~/.local/share/nvim.bak
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Clone the starter&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/LazyVim/starter ~/.config/nvim
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Remove the &lt;code&gt;.git&lt;/code&gt; folder, so you can add it to your own repo later&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;rm -rf ~/.config/nvim/.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Start Neovim!&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;nvim
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Refer to the comments in the files on how to customize &lt;strong&gt;LazyVim&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;p&gt;There's a great video created by &lt;a href="https://github.com/elijahmanor"&gt;@elijahmanor&lt;/a&gt; with a walkthrough to get started.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=N93cTbtLCIM"&gt;&lt;img src="https://img.youtube.com/vi/N93cTbtLCIM/hqdefault.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dusty-phillips"&gt;@dusty-phillips&lt;/a&gt; wrote a comprehensive book called &lt;a href="https://lazyvim-ambitious-devs.phillips.codes"&gt;LazyVim for Ambitious Developers&lt;/a&gt; available for free online.&lt;/p&gt; 
&lt;h2&gt;📂 File Structure&lt;/h2&gt; 
&lt;p&gt;The files under config will be automatically loaded at the appropriate time, so you don't need to require those files manually. &lt;strong&gt;LazyVim&lt;/strong&gt; comes with a set of default config files that will be loaded &lt;strong&gt;&lt;em&gt;before&lt;/em&gt;&lt;/strong&gt; your own. See &lt;a href="https://github.com/LazyVim/LazyVim/tree/main/lua/lazyvim/config"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can add your custom plugin specs under &lt;code&gt;lua/plugins/&lt;/code&gt;. All files there will be automatically loaded by &lt;a href="https://github.com/folke/lazy.nvim"&gt;lazy.nvim&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;
~/.config/nvim
├── lua
│&amp;nbsp;&amp;nbsp; ├── config
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; ├── autocmds.lua
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; ├── keymaps.lua
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; ├── lazy.lua
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; └── options.lua
│&amp;nbsp;&amp;nbsp; └── plugins
│&amp;nbsp;&amp;nbsp;     ├── spec1.lua
│&amp;nbsp;&amp;nbsp;     ├── **
│&amp;nbsp;&amp;nbsp;     └── spec2.lua
└── init.lua
&lt;/pre&gt; 
&lt;h2&gt;⚙️ Configuration&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://lazyvim.github.io"&gt;docs&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/markitdown</title>
      <link>https://github.com/microsoft/markitdown</link>
      <description>&lt;p&gt;Python tool for converting files and office documents to Markdown.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MarkItDown&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/markitdown/"&gt;&lt;img src="https://img.shields.io/pypi/v/markitdown.svg?sanitize=true" alt="PyPI" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/dd/markitdown" alt="PyPI - Downloads" /&gt; &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue" alt="Built by AutoGen Team" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See &lt;a href="https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp"&gt;markitdown-mcp&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Breaking changes between 0.0.1 to 0.1.0:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dependencies are now organized into optional feature-groups (further details below). Use &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt; to have backward-compatible behavior.&lt;/li&gt; 
  &lt;li&gt;convert_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.&lt;/li&gt; 
  &lt;li&gt;The DocumentConverter class interface has changed to read from file-like streams rather than file paths. &lt;em&gt;No temporary files are created anymore&lt;/em&gt;. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to &lt;a href="https://github.com/deanmalmgren/textract"&gt;textract&lt;/a&gt;, but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.&lt;/p&gt; 
&lt;p&gt;MarkItDown currently supports the conversion from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDF&lt;/li&gt; 
 &lt;li&gt;PowerPoint&lt;/li&gt; 
 &lt;li&gt;Word&lt;/li&gt; 
 &lt;li&gt;Excel&lt;/li&gt; 
 &lt;li&gt;Images (EXIF metadata and OCR)&lt;/li&gt; 
 &lt;li&gt;Audio (EXIF metadata and speech transcription)&lt;/li&gt; 
 &lt;li&gt;HTML&lt;/li&gt; 
 &lt;li&gt;Text-based formats (CSV, JSON, XML)&lt;/li&gt; 
 &lt;li&gt;ZIP files (iterates over contents)&lt;/li&gt; 
 &lt;li&gt;Youtube URLs&lt;/li&gt; 
 &lt;li&gt;EPubs&lt;/li&gt; 
 &lt;li&gt;... and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Markdown?&lt;/h2&gt; 
&lt;p&gt;Markdown is extremely close to plain text, with minimal markup or formatting, but still provides a way to represent important document structure. Mainstream LLMs, such as OpenAI's GPT-4o, natively "&lt;em&gt;speak&lt;/em&gt;" Markdown, and often incorporate Markdown into their responses unprompted. This suggests that they have been trained on vast amounts of Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions are also highly token-efficient.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;MarkItDown requires Python 3.10 or higher. It is recommended to use a virtual environment to avoid dependency conflicts.&lt;/p&gt; 
&lt;p&gt;With the standard Python installation, you can create and activate a virtual environment using the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If using &lt;code&gt;uv&lt;/code&gt;, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv --python=3.12 .venv
source .venv/bin/activate
# NOTE: Be sure to use 'uv pip install' rather than just 'pip install' to install packages in this virtual environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using Anaconda, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n markitdown python=3.12
conda activate markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install MarkItDown, use pip: &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt;. Alternatively, you can install it from the source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e 'packages/markitdown[all]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Command-Line&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf &amp;gt; document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;code&gt;-o&lt;/code&gt; to specify the output file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pipe content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat path-to-file.pdf | markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Dependencies&lt;/h3&gt; 
&lt;p&gt;MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the &lt;code&gt;[all]&lt;/code&gt; option. However, you can also install them individually for more control. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'markitdown[pdf, docx, pptx]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will install only the dependencies for PDF, DOCX, and PPTX files.&lt;/p&gt; 
&lt;p&gt;At the moment, the following optional dependencies are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[all]&lt;/code&gt; Installs all optional dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pptx]&lt;/code&gt; Installs dependencies for PowerPoint files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[docx]&lt;/code&gt; Installs dependencies for Word files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xlsx]&lt;/code&gt; Installs dependencies for Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xls]&lt;/code&gt; Installs dependencies for older Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pdf]&lt;/code&gt; Installs dependencies for PDF files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[outlook]&lt;/code&gt; Installs dependencies for Outlook messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[az-doc-intel]&lt;/code&gt; Installs dependencies for Azure Document Intelligence&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[audio-transcription]&lt;/code&gt; Installs dependencies for audio transcription of wav and mp3 files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[youtube-transcription]&lt;/code&gt; Installs dependencies for fetching YouTube video transcription&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Plugins&lt;/h3&gt; 
&lt;p&gt;MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --list-plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To enable plugins use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --use-plugins path-to-file.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find available plugins, search GitHub for the hashtag &lt;code&gt;#markitdown-plugin&lt;/code&gt;. To develop a plugin, see &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Azure Document Intelligence&lt;/h3&gt; 
&lt;p&gt;To use Microsoft Document Intelligence for conversion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md -d -e "&amp;lt;document_intelligence_endpoint&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More information about how to set up an Azure Document Intelligence Resource can be found &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Python API&lt;/h3&gt; 
&lt;p&gt;Basic usage in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert("test.xlsx")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Document Intelligence conversion in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint="&amp;lt;document_intelligence_endpoint&amp;gt;")
result = md.convert("test.pdf")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use Large Language Models for image descriptions (currently only for pptx and image files), provide &lt;code&gt;llm_client&lt;/code&gt; and &lt;code&gt;llm_model&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model="gpt-4o", llm_prompt="optional custom prompt")
result = md.convert("example.jpg")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &amp;lt; ~/your-file.pdf &amp;gt; output.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;p&gt;You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are of course just suggestions and you are welcome to contribute in any way you like.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;All&lt;/th&gt; 
    &lt;th&gt;Especially Needs Help from Community&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues"&gt;All Issues&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22"&gt;Issues open for contribution&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;PRs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls"&gt;All PRs&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22"&gt;PRs open for reviewing&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;Running Tests and Checks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to the MarkItDown package:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;cd packages/markitdown
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;code&gt;hatch&lt;/code&gt; in your environment and run tests:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
hatch shell
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(Alternative) Use the Devcontainer which has all the dependencies installed:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;# Reopen the project in Devcontainer and run:
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run pre-commit checks before submitting a PR: &lt;code&gt;pre-commit run --all-files&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing 3rd-party Plugins&lt;/h3&gt; 
&lt;p&gt;You can also contribute by creating and sharing 3rd party plugins. See &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>category-labs/monad</title>
      <link>https://github.com/category-labs/monad</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Monad Execution&lt;/h1&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository contains the execution component of a Monad node. It handles the transaction processing for new blocks, and keeps track of the state of the blockchain. Consequently, this repository contains the source code for Category Labs' custom &lt;a href="https://docs.monad.xyz/monad-arch/execution/native-compilation"&gt;EVM implementation&lt;/a&gt;, its &lt;a href="https://docs.monad.xyz/monad-arch/execution/monaddb"&gt;database implementation&lt;/a&gt;, and the high-level &lt;a href="https://docs.monad.xyz/monad-arch/execution/parallel-execution"&gt;transaction scheduling&lt;/a&gt;. The other main repository is &lt;a href="https://github.com/category-labs/monad-bft"&gt;monad-bft&lt;/a&gt;, which contains the source code for the consensus component.&lt;/p&gt; 
&lt;h2&gt;Building the source code&lt;/h2&gt; 
&lt;h3&gt;Package requirements&lt;/h3&gt; 
&lt;p&gt;Execution has two kinds of dependencies on third-party libraries:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self-managed&lt;/strong&gt;: execution's CMake build system will checkout most of its third-party dependencies as git submodules, and build them as part of its own build process, as CMake subprojects; this will happen automatically during the build, but you must run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;after checking out this repository.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System&lt;/strong&gt;: some dependencies are expected to already be part of the system in a default location, i.e., they are expected to come from the system's package manager. The primary development platform is Ubuntu, so the required packages use the Debian/Ubuntu package names; an up-to-date list of the required system dependencies can be found in the docker configuration file &lt;code&gt;docker/release.Dockerfile&lt;/code&gt; (you will need all the packages installed via the &lt;code&gt;apt install&lt;/code&gt; commands)&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Minimum development tool requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;gcc-15 or clang-19&lt;/li&gt; 
 &lt;li&gt;CMake 3.27&lt;/li&gt; 
 &lt;li&gt;Even when using clang, the only standard library supported is libstdc++; libc++ may work but it is not a tested platform&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;CPU compilation requirements&lt;/h3&gt; 
&lt;p&gt;As explained in the &lt;a href="https://docs.monad.xyz/monad-arch/hardware-requirements"&gt;hardware requirements&lt;/a&gt;, a Monad node requires a relatively recent CPU. Execution explicitly requires this to compile: it needs to emit machine code that is only supported on recent CPU models, for fast cryptographic operations.&lt;/p&gt; 
&lt;p&gt;The minimum ISA support corresponds to the &lt;a href="https://en.wikipedia.org/wiki/X86-64#Microarchitecture_levels"&gt;x86-64-v3&lt;/a&gt; feature level. Consequently, the minimum flag you must pass to the compiler is &lt;code&gt;-march=x86-64-v3&lt;/code&gt;, or alternatively &lt;code&gt;-march=haswell&lt;/code&gt; ("Haswell" was the codename of the first Intel CPU to support all of these features).&lt;/p&gt; 
&lt;p&gt;You may also pass any higher architecture level if you wish, although the compiled binary may not work on older CPUs. The execution docker files use &lt;code&gt;-march=haswell&lt;/code&gt; because it tries to maximize the number of systems the resulting binary can run on. If you are only running locally (i.e., the binary does not need to run anywhere else) use &lt;code&gt;-march=native&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling the execution code&lt;/h3&gt; 
&lt;p&gt;First, change your working directory to the root directory of the execution git repository root and then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;CC=gcc-15 CXX=g++-15 CFLAGS="-march=haswell" CXXFLAGS="-march=haswell" ASMFLAGS="-march=haswell" \
./scripts/configure.sh &amp;amp;&amp;amp; ./scripts/build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above command will do several things:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Use gcc-15 instead of the system's default compiler&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Emit machine code using Haswell-era CPU extensions&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run CMake, and generate a &lt;a href="https://ninja-build.org/"&gt;ninja&lt;/a&gt; build system in the &lt;code&gt;&amp;lt;path-to-execution-repo&amp;gt;/build&lt;/code&gt; directory with the &lt;a href="https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html"&gt;&lt;code&gt;CMAKE_BUILD_TYPE&lt;/code&gt;&lt;/a&gt; set to &lt;code&gt;RelWithDebInfo&lt;/code&gt; by default&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the CMake &lt;code&gt;all&lt;/code&gt; target, which builds everything&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The compiler and CPU options are injected via environment variables that are read by CMake. If you want debug binaries instead, you can also pass &lt;code&gt;CMAKE_BUILD_TYPE=Debug&lt;/code&gt; via the environment.&lt;/p&gt; 
&lt;p&gt;When finished, this will build all of the execution binaries. The main one is the execution daemon, &lt;code&gt;build/cmd/monad&lt;/code&gt;. This binary can provide block execution services for different EVM-compatible blockchains:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;When used as part of a Monad blockchain node, it behaves as the block execution service for the Category Labs consensus daemon (for details, see &lt;a href="https://raw.githubusercontent.com/category-labs/monad/main/docs/overview.md#how-is-execution-used"&gt;here&lt;/a&gt;); when running in this mode, Monad EVM extensions (e.g., Monad-style staking) are enabled&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;It can also replay the history of other EVM-compatible blockchains, by executing their historical blocks as inputs; a common developer workflow (and a good full system test) is to replay the history of the original Ethereum mainnet and verify that the computed Merkle roots match after each block&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can also run the full test suite in parallel with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CTEST_PARALLEL_LEVEL=$(nproc) ctest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;A tour of execution&lt;/h2&gt; 
&lt;p&gt;To understand how the source code is organized, you should start by reading the execution &lt;a href="https://raw.githubusercontent.com/category-labs/monad/main/docs/overview.md"&gt;developer overview&lt;/a&gt;, which explains how execution and consensus fit together, and where in the source tree you can find different pieces of functionality.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/AI-For-Beginners</title>
      <link>https://github.com/microsoft/AI-For-Beginners</link>
      <description>&lt;p&gt;12 Weeks, 24 Lessons, AI for All!&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/graphs/contributors/"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/issues/"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/pulls/"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub pull-requests" /&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/watchers/"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/network/"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://mybinder.org/v2/gh/microsoft/ai-for-beginners/HEAD"&gt;&lt;img src="https://mybinder.org/badge_logo.svg?sanitize=true" alt="Binder" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/Microsoft/ai-for-beginners?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge"&gt;&lt;img src="https://badges.gitter.im/Microsoft/ai-for-beginners.svg?sanitize=true" alt="Gitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/zxKYvhSnVp?WT.mc_id=academic-000002-leestott"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/ByRwuEEgH4" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Artificial Intelligence for Beginners - A Curriculum&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/sketchnotes/ai-overview.png" alt="Sketchnote by @girlie_mac https://twitter.com/girlie_mac" /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;AI For Beginners - &lt;em&gt;Sketchnote by &lt;a href="https://twitter.com/girlie_mac"&gt;@girlie_mac&lt;/a&gt;&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Explore the world of &lt;strong&gt;Artificial Intelligence&lt;/strong&gt; (AI) with our 12-week, 24-lesson curriculum! It includes practical lessons, quizzes, and labs. The curriculum is beginner-friendly and covers tools like TensorFlow and PyTorch, as well as ethics in AI&lt;/p&gt; 
&lt;h3&gt;🌐 Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If you wish to have additional translations languages supported are listed &lt;a href="https://github.com/Azure/co-op-translator/raw/main/getting_started/supported-languages.md"&gt;here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Join the Community&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/kzRShWzttr"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/kzRShWzttr" alt="Azure AI Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What you will learn&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="http://soshnikov.com/courses/ai-for-beginners/mindmap.html"&gt;Mindmap of the Course&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In this curriculum, you will learn:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Different approaches to Artificial Intelligence, including the "good old" symbolic approach with &lt;strong&gt;Knowledge Representation&lt;/strong&gt; and reasoning (&lt;a href="https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence"&gt;GOFAI&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Neural Networks&lt;/strong&gt; and &lt;strong&gt;Deep Learning&lt;/strong&gt;, which are at the core of modern AI. We will illustrate the concepts behind these important topics using code in two of the most popular frameworks - &lt;a href="http://Tensorflow.org"&gt;TensorFlow&lt;/a&gt; and &lt;a href="http://pytorch.org"&gt;PyTorch&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Neural Architectures&lt;/strong&gt; for working with images and text. We will cover recent models but may be a bit lacking in the state-of-the-art.&lt;/li&gt; 
 &lt;li&gt;Less popular AI approaches, such as &lt;strong&gt;Genetic Algorithms&lt;/strong&gt; and &lt;strong&gt;Multi-Agent Systems&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;What we will not cover in this curriculum:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;Find all additional resources for this course in our Microsoft Learn collection&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Business cases of using &lt;strong&gt;AI in Business&lt;/strong&gt;. Consider taking &lt;a href="https://docs.microsoft.com/learn/paths/introduction-ai-for-business-users/?WT.mc_id=academic-77998-bethanycheum"&gt;Introduction to AI for business users&lt;/a&gt; learning path on Microsoft Learn, or &lt;a href="https://www.microsoft.com/ai/ai-business-school/?WT.mc_id=academic-77998-bethanycheum"&gt;AI Business School&lt;/a&gt;, developed in cooperation with &lt;a href="https://www.insead.edu/"&gt;INSEAD&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Classic Machine Learning&lt;/strong&gt;, which is well described in our &lt;a href="http://github.com/Microsoft/ML-for-Beginners"&gt;Machine Learning for Beginners Curriculum&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Practical AI applications built using &lt;strong&gt;&lt;a href="https://azure.microsoft.com/services/cognitive-services/?WT.mc_id=academic-77998-bethanycheum"&gt;Cognitive Services&lt;/a&gt;&lt;/strong&gt;. For this, we recommend that you start with modules Microsoft Learn for &lt;a href="https://docs.microsoft.com/learn/paths/create-computer-vision-solutions-azure-cognitive-services/?WT.mc_id=academic-77998-bethanycheum"&gt;vision&lt;/a&gt;, &lt;a href="https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77998-bethanycheum"&gt;natural language processing&lt;/a&gt;, &lt;strong&gt;&lt;a href="https://learn.microsoft.com/en-us/training/paths/develop-ai-solutions-azure-openai/?WT.mc_id=academic-77998-bethanycheum"&gt;Generative AI with Azure OpenAI Service&lt;/a&gt;&lt;/strong&gt; and others.&lt;/li&gt; 
 &lt;li&gt;Specific ML &lt;strong&gt;Cloud Frameworks&lt;/strong&gt;, such as &lt;a href="https://azure.microsoft.com/services/machine-learning/?WT.mc_id=academic-77998-bethanycheum"&gt;Azure Machine Learning&lt;/a&gt;, &lt;a href="https://learn.microsoft.com/en-us/training/paths/get-started-fabric/?WT.mc_id=academic-77998-bethanycheum"&gt;Microsoft Fabric&lt;/a&gt;, or &lt;a href="https://docs.microsoft.com/learn/paths/data-engineer-azure-databricks?WT.mc_id=academic-77998-bethanycheum"&gt;Azure Databricks&lt;/a&gt;. Consider using &lt;a href="https://docs.microsoft.com/learn/paths/build-ai-solutions-with-azure-ml-service/?WT.mc_id=academic-77998-bethanycheum"&gt;Build and operate machine learning solutions with Azure Machine Learning&lt;/a&gt; and &lt;a href="https://docs.microsoft.com/learn/paths/build-operate-machine-learning-solutions-azure-databricks/?WT.mc_id=academic-77998-bethanycheum"&gt;Build and Operate Machine Learning Solutions with Azure Databricks&lt;/a&gt; learning paths.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversational AI&lt;/strong&gt; and &lt;strong&gt;Chat Bots&lt;/strong&gt;. There is a separate &lt;a href="https://docs.microsoft.com/learn/paths/create-conversational-ai-solutions/?WT.mc_id=academic-77998-bethanycheum"&gt;Create conversational AI solutions&lt;/a&gt; learning path, and you can also refer to &lt;a href="https://soshnikov.com/azure/hello-bot-conversational-ai-on-microsoft-platform/"&gt;this blog post&lt;/a&gt; for more detail.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deep Mathematics&lt;/strong&gt; behind deep learning. For this, we would recommend &lt;a href="https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618"&gt;Deep Learning&lt;/a&gt; by Ian Goodfellow, Yoshua Bengio and Aaron Courville, which is also available online at &lt;a href="https://www.deeplearningbook.org/"&gt;https://www.deeplearningbook.org/&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a gentle introduction to &lt;em&gt;AI in the Cloud&lt;/em&gt; topics you may consider taking the &lt;a href="https://docs.microsoft.com/learn/paths/get-started-with-artificial-intelligence-on-azure/?WT.mc_id=academic-77998-bethanycheum"&gt;Get started with artificial intelligence on Azure&lt;/a&gt; Learning Path.&lt;/p&gt; 
&lt;h1&gt;Content&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;Lesson Link&lt;/th&gt; 
   &lt;th align="center"&gt;PyTorch/Keras/TensorFlow&lt;/th&gt; 
   &lt;th&gt;Lab&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;0&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/setup.md"&gt;Course Setup&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/how-to-run.md"&gt;Setup Your Development Environment&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;I&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/1-Intro/README.md"&gt;&lt;strong&gt;Introduction to AI&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;01&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/1-Intro/README.md"&gt;Introduction and History of AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;II&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Symbolic AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;02&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/README.md"&gt;Knowledge Representation and Expert Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/Animals.ipynb"&gt;Expert Systems&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/FamilyOntology.ipynb"&gt;Ontology&lt;/a&gt; /&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/MSConceptGraph.ipynb"&gt;Concept Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;III&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/README.md"&gt;&lt;strong&gt;Introduction to Neural Networks&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;03&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/README.md"&gt;Perceptron&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/Perceptron.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;04&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/README.md"&gt;Multi-Layered Perceptron and Creating our own Framework&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;05&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/README.md"&gt;Intro to Frameworks (PyTorch/TensorFlow) and Overfitting&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb"&gt;Keras&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;IV&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/README.md"&gt;&lt;strong&gt;Computer Vision&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.microsoft.com/learn/modules/intro-computer-vision-pytorch/?WT.mc_id=academic-77998-cacaste"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://docs.microsoft.com/learn/modules/intro-computer-vision-TensorFlow/?WT.mc_id=academic-77998-cacaste"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;Explore Computer Vision on Microsoft Azure&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;06&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/README.md"&gt;Intro to Computer Vision. OpenCV&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/OpenCV.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;07&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/README.md"&gt;Convolutional Neural Networks&lt;/a&gt; &amp;amp; &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md"&gt;CNN Architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/ConvNetsPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/ConvNetsTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;08&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/README.md"&gt;Pre-trained Networks and Transfer Learning&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md"&gt;Training Tricks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;09&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/README.md"&gt;Autoencoders and VAEs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;10&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/README.md"&gt;Generative Adversarial Networks &amp;amp; Artistic Style Transfer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/GANTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;11&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/README.md"&gt;Object Detection&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;12&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/README.md"&gt;Semantic Segmentation. U-Net&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationPytorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;V&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/README.md"&gt;&lt;strong&gt;Natural Language Processing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://docs.microsoft.com/learn/modules/intro-natural-language-processing-TensorFlow/?WT.mc_id=academic-77998-cacaste"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;Explore Natural Language Processing on Microsoft Azure&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;13&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/13-TextRep/README.md"&gt;Text Representation. Bow/TF-IDF&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/13-TextRep/TextRepresentationPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/13-TextRep/TextRepresentationTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;14&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/14-Embeddings/README.md"&gt;Semantic word embeddings. Word2Vec and GloVe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/14-Embeddings/EmbeddingsPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/14-Embeddings/EmbeddingsTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;15&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/README.md"&gt;Language Modeling. Training your own embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/15-LanguageModeling/CBoW-PyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/15-LanguageModeling/CBoW-TF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;16&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/16-RNN/README.md"&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/RNNPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/RNNTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;17&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/README.md"&gt;Generative Recurrent Networks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/17-GenerativeNetworks/GenerativePyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/17-GenerativeNetworks/GenerativeTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;18&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/18-Transformers/README.md"&gt;Transformers. BERT.&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/18-Transformers/TransformersPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/18-Transformers/TransformersTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;19&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/README.md"&gt;Named Entity Recognition&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/19-NER/NER-TF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;20&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/20-LangModels/README.md"&gt;Large Language Models, Prompt Programming and Few-Shot Tasks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/20-LangModels/GPT-PyTorch.ipynb"&gt;PyTorch&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;VI&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Other AI Techniques&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;21&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/21-GeneticAlgorithms/README.md"&gt;Genetic Algorithms&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/21-GeneticAlgorithms/Genetic.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;22&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/README.md"&gt;Deep Reinforcement Learning&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/CartPole-RL-PyTorch.ipynb"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/CartPole-RL-TF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;23&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/23-MultiagentSystems/README.md"&gt;Multi-Agent Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;VII&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;AI Ethics&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;24&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/7-Ethics/README.md"&gt;AI Ethics and Responsible AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.microsoft.com/learn/paths/responsible-ai-business-principles/?WT.mc_id=academic-77998-cacaste"&gt;Microsoft Learn: Responsible AI Principles&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;IX&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Extras&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;25&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/X-Extras/X1-MultiModal/README.md"&gt;Multi-Modal Networks, CLIP and VQGAN&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/X-Extras/X1-MultiModal/Clip.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Each lesson contains&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pre-reading material&lt;/li&gt; 
 &lt;li&gt;Executable Jupyter Notebooks, which are often specific to the framework (&lt;strong&gt;PyTorch&lt;/strong&gt; or &lt;strong&gt;TensorFlow&lt;/strong&gt;). The executable notebook also contains a lot of theoretical material, so to understand the topic you need to go through at least one version of the notebook (either PyTorch or TensorFlow).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Labs&lt;/strong&gt; available for some topics, which give you an opportunity to try applying the material you have learned to a specific problem.&lt;/li&gt; 
 &lt;li&gt;Some sections contain links to &lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;&lt;strong&gt;MS Learn&lt;/strong&gt;&lt;/a&gt; modules that cover related topics.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We have created a &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/setup.md"&gt;setup lesson&lt;/a&gt; to help you with setting up your development environment. - For Educators, we have created a &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/for-teachers.md"&gt;curricula setup lesson&lt;/a&gt; for you too!&lt;/li&gt; 
 &lt;li&gt;How to &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/how-to-run.md"&gt;Run the code in a VSCode or a Codepace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Follow these steps:&lt;/p&gt; 
&lt;p&gt;Fork the Repository: Click on the "Fork" button at the top-right corner of this page.&lt;/p&gt; 
&lt;p&gt;Clone the Repository: &lt;code&gt;git clone https://github.com/microsoft/AI-For-Beginners.git&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Don't forget to star (🌟) this repo to find it easier later.&lt;/p&gt; 
&lt;h2&gt;Meet other Learners&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://aka.ms/genai-discord?WT.mc_id=academic-105485-bethanycheum"&gt;official AI Discord server&lt;/a&gt; to meet and network with other learners taking this course and get support.&lt;/p&gt; 
&lt;p&gt;If you have product feedback or questions whilst building visit our &lt;a href="https://aka.ms/foundry/forum"&gt;Azure AI Foundry Developer Forum&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quizzes&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;A note about quizzes&lt;/strong&gt;: All quizzes are contained in the Quiz-app folder in etc\quiz-app, or &lt;a href="https://ff-quizzes.netlify.app/"&gt;Online Here&lt;/a&gt; They are linked from within the lessons the quiz app can be run locally or deployed to Azure; follow the instruction in the &lt;code&gt;quiz-app&lt;/code&gt; folder. They are gradually being localized.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Help Wanted&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? Raise an issue or create a pull request.&lt;/p&gt; 
&lt;h2&gt;Special Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;✍️ Primary Author:&lt;/strong&gt; &lt;a href="http://soshnikov.com"&gt;Dmitry Soshnikov&lt;/a&gt;, PhD&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔥 Editor:&lt;/strong&gt; &lt;a href="https://twitter.com/jenlooper"&gt;Jen Looper&lt;/a&gt;, PhD&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎨 Sketchnote illustrator:&lt;/strong&gt; &lt;a href="https://twitter.com/girlie_mac"&gt;Tomomi Imura&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;✅ Quiz Creator:&lt;/strong&gt; &lt;a href="https://github.com/CinnamonXI"&gt;Lateefah Bello&lt;/a&gt;, &lt;a href="https://studentambassadors.microsoft.com/"&gt;MLSA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🙏 Core Contributors:&lt;/strong&gt; &lt;a href="https://github.com/Pe4enIks"&gt;Evgenii Pishchik&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other Curricula&lt;/h2&gt; 
&lt;p&gt;Our team produces other curricula! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/genai-beginners"&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet"&gt;Generative AI for Beginners .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-with-javascript"&gt;Generative AI with JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-java"&gt;Generative AI with Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming"&gt;Mastering GitHub Copilot for Agentic use&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>virattt/ai-hedge-fund</title>
      <link>https://github.com/virattt/ai-hedge-fund</link>
      <description>&lt;p&gt;An AI Hedge Fund Team&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Hedge Fund&lt;/h1&gt; 
&lt;p&gt;This is a proof of concept for an AI-powered hedge fund. The goal of this project is to explore the use of AI to make trading decisions. This project is for &lt;strong&gt;educational&lt;/strong&gt; purposes only and is not intended for real trading or investment.&lt;/p&gt; 
&lt;p&gt;This system employs several agents working together:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation&lt;/li&gt; 
 &lt;li&gt;Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety&lt;/li&gt; 
 &lt;li&gt;Bill Ackman Agent - An activist investor, takes bold positions and pushes for change&lt;/li&gt; 
 &lt;li&gt;Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption&lt;/li&gt; 
 &lt;li&gt;Charlie Munger Agent - Warren Buffett's partner, only buys wonderful businesses at fair prices&lt;/li&gt; 
 &lt;li&gt;Michael Burry Agent - The Big Short contrarian who hunts for deep value&lt;/li&gt; 
 &lt;li&gt;Mohnish Pabrai Agent - The Dhandho investor, who looks for doubles at low risk&lt;/li&gt; 
 &lt;li&gt;Peter Lynch Agent - Practical investor who seeks "ten-baggers" in everyday businesses&lt;/li&gt; 
 &lt;li&gt;Phil Fisher Agent - Meticulous growth investor who uses deep "scuttlebutt" research&lt;/li&gt; 
 &lt;li&gt;Rakesh Jhunjhunwala Agent - The Big Bull of India&lt;/li&gt; 
 &lt;li&gt;Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential&lt;/li&gt; 
 &lt;li&gt;Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price&lt;/li&gt; 
 &lt;li&gt;Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Sentiment Agent - Analyzes market sentiment and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Fundamentals Agent - Analyzes fundamental data and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Technicals Agent - Analyzes technical indicators and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Risk Manager - Calculates risk metrics and sets position limits&lt;/li&gt; 
 &lt;li&gt;Portfolio Manager - Makes final trading decisions and generates orders&lt;/li&gt; 
&lt;/ol&gt; 
&lt;img width="1042" alt="Screenshot 2025-03-22 at 6 19 07 PM" src="https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4" /&gt; 
&lt;p&gt;Note: the system does not actually make any trades.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/virattt"&gt;&lt;img src="https://img.shields.io/twitter/follow/virattt?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for &lt;strong&gt;educational and research purposes only&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not intended for real trading or investment&lt;/li&gt; 
 &lt;li&gt;No investment advice or guarantees provided&lt;/li&gt; 
 &lt;li&gt;Creator assumes no liability for financial losses&lt;/li&gt; 
 &lt;li&gt;Consult a financial advisor for investment decisions&lt;/li&gt; 
 &lt;li&gt;Past performance does not indicate future results&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to use it solely for learning purposes.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-install"&gt;How to Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-run"&gt;How to Run&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-command-line-interface"&gt;⌨️ Command Line Interface&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-web-application"&gt;🖥️ Web Application&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-contribute"&gt;How to Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#feature-requests"&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;Before you can run the AI Hedge Fund, you'll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.&lt;/p&gt; 
&lt;h3&gt;1. Clone the Repository&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set up API keys&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file for your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create .env file for your API keys (in the root directory)
cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open and edit the &lt;code&gt;.env&lt;/code&gt; file to add your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: You must set at least one LLM API key (e.g. &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;GROQ_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, or &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt;) for the hedge fund to work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Financial Data&lt;/strong&gt;: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the &lt;code&gt;FINANCIAL_DATASETS_API_KEY&lt;/code&gt; in the .env file.&lt;/p&gt; 
&lt;h2&gt;How to Run&lt;/h2&gt; 
&lt;h3&gt;⌨️ Command Line Interface&lt;/h3&gt; 
&lt;p&gt;You can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.&lt;/p&gt; 
&lt;img width="992" alt="Screenshot 2025-01-06 at 5 50 17 PM" src="https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b" /&gt; 
&lt;h4&gt;Quick Start&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Poetry (if not already installed):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://install.python-poetry.org | python3 -
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the AI Hedge Fund&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;--ollama&lt;/code&gt; flag to run the AI hedge fund using local LLMs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can optionally specify the start and end dates to make decisions over a specific time period.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the Backtester&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt; &lt;img width="941" alt="Screenshot 2025-01-06 at 5 47 52 PM" src="https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47" /&gt;&lt;/p&gt; 
&lt;p&gt;Note: The &lt;code&gt;--ollama&lt;/code&gt;, &lt;code&gt;--start-date&lt;/code&gt;, and &lt;code&gt;--end-date&lt;/code&gt; flags work for the backtester, as well!&lt;/p&gt; 
&lt;h3&gt;🖥️ Web Application&lt;/h3&gt; 
&lt;p&gt;The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. This is recommended for users who prefer visual interfaces over command line tools.&lt;/p&gt; 
&lt;p&gt;Please see detailed instructions on how to install and run the web application &lt;a href="https://github.com/virattt/ai-hedge-fund/tree/main/app"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;img width="1721" alt="Screenshot 2025-06-28 at 6 41 03 PM" src="https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b" /&gt; 
&lt;h2&gt;How to Contribute&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Commit your changes&lt;/li&gt; 
 &lt;li&gt;Push to the branch&lt;/li&gt; 
 &lt;li&gt;Create a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Please keep your pull requests small and focused. This will make it easier to review and merge.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;If you have a feature request, please open an &lt;a href="https://github.com/virattt/ai-hedge-fund/issues"&gt;issue&lt;/a&gt; and make sure it is tagged with &lt;code&gt;enhancement&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nocodb/nocodb</title>
      <link>https://github.com/nocodb/nocodb</link>
      <description>&lt;p&gt;🔥 🔥 🔥 Open Source Airtable Alternative&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center" style="border-bottom: none"&gt; 
 &lt;div&gt; 
  &lt;a style="color:#36f" href="https://www.nocodb.com"&gt; &lt;img src="https://raw.githubusercontent.com/nocodb/nocodb/develop/packages/nc-gui/assets/img/brand/nocodb-full.png" height="80" /&gt; &lt;br /&gt; The Open Source Airtable Alternative &lt;/a&gt; 
  &lt;br /&gt; 
 &lt;/div&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; NocoDB is the fastest and easiest way to build databases online. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="http://www.nocodb.com"&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; • &lt;a href="https://discord.gg/5RgZmkW"&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; • &lt;a href="https://community.nocodb.com/"&gt;&lt;b&gt;Community&lt;/b&gt;&lt;/a&gt; • &lt;a href="https://twitter.com/nocodb"&gt;&lt;b&gt;Twitter&lt;/b&gt;&lt;/a&gt; • &lt;a href="https://www.reddit.com/r/NocoDB/"&gt;&lt;b&gt;Reddit&lt;/b&gt;&lt;/a&gt; • &lt;a href="https://docs.nocodb.com/"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nocodb/nocodb/assets/86527202/e2fad786-f211-4dcb-9bd3-aaece83a6783" alt="video avi" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/chinese.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263434-75fe793d-42af-49e4-b964-d70920e41655.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/french.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263474-787d71e7-3a87-42a8-92a8-be1d1f55413d.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/german.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263531-fae58600-6616-4b43-95a0-5891019dd35d.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/spanish.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263589-3dbeda9a-0d2e-4bbd-b1fc-691404bb74fb.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/portuguese.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263669-f567196a-d4e8-4143-a80a-93d3be32ba90.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/italian.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263707-ba4e04a4-268a-4626-91b8-048e572fd9f6.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/japanese.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263770-38e3e79d-11d4-472e-ac27-ae0f17cf65c4.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/korean.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263822-28fce9de-915a-44dc-962d-7a61d340e91d.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/russian.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263888-151d4ad1-7084-4943-97c9-56f28cd40b80.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt;&lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/README.md"&gt;&lt;b&gt;See other languages »&lt;/b&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://static.scarf.sh/a.png?x-pxid=c12a77cc-855e-4602-8a0f-614b2d0da56a" /&gt; 
&lt;h1&gt;Join Our Community&lt;/h1&gt; 
&lt;a href="https://discord.gg/5RgZmkW" target="_blank"&gt; &lt;img src="https://discordapp.com/api/guilds/661905455894888490/widget.png?style=banner3" alt="" /&gt; &lt;/a&gt; 
&lt;p&gt;&lt;a href="https://github.com/nocodb/nocodb/stargazers"&gt;&lt;img src="http://reporoster.com/stars/nocodb/nocodb" alt="Stargazers repo roster for @nocodb/nocodb" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;h2&gt;Docker with SQLite&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name noco \
  -v "$(pwd)"/nocodb:/usr/app/data/ \
  -p 8080:8080 \
  nocodb/nocodb:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker with PG&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name noco \
  -v "$(pwd)"/nocodb:/usr/app/data/ \
  -p 8080:8080 \
  -e NC_DB="pg://host.docker.internal:5432?u=root&amp;amp;p=password&amp;amp;d=d1" \
  -e NC_AUTH_JWT_SECRET="569a1821-0a93-45e8-87ab-eb857f20a010" \
  nocodb/nocodb:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Auto-upstall&lt;/h2&gt; 
&lt;p&gt;Auto-upstall is a single command that sets up NocoDB on a server for production usage. Behind the scenes it auto-generates docker-compose for you.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash &amp;lt;(curl -sSL http://install.nocodb.com/noco.sh) &amp;lt;(mktemp)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Auto-upstall does the following: 🕊&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🐳 Automatically installs all pre-requisites like docker, docker-compose&lt;/li&gt; 
 &lt;li&gt;🚀 Automatically installs NocoDB with PostgreSQL, Redis, Minio, Traefik gateway using Docker Compose. 🐘 🗄️ 🌐&lt;/li&gt; 
 &lt;li&gt;🔄 Automatically upgrades NocoDB to the latest version when you run the command again.&lt;/li&gt; 
 &lt;li&gt;🔒 Automatically setups SSL and also renews it. Needs a domain or subdomain as input while installation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;install.nocodb.com/noco.sh script can be found &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/docker-compose/1_Auto_Upstall/noco.sh"&gt;here in our github&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Other Methods&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Binaries are only for quick testing locally.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Install Method&lt;/th&gt; 
   &lt;th&gt;Command to install&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🍏 MacOS arm64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/macos-arm64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🍏 MacOS x64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/macos-x64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🐧 Linux arm64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/linux-arm64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🐧 Linux x64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/linux-x64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🪟 Windows arm64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;iwr http://get.nocodb.com/win-arm64.exe -OutFile Noco-win-arm64.exe &amp;amp;&amp;amp; .\Noco-win-arm64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🪟 Windows x64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;iwr http://get.nocodb.com/win-x64.exe -OutFile Noco-win-x64.exe &amp;amp;&amp;amp; .\Noco-win-x64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;When running locally access nocodb by visiting: &lt;a href="http://localhost:8080/dashboard"&gt;http://localhost:8080/dashboard&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more installation methods, please refer to &lt;a href="https://docs.nocodb.com/category/installation"&gt;our docs&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Screenshots&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/nocodb/nocodb/assets/86527202/a127c05e-2121-4af2-a342-128e0e2d0291" alt="2" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/674da952-8a06-4848-a0e8-a7b02d5f5c88" alt="3" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/cbc5152a-9caf-4f77-a8f7-92a9d06d025b" alt="4" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/dc75dfdc-c486-4f5a-a853-2a8f9e6b569a" alt="5" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/35857179/194844886-a17006e0-979d-493f-83c4-0e72f5a9b716.png" alt="5" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/be64e619-7295-43e2-aa95-cace4462b17f" alt="7" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/4538bf5a-371f-4ec1-a867-8197e5824286" alt="8" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/35857179/194844893-82d5e21b-ae61-41bd-9990-31ad659bf490.png" alt="8" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844897-cfd79946-e413-4c97-b16d-eb4d7678bb79.png" alt="9" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844902-c0122570-0dd5-41cf-a26f-6f8d71fefc99.png" alt="10" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844903-c1e47f40-e782-4f5d-8dce-6449cc70b181.png" alt="11" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844907-09277d3e-cbbf-465c-9165-6afc4161e279.png" alt="12" /&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h3&gt;Rich Spreadsheet Interface&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡ &amp;nbsp;Basic Operations: Create, Read, Update and Delete Tables, Columns, and Rows&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;Fields Operations: Sort, Filter, Group, Hide / Unhide Columns&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;Multiple Views Types: Grid (By default), Gallery, Form, Kanban and Calendar View&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;View Permissions Types: Collaborative Views, &amp;amp; Locked Views&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;Share Bases / Views: either Public or Private (with Password Protected)&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;Variant Cell Types: ID, Links, Lookup, Rollup, SingleLineText, Attachment, Currency, Formula, User, etc&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;Access Control with Roles: Fine-grained Access Control at different levels&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;and more ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;App Store for Workflow Automations&lt;/h3&gt; 
&lt;p&gt;We provide different integrations in three main categories. See &lt;a href="https://docs.nocodb.com/account-settings/oss-specific-details/#app-store" target="_blank"&gt;App Store&lt;/a&gt; for details.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡ &amp;nbsp;Chat: Slack, Discord, Mattermost, and etc&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;Email: AWS SES, SMTP, MailerSend, and etc&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;Storage: AWS S3, Google Cloud Storage, Minio, and etc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Programmatic Access&lt;/h3&gt; 
&lt;p&gt;We provide the following ways to let users programmatically invoke actions. You can use a token (either JWT or Social Auth) to sign your requests for authorization to NocoDB.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡ &amp;nbsp;REST APIs&lt;/li&gt; 
 &lt;li&gt;⚡ &amp;nbsp;NocoDB SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Please refer to &lt;a href="https://github.com/nocodb/nocodb/raw/master/.github/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Why are we building this?&lt;/h1&gt; 
&lt;p&gt;Most internet businesses equip themselves with either spreadsheet or a database to solve their business needs. Spreadsheets are used by Billion+ humans collaboratively every single day. However, we are way off working at similar speeds on databases which are way more powerful tools when it comes to computing. Attempts to solve this with SaaS offerings have meant horrible access controls, vendor lock-in, data lock-in, abrupt price changes &amp;amp; most importantly a glass ceiling on what's possible in the future.&lt;/p&gt; 
&lt;h1&gt;Our Mission&lt;/h1&gt; 
&lt;p&gt;Our mission is to provide the most powerful no-code interface for databases that is open source to every single internet business in the world. This would not only democratise access to a powerful computing tool but also bring forth a billion+ people who will have radical tinkering-and-building abilities on the internet.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt; This project is licensed under &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/LICENSE"&gt;AGPLv3&lt;/a&gt;. &lt;/p&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;p&gt;Thank you for your contributions! We appreciate all the contributions from the community.&lt;/p&gt; 
&lt;a href="https://github.com/nocodb/nocodb/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=nocodb/nocodb" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>Alibaba-NLP/DeepResearch</title>
      <link>https://github.com/Alibaba-NLP/DeepResearch</link>
      <description>&lt;p&gt;Tongyi Deep Research, the Leading Open-source Deep Research Agent&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/logo.png" width="100%" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="line-height: 1;"&gt; 
 &lt;p&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B"&gt;&lt;img src="https://img.shields.io/badge/Models-5EDDD2?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="MODELS" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Alibaba-NLP/DeepResearch"&gt;&lt;img src="https://img.shields.io/badge/Github-24292F?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GITHUB" /&gt;&lt;/a&gt; &lt;a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/"&gt;&lt;img src="https://img.shields.io/badge/Blog-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="Blog" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; 🤗 &lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B" target="_blank"&gt;HuggingFace&lt;/a&gt; ｜ &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B" target="_blank"&gt;ModelScope&lt;/a&gt; | 💬 &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/wechat.jpg"&gt;WeChat(微信)&lt;/a&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14895" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14895" alt="Alibaba-NLP%2FDeepResearch | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;👏 Welcome to try Tongyi DeepResearch via our &lt;strong&gt;&lt;a href="https://www.modelscope.cn/studios/jialongwu/Tongyi-DeepResearch"&gt;&lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; Modelscope online demo&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href="https://huggingface.co/spaces/Alibaba-NLP/Tongyi-DeepResearch"&gt;🤗 Huggingface online demo&lt;/a&gt;&lt;/strong&gt; or &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/WebAgent/assets/aliyun.png" width="14px" style="display:inline;" /&gt; &lt;strong&gt;&lt;a href="https://bailian.console.aliyun.com/?spm=a2ty02.31808181.d_app-market.1.6c4974a1tFmoFc&amp;amp;tab=app#/app/app-market/deep-search/"&gt;bailian service&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This demo is for quick exploration only. Response times may vary or fail intermittently due to model latency and tool QPS limits. For a stable experience we recommend local deployment; for a production-ready service, visit &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/WebAgent/assets/aliyun.png" width="14px" style="display:inline;" /&gt; &lt;a href="https://bailian.console.aliyun.com/?spm=a2ty02.31808181.d_app-market.1.6c4974a1tFmoFc&amp;amp;tab=app#/app/app-market/deep-search/"&gt;bailian&lt;/a&gt; and follow the guided setup.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;We present &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;strong&gt;Tongyi DeepResearch&lt;/strong&gt;, an agentic large language model featuring 30.5 billion total parameters, with only 3.3 billion activated per token. Developed by Tongyi Lab, the model is specifically designed for &lt;strong&gt;long-horizon, deep information-seeking&lt;/strong&gt; tasks. Tongyi DeepResearch demonstrates state-of-the-art performance across a range of agentic search benchmarks, including Humanity's Last Exam, BrowserComp, BrowserComp-ZH, WebWalkerQA,xbench-DeepSearch, FRAMES and SimpleQA.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tongyi DeepResearch builds upon our previous work on the &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/WebAgent/"&gt;WebAgent&lt;/a&gt; project.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;More details can be found in our 📰&amp;nbsp;&lt;a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/"&gt;Tech Blog&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/performance.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚙️ &lt;strong&gt;Fully automated synthetic data generation pipeline&lt;/strong&gt;: We design a highly scalable data synthesis pipeline, which is fully automatic and empowers agentic pre-training, supervised fine-tuning, and reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Large-scale continual pre-training on agentic data&lt;/strong&gt;: Leveraging diverse, high-quality agentic interaction data to extend model capabilities, maintain freshness, and strengthen reasoning performance.&lt;/li&gt; 
 &lt;li&gt;🔁 &lt;strong&gt;End-to-end reinforcement learning&lt;/strong&gt;: We employ a strictly on-policy RL approach based on a customized Group Relative Policy Optimization framework, with token-level policy gradients, leave-one-out advantage estimation, and selective filtering of negative samples to stabilize training in a non‑stationary environment.&lt;/li&gt; 
 &lt;li&gt;🤖 &lt;strong&gt;Agent Inference Paradigm Compatibility&lt;/strong&gt;: At inference, Tongyi DeepResearch is compatible with two inference paradigms: ReAct, for rigorously evaluating the model's core intrinsic abilities, and an IterResearch-based 'Heavy' mode, which uses a test-time scaling strategy to unlock the model's maximum performance ceiling.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Model Download&lt;/h1&gt; 
&lt;p&gt;You can directly download the model by following the links below.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Download Links&lt;/th&gt; 
   &lt;th align="center"&gt;Model Size&lt;/th&gt; 
   &lt;th align="center"&gt;Context Length&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Tongyi-DeepResearch-30B-A3B&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B"&gt;🤗 HuggingFace&lt;/a&gt;&lt;br /&gt; &lt;a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B"&gt;🤖 ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;30B-A3B&lt;/td&gt; 
   &lt;td align="center"&gt;128K&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;News&lt;/h1&gt; 
&lt;p&gt;[2025/09/20]🚀 Tongyi-DeepResearch-30B-A3B is now on &lt;a href="https://openrouter.ai/alibaba/tongyi-deepresearch-30b-a3b"&gt;OpenRouter&lt;/a&gt;! Follow the &lt;a href="https://github.com/Alibaba-NLP/DeepResearch?tab=readme-ov-file#6-you-can-use-openrouters-api-to-call-our-model"&gt;Quick-start&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;[2025/09/17]🔥 We have released &lt;strong&gt;Tongyi-DeepResearch-30B-A3B&lt;/strong&gt;.&lt;/p&gt; 
&lt;h1&gt;Deep Research Benchmark Results&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/benchmark.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;This guide provides instructions for setting up the environment and running inference scripts located in the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/inference/"&gt;inference&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h3&gt;1. Environment Setup&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Recommended Python version: &lt;strong&gt;3.10.0&lt;/strong&gt; (using other versions may cause dependency issues).&lt;/li&gt; 
 &lt;li&gt;It is strongly advised to create an isolated environment using &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;virtualenv&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Example with Conda
conda create -n react_infer_env python=3.10.0
conda activate react_infer_env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install the required dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Environment Configuration and Prepare Evaluation Data&lt;/h3&gt; 
&lt;h4&gt;Environment Configuration&lt;/h4&gt; 
&lt;p&gt;Configure your API keys and settings by copying the example environment file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the example environment file
cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Edit the &lt;code&gt;.env&lt;/code&gt; file and provide your actual API keys and configuration values:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SERPER_KEY_ID&lt;/strong&gt;: Get your key from &lt;a href="https://serper.dev/"&gt;Serper.dev&lt;/a&gt; for web search and Google Scholar&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JINA_API_KEYS&lt;/strong&gt;: Get your key from &lt;a href="https://jina.ai/"&gt;Jina.ai&lt;/a&gt; for web page reading&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API_KEY/API_BASE&lt;/strong&gt;: OpenAI-compatible API for page summarization from &lt;a href="https://platform.openai.com/"&gt;OpenAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DASHSCOPE_API_KEY&lt;/strong&gt;: Get your key from &lt;a href="https://dashscope.aliyun.com/"&gt;Dashscope&lt;/a&gt; for file parsing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SANDBOX_FUSION_ENDPOINT&lt;/strong&gt;: Python interpreter sandbox endpoints (see &lt;a href="https://github.com/bytedance/SandboxFusion"&gt;SandboxFusion&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MODEL_PATH&lt;/strong&gt;: Path to your model weights&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DATASET&lt;/strong&gt;: Name of your evaluation dataset&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OUTPUT_PATH&lt;/strong&gt;: Directory for saving results&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;.env&lt;/code&gt; file is gitignored, so your secrets will not be committed to the repository.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Prepare Evaluation Data&lt;/h4&gt; 
&lt;p&gt;The system supports two input file formats: &lt;strong&gt;JSON&lt;/strong&gt; and &lt;strong&gt;JSONL&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Supported File Formats:&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: JSONL Format (recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create your data file with &lt;code&gt;.jsonl&lt;/code&gt; extension (e.g., &lt;code&gt;my_questions.jsonl&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Each line must be a valid JSON object with &lt;code&gt;question&lt;/code&gt; and &lt;code&gt;answer&lt;/code&gt; keys: &lt;pre&gt;&lt;code class="language-json"&gt;{"question": "What is the capital of France?", "answer": "Paris"}
{"question": "Explain quantum computing", "answer": ""}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: JSON Format&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create your data file with &lt;code&gt;.json&lt;/code&gt; extension (e.g., &lt;code&gt;my_questions.json&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;File must contain a JSON array of objects, each with &lt;code&gt;question&lt;/code&gt; and &lt;code&gt;answer&lt;/code&gt; keys: &lt;pre&gt;&lt;code class="language-json"&gt;[
  {"question": "What is the capital of France?", "answer": "Paris"},
  {"question": "Explain quantum computing", "answer": ""}
]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important Note:&lt;/strong&gt; The &lt;code&gt;answer&lt;/code&gt; field contains the &lt;strong&gt;ground truth/reference answer&lt;/strong&gt; used for evaluation. The system generates its own responses to the questions, and these reference answers are used to automatically judge the quality of the generated responses during benchmark evaluation.&lt;/p&gt; 
&lt;h4&gt;File References for Document Processing:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;If using the &lt;em&gt;file parser&lt;/em&gt; tool, &lt;strong&gt;prepend the filename to the &lt;code&gt;question&lt;/code&gt; field&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Place referenced files in &lt;code&gt;eval_data/file_corpus/&lt;/code&gt; directory&lt;/li&gt; 
 &lt;li&gt;Example: &lt;code&gt;{"question": "report.pdf What are the key findings?", "answer": "..."}&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;File Organization:&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;project_root/
├── eval_data/
│   ├── my_questions.jsonl          # Your evaluation data
│   └── file_corpus/                # Referenced documents
│       ├── report.pdf
│       └── data.xlsx
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. Configure the Inference Script&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open &lt;code&gt;run_react_infer.sh&lt;/code&gt; and modify the following variables as instructed in the comments: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;MODEL_PATH&lt;/code&gt; - path to the local or remote model weights.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;DATASET&lt;/code&gt; - full path to your evaluation file, e.g. &lt;code&gt;eval_data/my_questions.jsonl&lt;/code&gt; or &lt;code&gt;/path/to/my_questions.json&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OUTPUT_PATH&lt;/code&gt; - path for saving the prediction results, e.g. &lt;code&gt;./outputs&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Depending on the tools you enable (retrieval, calculator, web search, etc.), provide the required &lt;code&gt;API_KEY&lt;/code&gt;, &lt;code&gt;BASE_URL&lt;/code&gt;, or other credentials. Each key is explained inline in the bash script.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. Run the Inference Script&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash run_react_infer.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;With these steps, you can fully prepare the environment, configure the dataset, and run the model. For more details, consult the inline comments in each script or open an issue.&lt;/p&gt; 
&lt;h3&gt;6. You can use OpenRouter's API to call our model&lt;/h3&gt; 
&lt;p&gt;Tongyi-DeepResearch-30B-A3B is now available at &lt;a href="https://openrouter.ai/alibaba/tongyi-deepresearch-30b-a3b"&gt;OpenRouter&lt;/a&gt;. You can run the inference without any GPUs.&lt;/p&gt; 
&lt;p&gt;You need to modify the following in the file &lt;a href="https://github.com/Alibaba-NLP/DeepResearch/raw/main/inference/react_agent.py"&gt;inference/react_agent.py&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;In the call_server function: Set the API key and URL to your OpenRouter account’s API and URL.&lt;/li&gt; 
 &lt;li&gt;Change the model name to alibaba/tongyi-deepresearch-30b-a3b.&lt;/li&gt; 
 &lt;li&gt;Adjust the content concatenation way as described in the comments on lines &lt;strong&gt;88–90.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmark Evaluation&lt;/h2&gt; 
&lt;p&gt;We provide benchmark evaluation scripts for various datasets. Please refer to the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/evaluation/"&gt;evaluation scripts&lt;/a&gt; directory for more details.&lt;/p&gt; 
&lt;h2&gt;Deep Research Agent Family&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/family.png" /&gt; &lt;/p&gt; 
&lt;p&gt;Tongyi DeepResearch also has an extensive deep research agent family. You can find more information in the following paper:&lt;/p&gt; 
&lt;p&gt;[1] &lt;a href="https://arxiv.org/pdf/2501.07572"&gt;WebWalker: Benchmarking LLMs in Web Traversal&lt;/a&gt; (ACL 2025)&lt;br /&gt; [2] &lt;a href="https://arxiv.org/pdf/2505.22648"&gt;WebDancer: Towards Autonomous Information Seeking Agency&lt;/a&gt; (NeurIPS 2025)&lt;br /&gt; [3] &lt;a href="https://arxiv.org/pdf/2507.02592"&gt;WebSailor: Navigating Super-human Reasoning for Web Agent&lt;/a&gt;&lt;br /&gt; [4] &lt;a href="https://arxiv.org/pdf/2507.15061"&gt;WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization&lt;/a&gt;&lt;br /&gt; [5] &lt;a href="https://arxiv.org/pdf/2508.05748"&gt;WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent&lt;/a&gt;&lt;br /&gt; [6] &lt;a href="https://arxiv.org/pdf/2509.13309"&gt;WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents&lt;/a&gt;&lt;br /&gt; [7] &lt;a href="https://arxiv.org/pdf/2509.13313"&gt;ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization&lt;/a&gt;&lt;br /&gt; [8] &lt;a href="https://arxiv.org/pdf/2509.13312"&gt;WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research&lt;/a&gt;&lt;br /&gt; [9] &lt;a href="https://arxiv.org/pdf/2509.13305"&gt;WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning&lt;/a&gt;&lt;br /&gt; [10] &lt;a href="https://arxiv.org/pdf/2509.13310"&gt;Scaling Agents via Continual Pre-training&lt;/a&gt;&lt;br /&gt; [11] &lt;a href="https://arxiv.org/pdf/2509.13311"&gt;Towards General Agentic Intelligence via Environment Scaling&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🌟 Misc&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#Alibaba-NLP/DeepResearch&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Alibaba-NLP/DeepResearch&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🚩 Talent Recruitment&lt;/h2&gt; 
&lt;p&gt;🔥🔥🔥 We are hiring! Research intern positions are open (based in Hangzhou、Beijing、Shanghai)&lt;/p&gt; 
&lt;p&gt;📚 &lt;strong&gt;Research Area&lt;/strong&gt;：Web Agent, Search Agent, Agent RL, MultiAgent RL, Agentic RAG&lt;/p&gt; 
&lt;p&gt;☎️ &lt;strong&gt;Contact&lt;/strong&gt;：&lt;a href=""&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contact Information&lt;/h2&gt; 
&lt;p&gt;For communications, please contact Yong Jiang (&lt;a href="mailto:yongjiang.jy@alibaba-inc.com"&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{tongyidr,
  author={Tongyi DeepResearch Team},
  title={Tongyi-DeepResearch},
  year={2025},
  howpublished={\url{https://github.com/Alibaba-NLP/DeepResearch}}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>apple/container</title>
      <link>https://github.com/apple/container</link>
      <description>&lt;p&gt;A tool for creating and running Linux containers using lightweight virtual machines on a Mac. It is written in Swift, and optimized for Apple silicon.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;code&gt;container&lt;/code&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;container&lt;/code&gt; is a tool that you can use to create and run Linux containers as lightweight virtual machines on your Mac. It's written in Swift, and optimized for Apple silicon.&lt;/p&gt; 
&lt;p&gt;The tool consumes and produces &lt;a href="https://github.com/opencontainers/image-spec"&gt;OCI-compatible container images&lt;/a&gt;, so you can pull and run images from any standard container registry. You can push images that you build to those registries as well, and run the images in any other OCI-compatible application.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;container&lt;/code&gt; uses the &lt;a href="https://github.com/apple/containerization"&gt;Containerization&lt;/a&gt; Swift package for low level container, image, and process management.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apple/container/main/docs/assets/landing-movie.gif" alt="introductory movie showing some basic commands" /&gt;&lt;/p&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;You need a Mac with Apple silicon to run &lt;code&gt;container&lt;/code&gt;. To build it, see the &lt;a href="https://raw.githubusercontent.com/apple/container/main/BUILDING.md"&gt;BUILDING&lt;/a&gt; document.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;container&lt;/code&gt; is supported on macOS 26, since it takes advantage of new features and enhancements to virtualization and networking in this release. We do not support older versions of macOS and the &lt;code&gt;container&lt;/code&gt; maintainers typically will not address issues that cannot be reproduced on the latest macOS 26 beta.&lt;/p&gt; 
&lt;h3&gt;Install or upgrade&lt;/h3&gt; 
&lt;p&gt;If you're upgrading, first stop and uninstall your existing &lt;code&gt;container&lt;/code&gt; (the &lt;code&gt;-k&lt;/code&gt; flag keeps your user data, while &lt;code&gt;-d&lt;/code&gt; removes it):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;container system stop
uninstall-container.sh -k
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download the latest signed installer package for &lt;code&gt;container&lt;/code&gt; from the &lt;a href="https://github.com/apple/container/releases"&gt;GitHub release page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To install the tool, double-click the package file and follow the instructions. Enter your administrator password when prompted, to give the installer permission to place the installed files under &lt;code&gt;/usr/local&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Start the system service with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;container system start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Uninstall&lt;/h3&gt; 
&lt;p&gt;Use the &lt;code&gt;uninstall-container.sh&lt;/code&gt; script to remove &lt;code&gt;container&lt;/code&gt; from your system. To remove your user data along with the tool, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uninstall-container.sh -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To retain your user data so that it is available should you reinstall later, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uninstall-container.sh -k
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Next steps&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Take &lt;a href="https://raw.githubusercontent.com/apple/container/main/docs/tutorial.md"&gt;a guided tour of &lt;code&gt;container&lt;/code&gt;&lt;/a&gt; by building, running, and publishing a simple web server image.&lt;/li&gt; 
 &lt;li&gt;Learn how to &lt;a href="https://raw.githubusercontent.com/apple/container/main/docs/how-to.md"&gt;use various &lt;code&gt;container&lt;/code&gt; features&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Read a brief description and &lt;a href="https://raw.githubusercontent.com/apple/container/main/docs/technical-overview.md"&gt;technical overview&lt;/a&gt; of &lt;code&gt;container&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Browse the &lt;a href="https://raw.githubusercontent.com/apple/container/main/docs/command-reference.md"&gt;full command reference&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/apple/container/main/BUILDING.md"&gt;Build and run&lt;/a&gt; &lt;code&gt;container&lt;/code&gt; on your own development system.&lt;/li&gt; 
 &lt;li&gt;View the project &lt;a href="https://apple.github.io/container/documentation/"&gt;API documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The links above are for the CURRENT BRANCH's documentation. To find documentation for official releases, find the target release on the &lt;a href="https://github.com/apple/container/releases"&gt;Release Page&lt;/a&gt; and click the tag corresponding to your release version.&lt;/p&gt; 
 &lt;p&gt;Example: &lt;a href="https://github.com/apple/container/tree/0.4.1"&gt;release 0.4.1 tag&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions to &lt;code&gt;container&lt;/code&gt; are welcomed and encouraged. Please see our &lt;a href="https://github.com/apple/containerization/raw/main/CONTRIBUTING.md"&gt;main contributing guide&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Project Status&lt;/h2&gt; 
&lt;p&gt;The container project is currently under active development. Its stability, both for consuming the project as a Swift package and the &lt;code&gt;container&lt;/code&gt; tool, is only guaranteed within patch versions, such as between 0.1.1 and 0.1.2. Minor version number releases may include breaking changes until we achieve a 1.0.0 release.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ml-explore/mlx-swift-examples</title>
      <link>https://github.com/ml-explore/mlx-swift-examples</link>
      <description>&lt;p&gt;Examples using MLX Swift&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;Developers can use these examples in their own programs -- just import the swift package!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/mlxlmcommon/porting"&gt;Porting and implementing models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/mlxlmcommon"&gt;MLXLLMCommon&lt;/a&gt; -- common API for LLM and VLM&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/mlxllm"&gt;MLXLLM&lt;/a&gt; -- large language model example implementations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/mlxvlm"&gt;MLXVLM&lt;/a&gt; -- vision language model example implementations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/mlxembedders"&gt;MLXEmbedders&lt;/a&gt; -- popular Encoders / Embedding models example implementations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/stablediffusion"&gt;StableDiffusion&lt;/a&gt; -- SDXL Turbo and Stable Diffusion model example implementations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/mlxmnist"&gt;MLXMNIST&lt;/a&gt; -- MNIST implementation for all your digit recognition needs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;MLX Swift Examples&lt;/h1&gt; 
&lt;p&gt;Example &lt;a href="https://github.com/ml-explore/mlx-swift"&gt;MLX Swift&lt;/a&gt; programs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Applications/MNISTTrainer/README.md"&gt;MNISTTrainer&lt;/a&gt;: An example that runs on both iOS and macOS that downloads MNIST training data and trains a &lt;a href="https://en.wikipedia.org/wiki/LeNet"&gt;LeNet&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Applications/LLMEval/README.md"&gt;LLMEval&lt;/a&gt;: An example that runs on both iOS and macOS that downloads an LLM and tokenizer from Hugging Face and generates text from a given prompt.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Applications/VLMEval/README.md"&gt;VLMEval&lt;/a&gt;: An example that runs on iOS, macOS and visionOS to download a VLM and tokenizer from Hugging Face and analyzes the given image and describe it in text.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Applications/MLXChatExample/README.md"&gt;MLXChatExample&lt;/a&gt;: An example chat app that runs on both iOS and macOS that supports LLMs and VLMs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Tools/LinearModelTraining/README.md"&gt;LinearModelTraining&lt;/a&gt;: An example that trains a simple linear model.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Applications/StableDiffusionExample/README.md"&gt;StableDiffusionExample&lt;/a&gt;: An example that runs on both iOS and macOS that downloads a stable diffusion model from Hugging Face and and generates an image from a given prompt.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Tools/llm-tool/README.md"&gt;llm-tool&lt;/a&gt;: A command line tool for generating text using a variety of LLMs available on the Hugging Face hub.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Tools/ExampleLLM/README.md"&gt;ExampleLLM&lt;/a&gt;: A command line tool using the simplified API to interact with LLMs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Tools/image-tool/README.md"&gt;image-tool&lt;/a&gt;: A command line tool for generating images using a stable diffusion model from Hugging Face.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Tools/mnist-tool/README.md"&gt;mnist-tool&lt;/a&gt;: A command line tool for training a a LeNet on MNIST.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Interacting with LLMs&lt;/h2&gt; 
&lt;p&gt;See also &lt;a href="https://raw.githubusercontent.com/ml-explore/mlx-swift-examples/main/Libraries/MLXLMCommon"&gt;MLXLMCommon&lt;/a&gt;. You can easily use a wide variety of open weight LLM and VLMs in your code. You can use this simplified API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;let model = try await loadModel(id: "mlx-community/Qwen3-4B-4bit")
let session = ChatSession(model)
print(try await session.respond(to: "What are two things to see in San Francisco?")
print(try await session.respond(to: "How about a great place to eat?")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use the underlying API to control every aspect of the evaluation.&lt;/p&gt; 
&lt;h2&gt;Running&lt;/h2&gt; 
&lt;p&gt;The application and command line tool examples can be run from Xcode or from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./mlx-run llm-tool --prompt "swift programming language"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: &lt;code&gt;mlx-run&lt;/code&gt; is a shell script that uses &lt;code&gt;xcode&lt;/code&gt; command line tools to locate the built binaries. It is equivalent to running from Xcode itself.&lt;/p&gt; 
&lt;p&gt;See also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://swiftpackageindex.com/ml-explore/mlx-swift/main/documentation/mlx/troubleshooting"&gt;MLX troubleshooting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation of libraries&lt;/h2&gt; 
&lt;p&gt;The MLXLLM, MLXVLM, MLXLMCommon, MLXMNIST, MLXEmbedders, and StableDiffusion libraries in the example repo are available as Swift Packages.&lt;/p&gt; 
&lt;p&gt;Add the following dependency to your Package.swift&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;.package(url: "https://github.com/ml-explore/mlx-swift-examples/", branch: "main"),
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then add one or more libraries to the target as a dependency:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;.target(
    name: "YourTargetName",
    dependencies: [
        .product(name: "MLXLLM", package: "mlx-swift-examples")
    ]),
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, add &lt;code&gt;https://github.com/ml-explore/mlx-swift-examples/&lt;/code&gt; to the &lt;code&gt;Project Dependencies&lt;/code&gt; and set the &lt;code&gt;Dependency Rule&lt;/code&gt; to &lt;code&gt;Branch&lt;/code&gt; and &lt;code&gt;main&lt;/code&gt; in Xcode.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gin-gonic/gin</title>
      <link>https://github.com/gin-gonic/gin</link>
      <description>&lt;p&gt;Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performance—up to 40 times faster—thanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gin Web Framework&lt;/h1&gt; 
&lt;img align="right" width="159px" src="https://raw.githubusercontent.com/gin-gonic/logo/master/color.png" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/gin-gonic/gin/actions/workflows/gin.yml"&gt;&lt;img src="https://github.com/gin-gonic/gin/actions/workflows/gin.yml/badge.svg?branch=master" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/gin-gonic/gin"&gt;&lt;img src="https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/gin-gonic/gin"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gin-gonic/gin" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://sourcegraph.com/github.com/gin-gonic/gin?badge"&gt;&lt;img src="https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg?sanitize=true" alt="Sourcegraph" /&gt;&lt;/a&gt; &lt;a href="https://www.codetriage.com/gin-gonic/gin"&gt;&lt;img src="https://www.codetriage.com/gin-gonic/gin/badges/users.svg?sanitize=true" alt="Open Source Helpers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/gin-gonic/gin/releases"&gt;&lt;img src="https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square" alt="Release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📰 &lt;a href="https://gin-gonic.com/en/blog/news/gin-1-11-0-release-announcement/"&gt;Announcing Gin 1.11.0!&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Read about the latest features and improvements in Gin 1.11.0 on our official blog.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Gin is a high-performance HTTP web framework written in &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;. It provides a Martini-like API but with significantly better performance—up to 40 times faster—thanks to &lt;a href="https://github.com/julienschmidt/httprouter"&gt;httprouter&lt;/a&gt;. Gin is designed for building REST APIs, web applications, and microservices where speed and developer productivity are essential.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Gin?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Gin combines the simplicity of Express.js-style routing with Go's performance characteristics, making it ideal for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building high-throughput REST APIs&lt;/li&gt; 
 &lt;li&gt;Developing microservices that need to handle many concurrent requests&lt;/li&gt; 
 &lt;li&gt;Creating web applications that require fast response times&lt;/li&gt; 
 &lt;li&gt;Prototyping web services quickly with minimal boilerplate&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Gin's key features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero allocation router&lt;/strong&gt; - Extremely memory-efficient routing with no heap allocations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt; - Benchmarks show superior speed compared to other Go web frameworks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Middleware support&lt;/strong&gt; - Extensible middleware system for authentication, logging, CORS, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Crash-free&lt;/strong&gt; - Built-in recovery middleware prevents panics from crashing your server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON validation&lt;/strong&gt; - Automatic request/response JSON binding and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Route grouping&lt;/strong&gt; - Organize related routes and apply common middleware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error management&lt;/strong&gt; - Centralized error handling and logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in rendering&lt;/strong&gt; - Support for JSON, XML, HTML templates, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt; - Large ecosystem of community middleware and plugins&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Go version&lt;/strong&gt;: Gin requires &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt; version &lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt; or above&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic Go knowledge&lt;/strong&gt;: Familiarity with Go syntax and package management is helpful&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;With &lt;a href="https://go.dev/wiki/Modules#how-to-use-modules"&gt;Go's module support&lt;/a&gt;, simply import Gin in your code and Go will automatically fetch it during build:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "github.com/gin-gonic/gin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Your First Gin Application&lt;/h3&gt; 
&lt;p&gt;Here's a complete example that demonstrates Gin's simplicity:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "net/http"

  "github.com/gin-gonic/gin"
)

func main() {
  // Create a Gin router with default middleware (logger and recovery)
  r := gin.Default()
  
  // Define a simple GET endpoint
  r.GET("/ping", func(c *gin.Context) {
    // Return JSON response
    c.JSON(http.StatusOK, gin.H{
      "message": "pong",
    })
  })
  
  // Start server on port 8080 (default)
  // Server will listen on 0.0.0.0:8080 (localhost:8080 on Windows)
  r.Run()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Running the application:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Save the code above as &lt;code&gt;main.go&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the application:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;go run main.go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open your browser and visit &lt;a href="http://localhost:8080/ping"&gt;&lt;code&gt;http://localhost:8080/ping&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You should see: &lt;code&gt;{"message":"pong"}&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;What this example demonstrates:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creating a Gin router with default middleware&lt;/li&gt; 
 &lt;li&gt;Defining HTTP endpoints with simple handler functions&lt;/li&gt; 
 &lt;li&gt;Returning JSON responses&lt;/li&gt; 
 &lt;li&gt;Starting an HTTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next Steps&lt;/h3&gt; 
&lt;p&gt;After running your first Gin application, explore these resources to learn more:&lt;/p&gt; 
&lt;h4&gt;📚 Learning Resources&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/docs/doc.md"&gt;Gin Quick Start Guide&lt;/a&gt;&lt;/strong&gt; - Comprehensive tutorial with API examples and build configurations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/examples"&gt;Example Repository&lt;/a&gt;&lt;/strong&gt; - Ready-to-run examples demonstrating various Gin use cases: 
  &lt;ul&gt; 
   &lt;li&gt;REST API development&lt;/li&gt; 
   &lt;li&gt;Authentication &amp;amp; middleware&lt;/li&gt; 
   &lt;li&gt;File uploads and downloads&lt;/li&gt; 
   &lt;li&gt;WebSocket connections&lt;/li&gt; 
   &lt;li&gt;Template rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📖 Documentation&lt;/h2&gt; 
&lt;h3&gt;API Reference&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin"&gt;Go.dev API Documentation&lt;/a&gt;&lt;/strong&gt; - Complete API reference with examples&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guides&lt;/h3&gt; 
&lt;p&gt;The comprehensive documentation is available on &lt;a href="https://gin-gonic.com"&gt;gin-gonic.com&lt;/a&gt; in multiple languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/en/docs/"&gt;English&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-cn/docs/"&gt;简体中文&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-tw/docs/"&gt;繁體中文&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ja/docs/"&gt;日本語&lt;/a&gt; | &lt;a href="https://gin-gonic.com/ko-kr/docs/"&gt;한국어&lt;/a&gt; | &lt;a href="https://gin-gonic.com/es/docs/"&gt;Español&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/tr/docs/"&gt;Turkish&lt;/a&gt; | &lt;a href="https://gin-gonic.com/fa/docs/"&gt;Persian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/pt/docs/"&gt;Português&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ru/docs/"&gt;Russian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/id/docs/"&gt;Indonesian&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Official Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/tutorial/web-service-gin"&gt;Go.dev Tutorial: Developing a RESTful API with Go and Gin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;⚡ Performance Benchmarks&lt;/h2&gt; 
&lt;p&gt;Gin demonstrates exceptional performance compared to other Go web frameworks. It uses a custom version of &lt;a href="https://github.com/julienschmidt/httprouter"&gt;HttpRouter&lt;/a&gt; for maximum efficiency. &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/BENCHMARKS.md"&gt;View detailed benchmarks →&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gin vs. Other Go Frameworks&lt;/strong&gt; (GitHub API routing benchmark):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Benchmark name&lt;/th&gt; 
   &lt;th align="right"&gt;(1)&lt;/th&gt; 
   &lt;th align="right"&gt;(2)&lt;/th&gt; 
   &lt;th align="right"&gt;(3)&lt;/th&gt; 
   &lt;th align="right"&gt;(4)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGin_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;43550&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;27364 ns/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 B/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 allocs/op&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAce_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;40543&lt;/td&gt; 
   &lt;td align="right"&gt;29670 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAero_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;57632&lt;/td&gt; 
   &lt;td align="right"&gt;20648 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBear_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;9234&lt;/td&gt; 
   &lt;td align="right"&gt;216179 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;86448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;943 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBeego_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7407&lt;/td&gt; 
   &lt;td align="right"&gt;243496 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;71456 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBone_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;420&lt;/td&gt; 
   &lt;td align="right"&gt;2922835 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;720160 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;8620 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkChi_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7620&lt;/td&gt; 
   &lt;td align="right"&gt;238331 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;87696 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkDenco_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;18355&lt;/td&gt; 
   &lt;td align="right"&gt;64494 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;20224 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkEcho_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;31251&lt;/td&gt; 
   &lt;td align="right"&gt;38479 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGocraftWeb_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;4117&lt;/td&gt; 
   &lt;td align="right"&gt;300062 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;131656 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1686 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoji_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3274&lt;/td&gt; 
   &lt;td align="right"&gt;416158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;56112 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;334 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGojiv2_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;1402&lt;/td&gt; 
   &lt;td align="right"&gt;870518 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;352720 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4321 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoJsonRest_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2976&lt;/td&gt; 
   &lt;td align="right"&gt;401507 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;134371 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2737 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoRestful_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;410&lt;/td&gt; 
   &lt;td align="right"&gt;2913158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;910144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2938 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGorillaMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;346&lt;/td&gt; 
   &lt;td align="right"&gt;3384987 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;251650 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1994 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGowwwRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;143025 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;72144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;501 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;55938&lt;/td&gt; 
   &lt;td align="right"&gt;21360 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpTreeMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;153944 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;65856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;671 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkKocha_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;106315 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;23304 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;843 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkLARS_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;47779&lt;/td&gt; 
   &lt;td align="right"&gt;25084 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMacaron_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3266&lt;/td&gt; 
   &lt;td align="right"&gt;371907 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;149409 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1624 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMartini_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;331&lt;/td&gt; 
   &lt;td align="right"&gt;3444706 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;226551 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2325 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPat_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;273&lt;/td&gt; 
   &lt;td align="right"&gt;4381818 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;1483152 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;26963 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPossum_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;164367 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;84448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkR2router_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;160220 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;77328 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;979 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkRivet_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;14625&lt;/td&gt; 
   &lt;td align="right"&gt;82453 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;16272 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTango_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6255&lt;/td&gt; 
   &lt;td align="right"&gt;279611 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;63826 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1618 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTigerTonic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2008&lt;/td&gt; 
   &lt;td align="right"&gt;687874 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;193856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4474 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTraffic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;355&lt;/td&gt; 
   &lt;td align="right"&gt;3478508 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;820744 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;14114 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkVulcan_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6885&lt;/td&gt; 
   &lt;td align="right"&gt;193333 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;19894 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;(1): Total Repetitions achieved in constant time, higher means more confident result&lt;/li&gt; 
 &lt;li&gt;(2): Single Repetition Duration (ns/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(3): Heap Memory (B/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(4): Average Allocations per Repetition (allocs/op), lower is better&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔌 Middleware Ecosystem&lt;/h2&gt; 
&lt;p&gt;Gin has a rich ecosystem of middleware for common web development needs. Explore community-contributed middleware:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-contrib"&gt;gin-contrib&lt;/a&gt;&lt;/strong&gt; - Official middleware collection including:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Authentication (JWT, Basic Auth, Sessions)&lt;/li&gt; 
   &lt;li&gt;CORS, Rate limiting, Compression&lt;/li&gt; 
   &lt;li&gt;Logging, Metrics, Tracing&lt;/li&gt; 
   &lt;li&gt;Static file serving, Template engines&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/contrib"&gt;gin-gonic/contrib&lt;/a&gt;&lt;/strong&gt; - Additional community middleware&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🏢 Production Usage&lt;/h2&gt; 
&lt;p&gt;Gin powers many high-traffic applications and services in production:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/appleboy/gorush"&gt;gorush&lt;/a&gt;&lt;/strong&gt; - High-performance push notification server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/fnproject/fn"&gt;fnproject&lt;/a&gt;&lt;/strong&gt; - Container-native, serverless platform&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/photoprism/photoprism"&gt;photoprism&lt;/a&gt;&lt;/strong&gt; - AI-powered personal photo management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/luraproject/lura"&gt;lura&lt;/a&gt;&lt;/strong&gt; - Ultra-performant API Gateway framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/thoas/picfit"&gt;picfit&lt;/a&gt;&lt;/strong&gt; - Real-time image processing server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/distribworks/dkron"&gt;dkron&lt;/a&gt;&lt;/strong&gt; - Distributed job scheduling system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;Gin is the work of hundreds of contributors from around the world. We welcome and appreciate your contributions!&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;🐛 &lt;strong&gt;Report bugs&lt;/strong&gt; - Help us identify and fix issues&lt;/li&gt; 
 &lt;li&gt;💡 &lt;strong&gt;Suggest features&lt;/strong&gt; - Share your ideas for improvements&lt;/li&gt; 
 &lt;li&gt;📝 &lt;strong&gt;Improve documentation&lt;/strong&gt; - Help make our docs clearer&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;strong&gt;Submit code&lt;/strong&gt; - Fix bugs or implement new features&lt;/li&gt; 
 &lt;li&gt;🧪 &lt;strong&gt;Write tests&lt;/strong&gt; - Improve our test coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Contributing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for detailed guidelines&lt;/li&gt; 
 &lt;li&gt;Join our community discussions and ask questions&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;All contributions are valued and help make Gin better for everyone!&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>elastic/elasticsearch</title>
      <link>https://github.com/elastic/elasticsearch</link>
      <description>&lt;p&gt;Free and Open Source, Distributed, RESTful Search Engine&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>WebGoat/WebGoat</title>
      <link>https://github.com/WebGoat/WebGoat</link>
      <description>&lt;p&gt;WebGoat is a deliberately insecure application&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WebGoat: A deliberately insecure Web Application&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/WebGoat/WebGoat/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/WebGoat/WebGoat/actions/workflows/build.yml/badge.svg?branch=develop" alt="Build" /&gt;&lt;/a&gt; &lt;a href="https://jdk.java.net/"&gt;&lt;img src="https://img.shields.io/badge/java%20jdk-23-green.svg?sanitize=true" alt="java-jdk" /&gt;&lt;/a&gt; &lt;a href="https://owasp.org/projects/"&gt;&lt;img src="https://img.shields.io/badge/OWASP-Lab%20project-f7b73c.svg?sanitize=true" alt="OWASP Labs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/WebGoat/WebGoat/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/WebGoat/WebGoat.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/OWASPWebGoat/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge"&gt;&lt;img src="https://badges.gitter.im/OWASPWebGoat/community.svg?sanitize=true" alt="Gitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/WebGoat/WebGoat/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/WebGoat/WebGoat" alt="Discussions" /&gt;&lt;/a&gt; &lt;a href="https://conventionalcommits.org"&gt;&lt;img src="https://img.shields.io/badge/Conventional%20Commits-1.0.0-%23FE5196?logo=conventionalcommits&amp;amp;logoColor=white" alt="Conventional Commits" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;WebGoat is a deliberately insecure web application maintained by &lt;a href="http://www.owasp.org/"&gt;OWASP&lt;/a&gt; designed to teach web application security lessons.&lt;/p&gt; 
&lt;p&gt;This program is a demonstration of common server-side application flaws. The exercises are intended to be used by people to learn about application security and penetration testing techniques.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING 1:&lt;/strong&gt; &lt;em&gt;While running this program your machine will be extremely vulnerable to attack. You should disconnect from the Internet while using this program.&lt;/em&gt; WebGoat's default configuration binds to localhost to minimize the exposure.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING 2:&lt;/strong&gt; &lt;em&gt;This program is for educational purposes only. If you attempt these techniques without authorization, you are very likely to get caught. If you are caught engaging in unauthorized hacking, most companies will fire you. Claiming that you were doing security research will not work as that is the first thing that all hackers claim.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/WebGoat/WebGoat/main/docs/images/webgoat.png" alt="WebGoat" /&gt;&lt;/p&gt; 
&lt;h1&gt;Installation instructions:&lt;/h1&gt; 
&lt;p&gt;For more details check &lt;a href="https://raw.githubusercontent.com/WebGoat/WebGoat/main/CONTRIBUTING.md"&gt;the Contribution guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;1. Run using Docker&lt;/h2&gt; 
&lt;p&gt;Already have a browser and ZAP and/or Burp installed on your machine in this case you can run the WebGoat image directly using Docker.&lt;/p&gt; 
&lt;p&gt;Every release is also published on &lt;a href="https://hub.docker.com/r/webgoat/webgoat"&gt;DockerHub&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For some lessons you need the container run in the same timezone. For this you can set the TZ environment variable. E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e TZ=America/Boise webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to use OWASP ZAP or another proxy, you can no longer use 127.0.0.1 or localhost. but you can use custom host entries. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;127.0.0.1 www.webgoat.local www.webwolf.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the container with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e WEBGOAT_HOST=www.webgoat.local -e WEBWOLF_HOST=www.webwolf.local -e TZ=America/Boise webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;a href="http://www.webgoat.local:8080/WebGoat/"&gt;http://www.webgoat.local:8080/WebGoat/&lt;/a&gt; and &lt;a href="http://www.webwolf.local:9090/WebWolf/"&gt;http://www.webwolf.local:9090/WebWolf/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;2. Run using Docker with complete Linux Desktop&lt;/h2&gt; 
&lt;p&gt;Instead of installing tools locally we have a complete Docker image based on running a desktop in your browser. This way you only have to run a Docker image which will give you the best user experience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -p 127.0.0.1:3000:3000 webgoat/webgoat-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Standalone&lt;/h2&gt; 
&lt;p&gt;Download the latest WebGoat release from &lt;a href="https://github.com/WebGoat/WebGoat/releases"&gt;https://github.com/WebGoat/WebGoat/releases&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export TZ=Europe/Amsterdam # or your timezone
java -Dfile.encoding=UTF-8 -jar webgoat-2023.8.jar
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Click the link in the log to start WebGoat.&lt;/p&gt; 
&lt;h3&gt;3.1 Running on a different port&lt;/h3&gt; 
&lt;p&gt;If for some reason you want to run WebGoat on a different port, you can do so by adding the following parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;java -jar webgoat-2023.8.jar --webgoat.port=8001 --webwolf.port=8002
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a full overview of all the parameters you can use, please check the [WebGoat properties file](webgoat-container/src/main/resources/application-{webgoat, webwolf}.properties).&lt;/p&gt; 
&lt;h2&gt;4. Run from the sources&lt;/h2&gt; 
&lt;h3&gt;Prerequisites:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Java 23&lt;/li&gt; 
 &lt;li&gt;Your favorite IDE&lt;/li&gt; 
 &lt;li&gt;Git, or Git support in your IDE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Open a command shell/window:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;git clone git@github.com:WebGoat/WebGoat.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now let's start by compiling the project.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;cd WebGoat
git checkout &amp;lt;&amp;lt;branch_name&amp;gt;&amp;gt;
# On Linux/Mac:
./mvnw clean install

# On Windows:
./mvnw.cmd clean install

# Using docker or podman, you can than build the container locally
docker build -f Dockerfile . -t webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now we are ready to run the project. WebGoat is using Spring Boot.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;# On Linux/Mac:
./mvnw spring-boot:run
# On Windows:
./mvnw.cmd spring-boot:run

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;... you should be running WebGoat on &lt;a href="http://localhost:8080/WebGoat"&gt;http://localhost:8080/WebGoat&lt;/a&gt; momentarily.&lt;/p&gt; 
&lt;p&gt;Note: The above link will redirect you to login page if you are not logged in. LogIn/Create account to proceed.&lt;/p&gt; 
&lt;p&gt;To change the IP address add the following variable to the &lt;code&gt;WebGoat/webgoat-container/src/main/resources/application.properties&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;server.address=x.x.x.x
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Run with custom menu&lt;/h2&gt; 
&lt;p&gt;For specialist only. There is a way to set up WebGoat with a personalized menu. You can leave out some menu categories or individual lessons by setting certain environment variables.&lt;/p&gt; 
&lt;p&gt;For instance running as a jar on a Linux/macOS it will look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;export TZ=Europe/Amsterdam # or your timezone
export EXCLUDE_CATEGORIES="CLIENT_SIDE,GENERAL,CHALLENGE"
export EXCLUDE_LESSONS="SqlInjectionAdvanced,SqlInjectionMitigations"
java -jar target/webgoat-2023.8-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or in a docker run it would (once this version is pushed into docker hub) look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;docker run -d -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e EXCLUDE_CATEGORIES="CLIENT_SIDE,GENERAL,CHALLENGE" -e EXCLUDE_LESSONS="SqlInjectionAdvanced,SqlInjectionMitigations" webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>curl/curl</title>
      <link>https://github.com/curl/curl</link>
      <description>&lt;p&gt;A command line tool and library for transferring data with URL syntax, supporting DICT, FILE, FTP, FTPS, GOPHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS. libcurl offers a myriad of powerful features&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://curl.se/"&gt;&lt;img src="https://curl.se/logo/curl-logo.svg?sanitize=true" alt="curl logo" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;curl is a command-line tool for transferring data specified with URL syntax. Learn how to use curl by reading &lt;a href="https://curl.se/docs/manpage.html"&gt;the manpage&lt;/a&gt; or &lt;a href="https://everything.curl.dev/"&gt;everything curl&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Find out how to install curl by reading &lt;a href="https://curl.se/docs/install.html"&gt;the INSTALL document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;libcurl is the library curl is using to do its job. It is readily available to be used by your software. Read &lt;a href="https://curl.se/libcurl/c/libcurl.html"&gt;the libcurl manpage&lt;/a&gt; to learn how.&lt;/p&gt; 
&lt;h2&gt;Open Source&lt;/h2&gt; 
&lt;p&gt;curl is Open Source and is distributed under an MIT-like &lt;a href="https://curl.se/docs/copyright.html"&gt;license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Contact us on a suitable &lt;a href="https://curl.se/mail/"&gt;mailing list&lt;/a&gt; or use GitHub &lt;a href="https://github.com/curl/curl/issues"&gt;issues&lt;/a&gt;/ &lt;a href="https://github.com/curl/curl/pulls"&gt;pull requests&lt;/a&gt;/ &lt;a href="https://github.com/curl/curl/discussions"&gt;discussions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All contributors to the project are listed in &lt;a href="https://curl.se/docs/thanks.html"&gt;the THANKS document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Commercial support&lt;/h2&gt; 
&lt;p&gt;For commercial support, maybe private and dedicated help with your problems or applications using (lib)curl visit &lt;a href="https://curl.se/support.html"&gt;the support page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Website&lt;/h2&gt; 
&lt;p&gt;Visit the &lt;a href="https://curl.se/"&gt;curl website&lt;/a&gt; for the latest news and downloads.&lt;/p&gt; 
&lt;h2&gt;Source code&lt;/h2&gt; 
&lt;p&gt;Download the latest source from the Git server:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/curl/curl.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security problems&lt;/h2&gt; 
&lt;p&gt;Report suspected security problems via &lt;a href="https://hackerone.com/curl"&gt;our HackerOne page&lt;/a&gt; and not in public.&lt;/p&gt; 
&lt;h2&gt;Backers&lt;/h2&gt; 
&lt;p&gt;Thank you to all our backers &lt;span&gt;🙏&lt;/span&gt; &lt;a href="https://opencollective.com/curl#section-contribute"&gt;Become a backer&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Support this project by becoming a &lt;a href="https://curl.se/sponsors.html"&gt;sponsor&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zie619/n8n-workflows</title>
      <link>https://github.com/Zie619/n8n-workflows</link>
      <description>&lt;p&gt;all of the workflows of n8n i could find (also from the site itself)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;⚡ N8N Workflow Collection &amp;amp; Documentation&lt;/h1&gt; 
&lt;p&gt;A professionally organized collection of &lt;strong&gt;2,053 n8n workflows&lt;/strong&gt; with a lightning-fast documentation system that provides instant search, analysis, and browsing capabilities.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;⚠️ IMPORTANT NOTICE (Aug 14, 2025):&lt;/strong&gt; Repository history has been rewritten due to DMCA compliance. If you have a fork or local clone, please see &lt;a href="https://github.com/Zie619/n8n-workflows/issues/85"&gt;Issue 85&lt;/a&gt; for instructions on syncing your copy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support My Work&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.buymeacoffee.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/-Buy%20Me%20a%20Coffee-ffdd00?logo=buy-me-a-coffee&amp;amp;logoColor=black&amp;amp;style=flat" alt="Buy Me a Coffee" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you'd like to say thanks, consider buying me a coffee—your support helps me keep improving this project!&lt;/p&gt; 
&lt;h2&gt;🚀 &lt;strong&gt;NEW: High-Performance Documentation System&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Experience 100x performance improvement over traditional documentation!&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Quick Start - Fast Documentation System&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies
pip install -r requirements.txt

# Start the fast API server
python run.py

# Open in browser
http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡ &lt;strong&gt;Sub-100ms response times&lt;/strong&gt; with SQLite FTS5 search&lt;/li&gt; 
 &lt;li&gt;🔍 &lt;strong&gt;Instant full-text search&lt;/strong&gt; with advanced filtering&lt;/li&gt; 
 &lt;li&gt;📱 &lt;strong&gt;Responsive design&lt;/strong&gt; - works perfectly on mobile&lt;/li&gt; 
 &lt;li&gt;🌙 &lt;strong&gt;Dark/light themes&lt;/strong&gt; with system preference detection&lt;/li&gt; 
 &lt;li&gt;📊 &lt;strong&gt;Live statistics&lt;/strong&gt; - 365 unique integrations, 29,445 total nodes&lt;/li&gt; 
 &lt;li&gt;🎯 &lt;strong&gt;Smart categorization&lt;/strong&gt; by trigger type and complexity&lt;/li&gt; 
 &lt;li&gt;🎯 &lt;strong&gt;Use case categorization&lt;/strong&gt; by service name mapped to categories&lt;/li&gt; 
 &lt;li&gt;📄 &lt;strong&gt;On-demand JSON viewing&lt;/strong&gt; and download&lt;/li&gt; 
 &lt;li&gt;🔗 &lt;strong&gt;Mermaid diagram generation&lt;/strong&gt; for workflow visualization&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Real-time workflow naming&lt;/strong&gt; with intelligent formatting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Old System&lt;/th&gt; 
   &lt;th&gt;New System&lt;/th&gt; 
   &lt;th&gt;Improvement&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;File Size&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;71MB HTML&lt;/td&gt; 
   &lt;td&gt;&amp;lt;100KB&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;700x smaller&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Load Time&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;10+ seconds&lt;/td&gt; 
   &lt;td&gt;&amp;lt;1 second&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;10x faster&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Search&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Client-side only&lt;/td&gt; 
   &lt;td&gt;Full-text with FTS5&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Instant&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Memory Usage&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~2GB RAM&lt;/td&gt; 
   &lt;td&gt;&amp;lt;50MB RAM&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;40x less&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Mobile Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Poor&lt;/td&gt; 
   &lt;td&gt;Excellent&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Fully responsive&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📂 Repository Organization&lt;/h2&gt; 
&lt;h3&gt;Workflow Collection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2,053 workflows&lt;/strong&gt; with meaningful, searchable names&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;365 unique integrations&lt;/strong&gt; across popular platforms&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;29,445 total nodes&lt;/strong&gt; with professional categorization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality assurance&lt;/strong&gt; - All workflows analyzed and categorized&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Naming System ✨&lt;/h3&gt; 
&lt;p&gt;Our intelligent naming system converts technical filenames into readable titles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Before&lt;/strong&gt;: &lt;code&gt;2051_Telegram_Webhook_Automation_Webhook.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;After&lt;/strong&gt;: &lt;code&gt;Telegram Webhook Automation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% meaningful names&lt;/strong&gt; with smart capitalization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic integration detection&lt;/strong&gt; from node analysis&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Use Case Category ✨&lt;/h3&gt; 
&lt;p&gt;The search interface includes a dropdown filter that lets you browse 2,000+ workflows by category.&lt;/p&gt; 
&lt;p&gt;The system includes an automated categorization feature that organizes workflows by service categories to make them easier to discover and filter.&lt;/p&gt; 
&lt;h3&gt;How Categorization Works&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run the categorization script&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python create_categories.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Service Name Recognition&lt;/strong&gt; The script analyzes each workflow JSON filename to identify recognized service names (e.g., "Twilio", "Slack", "Gmail", etc.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Category Mapping&lt;/strong&gt; Each recognized service name is matched to its corresponding category using the definitions in &lt;code&gt;context/def_categories.json&lt;/code&gt;. For example:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Twilio → Communication &amp;amp; Messaging&lt;/li&gt; 
   &lt;li&gt;Gmail → Communication &amp;amp; Messaging&lt;/li&gt; 
   &lt;li&gt;Airtable → Data Processing &amp;amp; Analysis&lt;/li&gt; 
   &lt;li&gt;Salesforce → CRM &amp;amp; Sales&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Search Categories Generation&lt;/strong&gt; The script produces a &lt;code&gt;search_categories.json&lt;/code&gt; file that contains the categorized workflow data&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Filter Interface&lt;/strong&gt; Users can then filter workflows by category in the search interface, making it easier to find workflows for specific use cases&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Available Categories&lt;/h3&gt; 
&lt;p&gt;The categorization system includes the following main categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI Agent Development&lt;/li&gt; 
 &lt;li&gt;Business Process Automation&lt;/li&gt; 
 &lt;li&gt;Cloud Storage &amp;amp; File Management&lt;/li&gt; 
 &lt;li&gt;Communication &amp;amp; Messaging&lt;/li&gt; 
 &lt;li&gt;Creative Content &amp;amp; Video Automation&lt;/li&gt; 
 &lt;li&gt;Creative Design Automation&lt;/li&gt; 
 &lt;li&gt;CRM &amp;amp; Sales&lt;/li&gt; 
 &lt;li&gt;Data Processing &amp;amp; Analysis&lt;/li&gt; 
 &lt;li&gt;E-commerce &amp;amp; Retail&lt;/li&gt; 
 &lt;li&gt;Financial &amp;amp; Accounting&lt;/li&gt; 
 &lt;li&gt;Marketing &amp;amp; Advertising Automation&lt;/li&gt; 
 &lt;li&gt;Project Management&lt;/li&gt; 
 &lt;li&gt;Social Media Management&lt;/li&gt; 
 &lt;li&gt;Technical Infrastructure &amp;amp; DevOps&lt;/li&gt; 
 &lt;li&gt;Web Scraping &amp;amp; Data Extraction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contribute Categories&lt;/h3&gt; 
&lt;p&gt;You can help expand the categorization by adding more service-to-category mappings (e.g., Twilio → Communication &amp;amp; Messaging) in context/defs_categories.json.&lt;/p&gt; 
&lt;p&gt;Many workflow JSON files are conveniently named with the service name, often separated by underscores (_).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛠 Usage Instructions&lt;/h2&gt; 
&lt;h3&gt;Option 1: Modern Fast System (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone &amp;lt;repo-url&amp;gt;
cd n8n-workflows

# Install Python dependencies
pip install -r requirements.txt

# Start the documentation server
python run.py

# Browse workflows at http://localhost:8000
# - Instant search across 2,053 workflows
# - Professional responsive interface
# - Real-time workflow statistics
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 2: Development Mode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with auto-reload for development
python run.py --dev

# Or specify custom host/port
python run.py --host 0.0.0.0 --port 3000

# Force database reindexing
python run.py --reindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Import Workflows into n8n&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use the Python importer (recommended)
python import_workflows.py

# Or manually import individual workflows:
# 1. Open your n8n Editor UI
# 2. Click menu (☰) → Import workflow
# 3. Choose any .json file from the workflows/ folder
# 4. Update credentials/webhook URLs before running
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📊 Workflow Statistics&lt;/h2&gt; 
&lt;h3&gt;Current Collection Stats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Total Workflows&lt;/strong&gt;: 2,053 automation workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Active Workflows&lt;/strong&gt;: 215 (10.5% active rate)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Total Nodes&lt;/strong&gt;: 29,445 (avg 14.3 nodes per workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unique Integrations&lt;/strong&gt;: 365 different services and APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: SQLite with FTS5 full-text search&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Trigger Distribution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complex&lt;/strong&gt;: 831 workflows (40.5%) - Multi-trigger systems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Webhook&lt;/strong&gt;: 519 workflows (25.3%) - API-triggered automations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manual&lt;/strong&gt;: 477 workflows (23.2%) - User-initiated workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scheduled&lt;/strong&gt;: 226 workflows (11.0%) - Time-based executions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Complexity Analysis&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Low (≤5 nodes)&lt;/strong&gt;: ~35% - Simple automations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium (6-15 nodes)&lt;/strong&gt;: ~45% - Standard workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High (16+ nodes)&lt;/strong&gt;: ~20% - Complex enterprise systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Popular Integrations&lt;/h3&gt; 
&lt;p&gt;Top services by usage frequency:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Communication&lt;/strong&gt;: Telegram, Discord, Slack, WhatsApp&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Storage&lt;/strong&gt;: Google Drive, Google Sheets, Dropbox&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Databases&lt;/strong&gt;: PostgreSQL, MySQL, MongoDB, Airtable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI/ML&lt;/strong&gt;: OpenAI, Anthropic, Hugging Face&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development&lt;/strong&gt;: HTTP Request, Webhook, GraphQL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔍 Advanced Search Features&lt;/h2&gt; 
&lt;h3&gt;Smart Search Categories&lt;/h3&gt; 
&lt;p&gt;Our system automatically categorizes workflows into 12 service categories:&lt;/p&gt; 
&lt;h4&gt;Available Categories:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;messaging&lt;/strong&gt;: Telegram, Discord, Slack, WhatsApp, Teams&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ai_ml&lt;/strong&gt;: OpenAI, Anthropic, Hugging Face&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;database&lt;/strong&gt;: PostgreSQL, MySQL, MongoDB, Redis, Airtable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;email&lt;/strong&gt;: Gmail, Mailjet, Outlook, SMTP/IMAP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;cloud_storage&lt;/strong&gt;: Google Drive, Google Docs, Dropbox, OneDrive&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;project_management&lt;/strong&gt;: Jira, GitHub, GitLab, Trello, Asana&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;social_media&lt;/strong&gt;: LinkedIn, Twitter/X, Facebook, Instagram&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ecommerce&lt;/strong&gt;: Shopify, Stripe, PayPal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;analytics&lt;/strong&gt;: Google Analytics, Mixpanel&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;calendar_tasks&lt;/strong&gt;: Google Calendar, Cal.com, Calendly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;forms&lt;/strong&gt;: Typeform, Google Forms, Form Triggers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;development&lt;/strong&gt;: Webhook, HTTP Request, GraphQL, SSE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Search workflows by text
curl "http://localhost:8000/api/workflows?q=telegram+automation"

# Filter by trigger type and complexity
curl "http://localhost:8000/api/workflows?trigger=Webhook&amp;amp;complexity=high"

# Find all messaging workflows
curl "http://localhost:8000/api/workflows/category/messaging"

# Get database statistics
curl "http://localhost:8000/api/stats"

# Browse available categories
curl "http://localhost:8000/api/categories"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏗 Technical Architecture&lt;/h2&gt; 
&lt;h3&gt;Modern Stack&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite Database&lt;/strong&gt; - FTS5 full-text search with 365 indexed integrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FastAPI Backend&lt;/strong&gt; - RESTful API with automatic OpenAPI documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Responsive Frontend&lt;/strong&gt; - Modern HTML5 with embedded CSS/JavaScript&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Analysis&lt;/strong&gt; - Automatic workflow categorization and naming&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Change Detection&lt;/strong&gt; - MD5 hashing for efficient re-indexing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Processing&lt;/strong&gt; - Non-blocking workflow analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compressed Responses&lt;/strong&gt; - Gzip middleware for optimal speed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error Handling&lt;/strong&gt; - Graceful degradation and comprehensive logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile Optimization&lt;/strong&gt; - Touch-friendly interface design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database Performance&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;-- Optimized schema for lightning-fast queries
CREATE TABLE workflows (
    id INTEGER PRIMARY KEY,
    filename TEXT UNIQUE,
    name TEXT,
    active BOOLEAN,
    trigger_type TEXT,
    complexity TEXT,
    node_count INTEGER,
    integrations TEXT,  -- JSON array of 365 unique services
    description TEXT,
    file_hash TEXT,     -- MD5 for change detection
    analyzed_at TIMESTAMP
);

-- Full-text search with ranking
CREATE VIRTUAL TABLE workflows_fts USING fts5(
    filename, name, description, integrations, tags,
    content='workflows', content_rowid='id'
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔧 Setup &amp;amp; Requirements&lt;/h2&gt; 
&lt;h3&gt;System Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.7+&lt;/strong&gt; - For running the documentation system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modern Browser&lt;/strong&gt; - Chrome, Firefox, Safari, Edge&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;50MB Storage&lt;/strong&gt; - For SQLite database and indexes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;n8n Instance&lt;/strong&gt; - For importing and running workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone &amp;lt;repo-url&amp;gt;
cd n8n-workflows

# Install dependencies
pip install -r requirements.txt

# Start documentation server
python run.py

# Access at http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or .venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run with auto-reload for development
python api_server.py --reload

# Force database reindexing
python workflow_db.py --index --force
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📋 Naming Convention&lt;/h2&gt; 
&lt;h3&gt;Intelligent Formatting System&lt;/h3&gt; 
&lt;p&gt;Our system automatically converts technical filenames to user-friendly names:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Automatic transformations:
2051_Telegram_Webhook_Automation_Webhook.json → "Telegram Webhook Automation"
0250_HTTP_Discord_Import_Scheduled.json → "HTTP Discord Import Scheduled"  
0966_OpenAI_Data_Processing_Manual.json → "OpenAI Data Processing Manual"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Technical Format&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;[ID]_[Service1]_[Service2]_[Purpose]_[Trigger].json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Smart Capitalization Rules&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP&lt;/strong&gt; → HTTP (not Http)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt; → API (not Api)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;webhook&lt;/strong&gt; → Webhook&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;automation&lt;/strong&gt; → Automation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;scheduled&lt;/strong&gt; → Scheduled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 API Documentation&lt;/h2&gt; 
&lt;h3&gt;Core Endpoints&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /&lt;/code&gt; - Main workflow browser interface&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/stats&lt;/code&gt; - Database statistics and metrics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows&lt;/code&gt; - Search with filters and pagination&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}&lt;/code&gt; - Detailed workflow information&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}/download&lt;/code&gt; - Download workflow JSON&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}/diagram&lt;/code&gt; - Generate Mermaid diagram&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Search&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/category/{category}&lt;/code&gt; - Search by service category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/categories&lt;/code&gt; - List all available categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/integrations&lt;/code&gt; - Get integration statistics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /api/reindex&lt;/code&gt; - Trigger background reindexing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Response Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;// GET /api/stats
{
  "total": 2053,
  "active": 215,
  "inactive": 1838,
  "triggers": {
    "Complex": 831,
    "Webhook": 519,
    "Manual": 477,
    "Scheduled": 226
  },
  "total_nodes": 29445,
  "unique_integrations": 365
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;h3&gt;Adding New Workflows&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Export workflow&lt;/strong&gt; as JSON from n8n&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Name descriptively&lt;/strong&gt; following the established pattern&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add to workflows/&lt;/strong&gt; directory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remove sensitive data&lt;/strong&gt; (credentials, personal URLs)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Run reindexing&lt;/strong&gt; to update the database&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Quality Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ Workflow must be functional and tested&lt;/li&gt; 
 &lt;li&gt;✅ Remove all credentials and sensitive data&lt;/li&gt; 
 &lt;li&gt;✅ Follow naming convention for consistency&lt;/li&gt; 
 &lt;li&gt;✅ Verify compatibility with recent n8n versions&lt;/li&gt; 
 &lt;li&gt;✅ Include meaningful description or comments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;⚠️ Important Notes&lt;/h2&gt; 
&lt;h3&gt;Security &amp;amp; Privacy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Review before use&lt;/strong&gt; - All workflows shared as-is for educational purposes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update credentials&lt;/strong&gt; - Replace API keys, tokens, and webhooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test safely&lt;/strong&gt; - Verify in development environment first&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check permissions&lt;/strong&gt; - Ensure proper access rights for integrations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Compatibility&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;n8n Version&lt;/strong&gt; - Compatible with n8n 1.0+ (most workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Nodes&lt;/strong&gt; - Some workflows may require additional node installations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Changes&lt;/strong&gt; - External services may have updated their APIs since creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependencies&lt;/strong&gt; - Verify required integrations before importing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📚 Resources &amp;amp; References&lt;/h2&gt; 
&lt;h3&gt;Workflow Sources&lt;/h3&gt; 
&lt;p&gt;This comprehensive collection includes workflows from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Official n8n.io&lt;/strong&gt; - Documentation and community examples&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub repositories&lt;/strong&gt; - Open source community contributions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Blog posts &amp;amp; tutorials&lt;/strong&gt; - Real-world automation patterns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User submissions&lt;/strong&gt; - Tested and verified workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise use cases&lt;/strong&gt; - Business process automations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Learn More&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/"&gt;n8n Documentation&lt;/a&gt; - Official documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://community.n8n.io/"&gt;n8n Community&lt;/a&gt; - Community forum and support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/"&gt;Workflow Templates&lt;/a&gt; - Official template library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/integrations/"&gt;Integration Docs&lt;/a&gt; - Service-specific guides&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏆 Project Achievements&lt;/h2&gt; 
&lt;h3&gt;Repository Transformation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2,053 workflows&lt;/strong&gt; professionally organized and named&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;365 unique integrations&lt;/strong&gt; automatically detected and categorized&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% meaningful names&lt;/strong&gt; (improved from basic filename patterns)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero data loss&lt;/strong&gt; during intelligent renaming process&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced search&lt;/strong&gt; with 12 service categories&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Revolution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Sub-100ms search&lt;/strong&gt; with SQLite FTS5 full-text indexing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instant filtering&lt;/strong&gt; across 29,445 workflow nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile-optimized&lt;/strong&gt; responsive design for all devices&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time statistics&lt;/strong&gt; with live database queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional interface&lt;/strong&gt; with modern UX principles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;System Reliability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Robust error handling&lt;/strong&gt; with graceful degradation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change detection&lt;/strong&gt; for efficient database updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background processing&lt;/strong&gt; for non-blocking operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive logging&lt;/strong&gt; for debugging and monitoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production-ready&lt;/strong&gt; with proper middleware and security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;This repository represents the most comprehensive and well-organized collection of n8n workflows available, featuring cutting-edge search technology and professional documentation that makes workflow discovery and usage a delightful experience.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🎯 Perfect for&lt;/strong&gt;: Developers, automation engineers, business analysts, and anyone looking to streamline their workflows with proven n8n automations.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/README_ZH.md"&gt;中文&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TEN-framework/ten-framework</title>
      <link>https://github.com/TEN-framework/ten-framework</link>
      <description>&lt;p&gt;Open-source framework for conversational voice AI agents.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/7c8f72d7-3993-4d01-8504-b71578a22944" alt="TEN banner" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/ten-framework/ten-framework?color=369eff&amp;amp;labelColor=gray&amp;amp;logo=github&amp;amp;style=flat-square" alt="TEN Releases" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/ten-framework/ten-framework?labelColor=gray&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/discussions/"&gt;&lt;img src="https://img.shields.io/github/discussions/TEN-framework/ten_framework?labelColor=gray&amp;amp;color=%20%23f79009" alt="Discussion posts" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/commit-activity"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/TEN-framework/ten_framework?labelColor=gray&amp;amp;color=pink" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/issues"&gt;&lt;img src="https://img.shields.io/github/issues-search?query=repo%3ATEN-framework%2Ften-framework%20is%3Aclosed&amp;amp;label=issues%20closed&amp;amp;labelColor=gray&amp;amp;color=green" alt="Issues closed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/ten-framework/ten-framework?color=c4f042&amp;amp;labelColor=gray&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome!-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten_framework/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0_with_certain_conditions-blue.svg?labelColor=%20%23155EEF&amp;amp;color=%20%23528bff" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/TEN-framework/ten_framework/watchers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/watchers/TEN-framework/ten_framework?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/TEN-framework/ten_framework/network/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/forks/TEN-framework/ten_framework?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/TEN-framework/ten_framework/stargazers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/stars/TEN-framework/ten_framework?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/README.md"&gt;&lt;img alt="README in English" src="https://img.shields.io/badge/English-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-CN.md"&gt;&lt;img alt="简体中文操作指南" src="https://img.shields.io/badge/简体中文-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-JP.md"&gt;&lt;img alt="日本語のREADME" src="https://img.shields.io/badge/日本語-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-KR.md"&gt;&lt;img alt="README in 한국어" src="https://img.shields.io/badge/한국어-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-ES.md"&gt;&lt;img alt="README en Español" src="https://img.shields.io/badge/Español-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-FR.md"&gt;&lt;img alt="README en Français" src="https://img.shields.io/badge/Français-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-IT.md"&gt;&lt;img alt="README in Italiano" src="https://img.shields.io/badge/Italiano-lightgrey" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://theten.ai"&gt;Official Site&lt;/a&gt; • &lt;a href="https://theten.ai/docs/ten_agent/overview"&gt;Documentation&lt;/a&gt; • &lt;a href="https://theten.ai/blog"&gt;Blog&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11978" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11978" alt="TEN-framework%2Ften_framework | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Table of Contents&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;h4&gt;Table of Contents&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-welcome-to-ten"&gt;👋 Welcome to TEN&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-tman-designer"&gt;🎨 TMAN Designer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-features"&gt;✨ Features&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#1%EF%B8%8F%E2%83%A3-real-time-avatar"&gt;1️⃣ Real-time Avatar&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#2%EF%B8%8F%E2%83%A3-real-time-voice-with-mcp-servers"&gt;2️⃣ Real-time voice with MCP servers&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#3%EF%B8%8F%E2%83%A3-real-time-communication-with-hardware"&gt;3️⃣ Real-time communication with hardware&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#4%EF%B8%8F%E2%83%A3-real-time-vision-and-real-time-screenshare-detection"&gt;4️⃣ Real-time vision and real-time screenshare detection&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#5%EF%B8%8F%E2%83%A3-ten-with-other-llm-platforms"&gt;5️⃣ TEN with other LLM platforms&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#6%EF%B8%8F%E2%83%A3-storyteller---ten-image-generation"&gt;6️⃣ StoryTeller - TEN image generation&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-get-ten-agent-up-and-running"&gt;👩‍💻 Get TEN Agent up and running&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B0%EF%B8%8F-run-ten-agent-in-localhost"&gt;🅰️ Run TEN Agent in &lt;code&gt;localhost&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B1%EF%B8%8F-run-ten-agent-in-codespaceno-docker"&gt;🅱️ Run TEN Agent in Codespace(no docker)&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%EF%B8%8F-ten-agent-self-hosting"&gt;🛳️ TEN Agent Self Hosting&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B0%EF%B8%8F-deploying-with-docker"&gt;🅰️ Deploying with Docker&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B1%EF%B8%8F-deploying-with-other-cloud-services"&gt;🅱️ Deploying with other cloud services&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-ten-ecosystem"&gt;🌍 TEN Ecosystem&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-ask-questions"&gt;❓ Ask Questions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-contributing"&gt;🥰 Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#code-contributors"&gt;Code Contributors&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#contribution-guidelines"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;br /&gt; 
&lt;/details&gt; 
&lt;h2&gt;👋 Welcome to TEN&lt;/h2&gt; 
&lt;p&gt;TEN is a comprehensive open-source ecosystem for creating, customizing, and deploying real-time conversational AI agents with multimodal capabilities including voice, vision, and avatar interactions.&lt;/p&gt; 
&lt;p&gt;TEN includes &lt;a href="https://github.com/ten-framework/ten-framework"&gt;TEN Framework&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;TEN Turn Detection&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-vad"&gt;TEN VAD&lt;/a&gt;, &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/demo"&gt;TEN Agent&lt;/a&gt;, &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/core/src/ten_manager/designer_frontend"&gt;TMAN Designer&lt;/a&gt;, and &lt;a href="https://github.com/ten-framework/portal"&gt;TEN Portal&lt;/a&gt;. Check out &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-ten-ecosystem"&gt;🌍 TEN Ecosystem&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Community Channel&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/intent/follow?screen_name=TenFramework"&gt;&lt;img src="https://img.shields.io/twitter/follow/TenFramework?logo=X&amp;amp;color=%20%23f5f5f5" alt="Follow on X" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on X for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/company/ten-framework"&gt;&lt;img src="https://custom-icon-badges.demolab.com/badge/LinkedIn-TEN_Framework-0A66C2?logo=linkedin-white&amp;amp;logoColor=fff" alt="Follow on LinkedIn" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on LinkedIn for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/VnPftUzAMJ"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20TEN%20Community-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord TEN Community" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Discord community to connect with developers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/TEN-framework"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-TEN%20Framework-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face Space" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Hugging Face community to explore our spaces and models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-agent/discussions/170"&gt;&lt;img src="https://img.shields.io/badge/TEN_Framework-WeChat_Group-%2307C160?logo=wechat&amp;amp;labelColor=darkgreen&amp;amp;color=gray" alt="WeChat" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our WeChat group for Chinese community discussions&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Star TEN Repositories&lt;/strong&gt; ⭐️&lt;/p&gt; 
 &lt;p&gt;Get instant notifications for new releases and updates. Your support helps us grow and improve TEN!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/eeebe996-8c14-4bf7-82ae-f1a1f7e30705" alt="TEN star us gif" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;picture&gt; 
  &lt;img width="100%" src="https://api.star-history.com/svg?repos=ten-framework/ten-framework&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; 
&lt;/details&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;🎨 TMAN Designer&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/44c6a087-ec7a-45b0-a084-dab5dac5e36b"&gt;https://github.com/user-attachments/assets/44c6a087-ec7a-45b0-a084-dab5dac5e36b&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;TMAN Designer&lt;/h3&gt; 
&lt;p&gt;TMAN Designer is a low/no-code option to create voice agents with an easy-to-use workflow UI. It can load apps and graphs, and includes an online editor, log viewer, and much more.&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://theten.ai/blog/tman-designer-of-ten-framework"&gt;this blog&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/c6702995-de94-4d3e-8cae-af097f087ac1" alt="TEN Agent with Trulience" /&gt;&lt;/p&gt; 
&lt;h3&gt;1️⃣ Real-time Avatar&lt;/h3&gt; 
&lt;p&gt;Build engaging AI avatars with TEN Agent using &lt;a href="https://trulience.com"&gt;Trulience&lt;/a&gt;'s diverse collection of free avatar options. To get it up and running, you only need 2 steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Follow the README to finish setting up and running the Playground&lt;/li&gt; 
 &lt;li&gt;Enter the avatar ID and &lt;a href="https://trulience.com/docs#/authentication/jwt-tokens/jwt-tokens?id=use-your-custom-userid"&gt;token&lt;/a&gt; you get from &lt;a href="https://trulience.com"&gt;Trulience&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/afb77ad3-9c23-452f-b870-216687779017" alt="TEN with MCP servers" /&gt;&lt;/p&gt; 
&lt;h3&gt;2️⃣ Real-time voice with MCP servers&lt;/h3&gt; 
&lt;p&gt;TEN Agent now integrates seamlessly with MCP servers, expanding its LLM capabilities. To get started:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open the Module Picker in Playground&lt;/li&gt; 
 &lt;li&gt;Add the MCP server tool for LLM integration&lt;/li&gt; 
 &lt;li&gt;Paste a URL from your MCP server in the extension&lt;/li&gt; 
 &lt;li&gt;Start a realtime conversation with TEN Agent&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This integration allows you to leverage MCP's diverse servers offerings while maintaining TEN Agent's powerful conversational abilities.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/78647eef-2d66-44e6-99a8-1918a940fb9f"&gt;https://github.com/user-attachments/assets/78647eef-2d66-44e6-99a8-1918a940fb9f&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3️⃣ Real-time communication with hardware&lt;/h3&gt; 
&lt;p&gt;TEN Agent is now running on the Espressif ESP32-S3 Korvo V3 development board, an excellent way to integrate realtime communication with LLM on hardware.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/esp32-client"&gt;integration guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/a1addb02-a450-47be-8cb2-d25e3b574f53" alt="Real-time Vision" /&gt;&lt;/p&gt; 
&lt;h3&gt;4️⃣ Real-time vision and real-time screenshare detection&lt;/h3&gt; 
&lt;p&gt;Try Google Gemini Multimodal Live API with realtime vision and realtime screenshare detection capabilities, it is a ready-to-use extension, along with powerful tools like Weather Check and Web Search integrated perfectly into TEN Agent.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/234ff443-bef8-4cc4-9a10-09d6ec3f5bc1" alt="TEN with Dify" /&gt;&lt;/p&gt; 
&lt;h3&gt;5️⃣ TEN with other LLM platforms&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://theten.ai/docs/ten_agent/playground/use-cases/voice-assistant/run_dify#steps"&gt;TEN Agent + Dify&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;TEN offers a great support to make the realtime interactive experience even better on other LLM platform as well, check out docs for more.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/fe28a549-ddb9-431e-9282-57539fb87371" alt="TEN StoryTeller" /&gt;&lt;/p&gt; 
&lt;h3&gt;6️⃣ StoryTeller - TEN image generation&lt;/h3&gt; 
&lt;p&gt;Experience the real-time image generation with StoryTeller, it is a ready-to-use extension, along with powerful tools like Weather Check and Web Search integrated perfectly into TEN.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;👩‍💻 Get TEN Agent up and running&lt;/h2&gt; 
&lt;h4&gt;🅰️ Run TEN Agent in localhost&lt;/h4&gt; 
&lt;h4&gt;Step ⓵ - Prerequisites&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Requirements&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Keys&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;• Agora &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App ID&lt;/a&gt; and &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App Certificate&lt;/a&gt; (free minutes every month) &lt;br /&gt;• &lt;a href="https://openai.com/index/openai-api/"&gt;OpenAI&lt;/a&gt; API key (any LLM that is compatible with OpenAI)&lt;br /&gt;• &lt;a href="https://deepgram.com/"&gt;Deepgram&lt;/a&gt; ASR (free credits available with signup)&lt;br /&gt;• &lt;a href="https://elevenlabs.io/"&gt;Elevenlabs&lt;/a&gt; TTS (free credits available with signup)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;• &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; / &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;br /&gt;• &lt;a href="https://nodejs.org/en"&gt;Node.js(LTS) v18&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Minimum System Requirements&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;• CPU &amp;gt;= 2 Core&lt;br /&gt;• RAM &amp;gt;= 4 GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;macOS: Docker setting on Apple Silicon&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Uncheck "Use Rosetta for x86/amd64 emulation" in Docker settings, it may result in slower build times on ARM, but performance will be normal when deployed to x64 servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h4&gt;Step ⓶ - Build agent in VM&lt;/h4&gt; 
&lt;h5&gt;1. Clone down the repo,&lt;code&gt;cd&lt;/code&gt; to &lt;code&gt;ai-agents&lt;/code&gt; and create &lt;code&gt;.env&lt;/code&gt; file from &lt;code&gt;.env.example&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai_agents
cp ./.env.example ./.env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;2. Setup Agora App ID and App Certificate in &lt;code&gt;.env&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;AGORA_APP_ID=
AGORA_APP_CERTIFICATE=
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;3. Start agent development containers&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;4. Enter container&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it ten_agent_dev bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;5. Build agent with the default &lt;code&gt;graph&lt;/code&gt; ( ~5min - ~8min)&lt;/h5&gt; 
&lt;p&gt;check the &lt;code&gt;/examples&lt;/code&gt; folder for more examples&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# use the chained voice assistant
task use AGENT=voice-assistant

# or use the speech-to-speech voice assistant realtime
task use AGENT=voice-assistant-realtime
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;6. Start the web server&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# run task build if you changed any local source code, this is necessary if you are working on languages which require compilation like TypeScript or Golang.
task build

task run
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h4&gt;Step ⓷ - Customize your agent with TMAN Designer&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:49483"&gt;localhost:49483&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Right-click on the STT, LLM, and TTS extensions.&lt;/li&gt; 
 &lt;li&gt;Open their properties and enter APIs respectively.&lt;/li&gt; 
 &lt;li&gt;Right-click the canvas and select 'Manage Apps' to open the Apps Manager.&lt;/li&gt; 
 &lt;li&gt;Right under the Actions, click the ▶ to run the App.&lt;/li&gt; 
 &lt;li&gt;Check the 'Run with TEN Agent' option and click the Run button.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h3&gt;🅱️ Run TEN Agent in Codespace(no docker)&lt;/h3&gt; 
&lt;p&gt;GitHub offers free Codespace for each repository, you can run the playground in Codespace without using Docker.Also, the speed of Codespace is much faster than localhost.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/ten-framework/ten-agent"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://theten.ai/docs/ten_agent/setup_development_env/setting_up_development_inside_codespace"&gt;this guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;🛳️ TEN Agent Self Hosting&lt;/h2&gt; 
&lt;h4&gt;🅰️ Deploying with Docker&lt;/h4&gt; 
&lt;p&gt;Once you have customized your agent (either by using the TMAN Manager, Playground, or editing &lt;code&gt;property.json&lt;/code&gt; directly), you can deploy it by creating a release Docker image for your service.&lt;/p&gt; 
&lt;p&gt;Read the &lt;a href="https://theten.ai/docs/ten_agent/deploy_ten_agent/deploy_agent_service"&gt;Deployment Guide&lt;/a&gt; for detailed information about deployment.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h4&gt;🅱️ Deploying with other cloud services&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;coming soon&lt;/em&gt;&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;🌍 TEN Ecosystem&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project&lt;/th&gt; 
   &lt;th&gt;Preview&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten_framework"&gt;&lt;strong&gt;🏚️ TEN Framework&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN is an open-source framework for real-time, multimodal conversational AI.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten_framework?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/7c8f72d7-3993-4d01-8504-b71578a22944" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;&lt;strong&gt;️🔂 TEN Turn Detection&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN is for full-duplex dialogue communication.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-turn-detection?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/8d0ec716-5d0e-43e4-ad9a-d97b17305658" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-vad"&gt;&lt;strong&gt;🔉 TEN VAD&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN VAD is a low-latency, lightweight and high-performance streaming voice activity detector (VAD).&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-vad?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/d45870e4-9453-4047-8163-08737f82863f" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents"&gt;&lt;strong&gt;🎙️ TEN Agent&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN Agent is a showcase of TEN Framewrok.&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/38de2207-939b-4702-a0aa-04491f5b5275" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/core/src/ten_manager/designer_frontend"&gt;&lt;strong&gt;🎨 TMAN Designer&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TMAN Designer is low/no code option to make a voice agent with easy to use workflow UI.&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/804c3543-0a47-42b7-b40b-ef32b742fb8f" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/portal"&gt;&lt;strong&gt;📒 TEN Portal&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;The official site of TEN framework, it has documentation and blog.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/portal?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/e17d8aaa-5928-45dd-ac71-814928e26a89" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;❓ Ask Questions&lt;/h2&gt; 
&lt;p&gt;TEN Framework is available on these AI-powered Q&amp;amp;A platforms. They can help you find answers quickly and accurately in multiple languages, covering everything from basic setup to advanced implementation details.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepWiki&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ReadmeX&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🥰 Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome all forms of open-source collaboration! Whether you're fixing bugs, adding features, improving documentation, or sharing ideas - your contributions help advance personalized AI tools. Check out our GitHub Issues and Projects to find ways to contribute and show your skills. Together, we can build something amazing!&lt;/p&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Welcome all kinds of contributions&lt;/strong&gt; 🙏&lt;/p&gt; 
 &lt;p&gt;Join us in building TEN better! Every contribution makes a difference, from code to documentation. Share your TEN Agent projects on social media with to inspire others!&lt;/p&gt; 
 &lt;p&gt;Connect with one of the TEN maintainers &lt;a href="https://x.com/elliotchen100"&gt;@elliotchen100&lt;/a&gt; on 𝕏 or &lt;a href="https://github.com/cyfyifanchen"&gt;@cyfyifanchen&lt;/a&gt; on GitHub for project updates, discussions and collaboration opportunities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h3&gt;Code Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-agent/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=TEN-framework/ten-agent" alt="TEN" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contribution Guidelines&lt;/h3&gt; 
&lt;p&gt;Contributions are welcome! Please read the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/docs/code-of-conduct/contributing.md"&gt;contribution guidelines&lt;/a&gt; first.&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;The entire TEN framework (except for the folders explicitly listed below) is released under the Apache License, Version 2.0, with additional restrictions. For details, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/LICENSE"&gt;LICENSE&lt;/a&gt; file located in the root directory of the TEN framework.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The components within the &lt;code&gt;packages&lt;/code&gt; directory are released under the Apache License, Version 2.0. For details, please refer to the &lt;code&gt;LICENSE&lt;/code&gt; file located in each package's root directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The third-party libraries used by the TEN framework are listed and described in detail. For more information, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/third_party/"&gt;third_party&lt;/a&gt; folder.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>