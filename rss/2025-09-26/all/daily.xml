<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Thu, 25 Sep 2025 01:33:10 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>ultralytics/ultralytics</title>
      <link>https://github.com/ultralytics/ultralytics</link>
      <description>&lt;p&gt;Ultralytics YOLO üöÄ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://www.ultralytics.com/events/yolovision?utm_source=github&amp;amp;utm_medium=org&amp;amp;utm_campaign=yv25_event" target="_blank"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" alt="Ultralytics YOLO banner" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://docs.ultralytics.com/zh/"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/ko/"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/ja/"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/ru/"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/de/"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/fr/"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/pt/"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/tr/"&gt;T√ºrk√ße&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/vi/"&gt;Ti·∫øng Vi·ªát&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/ar/"&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;a href="https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Ultralytics CI" /&gt;&lt;/a&gt; 
  &lt;a href="https://clickpy.clickhouse.com/dashboard/ultralytics"&gt;&lt;img src="https://static.pepy.tech/badge/ultralytics" alt="Ultralytics Downloads" /&gt;&lt;/a&gt; 
  &lt;a href="https://zenodo.org/badge/latestdoi/264818686"&gt;&lt;img src="https://zenodo.org/badge/264818686.svg?sanitize=true" alt="Ultralytics YOLO Citation" /&gt;&lt;/a&gt; 
  &lt;a href="https://discord.com/invite/ultralytics"&gt;&lt;img alt="Ultralytics Discord" src="https://img.shields.io/discord/1089800235347353640?logo=discord&amp;amp;logoColor=white&amp;amp;label=Discord&amp;amp;color=blue" /&gt;&lt;/a&gt; 
  &lt;a href="https://community.ultralytics.com/"&gt;&lt;img alt="Ultralytics Forums" src="https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&amp;amp;logo=discourse&amp;amp;label=Forums&amp;amp;color=blue" /&gt;&lt;/a&gt; 
  &lt;a href="https://www.reddit.com/r/ultralytics/"&gt;&lt;img alt="Ultralytics Reddit" src="https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&amp;amp;logo=reddit&amp;amp;logoColor=white&amp;amp;label=Reddit&amp;amp;color=blue" /&gt;&lt;/a&gt; 
  &lt;br /&gt; 
  &lt;a href="https://console.paperspace.com/github/ultralytics/ultralytics"&gt;&lt;img src="https://assets.paperspace.io/img/gradient-badge.svg?sanitize=true" alt="Run Ultralytics on Gradient" /&gt;&lt;/a&gt; 
  &lt;a href="https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Ultralytics In Colab" /&gt;&lt;/a&gt; 
  &lt;a href="https://www.kaggle.com/models/ultralytics/yolo11"&gt;&lt;img src="https://kaggle.com/static/images/open-in-kaggle.svg?sanitize=true" alt="Open Ultralytics In Kaggle" /&gt;&lt;/a&gt; 
  &lt;a href="https://mybinder.org/v2/gh/ultralytics/ultralytics/HEAD?labpath=examples%2Ftutorial.ipynb"&gt;&lt;img src="https://mybinder.org/badge_logo.svg?sanitize=true" alt="Open Ultralytics In Binder" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://www.ultralytics.com/"&gt;Ultralytics&lt;/a&gt; creates cutting-edge, state-of-the-art (SOTA) &lt;a href="https://www.ultralytics.com/yolo"&gt;YOLO models&lt;/a&gt; built on years of foundational research in computer vision and AI. Constantly updated for performance and flexibility, our models are &lt;strong&gt;fast&lt;/strong&gt;, &lt;strong&gt;accurate&lt;/strong&gt;, and &lt;strong&gt;easy to use&lt;/strong&gt;. They excel at &lt;a href="https://docs.ultralytics.com/tasks/detect/"&gt;object detection&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/modes/track/"&gt;tracking&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/tasks/segment/"&gt;instance segmentation&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/tasks/classify/"&gt;image classification&lt;/a&gt;, and &lt;a href="https://docs.ultralytics.com/tasks/pose/"&gt;pose estimation&lt;/a&gt; tasks.&lt;/p&gt; 
&lt;p&gt;Find detailed documentation in the &lt;a href="https://docs.ultralytics.com/"&gt;Ultralytics Docs&lt;/a&gt;. Get support via &lt;a href="https://github.com/ultralytics/ultralytics/issues/new/choose"&gt;GitHub Issues&lt;/a&gt;. Join discussions on &lt;a href="https://discord.com/invite/ultralytics"&gt;Discord&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/ultralytics/"&gt;Reddit&lt;/a&gt;, and the &lt;a href="https://community.ultralytics.com/"&gt;Ultralytics Community Forums&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Request an Enterprise License for commercial use at &lt;a href="https://www.ultralytics.com/license"&gt;Ultralytics Licensing&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://docs.ultralytics.com/models/yolo11/" target="_blank"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/yolo/performance-comparison.png" alt="YOLO11 performance plots" /&gt; &lt;/a&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-github.png" width="2%" alt="Ultralytics GitHub" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://www.linkedin.com/company/ultralytics/"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-linkedin.png" width="2%" alt="Ultralytics LinkedIn" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://twitter.com/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-twitter.png" width="2%" alt="Ultralytics Twitter" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://youtube.com/ultralytics?sub_confirmation=1"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-youtube.png" width="2%" alt="Ultralytics YouTube" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://www.tiktok.com/@ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-tiktok.png" width="2%" alt="Ultralytics TikTok" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://ultralytics.com/bilibili"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-bilibili.png" width="2%" alt="Ultralytics BiliBili" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://discord.com/invite/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-discord.png" width="2%" alt="Ultralytics Discord" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìÑ Documentation&lt;/h2&gt; 
&lt;p&gt;See below for quickstart installation and usage examples. For comprehensive guidance on training, validation, prediction, and deployment, refer to our full &lt;a href="https://docs.ultralytics.com/"&gt;Ultralytics Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Install&lt;/summary&gt; 
 &lt;p&gt;Install the &lt;code&gt;ultralytics&lt;/code&gt; package, including all &lt;a href="https://github.com/ultralytics/ultralytics/raw/main/pyproject.toml"&gt;requirements&lt;/a&gt;, in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.8&lt;/strong&gt;&lt;/a&gt; environment with &lt;a href="https://pytorch.org/get-started/locally/"&gt;&lt;strong&gt;PyTorch&amp;gt;=1.8&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/ultralytics/"&gt;&lt;img src="https://img.shields.io/pypi/v/ultralytics?logo=pypi&amp;amp;logoColor=white" alt="PyPI - Version" /&gt;&lt;/a&gt; &lt;a href="https://clickpy.clickhouse.com/dashboard/ultralytics"&gt;&lt;img src="https://static.pepy.tech/badge/ultralytics" alt="Ultralytics Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/ultralytics/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/ultralytics?logo=python&amp;amp;logoColor=gold" alt="PyPI - Python Version" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install ultralytics
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For alternative installation methods, including &lt;a href="https://anaconda.org/conda-forge/ultralytics"&gt;Conda&lt;/a&gt;, &lt;a href="https://hub.docker.com/r/ultralytics/ultralytics"&gt;Docker&lt;/a&gt;, and building from source via Git, please consult the &lt;a href="https://docs.ultralytics.com/quickstart/"&gt;Quickstart Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://anaconda.org/conda-forge/ultralytics"&gt;&lt;img src="https://img.shields.io/conda/vn/conda-forge/ultralytics?logo=condaforge" alt="Conda Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/ultralytics/ultralytics"&gt;&lt;img src="https://img.shields.io/docker/v/ultralytics/ultralytics?sort=semver&amp;amp;logo=docker" alt="Docker Image Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/ultralytics/ultralytics"&gt;&lt;img src="https://img.shields.io/docker/pulls/ultralytics/ultralytics?logo=docker" alt="Ultralytics Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Usage&lt;/summary&gt; 
 &lt;h3&gt;CLI&lt;/h3&gt; 
 &lt;p&gt;You can use Ultralytics YOLO directly from the Command Line Interface (CLI) with the &lt;code&gt;yolo&lt;/code&gt; command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Predict using a pretrained YOLO model (e.g., YOLO11n) on an image
yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;yolo&lt;/code&gt; command supports various tasks and modes, accepting additional arguments like &lt;code&gt;imgsz=640&lt;/code&gt;. Explore the YOLO &lt;a href="https://docs.ultralytics.com/usage/cli/"&gt;CLI Docs&lt;/a&gt; for more examples.&lt;/p&gt; 
 &lt;h3&gt;Python&lt;/h3&gt; 
 &lt;p&gt;Ultralytics YOLO can also be integrated directly into your Python projects. It accepts the same &lt;a href="https://docs.ultralytics.com/usage/cfg/"&gt;configuration arguments&lt;/a&gt; as the CLI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from ultralytics import YOLO

# Load a pretrained YOLO11n model
model = YOLO("yolo11n.pt")

# Train the model on the COCO8 dataset for 100 epochs
train_results = model.train(
    data="coco8.yaml",  # Path to dataset configuration file
    epochs=100,  # Number of training epochs
    imgsz=640,  # Image size for training
    device="cpu",  # Device to run on (e.g., 'cpu', 0, [0,1,2,3])
)

# Evaluate the model's performance on the validation set
metrics = model.val()

# Perform object detection on an image
results = model("path/to/image.jpg")  # Predict on an image
results[0].show()  # Display results

# Export the model to ONNX format for deployment
path = model.export(format="onnx")  # Returns the path to the exported model
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Discover more examples in the YOLO &lt;a href="https://docs.ultralytics.com/usage/python/"&gt;Python Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ú® Models&lt;/h2&gt; 
&lt;p&gt;Ultralytics supports a wide range of YOLO models, from early versions like &lt;a href="https://docs.ultralytics.com/models/yolov3/"&gt;YOLOv3&lt;/a&gt; to the latest &lt;a href="https://docs.ultralytics.com/models/yolo11/"&gt;YOLO11&lt;/a&gt;. The tables below showcase YOLO11 models pretrained on the &lt;a href="https://docs.ultralytics.com/datasets/detect/coco/"&gt;COCO&lt;/a&gt; dataset for &lt;a href="https://docs.ultralytics.com/tasks/detect/"&gt;Detection&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/tasks/segment/"&gt;Segmentation&lt;/a&gt;, and &lt;a href="https://docs.ultralytics.com/tasks/pose/"&gt;Pose Estimation&lt;/a&gt;. Additionally, &lt;a href="https://docs.ultralytics.com/tasks/classify/"&gt;Classification&lt;/a&gt; models pretrained on the &lt;a href="https://docs.ultralytics.com/datasets/classify/imagenet/"&gt;ImageNet&lt;/a&gt; dataset are available. &lt;a href="https://docs.ultralytics.com/modes/track/"&gt;Tracking&lt;/a&gt; mode is compatible with all Detection, Segmentation, and Pose models. All &lt;a href="https://docs.ultralytics.com/models/"&gt;Models&lt;/a&gt; are automatically downloaded from the latest Ultralytics &lt;a href="https://github.com/ultralytics/assets/releases"&gt;release&lt;/a&gt; upon first use.&lt;/p&gt; 
&lt;a href="https://docs.ultralytics.com/tasks/" target="_blank"&gt; &lt;img width="100%" src="https://github.com/ultralytics/docs/releases/download/0/ultralytics-yolov8-tasks-banner.avif" alt="Ultralytics YOLO supported tasks" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;details open&gt;
 &lt;summary&gt;Detection (COCO)&lt;/summary&gt; 
 &lt;p&gt;Explore the &lt;a href="https://docs.ultralytics.com/tasks/detect/"&gt;Detection Docs&lt;/a&gt; for usage examples. These models are trained on the &lt;a href="https://cocodataset.org/"&gt;COCO dataset&lt;/a&gt;, featuring 80 object classes.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;val&lt;br /&gt;50-95&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt"&gt;YOLO11n&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;39.5&lt;/td&gt; 
    &lt;td&gt;56.1 ¬± 0.8&lt;/td&gt; 
    &lt;td&gt;1.5 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;2.6&lt;/td&gt; 
    &lt;td&gt;6.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt"&gt;YOLO11s&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;47.0&lt;/td&gt; 
    &lt;td&gt;90.0 ¬± 1.2&lt;/td&gt; 
    &lt;td&gt;2.5 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;9.4&lt;/td&gt; 
    &lt;td&gt;21.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt"&gt;YOLO11m&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;51.5&lt;/td&gt; 
    &lt;td&gt;183.2 ¬± 2.0&lt;/td&gt; 
    &lt;td&gt;4.7 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;20.1&lt;/td&gt; 
    &lt;td&gt;68.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt"&gt;YOLO11l&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;53.4&lt;/td&gt; 
    &lt;td&gt;238.6 ¬± 1.4&lt;/td&gt; 
    &lt;td&gt;6.2 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;25.3&lt;/td&gt; 
    &lt;td&gt;86.9&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt"&gt;YOLO11x&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;54.7&lt;/td&gt; 
    &lt;td&gt;462.8 ¬± 6.7&lt;/td&gt; 
    &lt;td&gt;11.3 ¬± 0.2&lt;/td&gt; 
    &lt;td&gt;56.9&lt;/td&gt; 
    &lt;td&gt;194.9&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;val&lt;/sup&gt;&lt;/strong&gt; values refer to single-model single-scale performance on the &lt;a href="https://cocodataset.org/"&gt;COCO val2017&lt;/a&gt; dataset. See &lt;a href="https://docs.ultralytics.com/guides/yolo-performance-metrics/"&gt;YOLO Performance Metrics&lt;/a&gt; for details. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val detect data=coco.yaml device=0&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over COCO val images using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val detect data=coco.yaml batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Segmentation (COCO)&lt;/summary&gt; 
 &lt;p&gt;Refer to the &lt;a href="https://docs.ultralytics.com/tasks/segment/"&gt;Segmentation Docs&lt;/a&gt; for usage examples. These models are trained on &lt;a href="https://docs.ultralytics.com/datasets/segment/coco/"&gt;COCO-Seg&lt;/a&gt;, including 80 classes.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;box&lt;br /&gt;50-95&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;mask&lt;br /&gt;50-95&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt"&gt;YOLO11n-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;38.9&lt;/td&gt; 
    &lt;td&gt;32.0&lt;/td&gt; 
    &lt;td&gt;65.9 ¬± 1.1&lt;/td&gt; 
    &lt;td&gt;1.8 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;2.9&lt;/td&gt; 
    &lt;td&gt;10.4&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-seg.pt"&gt;YOLO11s-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;46.6&lt;/td&gt; 
    &lt;td&gt;37.8&lt;/td&gt; 
    &lt;td&gt;117.6 ¬± 4.9&lt;/td&gt; 
    &lt;td&gt;2.9 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;10.1&lt;/td&gt; 
    &lt;td&gt;35.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-seg.pt"&gt;YOLO11m-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;51.5&lt;/td&gt; 
    &lt;td&gt;41.5&lt;/td&gt; 
    &lt;td&gt;281.6 ¬± 1.2&lt;/td&gt; 
    &lt;td&gt;6.3 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;22.4&lt;/td&gt; 
    &lt;td&gt;123.3&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-seg.pt"&gt;YOLO11l-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;53.4&lt;/td&gt; 
    &lt;td&gt;42.9&lt;/td&gt; 
    &lt;td&gt;344.2 ¬± 3.2&lt;/td&gt; 
    &lt;td&gt;7.8 ¬± 0.2&lt;/td&gt; 
    &lt;td&gt;27.6&lt;/td&gt; 
    &lt;td&gt;142.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-seg.pt"&gt;YOLO11x-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;54.7&lt;/td&gt; 
    &lt;td&gt;43.8&lt;/td&gt; 
    &lt;td&gt;664.5 ¬± 3.2&lt;/td&gt; 
    &lt;td&gt;15.8 ¬± 0.7&lt;/td&gt; 
    &lt;td&gt;62.1&lt;/td&gt; 
    &lt;td&gt;319.0&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;val&lt;/sup&gt;&lt;/strong&gt; values are for single-model single-scale on the &lt;a href="https://cocodataset.org/"&gt;COCO val2017&lt;/a&gt; dataset. See &lt;a href="https://docs.ultralytics.com/guides/yolo-performance-metrics/"&gt;YOLO Performance Metrics&lt;/a&gt; for details. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val segment data=coco.yaml device=0&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over COCO val images using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val segment data=coco.yaml batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Classification (ImageNet)&lt;/summary&gt; 
 &lt;p&gt;Consult the &lt;a href="https://docs.ultralytics.com/tasks/classify/"&gt;Classification Docs&lt;/a&gt; for usage examples. These models are trained on &lt;a href="https://docs.ultralytics.com/datasets/classify/imagenet/"&gt;ImageNet&lt;/a&gt;, covering 1000 classes.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;acc&lt;br /&gt;&lt;sup&gt;top1&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;acc&lt;br /&gt;&lt;sup&gt;top5&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B) at 224&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt"&gt;YOLO11n-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;70.0&lt;/td&gt; 
    &lt;td&gt;89.4&lt;/td&gt; 
    &lt;td&gt;5.0 ¬± 0.3&lt;/td&gt; 
    &lt;td&gt;1.1 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;1.6&lt;/td&gt; 
    &lt;td&gt;0.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-cls.pt"&gt;YOLO11s-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;75.4&lt;/td&gt; 
    &lt;td&gt;92.7&lt;/td&gt; 
    &lt;td&gt;7.9 ¬± 0.2&lt;/td&gt; 
    &lt;td&gt;1.3 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;5.5&lt;/td&gt; 
    &lt;td&gt;1.6&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-cls.pt"&gt;YOLO11m-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;77.3&lt;/td&gt; 
    &lt;td&gt;93.9&lt;/td&gt; 
    &lt;td&gt;17.2 ¬± 0.4&lt;/td&gt; 
    &lt;td&gt;2.0 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;10.4&lt;/td&gt; 
    &lt;td&gt;5.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-cls.pt"&gt;YOLO11l-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;78.3&lt;/td&gt; 
    &lt;td&gt;94.3&lt;/td&gt; 
    &lt;td&gt;23.2 ¬± 0.3&lt;/td&gt; 
    &lt;td&gt;2.8 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;12.9&lt;/td&gt; 
    &lt;td&gt;6.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-cls.pt"&gt;YOLO11x-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;79.5&lt;/td&gt; 
    &lt;td&gt;94.9&lt;/td&gt; 
    &lt;td&gt;41.4 ¬± 0.9&lt;/td&gt; 
    &lt;td&gt;3.8 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;28.4&lt;/td&gt; 
    &lt;td&gt;13.7&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;acc&lt;/strong&gt; values represent model accuracy on the &lt;a href="https://www.image-net.org/"&gt;ImageNet&lt;/a&gt; dataset validation set. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val classify data=path/to/ImageNet device=0&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over ImageNet val images using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val classify data=path/to/ImageNet batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Pose (COCO)&lt;/summary&gt; 
 &lt;p&gt;See the &lt;a href="https://docs.ultralytics.com/tasks/pose/"&gt;Pose Estimation Docs&lt;/a&gt; for usage examples. These models are trained on &lt;a href="https://docs.ultralytics.com/datasets/pose/coco/"&gt;COCO-Pose&lt;/a&gt;, focusing on the 'person' class.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;pose&lt;br /&gt;50-95&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;pose&lt;br /&gt;50&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt"&gt;YOLO11n-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;50.0&lt;/td&gt; 
    &lt;td&gt;81.0&lt;/td&gt; 
    &lt;td&gt;52.4 ¬± 0.5&lt;/td&gt; 
    &lt;td&gt;1.7 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;2.9&lt;/td&gt; 
    &lt;td&gt;7.6&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-pose.pt"&gt;YOLO11s-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;58.9&lt;/td&gt; 
    &lt;td&gt;86.3&lt;/td&gt; 
    &lt;td&gt;90.5 ¬± 0.6&lt;/td&gt; 
    &lt;td&gt;2.6 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;9.9&lt;/td&gt; 
    &lt;td&gt;23.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-pose.pt"&gt;YOLO11m-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;64.9&lt;/td&gt; 
    &lt;td&gt;89.4&lt;/td&gt; 
    &lt;td&gt;187.3 ¬± 0.8&lt;/td&gt; 
    &lt;td&gt;4.9 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;20.9&lt;/td&gt; 
    &lt;td&gt;71.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-pose.pt"&gt;YOLO11l-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;66.1&lt;/td&gt; 
    &lt;td&gt;89.9&lt;/td&gt; 
    &lt;td&gt;247.7 ¬± 1.1&lt;/td&gt; 
    &lt;td&gt;6.4 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;26.2&lt;/td&gt; 
    &lt;td&gt;90.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-pose.pt"&gt;YOLO11x-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;69.5&lt;/td&gt; 
    &lt;td&gt;91.1&lt;/td&gt; 
    &lt;td&gt;488.0 ¬± 13.9&lt;/td&gt; 
    &lt;td&gt;12.1 ¬± 0.2&lt;/td&gt; 
    &lt;td&gt;58.8&lt;/td&gt; 
    &lt;td&gt;203.3&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;val&lt;/sup&gt;&lt;/strong&gt; values are for single-model single-scale on the &lt;a href="https://docs.ultralytics.com/datasets/pose/coco/"&gt;COCO Keypoints val2017&lt;/a&gt; dataset. See &lt;a href="https://docs.ultralytics.com/guides/yolo-performance-metrics/"&gt;YOLO Performance Metrics&lt;/a&gt; for details. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val pose data=coco-pose.yaml device=0&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over COCO val images using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val pose data=coco-pose.yaml batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Oriented Bounding Boxes (DOTAv1)&lt;/summary&gt; 
 &lt;p&gt;Check the &lt;a href="https://docs.ultralytics.com/tasks/obb/"&gt;OBB Docs&lt;/a&gt; for usage examples. These models are trained on &lt;a href="https://docs.ultralytics.com/datasets/obb/dota-v2/#dota-v10/"&gt;DOTAv1&lt;/a&gt;, including 15 classes.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;test&lt;br /&gt;50&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-obb.pt"&gt;YOLO11n-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;78.4&lt;/td&gt; 
    &lt;td&gt;117.6 ¬± 0.8&lt;/td&gt; 
    &lt;td&gt;4.4 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;2.7&lt;/td&gt; 
    &lt;td&gt;17.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-obb.pt"&gt;YOLO11s-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;79.5&lt;/td&gt; 
    &lt;td&gt;219.4 ¬± 4.0&lt;/td&gt; 
    &lt;td&gt;5.1 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;9.7&lt;/td&gt; 
    &lt;td&gt;57.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-obb.pt"&gt;YOLO11m-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;80.9&lt;/td&gt; 
    &lt;td&gt;562.8 ¬± 2.9&lt;/td&gt; 
    &lt;td&gt;10.1 ¬± 0.4&lt;/td&gt; 
    &lt;td&gt;20.9&lt;/td&gt; 
    &lt;td&gt;183.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-obb.pt"&gt;YOLO11l-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;81.0&lt;/td&gt; 
    &lt;td&gt;712.5 ¬± 5.0&lt;/td&gt; 
    &lt;td&gt;13.5 ¬± 0.6&lt;/td&gt; 
    &lt;td&gt;26.2&lt;/td&gt; 
    &lt;td&gt;232.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-obb.pt"&gt;YOLO11x-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;81.3&lt;/td&gt; 
    &lt;td&gt;1408.6 ¬± 7.7&lt;/td&gt; 
    &lt;td&gt;28.6 ¬± 1.0&lt;/td&gt; 
    &lt;td&gt;58.8&lt;/td&gt; 
    &lt;td&gt;520.2&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;test&lt;/sup&gt;&lt;/strong&gt; values are for single-model multiscale performance on the &lt;a href="https://captain-whu.github.io/DOTA/dataset.html"&gt;DOTAv1 test set&lt;/a&gt;. &lt;br /&gt;Reproduce by &lt;code&gt;yolo val obb data=DOTAv1.yaml device=0 split=test&lt;/code&gt; and submit merged results to the &lt;a href="https://captain-whu.github.io/DOTA/evaluation.html"&gt;DOTA evaluation server&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over &lt;a href="https://docs.ultralytics.com/datasets/obb/dota-v2/#dota-v10"&gt;DOTAv1 val images&lt;/a&gt; using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce by &lt;code&gt;yolo val obb data=DOTAv1.yaml batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üß© Integrations&lt;/h2&gt; 
&lt;p&gt;Our key integrations with leading AI platforms extend the functionality of Ultralytics' offerings, enhancing tasks like dataset labeling, training, visualization, and model management. Discover how Ultralytics, in collaboration with partners like &lt;a href="https://docs.ultralytics.com/integrations/weights-biases/"&gt;Weights &amp;amp; Biases&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/integrations/comet/"&gt;Comet ML&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/integrations/roboflow/"&gt;Roboflow&lt;/a&gt;, and &lt;a href="https://docs.ultralytics.com/integrations/openvino/"&gt;Intel OpenVINO&lt;/a&gt;, can optimize your AI workflow. Explore more at &lt;a href="https://docs.ultralytics.com/integrations/"&gt;Ultralytics Integrations&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://docs.ultralytics.com/integrations/" target="_blank"&gt; &lt;img width="100%" src="https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png" alt="Ultralytics active learning integrations" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.ultralytics.com/hub"&gt; &lt;img src="https://github.com/ultralytics/assets/raw/main/partners/logo-ultralytics-hub.png" width="10%" alt="Ultralytics HUB logo" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="15%" height="0" alt="space" /&gt; 
 &lt;a href="https://docs.ultralytics.com/integrations/weights-biases/"&gt; &lt;img src="https://github.com/ultralytics/assets/raw/main/partners/logo-wb.png" width="10%" alt="Weights &amp;amp; Biases logo" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="15%" height="0" alt="space" /&gt; 
 &lt;a href="https://docs.ultralytics.com/integrations/comet/"&gt; &lt;img src="https://github.com/ultralytics/assets/raw/main/partners/logo-comet.png" width="10%" alt="Comet ML logo" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="15%" height="0" alt="space" /&gt; 
 &lt;a href="https://docs.ultralytics.com/integrations/neural-magic/"&gt; &lt;img src="https://github.com/ultralytics/assets/raw/main/partners/logo-neuralmagic.png" width="10%" alt="Neural Magic logo" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Ultralytics HUB üåü&lt;/th&gt; 
   &lt;th align="center"&gt;Weights &amp;amp; Biases&lt;/th&gt; 
   &lt;th align="center"&gt;Comet&lt;/th&gt; 
   &lt;th align="center"&gt;Neural Magic&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Streamline YOLO workflows: Label, train, and deploy effortlessly with &lt;a href="https://hub.ultralytics.com/"&gt;Ultralytics HUB&lt;/a&gt;. Try now!&lt;/td&gt; 
   &lt;td align="center"&gt;Track experiments, hyperparameters, and results with &lt;a href="https://docs.ultralytics.com/integrations/weights-biases/"&gt;Weights &amp;amp; Biases&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="center"&gt;Free forever, &lt;a href="https://docs.ultralytics.com/integrations/comet/"&gt;Comet ML&lt;/a&gt; lets you save YOLO models, resume training, and interactively visualize predictions.&lt;/td&gt; 
   &lt;td align="center"&gt;Run YOLO inference up to 6x faster with &lt;a href="https://docs.ultralytics.com/integrations/neural-magic/"&gt;Neural Magic DeepSparse&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üåü Ultralytics HUB&lt;/h2&gt; 
&lt;p&gt;Experience seamless AI with &lt;a href="https://hub.ultralytics.com/"&gt;Ultralytics HUB&lt;/a&gt;, the all-in-one platform for data visualization, training YOLO models, and deployment‚Äîno coding required. Transform images into actionable insights and bring your AI visions to life effortlessly using our cutting-edge platform and user-friendly &lt;a href="https://www.ultralytics.com/app-install"&gt;Ultralytics App&lt;/a&gt;. Start your journey for &lt;strong&gt;Free&lt;/strong&gt; today!&lt;/p&gt; 
&lt;a href="https://www.ultralytics.com/hub" target="_blank"&gt; &lt;img width="100%" src="https://github.com/ultralytics/assets/raw/main/im/ultralytics-hub.png" alt="Ultralytics HUB preview image" /&gt;&lt;/a&gt; 
&lt;h2&gt;ü§ù Contribute&lt;/h2&gt; 
&lt;p&gt;We thrive on community collaboration! Ultralytics YOLO wouldn't be the SOTA framework it is without contributions from developers like you. Please see our &lt;a href="https://docs.ultralytics.com/help/contributing/"&gt;Contributing Guide&lt;/a&gt; to get started. We also welcome your feedback‚Äîshare your experience by completing our &lt;a href="https://www.ultralytics.com/survey?utm_source=github&amp;amp;utm_medium=social&amp;amp;utm_campaign=Survey"&gt;Survey&lt;/a&gt;. A huge &lt;strong&gt;Thank You&lt;/strong&gt; üôè to everyone who contributes!&lt;/p&gt; 
&lt;!-- SVG image from https://opencollective.com/ultralytics/contributors.svg?width=1280 --&gt; 
&lt;p&gt;&lt;a href="https://github.com/ultralytics/ultralytics/graphs/contributors"&gt;&lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/im/image-contributors.png" alt="Ultralytics open-source contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We look forward to your contributions to help make the Ultralytics ecosystem even better!&lt;/p&gt; 
&lt;h2&gt;üìú License&lt;/h2&gt; 
&lt;p&gt;Ultralytics offers two licensing options to suit different needs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AGPL-3.0 License&lt;/strong&gt;: This &lt;a href="https://opensource.org/license"&gt;OSI-approved&lt;/a&gt; open-source license is perfect for students, researchers, and enthusiasts. It encourages open collaboration and knowledge sharing. See the &lt;a href="https://github.com/ultralytics/ultralytics/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for full details.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ultralytics Enterprise License&lt;/strong&gt;: Designed for commercial use, this license allows for the seamless integration of Ultralytics software and AI models into commercial products and services, bypassing the open-source requirements of AGPL-3.0. If your use case involves commercial deployment, please contact us via &lt;a href="https://www.ultralytics.com/license"&gt;Ultralytics Licensing&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìû Contact&lt;/h2&gt; 
&lt;p&gt;For bug reports and feature requests related to Ultralytics software, please visit &lt;a href="https://github.com/ultralytics/ultralytics/issues"&gt;GitHub Issues&lt;/a&gt;. For questions, discussions, and community support, join our active communities on &lt;a href="https://discord.com/invite/ultralytics"&gt;Discord&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/ultralytics/"&gt;Reddit&lt;/a&gt;, and the &lt;a href="https://community.ultralytics.com/"&gt;Ultralytics Community Forums&lt;/a&gt;. We're here to help with all things Ultralytics!&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-github.png" width="3%" alt="Ultralytics GitHub" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://www.linkedin.com/company/ultralytics/"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-linkedin.png" width="3%" alt="Ultralytics LinkedIn" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://twitter.com/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-twitter.png" width="3%" alt="Ultralytics Twitter" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://youtube.com/ultralytics?sub_confirmation=1"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-youtube.png" width="3%" alt="Ultralytics YouTube" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://www.tiktok.com/@ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-tiktok.png" width="3%" alt="Ultralytics TikTok" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://ultralytics.com/bilibili"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-bilibili.png" width="3%" alt="Ultralytics BiliBili" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://discord.com/invite/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-discord.png" width="3%" alt="Ultralytics Discord" /&gt;&lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>bytedance/Dolphin</title>
      <link>https://github.com/bytedance/Dolphin</link>
      <description>&lt;p&gt;The official repo for ‚ÄúDolphin: Document Image Parsing via Heterogeneous Anchor Prompting‚Äù, ACL, 2025.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/dolphin.png" width="300" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://arxiv.org/abs/2505.14059"&gt; &lt;img src="https://img.shields.io/badge/Paper-arXiv-red" /&gt; &lt;/a&gt; 
 &lt;a href="https://huggingface.co/ByteDance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/HuggingFace-Dolphin-yellow" /&gt; &lt;/a&gt; 
 &lt;a href="https://modelscope.cn/models/ByteDance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/ModelScope-Dolphin-purple" /&gt; &lt;/a&gt; 
 &lt;a href="https://huggingface.co/spaces/ByteDance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/Demo-Dolphin-blue" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/bytedance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/Code-Github-green" /&gt; &lt;/a&gt; 
 &lt;a href="https://opensource.org/licenses/MIT"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-lightgray" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/demo.gif" width="800" /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting&lt;/h1&gt; 
&lt;p&gt;Dolphin (&lt;strong&gt;Do&lt;/strong&gt;cument Image &lt;strong&gt;P&lt;/strong&gt;arsing via &lt;strong&gt;H&lt;/strong&gt;eterogeneous Anchor Prompt&lt;strong&gt;in&lt;/strong&gt;g) is a novel multimodal document image parsing model following an analyze-then-parse paradigm. This repository contains the demo code and pre-trained models for Dolphin.&lt;/p&gt; 
&lt;h2&gt;üìë Overview&lt;/h2&gt; 
&lt;p&gt;Document image parsing is challenging due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables. Dolphin addresses these challenges through a two-stage approach:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Stage 1&lt;/strong&gt;: Comprehensive page-level layout analysis by generating element sequence in natural reading order&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß© Stage 2&lt;/strong&gt;: Efficient parallel parsing of document elements using heterogeneous anchors and task-specific prompts&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/framework.png" width="680" /&gt; 
&lt;/div&gt; 
&lt;p&gt;Dolphin achieves promising performance across diverse page-level and element-level parsing tasks while ensuring superior efficiency through its lightweight architecture and parallel parsing mechanism.&lt;/p&gt; 
&lt;h2&gt;üöÄ Demo&lt;/h2&gt; 
&lt;p&gt;Try our demo on &lt;a href="http://115.190.42.15:8888/dolphin/"&gt;Demo-Dolphin&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìÖ Changelog&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.07.10&lt;/strong&gt; Released the &lt;em&gt;Fox-Page Benchmark&lt;/em&gt;, a manually refined subset of the original &lt;a href="https://github.com/ucaslcl/Fox"&gt;Fox dataset&lt;/a&gt;. Download via: &lt;a href="https://pan.baidu.com/share/init?surl=t746ULp6iU5bUraVrPlMSw&amp;amp;pwd=fox1"&gt;Baidu Yun&lt;/a&gt; | &lt;a href="https://drive.google.com/file/d/1yZQZqI34QCqvhB4Tmdl3X_XEvYvQyP0q/view?usp=sharing"&gt;Google Drive&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.06.30&lt;/strong&gt; Added &lt;a href="https://github.com/bytedance/Dolphin/raw/master/deployment/tensorrt_llm/ReadMe.md"&gt;TensorRT-LLM support&lt;/a&gt; for accelerated inferenceÔºÅ&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.06.27&lt;/strong&gt; Added &lt;a href="https://github.com/bytedance/Dolphin/raw/master/deployment/vllm/ReadMe.md"&gt;vLLM support&lt;/a&gt; for accelerated inferenceÔºÅ&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.06.13&lt;/strong&gt; Added multi-page PDF document parsing capability.&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.05.21&lt;/strong&gt; Our demo is released at &lt;a href="http://115.190.42.15:8888/dolphin/"&gt;link&lt;/a&gt;. Check it out!&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.05.20&lt;/strong&gt; The pretrained model and inference code of Dolphin are released.&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.05.16&lt;/strong&gt; Our paper has been accepted by ACL 2025. Paper link: &lt;a href="https://arxiv.org/abs/2505.14059"&gt;arXiv&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ†Ô∏è Installation&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ByteDance/Dolphin.git
cd Dolphin
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install the dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Download the pre-trained models using one of the following options:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Option A: Original Model Format (config-based)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Download from &lt;a href="https://pan.baidu.com/s/15zcARoX0CTOHKbW8bFZovQ?pwd=9rpx"&gt;Baidu Yun&lt;/a&gt; or &lt;a href="https://drive.google.com/drive/folders/1PQJ3UutepXvunizZEw-uGaQ0BCzf-mie?usp=sharing"&gt;Google Drive&lt;/a&gt; and put them in the &lt;code&gt;./checkpoints&lt;/code&gt; folder.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Option B: Hugging Face Model Format&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Visit our Huggingface &lt;a href="https://huggingface.co/ByteDance/Dolphin"&gt;model card&lt;/a&gt;, or download model by:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Download the model from Hugging Face Hub
git lfs install
git clone https://huggingface.co/ByteDance/Dolphin ./hf_model
# Or use the Hugging Face CLI
pip install huggingface_hub
huggingface-cli download ByteDance/Dolphin --local-dir ./hf_model
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;‚ö° Inference&lt;/h2&gt; 
&lt;p&gt;Dolphin provides two inference frameworks with support for two parsing granularities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Page-level Parsing&lt;/strong&gt;: Parse the entire document page into a structured JSON and Markdown format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Element-level Parsing&lt;/strong&gt;: Parse individual document elements (text, table, formula)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìÑ Page-level Parsing&lt;/h3&gt; 
&lt;h4&gt;Using Original Framework (config-based)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single document image
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs/page_1.jpeg --save_dir ./results

# Process a single document pdf
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs/page_6.pdf --save_dir ./results

# Process all documents in a directory
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs --save_dir ./results

# Process with custom batch size for parallel element decoding
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs --save_dir ./results --max_batch_size 8
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Hugging Face Framework&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single document image
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs/page_1.jpeg --save_dir ./results

# Process a single document pdf
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs/page_6.pdf --save_dir ./results

# Process all documents in a directory
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs --save_dir ./results

# Process with custom batch size for parallel element decoding
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs --save_dir ./results --max_batch_size 16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üß© Element-level Parsing&lt;/h3&gt; 
&lt;h4&gt;Using Original Framework (config-based)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single table image
python demo_element.py --config ./config/Dolphin.yaml --input_path ./demo/element_imgs/table_1.jpeg --element_type table

# Process a single formula image
python demo_element.py --config ./config/Dolphin.yaml --input_path ./demo/element_imgs/line_formula.jpeg --element_type formula

# Process a single text paragraph image
python demo_element.py --config ./config/Dolphin.yaml --input_path ./demo/element_imgs/para_1.jpg --element_type text
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Hugging Face Framework&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single table image
python demo_element_hf.py --model_path ./hf_model --input_path ./demo/element_imgs/table_1.jpeg --element_type table

# Process a single formula image
python demo_element_hf.py --model_path ./hf_model --input_path ./demo/element_imgs/line_formula.jpeg --element_type formula

# Process a single text paragraph image
python demo_element_hf.py --model_path ./hf_model --input_path ./demo/element_imgs/para_1.jpg --element_type text
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üåü Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîÑ Two-stage analyze-then-parse approach based on a single VLM&lt;/li&gt; 
 &lt;li&gt;üìä Promising performance on document parsing tasks&lt;/li&gt; 
 &lt;li&gt;üîç Natural reading order element sequence generation&lt;/li&gt; 
 &lt;li&gt;üß© Heterogeneous anchor prompting for different document elements&lt;/li&gt; 
 &lt;li&gt;‚è±Ô∏è Efficient parallel parsing mechanism&lt;/li&gt; 
 &lt;li&gt;ü§ó Support for Hugging Face Transformers for easier integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÆ Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Call for Bad Cases:&lt;/strong&gt; If you have encountered any cases where the model performs poorly, we would greatly appreciate it if you could share them in the issue. We are continuously working to optimize and improve the model.&lt;/p&gt; 
&lt;h2&gt;üíñ Acknowledgement&lt;/h2&gt; 
&lt;p&gt;We would like to acknowledge the following open-source projects that provided inspiration and reference for this work:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/clovaai/donut/"&gt;Donut&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebookresearch/nougat"&gt;Nougat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Ucas-HaoranWei/GOT-OCR2.0"&gt;GOT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/MinerU/tree/master"&gt;MinerU&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Swin-Transformer"&gt;Swin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/transformers"&gt;Hugging Face Transformers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìù Citation&lt;/h2&gt; 
&lt;p&gt;If you find this code useful for your research, please use the following BibTeX entry.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{feng2025dolphin,
  title={Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting},
  author={Feng, Hao and Wei, Shu and Fei, Xiang and Shi, Wei and Han, Yingdong and Liao, Lei and Lu, Jinghui and Wu, Binghong and Liu, Qi and Lin, Chunhui and others},
  journal={arXiv preprint arXiv:2505.14059},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#bytedance/Dolphin&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=bytedance/Dolphin&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LadybirdBrowser/ladybird</title>
      <link>https://github.com/LadybirdBrowser/ladybird</link>
      <description>&lt;p&gt;Truly independent web browser&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ladybird&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://ladybird.org"&gt;Ladybird&lt;/a&gt; is a truly independent web browser, using a novel engine based on web standards.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Ladybird is in a pre-alpha state, and only suitable for use by developers&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;We aim to build a complete, usable browser for the modern web.&lt;/p&gt; 
&lt;p&gt;Ladybird uses a multi-process architecture with a main UI process, several WebContent renderer processes, an ImageDecoder process, and a RequestServer process.&lt;/p&gt; 
&lt;p&gt;Image decoding and network connections are done out of process to be more robust against malicious content. Each tab has its own renderer process, which is sandboxed from the rest of the system.&lt;/p&gt; 
&lt;p&gt;At the moment, many core library support components are inherited from SerenityOS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LibWeb: Web rendering engine&lt;/li&gt; 
 &lt;li&gt;LibJS: JavaScript engine&lt;/li&gt; 
 &lt;li&gt;LibWasm: WebAssembly implementation&lt;/li&gt; 
 &lt;li&gt;LibCrypto/LibTLS: Cryptography primitives and Transport Layer Security&lt;/li&gt; 
 &lt;li&gt;LibHTTP: HTTP/1.1 client&lt;/li&gt; 
 &lt;li&gt;LibGfx: 2D Graphics Library, Image Decoding and Rendering&lt;/li&gt; 
 &lt;li&gt;LibUnicode: Unicode and locale support&lt;/li&gt; 
 &lt;li&gt;LibMedia: Audio and video playback&lt;/li&gt; 
 &lt;li&gt;LibCore: Event loop, OS abstraction layer&lt;/li&gt; 
 &lt;li&gt;LibIPC: Inter-process communication&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How do I build and run this?&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/BuildInstructionsLadybird.md"&gt;build instructions&lt;/a&gt; for information on how to build Ladybird.&lt;/p&gt; 
&lt;p&gt;Ladybird runs on Linux, macOS, Windows (with WSL2), and many other *Nixes.&lt;/p&gt; 
&lt;h2&gt;How do I read the documentation?&lt;/h2&gt; 
&lt;p&gt;Code-related documentation can be found in the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/"&gt;documentation&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h2&gt;Get in touch and participate!&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href="https://discord.gg/nvfjVJ4Svh"&gt;our Discord server&lt;/a&gt; to participate in development discussion.&lt;/p&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/GettingStartedContributing.md"&gt;Getting started contributing&lt;/a&gt; if you plan to contribute to Ladybird for the first time.&lt;/p&gt; 
&lt;p&gt;Before opening an issue, please see the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md#issue-policy"&gt;issue policy&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/ISSUES.md"&gt;detailed issue-reporting guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The full contribution guidelines can be found in &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Ladybird is licensed under a 2-clause BSD license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aliasrobotics/cai</title>
      <link>https://github.com/aliasrobotics/cai</link>
      <description>&lt;p&gt;Cybersecurity AI (CAI), the framework for AI Security&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;)&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://github.com/aliasrobotics/CAI"&gt; &lt;img width="100%" src="https://github.com/aliasrobotics/cai/raw/main/media/cai.png" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/cai-framework"&gt;&lt;img src="https://badge.fury.io/py/cai-framework.svg?sanitize=true" alt="version" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/cai-framework"&gt;&lt;img src="https://static.pepy.tech/badge/cai-framework" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/Linux-Supported-brightgreen?logo=linux&amp;amp;logoColor=white" alt="Linux" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/OS%20X-Supported-brightgreen?logo=apple&amp;amp;logoColor=white" alt="OS X" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/Windows-Supported-brightgreen?logo=windows&amp;amp;logoColor=white" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/Android-Supported-brightgreen?logo=android&amp;amp;logoColor=white" alt="Android" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/fnUFcTaQAC"&gt;&lt;img src="https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2508.21669"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.21669-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2509.14096"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14096-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2509.14139"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14139-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Cybersecurity AI (CAI) is a lightweight, open-source framework that empowers security professionals to build and deploy AI-powered offensive and defensive automation. CAI is the &lt;em&gt;de facto&lt;/em&gt; framework for AI Security, already used by thousands of individual users and hundreds of organizations. Whether you're a security researcher, ethical hacker, IT professional, or organization looking to enhance your security posture, CAI provides the building blocks to create specialized AI agents that can assist with mitigation, vulnerability discovery, exploitation, and security assessment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;300+ AI Models&lt;/strong&gt;: Support for OpenAI, Anthropic, DeepSeek, Ollama, and more&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Built-in Security Tools&lt;/strong&gt;: Ready-to-use tools for reconnaissance, exploitation, and privilege escalation&lt;/li&gt; 
 &lt;li&gt;üèÜ &lt;strong&gt;Battle-tested&lt;/strong&gt;: Proven in HackTheBox CTFs, bug bounties, and real-world security &lt;a href="https://aliasrobotics.com/case-studies-robot-cybersecurity.php"&gt;case studies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üéØ &lt;strong&gt;Agent-based Architecture&lt;/strong&gt;: Modular framework design to build specialized agents for different security tasks&lt;/li&gt; 
 &lt;li&gt;üõ°Ô∏è &lt;strong&gt;Guardrails Protection&lt;/strong&gt;: Built-in defenses against prompt injection and dangerous command execution&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Research-oriented&lt;/strong&gt;: Research foundation to democratize cybersecurity AI for the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Read the technical report: &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;CAI: An Open, Bug Bounty-Ready Cybersecurity AI&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;For further readings, refer to our &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-impact"&gt;impact&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#citation"&gt;CAI citation&lt;/a&gt; sections.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-ecoforest.php"&gt;&lt;code&gt;OT&lt;/code&gt; - CAI and alias0 on: Ecoforest Heat Pumps&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mir.php"&gt;&lt;code&gt;Robotics&lt;/code&gt; - CAI and alias0 on: Mobile Industrial Robots (MiR)&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CAI discovers critical vulnerability in Ecoforest heat pumps allowing unauthorized remote access and potential catastrophic failures. AI-powered security testing reveals exposed credentials and DES encryption weaknesses affecting all of their deployed units across Europe.&lt;/td&gt; 
   &lt;td&gt;CAI-powered security testing of MiR (Mobile Industrial Robot) platform through automated ROS message injection attacks. This study demonstrates how AI-driven vulnerability discovery can expose unauthorized access to robot control systems and alarm triggers.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-ecoforest.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-ecoforest.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mir.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-mir-cai.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-mercado-libre.php"&gt;&lt;code&gt;IT&lt;/code&gt; (Web) - CAI and alias0 on: Mercado Libre's e-commerce&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mqtt-broker.php"&gt;&lt;code&gt;OT&lt;/code&gt; - CAI and alias0 on: MQTT broker&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CAI-powered API vulnerability discovery at Mercado Libre through automated enumeration attacks. This study demonstrates how AI-driven security testing can expose user data exposure risks in e-commerce platforms at scale.&lt;/td&gt; 
   &lt;td&gt;CAI-powered testing exposed critical flaws in an MQTT broker within a Dockerized OT network. Without authentication, CAI subscribed to temperature and humidity topics and injected false values, corrupting data shown in Grafana dashboards.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-mercado-libre.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-mercado-libre.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mqtt-broker.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-mqtt-broker-cai.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;span&gt;‚ö†&lt;/span&gt; CAI is in active development, so don't expect it to work flawlessly. Instead, contribute by raising an issue or &lt;a href="https://github.com/aliasrobotics/cai/pulls"&gt;sending a PR&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;Access to this library and the use of information, materials (or portions thereof), is &lt;strong&gt;&lt;u&gt;not intended&lt;/u&gt;, and is &lt;u&gt;prohibited&lt;/u&gt;, where such access or use violates applicable laws or regulations&lt;/strong&gt;. By no means the authors encourage or promote the unauthorized tampering with running systems. This can cause serious human harm and material damages.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;By no means the authors of CAI encourage or promote the unauthorized tampering with compute systems. Please don't use the source code in here for cybercrime. &lt;u&gt;Pentest for good instead&lt;/u&gt;&lt;/em&gt;. By downloading, using, or modifying this source code, you agree to the terms of the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; and the limitations outlined in the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/DISCLAIMER"&gt;&lt;code&gt;DISCLAIMER&lt;/code&gt;&lt;/a&gt; file.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;span&gt;üîñ&lt;/span&gt; Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#cybersecurity-ai-cai"&gt;Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#bookmark-table-of-contents"&gt;&lt;span&gt;üîñ&lt;/span&gt; Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-impact"&gt;üéØ Impact&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-competitions-and-challenges"&gt;üèÜ Competitions and challenges&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-research-impact"&gt;üìä Research Impact&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-research-products-cybersecurity-ai"&gt;üìö Research products: &lt;code&gt;Cybersecurity AI&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#pocs"&gt;PoCs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#motivation"&gt;Motivation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#bust_in_silhouette-why-cai"&gt;&lt;span&gt;üë§&lt;/span&gt; Why CAI?&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#ethical-principles-behind-cai"&gt;Ethical principles behind CAI&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#closed-source-alternatives"&gt;Closed-source alternatives&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#learn---cai-fluency"&gt;Learn - &lt;code&gt;CAI&lt;/code&gt; Fluency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#nut_and_bolt-install"&gt;&lt;span&gt;üî©&lt;/span&gt; Install&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#os-x"&gt;OS X&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#ubuntu-2404"&gt;Ubuntu 24.04&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#ubuntu-2004"&gt;Ubuntu 20.04&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#windows-wsl"&gt;Windows WSL&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#android"&gt;Android&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#nut_and_bolt-setup-env-file"&gt;&lt;span&gt;üî©&lt;/span&gt; Setup &lt;code&gt;.env&lt;/code&gt; file&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-custom-openai-base-url-support"&gt;üîπ Custom OpenAI Base URL Support&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#triangular_ruler-architecture"&gt;&lt;span&gt;üìê&lt;/span&gt; Architecture:&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-agent"&gt;üîπ Agent&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-tools"&gt;üîπ Tools&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-handoffs"&gt;üîπ Handoffs&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-patterns"&gt;üîπ Patterns&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-turns-and-interactions"&gt;üîπ Turns and Interactions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-tracing"&gt;üîπ Tracing&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-guardrails"&gt;üîπ Guardrails&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-human-in-the-loop-hitl"&gt;üîπ Human-In-The-Loop (HITL)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#rocket-quickstart"&gt;&lt;span&gt;üöÄ&lt;/span&gt; Quickstart&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#environment-variables"&gt;Environment Variables&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#openrouter-integration"&gt;OpenRouter Integration&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#mcp"&gt;MCP&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#development"&gt;Development&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#contributions"&gt;Contributions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#optional-requirements-caiextensions"&gt;Optional Requirements: caiextensions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#information_source-usage-data-collection"&gt;&lt;span&gt;‚Ñπ&lt;/span&gt; Usage Data Collection&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#reproduce-ci-setup-locally"&gt;Reproduce CI-Setup locally&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#academic-collaborations"&gt;Academic Collaborations&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéØ Impact&lt;/h2&gt; 
&lt;h3&gt;üèÜ Competitions and challenges&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_90_Spain_(5_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_50_Spain_(6_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_30_Spain_(7_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_500_World_(7_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-top_1_(AIs)_world-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-top_1_Spain-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-top_20_World-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-750_$-yellow.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://lu.ma/roboticshack?tk=RuryKF"&gt;&lt;img src="https://img.shields.io/badge/Mistral_AI_Robotics_Hackathon-2500_$-yellow.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üìä Research Impact&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Pioneered LLM-powered AI Security with PentestGPT, establishing the foundation for the &lt;code&gt;Cybersecurity AI&lt;/code&gt; research domain &lt;a href="https://arxiv.org/pdf/2308.06782"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2308.06782-4a9b8e.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Established the &lt;code&gt;Cybersecurity AI&lt;/code&gt; research line with &lt;strong&gt;6 papers and technical reports&lt;/strong&gt;, with active research collaborations &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-7dd3c0.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-52a896.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2508.21669"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.21669-85e0d1.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2509.14096"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14096-3e8b7a.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2509.14139"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14139-6bc7b5.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Demonstrated &lt;strong&gt;3,600√ó performance improvement&lt;/strong&gt; over human penetration testers in standardized CTF benchmark evaluations &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Identified &lt;strong&gt;CVSS 4.3-7.5 severity vulnerabilities&lt;/strong&gt; in production systems through automated security assessment &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Democratization of AI-empowered vulnerability research&lt;/strong&gt;: CAI enables both non-security domain experts and experienced researchers to conduct more efficient vulnerability discovery, expanding the security research community while empowering small and medium enterprises to conduct autonomous security assessments &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Systematic evaluation of large language models&lt;/strong&gt; across both proprietary and open-weight architectures, revealing &lt;u&gt;substantial gaps&lt;/u&gt; between vendor-reported capabilities and empirical cybersecurity performance metrics &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Established the &lt;strong&gt;autonomy levels in cybersecurity&lt;/strong&gt; and argued about autonomy vs automation in the field &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-7dd3c0.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Collaborative research initiatives&lt;/strong&gt; with international academic institutions focused on developing cybersecurity education curricula and training methodologies &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-52a896.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Contributed a comprehensive defense framework against prompt injection in AI security agents&lt;/strong&gt;: developed and empirically validated a multi-layered defense system that addresses the identified prompt injection issues &lt;a href="https://arxiv.org/abs/2508.21669"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.21669-85e0d1.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Explord the Cybersecurity of Humanoid Robots with CAI and identified new attack vectors showing how it &lt;code&gt;(a)&lt;/code&gt; operates simultaneously as a covert surveillance node and &lt;code&gt;(b)&lt;/code&gt; can be purposed as an active cyber operations platform &lt;a href="https://arxiv.org/abs/2509.14096"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14096-3e8b7a.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2509.14139"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14139-6bc7b5.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìö Research products: &lt;code&gt;Cybersecurity AI&lt;/code&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;CAI, An Open, Bug Bounty-Ready Cybersecurity AI &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;The Dangerous Gap Between Automation and Autonomy &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-7dd3c0.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;CAI Fluency, A Framework for Cybersecurity AI Fluency &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-52a896.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://aliasrobotics.com/img/paper-cai.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.arxiv.org/pdf/2506.23592"&gt;&lt;img src="https://aliasrobotics.com/img/cai_automation_vs_autonomy.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2508.13588"&gt;&lt;img src="https://aliasrobotics.com/img/cai_fluency_cover.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Hacking the AI Hackers via Prompt Injection &lt;a href="https://arxiv.org/abs/2508.21669"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.21669-85e0d1.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;Humanoid Robots as Attack Vectors &lt;a href="https://arxiv.org/abs/2509.14139"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14139-6bc7b5.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;The Cybersecurity of a Humanoid Robot &lt;a href="https://arxiv.org/abs/2509.14096"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14096-3e8b7a.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2508.21669"&gt;&lt;img src="https://aliasrobotics.com/img/aihackers.jpeg" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2509.14139"&gt;&lt;img src="https://aliasrobotics.com/img/humanoids-cover.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2509.14096"&gt;&lt;img src="https://aliasrobotics.com/img/humanoid.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;PoCs&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;CAI with &lt;code&gt;alias0&lt;/code&gt; on ROS message injection attacks in MiR-100 robot&lt;/th&gt; 
   &lt;th&gt;CAI with &lt;code&gt;alias0&lt;/code&gt; on API vulnerability discovery at Mercado Libre&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh"&gt;&lt;img src="https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww"&gt;&lt;img src="https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;CAI on JWT@PortSwigger CTF ‚Äî Cybersecurity AI&lt;/th&gt; 
   &lt;th&gt;CAI on HackableII Boot2Root CTF ‚Äî Cybersecurity AI&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/713487"&gt;&lt;img src="https://asciinema.org/a/713487.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/713485"&gt;&lt;img src="https://asciinema.org/a/713485.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More case studies and PoCs are available at &lt;a href="https://aliasrobotics.com/case-studies-robot-cybersecurity.php"&gt;https://aliasrobotics.com/case-studies-robot-cybersecurity.php&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;h3&gt;&lt;span&gt;üë§&lt;/span&gt; Why CAI?&lt;/h3&gt; 
&lt;p&gt;The cybersecurity landscape is undergoing a dramatic transformation as AI becomes increasingly integrated into security operations. &lt;strong&gt;We predict that by 2028, AI-powered security testing tools will outnumber human pentesters&lt;/strong&gt;. This shift represents a fundamental change in how we approach cybersecurity challenges. &lt;em&gt;AI is not just another tool - it's becoming essential for addressing complex security vulnerabilities and staying ahead of sophisticated threats. As organizations face more advanced cyber attacks, AI-enhanced security testing will be crucial for maintaining robust defenses.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This work builds upon prior efforts[^4] and similarly, we believe that democratizing access to advanced cybersecurity AI tools is vital for the entire security community. That's why we're releasing Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;) as an open source framework. Our goal is to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools. By making these capabilities openly available, we aim to level the playing field and ensure that cutting-edge security AI technology isn't limited to well-funded private companies or state actors.&lt;/p&gt; 
&lt;p&gt;Bug Bounty programs have become a cornerstone of modern cybersecurity, providing a crucial mechanism for organizations to identify and fix vulnerabilities in their systems before they can be exploited. These programs have proven highly effective at securing both public and private infrastructure, with researchers discovering critical vulnerabilities that might have otherwise gone unnoticed. CAI is specifically designed to enhance these efforts by providing a lightweight, ergonomic framework for building specialized AI agents that can assist in various aspects of Bug Bounty hunting - from initial reconnaissance to vulnerability validation and reporting. Our framework aims to augment human expertise with AI capabilities, helping researchers work more efficiently and thoroughly in their quest to make digital systems more secure.&lt;/p&gt; 
&lt;h3&gt;Ethical principles behind CAI&lt;/h3&gt; 
&lt;p&gt;You might be wondering if releasing CAI &lt;em&gt;in-the-wild&lt;/em&gt; given its capabilities and security implications is ethical. Our decision to open-source this framework is guided by two core ethical principles:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Democratizing Cybersecurity AI&lt;/strong&gt;: We believe that advanced cybersecurity AI tools should be accessible to the entire security community, not just well-funded private companies or state actors. By releasing CAI as an open source framework, we aim to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools, leveling the playing field in cybersecurity.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transparency in AI Security Capabilities&lt;/strong&gt;: Based on our research results, understanding of the technology, and dissection of top technical reports, we argue that current LLM vendors are undermining their cybersecurity capabilities. This is extremely dangerous and misleading. By developing CAI openly, we provide a transparent benchmark of what AI systems can actually do in cybersecurity contexts, enabling more informed decisions about security postures.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;CAI is built on the following core principles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cybersecurity oriented AI framework&lt;/strong&gt;: CAI is specifically designed for cybersecurity use cases, aiming at semi- and fully-automating offensive and defensive security tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open source, free for research&lt;/strong&gt;: CAI is open source and free for research purposes. We aim at democratizing access to AI and Cybersecurity. For professional or commercial use, including on-premise deployments, dedicated technical support and custom extensions &lt;a href="mailto:research@aliasrobotics.com"&gt;reach out&lt;/a&gt; to obtain a license.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: CAI is designed to be fast, and easy to use.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modular and agent-centric design&lt;/strong&gt;: CAI operates on the basis of agents and agentic patterns, which allows flexibility and scalability. You can easily add the most suitable agents and pattern for your cybersecuritytarget case.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tool-integration&lt;/strong&gt;: CAI integrates already built-in tools, and allows the user to integrate their own tools with their own logic easily.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Logging and tracing integrated&lt;/strong&gt;: using &lt;a href="https://github.com/Arize-ai/phoenix"&gt;&lt;code&gt;phoenix&lt;/code&gt;&lt;/a&gt;, the open source tracing and logging tool for LLMs. This provides the user with a detailed traceability of the agents and their execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model Support&lt;/strong&gt;: more than 300 supported and empowered by &lt;a href="https://github.com/BerriAI/litellm"&gt;LiteLLM&lt;/a&gt;. The most popular providers: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;: &lt;code&gt;Claude 3.7&lt;/code&gt;, &lt;code&gt;Claude 3.5&lt;/code&gt;, &lt;code&gt;Claude 3&lt;/code&gt;, &lt;code&gt;Claude 3 Opus&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;: &lt;code&gt;O1&lt;/code&gt;, &lt;code&gt;O1 Mini&lt;/code&gt;, &lt;code&gt;O3 Mini&lt;/code&gt;, &lt;code&gt;GPT-4o&lt;/code&gt;, &lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;: &lt;code&gt;DeepSeek V3&lt;/code&gt;, &lt;code&gt;DeepSeek R1&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: &lt;code&gt;Qwen2.5 72B&lt;/code&gt;, &lt;code&gt;Qwen2.5 14B&lt;/code&gt;, etc&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Closed-source alternatives&lt;/h3&gt; 
&lt;p&gt;Cybersecurity AI is a critical field, yet many groups are misguidedly pursuing it through closed-source methods for pure economic return, leveraging similar techniques and building upon existing closed-source (&lt;em&gt;often third-party owned&lt;/em&gt;) models. This approach not only squanders valuable engineering resources but also represents an economic waste and results in redundant efforts, as they often end up reinventing the wheel. Here are some of the closed-source initiatives we keep track of and attempting to leverage genAI and agentic frameworks in cybersecurity AI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.acyber.co/"&gt;Autonomous Cyber&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cracken.ai/"&gt;CrackenAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ethiack.com/"&gt;ETHIACK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://horizon3.ai/"&gt;Horizon3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.irregular.com/"&gt;Irregular&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.kindo.ai/"&gt;Kindo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lakera.ai"&gt;Lakera&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/www.mindfort.ai"&gt;Mindfort&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mindgard.ai/"&gt;Mindgard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ndaysecurity.com/"&gt;NDAY Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.runsybil.com"&gt;Runsybil&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.selfhack.fi"&gt;Selfhack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sola.security/"&gt;Sola Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://squr.ai/"&gt;SQUR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staris.tech/"&gt;Staris&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sxipher.com/"&gt;Sxipher&lt;/a&gt; (seems discontinued)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.terra.security"&gt;Terra Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xint.io/"&gt;Xint&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.xbow.com"&gt;XBOW&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zeropath.com"&gt;ZeroPath&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zynap.com"&gt;Zynap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://7ai.com"&gt;7ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Learn - &lt;code&gt;CAI&lt;/code&gt; Fluency&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://github.com/aliasrobotics/CAI"&gt; &lt;img width="100%" src="https://github.com/aliasrobotics/cai/raw/main/media/caiedu.PNG" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;CAI Fluency technical report (&lt;a href="https://arxiv.org/pdf/2508.13588"&gt;arXiv:2508.13588&lt;/a&gt;) establishes formal educational frameworks for cybersecurity AI literacy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;English&lt;/th&gt; 
   &lt;th&gt;Spanish&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 0&lt;/strong&gt;: What is CAI?&lt;/td&gt; 
   &lt;td&gt;Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;) explained&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=nBdTxbKM4oo"&gt;&lt;img src="https://img.youtube.com/vi/nBdTxbKM4oo/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=FaUL9HXrQ5k"&gt;&lt;img src="https://img.youtube.com/vi/FaUL9HXrQ5k/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 1&lt;/strong&gt;: The &lt;code&gt;CAI&lt;/code&gt; Framework&lt;/td&gt; 
   &lt;td&gt;Vision &amp;amp; Ethics - Explore the core motivation behind CAI and delve into the crucial ethical principles guiding its development. Understand the motivation behind CAI and how you can actively contribute to the future of cybersecurity and the CAI framework.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=QEiGdsMf29M&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=3"&gt;&lt;img src="https://img.youtube.com/vi/QEiGdsMf29M/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 2&lt;/strong&gt;: From Zero to Cyber Hero&lt;/td&gt; 
   &lt;td&gt;Breaking into Cybersecurity with AI - A comprehensive guide for complete beginners to become cybersecurity practitioners using CAI and AI tools. Learn how to leverage artificial intelligence to accelerate your cybersecurity learning journey, from understanding basic security concepts to performing real-world security assessments, all without requiring prior cybersecurity experience.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=hSTLHOOcQoY&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=14"&gt;&lt;img src="https://img.youtube.com/vi/hSTLHOOcQoY/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 3&lt;/strong&gt;: Vibe-Hacking Tutorial&lt;/td&gt; 
   &lt;td&gt;"My first Hack" - A Vibe-Hacking guide for newbies. We demonstrate a simple web security hack using a default agent and show how to leverage tools and interpret CIA output with the help of the CAI Python API. You'll also learn to compare different LLM models to find the best fit for your hacking endeavors.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=9vZ_Iyex7uI&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=1"&gt;&lt;img src="https://img.youtube.com/vi/9vZ_Iyex7uI/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=iAOMaI1ftiA&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=2"&gt;&lt;img src="https://img.youtube.com/vi/iAOMaI1ftiA/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 4&lt;/strong&gt;: Intro ReAct&lt;/td&gt; 
   &lt;td&gt;The Evolution of LLMs - Learn how LLMs evolved from basic language models to advanced multiagency AI systems. From basic LLMs to Chain-of-Thought and Reasoning LLMs towards ReAct and Multi-Agent Architectures. Get to know the basic terms&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=tLdFO1flj_o&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=13"&gt;&lt;img src="https://img.youtube.com/vi/tLdFO1flj_o/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 5&lt;/strong&gt;: CAI on CTF challenges&lt;/td&gt; 
   &lt;td&gt;Dive into Capture The Flag (CTF) competitions using CAI. Learn how to leverage AI agents to solve various cybersecurity challenges including web exploitation, cryptography, reverse engineering, and forensics. Discover how to configure CAI for competitive hacking scenarios and maximize your CTF performance with intelligent automation.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=MrXTQ0e2to4&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=13"&gt;&lt;img src="https://img.youtube.com/vi/MrXTQ0e2to4/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=r9US_JZa9_c&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=12"&gt;&lt;img src="https://img.youtube.com/vi/r9US_JZa9_c/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 1&lt;/strong&gt;: &lt;code&gt;CAI&lt;/code&gt; 0.5.x release&lt;/td&gt; 
   &lt;td&gt;Introduce version 0.5 of &lt;code&gt;CAI&lt;/code&gt; including new multi-agent functionality, new commands such as &lt;code&gt;/history&lt;/code&gt;, &lt;code&gt;/compact&lt;/code&gt;, &lt;code&gt;/graph&lt;/code&gt; or &lt;code&gt;/memory&lt;/code&gt; and a case study showing how &lt;code&gt;CAI&lt;/code&gt; found a critical security flaw in OT heap pumps spread around the world.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=OPFH0ANUMMw"&gt;&lt;img src="https://img.youtube.com/vi/OPFH0ANUMMw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=Q8AI4E4gH8k"&gt;&lt;img src="https://img.youtube.com/vi/Q8AI4E4gH8k/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 2&lt;/strong&gt;: &lt;code&gt;CAI&lt;/code&gt; 0.4.x release and &lt;code&gt;alias0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Introducing version 0.4 of &lt;code&gt;CAI&lt;/code&gt; with &lt;em&gt;streaming&lt;/em&gt; and improved MCP support. We also introduce &lt;code&gt;alias0&lt;/code&gt;, the Privacy-First Cybersecurity AI, a Model-of-Models Intelligence that implements a Privacy-by-Design architecture and obtains state-of-the-art results in cybersecurity benchmarks.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=NZjzfnvAZcc"&gt;&lt;img src="https://img.youtube.com/vi/NZjzfnvAZcc/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 3&lt;/strong&gt;: Cybersecurity AI Community Meeting #1&lt;/td&gt; 
   &lt;td&gt;First Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;) community meeting, over 40 participants from academia, industry, and defense gathered to discuss the open-source scaffolding behind CAI ‚Äî a project designed to build agentic AI systems for cybersecurity that are open, modular, and Bug Bounty-ready.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=4JqaTiVlgsw"&gt;&lt;img src="https://img.youtube.com/vi/4JqaTiVlgsw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;&lt;span&gt;üî©&lt;/span&gt; Install&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install cai-framework
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Always create a new virtual environment to ensure proper dependency installation when updating CAI.&lt;/p&gt; 
&lt;p&gt;The following subsections provide a more detailed walkthrough on selected popular Operating Systems. Refer to the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#development"&gt;Development&lt;/a&gt; section for developer-related install instructions.&lt;/p&gt; 
&lt;h3&gt;OS X&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew update &amp;amp;&amp;amp; \
    brew install git python@3.12

# Create virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ubuntu 24.04&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update &amp;amp;&amp;amp; \
    sudo apt-get install -y git python3-pip python3.12-venv

# Create the virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ubuntu 20.04&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update &amp;amp;&amp;amp; \
    sudo apt-get install -y software-properties-common

# Fetch Python 3.12
sudo add-apt-repository ppa:deadsnakes/ppa &amp;amp;&amp;amp; sudo apt update
sudo apt install python3.12 python3.12-venv python3.12-dev -y

# Create the virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Windows WSL&lt;/h3&gt; 
&lt;p&gt;Go to the Microsoft page: &lt;a href="https://learn.microsoft.com/en-us/windows/wsl/install"&gt;https://learn.microsoft.com/en-us/windows/wsl/install&lt;/a&gt;. Here you will find all the instructions to install WSL&lt;/p&gt; 
&lt;p&gt;From Powershell write: wsl --install&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;
sudo apt-get update &amp;amp;&amp;amp; \
    sudo apt-get install -y git python3-pip python3-venv

# Create the virtual environment
python3 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;p&gt;We recommend having at least 8 GB of RAM:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;First of all, install userland &lt;a href="https://play.google.com/store/apps/details?id=tech.ula&amp;amp;hl=es"&gt;https://play.google.com/store/apps/details?id=tech.ula&amp;amp;hl=es&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install Kali minimal in basic options (for free). [Or any other kali option if preferred]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Update apt keys like in this example: &lt;a href="https://superuser.com/questions/1644520/apt-get-update-issue-in-kali"&gt;https://superuser.com/questions/1644520/apt-get-update-issue-in-kali&lt;/a&gt;, inside UserLand's Kali terminal execute&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Get new apt keys
wget http://http.kali.org/kali/pool/main/k/kali-archive-keyring/kali-archive-keyring_2024.1_all.deb

# Install new apt keys
sudo dpkg -i kali-archive-keyring_2024.1_all.deb &amp;amp;&amp;amp; rm kali-archive-keyring_2024.1_all.deb

# Update APT repository
sudo apt-get update

# CAI requieres python 3.12, lets install it (CAI for kali in Android)
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y git python3-pip build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev pkg-config
wget https://www.python.org/ftp/python/3.12.4/Python-3.12.4.tar.xz
tar xf Python-3.12.4.tar.xz
cd ./configure --enable-optimizations
sudo make altinstall # This command takes long to execute

# Clone CAI's source code
git clone https://github.com/aliasrobotics/cai &amp;amp;&amp;amp; cd cai

# Create virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip3 install -e .

# Generate a .env file and set up
cp .env.example .env  # edit here your keys/models

# Launch CAI
cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;span&gt;üî©&lt;/span&gt; Setup &lt;code&gt;.env&lt;/code&gt; file&lt;/h3&gt; 
&lt;p&gt;CAI leverages the &lt;code&gt;.env&lt;/code&gt; file to load configuration at launch. To facilitate the setup, the repo provides an exemplary &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/.env.example"&gt;&lt;code&gt;.env.example&lt;/code&gt;&lt;/a&gt; file provides a template for configuring CAI's setup and your LLM API keys to work with desired LLM models.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; Important:&lt;/p&gt; 
&lt;p&gt;CAI does NOT provide API keys for any model by default. Don't ask us to provide keys, use your own or host your own models.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; Note:&lt;/p&gt; 
&lt;p&gt;The OPENAI_API_KEY must not be left blank. It should contain either "sk-123" (as a placeholder) or your actual API key. See &lt;a href="https://github.com/aliasrobotics/cai/issues/27"&gt;https://github.com/aliasrobotics/cai/issues/27&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; Note:&lt;/p&gt; 
&lt;p&gt;If you are using alias0 model, make sure that CAI is &amp;gt;0.4.0 version and here you have an .env example to be able to use it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY="sk-1234"
OLLAMA=""
ALIAS_API_KEY="&amp;lt;sk-your-key&amp;gt;"  # note, add yours
CAI_STEAM=False
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîπ Custom OpenAI Base URL Support&lt;/h3&gt; 
&lt;p&gt;CAI supports configuring a custom OpenAI API base URL via the &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt; environment variable. This allows users to redirect API calls to a custom endpoint, such as a proxy or self-hosted OpenAI-compatible service.&lt;/p&gt; 
&lt;p&gt;Example &lt;code&gt;.env&lt;/code&gt; entry configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OLLAMA_API_BASE="https://custom-openai-proxy.com/v1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or directly from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_API_BASE="https://custom-openai-proxy.com/v1" cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;span&gt;üìê&lt;/span&gt; Architecture:&lt;/h2&gt; 
&lt;p&gt;CAI focuses on making cybersecurity agent &lt;strong&gt;coordination&lt;/strong&gt; and &lt;strong&gt;execution&lt;/strong&gt; lightweight, highly controllable, and useful for humans. To do so it builds upon 8 pillars: &lt;code&gt;Agent&lt;/code&gt;s, &lt;code&gt;Tools&lt;/code&gt;, &lt;code&gt;Handoffs&lt;/code&gt;, &lt;code&gt;Patterns&lt;/code&gt;, &lt;code&gt;Turns&lt;/code&gt;, &lt;code&gt;Tracing&lt;/code&gt;, &lt;code&gt;Guardrails&lt;/code&gt; and &lt;code&gt;HITL&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ      HITL     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Turns   ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Patterns ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Handoffs ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ   Agents  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    LLMs   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ                   ‚îÇ
                          ‚îÇ                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Extensions ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Tracing  ‚îÇ       ‚îÇ   Tools   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Guardrails ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚ñº             ‚ñº          ‚ñº             ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ LinuxCmd  ‚îÇ‚îÇ WebSearch ‚îÇ‚îÇ    Code    ‚îÇ‚îÇ SSHTunnel ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to dive deeper into the code, check the following files as a start point for using CAI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/__init__.py"&gt;&lt;strong&gt;init&lt;/strong&gt;.py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/cli.py"&gt;cli.py&lt;/a&gt; - entrypoint for command line interface&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/util.py"&gt;util.py&lt;/a&gt; - utility functions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/agents"&gt;agents&lt;/a&gt; - Agent implementations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/internal"&gt;internal&lt;/a&gt; - CAI internal functions (endpoints, metrics, logging, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/prompts"&gt;prompts&lt;/a&gt; - Agent Prompt Database&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/repl"&gt;repl&lt;/a&gt; - CLI aesthetics and commands&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/sdk"&gt;sdk&lt;/a&gt; - CAI command sdk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/tree/main/src/cai/tools"&gt;tools&lt;/a&gt; - agent tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîπ Agent&lt;/h3&gt; 
&lt;p&gt;At its core, CAI abstracts its cybersecurity behavior via &lt;code&gt;Agents&lt;/code&gt; and agentic &lt;code&gt;Patterns&lt;/code&gt;. An Agent in &lt;em&gt;an intelligent system that interacts with some environment&lt;/em&gt;. More technically, within CAI we embrace a robotics-centric definition wherein an agent is anything that can be viewed as a system perceiving its environment through sensors, reasoning about its goals and and acting accordingly upon that environment through actuators (&lt;em&gt;adapted&lt;/em&gt; from Russel &amp;amp; Norvig, AI: A Modern Approach). In cybersecurity, an &lt;code&gt;Agent&lt;/code&gt; interacts with systems and networks, using peripherals and network interfaces as sensors, reasons accordingly and then executes network actions as if actuators. Correspondingly, in CAI, &lt;code&gt;Agent&lt;/code&gt;s implement the &lt;code&gt;ReACT&lt;/code&gt; (Reasoning and Action) agent model[^3]. For more information, see the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/basic/hello_world.py"&gt;example here&lt;/a&gt; for the full execution code, and refer to this &lt;a href="https://github.com/aliasrobotics/cai/raw/main/fluency/my-first-hack/my_first_hack.ipynb"&gt;jupyter notebook&lt;/a&gt; for a tutorial on how to use it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from cai.sdk.agents import Agent, Runner, OpenAIChatCompletionsModel

import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()

agent = Agent(
      name="Custom Agent",
      instructions="""You are a Cybersecurity expert Leader""",
      model=OpenAIChatCompletionsModel(
          model=os.getenv('CAI_MODEL', "openai/gpt-4o"),
          openai_client=AsyncOpenAI(),
          )
      )

message = "Tell me about recursion in programming."
result = await Runner.run(agent, message)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîπ Tools&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Tools&lt;/code&gt; let cybersecurity agents take actions by providing interfaces to execute system commands, run security scans, analyze vulnerabilities, and interact with target systems and APIs - they are the core capabilities that enable CAI agents to perform security tasks effectively; in CAI, tools include built-in cybersecurity utilities (like LinuxCmd for command execution, WebSearch for OSINT gathering, Code for dynamic script execution, and SSHTunnel for secure remote access), function calling mechanisms that allow integration of any Python function as a security tool, and agent-as-tool functionality that enables specialized security agents (such as reconnaissance or exploit agents) to be used by other agents, creating powerful collaborative security workflows without requiring formal handoffs between agents. For more information, please refer to the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/basic/tools.py"&gt;example here&lt;/a&gt; for the complete configuration of custom functions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from cai.sdk.agents import Agent, Runner, OpenAIChatCompletionsModel
from cai.tools.reconnaissance.exec_code import execute_code
from cai.tools.reconnaissance.generic_linux_command import generic_linux_command

import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()

agent = Agent(
      name="Custom Agent",
      instructions="""You are a Cybersecurity expert Leader""",
      tools= [
        generic_linux_command,
        execute_code
      ],
      model=OpenAIChatCompletionsModel(
          model=os.getenv('CAI_MODEL', "openai/gpt-4o"),
          openai_client=AsyncOpenAI(),
          )
      )

message = "Tell me about recursion in programming."
result = await Runner.run(agent, message)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You may find different &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/tools"&gt;tools&lt;/a&gt;. They are grouped in 6 major categories inspired by the security kill chain [^2]:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Reconnaissance and weaponization - &lt;em&gt;reconnaissance&lt;/em&gt; (crypto, listing, etc)&lt;/li&gt; 
 &lt;li&gt;Exploitation - &lt;em&gt;exploitation&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Privilege escalation - &lt;em&gt;escalation&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Lateral movement - &lt;em&gt;lateral&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Data exfiltration - &lt;em&gt;exfiltration&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Command and control - &lt;em&gt;control&lt;/em&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üîπ Handoffs&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Handoffs&lt;/code&gt; allow an &lt;code&gt;Agent&lt;/code&gt; to delegate tasks to another agent, which is crucial in cybersecurity operations where specialized expertise is needed for different phases of an engagement. In our framework, &lt;code&gt;Handoffs&lt;/code&gt; are implemented as tools for the LLM, where a &lt;strong&gt;handoff/transfer function&lt;/strong&gt; like &lt;code&gt;transfer_to_flag_discriminator&lt;/code&gt; enables the &lt;code&gt;ctf_agent&lt;/code&gt; to pass control to the &lt;code&gt;flag_discriminator_agent&lt;/code&gt; once it believes it has found the flag. This creates a security validation chain where the first agent handles exploitation and flag discovery, while the second agent specializes in flag verification, ensuring proper segregation of duties and leveraging specialized capabilities of different models for distinct security tasks. For more information, please refer to the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/cai/agent_patterns/handoffs.py"&gt;example here&lt;/a&gt; for the full execution code.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from cai.sdk.agents import function_tool
from cai.tools.common import run_command
from cai.sdk.agents import Agent, OpenAIChatCompletionsModel, HandoffInputData, Runner, function_tool, handoff, trace
from cai.sdk.agents.extensions import handoff_filters

import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()

@function_tool
def execute_cli_command(command: str) -&amp;gt; str:
    return run_command(command)

flag_discriminator = Agent(
    name="Flag discriminator",
    description="Agent focused on extracting the flag from the output",
    instructions="You are an agent tailored to extract the flag from a given output.",
    model=OpenAIChatCompletionsModel(
        model=os.getenv('CAI_MODEL', "qwen2.5:14b"),
        openai_client=AsyncOpenAI(),
    ) 
)

ctf_agent = Agent(
    name="CTF agent",
    description="Agent focused on conquering security challenges",
    instructions="You are a Cybersecurity expert Leader facing a CTF",
    tools=[
        execute_cli_command,
    ],
    model=OpenAIChatCompletionsModel(
        model= os.getenv('CAI_MODEL', "qwen2.5:14b"),
        openai_client=AsyncOpenAI(),
    ), 
    handoffs = [flag_discriminator]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîπ Patterns&lt;/h3&gt; 
&lt;p&gt;An agentic &lt;code&gt;Pattern&lt;/code&gt; is a &lt;em&gt;structured design paradigm&lt;/em&gt; in artificial intelligence systems where autonomous or semi-autonomous agents operate within a defined &lt;em&gt;interaction framework&lt;/em&gt; (the pattern) to achieve a goal. These &lt;code&gt;Patterns&lt;/code&gt; specify the organization, coordination, and communication methods among agents, guiding decision-making, task execution, and delegation.&lt;/p&gt; 
&lt;p&gt;An agentic pattern (&lt;code&gt;AP&lt;/code&gt;) can be formally defined as a tuple:&lt;/p&gt; 
&lt;p&gt;\[ AP = (A, H, D, C, E) \]&lt;/p&gt; 
&lt;p&gt;wherein:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;\(A\) (Agents):&lt;/strong&gt; A set of autonomous entities, \( A = \{a_1, a_2, ..., a_n\} \), each with defined roles, capabilities, and internal states.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(H\) (Handoffs):&lt;/strong&gt; A function \( H: A \times T \to A \) that governs how tasks \( T \) are transferred between agents based on predefined logic (e.g., rules, negotiation, bidding).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(D\) (Decision Mechanism):&lt;/strong&gt; A decision function \( D: S \to A \) where \( S \) represents system states, and \( D \) determines which agent takes action at any given time.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(C\) (Communication Protocol):&lt;/strong&gt; A messaging function \( C: A \times A \to M \), where \( M \) is a message space, defining how agents share information.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(E\) (Execution Model):&lt;/strong&gt; A function \( E: A \times I \to O \) where \( I \) is the input space and \( O \) is the output space, defining how agents perform tasks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When building &lt;code&gt;Patterns&lt;/code&gt;, we generall y classify them among one of the following categories, though others exist:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Agentic&lt;/strong&gt; &lt;code&gt;Pattern&lt;/code&gt; &lt;strong&gt;categories&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Swarm&lt;/code&gt; (Decentralized)&lt;/td&gt; 
   &lt;td&gt;Agents share tasks and self-assign responsibilities without a central orchestrator. Handoffs occur dynamically. &lt;em&gt;An example of a peer-to-peer agentic pattern is the &lt;code&gt;CTF Agentic Pattern&lt;/code&gt;, which involves a team of agents working together to solve a CTF challenge with dynamic handoffs.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Hierarchical&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A top-level agent (e.g., "PlannerAgent") assigns tasks via structured handoffs to specialized sub-agents. Alternatively, the structure of the agents is harcoded into the agentic pattern with pre-defined handoffs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Chain-of-Thought&lt;/code&gt; (Sequential Workflow)&lt;/td&gt; 
   &lt;td&gt;A structured pipeline where Agent A produces an output, hands it to Agent B for reuse or refinement, and so on. Handoffs follow a linear sequence. &lt;em&gt;An example of a chain-of-thought agentic pattern is the &lt;code&gt;ReasonerAgent&lt;/code&gt;, which involves a Reasoning-type LLM that provides context to the main agent to solve a CTF challenge with a linear sequence.&lt;/em&gt;[^1]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Auction-Based&lt;/code&gt; (Competitive Allocation)&lt;/td&gt; 
   &lt;td&gt;Agents "bid" on tasks based on priority, capability, or cost. A decision agent evaluates bids and hands off tasks to the best-fit agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Recursive&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A single agent continuously refines its own output, treating itself as both executor and evaluator, with handoffs (internal or external) to itself. &lt;em&gt;An example of a recursive agentic pattern is the &lt;code&gt;CodeAgent&lt;/code&gt; (when used as a recursive agent), which continuously refines its own output by executing code and updating its own instructions.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For more information and examples of common agentic patterns, see the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/agent_patterns/README.md"&gt;examples folder&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;üîπ Turns and Interactions&lt;/h3&gt; 
&lt;p&gt;During the agentic flow (conversation), we distinguish between &lt;strong&gt;interactions&lt;/strong&gt; and &lt;strong&gt;turns&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Interactions&lt;/strong&gt; are sequential exchanges between one or multiple agents. Each agent executing its logic corresponds with one &lt;em&gt;interaction&lt;/em&gt;. Since an &lt;code&gt;Agent&lt;/code&gt; in CAI generally implements the &lt;code&gt;ReACT&lt;/code&gt; agent model[^3], each &lt;em&gt;interaction&lt;/em&gt; consists of 1) a reasoning step via an LLM inference and 2) act by calling zero-to-n &lt;code&gt;Tools&lt;/code&gt;. This is defined in&lt;code&gt;process_interaction()&lt;/code&gt; in &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py"&gt;core.py&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Turns&lt;/strong&gt;: A turn represents a cycle of one ore more &lt;strong&gt;interactions&lt;/strong&gt; which finishes when the &lt;code&gt;Agent&lt;/code&gt; (or &lt;code&gt;Pattern&lt;/code&gt;) executing returns &lt;code&gt;None&lt;/code&gt;, judging there're no further actions to undertake. This is defined in &lt;code&gt;run()&lt;/code&gt;, see &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py"&gt;core.py&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] CAI Agents are not related to Assistants in the Assistants API. They are named similarly for convenience, but are otherwise completely unrelated. CAI is entirely powered by the Chat Completions API and is hence stateless between calls.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üîπ Tracing&lt;/h3&gt; 
&lt;p&gt;CAI implements AI observability by adopting the OpenTelemetry standard and to do so, it leverages &lt;a href="https://github.com/Arize-ai/phoenix"&gt;Phoenix&lt;/a&gt; which provides comprehensive tracing capabilities through OpenTelemetry-based instrumentation, allowing you to monitor and analyze your security operations in real-time. This integration enables detailed visibility into agent interactions, tool usage, and attack vectors throughout penetration testing workflows, making it easier to debug complex exploitation chains, track vulnerability discovery processes, and optimize agent performance for more effective security assessments.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/tracing.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;üîπ Guardrails&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Guardrails&lt;/code&gt; provide a critical security layer for CAI agents, protecting against prompt injection attacks and preventing execution of dangerous commands. These guardrails run in parallel to agents, validating both input and output to ensure safe operation. The framework includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Input Guardrails&lt;/strong&gt;: Detect and block prompt injection attempts before they reach agents, using pattern matching, Unicode homograph detection, and AI-powered analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Output Guardrails&lt;/strong&gt;: Validate agent outputs before execution, preventing dangerous commands like reverse shells, fork bombs, or data exfiltration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-layered Defense&lt;/strong&gt;: Protection at input, processing, and execution stages with tool-level validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Base64/Base32 Aware&lt;/strong&gt;: Automatically decodes and analyzes encoded payloads to detect hidden malicious commands&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable&lt;/strong&gt;: Can be enabled/disabled via &lt;code&gt;CAI_GUARDRAILS&lt;/code&gt; environment variable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed implementation, see &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/guardrails.md"&gt;docs/guardrails.md&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/cai_prompt_injection.md"&gt;docs/cai_prompt_injection.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;üîπ Human-In-The-Loop (HITL)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ                                 ‚îÇ
                      ‚îÇ      Cybersecurity AI (CAI)     ‚îÇ
                      ‚îÇ                                 ‚îÇ
                      ‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
                      ‚îÇ       ‚îÇ  Autonomous AI  ‚îÇ       ‚îÇ
                      ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
                      ‚îÇ                ‚îÇ                ‚îÇ
                      ‚îÇ                ‚îÇ                ‚îÇ
                      ‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
                      ‚îÇ       ‚îÇ HITL Interaction ‚îÇ      ‚îÇ
                      ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
                      ‚îÇ                ‚îÇ                ‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                       ‚îÇ
                                       ‚îÇ Ctrl+C (cli.py)
                                       ‚îÇ
                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                           ‚îÇ   Human Operator(s)   ‚îÇ
                           ‚îÇ  Expertise | Judgment ‚îÇ
                           ‚îÇ    Teleoperation      ‚îÇ
                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CAI delivers a framework for building Cybersecurity AIs with a strong emphasis on &lt;em&gt;semi-autonomous&lt;/em&gt; operation, as the reality is that &lt;strong&gt;fully-autonomous&lt;/strong&gt; cybersecurity systems remain premature and face significant challenges when tackling complex tasks. While CAI explores autonomous capabilities, we recognize that effective security operations still require human teleoperation providing expertise, judgment, and oversight in the security process.&lt;/p&gt; 
&lt;p&gt;Accordingly, the Human-In-The-Loop (&lt;code&gt;HITL&lt;/code&gt;) module is a core design principle of CAI, acknowledging that human intervention and teleoperation are essential components of responsible security testing. Through the &lt;code&gt;cli.py&lt;/code&gt; interface, users can seamlessly interact with agents at any point during execution by simply pressing &lt;code&gt;Ctrl+C&lt;/code&gt;. This is implemented across &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py"&gt;core.py&lt;/a&gt; and also in the REPL abstractions &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl"&gt;REPL&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üöÄ&lt;/span&gt; Quickstart&lt;/h2&gt; 
&lt;p&gt;To start CAI after installing it, just type &lt;code&gt;cai&lt;/code&gt; in the CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;‚îî‚îÄ# cai

          CCCCCCCCCCCCC      ++++++++   ++++++++      IIIIIIIIII
       CCC::::::::::::C  ++++++++++       ++++++++++  I::::::::I
     CC:::::::::::::::C ++++++++++         ++++++++++ I::::::::I
    C:::::CCCCCCCC::::C +++++++++    ++     +++++++++ II::::::II
   C:::::C       CCCCCC +++++++     +++++     +++++++   I::::I
  C:::::C                +++++     +++++++     +++++    I::::I
  C:::::C                ++++                   ++++    I::::I
  C:::::C                 ++                     ++     I::::I
  C:::::C                  +   +++++++++++++++   +      I::::I
  C:::::C                    +++++++++++++++++++        I::::I
  C:::::C                     +++++++++++++++++         I::::I
   C:::::C       CCCCCC        +++++++++++++++          I::::I
    C:::::CCCCCCCC::::C         +++++++++++++         II::::::II
     CC:::::::::::::::C           +++++++++           I::::::::I
       CCC::::::::::::C             +++++             I::::::::I
          CCCCCCCCCCCCC               ++              IIIIIIIIII

                      Cybersecurity AI (CAI), vX.Y.Z
                          Bug bounty-ready AI

CAI&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That should initialize CAI and provide a prompt to execute any security task you want to perform. The navigation bar at the bottom displays important system information. This information helps you understand your environment while working with CAI.&lt;/p&gt; 
&lt;p&gt;Here's a quick &lt;a href="https://asciinema.org/a/zm7wS5DA2o0S9pu1Tb44pnlvy"&gt;demo video&lt;/a&gt; to help you get started with CAI. We'll walk through the basic steps ‚Äî from launching the tool to running your first AI-powered task in the terminal. Whether you're a beginner or just curious, this guide will show you how easy it is to begin using CAI.&lt;/p&gt; 
&lt;p&gt;From here on, type on &lt;code&gt;CAI&lt;/code&gt; and start your security exercise. Best way to learn is by example:&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;For using private models, you are given a &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/.env.example"&gt;&lt;code&gt;.env.example&lt;/code&gt;&lt;/a&gt; file. Copy it and rename it as &lt;code&gt;.env&lt;/code&gt;. Fill in your corresponding API keys, and you are ready to use CAI.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;List of Environment Variables&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Variable&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_NAME&lt;/td&gt; 
    &lt;td&gt;Name of the CTF challenge to run (e.g. "picoctf_static_flag")&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_CHALLENGE&lt;/td&gt; 
    &lt;td&gt;Specific challenge name within the CTF to test&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_SUBNET&lt;/td&gt; 
    &lt;td&gt;Network subnet for the CTF container&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_IP&lt;/td&gt; 
    &lt;td&gt;IP address for the CTF container&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_INSIDE&lt;/td&gt; 
    &lt;td&gt;Whether to conquer the CTF from within container&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MODEL&lt;/td&gt; 
    &lt;td&gt;Model to use for agents&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_DEBUG&lt;/td&gt; 
    &lt;td&gt;Set debug output level (0: Only tool outputs, 1: Verbose debug output, 2: CLI debug output)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_BRIEF&lt;/td&gt; 
    &lt;td&gt;Enable/disable brief output mode&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MAX_TURNS&lt;/td&gt; 
    &lt;td&gt;Maximum number of turns for agent interactions&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_TRACING&lt;/td&gt; 
    &lt;td&gt;Enable/disable OpenTelemetry tracing&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_AGENT_TYPE&lt;/td&gt; 
    &lt;td&gt;Specify the agents to use (boot2root, one_tool...)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_STATE&lt;/td&gt; 
    &lt;td&gt;Enable/disable stateful mode&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY&lt;/td&gt; 
    &lt;td&gt;Enable/disable memory mode (episodic, semantic, all)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY_ONLINE&lt;/td&gt; 
    &lt;td&gt;Enable/disable online memory mode&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY_OFFLINE&lt;/td&gt; 
    &lt;td&gt;Enable/disable offline memory&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_ENV_CONTEXT&lt;/td&gt; 
    &lt;td&gt;Add dirs and current env to llm context&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY_ONLINE_INTERVAL&lt;/td&gt; 
    &lt;td&gt;Number of turns between online memory updates&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_PRICE_LIMIT&lt;/td&gt; 
    &lt;td&gt;Price limit for the conversation in dollars&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_REPORT&lt;/td&gt; 
    &lt;td&gt;Enable/disable reporter mode (ctf, nis2, pentesting)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_SUPPORT_MODEL&lt;/td&gt; 
    &lt;td&gt;Model to use for the support agent&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_SUPPORT_INTERVAL&lt;/td&gt; 
    &lt;td&gt;Number of turns between support agent executions&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_WORKSPACE&lt;/td&gt; 
    &lt;td&gt;Defines the name of the workspace&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_WORKSPACE_DIR&lt;/td&gt; 
    &lt;td&gt;Specifies the directory path where the workspace is located&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_GUARDRAILS&lt;/td&gt; 
    &lt;td&gt;Enable/disable guardrails for prompt injection protection (default: true)&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;OpenRouter Integration&lt;/h3&gt; 
&lt;p&gt;The Cybersecurity AI (CAI) platform offers seamless integration with OpenRouter, a unified interface for Large Language Models (LLMs). This integration is crucial for users who wish to leverage advanced AI capabilities in their cybersecurity tasks. OpenRouter acts as a bridge, allowing CAI to communicate with various LLMs, thereby enhancing the flexibility and power of the AI agents used within CAI.&lt;/p&gt; 
&lt;p&gt;To enable OpenRouter support in CAI, you need to configure your environment by adding specific entries to your &lt;code&gt;.env&lt;/code&gt; file. This setup ensures that CAI can interact with the OpenRouter API, facilitating the use of sophisticated models like Meta-LLaMA. Here‚Äôs how you can configure it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI_AGENT_TYPE=redteam_agent
CAI_MODEL=openrouter/meta-llama/llama-4-maverick
OPENROUTER_API_KEY=&amp;lt;sk-your-key&amp;gt;  # note, add yours
OPENROUTER_API_BASE=https://openrouter.ai/api/v1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Azure OpenAI&lt;/h3&gt; 
&lt;p&gt;The Cybersecurity AI (CAI) platform integrates seamlessly with Azure OpenAI, enabling organizations to run CAI against enterprise-hosted models (e.g., gpt-4o). This pathway is ideal for teams that must operate within Azure governance while leveraging advanced model capabilities. To enable Azure OpenAI support in CAI, configure your environment by adding the following entries to your .env. This ensures CAI can reach your Azure deployment endpoint and authenticate correctly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI_AGENT_TYPE=redteam_agent
CAI_MODEL=azure/&amp;lt;model-name-deployed&amp;gt;
# Required: keep non-empty even when using Azure
OPENAI_API_KEY=dummy
# Azure credentials and endpoint
AZURE_API_KEY=&amp;lt;your-azure-openai-key&amp;gt;
AZURE_API_BASE=https://&amp;lt;resource&amp;gt;.openai.azure.com/openai/deployments/&amp;lt;deployment-name&amp;gt;/chat/completions?api-version=2025-01-01-preview
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCP&lt;/h3&gt; 
&lt;p&gt;CAI supports the Model Context Protocol (MCP) for integrating external tools and services with AI agents. MCP is supported via two transport mechanisms:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;SSE (Server-Sent Events)&lt;/strong&gt; - For web-based servers that push updates over HTTP connections:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp load http://localhost:9876/sse burp
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;STDIO (Standard Input/Output)&lt;/strong&gt; - For local inter-process communication:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp load stdio myserver python mcp_server.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once connected, you can add the MCP tools to any agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp add burp redteam_agent
Adding tools from MCP server 'burp' to agent 'Red Team Agent'...
                                 Adding tools to Red Team Agent
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Tool                              ‚îÉ Status ‚îÉ Details                                         ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ send_http_request                 ‚îÇ Added  ‚îÇ Available as: send_http_request                 ‚îÇ
‚îÇ create_repeater_tab               ‚îÇ Added  ‚îÇ Available as: create_repeater_tab               ‚îÇ
‚îÇ send_to_intruder                  ‚îÇ Added  ‚îÇ Available as: send_to_intruder                  ‚îÇ
‚îÇ url_encode                        ‚îÇ Added  ‚îÇ Available as: url_encode                        ‚îÇ
‚îÇ url_decode                        ‚îÇ Added  ‚îÇ Available as: url_decode                        ‚îÇ
‚îÇ base64encode                      ‚îÇ Added  ‚îÇ Available as: base64encode                      ‚îÇ
‚îÇ base64decode                      ‚îÇ Added  ‚îÇ Available as: base64decode                      ‚îÇ
‚îÇ generate_random_string            ‚îÇ Added  ‚îÇ Available as: generate_random_string            ‚îÇ
‚îÇ output_project_options            ‚îÇ Added  ‚îÇ Available as: output_project_options            ‚îÇ
‚îÇ output_user_options               ‚îÇ Added  ‚îÇ Available as: output_user_options               ‚îÇ
‚îÇ set_project_options               ‚îÇ Added  ‚îÇ Available as: set_project_options               ‚îÇ
‚îÇ set_user_options                  ‚îÇ Added  ‚îÇ Available as: set_user_options                  ‚îÇ
‚îÇ get_proxy_http_history            ‚îÇ Added  ‚îÇ Available as: get_proxy_http_history            ‚îÇ
‚îÇ get_proxy_http_history_regex      ‚îÇ Added  ‚îÇ Available as: get_proxy_http_history_regex      ‚îÇ
‚îÇ get_proxy_websocket_history       ‚îÇ Added  ‚îÇ Available as: get_proxy_websocket_history       ‚îÇ
‚îÇ get_proxy_websocket_history_regex ‚îÇ Added  ‚îÇ Available as: get_proxy_websocket_history_regex ‚îÇ
‚îÇ set_task_execution_engine_state   ‚îÇ Added  ‚îÇ Available as: set_task_execution_engine_state   ‚îÇ
‚îÇ set_proxy_intercept_state         ‚îÇ Added  ‚îÇ Available as: set_proxy_intercept_state         ‚îÇ
‚îÇ get_active_editor_contents        ‚îÇ Added  ‚îÇ Available as: get_active_editor_contents        ‚îÇ
‚îÇ set_active_editor_contents        ‚îÇ Added  ‚îÇ Available as: set_active_editor_contents        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Added 20 tools from server 'burp' to agent 'Red Team Agent'.
CAI&amp;gt;/agent 13
CAI&amp;gt;Create a repeater tab
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can list all active MCP connections and their transport types:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp list
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/386a1fd3-3469-4f84-9396-2a5236febe1f"&gt;https://github.com/user-attachments/assets/386a1fd3-3469-4f84-9396-2a5236febe1f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Development is facilitated via VS Code dev. environments. To try out our development environment, clone the repository, open VS Code and enter de dev. container mode:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/cai_devenv.gif" alt="CAI Development Environment" /&gt;&lt;/p&gt; 
&lt;h3&gt;Contributions&lt;/h3&gt; 
&lt;p&gt;If you want to contribute to this project, use &lt;a href="https://pre-commit.com/"&gt;&lt;strong&gt;Pre-commit&lt;/strong&gt;&lt;/a&gt; before your MR&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install pre-commit
pre-commit # files staged
pre-commit run --all-files # all files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Requirements: caiextensions&lt;/h3&gt; 
&lt;p&gt;Currently, the extensions are not publicly available as the engineering endeavour to maintain them is significant. Instead, we're making selected custom caiextensions available for partner companies across collaborations.&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;‚Ñπ&lt;/span&gt; Usage Data Collection&lt;/h3&gt; 
&lt;p&gt;CAI is provided free of charge for researchers. To improve CAI‚Äôs detection accuracy and publish open security research, instead of payment for research use cases, we ask you to contribute to the CAI community by allowing usage data collection. This data helps us identify areas for improvement, understand how the framework is being used, and prioritize new features. Legal basis of data collection is under Art. 6 (1)(f) GDPR ‚Äî CAI‚Äôs legitimate interest in maintaining and improving security tooling, with Art. 89 safeguards for research. The collected data includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Basic system information (OS type, Python version)&lt;/li&gt; 
 &lt;li&gt;Username and IP information&lt;/li&gt; 
 &lt;li&gt;Tool usage patterns and performance metrics&lt;/li&gt; 
 &lt;li&gt;Model interactions and token usage statistics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We take your privacy seriously and only collect what's needed to make CAI better. For further info, reach out to researchÔº†aliasrobotics.com. You can disable some of the data collection features via the &lt;code&gt;CAI_TELEMETRY&lt;/code&gt; environment variable but we encourage you to keep it enabled and contribute back to research:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI_TELEMETRY=False cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reproduce CI-Setup locally&lt;/h3&gt; 
&lt;p&gt;To simulate the CI/CD pipeline, you can run the following in the Gitlab runner machines:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it \
  --privileged \
  --network=exploitflow_net \
  --add-host="host.docker.internal:host-gateway" \
  -v /cache:/cache \
  -v /var/run/docker.sock:/var/run/docker.sock:rw \
  registry.gitlab.com/aliasrobotics/alias_research/cai:latest bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt;
 &lt;summary&gt;OLLAMA is giving me 404 errors&lt;/summary&gt; 
 &lt;p&gt;Ollama's API in OpenAI mode uses &lt;code&gt;/v1/chat/completions&lt;/code&gt; whereas the &lt;code&gt;openai&lt;/code&gt; library uses &lt;code&gt;base_url&lt;/code&gt; + &lt;code&gt;/chat/completions&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;We adopt the latter for overall alignment with the gen AI community and empower the former by allowing users to add the &lt;code&gt;v1&lt;/code&gt; themselves via:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_API_BASE=http://IP:PORT/v1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See the following issues that treat this topic in more detail:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/issues/76"&gt;https://github.com/aliasrobotics/cai/issues/76&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/issues/83"&gt;https://github.com/aliasrobotics/cai/issues/83&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/issues/82"&gt;https://github.com/aliasrobotics/cai/issues/82&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Where are all the caiextensions?&lt;/summary&gt; 
 &lt;p&gt;See &lt;a href="https://gitlab.com/aliasrobotics/alias_research/caiextensions"&gt;all caiextensions&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How do I install the report caiextension?&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#optional-requirements-caiextensions"&gt;See here&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How do I set up SSH access for Gitlab?&lt;/summary&gt; 
 &lt;p&gt;Generate a new SSH key&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ssh-keygen -t ed25519
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Add the key to the SSH agent&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ssh-add ~/.ssh/id_ed25519
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Add the public key to Gitlab Copy the key and add it to Gitlab under &lt;a href="https://gitlab.com/-/user_settings/ssh_keys"&gt;https://gitlab.com/-/user_settings/ssh_keys&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cat ~/.ssh/id_ed25519.pub
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To verify it:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ssh -T git@gitlab.com
Welcome to GitLab, @vmayoral!
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How do I clear Python cache?&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;find . -name "*.pyc" -delete &amp;amp;&amp;amp; find . -name "__pycache__" -delete
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;If host networking is not working with ollama check whether it has been disabled in Docker because you are not signed in&lt;/summary&gt; 
 &lt;p&gt;Docker in OS X behaves funny sometimes. Check if the following message has shown up:&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Host networking has been disabled because you are not signed in. Please sign in to enable it&lt;/em&gt;.&lt;/p&gt; 
 &lt;p&gt;Make sure this has been addressed and also that the Dev Container is not forwarding the 8000 port (click on x, if necessary in the ports section).&lt;/p&gt; 
 &lt;p&gt;To verify connection, from within the VSCode devcontainer:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -v http://host.docker.internal:8000/api/version
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Run CAI against any target&lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-004-first-message.png" alt="cai-004-first-message" /&gt;&lt;/p&gt; 
 &lt;p&gt;The starting user prompt in this case is: &lt;code&gt;Target IP: 192.168.3.10, perform a full network scan&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;The agent started performing a nmap scan. You could either interact with the agent and give it more instructions, or let it run to see what it explores next.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do I interact with the agent? Type twice CTRL + C &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-005-ctrl-c.png" alt="cai-005-ctrl-c" /&gt;&lt;/p&gt; 
 &lt;p&gt;If you want to use the HITL mode, you can do it by presssing twice &lt;code&gt;Ctrl + C&lt;/code&gt;. This will allow you to interact (prompt) with the agent whenever you want. The agent will not lose the previous context, as it is stored in the &lt;code&gt;history&lt;/code&gt; variable, which is passed to it and any agent that is called. This enables any agent to use the previous information and be more accurate and efficient.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; Can I change the model while CAI is running? /model &lt;/summary&gt; 
 &lt;p&gt;Use &lt;code&gt;/model&lt;/code&gt; to change the model.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-007-model-change.png" alt="cai-007-model-change" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How can I list all the agents available? /agent &lt;/summary&gt; 
 &lt;p&gt;Use &lt;code&gt;/agent&lt;/code&gt; to list all the agents available.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-010-agents-menu.png" alt="cai-010-agents-menu" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; Where can I list all the environment variables? /config &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-008-config.png" alt="cai-008-config" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; How to know more about the CLI? /help &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-006-help.png" alt="cai-006-help" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How can I trace the whole execution?&lt;/summary&gt; The environment variable `CAI_TRACING` allows the user to set it to `CAI_TRACING=true` to enable tracing, or `CAI_TRACING=false` to disable it. When CAI is prompted by the first time, the user is provided with two paths, the execution log, and the tracing log. 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-009-logs.png" alt="cai-009-logs" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can I expand CAI capabilities using previous run logs?&lt;/summary&gt; 
 &lt;p&gt;Yes. Today CAI performs best by relying on In‚ÄëContext Learning (ICL). Rather than building long‚Äëterm stores, the recommended workflow is to load relevant prior logs directly into the current session so the model can reason with them in context.&lt;/p&gt; 
 &lt;p&gt;Use the &lt;code&gt;/load&lt;/code&gt; command to bring JSONL logs into CAI‚Äôs context (this replaces the legacy memory-loading tool):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/load logs/cai_20250408_111856.jsonl         # Load into current agent
CAI&amp;gt;/load &amp;lt;file&amp;gt; agent &amp;lt;name&amp;gt;                    # Load into a specific agent
CAI&amp;gt;/load &amp;lt;file&amp;gt; all                             # Distribute across all agents
CAI&amp;gt;/load &amp;lt;file&amp;gt; parallel                        # Match to configured parallel agents
# Tip: if you omit &amp;lt;file&amp;gt;, /load uses `logs/last`. Alias: /l
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;CAI prints the path to the current run‚Äôs JSONL log at startup (highlighted in orange), which you can pass to &lt;code&gt;/load&lt;/code&gt;:&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-009-logs.png" alt="cai-009-logs" /&gt;&lt;/p&gt; 
 &lt;p&gt;Legacy notes: earlier ‚Äúmemory extension‚Äù mechanisms (episodic/semantic stores and offline ingestion) are retained for reference only. See &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/src/cai/agents/memory.py"&gt;src/cai/agents/memory.py&lt;/a&gt; for background and legacy details. Our current direction prioritizes ICL over persistent memory.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can I expand CAI capabilities using scripts or extra information?&lt;/summary&gt; 
 &lt;p&gt;Currently, CAI supports text based information. You can add any extra information on the target you are facing by copy-pasting it directly into the system or user prompt.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt; By adding it to the system (&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl/templates/system_master_template.md"&gt;&lt;code&gt;system_master_template.md&lt;/code&gt;&lt;/a&gt;) or the user prompt (&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl/templates/user_master_template.md"&gt;&lt;code&gt;user_master_template.md&lt;/code&gt;&lt;/a&gt;). You can always directly prompt the path to the model, and it will &lt;code&gt;cat&lt;/code&gt; it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How CAI licence works?&lt;/summary&gt; 
 &lt;p&gt;CAI‚Äôs current license does not restrict usage for research purposes. You are free to use CAI for security assessments (pentests), to develop additional features, and to integrate it into your research activities, as long as you comply with local laws.&lt;/p&gt; 
 &lt;p&gt;If you or your organization start benefiting commercially from CAI (e.g., offering pentesting services powered by CAI), then a commercial license will be required to help sustain the project.&lt;/p&gt; 
 &lt;p&gt;CAI itself is not a profit-seeking initiative. Our goal is to build a sustainable open-source project. We simply ask that those who profit from CAI contribute back and support our ongoing development.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;I get a `Unable to locate package python3.12-venv` when installing the prerequisites on my debian based system!&lt;/summary&gt; 
 &lt;p&gt;The easiest way to get around this is to simply install &lt;a href="https://www.python.org/downloads/release/python-3120/"&gt;&lt;code&gt;python3.12&lt;/code&gt;&lt;/a&gt; from source.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you want to cite our work, please use the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{mayoralvilches2025caiopenbugbountyready,
      title={CAI: An Open, Bug Bounty-Ready Cybersecurity AI},
      author={V√≠ctor Mayoral-Vilches and Luis Javier Navarrete-Lozano and Mar√≠a Sanz-G√≥mez and Lidia Salas Espejo and Marti√±o Crespo-√Ålvarez and Francisco Oca-Gonzalez and Francesco Balassone and Alfonso Glera-Pic√≥n and Unai Ayucar-Carbajo and Jon Ander Ruiz-Alcalde and Stefan Rass and Martin Pinzger and Endika Gil-Uriarte},
      year={2025},
      eprint={2504.06017},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2504.06017},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{mayoralvilches2025cybersecurityaidangerousgap,
      title={Cybersecurity AI: The Dangerous Gap Between Automation and Autonomy}, 
      author={V√≠ctor Mayoral-Vilches},
      year={2025},
      eprint={2506.23592},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2506.23592}, 
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{mayoralvilches2025caifluencyframeworkcybersecurity,
      title={CAI Fluency: A Framework for Cybersecurity AI Fluency}, 
      author={V√≠ctor Mayoral-Vilches and Jasmin Wachter and Crist√≥bal R. J. Veas Chavez and Cathrin Schachner and Luis Javier Navarrete-Lozano and Mar√≠a Sanz-G√≥mez},
      year={2025},
      eprint={2508.13588},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2508.13588}, 
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{mayoralvilches2025cybersecurityaihackingai,
      title={Cybersecurity AI: Hacking the AI Hackers via Prompt Injection}, 
      author={V√≠ctor Mayoral-Vilches and Per Mannermaa Rynning},
      year={2025},
      eprint={2508.21669},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2508.21669}, 
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;CAI was initially developed by &lt;a href="https://aliasrobotics.com"&gt;Alias Robotics&lt;/a&gt; and co-funded by the European EIC accelerator project RIS (GA 101161136) - HORIZON-EIC-2023-ACCELERATOR-01 call. The original agentic principles are inspired from OpenAI's &lt;a href="https://github.com/openai/swarm"&gt;&lt;code&gt;swarm&lt;/code&gt;&lt;/a&gt; library and translated into newer prototypes. This project also makes use of other relevant open source building blocks including &lt;a href="https://github.com/BerriAI/litellm"&gt;&lt;code&gt;LiteLLM&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://github.com/Arize-ai/phoenix"&gt;&lt;code&gt;phoenix&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Academic Collaborations&lt;/h3&gt; 
&lt;p&gt;CAI benefits from ongoing research collaborations with academic institutions. Researchers interested in collaborative projects, dataset access, or academic licenses should contact &lt;a href="mailto:research@aliasrobotics.com"&gt;research@aliasrobotics.com&lt;/a&gt;. We provide special support for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PhD research projects&lt;/li&gt; 
 &lt;li&gt;Academic benchmarking studies&lt;/li&gt; 
 &lt;li&gt;Security education initiatives&lt;/li&gt; 
 &lt;li&gt;Open-source contributions from research labs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- Footnotes --&gt; 
&lt;p&gt;[^1]: Arguably, the Chain-of-Thought agentic pattern is a special case of the Hierarchical agentic pattern. [^2]: Kamhoua, C. A., Leslie, N. O., &amp;amp; Weisman, M. J. (2018). Game theoretic modeling of advanced persistent threat in internet of things. Journal of Cyber Security and Information Systems. [^3]: Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., &amp;amp; Cao, Y. (2023, January). React: Synergizing reasoning and acting in language models. In International Conference on Learning Representations (ICLR). [^4]: Deng, G., Liu, Y., Mayoral-Vilches, V., Liu, P., Li, Y., Xu, Y., ... &amp;amp; Rass, S. (2024). {PentestGPT}: Evaluating and harnessing large language models for automated penetration testing. In 33rd USENIX Security Symposium (USENIX Security 24) (pp. 847-864).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gin-gonic/gin</title>
      <link>https://github.com/gin-gonic/gin</link>
      <description>&lt;p&gt;Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performance‚Äîup to 40 times faster‚Äîthanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gin Web Framework&lt;/h1&gt; 
&lt;img align="right" width="159px" src="https://raw.githubusercontent.com/gin-gonic/logo/master/color.png" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/gin-gonic/gin/actions/workflows/gin.yml"&gt;&lt;img src="https://github.com/gin-gonic/gin/actions/workflows/gin.yml/badge.svg?branch=master" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/gin-gonic/gin"&gt;&lt;img src="https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/gin-gonic/gin"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gin-gonic/gin" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://sourcegraph.com/github.com/gin-gonic/gin?badge"&gt;&lt;img src="https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg?sanitize=true" alt="Sourcegraph" /&gt;&lt;/a&gt; &lt;a href="https://www.codetriage.com/gin-gonic/gin"&gt;&lt;img src="https://www.codetriage.com/gin-gonic/gin/badges/users.svg?sanitize=true" alt="Open Source Helpers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/gin-gonic/gin/releases"&gt;&lt;img src="https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square" alt="Release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ &lt;a href="https://gin-gonic.com/en/blog/news/gin-1-11-0-release-announcement/"&gt;Announcing Gin 1.11.0!&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Read about the latest features and improvements in Gin 1.11.0 on our official blog.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Gin is a high-performance HTTP web framework written in &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;. It provides a Martini-like API but with significantly better performance‚Äîup to 40 times faster‚Äîthanks to &lt;a href="https://github.com/julienschmidt/httprouter"&gt;httprouter&lt;/a&gt;. Gin is designed for building REST APIs, web applications, and microservices where speed and developer productivity are essential.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Gin?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Gin combines the simplicity of Express.js-style routing with Go's performance characteristics, making it ideal for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building high-throughput REST APIs&lt;/li&gt; 
 &lt;li&gt;Developing microservices that need to handle many concurrent requests&lt;/li&gt; 
 &lt;li&gt;Creating web applications that require fast response times&lt;/li&gt; 
 &lt;li&gt;Prototyping web services quickly with minimal boilerplate&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Gin's key features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero allocation router&lt;/strong&gt; - Extremely memory-efficient routing with no heap allocations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt; - Benchmarks show superior speed compared to other Go web frameworks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Middleware support&lt;/strong&gt; - Extensible middleware system for authentication, logging, CORS, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Crash-free&lt;/strong&gt; - Built-in recovery middleware prevents panics from crashing your server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON validation&lt;/strong&gt; - Automatic request/response JSON binding and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Route grouping&lt;/strong&gt; - Organize related routes and apply common middleware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error management&lt;/strong&gt; - Centralized error handling and logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in rendering&lt;/strong&gt; - Support for JSON, XML, HTML templates, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt; - Large ecosystem of community middleware and plugins&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Go version&lt;/strong&gt;: Gin requires &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt; version &lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt; or above&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic Go knowledge&lt;/strong&gt;: Familiarity with Go syntax and package management is helpful&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;With &lt;a href="https://go.dev/wiki/Modules#how-to-use-modules"&gt;Go's module support&lt;/a&gt;, simply import Gin in your code and Go will automatically fetch it during build:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "github.com/gin-gonic/gin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Your First Gin Application&lt;/h3&gt; 
&lt;p&gt;Here's a complete example that demonstrates Gin's simplicity:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "net/http"

  "github.com/gin-gonic/gin"
)

func main() {
  // Create a Gin router with default middleware (logger and recovery)
  r := gin.Default()
  
  // Define a simple GET endpoint
  r.GET("/ping", func(c *gin.Context) {
    // Return JSON response
    c.JSON(http.StatusOK, gin.H{
      "message": "pong",
    })
  })
  
  // Start server on port 8080 (default)
  // Server will listen on 0.0.0.0:8080 (localhost:8080 on Windows)
  r.Run()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Running the application:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Save the code above as &lt;code&gt;main.go&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the application:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;go run main.go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open your browser and visit &lt;a href="http://localhost:8080/ping"&gt;&lt;code&gt;http://localhost:8080/ping&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You should see: &lt;code&gt;{"message":"pong"}&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;What this example demonstrates:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creating a Gin router with default middleware&lt;/li&gt; 
 &lt;li&gt;Defining HTTP endpoints with simple handler functions&lt;/li&gt; 
 &lt;li&gt;Returning JSON responses&lt;/li&gt; 
 &lt;li&gt;Starting an HTTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next Steps&lt;/h3&gt; 
&lt;p&gt;After running your first Gin application, explore these resources to learn more:&lt;/p&gt; 
&lt;h4&gt;üìö Learning Resources&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/docs/doc.md"&gt;Gin Quick Start Guide&lt;/a&gt;&lt;/strong&gt; - Comprehensive tutorial with API examples and build configurations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/examples"&gt;Example Repository&lt;/a&gt;&lt;/strong&gt; - Ready-to-run examples demonstrating various Gin use cases: 
  &lt;ul&gt; 
   &lt;li&gt;REST API development&lt;/li&gt; 
   &lt;li&gt;Authentication &amp;amp; middleware&lt;/li&gt; 
   &lt;li&gt;File uploads and downloads&lt;/li&gt; 
   &lt;li&gt;WebSocket connections&lt;/li&gt; 
   &lt;li&gt;Template rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;h3&gt;API Reference&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin"&gt;Go.dev API Documentation&lt;/a&gt;&lt;/strong&gt; - Complete API reference with examples&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guides&lt;/h3&gt; 
&lt;p&gt;The comprehensive documentation is available on &lt;a href="https://gin-gonic.com"&gt;gin-gonic.com&lt;/a&gt; in multiple languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/en/docs/"&gt;English&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-cn/docs/"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-tw/docs/"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ja/docs/"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://gin-gonic.com/ko-kr/docs/"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://gin-gonic.com/es/docs/"&gt;Espa√±ol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/tr/docs/"&gt;Turkish&lt;/a&gt; | &lt;a href="https://gin-gonic.com/fa/docs/"&gt;Persian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/pt/docs/"&gt;Portugu√™s&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ru/docs/"&gt;Russian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/id/docs/"&gt;Indonesian&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Official Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/tutorial/web-service-gin"&gt;Go.dev Tutorial: Developing a RESTful API with Go and Gin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Performance Benchmarks&lt;/h2&gt; 
&lt;p&gt;Gin demonstrates exceptional performance compared to other Go web frameworks. It uses a custom version of &lt;a href="https://github.com/julienschmidt/httprouter"&gt;HttpRouter&lt;/a&gt; for maximum efficiency. &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/BENCHMARKS.md"&gt;View detailed benchmarks ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gin vs. Other Go Frameworks&lt;/strong&gt; (GitHub API routing benchmark):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Benchmark name&lt;/th&gt; 
   &lt;th align="right"&gt;(1)&lt;/th&gt; 
   &lt;th align="right"&gt;(2)&lt;/th&gt; 
   &lt;th align="right"&gt;(3)&lt;/th&gt; 
   &lt;th align="right"&gt;(4)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGin_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;43550&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;27364 ns/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 B/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 allocs/op&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAce_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;40543&lt;/td&gt; 
   &lt;td align="right"&gt;29670 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAero_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;57632&lt;/td&gt; 
   &lt;td align="right"&gt;20648 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBear_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;9234&lt;/td&gt; 
   &lt;td align="right"&gt;216179 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;86448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;943 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBeego_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7407&lt;/td&gt; 
   &lt;td align="right"&gt;243496 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;71456 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBone_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;420&lt;/td&gt; 
   &lt;td align="right"&gt;2922835 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;720160 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;8620 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkChi_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7620&lt;/td&gt; 
   &lt;td align="right"&gt;238331 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;87696 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkDenco_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;18355&lt;/td&gt; 
   &lt;td align="right"&gt;64494 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;20224 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkEcho_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;31251&lt;/td&gt; 
   &lt;td align="right"&gt;38479 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGocraftWeb_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;4117&lt;/td&gt; 
   &lt;td align="right"&gt;300062 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;131656 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1686 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoji_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3274&lt;/td&gt; 
   &lt;td align="right"&gt;416158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;56112 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;334 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGojiv2_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;1402&lt;/td&gt; 
   &lt;td align="right"&gt;870518 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;352720 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4321 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoJsonRest_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2976&lt;/td&gt; 
   &lt;td align="right"&gt;401507 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;134371 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2737 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoRestful_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;410&lt;/td&gt; 
   &lt;td align="right"&gt;2913158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;910144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2938 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGorillaMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;346&lt;/td&gt; 
   &lt;td align="right"&gt;3384987 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;251650 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1994 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGowwwRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;143025 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;72144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;501 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;55938&lt;/td&gt; 
   &lt;td align="right"&gt;21360 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpTreeMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;153944 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;65856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;671 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkKocha_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;106315 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;23304 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;843 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkLARS_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;47779&lt;/td&gt; 
   &lt;td align="right"&gt;25084 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMacaron_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3266&lt;/td&gt; 
   &lt;td align="right"&gt;371907 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;149409 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1624 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMartini_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;331&lt;/td&gt; 
   &lt;td align="right"&gt;3444706 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;226551 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2325 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPat_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;273&lt;/td&gt; 
   &lt;td align="right"&gt;4381818 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;1483152 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;26963 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPossum_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;164367 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;84448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkR2router_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;160220 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;77328 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;979 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkRivet_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;14625&lt;/td&gt; 
   &lt;td align="right"&gt;82453 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;16272 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTango_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6255&lt;/td&gt; 
   &lt;td align="right"&gt;279611 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;63826 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1618 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTigerTonic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2008&lt;/td&gt; 
   &lt;td align="right"&gt;687874 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;193856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4474 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTraffic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;355&lt;/td&gt; 
   &lt;td align="right"&gt;3478508 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;820744 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;14114 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkVulcan_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6885&lt;/td&gt; 
   &lt;td align="right"&gt;193333 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;19894 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;(1): Total Repetitions achieved in constant time, higher means more confident result&lt;/li&gt; 
 &lt;li&gt;(2): Single Repetition Duration (ns/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(3): Heap Memory (B/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(4): Average Allocations per Repetition (allocs/op), lower is better&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîå Middleware Ecosystem&lt;/h2&gt; 
&lt;p&gt;Gin has a rich ecosystem of middleware for common web development needs. Explore community-contributed middleware:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-contrib"&gt;gin-contrib&lt;/a&gt;&lt;/strong&gt; - Official middleware collection including:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Authentication (JWT, Basic Auth, Sessions)&lt;/li&gt; 
   &lt;li&gt;CORS, Rate limiting, Compression&lt;/li&gt; 
   &lt;li&gt;Logging, Metrics, Tracing&lt;/li&gt; 
   &lt;li&gt;Static file serving, Template engines&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/contrib"&gt;gin-gonic/contrib&lt;/a&gt;&lt;/strong&gt; - Additional community middleware&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üè¢ Production Usage&lt;/h2&gt; 
&lt;p&gt;Gin powers many high-traffic applications and services in production:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/appleboy/gorush"&gt;gorush&lt;/a&gt;&lt;/strong&gt; - High-performance push notification server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/fnproject/fn"&gt;fnproject&lt;/a&gt;&lt;/strong&gt; - Container-native, serverless platform&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/photoprism/photoprism"&gt;photoprism&lt;/a&gt;&lt;/strong&gt; - AI-powered personal photo management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/luraproject/lura"&gt;lura&lt;/a&gt;&lt;/strong&gt; - Ultra-performant API Gateway framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/thoas/picfit"&gt;picfit&lt;/a&gt;&lt;/strong&gt; - Real-time image processing server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/distribworks/dkron"&gt;dkron&lt;/a&gt;&lt;/strong&gt; - Distributed job scheduling system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;Gin is the work of hundreds of contributors from around the world. We welcome and appreciate your contributions!&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Report bugs&lt;/strong&gt; - Help us identify and fix issues&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;Suggest features&lt;/strong&gt; - Share your ideas for improvements&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;Improve documentation&lt;/strong&gt; - Help make our docs clearer&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Submit code&lt;/strong&gt; - Fix bugs or implement new features&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Write tests&lt;/strong&gt; - Improve our test coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Contributing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for detailed guidelines&lt;/li&gt; 
 &lt;li&gt;Join our community discussions and ask questions&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;All contributions are valued and help make Gin better for everyone!&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>elastic/elasticsearch</title>
      <link>https://github.com/elastic/elasticsearch</link>
      <description>&lt;p&gt;Free and Open Source, Distributed, RESTful Search Engine&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>django/django</title>
      <link>https://github.com/django/django</link>
      <description>&lt;p&gt;The Web framework for perfectionists with deadlines.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;====== Django&lt;/h1&gt; 
&lt;p&gt;Django is a high-level Python web framework that encourages rapid development and clean, pragmatic design. Thanks for checking it out.&lt;/p&gt; 
&lt;p&gt;All documentation is in the "&lt;code&gt;docs&lt;/code&gt;" directory and online at &lt;a href="https://docs.djangoproject.com/en/stable/"&gt;https://docs.djangoproject.com/en/stable/&lt;/a&gt;. If you're just getting started, here's how we recommend you read the docs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;First, read &lt;code&gt;docs/intro/install.txt&lt;/code&gt; for instructions on installing Django.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Next, work through the tutorials in order (&lt;code&gt;docs/intro/tutorial01.txt&lt;/code&gt;, &lt;code&gt;docs/intro/tutorial02.txt&lt;/code&gt;, etc.).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you want to set up an actual deployment server, read &lt;code&gt;docs/howto/deployment/index.txt&lt;/code&gt; for instructions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You'll probably want to read through the topical guides (in &lt;code&gt;docs/topics&lt;/code&gt;) next; from there you can jump to the HOWTOs (in &lt;code&gt;docs/howto&lt;/code&gt;) for specific problems, and check out the reference (&lt;code&gt;docs/ref&lt;/code&gt;) for gory details.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;See &lt;code&gt;docs/README&lt;/code&gt; for instructions on building an HTML version of the docs.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Docs are updated rigorously. If you find any problems in the docs, or think they should be clarified in any way, please take 30 seconds to fill out a ticket here: &lt;a href="https://code.djangoproject.com/newticket"&gt;https://code.djangoproject.com/newticket&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;To get more help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Join the &lt;code&gt;Django Discord community &amp;lt;https://chat.djangoproject.com&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Join the community on the &lt;code&gt;Django Forum &amp;lt;https://forum.djangoproject.com/&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To contribute to Django:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out &lt;a href="https://docs.djangoproject.com/en/dev/internals/contributing/"&gt;https://docs.djangoproject.com/en/dev/internals/contributing/&lt;/a&gt; for information about getting involved.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To run Django's test suite:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the instructions in the "Unit tests" section of &lt;code&gt;docs/internals/contributing/writing-code/unit-tests.txt&lt;/code&gt;, published online at &lt;a href="https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/unit-tests/#running-the-unit-tests"&gt;https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/unit-tests/#running-the-unit-tests&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Supporting the Development of Django&lt;/h1&gt; 
&lt;p&gt;Django's development depends on your contributions.&lt;/p&gt; 
&lt;p&gt;If you depend on Django, remember to support the Django Software Foundation: &lt;a href="https://www.djangoproject.com/fundraising/"&gt;https://www.djangoproject.com/fundraising/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>freqtrade/freqtrade</title>
      <link>https://github.com/freqtrade/freqtrade</link>
      <description>&lt;p&gt;Free, open source crypto trading bot&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade_poweredby.svg?sanitize=true" alt="freqtrade" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/freqtrade/freqtrade/actions/"&gt;&lt;img src="https://github.com/freqtrade/freqtrade/actions/workflows/ci.yml/badge.svg?branch=develop" alt="Freqtrade CI" /&gt;&lt;/a&gt; &lt;a href="https://doi.org/10.21105/joss.04864"&gt;&lt;img src="https://joss.theoj.org/papers/10.21105/joss.04864/status.svg?sanitize=true" alt="DOI" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/freqtrade/freqtrade?branch=develop"&gt;&lt;img src="https://coveralls.io/repos/github/freqtrade/freqtrade/badge.svg?branch=develop&amp;amp;service=github" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://www.freqtrade.io"&gt;&lt;img src="https://readthedocs.org/projects/freqtrade/badge/" alt="Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png" alt="freqtrade" /&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This software is for educational purposes only. Do not risk money which you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.&lt;/p&gt; 
&lt;p&gt;Always start by running a trading bot in Dry-run and do not engage money before you understand how it works and what profit/loss you should expect.&lt;/p&gt; 
&lt;p&gt;We strongly recommend you to have coding and Python knowledge. Do not hesitate to read the source code and understand the mechanism of this bot.&lt;/p&gt; 
&lt;h2&gt;Supported Exchange marketplaces&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/exchanges.md"&gt;exchange specific notes&lt;/a&gt; to learn about eventual, special configurations needed for each exchange.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.binance.com/"&gt;Binance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://bitmart.com/"&gt;Bitmart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://bingx.com/invite/0EM9RX"&gt;BingX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://bybit.com/"&gt;Bybit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.gate.io/ref/6266643"&gt;Gate.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.htx.com/"&gt;HTX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://hyperliquid.xyz/"&gt;Hyperliquid&lt;/a&gt; (A decentralized exchange, or DEX)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://kraken.com/"&gt;Kraken&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://okx.com/"&gt;OKX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://okx.com/"&gt;MyOKX&lt;/a&gt; (OKX EEA)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://github.com/ccxt/ccxt/"&gt;potentially many others&lt;/a&gt;. &lt;em&gt;(We cannot guarantee they will work)&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported Futures Exchanges (experimental)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.binance.com/"&gt;Binance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.gate.io/ref/6266643"&gt;Gate.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://hyperliquid.xyz/"&gt;Hyperliquid&lt;/a&gt; (A decentralized exchange, or DEX)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://okx.com/"&gt;OKX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://bybit.com/"&gt;Bybit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please make sure to read the &lt;a href="https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/exchanges.md"&gt;exchange specific notes&lt;/a&gt;, as well as the &lt;a href="https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/leverage.md"&gt;trading with leverage&lt;/a&gt; documentation before diving in.&lt;/p&gt; 
&lt;h3&gt;Community tested&lt;/h3&gt; 
&lt;p&gt;Exchanges confirmed working by the community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://bitvavo.com/"&gt;Bitvavo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.kucoin.com/"&gt;Kucoin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;We invite you to read the bot documentation to ensure you understand how the bot is working.&lt;/p&gt; 
&lt;p&gt;Please find the complete documentation on the &lt;a href="https://www.freqtrade.io"&gt;freqtrade website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Based on Python 3.11+&lt;/strong&gt;: For botting on any operating system - Windows, macOS and Linux.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Persistence&lt;/strong&gt;: Persistence is achieved through sqlite.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Dry-run&lt;/strong&gt;: Run the bot without paying money.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Backtesting&lt;/strong&gt;: Run a simulation of your buy/sell strategy.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Strategy Optimization by machine learning&lt;/strong&gt;: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Adaptive prediction modeling&lt;/strong&gt;: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. &lt;a href="https://www.freqtrade.io/en/stable/freqai/"&gt;Learn more&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Whitelist crypto-currencies&lt;/strong&gt;: Select which crypto-currency you want to trade or use dynamic whitelists.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Blacklist crypto-currencies&lt;/strong&gt;: Select which crypto-currency you want to avoid.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Builtin WebUI&lt;/strong&gt;: Builtin web UI to manage your bot.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Manageable via Telegram&lt;/strong&gt;: Manage the bot with Telegram.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Display profit/loss in fiat&lt;/strong&gt;: Display your profit/loss in fiat currency.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Performance status report&lt;/strong&gt;: Provide a performance status of your current trades.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://www.freqtrade.io/en/stable/docker_quickstart/"&gt;Docker Quickstart documentation&lt;/a&gt; on how to get started quickly.&lt;/p&gt; 
&lt;p&gt;For further (native) installation methods, please refer to the &lt;a href="https://www.freqtrade.io/en/stable/installation/"&gt;Installation documentation page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Basic Usage&lt;/h2&gt; 
&lt;h3&gt;Bot commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;usage: freqtrade [-h] [-V]
                 {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
                 ...

Free, open source crypto trading bot

positional arguments:
  {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
    trade               Trade module.
    create-userdir      Create user-data directory.
    new-config          Create new config
    show-config         Show resolved config
    new-strategy        Create new strategy
    download-data       Download backtesting data.
    convert-data        Convert candle (OHLCV) data from one format to
                        another.
    convert-trade-data  Convert trade data from one format to another.
    trades-to-ohlcv     Convert trade data to OHLCV data.
    list-data           List downloaded data.
    backtesting         Backtesting module.
    backtesting-show    Show past Backtest results
    backtesting-analysis
                        Backtest Analysis module.
    hyperopt            Hyperopt module.
    hyperopt-list       List Hyperopt results
    hyperopt-show       Show details of Hyperopt results
    list-exchanges      Print available exchanges.
    list-markets        Print markets on exchange.
    list-pairs          Print pairs on exchange.
    list-strategies     Print available strategies.
    list-hyperoptloss   Print available hyperopt loss functions.
    list-freqaimodels   Print available freqAI models.
    list-timeframes     Print available timeframes for the exchange.
    show-trades         Show trades.
    test-pairlist       Test your pairlist configuration.
    convert-db          Migrate database to different system
    install-ui          Install FreqUI
    plot-dataframe      Plot candles with indicators.
    plot-profit         Generate plot showing profits.
    webserver           Webserver module.
    strategy-updater    updates outdated strategy files to the current version
    lookahead-analysis  Check for potential look ahead bias.
    recursive-analysis  Check for potential recursive formula issue.

options:
  -h, --help            show this help message and exit
  -V, --version         show program's version number and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Telegram RPC commands&lt;/h3&gt; 
&lt;p&gt;Telegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the &lt;a href="https://www.freqtrade.io/en/latest/telegram-usage/"&gt;documentation&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;/start&lt;/code&gt;: Starts the trader.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/stop&lt;/code&gt;: Stops the trader.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/stopentry&lt;/code&gt;: Stop entering new trades.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/status &amp;lt;trade_id&amp;gt;|[table]&lt;/code&gt;: Lists all or specific open trades.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/profit [&amp;lt;n&amp;gt;]&lt;/code&gt;: Lists cumulative profit from all finished trades, over the last n days.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/profit_long [&amp;lt;n&amp;gt;]&lt;/code&gt;: Lists cumulative profit from all finished long trades, over the last n days.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/profit_short [&amp;lt;n&amp;gt;]&lt;/code&gt;: Lists cumulative profit from all finished short trades, over the last n days.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/forceexit &amp;lt;trade_id&amp;gt;|all&lt;/code&gt;: Instantly exits the given trade (Ignoring &lt;code&gt;minimum_roi&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/fx &amp;lt;trade_id&amp;gt;|all&lt;/code&gt;: Alias to &lt;code&gt;/forceexit&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/performance&lt;/code&gt;: Show performance of each finished trade grouped by pair&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/balance&lt;/code&gt;: Show account balance per currency.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/daily &amp;lt;n&amp;gt;&lt;/code&gt;: Shows profit or loss per day, over the last n days.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/help&lt;/code&gt;: Show help message.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/version&lt;/code&gt;: Show version.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development branches&lt;/h2&gt; 
&lt;p&gt;The project is currently setup in two main branches:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; - This branch contains the latest stable release. This branch is generally well tested.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;feat/*&lt;/code&gt; - These are feature branches, which are being worked on heavily. Please don't use these unless you want to test a specific feature.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;h3&gt;Help / Discord&lt;/h3&gt; 
&lt;p&gt;For any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade &lt;a href="https://discord.gg/p7nuUNVfP7"&gt;discord server&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue"&gt;Bugs / Issues&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;If you discover a bug in the bot, please &lt;a href="https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue"&gt;search the issue tracker&lt;/a&gt; first. If it hasn't been reported, please &lt;a href="https://github.com/freqtrade/freqtrade/issues/new/choose"&gt;create a new issue&lt;/a&gt; and ensure you follow the template guide so that the team can assist you as quickly as possible.&lt;/p&gt; 
&lt;p&gt;For every &lt;a href="https://github.com/freqtrade/freqtrade/issues/new/choose"&gt;issue&lt;/a&gt; created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.&lt;/p&gt; 
&lt;p&gt;--Maintain github's &lt;a href="https://docs.github.com/en/site-policy/github-terms/github-community-code-of-conduct"&gt;community policy&lt;/a&gt;--&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://github.com/freqtrade/freqtrade/labels/enhancement"&gt;Feature Requests&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Have you a great idea to improve the bot you want to share? Please, first search if this feature was not &lt;a href="https://github.com/freqtrade/freqtrade/labels/enhancement"&gt;already discussed&lt;/a&gt;. If it hasn't been requested, please &lt;a href="https://github.com/freqtrade/freqtrade/issues/new/choose"&gt;create a new request&lt;/a&gt; and ensure you follow the template guide so that it does not get lost in the bug reports.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://github.com/freqtrade/freqtrade/pulls"&gt;Pull Requests&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Feel like the bot is missing a feature? We welcome your pull requests!&lt;/p&gt; 
&lt;p&gt;Please read the &lt;a href="https://github.com/freqtrade/freqtrade/raw/develop/CONTRIBUTING.md"&gt;Contributing document&lt;/a&gt; to understand the requirements before sending your pull-requests.&lt;/p&gt; 
&lt;p&gt;Coding is not a necessity to contribute - maybe start with improving the documentation? Issues labeled &lt;a href="https://github.com/freqtrade/freqtrade/labels/good%20first%20issue"&gt;good first issue&lt;/a&gt; can be good first contributions, and will help get you familiar with the codebase.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; before starting any major new feature work, &lt;em&gt;please open an issue describing what you are planning to do&lt;/em&gt; or talk to us on &lt;a href="https://discord.gg/p7nuUNVfP7"&gt;discord&lt;/a&gt; (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Always create your PR against the &lt;code&gt;develop&lt;/code&gt; branch, not &lt;code&gt;stable&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;h3&gt;Up-to-date clock&lt;/h3&gt; 
&lt;p&gt;The clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.&lt;/p&gt; 
&lt;h3&gt;Minimum hardware required&lt;/h3&gt; 
&lt;p&gt;To run this bot we recommend you a cloud instance with a minimum of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Software requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://docs.python-guide.org/en/latest/starting/installation/"&gt;Python &amp;gt;= 3.11&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pip.pypa.io/en/stable/installing/"&gt;pip&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git"&gt;git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ta-lib.github.io/ta-lib-python/"&gt;TA-Lib&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://virtualenv.pypa.io/en/stable/installation.html"&gt;virtualenv&lt;/a&gt; (Recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/products/docker"&gt;Docker&lt;/a&gt; (Recommended)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>solana-labs/solana</title>
      <link>https://github.com/solana-labs/solana</link>
      <description>&lt;p&gt;Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PLEASE READ: This repo is now a public archive&lt;/h1&gt; 
&lt;p&gt;This repo still exists in archived form, feel free to fork any reference implementations it still contains.&lt;/p&gt; 
&lt;p&gt;See Agave, the Solana validator implementation from Anza: &lt;a href="https://github.com/anza-xyz/agave"&gt;https://github.com/anza-xyz/agave&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://solana.com"&gt; &lt;img alt="Solana" src="https://i.imgur.com/IKyzQ6T.png" width="250" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/solana-core"&gt;&lt;img src="https://img.shields.io/crates/v/solana-core.svg?sanitize=true" alt="Solana crate" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/solana-core"&gt;&lt;img src="https://docs.rs/solana-core/badge.svg?sanitize=true" alt="Solana documentation" /&gt;&lt;/a&gt; &lt;a href="https://buildkite.com/solana-labs/solana/builds?branch=master"&gt;&lt;img src="https://badge.buildkite.com/8cc350de251d61483db98bdfc895b9ea0ac8ffa4a32ee850ed.svg?branch=master" alt="Build status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/solana-labs/solana"&gt;&lt;img src="https://codecov.io/gh/solana-labs/solana/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Building&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;1. Install rustc, cargo and rustfmt.&lt;/strong&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl https://sh.rustup.rs -sSf | sh
$ source $HOME/.cargo/env
$ rustup component add rustfmt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When building the master branch, please make sure you are using the latest stable rust version by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ rustup update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When building a specific release branch, you should check the rust version in &lt;code&gt;ci/rust-version.sh&lt;/code&gt; and if necessary, install that version by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ rustup install VERSION
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that if this is not the latest rust version on your machine, cargo commands may require an &lt;a href="https://rust-lang.github.io/rustup/overrides.html"&gt;override&lt;/a&gt; in order to use the correct version.&lt;/p&gt; 
&lt;p&gt;On Linux systems you may need to install libssl-dev, pkg-config, zlib1g-dev, protobuf etc.&lt;/p&gt; 
&lt;p&gt;On Ubuntu:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ sudo apt-get update
$ sudo apt-get install libssl-dev libudev-dev pkg-config zlib1g-dev llvm clang cmake make libprotobuf-dev protobuf-compiler
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Fedora:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ sudo dnf install openssl-devel systemd-devel pkg-config zlib-devel llvm clang cmake make protobuf-devel protobuf-compiler perl-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;strong&gt;2. Download the source code.&lt;/strong&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ git clone https://github.com/solana-labs/solana.git
$ cd solana
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;strong&gt;3. Build.&lt;/strong&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ ./cargo build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Testing&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Run the test suite:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ ./cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Starting a local testnet&lt;/h3&gt; 
&lt;p&gt;Start your own testnet locally, instructions are in the &lt;a href="https://docs.solanalabs.com/clusters/benchmark"&gt;online docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Accessing the remote development cluster&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;devnet&lt;/code&gt; - stable public cluster for development accessible via devnet.solana.com. Runs 24/7. Learn more about the &lt;a href="https://docs.solanalabs.com/clusters"&gt;public clusters&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Benchmarking&lt;/h1&gt; 
&lt;p&gt;First, install the nightly build of rustc. &lt;code&gt;cargo bench&lt;/code&gt; requires the use of the unstable features only available in the nightly build.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ rustup install nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the benchmarks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cargo +nightly bench
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Release Process&lt;/h1&gt; 
&lt;p&gt;The release process for this project is described &lt;a href="https://raw.githubusercontent.com/solana-labs/solana/master/RELEASE.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Code coverage&lt;/h1&gt; 
&lt;p&gt;To generate code coverage statistics:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ scripts/coverage.sh
$ open target/cov/lcov-local/index.html
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Why coverage? While most see coverage as a code quality metric, we see it primarily as a developer productivity metric. When a developer makes a change to the codebase, presumably it's a &lt;em&gt;solution&lt;/em&gt; to some problem. Our unit-test suite is how we encode the set of &lt;em&gt;problems&lt;/em&gt; the codebase solves. Running the test suite should indicate that your change didn't &lt;em&gt;infringe&lt;/em&gt; on anyone else's solutions. Adding a test &lt;em&gt;protects&lt;/em&gt; your solution from future changes. Say you don't understand why a line of code exists, try deleting it and running the unit-tests. The nearest test failure should tell you what problem was solved by that code. If no test fails, go ahead and submit a Pull Request that asks, "what problem is solved by this code?" On the other hand, if a test does fail and you can think of a better way to solve the same problem, a Pull Request with your solution would most certainly be welcome! Likewise, if rewriting a test can better communicate what code it's protecting, please send us that patch!&lt;/p&gt; 
&lt;h1&gt;Disclaimer&lt;/h1&gt; 
&lt;p&gt;All claims, content, designs, algorithms, estimates, roadmaps, specifications, and performance measurements described in this project are done with the Solana Labs, Inc. (‚ÄúSL‚Äù) good faith efforts. It is up to the reader to check and validate their accuracy and truthfulness. Furthermore, nothing in this project constitutes a solicitation for investment.&lt;/p&gt; 
&lt;p&gt;Any content produced by SL or developer resources that SL provides are for educational and inspirational purposes only. SL does not encourage, induce or sanction the deployment, integration or use of any such applications (including the code comprising the Solana blockchain protocol) in violation of applicable laws or regulations and hereby prohibits any such deployment, integration or use. This includes the use of any such applications by the reader (a) in violation of export control or sanctions laws of the United States or any other applicable jurisdiction, (b) if the reader is located in or ordinarily resident in a country or territory subject to comprehensive sanctions administered by the U.S. Office of Foreign Assets Control (OFAC), or (c) if the reader is or is working on behalf of a Specially Designated National (SDN) or a person subject to similar blocking or denied party prohibitions.&lt;/p&gt; 
&lt;p&gt;The reader should be aware that U.S. export control and sanctions laws prohibit U.S. persons (and other persons that are subject to such laws) from transacting with persons in certain countries and territories or that are on the SDN list. Accordingly, there is a risk to individuals that other persons using any of the code contained in this repo, or a derivation thereof, may be sanctioned persons and that transactions with such persons would be a violation of U.S. export controls and sanctions law.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gar-b-age/CookLikeHOC</title>
      <link>https://github.com/Gar-b-age/CookLikeHOC</link>
      <description>&lt;p&gt;ü•¢ÂÉèËÄÅ‰π°È∏°üêîÈÇ£Ê†∑ÂÅöÈ•≠„ÄÇ‰∏ªË¶ÅÈÉ®ÂàÜ‰∫é2024Âπ¥ÂÆåÂ∑•ÔºåÈùûËÄÅ‰π°È∏°ÂÆòÊñπ‰ªìÂ∫ì„ÄÇÊñáÂ≠óÊù•Ëá™„ÄäËÄÅ‰π°È∏°ËèúÂìÅÊ∫ØÊ∫êÊä•Âëä„ÄãÔºåÂπ∂ÂÅöÂΩíÁ∫≥„ÄÅÁºñËæë‰∏éÊï¥ÁêÜ„ÄÇCookLikeHOC.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/banner.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h1&gt;ÂÉèËÄÅ‰π°È∏°ÈÇ£Ê†∑ÂÅöÈ•≠&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/Gar-b-age/CookLikeHOC/issues/26"&gt;&lt;strong&gt;‰∏Ä‰∫õËØ¥Êòé&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‰ªìÂ∫ì‰∏ª‰ΩìÈÉ®ÂàÜ‰∫é2024Âπ¥ÂÆåÂ∑•ÔºåÂíå2025Âπ¥9Êúà‰ªΩÁöÑËàÜËÆ∫‰∫ã‰ª∂Êó†ÂÖ≥„ÄÇÊà™Ê≠¢Êèê‰∫§Êó∂Ôºå‰ªìÂ∫ìÁöÑË¥°ÁåÆËÄÖ‰ª¨‰∏éËÄÅ‰π°È∏°ÁöÑÂîØ‰∏ÄÂÖ≥Á≥ªÂè™ÊúâÊ∂àË¥πËÄÖÂíåÂïÜÂÆ∂ÁöÑÂÖ≥Á≥ª„ÄÇÊú¨‰ªìÂ∫ì‰∏çÊòØËÄÅ‰π°È∏°ÁöÑÂÆòÊñπ‰ªìÂ∫ì„ÄÇÂ¶ÇÊûúÊúâ‰ªª‰ΩïÈóÆÈ¢òÊàñÊÑèËßÅÂª∫ËÆÆÔºåÊ¨¢ËøéÊåáÂá∫&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Êñ∞Êõ¥Êñ∞&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ê¨¢ËøéÂ§ßÂÆ∂Êù•Ë¥°ÁåÆÂÆûÊãçÂõæ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Áé∞Â∑≤‰∏äÁ∫øÁΩëÈ°µÁ´ØÔºå&lt;a href="https://cooklikehoc.soilzhu.su"&gt;ÁÇπÂáªËÆøÈóÆ&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run with Docker? Check it out &lt;a href="https://github.com/Gar-b-age/CookLikeHOC/tree/main/docker_support"&gt;here&lt;/a&gt;, supported by &lt;a href="https://github.com/honestAnt"&gt;@honestAnt&lt;/a&gt; in &lt;a href="https://github.com/Gar-b-age/CookLikeHOC/pull/141"&gt;PR #141&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI ÁªòÂà∂ÁöÑÊâãÁªòÂõæÁâàÂèäAIÈÖçÂõæÊµÅÁ®ãÁâàÁΩëÈ°µÔºö &lt;a href="https://ai.cooklikehoc.soilzhu.su"&gt;ÁÇπÂáªËÆøÈóÆ&lt;/a&gt;, ÊâãÁªòÂõæÁî± &lt;a href="https://github.com/liucongg"&gt;@liucongg&lt;/a&gt; Ë¥°ÁåÆÔºåËßÅ &lt;a href="https://github.com/Gar-b-age/CookLikeHOC/pull/143"&gt;PR #143&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://t.me/cooklikehoc"&gt;&lt;img src="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/tg.png" alt="link" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;„ÄäËÄÅ‰π°È∏°ËèúÂìÅÊ∫ØÊ∫êÊä•Âëä„Äã‰∏≠ÂÖ¨Â∏ÉÁöÑÊâÄÊúâËèúÂìÅÂ∑≤ÁªèÂÖ®ÈÉ®ÂΩïÂÖ•ÂÆåÔºåÊ¨¢ËøéÂ§ßÂÆ∂Êü•ÈòÖÂíåË°•ÂÖÖ„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÊñáÂ≠óË∂ÖÂ§ßÊÆµcopyËá™&lt;a href="https://www.lxjchina.com.cn/display.asp?id=4226"&gt;„ÄäËÄÅ‰π°È∏°ËèúÂìÅÊ∫ØÊ∫êÊä•Âëä„Äã&lt;/a&gt;ÔºåÊúâÁºñËæë‰∏éÊï¥ÁêÜ&lt;/p&gt; 
&lt;p&gt;ÊåáË∑ØÈöîÂ£Å &lt;a href="https://cook.aiursoft.cn/"&gt;How To Cook&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Ëá≥‰∫é‰∏∫‰ªÄ‰πà‰ªìÂ∫ìÂêçË¶ÅÂè´CookLikeHOCÔºåÂõ†‰∏∫Áõ¥Êé•ÂÜôLaoxiangjiÂ§ßÊ¶Ç‰∏çÊñπ‰æøÈòÖËØªÔºåËÄåHome Original ChickenÊòØchina dailyÊä•ÈÅì‰∏≠ÊâÄ‰ΩøÁî®ÁöÑËÄÅ‰π°È∏°ÁöÑËã±ÊñáÂêçÔºåÊïÖÁÆÄÂÜôÊàêHOC„ÄÇ&lt;/p&gt; 
&lt;p&gt;Contributor&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://contrib.rocks/image?repo=Gar-b-age/CookLikeHOC" alt="cr" /&gt;&lt;/p&gt; 
&lt;p&gt;Logo &lt;img src="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/logo.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;p&gt;Star History&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Gar-b-age/CookLikeHOC&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Gar-b-age/CookLikeHOC&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>siyuan-note/siyuan</title>
      <link>https://github.com/siyuan-note/siyuan</link>
      <description>&lt;p&gt;A privacy-first, self-hosted, fully open source personal knowledge management software, written in typescript and golang.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img alt="SiYuan" src="https://b3log.org/images/brand/siyuan-128.png" /&gt; &lt;br /&gt; &lt;em&gt;Refactor your thinking&lt;/em&gt; &lt;br /&gt;&lt;br /&gt; &lt;a title="Build Status" target="_blank" href="https://github.com/siyuan-note/siyuan/actions/workflows/ci.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/siyuan-note/siyuan/cd.yml?style=flat-square" /&gt;&lt;/a&gt; &lt;a title="Releases" target="_blank" href="https://github.com/siyuan-note/siyuan/releases"&gt;&lt;img src="https://img.shields.io/github/release/siyuan-note/siyuan.svg?style=flat-square&amp;amp;color=9CF" /&gt;&lt;/a&gt; &lt;a title="Downloads" target="_blank" href="https://github.com/siyuan-note/siyuan/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/siyuan-note/siyuan/total.svg?style=flat-square&amp;amp;color=blueviolet" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a title="Docker Pulls" target="_blank" href="https://hub.docker.com/r/b3log/siyuan"&gt;&lt;img src="https://img.shields.io/docker/pulls/b3log/siyuan.svg?style=flat-square&amp;amp;color=green" /&gt;&lt;/a&gt; &lt;a title="Docker Image Size" target="_blank" href="https://hub.docker.com/r/b3log/siyuan"&gt;&lt;img src="https://img.shields.io/docker/image-size/b3log/siyuan.svg?style=flat-square&amp;amp;color=ff96b4" /&gt;&lt;/a&gt; &lt;a title="Hits" target="_blank" href="https://github.com/siyuan-note/siyuan"&gt;&lt;img src="https://hits.b3log.org/siyuan-note/siyuan.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a title="AGPLv3" target="_blank" href="https://www.gnu.org/licenses/agpl-3.0.txt"&gt;&lt;img src="http://img.shields.io/badge/license-AGPLv3-orange.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;a title="Code Size" target="_blank" href="https://github.com/siyuan-note/siyuan"&gt;&lt;img src="https://img.shields.io/github/languages/code-size/siyuan-note/siyuan.svg?style=flat-square&amp;amp;color=yellow" /&gt;&lt;/a&gt; &lt;a title="GitHub Pull Requests" target="_blank" href="https://github.com/siyuan-note/siyuan/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr-closed/siyuan-note/siyuan.svg?style=flat-square&amp;amp;color=FF9966" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a title="GitHub Commits" target="_blank" href="https://github.com/siyuan-note/siyuan/commits/master"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/siyuan-note/siyuan.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;a title="Last Commit" target="_blank" href="https://github.com/siyuan-note/siyuan/commits/master"&gt;&lt;img src="https://img.shields.io/github/last-commit/siyuan-note/siyuan.svg?style=flat-square&amp;amp;color=FF9900" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt; &lt;a title="Twitter" target="_blank" href="https://twitter.com/b3logos"&gt;&lt;img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/b3logos?label=Follow&amp;amp;style=social" /&gt;&lt;/a&gt; &lt;a title="Discord" target="_blank" href="https://discord.gg/dmMbCqVX7G"&gt;&lt;img alt="Chat on Discord" src="https://img.shields.io/discord/808152298789666826?label=Discord&amp;amp;logo=Discord&amp;amp;style=social" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://trendshift.io/repositories/3949" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3949" alt="siyuan-note%2Fsiyuan | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/README_zh_CN.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/README_ja_JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#-introduction"&gt;üí° Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#-features"&gt;üîÆ Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#-architecture-and-ecosystem"&gt;üèóÔ∏è Architecture and Ecosystem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#-star-history"&gt;üåü Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#%EF%B8%8F-roadmap"&gt;üó∫Ô∏è Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#-download-setup"&gt;üöÄ Download Setup&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#app-market"&gt;App Market&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#installation-package"&gt;Installation Package&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#docker-hosting"&gt;Docker Hosting&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#unraid-hosting"&gt;Unraid Hosting&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#insider-preview"&gt;Insider Preview&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#%EF%B8%8F-community"&gt;üèòÔ∏è Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#%EF%B8%8F-development-guide"&gt;üõ†Ô∏è Development Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#-faq"&gt;‚ùì FAQ&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#how-does-siyuan-store-data"&gt;How does SiYuan store data?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#does-it-support-data-synchronization-through-a-third-party-sync-disk"&gt;Does it support data synchronization through a third-party sync disk?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#is-siyuan-open-source"&gt;Is SiYuan open source?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#how-to-upgrade-to-a-new-version"&gt;How to upgrade to a new version?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#what-if-some-blocks-such-as-paragraph-blocks-in-list-items-cannot-find-the-block-icon"&gt;What if some blocks (such as paragraph blocks in list items) cannot find the block icon?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#what-should-i-do-if-the-data-repo-key-is-lost"&gt;What should I do if the data repo key is lost?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#do-i-need-to-pay-for-it"&gt;Do I need to pay for it?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#-acknowledgement"&gt;üôè Acknowledgement&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/#contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° Introduction&lt;/h2&gt; 
&lt;p&gt;SiYuan is a privacy-first personal knowledge management system, support fine-grained block-level reference and Markdown WYSIWYG.&lt;/p&gt; 
&lt;p&gt;Welcome to &lt;a href="https://liuyun.io"&gt;SiYuan English Discussion Forum&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://b3logfile.com/file/2024/01/feature0-1orBRlI.png" alt="feature0.png" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://b3logfile.com/file/2024/02/feature5-1-uYYjAqy.png" alt="feature51.png" /&gt;&lt;/p&gt; 
&lt;h2&gt;üîÆ Features&lt;/h2&gt; 
&lt;p&gt;Most features are free, even for commercial use.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Content block 
  &lt;ul&gt; 
   &lt;li&gt;Block-level reference and two-way links&lt;/li&gt; 
   &lt;li&gt;Custom attributes&lt;/li&gt; 
   &lt;li&gt;SQL query embed&lt;/li&gt; 
   &lt;li&gt;Protocol &lt;code&gt;siyuan://&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Editor 
  &lt;ul&gt; 
   &lt;li&gt;Block-style&lt;/li&gt; 
   &lt;li&gt;Markdown WYSIWYG&lt;/li&gt; 
   &lt;li&gt;List outline&lt;/li&gt; 
   &lt;li&gt;Block zoom-in&lt;/li&gt; 
   &lt;li&gt;Million-word large document editing&lt;/li&gt; 
   &lt;li&gt;Mathematical formulas, charts, flowcharts, Gantt charts, timing charts, staffs, etc.&lt;/li&gt; 
   &lt;li&gt;Web clipping&lt;/li&gt; 
   &lt;li&gt;PDF Annotation link&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Export 
  &lt;ul&gt; 
   &lt;li&gt;Block ref and embed&lt;/li&gt; 
   &lt;li&gt;Standard Markdown with assets&lt;/li&gt; 
   &lt;li&gt;PDF, Word and HTML&lt;/li&gt; 
   &lt;li&gt;Copy to WeChat MP, Zhihu and Yuque&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Database 
  &lt;ul&gt; 
   &lt;li&gt;Table view&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Flashcard spaced repetition&lt;/li&gt; 
 &lt;li&gt;AI writing and Q/A chat via OpenAI API&lt;/li&gt; 
 &lt;li&gt;Tesseract OCR&lt;/li&gt; 
 &lt;li&gt;Multi-tab, drag and drop to split screen&lt;/li&gt; 
 &lt;li&gt;Template snippet&lt;/li&gt; 
 &lt;li&gt;JavaScript/CSS snippet&lt;/li&gt; 
 &lt;li&gt;Android/iOS/HarmonyOS App&lt;/li&gt; 
 &lt;li&gt;Docker deployment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siyuan-note/siyuan/raw/master/API.md"&gt;API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community marketplace&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Some features are only available to paid members, for more details please refer to &lt;a href="https://b3log.org/siyuan/en/pricing.html"&gt;Pricing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üèóÔ∏è Architecture and Ecosystem&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://b3logfile.com/file/2023/05/SiYuan_Arch-Sgu8vXT.png" alt="SiYuan Arch" title="SiYuan Arch" /&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Forks&lt;/th&gt; 
   &lt;th&gt;Stars&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/88250/lute"&gt;lute&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Editor engine&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/forks/88250/lute" alt="GitHub forks" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/stars/88250/lute" alt="GitHub Repo stars" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/siyuan-note/siyuan-chrome"&gt;chrome&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Chrome/Edge extension&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/forks/siyuan-note/siyuan-chrome" alt="GitHub forks" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/stars/siyuan-note/siyuan-chrome" alt="GitHub Repo stars" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/siyuan-note/bazaar"&gt;bazaar&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Community marketplace&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/forks/siyuan-note/bazaar" alt="GitHub forks" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/stars/siyuan-note/bazaar" alt="GitHub Repo stars" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/siyuan-note/dejavu"&gt;dejavu&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Data repo&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/forks/siyuan-note/dejavu" alt="GitHub forks" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/stars/siyuan-note/dejavu" alt="GitHub Repo stars" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/siyuan-note/petal"&gt;petal&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin API&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/forks/siyuan-note/petal" alt="GitHub forks" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/stars/siyuan-note/petal" alt="GitHub Repo stars" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/siyuan-note/siyuan-android"&gt;android&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Android App&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/forks/siyuan-note/siyuan-android" alt="GitHub forks" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/stars/siyuan-note/siyuan-android" alt="GitHub Repo stars" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/siyuan-note/siyuan-ios"&gt;ios&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;iOS App&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/forks/siyuan-note/siyuan-ios" alt="GitHub forks" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/stars/siyuan-note/siyuan-ios" alt="GitHub Repo stars" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/siyuan-note/siyuan-harmony"&gt;harmony&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;HarmonyOS App&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/forks/siyuan-note/siyuan-harmony" alt="GitHub forks" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/stars/siyuan-note/siyuan-harmony" alt="GitHub Repo stars" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/siyuan-note/riff"&gt;riff&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Spaced repetition&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/forks/siyuan-note/riff" alt="GitHub forks" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://img.shields.io/github/stars/siyuan-note/riff" alt="GitHub Repo stars" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üåü Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#siyuan-note/siyuan&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=siyuan-note/siyuan&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=siyuan-note/siyuan&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=siyuan-note/siyuan&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;üó∫Ô∏è Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/siyuan-note/projects/1"&gt;SiYuan development plan and progress&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/siyuan-note/siyuan/master/CHANGELOG.md"&gt;SiYuan changelog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Download Setup&lt;/h2&gt; 
&lt;p&gt;It is recommended to give priority to installing through the application market on the desktop and mobile, so that you can upgrade the version with one click in the future.&lt;/p&gt; 
&lt;h3&gt;App Market&lt;/h3&gt; 
&lt;p&gt;Mobile:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://apps.apple.com/us/app/siyuan/id1583226508"&gt;App Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://play.google.com/store/apps/details?id=org.b3log.siyuan"&gt;Google Play&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://f-droid.org/packages/org.b3log.siyuan"&gt;F-Droid&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Desktop:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://apps.microsoft.com/detail/9p7hpmxp73k4"&gt;Microsoft Store&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation Package&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://b3log.org/siyuan/en/download.html"&gt;B3log&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siyuan-note/siyuan/releases"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Docker Hosting&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Docker Deployment&lt;/summary&gt; 
 &lt;h4&gt;Overview&lt;/h4&gt; 
 &lt;p&gt;The easiest way to serve SiYuan on a server is to deploy it through Docker.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Image name &lt;code&gt;b3log/siyuan&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://hub.docker.com/r/b3log/siyuan"&gt;Image URL&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;File structure&lt;/h4&gt; 
 &lt;p&gt;The overall program is located under &lt;code&gt;/opt/siyuan/&lt;/code&gt;, which is basically the structure under the resources folder of the Electron installation package:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;appearance: icon, theme, languages&lt;/li&gt; 
  &lt;li&gt;guide: user guide document&lt;/li&gt; 
  &lt;li&gt;stage: interface and static resources&lt;/li&gt; 
  &lt;li&gt;kernel: kernel program&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;Entrypoint&lt;/h4&gt; 
 &lt;p&gt;The entry point is set when building the Docker image: &lt;code&gt;ENTRYPOINT ["/opt/siyuan/entrypoint.sh"]&lt;/code&gt;. This script allows changing the &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt; of the user that will run inside the container. This is especially relevant to solve permission issues when mounting directories from the host. The &lt;code&gt;PUID&lt;/code&gt; (User ID) and &lt;code&gt;PGID&lt;/code&gt; (Group ID) can be passed as environment variables, making it easier to ensure correct permissions when accessing host-mounted directories.&lt;/p&gt; 
 &lt;p&gt;Use the following parameters when running the container with &lt;code&gt;docker run b3log/siyuan&lt;/code&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;--workspace&lt;/code&gt;: Specifies the workspace folder path, mounted to the container via &lt;code&gt;-v&lt;/code&gt; on the host&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--accessAuthCode&lt;/code&gt;: Specifies the access authorization code&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;More parameters can be found using &lt;code&gt;--help&lt;/code&gt;. Here‚Äôs an example of a startup command with the new environment variables:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  -v workspace_dir_host:workspace_dir_container \
  -p 6806:6806 \
  -e PUID=1001 -e PGID=1002 \
  b3log/siyuan \
  --workspace=workspace_dir_container \
  --accessAuthCode=xxx
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;PUID&lt;/code&gt;: Custom user ID (optional, defaults to &lt;code&gt;1000&lt;/code&gt; if not provided)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;PGID&lt;/code&gt;: Custom group ID (optional, defaults to &lt;code&gt;1000&lt;/code&gt; if not provided)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;workspace_dir_host&lt;/code&gt;: The workspace folder path on the host&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;workspace_dir_container&lt;/code&gt;: The path of the workspace folder in the container, as specified in &lt;code&gt;--workspace&lt;/code&gt; 
   &lt;ul&gt; 
    &lt;li&gt;In alternative, it's possible to set the path via the &lt;code&gt;SIYUAN_WORKSPACE_PATH&lt;/code&gt; env variable. The commandline will always have the priority, if both are set&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;accessAuthCode&lt;/code&gt;: Access authorization code (please &lt;strong&gt;be sure to modify&lt;/strong&gt;, otherwise anyone can access your data) 
   &lt;ul&gt; 
    &lt;li&gt;In alternative, it's possible to set the auth code via the &lt;code&gt;SIYUAN_ACCESS_AUTH_CODE&lt;/code&gt; env variable. The commandline will always have the priority, if both are set&lt;/li&gt; 
    &lt;li&gt;To disable the Access authorization code set the env variable &lt;code&gt;SIYUAN_ACCESS_AUTH_CODE_BYPASS=true&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;To simplify things, it is recommended to configure the workspace folder path to be consistent on the host and container, such as having both &lt;code&gt;workspace_dir_host&lt;/code&gt; and &lt;code&gt;workspace_dir_container&lt;/code&gt; configured as &lt;code&gt;/siyuan/workspace&lt;/code&gt;. The corresponding startup command would be:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  -v /siyuan/workspace:/siyuan/workspace \
  -p 6806:6806 \
  -e PUID=1001 -e PGID=1002 \
  b3log/siyuan \
  --workspace=/siyuan/workspace/ \
  --accessAuthCode=xxx
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Docker Compose&lt;/h4&gt; 
 &lt;p&gt;For users running Siyuan with Docker Compose, the environment variables &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt; can be passed to customize the user and group IDs. Here's an example of a Docker Compose configuration:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;version: "3.9"
services:
  main:
    image: b3log/siyuan
    command: ['--workspace=/siyuan/workspace/', '--accessAuthCode=${AuthCode}']
    ports:
      - 6806:6806
    volumes:
      - /siyuan/workspace:/siyuan/workspace
    restart: unless-stopped
    environment:
      # A list of time zone identifiers can be found at https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
      - TZ=${YOUR_TIME_ZONE}
      - PUID=${YOUR_USER_PUID}  # Customize user ID
      - PGID=${YOUR_USER_PGID}  # Customize group ID
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;In this setup:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt; are set dynamically and passed to the container&lt;/li&gt; 
  &lt;li&gt;If these variables are not provided, the default &lt;code&gt;1000&lt;/code&gt; will be used&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;By specifying &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt; in the environment, you avoid the need to explicitly set the &lt;code&gt;user&lt;/code&gt; directive (&lt;code&gt;user: '1000:1000'&lt;/code&gt;) in the compose file. The container will dynamically adjust the user and group based on these environment variables at startup.&lt;/p&gt; 
 &lt;h4&gt;User Permissions&lt;/h4&gt; 
 &lt;p&gt;In the image, the &lt;code&gt;entrypoint.sh&lt;/code&gt; script ensures the creation of the &lt;code&gt;siyuan&lt;/code&gt; user and group with the specified &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt;. Therefore, when the host creates a workspace folder, pay attention to setting the user and group ownership of the folder to match the &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt; you plan to use. For example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;chown -R 1001:1002 /siyuan/workspace
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you use custom &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt; values, the entrypoint script will ensure that the correct user and group are created inside the container, and ownership of mounted volumes will be adjusted accordingly. There‚Äôs no need to manually pass &lt;code&gt;-u&lt;/code&gt; in &lt;code&gt;docker run&lt;/code&gt; or &lt;code&gt;docker-compose&lt;/code&gt; as the environment variables will handle the customization.&lt;/p&gt; 
 &lt;h4&gt;Hidden port&lt;/h4&gt; 
 &lt;p&gt;Use NGINX reverse proxy to hide port 6806, please note:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Configure WebSocket reverse proxy &lt;code&gt;/ws&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;Note&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Be sure to confirm the correctness of the mounted volume, otherwise the data will be lost after the container is deleted&lt;/li&gt; 
  &lt;li&gt;Do not use URL rewriting for redirection, otherwise there may be problems with authentication, it is recommended to configure a reverse proxy&lt;/li&gt; 
  &lt;li&gt;If you encounter permission issues, verify that the &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt; environment variables match the ownership of the mounted directories on your host system&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;Limitations&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Does not support desktop and mobile application connections, only supports use on browsers&lt;/li&gt; 
  &lt;li&gt;Export to PDF, HTML and Word formats is not supported&lt;/li&gt; 
  &lt;li&gt;Import Markdown file is not supported&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Unraid Hosting&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Unraid Deployment&lt;/summary&gt; 
 &lt;p&gt;Note: First run &lt;code&gt;chown -R 1000:1000 /mnt/user/appdata/siyuan&lt;/code&gt; in the terminal&lt;/p&gt; 
 &lt;p&gt;Template reference:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;Web UI: 6806
Container Port: 6806
Container Path: /home/siyuan
Host path: /mnt/user/appdata/siyuan
PUID: 1000
PGID: 1000
Publish parameters: --accessAuthCode=******(Access authorization code)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Insider Preview&lt;/h3&gt; 
&lt;p&gt;We release insider preview before major updates, please visit &lt;a href="https://github.com/siyuan-note/insider"&gt;https://github.com/siyuan-note/insider&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üèòÔ∏è Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://liuyun.io"&gt;English Discussion Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://liuyun.io/article/1687779743723"&gt;User community summary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siyuan-note/awesome"&gt;Awesome SiYuan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ†Ô∏è Development Guide&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/siyuan-note/siyuan/raw/master/.github/CONTRIBUTING.md"&gt;Development Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ùì FAQ&lt;/h2&gt; 
&lt;h3&gt;How does SiYuan store data?&lt;/h3&gt; 
&lt;p&gt;The data is saved in the workspace folder, in the workspace data folder:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;assets&lt;/code&gt; is used to save all inserted assets&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;emojis&lt;/code&gt; is used to save emoji images&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;snippets&lt;/code&gt; is used to save code snippets&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;storage&lt;/code&gt; is used to save query conditions, layouts and flashcards, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;templates&lt;/code&gt; is used to save template snippets&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;widgets&lt;/code&gt; is used to save widgets&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;plugins&lt;/code&gt; is used to save plugins&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;public&lt;/code&gt; is used to save public data&lt;/li&gt; 
 &lt;li&gt;The rest of the folders are the notebook folders created by the user, files with the suffix of &lt;code&gt;.sy&lt;/code&gt; in the notebook folder are used to save the document data, and the data format is JSON&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Does it support data synchronization through a third-party sync disk?&lt;/h3&gt; 
&lt;p&gt;Data synchronization through third-party synchronization disks is not supported, otherwise data may be corrupted.&lt;/p&gt; 
&lt;p&gt;Although it does not support third-party sync disks, it supports connect with third-party cloud storage (Member's privileges).&lt;/p&gt; 
&lt;p&gt;In addition, you can also consider manually exporting and importing data to achieve data synchronization:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Desktop: &lt;kbd&gt;Settings&lt;/kbd&gt; - &lt;kbd&gt;Export&lt;/kbd&gt; - &lt;kbd&gt;Export Data&lt;/kbd&gt; / &lt;kbd&gt;Import Data&lt;/kbd&gt;&lt;/li&gt; 
 &lt;li&gt;Mobile: &lt;kbd&gt;Right column&lt;/kbd&gt; - &lt;kbd&gt;About&lt;/kbd&gt; - &lt;kbd&gt;Export Data&lt;/kbd&gt; / &lt;kbd&gt;Import Data&lt;/kbd&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Is SiYuan open source?&lt;/h3&gt; 
&lt;p&gt;SiYuan is completely open source, and contributions are welcome:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siyuan-note/siyuan"&gt;User Interface and Kernel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siyuan-note/siyuan-android"&gt;Android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siyuan-note/siyuan-ios"&gt;iOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siyuan-note/siyuan-harmony"&gt;HarmonyOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siyuan-note/siyuan-chrome"&gt;Chrome Clipping Extension&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more details, please refer to &lt;a href="https://github.com/siyuan-note/siyuan/raw/master/.github/CONTRIBUTING.md"&gt;Development Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;How to upgrade to a new version?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;If installed via app store, please update via app store&lt;/li&gt; 
 &lt;li&gt;If it is installed through the installation package on the desktop, you can open the option of &lt;kbd&gt;Settings&lt;/kbd&gt; - &lt;kbd&gt;About&lt;/kbd&gt; - &lt;kbd&gt;Automatically download update installation package&lt;/kbd&gt;, so that SiYuan will automatically download The latest version of the installation package and prompts to install&lt;/li&gt; 
 &lt;li&gt;If it is installed by manual installation package, please download the installation package again to install&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can &lt;kbd&gt;Check update&lt;/kbd&gt; in &lt;kbd&gt;Settings&lt;/kbd&gt; - &lt;kbd&gt;About&lt;/kbd&gt; - &lt;kbd&gt;Current Version&lt;/kbd&gt;, or pay attention to &lt;a href="https://b3log.org/siyuan/en/download.html"&gt;Official Download&lt;/a&gt; or &lt;a href="https://github.com/siyuan-note/siyuan/releases"&gt;GitHub Releases&lt;/a&gt; to get the new version.&lt;/p&gt; 
&lt;h3&gt;What if some blocks (such as paragraph blocks in list items) cannot find the block icon?&lt;/h3&gt; 
&lt;p&gt;The first sub-block under the list item is the block icon omitted. You can move the cursor into this block and trigger its block menu with &lt;kbd&gt;Ctrl+/&lt;/kbd&gt; .&lt;/p&gt; 
&lt;h3&gt;What should I do if the data repo key is lost?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;If the data repo key is correctly initialized on multiple devices before, the key is the same on all devices and can be set in &lt;kbd&gt;Settings&lt;/kbd&gt; - &lt;kbd&gt;About&lt;/kbd&gt; - &lt;kbd&gt;Data repo key&lt;/kbd&gt; - &lt;kbd&gt;Copy key string&lt;/kbd&gt; retrieve&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If it has not been configured correctly before (for example, the keys on multiple devices are inconsistent) or all devices are unavailable and the key string cannot be obtained, you can reset the key by following the steps below:&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;Manually back up the data, you can use &lt;kbd&gt;Export Data&lt;/kbd&gt; or directly copy the &lt;kbd&gt;workspace/data/&lt;/kbd&gt; folder on the file system&lt;/li&gt; 
   &lt;li&gt;&lt;kbd&gt;Settings&lt;/kbd&gt; - &lt;kbd&gt;About&lt;/kbd&gt; - &lt;kbd&gt;Data rep key&lt;/kbd&gt; - &lt;kbd&gt;Reset data repo&lt;/kbd&gt;&lt;/li&gt; 
   &lt;li&gt;Reinitialize the data repo key. After initializing the key on one device, other devices import the key&lt;/li&gt; 
   &lt;li&gt;The cloud uses the new synchronization directory, the old synchronization directory is no longer available and can be deleted&lt;/li&gt; 
   &lt;li&gt;The existing cloud snapshots are no longer available and can be deleted&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Do I need to pay for it?&lt;/h3&gt; 
&lt;p&gt;Most features are free, even for commercial use.&lt;/p&gt; 
&lt;p&gt;Member's privileges can only be used after payment, please refer to &lt;a href="https://b3log.org/siyuan/en/pricing.html"&gt;Pricing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgement&lt;/h2&gt; 
&lt;p&gt;The birth of SiYuan is inseparable from many open source projects and contributors, please refer to the project source code kernel/go.mod, app/package.json and project homepage.&lt;/p&gt; 
&lt;p&gt;The growth of SiYuan is inseparable from user feedback and promotion, thank you for everyone's help to SiYuan ‚ù§Ô∏è&lt;/p&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;p&gt;Welcome to join us and contribute code to SiYuan together.&lt;/p&gt; 
&lt;a href="https://github.com/siyuan-note/siyuan/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=siyuan-note/siyuan" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>istio/istio</title>
      <link>https://github.com/istio/istio</link>
      <description>&lt;p&gt;Connect, secure, control, and observe services.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Istio&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://bestpractices.coreinfrastructure.org/projects/1395"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/1395/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/istio/istio"&gt;&lt;img src="https://goreportcard.com/badge/github.com/istio/istio" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/istio.io/istio"&gt;&lt;img src="https://godoc.org/istio.io/istio?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://istio.io/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/projects/istio/icon/color/istio-icon-color.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/istio/istio/raw/master/logo/istio-bluelogo-whitebackground-unframed.svg" /&gt; 
  &lt;img title="Istio" height="100" width="100" alt="Istio logo" src="https://github.com/istio/istio/raw/master/logo/istio-bluelogo-whitebackground-unframed.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;p&gt;Istio is an open source service mesh that layers transparently onto existing distributed applications. Istio‚Äôs powerful features provide a uniform and more efficient way to secure, connect, and monitor services. Istio is the path to load balancing, service-to-service authentication, and monitoring ‚Äì with few or no service code changes.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For in-depth information about how to use Istio, visit &lt;a href="https://istio.io"&gt;istio.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;To ask questions and get assistance from our community, visit &lt;a href="https://github.com/istio/istio/discussions"&gt;Github Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;To learn how to participate in our overall community, visit &lt;a href="https://istio.io/about/community"&gt;our community page&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In this README:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/istio/istio/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/istio/istio/master/#repositories"&gt;Repositories&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/istio/istio/master/#issue-management"&gt;Issue management&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition, here are some other documents you may wish to read:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/istio/community#istio-community"&gt;Istio Community&lt;/a&gt; - describes how to get involved and contribute to the Istio project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/istio/istio/wiki/Preparing-for-Development"&gt;Istio Developer's Guide&lt;/a&gt; - explains how to set up and use an Istio development environment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/istio/istio/wiki/Development-Conventions"&gt;Project Conventions&lt;/a&gt; - describes the conventions we use within the code base&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/istio/istio/wiki/Writing-Fast-and-Lean-Code"&gt;Creating Fast and Lean Code&lt;/a&gt; - performance-oriented advice and guidelines for the code base&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You'll find many other useful documents on our &lt;a href="https://github.com/istio/istio/wiki"&gt;Wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://istio.io/latest/docs/concepts/what-is-istio/"&gt;Istio&lt;/a&gt; is an open platform for providing a uniform way to &lt;a href="https://istio.io/latest/docs/examples/microservices-istio/"&gt;integrate microservices&lt;/a&gt;, manage &lt;a href="https://istio.io/latest/docs/concepts/traffic-management/"&gt;traffic flow&lt;/a&gt; across microservices, enforce policies and aggregate telemetry data. Istio's control plane provides an abstraction layer over the underlying cluster management platform, such as Kubernetes.&lt;/p&gt; 
&lt;p&gt;Istio is composed of these components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Envoy&lt;/strong&gt; - Sidecar proxies per microservice to handle ingress/egress traffic between services in the cluster and from a service to external services. The proxies form a &lt;em&gt;secure microservice mesh&lt;/em&gt; providing a rich set of functions like discovery, rich layer-7 routing, circuit breakers, policy enforcement and telemetry recording/reporting functions.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Note: The service mesh is not an overlay network. It simplifies and enhances how microservices in an application talk to each other over the network provided by the underlying platform.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Istiod&lt;/strong&gt; - The Istio control plane. It provides service discovery, configuration and certificate management. It consists of the following sub-components:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pilot&lt;/strong&gt; - Responsible for configuring the proxies at runtime.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Citadel&lt;/strong&gt; - Responsible for certificate issuance and rotation.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Galley&lt;/strong&gt; - Responsible for validating, ingesting, aggregating, transforming and distributing config within Istio.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Operator&lt;/strong&gt; - The component provides user friendly options to operate the Istio service mesh.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Repositories&lt;/h2&gt; 
&lt;p&gt;The Istio project is divided across a few GitHub repositories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/istio/api"&gt;istio/api&lt;/a&gt;. This repository defines component-level APIs and common configuration formats for the Istio platform.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/istio/community"&gt;istio/community&lt;/a&gt;. This repository contains information on the Istio community, including the various documents that govern the Istio open source project.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/istio/istio/master/README.md"&gt;istio/istio&lt;/a&gt;. This is the main code repository. It hosts Istio's core components, install artifacts, and sample programs. It includes:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/istio/istio/master/istioctl/"&gt;istioctl&lt;/a&gt;. This directory contains code for the &lt;a href="https://istio.io/latest/docs/reference/commands/istioctl/"&gt;&lt;em&gt;istioctl&lt;/em&gt;&lt;/a&gt; command line utility.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/istio/istio/master/pilot/"&gt;pilot&lt;/a&gt;. This directory contains platform-specific code to populate the &lt;a href="https://istio.io/docs/concepts/traffic-management/#pilot"&gt;abstract service model&lt;/a&gt;, dynamically reconfigure the proxies when the application topology changes, as well as translate &lt;a href="https://istio.io/latest/docs/reference/config/networking/"&gt;routing rules&lt;/a&gt; into proxy specific configuration.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/istio/istio/master/security/"&gt;security&lt;/a&gt;. This directory contains &lt;a href="https://istio.io/latest/docs/concepts/security/"&gt;security&lt;/a&gt; related code, including Citadel (acting as Certificate Authority), citadel agent, etc.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/istio/proxy"&gt;istio/proxy&lt;/a&gt;. The Istio proxy contains extensions to the &lt;a href="https://github.com/envoyproxy/envoy"&gt;Envoy proxy&lt;/a&gt; (in the form of Envoy filters) that support authentication, authorization, and telemetry collection.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/istio/ztunnel"&gt;istio/ztunnel&lt;/a&gt;. The repository contains the Rust implementation of the ztunnel component of Ambient mesh.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/istio/client-go"&gt;istio/client-go&lt;/a&gt;. This repository defines auto-generated Kubernetes clients for interacting with Istio resources programmatically.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Only the &lt;code&gt;istio/api&lt;/code&gt; and &lt;code&gt;istio/client-go&lt;/code&gt; repositories expose stable interfaces intended for direct usage as libraries.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Issue management&lt;/h2&gt; 
&lt;p&gt;We use GitHub to track all of our bugs and feature requests. Each issue we track has a variety of metadata:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Epic&lt;/strong&gt;. An epic represents a feature area for Istio as a whole. Epics are fairly broad in scope and are basically product-level things. Each issue is ultimately part of an epic.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Milestone&lt;/strong&gt;. Each issue is assigned a milestone. This is 0.1, 0.2, ..., or 'Nebulous Future'. The milestone indicates when we think the issue should get addressed.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Priority&lt;/strong&gt;. Each issue has a priority which is represented by the column in the &lt;a href="https://github.com/orgs/istio/projects/6"&gt;Prioritization&lt;/a&gt; project. Priority can be one of P0, P1, P2, or &amp;gt;P2. The priority indicates how important it is to address the issue within the milestone. P0 says that the milestone cannot be considered achieved if the issue isn't resolved.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg" /&gt; 
  &lt;img width="300" alt="Cloud Native Computing Foundation logo" src="https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;Istio is a &lt;a href="https://cncf.io"&gt;Cloud Native Computing Foundation&lt;/a&gt; project.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>mtdvio/every-programmer-should-know</title>
      <link>https://github.com/mtdvio/every-programmer-should-know</link>
      <description>&lt;p&gt;A collection of (mostly) technical things every software developer should know about&lt;/p&gt;&lt;hr&gt;&lt;div align="center" markdown="1"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://tuple.app/every-programmer-should-know"&gt; &lt;img width="400" alt="Tuple's sponsorship image" src="https://github.com/user-attachments/assets/dc223735-2060-476e-9f76-0b225e03ce1f" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;a href="https://tuple.app/every-programmer-should-know"&gt;Tuple, the premier screen sharing app for developers&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://tuple.app/every-programmer-should-know"&gt;Available for MacOS &amp;amp; Windows&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" markdown="1"&gt;
  Want to become a Senior Engineer sooner? 
 &lt;p&gt;&lt;a href="https://maven.com/top-engineer/fast-track-to-senior?utm_source=github&amp;amp;utm_campaign=autumn_repo_bump"&gt;Join a waitlist for repo author's course&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Every Programmer Should Know &lt;span&gt;ü§î&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;A collection of (mostly) technical things every software developer should know.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;‚òù&lt;/span&gt; &lt;em&gt;These are resources I can recommend to every programmer regardless of their skill level or tech stack&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Highly opinionated &lt;span&gt;üí£&lt;/span&gt;. Not backed by science. Comes in no particular order &lt;span&gt;‚ôª&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;U like it? &lt;span&gt;‚≠ê&lt;/span&gt; it and &lt;a href="https://twitter.com/mr_mig_by/status/900735231552098306"&gt;share&lt;/a&gt; with a friendly developer! U don't like it? &lt;a href="https://twitter.com/RespectfulMemes/status/900147758845308930"&gt;Watch the doggo&lt;/a&gt; &lt;span&gt;üê∂&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;P.S. You &lt;a href="https://xkcd.com/1050/"&gt;don't need to know&lt;/a&gt; all of that by heart to be a programmer. But knowing the stuff will help you become better! &lt;span&gt;üí™&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;P.P.S. &lt;a href="https://raw.githubusercontent.com/mtdvio/every-programmer-should-know/master/CONTRIBUTING.md"&gt;Contributions&lt;/a&gt; are welcome!&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Introduction&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=SzJ46YA_RaA"&gt;Map of Computer Science&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="http://carlcheo.com/compsci"&gt;40 Key Computer Science Concepts Explained In Layman‚Äôs Terms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://roadmap.sh/computer-science"&gt;Computer Science Roadmap&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Falsehoods&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kdeldycke/awesome-falsehood"&gt;Awesome Falsehoods&lt;/a&gt; üíä Curated list of falsehoods programmers believe in. Check for things you do not know about Strings, Addresses, Names, Numbers, Emails, Timezones and Dates and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Algorithms&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://bigocheatsheet.com/"&gt;Big O Cheatsheet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/34189798-computer-science-distilled"&gt;Computer Science Distilled&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/22847284-grokking-algorithms-an-illustrated-guide-for-programmers-and-other-curio"&gt;Grokking Algorithms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/108986.Introduction_to_Algorithms?from_search=true&amp;amp;from_srp=true&amp;amp;qid=8mUglV9uZ1&amp;amp;rank=1"&gt;Introduction to Algorithms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cs.usfca.edu/~galles/visualization/Algorithms.html"&gt;Algorithms Visualization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cp-algorithms.com/"&gt;Algorithms for Competitive Programming&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Data Structures&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://sp19.datastructur.es/"&gt;UC Berkeley, Data Structures Course&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.edx.org/course/foundations-data-structures-iitbombayx-cs213-1x-0#!"&gt;Foundations of Data Structures - EDX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures"&gt;Data Structures - Coursera&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://courses.csail.mit.edu/6.042/spring17/mcs.pdf"&gt;Mathematics for Computer Science - Eric Lehman&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Numbers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/12093869-how-to-count"&gt;How to Count&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="http://floating-point-gui.de/"&gt;Floating Point Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html#680"&gt;What Every Computer Scientist Should Know About Floating-Point Arithmetic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://www.codechef.com/wiki/tutorial-number-theory/"&gt;Basic Number Theory Every Programmer Should Know...&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Strings&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://www.joelonsoftware.com/articles/Unicode.html"&gt;Unicode and Character Sets&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/codebox/homoglyph/"&gt;Homoglyphs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://cldr.unicode.org/"&gt;Unicode Common Locale Data Repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=B1Sf1IhA0j4"&gt;ASCII&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=vLBtrd9Ar28"&gt;UTF-8&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Latency&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html"&gt;Interactive Latency Infographics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://gist.github.com/jboner/2841832"&gt;Latency Numbers Every Programmer Should Know&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Time&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://unix4lyfe.org/time/"&gt;Some notes about time&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=-5wpm-gesOY"&gt;The Problem with Timezones&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Memory&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://lwn.net/Articles/250967/"&gt;What every Programmer should know about memory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Distributed Systems&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/56977420-understanding-distributed-systems"&gt;Understanding Distributed Systems&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/23463279-designing-data-intensive-applications"&gt;Designing Data-Intensive Applications&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìú&lt;/span&gt; &lt;a href="https://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf"&gt;Designs, Lessons and Advice from Building Large Distributed Systems&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìú&lt;/span&gt; &lt;a href="https://www.microsoft.com/en-us/research/publication/time-clocks-ordering-events-distributed-system/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Ftime-clocks.pdf"&gt;Time, Clocks and the Ordering of Events in a Distributed System&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://queue.acm.org/detail.cfm?id=2745385"&gt;There is No Now&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://aphyr.com/tags/jepsen"&gt;Jepsen: how different databases behave under partition&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìú&lt;/span&gt; &lt;a href="https://pages.cs.wisc.edu/~zuyu/files/fallacies.pdf"&gt;Fallacies of Distributed Computing Explained&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RegExp&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/regexhq"&gt;RegexHQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ziishaned/learn-regex"&gt;Learn regex the easy way&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Security&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.dwheeler.com/secure-programs/"&gt;Security Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="http://loup-vaillant.fr/articles/rolling-your-own-crypto"&gt;Rolling Your Own Crypto&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://gist.github.com/tqbf/be58d2d39690c3b366ad"&gt;Cryptographic Right Answers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://gist.github.com/paragonie-scott/e9319254c8ecbad4f227"&gt;An Open Letter to Developers Everywhere (About Cryptography)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/128003.Foundations_of_Security"&gt;Foundations of Security: What Every Programmer Needs to Know &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://owasp.org/www-project-top-ten"&gt;OWASP Top 10&lt;/a&gt; - The "gold standard" for web application vulnerabilities.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://portswigger.net"&gt;Portswigger Academy&lt;/a&gt; - Practical Labs for learning about web application security.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://google-gruyere.appspot.com/part1"&gt;Web Application Exploits and Defenses&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://www.integralist.co.uk/posts/hashing-and-encryption/"&gt;Hashing, Encryption and Encoding&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;UX/Usability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/18197267-don-t-make-me-think-revisited"&gt;Don't Make Me Think: A Common Sense Approach to Web Usability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://vimeo.com/36579366"&gt;Inventing on Principle&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;SEO&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://katemats.com/blog/what-every-programmer-should-know-about-seo"&gt;What Every Programmer Should Know About SEO&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìú&lt;/span&gt; &lt;a href="https://web.cs.wpi.edu/~cs562/s98/pdf/Boxology.pdf"&gt;A Field Guide to Boxology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìú&lt;/span&gt; &lt;a href="https://github.com/papers-we-love/papers-we-love/raw/master/design/out-of-the-tar-pit.pdf?raw=true"&gt;Out of the Tar Pit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìú&lt;/span&gt; &lt;a href="http://www.cs.unc.edu/techreports/86-020.pdf"&gt;No Silver Bullet ‚Äî Essence and Accidents of Software Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=_ahvzDzKdB0"&gt;Growing a Language&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=JHGkaShoyNs"&gt;CQRS and Event Sourcing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.poodr.com/"&gt;Practical Object Oriented Design in Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=CglSFhwbI3s"&gt;Evolutionary Software Architectures&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer"&gt;System Design: A Primer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://blog.sessionstack.com/how-does-javascript-actually-work-part-1-b0bacc073cf"&gt;How JavaScript works: part-1&lt;/a&gt;, &lt;a href="https://blog.sessionstack.com/how-javascript-works-inside-the-v8-engine-5-tips-on-how-to-write-optimized-code-ac089e62b12e"&gt;2&lt;/a&gt;, &lt;a href="https://blog.sessionstack.com/how-javascript-works-memory-management-how-to-handle-4-common-memory-leaks-3f28b94cfbec"&gt;3&lt;/a&gt;, &lt;a href="https://blog.sessionstack.com/how-javascript-works-event-loop-and-the-rise-of-async-programming-5-ways-to-better-coding-with-2f077c4438b5"&gt;4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=lNTaC-JWmdI&amp;amp;t=166s&amp;amp;list=PLZlJZzHmx31XvgT96DfbXQ4IMb1ryztbp&amp;amp;index=33"&gt;Entity-Component-System Architecture with Unity by example&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Code Design&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="http://www.principles-wiki.net/"&gt;Programming Principles Wiki&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Engineering Philosophy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=ho7oagHeqNc"&gt;Category Theory in Life&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.infoq.com/presentations/Simple-Made-Easy"&gt;Simple Made Easy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://www.targetprocess.com/articles/speed-in-software-development/"&gt;Speed In Software Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=QVBlnCTu9Ms"&gt;#NoEstimates&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=0SARbwvhupQ&amp;amp;feature=youtu.be"&gt;The Myth of the Genius Programmer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=FKTxC9pl-WM&amp;amp;t=2s"&gt;Making Badass Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://www.zenprogrammer.org/en/10-rules-of-a-zen-programmer.html"&gt;The Ten Rules of a Zen Programmer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="http://antirez.com/news/112"&gt;The mythical 10x programmer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://queue.acm.org/detail.cfm?id=3068754"&gt;The Debugging Mindset&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="http://worrydream.com/dbx/"&gt;The Future of Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://www.infoworld.com/article/3214481/application-development/the-good-software-development-manifesto.html"&gt;The Good Software Development Manifesto&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=8bZh5LMaSmE"&gt;All the Little Things&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="http://norvig.com/21-days.html"&gt;Teach Yourself Programming in Ten Years&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Practices&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/44919.Working_Effectively_with_Legacy_Code"&gt;Working Effectively with Legacy Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/ru/book/show/8677004-the-art-of-readable-code"&gt;The Art of Readable Code: Simple and Practical Techniques for Writing Better Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/4845.Code_Complete"&gt;Code Complete&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/3735293-clean-code"&gt;Clean Code: A Handbook of Agile Software Craftsmanship&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/387190.Test_Driven_Development"&gt;Test Driven Development: By Example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;‚úÖ&lt;/span&gt; &lt;a href="https://github.com/mr-mig/going-to-production"&gt;Going To Production Checklist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/1069827.Release_It_"&gt;Release It!&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://mostly-adequate.gitbook.io/mostly-adequate-guide/"&gt;Professor Frisby's Mostly Adequate Guide to Functional Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/43713.Structure_and_Interpretation_of_Computer_Programs"&gt;SICP: Structure and Interpretation of Computer Programs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://fsharpforfunandprofit.com/posts/13-ways-of-looking-at-a-turtle-3/"&gt;Thirteen Ways of Looking at a Turtle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìú&lt;/span&gt; &lt;a href="https://www.info.ucl.ac.be/~pvr/VanRoyChapter.pdf"&gt;Programming Paradigms for Dummies: What Every Programmer Should Know&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learnxinyminutes.com/"&gt;Learn X in Y Minutes&lt;/a&gt; Learn the basics of a language in a highly condensed way.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://hyperpolyglot.org/"&gt;Hyperpolyglot&lt;/a&gt; Compare commonly used features of more or less similar languages side-by-side. Helps you to jump Python&amp;lt;-&amp;gt;Ruby, Ocaml&amp;lt;-&amp;gt;Haskell, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://medium.com/@mr_mig_by/pomodoro-for-programmers-d6568dd1e6fc"&gt;Pomodoro for Programmers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://landing.google.com/sre/sre-book/toc/index.html"&gt;Site Reliability Engineering&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Career&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üí∞&lt;/span&gt; &lt;a href="https://www.levels.fyi"&gt;Levels FYI&lt;/a&gt;&lt;br /&gt; Salary stats for various tech companies. Better than Glassdoor.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="http://www.applematters.com/article/10-things-every-programmer-should-know-for-their-first-job/"&gt;10 Things Every Programmer Should Know For Their First Job&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://www.codementor.io/blog/best-cities-software-engineer-earnings-271vpf599k"&gt;How Much Do Software Engineers Really Make in Each City?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://hackerlife.co/blog/san-francisco-large-corporation-employee-tenure"&gt;Software Engineers Tenure in San Francisco&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slides.com/mr-mig/se101"&gt;Software Engineering 101&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/6399113-the-passionate-programmer"&gt;The Passionate Programmer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/23232941-soft-skills"&gt;Soft Skills: The software developer's life manual&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/35674293-the-complete-software-developer-s-career-guide"&gt;The Complete Software Developer's Career Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/29895093-programming-beyond-practices"&gt;Programming Beyond Practices: Be More Than Just a Code Monkey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/spreadsheets/d/1hfl67rI0Pk_hSm0GIX0QByW4NgfAH-cEmMa4N6UoO1w/edit#gid=1203141194"&gt;A list of European Investors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://medium.com/free-code-camp/ten-rules-for-negotiating-a-job-offer-ee17cccbdab6"&gt;Ten Rules for Negotiating a Job Offer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://medium.freecodecamp.com/how-to-interview-as-a-developer-candidate-b666734f12dd"&gt;How To Interview As a Developer Candidate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://relocate.me/blog/job-relocation/landing-a-tech-job-abroad-7-simple-tips/#more-514"&gt;How To Get a Tech Job Abroad Faster&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="http://vlsicad.ucsd.edu/Research/Advice/star_engineer.pdf"&gt;How To Be A STAR Engineer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://tldroptions.io/"&gt;TL;DR; Stock Options&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://blog.carta.com/equity-101-stock-option-basics/"&gt;Equity 101 for Startup Employees&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/25707092-cracking-the-coding-interview"&gt;Cracking the Coding Interview: 189 Programming Questions and Solutions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üî•&lt;/span&gt; &lt;a href="https://github.com/kdn251/interviews"&gt;Everything you need to know to get the job&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://github.com/yangshun/tech-interview-handbook"&gt;Tech Interview Handbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://norvig.com/21-days.html"&gt;Teach Yourself Programming in Ten Years&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìÑ&lt;/span&gt; &lt;a href="https://qotoqot.com/blog/founder-skills/"&gt;What you should know as a founder of a software company&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.pramp.com/"&gt;Code Interview Prep &amp;amp; Programming Questions | Pramp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://github.com/97-things/97-things-every-programmer-should-know"&gt;97 things every programmer should know&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href="https://www.youtube.com/watch?v=bmSAYlu0NcY&amp;amp;t=403s"&gt;A Philosophy of Software Design | John Ousterhout | Talks at Google&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Fine-tune Your Resume&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üî®&lt;/span&gt; &lt;a href="https://cvcompiler.com/"&gt;CV Compiler&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Open Source&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üåê&lt;/span&gt; &lt;a href="https://www.deployhq.com/git"&gt;Learn how to use Git and GitHub&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Remote Work&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üåê&lt;/span&gt; &lt;a href="https://docs.google.com/spreadsheets/d/1TLJSlNxCbwRNxy14Toe1PYwbCTY7h0CNHeer9J0VRzE/htmlview?sle=true#gid=1279011369"&gt;Remotive.io: Startups hiring remotely&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üåê&lt;/span&gt; &lt;a href="https://github.com/georgemandis/remote-working-list"&gt;Remote Work List for Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;‚ö°&lt;/span&gt; &lt;a href="https://nomadlist.com/"&gt;NomadList&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://zapier.com/learn/remote-work/"&gt;The Ultimate Guide to Remote Work&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üè†&lt;/span&gt; &lt;a href="https://github.com/lukasz-madon/awesome-remote-job"&gt;Awesome Remote Job&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Problem Solving&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/593458.The_Art_and_Craft_of_Problem_Solving"&gt;The Art and Craft of Problem Solving&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/192221.How_to_Solve_It"&gt;How to Solve It: A New Aspect of Mathematical Method&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Soft Skills&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/774088.Difficult_Conversations"&gt;Difficult Conversations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/15014.Crucial_Conversations"&gt;Crucial Conversations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;a href="https://www.goodreads.com/book/show/4865.How_to_Win_Friends_and_Influence_People"&gt;How to Win Friends and Influence People&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mental Health&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dreamingechoes/awesome-mental-health"&gt;Awesome Mental Health&lt;/a&gt;&lt;br /&gt; A curated list of awesome articles, websites and resources about mental health in the software industry.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Papers on Programming&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;‚ù§Ô∏è&lt;/span&gt; &lt;a href="https://github.com/papers-we-love/papers-we-love"&gt;Papers We Love&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üì∞&lt;/span&gt; &lt;a href="https://blog.acolyer.org/"&gt;The Morning Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://akkadia.org/drepper/cpumemory.pdf"&gt;What Every Programmer Should Know About Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf"&gt;Go To Statement Considered Harmful&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üì∞&lt;/span&gt; &lt;a href="https://arxiv.org/"&gt;Arxiv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üì∞&lt;/span&gt; &lt;a href="https://sci-hub.se/"&gt;Sci-hub&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Free Books on Programming&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üìö&lt;/span&gt; &lt;a href="https://github.com/EbookFoundation/free-programming-books"&gt;Free Programming Books&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Services &lt;span&gt;‚ö°&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;a href="https://www.abstractapi.com"&gt;Abstract API's&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ripienaar/free-for-dev/raw/master/README.md"&gt;Free For Dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abhishekbanthia/Public-APIs"&gt;Public APIs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://thenounproject.com/"&gt;The Noun Project&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.producthunt.com/@jurica87/collections/without-coding"&gt;Without Coding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://simpleicons.org/"&gt;Simpleicons&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn-anything.xyz/"&gt;Learn Anything&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://repl.it/"&gt;repl.it&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Licenses&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://choosealicense.com/"&gt;Choose An Open Source License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tldrlegal.com/"&gt;Well-explained Software licenses in TLDR version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.freecodecamp.org/how-open-source-licenses-work-and-how-to-add-them-to-your-projects-34310c3cf94"&gt;How open source licenses work and how to add them to your projects&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Where To Look For Further Info&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://guide.freecodecamp.org/"&gt;freeCodeCamp Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.geeksforgeeks.org/"&gt;GeeksForGeeks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dev.to/"&gt;Dev.To&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stackoverflow.com/"&gt;Stack Overflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dzone.com/"&gt;Dzone&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Coding Practice Sites &lt;span&gt;‚ö°&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="http://codeforces.com/"&gt;CodeForces&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://www.codechef.com"&gt;CodeChef&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://coderbyte.com/"&gt;Coderbyte&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://www.codingame.com/"&gt;CodinGame&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://csacademy.com/"&gt;Cs Academy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://hackerrank.com/"&gt;HackerRank&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://spoj.com/"&gt;Spoj&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://hackerearth.com/"&gt;HackerEarth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://www.topcoder.com/"&gt;TopCoder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://codewars.com/"&gt;Codewars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="http://www.exercism.io/"&gt;Exercism&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://codesignal.com/"&gt;CodeSignal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://projecteuler.net/"&gt;Project Euler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://leetcode.com/"&gt;LeetCode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://www.firecode.io/"&gt;Firecode.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://www.interviewbit.com/"&gt;InterviewBit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://ucoder.com.br"&gt;uCoder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://www.lintcode.com/"&gt;LintCode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://codecombat.com/"&gt;CodeCombat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://www.interviewcake.com/"&gt;InterviewCake&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://atcoder.jp/"&gt;At Coder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://www.codility.com/"&gt;Codility&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://icpc.kattis.com/"&gt;ICPC Problem Archive&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://codemia.io/"&gt;Codemia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://labex.io/"&gt;LabEx&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; &lt;a href="https://codebattle.hexlet.io/"&gt;Codebattle&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Platform Engineering&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A modern discipline that evolved from DevOps and SRE principles, focused on improving developer experience and productivity by building and managing self-service tools and workflows, often through an Internal Developer Platform (IDP). The goal is to reduce cognitive load on developers and streamline the path to production.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;What is Platform Engineering?&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/platform-engineering/what-is-platform-engineering"&gt;Microsoft Learn: What is platform engineering?&lt;/a&gt;&lt;br /&gt; A comprehensive overview of the practice, its goals, and core capabilities.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.atlassian.com/developer-experience/platform-engineering"&gt;Atlassian: What is Platform Engineering?&lt;/a&gt;&lt;br /&gt; A great explanation of the roles and responsibilities of a platform team.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Internal Developer Platform (IDP)&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://internaldeveloperplatform.org/what-is-an-internal-developer-platform/"&gt;internaldeveloperplatform.org: What is an IDP?&lt;/a&gt;&lt;br /&gt; A foundational resource explaining the concept of an IDP as the core product of a platform team.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.atlassian.com/developer-experience/internal-developer-platform"&gt;Atlassian: Internal Developer Platform Guide&lt;/a&gt;&lt;br /&gt; A deep dive into the benefits and best practices for building an IDP.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Golden Paths (Paved Roads)&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://backstage.spotify.com/learn/onboarding-software-to-backstage/setting-up-software-templates/11-spotify-templates/"&gt;Spotify Engineering: How we use Golden Paths to solve fragmentation&lt;/a&gt;&lt;br /&gt; The original concept from Spotify, explaining how they use "opinionated and supported paths" to guide developers.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.redhat.com/en/topics/devops/golden-paths"&gt;Red Hat: What is a Golden Path for software development?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;A clear article on how Golden Paths provide templates and standardized workflows to increase efficiency.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>cloudflare/capnweb</title>
      <link>https://github.com/cloudflare/capnweb</link>
      <description>&lt;p&gt;JavaScript/TypeScript-native, low-boilerplate, object-capability RPC system&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Cap'n Web: A JavaScript-native RPC system&lt;/h1&gt; 
&lt;p&gt;Cap'n Web is a spiritual sibling to &lt;a href="https://capnproto.org"&gt;Cap'n Proto&lt;/a&gt; (and is created by the same author), but designed to play nice in the web stack. That means:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Like Cap'n Proto, it is an object-capability protocol. ("Cap'n" is short for "capabilities and".) We'll get into this more below, but it's incredibly powerful.&lt;/li&gt; 
 &lt;li&gt;Unlike Cap'n Proto, Cap'n Web has no schemas. In fact, it has almost no boilerplate whatsoever. This means it works more like the &lt;a href="https://blog.cloudflare.com/javascript-native-rpc/"&gt;JavaScript-native RPC system in Cloudflare Workers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;That said, it integrates nicely with TypeScript.&lt;/li&gt; 
 &lt;li&gt;Also unlike Cap'n Proto, Cap'n Web's underlying serialization is human-readable. In fact, it's just JSON, with a little pre-/post-processing.&lt;/li&gt; 
 &lt;li&gt;It works over HTTP, WebSocket, and postMessage() out-of-the-box, with the ability to extend it to other transports easily.&lt;/li&gt; 
 &lt;li&gt;It works in all major browsers, Cloudflare Workers, Node.js, and other modern JavaScript runtimes. The whole thing compresses (minify+gzip) to under 10kB with no dependencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Cap'n Web is more expressive than almost every other RPC system, because it implements an object-capability RPC model. That means it:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports bidirectional calling. The client can call the server, and the server can also call the client.&lt;/li&gt; 
 &lt;li&gt;Supports passing functions by reference: If you pass a function over RPC, the recipient receives a "stub". When they call the stub, they actually make an RPC back to you, invoking the function where it was created. This is how bidirectional calling happens: the client passes a callback to the server, and then the server can call it later.&lt;/li&gt; 
 &lt;li&gt;Similarly, supports passing objects by reference: If a class extends the special marker type &lt;code&gt;RpcTarget&lt;/code&gt;, then instances of that class are passed by reference, with method calls calling back to the location where the object was created.&lt;/li&gt; 
 &lt;li&gt;Supports promise pipelining. When you start an RPC, you get back a promise. Instead of awaiting it, you can immediately use the promise in dependent RPCs, thus performing a chain of calls in a single network round trip.&lt;/li&gt; 
 &lt;li&gt;Supports capability-based security patterns.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.npmjs.com/package/capnweb"&gt;Cap'n Web is an npm package.&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npm i capnweb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;A client looks like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;import { newWebSocketRpcSession } from "capnweb";

// One-line setup.
let api = newWebSocketRpcSession("wss://example.com/api");

// Call a method on the server!
let result = await api.hello("World");

console.log(result);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;import { RpcTarget, newWorkersRpcResponse } from "capnweb";

// This is the server implementation.
class MyApiServer extends RpcTarget {
  hello(name) {
    return `Hello, ${name}!`
  }
}

// Standard Cloudflare Workers HTTP handler.
//
// (Node and other runtimes are supported too; see below.)
export default {
  fetch(request, env, ctx) {
    // Parse URL for routing.
    let url = new URL(request.url);

    // Serve API at `/api`.
    if (url.pathname === "/api") {
      return newWorkersRpcResponse(request, new MyApiServer());
    }

    // You could serve other endpoints here...
    return new Response("Not found", {status: 404});
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;More complicated example&lt;/h3&gt; 
&lt;p&gt;Here's an example that:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Uses TypeScript&lt;/li&gt; 
 &lt;li&gt;Sends multiple calls, where the second call depends on the result of the first, in one round trip.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We declare our interface in a shared types file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;interface PublicApi {
  // Authenticate the API token, and returned the authenticated API.
  authenticate(apiToken: string): AuthedApi;

  // Get a given user's public profile info. (Doesn't require authentication.)
  getUserProfile(userId: string): Promise&amp;lt;UserProfile&amp;gt;;
}

interface AuthedApi {
  getUserId(): number;

  // Get the user IDs of all the user's friends.
  getFriendIds(): number[];
}

type UserProfile = {
  name: string;
  photoUrl: string;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(Note: you don't &lt;em&gt;have to&lt;/em&gt; declare your interface separately. The client could just use &lt;code&gt;import("./server").ApiServer&lt;/code&gt; as the type.)&lt;/p&gt; 
&lt;p&gt;On the server, we implement the interface as an RpcTarget:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { newWorkersRpcResponse, RpcTarget } from "capnweb";

class ApiServer extends RpcTarget implements PublicApi {
  // ... implement PublicApi ...
}

export default {
  async fetch(req, env, ctx) {
    // ... same as previous example ...
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On the client, we can use it in a batch request:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { newHttpBatchRpcSession } from "capnweb";

let api = newHttpBatchRpcSession&amp;lt;PublicApi&amp;gt;("https://example.com/api");

// Call authenticate(), but don't await it. We can use the returned promise
// to make "pipelined" calls without waiting.
let authedApi: RpcPromise&amp;lt;AuthedApi&amp;gt; = api.authenticate(apiToken);

// Make a pipelined call to get the user's ID. Again, don't await it.
let userIdPromise: RpcPromise&amp;lt;number&amp;gt; = authedApi.getUserId();

// Make another pipelined call to fetch the user's public profile, based on
// the user ID. Notice how we can use `RpcPromise&amp;lt;T&amp;gt;` in the parameters of a
// call anywhere where T is expected. The promise will be replaced with its
// resolution before delivering the call.
let profilePromise = api.getUserProfile(userIdPromise);

// Make another call to get the user's friends.
let friendsPromise = authedApi.getFriendIds();

// That only returns an array of user IDs, but we want all the profile info
// too, so use the magic .map() function to get them, too! Still one round
// trip.
let friendProfilesPromise = friendsPromise.map((id: RpcPromise&amp;lt;number&amp;gt;) =&amp;gt; {
  return { id, profile: api.getUserProfile(id); };
});

// Now await the promises. The batch is sent at this point. It's important
// to simultaneously await all promises for which you actually want the
// result. If you don't actually await a promise before the batch is sent,
// the system detects this and doesn't actually ask the server to send the
// return value back!
let [profile, friendProfiles] =
    await Promise.all([profilePromise, friendProfilesPromise]);

console.log(`Hello, ${profile.name}!`);

// Note that at this point, the `api` and `authedApi` stubs no longer work,
// because the batch is done. You must start a new batch.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, for a long-running interactive application, we can set up a persistent WebSocket connection:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { newWebSocketRpcSession } from "capnweb";

// We declare `api` with `using` so that it'll be disposed at the end of the
// scope, which closes the connection. `using` is a fairly new JavaScript
// feature, part of the "explicit resource management" spec. Alternatively,
// we could declare `api` with `let` or `const` and make sure to call
// `api[Symbol.dispose]()` to dispose it and close the connection later.
using api = newWebSocketRpcSession&amp;lt;PublicApi&amp;gt;("https://example.com/api");

// Usage is exactly the same, except we don't have to await all the promises
// at once.

// Authenticate and get the user ID in one round trip. Note we use `using`
// again so that `authedApi` will be disposed when we're done with it. In
// this case, it won't close the connection (since it's not the main stub),
// but disposing it does release the `AuthedApi` object on the server side.
using authedApi: RpcPromise&amp;lt;AuthedApi&amp;gt; = api.authenticate(apiToken);
let userId: number = await authedApi.getUserId();

// ... continue calling other methods, now or in the future ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;RPC Basics&lt;/h2&gt; 
&lt;h3&gt;Pass-by-value types&lt;/h3&gt; 
&lt;p&gt;The following types can be passed over RPC (in arguments or return values), and will be passed "by value", meaning the content is serialized, producing a copy at the receiving end:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Primitive values: strings, numbers, booleans, null, undefined&lt;/li&gt; 
 &lt;li&gt;Plain objects (e.g., from object literals)&lt;/li&gt; 
 &lt;li&gt;Arrays&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bigint&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Date&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Uint8Array&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Error&lt;/code&gt; and its well-known subclasses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following types are not supported as of this writing, but may be added in the future:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Map&lt;/code&gt; and &lt;code&gt;Set&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ArrayBuffer&lt;/code&gt; and typed arrays other than &lt;code&gt;Uint8Array&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;RegExp&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ReadableStream&lt;/code&gt; and &lt;code&gt;WritableStream&lt;/code&gt;, with automatic flow control.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Headers&lt;/code&gt;, &lt;code&gt;Request&lt;/code&gt;, and &lt;code&gt;Response&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following are intentionally NOT supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Application-defined classes that do not extend &lt;code&gt;RpcTarget&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Cyclic values. Messages are serialized strictly as trees (like JSON).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;code&gt;RpcTarget&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;To export an interface over RPC, you must write a class that &lt;code&gt;extends RpcTarget&lt;/code&gt;. Extending &lt;code&gt;RpcTarget&lt;/code&gt; tells the RPC system: instances of this class are &lt;em&gt;pass-by-reference&lt;/em&gt;. When an instance is passed over RPC, the object should NOT be serialized. Instead, the RPC message will contain a "stub" that points back to the original target object. Invoking this stub calls back over RPC.&lt;/p&gt; 
&lt;p&gt;When you send someone an &lt;code&gt;RpcTarget&lt;/code&gt; reference, they will be able to call any class method over RPC, including getters. They will not, however, be able to access "own" properties. In precise JavaScript terms, they can access prototype properties but not instance properties. This policy is intended to "do the right thing" for typical JavaScript code, where private members are typically stored as instance properties.&lt;/p&gt; 
&lt;p&gt;WARNING: If you are using TypeScript, note that declaring a method &lt;code&gt;private&lt;/code&gt; does not hide it from RPC, because TypeScript annotations are "erased" at runtime, so cannot be enforced. To actually make methods private, you must prefix their names with &lt;code&gt;#&lt;/code&gt;, which makes them private for JavaScript (not just TypeScript). Names prefixed with &lt;code&gt;#&lt;/code&gt; are never available over RPC.&lt;/p&gt; 
&lt;h3&gt;Functions&lt;/h3&gt; 
&lt;p&gt;When a plain function is passed over RPC, it will be treated similarly to an &lt;code&gt;RpcTarget&lt;/code&gt;. The function will be replaced by a stub which, when invoked, calls back over RPC to the original function object.&lt;/p&gt; 
&lt;p&gt;If the function has any own properties, those will be available over RPC. Note that this differs from &lt;code&gt;RpcTarget&lt;/code&gt;: With &lt;code&gt;RpcTarget&lt;/code&gt;, own properties are not exposed, but with functions, &lt;em&gt;only&lt;/em&gt; own properties are exposed. Generally functions don't have properties anyway, making the point moot.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;RpcStub&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;When a type &lt;code&gt;T&lt;/code&gt; which extends &lt;code&gt;RpcTarget&lt;/code&gt; (or is a function) is sent as part of an RPC message (in the arguments to a call, or in the return value), it is replaced with a stub of type &lt;code&gt;RpcStub&amp;lt;T&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Stubs are implemented using JavaScript &lt;code&gt;Proxy&lt;/code&gt;s. A stub appears to have every possible method and property name. The stub does not know at runtime which properties actually exist on the server side. If you use a property that doesn't exist, an error will not be produced until you await the results.&lt;/p&gt; 
&lt;p&gt;TypeScript, however, will know which properties exist from type parameter &lt;code&gt;T&lt;/code&gt;. Thus, if you are using TypeScript, you will get full compile-time type checking, auto-complete, etc. Hooray!&lt;/p&gt; 
&lt;p&gt;To read a property from the remote object (as opposed to calling a method), simply &lt;code&gt;await&lt;/code&gt; the property, like &lt;code&gt;let foo = await stub.foo;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;A stub can be passed across RPC again, including over independent connections. If Alice is connected to Bob and Carol, and Alice receives a stub from Bob, Alice can pass the stub in an RPC to Carol, thus allowing Carol to call Bob. (As of this writing, any such calls will be proxied through Alice, but in the future we may support "three-party handoff" such that Carol can make a direct connection to Bob.)&lt;/p&gt; 
&lt;p&gt;You may construct a stub explicitly without an RPC connection, using &lt;code&gt;new RpcStub(target)&lt;/code&gt;. This is sometimes useful to be able to perform local calls as if they were remote, or to help manage disposal (see below).&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;RpcPromise&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Calling an RPC method returns an &lt;code&gt;RpcPromise&lt;/code&gt; rather than a regular &lt;code&gt;Promise&lt;/code&gt;. You can use an &lt;code&gt;RpcPromise&lt;/code&gt; in all the ways a regular &lt;code&gt;Promise&lt;/code&gt; can be used, that is, you can &lt;code&gt;await&lt;/code&gt; it, call &lt;code&gt;.then()&lt;/code&gt;, pass it to &lt;code&gt;Promise.resolve()&lt;/code&gt;, etc. (This is all possible because &lt;code&gt;RpcPromise&lt;/code&gt; is a &lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise#thenables"&gt;"thenable"&lt;/a&gt;.)&lt;/p&gt; 
&lt;p&gt;However, you can do more with &lt;code&gt;RpcPromise&lt;/code&gt;. &lt;code&gt;RpcPromise&lt;/code&gt; supports &lt;em&gt;Promise Pipelining&lt;/em&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;An &lt;code&gt;RpcPromise&lt;/code&gt; also acts as a &lt;em&gt;stub&lt;/em&gt; for the eventual result of the promise. That means, you can access properties and invoke methods on it, without awaiting the promise first.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// In a single round trip, authenticate the user, and fetch their notifications.
let user = api.authenticate(cookie);
let notifications = await user.getNotifications();
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;An &lt;code&gt;RpcPromise&lt;/code&gt; (or its properties) can be passed as parameters to other RPC calls.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// In a single round trip, authenticate the user, and fetch their public profile
// given their ID.
let user = api.authenticate(cookie);
let profile = await api.getUserProfile(user.id);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Whenever an &lt;code&gt;RpcPromise&lt;/code&gt; is passed in the parameters to an RPC, or returned as part of the result, the promise will be replaced with its resolution before delivery to the receiving application. So, you can use an &lt;code&gt;RpcPromise&amp;lt;T&amp;gt;&lt;/code&gt; anywhere where a &lt;code&gt;T&lt;/code&gt; is required!&lt;/p&gt; 
&lt;h3&gt;The magic &lt;code&gt;map()&lt;/code&gt; method&lt;/h3&gt; 
&lt;p&gt;Every RPC promise has a special method &lt;code&gt;.map()&lt;/code&gt; which can be used to remotely transform a value, without pulling it back locally. Here's an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Get a list of user IDs.
let idsPromise = api.listUserIds();

// Look up the username for each one.
let names = await idsPromise.map(id =&amp;gt; [id, api.getUserName(id)]);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This example calls one API method to get a list of user IDs, then, for each user ID in the list, makes another RPC call to look up the user's name, producing a list of id/name pairs.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;All this happens in a single network round trip!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;promise.map(func)&lt;/code&gt; transfers a representation of &lt;code&gt;func&lt;/code&gt; to the server, where it is executed on the promise's result. Specifically:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If the promise resolves to an array, the mapper function executes on each element of the array. The overall &lt;code&gt;.map()&lt;/code&gt; operation returns a promise for an array of the results.&lt;/li&gt; 
 &lt;li&gt;If the promise resolves to &lt;code&gt;null&lt;/code&gt; or &lt;code&gt;undefined&lt;/code&gt;, the map function is not executed at all. The result is the same value.&lt;/li&gt; 
 &lt;li&gt;If the promise resolves to any other value, the map function executes once on that value, returning the result.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Thus, &lt;code&gt;map()&lt;/code&gt; can be used both for handling arrays, and for handling nullable values.&lt;/p&gt; 
&lt;p&gt;There are some restrictions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The callback must have no side effects other than calling RPCs.&lt;/li&gt; 
 &lt;li&gt;The callback must be synchronous. It cannot await anything.&lt;/li&gt; 
 &lt;li&gt;The input to the callback is an &lt;code&gt;RpcPromise&lt;/code&gt;, hence the callback cannot actually operate on it, other than to invoke its RPC methods, or to use it in the params of other RPC methods.&lt;/li&gt; 
 &lt;li&gt;Any stubs which you use in the callback -- and any parameters you pass to them -- will be sent to the peer. Be warned, a malicious peer can use these stubs for anything, not just calling your callback. Typically, it only makes sense to invoke stubs that came from the same peer originally, since this is what saves round-trips.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;How the heck does that work?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Cap'n Web does NOT send arbitrary code over the wire!&lt;/p&gt; 
&lt;p&gt;The trick here is record-replay: On the calling side, Cap'n Web will invoke your callback once, in a special "recording" mode, passing in a special placeholder stub which records what you do with it. During the invocation, any RPCs invoked by the callback (on &lt;em&gt;any&lt;/em&gt; stub) will not actually be executed, but will be recorded as an action the callback performs. Any stubs you use during the recording are "captured" as well. Once the callback returns, the recording and the capture list can then be sent to the peer, where the recording can then be replayed as needed to process individual results.&lt;/p&gt; 
&lt;p&gt;Since all of the not-yet-determined values seen by the callback are represented as &lt;code&gt;RpcPromise&lt;/code&gt;s, the callback's behavior is deterministic. Any actual computation (arithmetic, branching, etc.) can't possibly use these promises as (meaningful) inputs, so would logically produce the same results for every invocation of the callback. Any such computation will actually end up being performed on the sending side, just once, with the results being imbued into the recording.&lt;/p&gt; 
&lt;h3&gt;Cloudflare Workers RPC interoperability&lt;/h3&gt; 
&lt;p&gt;Cap'n Web works on any JavaScript platform. But, on Cloudflare Workers specifically, it's designed to play nicely with the &lt;a href="https://blog.cloudflare.com/javascript-native-rpc/"&gt;the built-in RPC system&lt;/a&gt;. The two have basically the same semantics, the only difference being that Workers RPC is a built-in API provided by the Workers Runtime, whereas Cap'n Web is implemented in pure JavaScript.&lt;/p&gt; 
&lt;p&gt;To facilitate interoperability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;On Workers, the &lt;code&gt;RpcTarget&lt;/code&gt; class exported by "capnweb" is just an alias of the built-in one, so you can use them interchangeably.&lt;/li&gt; 
 &lt;li&gt;RPC stubs and promises originating from one RPC system can be passed over the other. This will automatically set up proxying.&lt;/li&gt; 
 &lt;li&gt;You can also send Workers Service Bindings and Durable Object stubs over Cap'n Web -- again, this sets up proxying.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;So basically, it "just works".&lt;/p&gt; 
&lt;p&gt;With that said, as of this writing, the feature set is not exactly the same between the two. We aim to fix this over time, by adding missing features to both sides until they match. In particular, as of this writing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Workers RPC supports some types that Cap'n Web does not yet, like &lt;code&gt;Map&lt;/code&gt;, streams, etc.&lt;/li&gt; 
 &lt;li&gt;Workers RPC supports sending values that contain aliases and cycles. This can actually cause problems, so we actually plan to &lt;em&gt;remove&lt;/em&gt; this feature from Workers RPC (with a compatibility flag, of course).&lt;/li&gt; 
 &lt;li&gt;Workers RPC does not yet support placing an &lt;code&gt;RpcPromise&lt;/code&gt; into the parameters of a request, to be replaced by its resolution.&lt;/li&gt; 
 &lt;li&gt;Workers RPC does not yet support the magic &lt;code&gt;.map()&lt;/code&gt; method.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resource Management and Disposal&lt;/h2&gt; 
&lt;p&gt;Unfortunately, garbage collection does not work well when remote resources are involved, for two reasons:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Many JavaScript runtimes only run the garbage collector when they sense "memory pressure" -- if memory is not running low, then they figure there's no need to try to reclaim any. However, the runtime has no way to know if the other side of an RPC connection is suffering memory pressure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Garbage collectors need to trace the full object graph in order to detect which objects are unreachable, especially when those objects contain cyclic references. However, the garbage collector can only see local objects; it has no ability to trace through the remote graph to discover cycles that may cross RPC connections.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Both of these problems might be solvable with sufficient work, but the problem seems exceedingly difficult. We make no attempt to solve it in this library.&lt;/p&gt; 
&lt;p&gt;Instead, you may choose one of two strategies:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Explicitly dispose stubs when you are done with them. This notifies the remote end that it can release the associated resources.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use short-lived sessions. When the session ends, all stubs are implicitly disposed. In particular, when using HTTP batch request, there's generally no need to dispose stubs. When using long-lived WebSocket sessions, however, disposal may be important.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Note: We might extend Cap'n Web to use &lt;code&gt;FinalizationRegistry&lt;/code&gt; to automatically dispose abandoned stubs in the future, but even if we do, it should not be relied upon, due to problems discussed above.&lt;/p&gt; 
&lt;h3&gt;How to dispose&lt;/h3&gt; 
&lt;p&gt;Stubs integrate with JavaScript's &lt;a href="https://v8.dev/features/explicit-resource-management"&gt;explicit resource management&lt;/a&gt;, which became widely available in mid-2025 (and has been supported via transpilers and polyfills going back a few years earlier). In short:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Disposable objects (including stubs) have a method &lt;code&gt;[Symbol.dispose]&lt;/code&gt;. You can call this like &lt;code&gt;stub[Symbol.dispose]()&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;You can arrange for a stub to be disposed automatically at the end of a function scope by assigning it to a &lt;code&gt;using&lt;/code&gt; variable, like &lt;code&gt;using stub = api.getStub();&lt;/code&gt;. The disposer will automatically be invoked when the variable goes out-of-scope.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Automatic disposal&lt;/h3&gt; 
&lt;p&gt;This library implements several rules to help make resource management more manageable. These rules may appear a bit complicated, but are intended to implement the behavior you would naturally expect.&lt;/p&gt; 
&lt;p&gt;The basic principle is: &lt;strong&gt;The caller is responsible for disposing all stubs.&lt;/strong&gt; That is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stubs passed in the params of a call remain property of the caller, and must be disposed by the caller, not by the callee.&lt;/li&gt; 
 &lt;li&gt;Stubs returned in the result of a call have their ownership transferred from the callee to the caller, and must be disposed by the caller.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In practice, though, the callee and caller do not actually share the same stubs. When stubs are passed over RPC, they are &lt;em&gt;duplicated&lt;/em&gt;, and the the target object is only disposed when all duplicates of the stub are disposed. Thus, to achieve the rule that only the caller needs to dispose stubs, the RPC system implicitly disposes the callee's duplicates of all stubs when the call completes. That is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Any stubs the callee receives in the parameters are implicitly disposed when the call completes.&lt;/li&gt; 
 &lt;li&gt;Any stubs returned in the results are implicitly disposed some time after the call completes. (Specifically, the RPC system will dispose them once it knows there will be no more pipelined calls.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Some additional wonky details:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Disposing an &lt;code&gt;RpcPromise&lt;/code&gt; will automatically dispose the future result. (It may also cause the promise to be canceled and rejected, though this is not guaranteed.) If you don't intend to await an RPC promise, you should dispose it.&lt;/li&gt; 
 &lt;li&gt;Passing an &lt;code&gt;RpcPromise&lt;/code&gt; in params or the return value of a call has the same ownership / disposal rules as passing an &lt;code&gt;RpcStub&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;When you access a property of an &lt;code&gt;RpcStub&lt;/code&gt; or &lt;code&gt;RpcPromise&lt;/code&gt;, the result is itself an &lt;code&gt;RpcPromise&lt;/code&gt;. However, this &lt;code&gt;RpcPromise&lt;/code&gt; does not have its own disposer; you must dispose the stub or promise it came from. You can pass such properties in params or return values, but doing so will never lead to anything being implicitly disposed.&lt;/li&gt; 
 &lt;li&gt;The caller of an RPC may dispose any stubs used in the parameters immediately after initiating the RPC, without waiting for the RPC to complete. All stubs are duplicated at the moment of the call, so the callee is not responsible for keeping them alive.&lt;/li&gt; 
 &lt;li&gt;If the final result of an RPC returned to the caller is an object, it will always have a disposer. Disposing it will dispose all stubs found in that response. It's a good idea to always dispose return values even if you don't expect they contain any stubs, just in case the server changes the API in the future to add stubs to the result.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;WARNING: The ownership behavior of calls differs from the original behavior in the native RPC implementation built into the Cloudflare Workers Runtime. In the original Workers behavior, the callee loses ownership of stubs passed in a call's parameters. We plan to change the Workers Runtime to match Cap'n Web's behavior, as the original behavior has proven more problematic than helpful.&lt;/p&gt; 
&lt;h3&gt;Duplicating stubs&lt;/h3&gt; 
&lt;p&gt;Sometimes you need to pass a stub somewhere where it will be disposed, but also keep the stub for later use. To prevent the disposer from disabling your copy of the stub, you can duplicate the stub by calling &lt;code&gt;stub.dup()&lt;/code&gt;. The stub's target will only be disposed when all duplicates of the stub have been disposed.&lt;/p&gt; 
&lt;p&gt;Hint: You can call &lt;code&gt;.dup()&lt;/code&gt; on a property of a stub or promise, in order to create a stub backed by that property. This is particularly useful when you know in advance that the property is going to resolve to a stub: calling &lt;code&gt;.dup()&lt;/code&gt; on it gives you a stub you can start using immediately, that otherwise behaves exactly the same as the eventual stub would if you awaited it.&lt;/p&gt; 
&lt;h3&gt;Listening for disposal&lt;/h3&gt; 
&lt;p&gt;An &lt;code&gt;RpcTarget&lt;/code&gt; may declare a &lt;code&gt;Symbol.dispose&lt;/code&gt; method. If it does, the RPC system will automatically invoke it when a stub pointing at it (and all its duplicates) has been disposed.&lt;/p&gt; 
&lt;p&gt;Note that if you pass the same &lt;code&gt;RpcTarget&lt;/code&gt; instance to RPC multiple times -- thus creating multiple stubs -- you will eventually get a separate dispose call for each one. To avoid this, you could use &lt;code&gt;new RpcStub(target)&lt;/code&gt; to create a single stub upfront, and then pass that stub across multiple RPCs. In this case, you will receive only one call to the target's disposer when all stubs are disposed.&lt;/p&gt; 
&lt;h3&gt;Listening for disconnect&lt;/h3&gt; 
&lt;p&gt;You can monitor any stub for "brokennness" with its &lt;code&gt;onRpcBroken()&lt;/code&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;stub.onRpcBroken((error: any) =&amp;gt; {
  console.error(error);
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If anything happens to the stub that would cause all further method calls and property accesses to throw exceptions, then the callback will be called. In particular, this happens if:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The stub's underlying connection is lost.&lt;/li&gt; 
 &lt;li&gt;The stub is a promise, and the promise rejects.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security Considerations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;The WebSocket API in browsers always permits cross-site connections, and does not permit setting headers. Because of this, you generally cannot use cookies nor other headers for authentication. Instead, we highly recommend the pattern shown in the second example above, in which authentication happens in-band via an RPC method that returns the authenticated API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Cap'n Web's pipelining can make it easy for a malicious client to enqueue a large amount of work to occur on a server. To mitigate this, we recommend implementing rate limits on expensive operations. If using Cloudflare Workers, you may also consider configuring &lt;a href="https://developers.cloudflare.com/workers/wrangler/configuration/#limits"&gt;per-request CPU limits&lt;/a&gt; to be lower than the default 30s. Note that in stateless Workers (i.e. not Durable Objects), the system considers an entire WebSocket session to be one "request" for CPU limits purposes.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Cap'n Web currently does not provide any runtime type checking. When using TypeScript, keep in mind that types are checked only at compile time. A malicious client can send types you did not expect, and this could cause you application to behave in unexpected ways. For example, MongoDB uses special property names to express queries; placing attacker-provided values directly into queries can result in query injection vulnerabilities (similar to SQL injection). Of course, JSON has always had the same problem, and there exists tooling to solve it. You might consider using a runtime type-checking framework like Zod to check your inputs. In the future, we hope to explore auto-generating type-checking code based on TypeScript types.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Setting up a session&lt;/h2&gt; 
&lt;h3&gt;HTTP batch client&lt;/h3&gt; 
&lt;p&gt;In HTTP batch mode, a batch of RPC calls can be made in a single HTTP request, with the server returning a batch of results.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Cap'n Web has a magic trick:&lt;/strong&gt; The results of one call in the batch can be used in the parameters to later calls in the same batch, even though the entire batch is sent at once. If you simply take the Promise returned by one call and use it in the parameters to another call, the Promise will be replaced with its resolution before delivering it to the callee. &lt;strong&gt;This is called Promise Pipelining.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { RpcTarget, RpcStub, newHttpBatchRpcSession } from "capnweb";

// Declare our RPC interface.
interface MyApi extends RpcTarget {
  // Returns information about the logged-in user.
  getUserInfo(): UserInfo;

  // Returns a friendly greeting for a user with the given name.
  greet(name: string): string;
};

// Start a batch request using this interface.
using stub: RpcStub&amp;lt;MyApi&amp;gt; = newHttpBatchRpcSession&amp;lt;MyApi&amp;gt;("https://example.com/api");

// The batch will be sent on the next I/O tick (i.e. using setTimeout(sendBatch, 0)). You have
// until then to add calls to the batch.
//
// We can make any number of calls as part of the batch, as long as we store the promises without
// awaiting them yet.
let promise1 = stub.greet("Alice");
let promise2 = stub.greet("Bob");

// Note that a promise returned by one call can be used in the input to another call. The first
// call's result will be substituted into the second call's parameters on the server side. If the
// first call returns an object, you can even specify a property of the object to pass to the
// second call, as shown here.
let userInfoPromise = stub.getUserInfo();
let promise3 = stub.greet(userInfoPromise.name);

// Use Promise.all() to wait on all the promises at once. NOTE: You don't necessarily have to
// use Promise.all(), but you must make sure you have explicitly awaited (or called `.then()` on)
// all promises before the batch is sent. The system will only ask the server to send back
// results for the promises you explicitly await. In this example, we have not awaited
// `userInfoPromise` -- we only used it as a parameter to another call -- so the result will
// not actually be returned.
let [greeting1, greeting2, greeting3] = await Promise.all([promise1, promise2, promise3]);

// Now we can do stuff with the results.
console.log(greeting1);
console.log(greeting2);
console.log(greeting3);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;WebSocket client&lt;/h3&gt; 
&lt;p&gt;In WebSocket mode, the client forms a long-lived connection to the server, allowing us to make many calls over a long period of time. In this mode, the server can even make asynchronous calls back to the client.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { RpcTarget, RpcStub, newWebSocketRpcSession } from "capnweb";

// Declare our RPC interface.
interface MyApi extends RpcTarget {
  // Returns information about the logged-in user.
  getUserInfo(): UserInfo;

  // Returns a friendly greeting for a user with the given name.
  greet(name: string): string;
};

// Start a WebSocket session.
//
// (Note that disposing the root stub will close the connection. Here we declare it with `using` so
// that the connection will be closed when the stub goes out of scope, but you can also call
// `stub[Symbol.dispose]()` directly.)
using stub: RpcStub&amp;lt;MyApi&amp;gt; = newWebSocketRpcSession&amp;lt;MyApi&amp;gt;("wss://example.com/api");

// With a WebSocket, we can freely make calls over time.
console.log(await stub.greet("Alice"));
console.log(await stub.greet("Bob"));

// But we can still use Promise Pipelining to reduce round trips. Note that we should use `using`
// with promises we don't intend to await so that the system knows when we don't need them anymore.
{
  using userInfoPromise = stub.getUserInfo();
  console.log(await stub.greet(userInfoPromise.name));
}

// Note that since we never awaited `userInfoPromise`, the server won't even bother sending the
// response back over the wire.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;HTTP server on Cloudflare Workers&lt;/h3&gt; 
&lt;p&gt;The helper function &lt;code&gt;newWorkersRpcResponse()&lt;/code&gt; makes it easy to implement an HTTP server that accepts both the HTTP batch and WebSocket APIs at once:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { RpcTarget, newWorkersRpcResponse } from "capnweb";

// Define our server implementation.
class MyApiImpl extends RpcTarget implements MyApi {
  constructor(private userInfo: UserInfo) {}

  getUserInfo(): UserInfo {
    return this.userInfo;
  }

  greet(name: string): string {
    return `Hello, ${name}!`;
  }
};

// Define our Worker HTTP handler.
export default {
  fetch(request: Request, env, ctx) {
    let userInfo: UserInfo = authenticateFromCookie(request);
    let url = new URL(request.url);

    // Serve API at `/api`.
    if (url.pathname === "/api") {
      return newWorkersRpcResponse(request, new MyApiImpl(userInfo));
    }

    return new Response("Not found", {status: 404});
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;HTTP server on Node.js&lt;/h3&gt; 
&lt;p&gt;A server on Node.js is a bit more involved, due to the awkward handling of WebSockets in Node's HTTP library.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import http from "node:http";
import { WebSocketServer } from 'ws';  // npm package
import { RpcTarget, newWebSocketRpcSession, nodeHttpBatchRpcResponse } from "capnweb";

class MyApiImpl extends RpcTarget implements MyApi {
  // ... define API, same as above ...
}

// Run standard HTTP server on a port.
httpServer = http.createServer(async (request, response) =&amp;gt; {
  if (request.headers.upgrade?.toLowerCase() === 'websocket') {
    // Ignore, should be handled by WebSocketServer instead.
    return;
  }

  // Accept Cap'n Web requests at `/api`.
  if (request.url === "/api") {
    try {
      await nodeHttpBatchRpcResponse(request, response, new MyApiImpl(), {
        // If you are accepting WebSockets, then you might as well accept cross-origin HTTP, since
        // WebSockets always permit cross-origin request anyway. But, see security considerations
        // for further discussion.
        headers: { "Access-Control-Allow-Origin": "*" }
      });
    } catch (err) {
      response.writeHead(500, { 'content-type': 'text/plain' });
      response.end(String(err?.stack || err));
    }
    return;
  }

  response.writeHead(404, { 'content-type': 'text/plain' });
  response.end("Not Found");
});

// Arrange to handle WebSockets as well, using the `ws` package. You can skip this if you only
// want to handle HTTP batch requests.
wsServer = new WebSocketServer({ server: httpServer })
wsServer.on('connection', (ws) =&amp;gt; {
  // The `as any` here is because the `ws` module seems to have its own `WebSocket` type
  // declaration that's incompatible with the standard one. In practice, though, they are
  // compatible enough for Cap'n Web!
  newWebSocketRpcSession(ws as any, new MyApiImpl());
})

// Accept requests on port 8080.
httpServer.listen(8080);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;HTTP server on other runtimes&lt;/h3&gt; 
&lt;p&gt;Every runtime does HTTP handling and WebSockets a little differently, although most modern runtimes use the standard &lt;code&gt;Request&lt;/code&gt; and &lt;code&gt;Response&lt;/code&gt; types from the Fetch API, as well as the standard &lt;code&gt;WebSocket&lt;/code&gt; API. You should be able to use these two functions (exported by &lt;code&gt;capnweb&lt;/code&gt;) to implement both HTTP batch and WebSocket handling on all platforms:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Run a single HTTP batch.
function newHttpBatchRpcResponse(
    request: Request, yourApi: RpcTarget, options?: RpcSessionOptions)
    : Promise&amp;lt;Response&amp;gt;;

// Run a WebSocket session.
//
// This is actually the same function as is used on the client side! But on the
// server, you should pass in a `WebSocket` object representing the already-open
// connection, instead of a URL string, and you pass your API implementation as
// the second parameter.
//
// You can dispose the returned `Disposable` to close the connection, or just
// let it run until the client closes it.
function newWebSocketRpcSession(
    webSocket: WebSocket, yourApi: RpcTarget, options?: RpcSessionOptions)
    : Disposable;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MessagePort&lt;/h3&gt; 
&lt;p&gt;Cap'n Web can also talk over MessagePorts. This can be used in a browser to talk to Web Workers, iframes, etc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { RpcTarget, RpcStub, newMessagePortRpcSession } from "capnweb";

// Declare our RPC interface.
class Greeter extends RpcTarget {
  greet(name: string): string {
    return `Hello, ${name}!`;
  }
};

// Create a MessageChannel (pair of MessagePorts).
let channel = new MessageChannel()

// Initialize the server on port1.
newMessagePortRpcSession(channel.port1, new Greeter());

// Initialize the client on port2.
using stub: RpcStub&amp;lt;Greeter&amp;gt; = newMessagePortRpcSession&amp;lt;Greeter&amp;gt;(channel.port2);

// Now you can make calls.
console.log(await stub.greet("Alice"));
console.log(await stub.greet("Bob"));
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Of course, in a real-world scenario, you'd probably want to send one of the two ports to another context. A &lt;code&gt;MessagePort&lt;/code&gt; can itself be transferred to another context using &lt;code&gt;postMessage()&lt;/code&gt;, e.g. &lt;code&gt;window.postMessage()&lt;/code&gt;, &lt;code&gt;worker.postMessage()&lt;/code&gt;, or even &lt;code&gt;port.postMessage()&lt;/code&gt; on some other existing &lt;code&gt;MessagePort&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that you should not use a &lt;code&gt;Window&lt;/code&gt; object itself as a port for RPC -- you should always create a new &lt;code&gt;MessageChannel&lt;/code&gt; and send one of the ports over. This is because anyone can &lt;code&gt;postMessage()&lt;/code&gt; to a window, and the RPC system does not authenticate that messages came from the expected sender. You need to verify that you received the port itself from the expected sender first, then let the RPC system take over.&lt;/p&gt; 
&lt;h3&gt;Custom transports&lt;/h3&gt; 
&lt;p&gt;You can implement a custom RPC transport across any bidirectional stream. To do so, implement the interface &lt;code&gt;RpcTransport&lt;/code&gt;, which is defined as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Interface for an RPC transport, which is a simple bidirectional message stream.
export interface RpcTransport {
  // Sends a message to the other end.
  send(message: string): Promise&amp;lt;void&amp;gt;;

  // Receives a message sent by the other end.
  //
  // If and when the transport becomes disconnected, this will reject. The thrown error will be
  // propagated to all outstanding calls and future calls on any stubs associated with the session.
  // If there are no outstanding calls (and none are made in the future), then the error does not
  // propagate anywhere -- this is considered a "clean" shutdown.
  receive(): Promise&amp;lt;string&amp;gt;;

  // Indicates that the RPC system has suffered an error that prevents the session from continuing.
  // The transport should ideally try to send any queued messages if it can, and then close the
  // connection. (It's not strictly necessary to deliver queued messages, but the last message sent
  // before abort() is called is often an "abort" message, which communicates the error to the
  // peer, so if that is dropped, the peer may have less information about what happened.)
  abort?(reason: any): void;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then set up a connection over it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Create the transport.
let transport: RpcTransport = new MyTransport();

// Create the main interface we will expose to the other end.
let localMain: RpcTarget = new MyMainInterface():

// Start the session.
let session = new RpcSession&amp;lt;RemoteMainInterface&amp;gt;(transport, localMain);

// Get a stub for the other end's main interface.
let stub: RemoteMainInterface = session.getRemoteMain();

// Now we can call methods on the stub.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that sessions are entirely symmetric: neither side is defined as the "client" nor the "server". Each side can optionally expose a "main interface" to the other. In typical scenarios with a logical client and server, the server exposes a main interface but the client does not.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/RAG-Anything</title>
      <link>https://github.com/HKUDS/RAG-Anything</link>
      <description>&lt;p&gt;"RAG-Anything: All-in-One RAG Framework"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div style="margin: 20px 0;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/logo.png" width="120" height="120" alt="RAG-Anything Logo" style="border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;üöÄ RAG-Anything: All-in-One RAG Framework&lt;/h1&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://readme-typing-svg.herokuapp.com?font=Orbitron&amp;amp;size=24&amp;amp;duration=3000&amp;amp;pause=1000&amp;amp;color=00D9FF&amp;amp;center=true&amp;amp;vCenter=true&amp;amp;width=600&amp;amp;lines=Welcome+to+RAG-Anything;Next-Gen+Multimodal+RAG+System;Powered+by+Advanced+AI+Technology" alt="Typing Animation" /&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;"&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;&lt;img src="https://img.shields.io/badge/üî•Project-Page-00d9ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2410.05779"&gt;&lt;img src="https://img.shields.io/badge/üìÑarXiv-2410.05779-ff6b6b?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt;&lt;img src="https://img.shields.io/badge/‚ö°Based%20on-LightRAG-4ecdc4?style=for-the-badge&amp;amp;logo=lightning&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/RAG-Anything?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/üêçPython-3.10-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/raganything/"&gt;&lt;img src="https://img.shields.io/pypi/v/raganything.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/badge/‚ö°uv-Ready-ff6b6b?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/issues/7"&gt;&lt;img src="https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README_zh.md"&gt;&lt;img src="https://img.shields.io/badge/üá®üá≥‰∏≠ÊñáÁâà-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/üá∫üá∏English-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéâ News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.08.12]üéØüì¢ üîç RAG-Anything now features &lt;strong&gt;VLM-Enhanced Query&lt;/strong&gt; mode! When documents include images, the system seamlessly integrates them into VLM for advanced multimodal analysis, combining visual and textual context for deeper insights.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.05]üéØüì¢ RAG-Anything now features a &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/docs/context_aware_processing.md"&gt;context configuration module&lt;/a&gt;, enabling intelligent integration of relevant contextual information to enhance multimodal content processing.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.04]üéØüì¢ üöÄ RAG-Anything now supports multimodal query capabilities, enabling enhanced RAG with seamless processing of text, images, tables, and equations.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.03]üéØüì¢ üéâ RAG-Anything has reached 1küåü stars on GitHub! Thank you for your incredible support and valuable contributions to the project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåü System Overview&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Next-Generation Multimodal Intelligence&lt;/em&gt;&lt;/p&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border: 2px solid #00d9ff; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);"&gt; 
 &lt;p&gt;Modern documents increasingly contain diverse multimodal content‚Äîtext, images, tables, equations, charts, and multimedia‚Äîthat traditional text-focused RAG systems cannot effectively process. &lt;strong&gt;RAG-Anything&lt;/strong&gt; addresses this challenge as a comprehensive &lt;strong&gt;All-in-One Multimodal Document Processing RAG system&lt;/strong&gt; built on &lt;a href="https://github.com/HKUDS/LightRAG"&gt;LightRAG&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;As a unified solution, RAG-Anything &lt;strong&gt;eliminates the need for multiple specialized tools&lt;/strong&gt;. It provides &lt;strong&gt;seamless processing and querying across all content modalities&lt;/strong&gt; within a single integrated framework. Unlike conventional RAG approaches that struggle with non-textual elements, our all-in-one system delivers &lt;strong&gt;comprehensive multimodal retrieval capabilities&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Users can query documents containing &lt;strong&gt;interleaved text&lt;/strong&gt;, &lt;strong&gt;visual diagrams&lt;/strong&gt;, &lt;strong&gt;structured tables&lt;/strong&gt;, and &lt;strong&gt;mathematical formulations&lt;/strong&gt; through &lt;strong&gt;one cohesive interface&lt;/strong&gt;. This consolidated approach makes RAG-Anything particularly valuable for academic research, technical documentation, financial reports, and enterprise knowledge management where rich, mixed-content documents demand a &lt;strong&gt;unified processing framework&lt;/strong&gt;.&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/rag_anything_framework.png" alt="RAG-Anything" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;üéØ Key Features&lt;/h3&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; padding: 25px; margin: 20px 0;"&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;üîÑ End-to-End Multimodal Pipeline&lt;/strong&gt; - Complete workflow from document ingestion and parsing to intelligent multimodal query answering&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üìÑ Universal Document Support&lt;/strong&gt; - Seamless processing of PDFs, Office documents, images, and diverse file formats&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üß† Specialized Content Analysis&lt;/strong&gt; - Dedicated processors for images, tables, mathematical equations, and heterogeneous content types&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üîó Multimodal Knowledge Graph&lt;/strong&gt; - Automatic entity extraction and cross-modal relationship discovery for enhanced understanding&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;‚ö° Adaptive Processing Modes&lt;/strong&gt; - Flexible MinerU-based parsing or direct multimodal content injection workflows&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üìã Direct Content List Insertion&lt;/strong&gt; - Bypass document parsing by directly inserting pre-parsed content lists from external sources&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üéØ Hybrid Intelligent Retrieval&lt;/strong&gt; - Advanced search capabilities spanning textual and multimodal content with contextual understanding&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è Algorithm &amp;amp; Architecture&lt;/h2&gt; 
&lt;div style="background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border-left: 5px solid #00d9ff;"&gt; 
 &lt;h3&gt;Core Algorithm&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;RAG-Anything&lt;/strong&gt; implements an effective &lt;strong&gt;multi-stage multimodal pipeline&lt;/strong&gt; that fundamentally extends traditional RAG architectures to seamlessly handle diverse content modalities through intelligent orchestration and cross-modal understanding.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: space-around; align-items: center; flex-wrap: wrap; gap: 20px;"&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üìÑ
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Document Parsing
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    ‚Üí
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üß†
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Content Analysis
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    ‚Üí
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üîç
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Knowledge Graph
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    ‚Üí
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üéØ
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Intelligent Retrieval
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;1. Document Parsing Stage&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The system provides high-fidelity document extraction through adaptive content decomposition. It intelligently segments heterogeneous elements while preserving contextual relationships. Universal format compatibility is achieved via specialized optimized parsers.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚öôÔ∏è MinerU Integration&lt;/strong&gt;: Leverages &lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; for high-fidelity document structure extraction and semantic preservation across complex layouts.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üß© Adaptive Content Decomposition&lt;/strong&gt;: Automatically segments documents into coherent text blocks, visual elements, structured tables, mathematical equations, and specialized content types while preserving contextual relationships.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìÅ Universal Format Support&lt;/strong&gt;: Provides comprehensive handling of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and emerging formats through specialized parsers with format-specific optimization.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;2. Multi-Modal Content Understanding &amp;amp; Processing&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The system automatically categorizes and routes content through optimized channels. It uses concurrent pipelines for parallel text and multimodal processing. Document hierarchy and relationships are preserved during transformation.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéØ Autonomous Content Categorization and Routing&lt;/strong&gt;: Automatically identify, categorize, and route different content types through optimized execution channels.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Concurrent Multi-Pipeline Architecture&lt;/strong&gt;: Implements concurrent execution of textual and multimodal content through dedicated processing pipelines. This approach maximizes throughput efficiency while preserving content integrity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üèóÔ∏è Document Hierarchy Extraction&lt;/strong&gt;: Extracts and preserves original document hierarchy and inter-element relationships during content transformation.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;3. Multimodal Analysis Engine&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #0f3460 0%, #1a1a2e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #00d9ff;"&gt; 
 &lt;p&gt;The system deploys modality-aware processing units for heterogeneous data modalities:&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Specialized Analyzers:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Visual Content Analyzer&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Integrate vision model for image analysis.&lt;/li&gt; 
    &lt;li&gt;Generates context-aware descriptive captions based on visual semantics.&lt;/li&gt; 
    &lt;li&gt;Extracts spatial relationships and hierarchical structures between visual elements.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìä Structured Data Interpreter&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Performs systematic interpretation of tabular and structured data formats.&lt;/li&gt; 
    &lt;li&gt;Implements statistical pattern recognition algorithms for data trend analysis.&lt;/li&gt; 
    &lt;li&gt;Identifies semantic relationships and dependencies across multiple tabular datasets.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìê Mathematical Expression Parser&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Parses complex mathematical expressions and formulas with high accuracy.&lt;/li&gt; 
    &lt;li&gt;Provides native LaTeX format support for seamless integration with academic workflows.&lt;/li&gt; 
    &lt;li&gt;Establishes conceptual mappings between mathematical equations and domain-specific knowledge bases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîß Extensible Modality Handler&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Provides configurable processing framework for custom and emerging content types.&lt;/li&gt; 
    &lt;li&gt;Enables dynamic integration of new modality processors through plugin architecture.&lt;/li&gt; 
    &lt;li&gt;Supports runtime configuration of processing pipelines for specialized use cases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;4. Multimodal Knowledge Graph Index&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The multi-modal knowledge graph construction module transforms document content into structured semantic representations. It extracts multimodal entities, establishes cross-modal relationships, and preserves hierarchical organization. The system applies weighted relevance scoring for optimized knowledge retrieval.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Core Functions:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Multi-Modal Entity Extraction&lt;/strong&gt;: Transforms significant multimodal elements into structured knowledge graph entities. The process includes semantic annotations and metadata preservation.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Cross-Modal Relationship Mapping&lt;/strong&gt;: Establishes semantic connections and dependencies between textual entities and multimodal components. This is achieved through automated relationship inference algorithms.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üèóÔ∏è Hierarchical Structure Preservation&lt;/strong&gt;: Maintains original document organization through "belongs_to" relationship chains. These chains preserve logical content hierarchy and sectional dependencies.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚öñÔ∏è Weighted Relationship Scoring&lt;/strong&gt;: Assigns quantitative relevance scores to relationship types. Scoring is based on semantic proximity and contextual significance within the document structure.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;5. Modality-Aware Retrieval&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The hybrid retrieval system combines vector similarity search with graph traversal algorithms for comprehensive content retrieval. It implements modality-aware ranking mechanisms and maintains relational coherence between retrieved elements to ensure contextually integrated information delivery.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Retrieval Mechanisms:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîÄ Vector-Graph Fusion&lt;/strong&gt;: Integrates vector similarity search with graph traversal algorithms. This approach leverages both semantic embeddings and structural relationships for comprehensive content retrieval.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìä Modality-Aware Ranking&lt;/strong&gt;: Implements adaptive scoring mechanisms that weight retrieval results based on content type relevance. The system adjusts rankings according to query-specific modality preferences.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Relational Coherence Maintenance&lt;/strong&gt;: Maintains semantic and structural relationships between retrieved elements. This ensures coherent information delivery and contextual integrity.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Initialize Your AI Journey&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212284158-e840e285-664b-44d7-b79b-e264b5e54825.gif" width="400" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Option 1: Install from PyPI (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
pip install raganything

# With optional dependencies for extended format support:
pip install 'raganything[all]'              # All optional features
pip install 'raganything[image]'            # Image format conversion (BMP, TIFF, GIF, WebP)
pip install 'raganything[text]'             # Text file processing (TXT, MD)
pip install 'raganything[image,text]'       # Multiple features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option 2: Install from Source&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and setup the project with uv
git clone https://github.com/HKUDS/RAG-Anything.git
cd RAG-Anything

# Install the package and dependencies in a virtual environment
uv sync

# If you encounter network timeouts (especially for opencv packages):
# UV_HTTP_TIMEOUT=120 uv sync

# Run commands directly with uv (recommended approach)
uv run python examples/raganything_example.py --help

# Install with optional dependencies
uv sync --extra image --extra text  # Specific extras
uv sync --all-extras                 # All optional features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Optional Dependencies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[image]&lt;/code&gt;&lt;/strong&gt; - Enables processing of BMP, TIFF, GIF, WebP image formats (requires Pillow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[text]&lt;/code&gt;&lt;/strong&gt; - Enables processing of TXT and MD files (requires ReportLab)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[all]&lt;/code&gt;&lt;/strong&gt; - Includes all Python optional dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Office Document Processing Requirements:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Office documents (.doc, .docx, .ppt, .pptx, .xls, .xlsx) require &lt;strong&gt;LibreOffice&lt;/strong&gt; installation&lt;/li&gt; 
  &lt;li&gt;Download from &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice official website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: Download installer from official website&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;brew install --cask libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ubuntu/Debian&lt;/strong&gt;: &lt;code&gt;sudo apt-get install libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;CentOS/RHEL&lt;/strong&gt;: &lt;code&gt;sudo yum install libreoffice&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Check MinerU installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Verify installation
mineru --version

# Check if properly configured
python -c "from raganything import RAGAnything; rag = RAGAnything(); print('‚úÖ MinerU installed properly' if rag.check_parser_installation() else '‚ùå MinerU installation issue')"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Models are downloaded automatically on first use. For manual download, refer to &lt;a href="https://github.com/opendatalab/MinerU/raw/master/README.md#22-model-source-configuration"&gt;MinerU Model Source Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;h4&gt;1. End-to-End Document Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def main():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        parser="mineru",  # Parser selection: mineru or docling
        parse_method="auto",  # Parse method: auto, ocr, or txt
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define LLM model function
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Define embedding function
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Process a document
    await rag.process_document_complete(
        file_path="path/to/your/document.pdf",
        output_dir="./output",
        parse_method="auto"
    )

    # Query the processed content
    # Pure text query - for basic knowledge base search
    text_result = await rag.aquery(
        "What are the main findings shown in the figures and tables?",
        mode="hybrid"
    )
    print("Text query result:", text_result)

    # Multimodal query with specific multimodal content
    multimodal_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
    print("Multimodal query result:", multimodal_result)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Direct Multimodal Content Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc
from raganything.modalprocessors import ImageModalProcessor, TableModalProcessor

async def process_multimodal_content():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Initialize LightRAG
    rag = LightRAG(
        working_dir="./rag_storage",
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )
    await rag.initialize_storages()

    # Process an image
    image_processor = ImageModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(
            "gpt-4o",
            "",
            system_prompt=None,
            history_messages=[],
            messages=[
                {"role": "system", "content": system_prompt} if system_prompt else None,
                {"role": "user", "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                ]} if image_data else {"role": "user", "content": prompt}
            ],
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ) if image_data else openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    image_content = {
        "img_path": "path/to/image.jpg",
        "image_caption": ["Figure 1: Experimental results"],
        "image_footnote": ["Data collected in 2024"]
    }

    description, entity_info = await image_processor.process_multimodal_content(
        modal_content=image_content,
        content_type="image",
        file_path="research_paper.pdf",
        entity_name="Experimental Results Figure"
    )

    # Process a table
    table_processor = TableModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    table_content = {
        "table_body": """
        | Method | Accuracy | F1-Score |
        |--------|----------|----------|
        | RAGAnything | 95.2% | 0.94 |
        | Baseline | 87.3% | 0.85 |
        """,
        "table_caption": ["Performance Comparison"],
        "table_footnote": ["Results on test dataset"]
    }

    description, entity_info = await table_processor.process_multimodal_content(
        modal_content=table_content,
        content_type="table",
        file_path="research_paper.pdf",
        entity_name="Performance Results Table"
    )

if __name__ == "__main__":
    asyncio.run(process_multimodal_content())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Batch Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Process multiple documents
await rag.process_folder_complete(
    folder_path="./documents",
    output_dir="./output",
    file_extensions=[".pdf", ".docx", ".pptx"],
    recursive=True,
    max_workers=4
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Custom Modal Processors&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from raganything.modalprocessors import GenericModalProcessor

class CustomModalProcessor(GenericModalProcessor):
    async def process_multimodal_content(self, modal_content, content_type, file_path, entity_name):
        # Your custom processing logic
        enhanced_description = await self.analyze_custom_content(modal_content)
        entity_info = self.create_custom_entity(enhanced_description, entity_name)
        return await self._create_entity_and_chunk(enhanced_description, entity_info, file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Query Options&lt;/h4&gt; 
&lt;p&gt;RAG-Anything provides three types of query methods:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Pure Text Queries&lt;/strong&gt; - Direct knowledge base search using LightRAG:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Different query modes for text queries
text_result_hybrid = await rag.aquery("Your question", mode="hybrid")
text_result_local = await rag.aquery("Your question", mode="local")
text_result_global = await rag.aquery("Your question", mode="global")
text_result_naive = await rag.aquery("Your question", mode="naive")

# Synchronous version
sync_text_result = rag.query("Your question", mode="hybrid")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;VLM Enhanced Queries&lt;/strong&gt; - Automatically analyze images in retrieved context using VLM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# VLM enhanced query (automatically enabled when vision_model_func is provided)
vlm_result = await rag.aquery(
    "Analyze the charts and figures in the document",
    mode="hybrid"
    # vlm_enhanced=True is automatically set when vision_model_func is available
)

# Manually control VLM enhancement
vlm_enabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=True  # Force enable VLM enhancement
)

vlm_disabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=False  # Force disable VLM enhancement
)

# When documents contain images, VLM can see and analyze them directly
# The system will automatically:
# 1. Retrieve relevant context containing image paths
# 2. Load and encode images as base64
# 3. Send both text context and images to VLM for comprehensive analysis
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Multimodal Queries&lt;/strong&gt; - Enhanced queries with specific multimodal content analysis:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Query with table data
table_result = await rag.aquery_with_multimodal(
    "Compare these performance metrics with the document content",
    multimodal_content=[{
        "type": "table",
        "table_data": """Method,Accuracy,Speed
                        RAGAnything,95.2%,120ms
                        Traditional,87.3%,180ms""",
        "table_caption": "Performance comparison"
    }],
    mode="hybrid"
)

# Query with equation content
equation_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6. Loading Existing LightRAG Instance&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status
from lightrag.utils import EmbeddingFunc
import os

async def load_existing_lightrag():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # First, create or load existing LightRAG instance
    lightrag_working_dir = "./existing_lightrag_storage"

    # Check if previous LightRAG instance exists
    if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):
        print("‚úÖ Found existing LightRAG instance, loading...")
    else:
        print("‚ùå No existing LightRAG instance found, will create new one")

    # Create/load LightRAG instance with your configuration
    lightrag_instance = LightRAG(
        working_dir=lightrag_working_dir,
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )

    # Initialize storage (this will load existing data if available)
    await lightrag_instance.initialize_storages()
    await initialize_pipeline_status()

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return lightrag_instance.llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Now use existing LightRAG instance to initialize RAGAnything
    rag = RAGAnything(
        lightrag=lightrag_instance,  # Pass existing LightRAG instance
        vision_model_func=vision_model_func,
        # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance
    )

    # Query existing knowledge base
    result = await rag.aquery(
        "What data has been processed in this LightRAG instance?",
        mode="hybrid"
    )
    print("Query result:", result)

    # Add new multimodal document to existing LightRAG instance
    await rag.process_document_complete(
        file_path="path/to/new/multimodal_document.pdf",
        output_dir="./output"
    )

if __name__ == "__main__":
    asyncio.run(load_existing_lightrag())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;7. Direct Content List Insertion&lt;/h4&gt; 
&lt;p&gt;For scenarios where you already have a pre-parsed content list (e.g., from external parsers or previous processing), you can directly insert it into RAGAnything without document parsing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def insert_content_list_example():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define model functions
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ],
                    } if image_data else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Example: Pre-parsed content list from external source
    content_list = [
        {
            "type": "text",
            "text": "This is the introduction section of our research paper.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "image",
            "img_path": "/absolute/path/to/figure1.jpg",  # IMPORTANT: Use absolute path
            "image_caption": ["Figure 1: System Architecture"],
            "image_footnote": ["Source: Authors' original design"],
            "page_idx": 1  # Page number where this image appears
        },
        {
            "type": "table",
            "table_body": "| Method | Accuracy | F1-Score |\n|--------|----------|----------|\n| Ours | 95.2% | 0.94 |\n| Baseline | 87.3% | 0.85 |",
            "table_caption": ["Table 1: Performance Comparison"],
            "table_footnote": ["Results on test dataset"],
            "page_idx": 2  # Page number where this table appears
        },
        {
            "type": "equation",
            "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
            "text": "Document relevance probability formula",
            "page_idx": 3  # Page number where this equation appears
        },
        {
            "type": "text",
            "text": "In conclusion, our method demonstrates superior performance across all metrics.",
            "page_idx": 4  # Page number where this content appears
        }
    ]

    # Insert the content list directly
    await rag.insert_content_list(
        content_list=content_list,
        file_path="research_paper.pdf",  # Reference file name for citation
        split_by_character=None,         # Optional text splitting
        split_by_character_only=False,   # Optional text splitting mode
        doc_id=None,                     # Optional custom document ID (will be auto-generated if not provided)
        display_stats=True               # Show content statistics
    )

    # Query the inserted content
    result = await rag.aquery(
        "What are the key findings and performance metrics mentioned in the research?",
        mode="hybrid"
    )
    print("Query result:", result)

    # You can also insert multiple content lists with different document IDs
    another_content_list = [
        {
            "type": "text",
            "text": "This is content from another document.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "table",
            "table_body": "| Feature | Value |\n|---------|-------|\n| Speed | Fast |\n| Accuracy | High |",
            "table_caption": ["Feature Comparison"],
            "page_idx": 1  # Page number where this table appears
        }
    ]

    await rag.insert_content_list(
        content_list=another_content_list,
        file_path="another_document.pdf",
        doc_id="custom-doc-id-123"  # Custom document ID
    )

if __name__ == "__main__":
    asyncio.run(insert_content_list_example())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Content List Format:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;content_list&lt;/code&gt; should follow the standard format with each item being a dictionary containing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text content&lt;/strong&gt;: &lt;code&gt;{"type": "text", "text": "content text", "page_idx": 0}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image content&lt;/strong&gt;: &lt;code&gt;{"type": "image", "img_path": "/absolute/path/to/image.jpg", "image_caption": ["caption"], "image_footnote": ["note"], "page_idx": 1}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Table content&lt;/strong&gt;: &lt;code&gt;{"type": "table", "table_body": "markdown table", "table_caption": ["caption"], "table_footnote": ["note"], "page_idx": 2}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equation content&lt;/strong&gt;: &lt;code&gt;{"type": "equation", "latex": "LaTeX formula", "text": "description", "page_idx": 3}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic content&lt;/strong&gt;: &lt;code&gt;{"type": "custom_type", "content": "any content", "page_idx": 4}&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important Notes:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;img_path&lt;/code&gt;&lt;/strong&gt;: Must be an absolute path to the image file (e.g., &lt;code&gt;/home/user/images/chart.jpg&lt;/code&gt; or &lt;code&gt;C:\Users\user\images\chart.jpg&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;page_idx&lt;/code&gt;&lt;/strong&gt;: Represents the page number where the content appears in the original document (0-based indexing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content ordering&lt;/strong&gt;: Items are processed in the order they appear in the list&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This method is particularly useful when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You have content from external parsers (non-MinerU/Docling)&lt;/li&gt; 
 &lt;li&gt;You want to process programmatically generated content&lt;/li&gt; 
 &lt;li&gt;You need to insert content from multiple sources into a single knowledge base&lt;/li&gt; 
 &lt;li&gt;You have cached parsing results that you want to reuse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üõ†Ô∏è Examples&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Practical Implementation Demos&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212257455-13e3e01e-d6a6-45dc-bb92-3ab87b12dfc1.gif" width="300" /&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;code&gt;examples/&lt;/code&gt; directory contains comprehensive usage examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;raganything_example.py&lt;/code&gt;&lt;/strong&gt;: End-to-end document processing with MinerU&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;modalprocessors_example.py&lt;/code&gt;&lt;/strong&gt;: Direct multimodal content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;office_document_test.py&lt;/code&gt;&lt;/strong&gt;: Office document parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;image_format_test.py&lt;/code&gt;&lt;/strong&gt;: Image format parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;text_format_test.py&lt;/code&gt;&lt;/strong&gt;: Text format parsing test with MinerU (no API key required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Run examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# End-to-end processing with parser selection
python examples/raganything_example.py path/to/document.pdf --api-key YOUR_API_KEY --parser mineru

# Direct modal processing
python examples/modalprocessors_example.py --api-key YOUR_API_KEY

# Office document parsing test (MinerU only)
python examples/office_document_test.py --file path/to/document.docx

# Image format parsing test (MinerU only)
python examples/image_format_test.py --file path/to/image.bmp

# Text format parsing test (MinerU only)
python examples/text_format_test.py --file path/to/document.md

# Check LibreOffice installation
python examples/office_document_test.py --check-libreoffice --file dummy

# Check PIL/Pillow installation
python examples/image_format_test.py --check-pillow --file dummy

# Check ReportLab installation
python examples/text_format_test.py --check-reportlab --file dummy
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîß Configuration&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;System Optimization Parameters&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file (refer to &lt;code&gt;.env.example&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_openai_api_key
OPENAI_BASE_URL=your_base_url  # Optional
OUTPUT_DIR=./output             # Default output directory for parsed documents
PARSER=mineru                   # Parser selection: mineru or docling
PARSE_METHOD=auto              # Parse method: auto, ocr, or txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For backward compatibility, legacy environment variable names are still supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;MINERU_PARSE_METHOD&lt;/code&gt; is deprecated, please use &lt;code&gt;PARSE_METHOD&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: API keys are only required for full RAG processing with LLM integration. The parsing test files (&lt;code&gt;office_document_test.py&lt;/code&gt; and &lt;code&gt;image_format_test.py&lt;/code&gt;) only test parser functionality and do not require API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Parser Configuration&lt;/h3&gt; 
&lt;p&gt;RAGAnything now supports multiple parsers, each with specific advantages:&lt;/p&gt; 
&lt;h4&gt;MinerU Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports PDF, images, Office documents, and more formats&lt;/li&gt; 
 &lt;li&gt;Powerful OCR and table extraction capabilities&lt;/li&gt; 
 &lt;li&gt;GPU acceleration support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docling Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Optimized for Office documents and HTML files&lt;/li&gt; 
 &lt;li&gt;Better document structure preservation&lt;/li&gt; 
 &lt;li&gt;Native support for multiple Office formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MinerU Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# MinerU 2.0 uses command-line parameters instead of config files
# Check available options:
mineru --help

# Common configurations:
mineru -p input.pdf -o output_dir -m auto    # Automatic parsing mode
mineru -p input.pdf -o output_dir -m ocr     # OCR-focused parsing
mineru -p input.pdf -o output_dir -b pipeline --device cuda  # GPU acceleration
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also configure parsing through RAGAnything parameters:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Basic parsing configuration with parser selection
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # or "ocr", "txt"
    parser="mineru"               # Optional: "mineru" or "docling"
)

# Advanced parsing configuration with special parameters
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # Parsing method: "auto", "ocr", "txt"
    parser="mineru",              # Parser selection: "mineru" or "docling"

    # MinerU special parameters - all supported kwargs:
    lang="ch",                   # Document language for OCR optimization (e.g., "ch", "en", "ja")
    device="cuda:0",             # Inference device: "cpu", "cuda", "cuda:0", "npu", "mps"
    start_page=0,                # Starting page number (0-based, for PDF)
    end_page=10,                 # Ending page number (0-based, for PDF)
    formula=True,                # Enable formula parsing
    table=True,                  # Enable table parsing
    backend="pipeline",          # Parsing backend: pipeline|vlm-transformers|vlm-sglang-engine|vlm-sglang-client.
    source="huggingface",        # Model source: "huggingface", "modelscope", "local"
    # vlm_url="http://127.0.0.1:3000" # Service address when using backend=vlm-sglang-client

    # Standard RAGAnything parameters
    display_stats=True,          # Display content statistics
    split_by_character=None,     # Optional character to split text by
    doc_id=None                  # Optional document ID
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: MinerU 2.0 no longer uses the &lt;code&gt;magic-pdf.json&lt;/code&gt; configuration file. All settings are now passed as command-line parameters or function arguments. RAG-Anything now supports multiple document parsers - you can choose between MinerU and Docling based on your needs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Processing Requirements&lt;/h3&gt; 
&lt;p&gt;Different content types require specific optional dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; (.doc, .docx, .ppt, .pptx, .xls, .xlsx): Install &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extended Image Formats&lt;/strong&gt; (.bmp, .tiff, .gif, .webp): Install with &lt;code&gt;pip install raganything[image]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; (.txt, .md): Install with &lt;code&gt;pip install raganything[text]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìã Quick Install&lt;/strong&gt;: Use &lt;code&gt;pip install raganything[all]&lt;/code&gt; to enable all format support (Python dependencies only - LibreOffice still needs separate installation)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üß™ Supported Content Types&lt;/h2&gt; 
&lt;h3&gt;Document Formats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PDFs&lt;/strong&gt; - Research papers, reports, presentations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; - DOC, DOCX, PPT, PPTX, XLS, XLSX&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - JPG, PNG, BMP, TIFF, GIF, WebP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; - TXT, MD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multimodal Elements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - Photographs, diagrams, charts, screenshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tables&lt;/strong&gt; - Data tables, comparison charts, statistical summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equations&lt;/strong&gt; - Mathematical formulas in LaTeX format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic Content&lt;/strong&gt; - Custom content types via extensible processors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;For installation of format-specific dependencies, see the &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-configuration"&gt;Configuration&lt;/a&gt; section.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìñ Citation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Academic Reference&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 60px; height: 60px; margin: 20px auto; position: relative;"&gt; 
  &lt;div style="width: 100%; height: 100%; border: 2px solid #00d9ff; border-radius: 50%; position: relative;"&gt; 
   &lt;div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); font-size: 24px; color: #00d9ff;"&gt;
    üìñ
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div style="position: absolute; bottom: -5px; left: 50%; transform: translateX(-50%); width: 20px; height: 20px; background: white; border-right: 2px solid #00d9ff; border-bottom: 2px solid #00d9ff; transform: rotate(45deg);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;If you find RAG-Anything useful in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{guo2024lightrag,
  title={LightRAG: Simple and Fast Retrieval-Augmented Generation},
  author={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
  year={2024},
  eprint={2410.05779},
  archivePrefix={arXiv},
  primaryClass={cs.IR}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîó Related Projects&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Ecosystem &amp;amp; Extensions&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;‚ö°&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;LightRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Simple and Fast RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/VideoRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;üé•&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;VideoRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extreme Long-Context Video RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/MiniRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;‚ú®&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;MiniRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extremely Simple RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://star-history.com/#HKUDS/RAG-Anything&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contribution&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Join the Innovation&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt;
  We thank all our contributors for their valuable contributions. 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/HKUDS/RAG-Anything/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=HKUDS/RAG-Anything" style="border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;"&gt; 
 &lt;div&gt; 
  &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="500" /&gt; 
 &lt;/div&gt; 
 &lt;div style="margin-top: 20px;"&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/‚≠ê%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/issues" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/üêõ%20Report%20Issues-ff6b6b?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/discussions" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/üí¨%20Discussions-4ecdc4?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: center; align-items: center; gap: 15px;"&gt; 
   &lt;span style="font-size: 24px;"&gt;‚≠ê&lt;/span&gt; 
   &lt;span style="color: #00d9ff; font-size: 18px;"&gt;Thank you for visiting RAG-Anything!&lt;/span&gt; 
   &lt;span style="font-size: 24px;"&gt;‚≠ê&lt;/span&gt; 
  &lt;/div&gt; 
  &lt;div style="margin-top: 10px; color: #00d9ff; font-size: 16px;"&gt;
   Building the Future of Multimodal AI
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>ByteByteGoHq/system-design-101</title>
      <link>https://github.com/ByteByteGoHq/system-design-101</link>
      <description>&lt;p&gt;Explain complex systems using visuals and simple terms. Help you prepare for system design interviews.&lt;/p&gt;&lt;hr&gt;&lt;p&gt; &lt;a href="https://blog.bytebytego.com/?utm_source=site"&gt;&lt;img src="https://raw.githubusercontent.com/ByteByteGoHq/system-design-101/main/.github/banner.jpg" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; „Äê &lt;a href="https://www.youtube.com/channel/UCZgt6AzoyjslHTC9dz0UoTw"&gt; üë®üèª‚Äçüíª YouTube &lt;/a&gt; | &lt;a href="https://blog.bytebytego.com/?utm_source=site"&gt; üìÆ Newsletter &lt;/a&gt; „Äë &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/3709" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3709" alt="ByteByteGoHq%2Fsystem-design-101 | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;System Design 101&lt;/h1&gt; 
&lt;p&gt;Explain complex systems using visuals and simple terms.&lt;/p&gt; 
&lt;p&gt;Whether you're preparing for a System Design Interview or you simply want to understand how systems work beneath the surface, we hope this repository will help you achieve that.&lt;/p&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;!-- TOC --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/api-web-development"&gt;API and Web Development&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/shortlong-polling-sse-websocket"&gt;Short/long polling, SSE, WebSocket&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/load-balancer-realistic-use-cases-you-may-not-know"&gt;Load Balancer Realistic Use Cases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/5-http-status-codes-that-should-never-have-been-created"&gt;5 HTTP Status Codes That Should Never Have Been Created&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-grpc-work"&gt;How does gRPC work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-nat-made-the-growth-of-the-internet-possible"&gt;How NAT Enabled the Internet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/important-things-about-http-headers-you-may-not-know"&gt;Important Things About HTTP Headers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/internet-traffic-routing-policies"&gt;Internet Traffic Routing Policies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-the-browser-render-a-web-page"&gt;How Browsers Render Web Pages&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-makes-http2-faster-than-http1"&gt;What makes HTTP2 faster than HTTP1?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-css-cascading-style-sheets"&gt;What is CSS (Cascading Style Sheets)?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/key-use-cases-for-load-balancers"&gt;Key Use Cases for Load Balancers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/18-common-ports-worth-knowing"&gt;18 Common Ports Worth Knowing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-are-the-differences-between-wan-lan-pan-and-man"&gt;What are the differences between WAN, LAN, PAN and MAN?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-javascript-work"&gt;How does Javascript Work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/8-tips-for-efficient-api-design"&gt;8 Tips for Efficient API Design&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/reverse-proxy-vs-api-gateway-vs-load-balancer"&gt;Reverse Proxy vs. API Gateway vs. Load Balancer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-rest-api-work"&gt;How does REST API work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-are-the-differences-between-a-load-balancer-and-an-api-gateway"&gt;Load Balancer vs. API Gateway&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-graphql-work-in-the-real-world"&gt;How GraphQL Works at LinkedIn&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/graphql-adoption-patterns"&gt;GraphQL Adoption Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-cheat-sheet-for-api-designs"&gt;A cheat sheet for API designs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/api-gateway-101"&gt;API Gateway 101&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-3-api-gateway-use-cases"&gt;Top 3 API Gateway Use Cases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-do-version-numbers-mean"&gt;What do version numbers mean?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/do-you-know-all-the-components-of-a-url"&gt;Do you know all the components of a URL?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/unicast-vs-broadcast-vs-multicast-vs-anycast"&gt;Unicast vs Broadcast vs Multicast vs Anycast&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/10-essential-components-of-a-production-web-application"&gt;10 Essential Components of a Production Web Application&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/url-uri-urn-do-you-know-the-differences"&gt;URL, URI, URN - Differences Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/api-vs-sdk"&gt;API vs SDK&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-cheatsheet-to-build-secure-apis"&gt;A Cheatsheet to Build Secure APIs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/http-status-code-you-should-know"&gt;HTTP Status Codes You Should Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/soap-vs-rest-vs-graphql-vs-rpc"&gt;SOAP vs REST vs GraphQL vs RPC&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-cheatsheet-on-comparing-api-architectural-styles"&gt;A Cheatsheet on Comparing API Architectural Styles&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-9-http-request-methods"&gt;Top 9 HTTP Request Methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-a-load-balancer"&gt;What is a Load Balancer?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/proxy-vs-reverse-proxy"&gt;Proxy vs Reverse Proxy&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/http1-http2-http3"&gt;HTTP/1 -&amp;gt; HTTP/2 -&amp;gt; HTTP/3&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/polling-vs-webhooks"&gt;Polling vs Webhooks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-perform-pagination-in-api-design"&gt;How do we Perform Pagination in API Design?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-design-effective-and-safe-apis"&gt;How to Design Effective and Safe APIs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-design-secure-web-api-access-for-your-website"&gt;How to Design Secure Web API Access&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-does-api-gateway-do"&gt;What Does an API Gateway Do?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-grpc"&gt;What is gRPC?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-12-tips-for-api-security"&gt;Top 12 Tips for API Security&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/explaining-9-types-of-api-testing"&gt;Explaining 9 Types of API Testing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/rest-api-vs-graphql"&gt;REST API vs. GraphQL&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-graphql"&gt;What is GraphQL?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/rest-api-cheatsheet"&gt;REST API Cheatsheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-ultimate-api-learning-roadmap"&gt;The Ultimate API Learning Roadmap&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-evolving-landscape-of-api-protocols-in-2023"&gt;The Evolving Landscape of API Protocols in 2023&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/real-world-case-studies"&gt;Real World Case Studies&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/100x-postgres-scaling-at-figma"&gt;100X Postgres Scaling at Figma&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/api-of-apis-app-integrations"&gt;API of APIs - App Integrations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-one-line-change-that-reduced-clone-times-by-a-whopping-99-says-pinterest"&gt;The one-line change that reduced clone times by 99% at Pinterest&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/is-telegram-secure"&gt;Is Telegram Secure?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/fixing-bugs-automatically-at-meta-scale"&gt;Fixing Bugs Automatically at Meta Scale&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-levelsfyi-scaled-to-millions-of-users-with-google-sheets"&gt;How Levelsfyi Scaled to Millions of Users with Google Sheets&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/mcdonald's-event-driven-architecture"&gt;McDonald‚Äôs Event-Driven Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/uber-tech-stack-cicd"&gt;Uber Tech Stack - CI/CD&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-will-you-design-the-stack-overflow-website"&gt;How to Design Stack Overflow&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/twitter-10-tech-stack"&gt;Twitter 1.0 Tech Stack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-twitter-recommend-tweets"&gt;How does Twitter recommend ‚ÄúFor You‚Äù Timeline in 1.5 seconds?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-youtube-handle-massive-video-content-upload"&gt;How YouTube Handles Massive Video Uploads&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-a-typical-push-notification-system-work"&gt;How Does a Typical Push Notification System Work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/4-ways-netflix-uses-caching-to-hold-user-attention"&gt;4 Ways Netflix Uses Caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/netflix-tech-stack-databases"&gt;Netflix Tech Stack - Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/airbnb-artchitectural-evolution"&gt;0 to 1.5 Billion Guests: Airbnb's Architectural Evolution&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-netflix-scale-push-messaging-for-millions-of-devices"&gt;How Netflix Scales Push Messaging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/netflixs-overall-architecture"&gt;Netflix's Overall Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/netflix-tech-stack-cicd-pipeline"&gt;Netflix Tech Stack - CI/CD Pipeline&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-tiktok-manages-a-200k-file-frontend-monorepo"&gt;How TikTok Manages a 200K File Frontend MonoRepo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-netflix-really-uses-java"&gt;How Netflix Really Uses Java&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/evolution-of-airbnb's-microservice"&gt;Evolution of Airbnb‚Äôs Microservice Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/reddit's-core-architecture"&gt;Reddit's Core Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/10-principles-for-building-resilient-payment-systems-by-shopify"&gt;10 Principles for Building Resilient Payment Systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-the-journey-of-a-slack-message"&gt;What is the Journey of a Slack Message?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-9-engineering-blog-favorites"&gt;Top 9 Engineering Blogs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/uber-tech-stack"&gt;Uber Tech Stack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/evolution-of-the-netflix-api-architecture"&gt;Evolution of the Netflix API Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-discord-stores-trillions-of-messages"&gt;How Discord Stores Trillions of Messages&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/twitter-architecture-2022-vs-2012"&gt;Twitter Architecture 2022 vs. 2012&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/evolution-of-uber's-api-layer"&gt;Evolution of Uber's API Layer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/netflixs-tech-stack"&gt;Netflix's Tech Stack&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/ai-machine-learning"&gt;AI and Machine Learning&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/5-functions-to-merge-data-with-pandas"&gt;5 Functions to Merge Data with Pandas&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/key-data-terms"&gt;Key Data Terms&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/chatgpt-timeline"&gt;ChatGPT Timeline&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/deepseek-1-pager"&gt;DeepSeek 1-Pager&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-open-source-ai-stack"&gt;The Open Source AI Stack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-an-ai-agent"&gt;What is an AI Agent?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/data-pipelines-overview"&gt;Data Pipelines Overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-chatgpt-work"&gt;How does ChatGPT work?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/database-and-storage"&gt;Database and Storage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/read-replica-pattern"&gt;Read Replica Pattern&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/pessimistic-vs-optimistic-locking"&gt;Pessimistic vs Optimistic Locking&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-upload-a-large-file-to-s3"&gt;How to Upload a Large File to S3&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/types-of-message-queue"&gt;Types of Message Queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/smooth-data-migration-with-avro"&gt;Smooth Data Migration with Avro&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-ultimate-kafka-101-you-cannot-miss"&gt;The Ultimate Kafka 101 You Cannot Miss&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-are-database-isolation-levels"&gt;Database Isolation Levels&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-manage-data"&gt;Top 6 Data Management Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/why-is-kafka-fast"&gt;Why is Kafka Fast?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/explaining-the-4-most-commonly-used-types-of-queues-in-a-single-diagram"&gt;Explaining the 4 Most Commonly Used Types of Queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/time-series-db-tsdb-in-20-lines"&gt;Time Series DB (TSDB) in 20 Lines&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/differences-in-event-sourcing-system-design"&gt;Differences in Event Sourcing System Design&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/erasure-coding"&gt;Erasure Coding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/delivery-semantics"&gt;Delivery Semantics&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/change-data-capture-key-to-leverage-real-time-data"&gt;Change Data Capture: Key to Leverage Real-time Data&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/can-kafka-lose-messages"&gt;Can Kafka Lose Messages?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/storage-systems-overview"&gt;Storage Systems Overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/explain-the-top-6-use-cases-of-object-stores"&gt;Explain the Top 6 Use Cases of Object Stores&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-eventual-consistency-patterns-you-must-know"&gt;Top Eventual Consistency Patterns You Must Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/b-tree-vs"&gt;B-Tree vs. LSM-Tree&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-you-decide-which-type-of-database-to-use"&gt;How to Decide Which Type of Database to Use&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cloud-database-cheat-sheet"&gt;Cloud Database Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/types-of-memory"&gt;Types of Memory&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/understanding-database-types"&gt;Understanding Database Types&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-4-data-sharding-algorithms-explained"&gt;Top 4 Data Sharding Algorithms Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-6-database-models"&gt;Top 6 Database Models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-is-a-sql-statement-executed-in-the-database"&gt;SQL Statement Execution in Database&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-serverless-db"&gt;What is Serverless DB?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/why-is-postgresql-voted-as-the-most-loved-database-by-stackoverflow-2022-developer-survey"&gt;Why PostgreSQL is the Most Loved Database&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-10-most-popular-open-source-databases"&gt;Top 10 Most Popular Open-Source Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/is-postgresql-eating-the-database-world"&gt;Is PostgreSQL Eating the Database World?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-choose-the-right-database"&gt;How to Choose the Right Database&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/iqiyi-database-selection-trees"&gt;iQIYI Database Selection Trees&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/8-data-structures-that-power-your-databases"&gt;8 Data Structures That Power Your Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-implement-read-replica-pattern"&gt;How to Implement Read Replica Pattern&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-crash-course-in-database-sharding"&gt;A Crash Course on Database Sharding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-message-queue-architectures-evolve"&gt;IBM MQ -&amp;gt; RabbitMQ -&amp;gt; Kafka -&amp;gt; Pulsar: Message Queue Evolution&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cap-theorem-one-of-the-most-misunderstood-terms"&gt;CAP Theorem: One of the Most Misunderstood Terms&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/consistent-hashing"&gt;Consistent Hashing Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/types-of-databases"&gt;Types of Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/key-concepts-to-understand-database-sharding"&gt;Key Concepts to Understand Database Sharding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-are-the-differences-among-database-locks"&gt;Database Locks Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-cheatsheet-on-database-performance"&gt;A Cheatsheet on Database Performance&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-does-acid-mean"&gt;What does ACID mean?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-5-kafka-use-cases"&gt;Top 5 Kafka Use Cases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/types-of-memory-and-storage"&gt;Types of Memory and Storage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/7-must-know-strategies-to-scale-your-database"&gt;7 Must-Know Strategies to Scale Your Database&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/technical-interviews"&gt;Technical Interviews&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-sql-joins-work"&gt;How do SQL Joins Work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-happens-when-you-type-google"&gt;What Happens When You Type google.com Into a Browser?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-happens-when-you-type-a-url-into-your-browser"&gt;What Happens When You Type a URL Into Your Browser?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-ace-system-design-interviews-like-a-boss"&gt;How to Ace System Design Interviews&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/my-recommended-materials-for-cracking-your-next-technical-interview"&gt;Recommended Materials for Technical Interviews&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/caching-performance"&gt;Caching &amp;amp; Performance&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-elk-stack-and-why-is-it-so-popular-for-log-management"&gt;What is ELK Stack and Why is it Popular?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/why-are-content-delivery-networks-cdn-so-popular"&gt;Why are Content Delivery Networks (CDN) so Popular?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-big-keys-impact-redis-persistence"&gt;How Big Keys Impact Redis Persistence&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-beginner's-guide-to-cdn-content-delivery-network"&gt;A Beginner's Guide to CDN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-ultimate-redis-101"&gt;The Ultimate Redis 101&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cache-systems-every-developer-should-know"&gt;Cache Systems Every Developer Should Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-5-strategies-to-reduce-latency"&gt;Top 5 Strategies to Reduce Latency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-5-caching-strategies"&gt;Top 5 Caching Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/things-to-consider-when-using-cache"&gt;Things to Consider When Using Cache&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/most-popular-cache-eviction"&gt;Cache Eviction Policies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/memcached-vs-redis"&gt;Memcached vs Redis&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/low-latency-stock-exchange"&gt;Low Latency Stock Exchange&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cache-miss-attack"&gt;Cache Miss Attack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-8-cache-eviction-strategies"&gt;Top 8 Cache Eviction Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-can-cache-systems-go-wrong"&gt;How Can Cache Systems Go Wrong?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-6-elasticsearch-use-cases"&gt;Top 6 Elasticsearch Use Cases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-cnd-work"&gt;How Does CDN Work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-redis-architecture-evolve"&gt;How Redis Architecture Evolved&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-redis-persist-data"&gt;How Does Redis Persist Data?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-can-redis-be-used"&gt;How can Redis be used?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/why-is-redis-so-fast"&gt;Why is Redis so Fast?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-learn-elasticsearch"&gt;How to Learn Elasticsearch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-cdn-content-delivery-network"&gt;What is CDN (Content Delivery Network)?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-load-your-websites-at-lightning-speed"&gt;Frontend Performance Optimization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/which-latency-numbers-should-you-know"&gt;Which Latency Numbers Should You Know?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-are-the-top-caching-strategies"&gt;Top Caching Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-9-website-performance-metrics-you-cannot-ignore"&gt;Top 9 Website Performance Metrics You Cannot Ignore&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-5-common-ways-to-improve-api-performance"&gt;Top 5 Common Ways to Improve API Performance&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/learn-cache"&gt;Learn Cache&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/payment-and-fintech"&gt;Payment and Fintech&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/e-commerce-workflow"&gt;E-commerce Workflow&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/digital-wallet-in-traditional-banks-vs-wallet-in-blockchain"&gt;Digital Wallets: Banks vs. Blockchain&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-a-stop-loss-order-and-how-does-it-work"&gt;What is a Stop-Loss Order and How Does it Work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-web-3"&gt;What is Web 3.0? Why doesn't it have ads?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/swift-payment-messaging-system"&gt;SWIFT Payment Messaging System&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/4-ways-of-qr-code-payment"&gt;4 Ways of QR Code Payment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/handling-hotspot-accounts"&gt;Handling Hotspot Accounts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/reconciliation-in-payment"&gt;Reconciliation in Payment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/unified-payments-interface-upi-in-india"&gt;Unified Payments Interface (UPI)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-scan-to-pay-work"&gt;How Scan to Pay Works&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/money-movement"&gt;Money Movement&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/payment-system"&gt;Payment System&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-learn-payments"&gt;How to Learn Payments&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-payments-ecosystem"&gt;The Payments Ecosystem&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/foreign-exchange-payments"&gt;Foreign Exchange Payments&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-avoid-double-payment"&gt;How to Avoid Double Payment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-applegoogle-pay-works"&gt;How do Apple Pay and Google Pay work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-visa-work-when-we-swipe-a-credit-card-at-a-merchant's-shop"&gt;How VISA Works When Swiping a Credit Card&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-ach-payment-work"&gt;How ACH Payment Works&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-visa-make-money"&gt;How does Visa make money?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/software-architecture"&gt;Software Architecture&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-processes-talk-to-each-other-on-linux"&gt;Inter-Process Communication on Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/orchestration-vs-choreography-microservices"&gt;Orchestration vs. Choreography in Microservices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-cheatsheet-for-uml-class-diagrams"&gt;UML Class Diagrams Cheatsheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/amazon-prime-video-monitoring-service"&gt;Amazon Prime Video Monitoring Service&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/is-microservice-architecture-the-silver-bullet"&gt;Is Microservice Architecture the Silver Bullet?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/database-middleware"&gt;Database Middleware&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/9-best-practices-for-developing-microservices"&gt;9 Best Practices for Developing Microservices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/design-patterns-cheat-sheet-part-1-and-part-2"&gt;Design Patterns Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/key-terms-in-domain-driven-design"&gt;Key Terms in Domain-Driven Design&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/8-key-oop-concepts-every-developer-should-know"&gt;8 Key OOP Concepts Every Developer Should Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/18-key-design-patterns-every-developer-should-know"&gt;18 Key Design Patterns Every Developer Should Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/10-system-design-tradeoffs-you-cannot-ignore"&gt;10 System Design Tradeoffs You Cannot Ignore&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/9-essential-components-of-a-production-microservice-application"&gt;9 Essential Components of a Production Microservice Application&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/9-best-practices-for-building-microservices"&gt;9 Best Practices for Building Microservices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/8-key-concepts-in-ddd"&gt;8 Key Concepts in Domain-Driven Design&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/8-common-system-design-problems-and-solutions"&gt;8 Common System Design Problems and Solutions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/6-software-architectural-patterns-you-must-know"&gt;6 Software Architectural Patterns You Must Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-release-a-mobile-app"&gt;How To Release A Mobile App&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-computer-programs-run"&gt;How Do Computer Programs Run?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/linux-boot-process-explained"&gt;Linux Boot Process Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/mvc-mvp-mvvm-viper-patterns"&gt;MVC, MVP, MVVM, VIPER Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-ultimate-software-architect-knowledge-map"&gt;The Ultimate Software Architect Knowledge Map&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-does-a-typical-microservice-architecture-look-like"&gt;Typical Microservice Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-5-software-architectural-patterns"&gt;Top 5 Software Architectural Patterns&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/devtools-productivity"&gt;DevTools &amp;amp; Productivity&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/git-commands-cheat-sheet"&gt;Git Commands Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/git-workflow"&gt;How does Git Work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/json-files"&gt;JSON Crack: Visualize JSON Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/git-vs-github"&gt;Git vs GitHub&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/git-merge-vs-git-rebate"&gt;Git Merge vs. Git Rebase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/30-useful-ai-apps-that-can-help-you-in-2025"&gt;30 Useful AI Apps That Can Help You in 2025&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/diagram-as-code"&gt;Diagram as Code&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-9-cases-behind-100-cpu-usage"&gt;Top 9 Causes of 100% CPU Usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-6-tools-to-turn-code-into-beautiful-diagrams"&gt;Top 6 Tools to Turn Code into Beautiful Diagrams&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-tools-does-your-team-use-to-ship-code-to-production-and-ensure-code-quality"&gt;Tools for Shipping Code to Production&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/making-sense-of-search-engine-optimization"&gt;Making Sense of Search Engine Optimization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/most-used-linux-commands-map"&gt;Most Used Linux Commands Map&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/linux-file-permission-illustrated"&gt;Linux File Permissions Illustrated&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/5-important-components-of-linux"&gt;5 Important Components of Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/15-open-source-projects-that-changed-the-world"&gt;15 Open-Source Projects That Changed the World&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/20-popular-open-source-projects-started-or-supported-by-big-companies"&gt;20 Popular Open Source Projects Started by Big Companies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/linux-file-system-explained"&gt;Linux File System Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/life-is-short-use-dev-tools"&gt;Life is Short, Use Dev Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-git-work"&gt;How Git Works&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-companies-ship-code-to-production"&gt;How do Companies Ship Code to Production?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/software-development"&gt;Software Development&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-6-most-commonly-used-server-types"&gt;Top 6 Most Commonly Used Server Types&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-garbage-collection-work"&gt;How does Garbage Collection work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-roadmap-for-full-stack-development"&gt;A Roadmap for Full-Stack Development&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-are-the-greenest-programming-languages"&gt;What Are the Greenest Programming Languages?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/java-collection-hierarchy"&gt;Java Collection Hierarchy&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/is-it-possible-to-run-c-c++-or-rust-on-a-web-browser"&gt;Running C, C++, or Rust in a Web Browser&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-8-c++-use-cases"&gt;Top 8 C++ Use Cases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-6-multithreading-design-patterns-you-must-know"&gt;Top 6 Multithreading Design Patterns You Must Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-is-data-transmitted-between-applications"&gt;Data Transmission Between Applications&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/blocking-vs-non-blocking-queue"&gt;Blocking vs Non-Blocking Queue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/big-endian-vs-little-endian"&gt;Big Endian vs Little Endian&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-avoid-crawling-duplicate-urls-at-google-scale"&gt;How to Avoid Crawling Duplicate URLs at Google Scale?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/10-books-for-software-developers"&gt;10 Books for Software Developers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-8-standards-every-developer-should-know"&gt;Top 8 Standards Every Developer Should Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-c++-java-python-work"&gt;How Do C++, Java, Python Work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/10-key-data-structures-we-use-every-day"&gt;10 Key Data Structures We Use Every Day&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-brief-history-og-programming-languages"&gt;A Brief History of Programming Languages&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-6-load-balancing-algorithms"&gt;Top 6 Load Balancing Algorithms&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-fundamental-pillars-of-object-oriented-programming"&gt;The Fundamental Pillars of Object-Oriented Programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-8-programming-paradigms"&gt;Top 8 Programming Paradigms&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/algorithms-you-should-know-before-taking-system-design-interviews"&gt;Algorithms for System Design Interviews&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/imperative-vs-functional-vs-object-oriented-programming"&gt;Imperative vs Functional vs Object-oriented Programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/explaining-9-types-of-api-testing"&gt;Explaining 9 Types of API Testing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-9-algorithms-that-dominate-our-world"&gt;The 9 Algorithms That Dominate Our World&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/concurrency-is-not-parallelism"&gt;Concurrency vs Parallelism&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/linux-boot-process-explained"&gt;Linux Boot Process Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/11-steps-to-go-from-junior-to-senior-developer"&gt;11 Steps to Go From Junior to Senior Developer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/10-good-coding-principles-to-improve-code-quality"&gt;10 Good Coding Principles to Improve Code Quality&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cloud-distributed-systems"&gt;Cloud &amp;amp; Distributed Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-aws-lambda-work-behind-the-scenes"&gt;How AWS Lambda Works Behind the Scenes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/8-must-know-scalability-strategies"&gt;8 Must-Know Scalability Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/system-design-cheat-sheet"&gt;System Design Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cloud-disaster-recovery-strategies"&gt;Cloud Disaster Recovery Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/vertical-partitioning-vs-horizontal-partitioning"&gt;Vertical vs Horizontal Partitioning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-9-architectural-patterns-for-data-and-communication-flow"&gt;Top 9 Architectural Patterns for Data and Communication Flow&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-6-cases-to-apply-idempotency"&gt;Top 6 Cases to Apply Idempotency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-5-trade-offs-in-system-designs"&gt;Top 5 Trade-offs in System Designs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-detect-node-failures-in-distributed-systems"&gt;How to Detect Node Failures in Distributed Systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/do-you-know-why-meta-google-and-amazon-all-stop-using-leap-seconds"&gt;Why Meta, Google, and Amazon Stop Using Leap Seconds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/who-are-the-fantastic-four-of-system-design"&gt;The Fantastic Four of System Design&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-makes-aws-lambda-so-fast"&gt;What makes AWS Lambda so fast?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-scale-a-website-to-support-millions-of-users"&gt;Scaling Websites for Millions of Users&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/resiliency-patterns"&gt;Resiliency Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/25-papers-that-completely-transformed-the-computer-world"&gt;25 Papers That Completely Transformed the Computer World&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-crash-course-on-architectural-scalability"&gt;A Crash Course on Architectural Scalability&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/must-know-system-design-building-blocks"&gt;Must Know System Design Building Blocks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/monorepo-vs"&gt;Monorepo vs. Microrepo: Which is Best?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-handle-web-request-error"&gt;How to Handle Web Request Errors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-cheat-sheet-for-designing-fault-tolerant-systems"&gt;A Cheat Sheet for Designing Fault-Tolerant Systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/typical-aws-network-architecture-in-one-diagram"&gt;Typical AWS Network Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/unique-id-generator"&gt;Unique ID Generator&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-amazon-build-system-work"&gt;Amazon's Build System: Brazil&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-cheatsheet-on-infrastructure-as-code-landscape"&gt;Infrastructure as Code Landscape Cheatsheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-manage-configurations-in-a-system"&gt;How do we manage configurations in a system?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-incorporate-event-sourcing-into-the-systems"&gt;How do we incorporate Event Sourcing into systems?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-12-factor-app"&gt;The 12-Factor App&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/explaining-5-unique-id-generators-in-distributed-systems"&gt;Explaining 5 Unique ID Generators&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-retry-on-failures"&gt;Retry Strategies for System Failures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cloud-monitoring-cheat-sheet"&gt;Cloud Monitoring Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/why-do-we-need-to-use-a-distributed-lock"&gt;Why Use a Distributed Lock?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-6-cloud-messaging-patterns"&gt;Top 6 Cloud Messaging Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-are-the-most-important-aws-services-to-learn"&gt;Most Important AWS Services to Learn&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-transform-a-system-to-be-cloud-native"&gt;How to Transform a System to be Cloud Native&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/hidden-costs-of-the-cloud"&gt;Hidden Costs of the Cloud&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/2-decades-of-cloud-evolution"&gt;2 Decades of Cloud Evolution&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cloud-cost-reduction-techniques"&gt;Cloud Cost Reduction Techniques&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-7-most-used-distributed-system-patterns"&gt;Top 7 Most-Used Distributed System Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cloud-load-balancer-cheat-sheet"&gt;Cloud Load Balancer Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/aws-services-evolution"&gt;AWS Services Evolution&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/azure-services-cheat-sheet"&gt;Azure Services Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/a-cheat-sheet-for-system-designs"&gt;A cheat sheet for system designs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cap-base-solid-kiss-what-do-these-acronyms-mean"&gt;CAP, BASE, SOLID, KISS, What do these acronyms mean?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/system-design-blueprint-the-ultimate-guide"&gt;System Design Blueprint: The Ultimate Guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-design-for-high-availability"&gt;How to Design for High Availability&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-cloud-native"&gt;What is Cloud Native?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cloud-comparison-cheat-sheet"&gt;Cloud Comparison Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/big-data-pipeline-cheatsheet-for-aws-azure-and-google-cloud"&gt;Big Data Pipeline Cheatsheet for AWS, Azure, and Google Cloud&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/aws-services-cheat-sheet"&gt;AWS Services Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-it-works"&gt;How it Works?&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-airtags-work"&gt;How do AirTags work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-is-email-delivered"&gt;How is Email Delivered?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/design-gmail"&gt;Design Gmail&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-googleapple-maps-blur-license-plates-and-human-faces-on-street-view"&gt;How Google/Apple Maps Blur License Plates and Faces&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/quadtree"&gt;Quadtree&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/build-a-simple-chat-application"&gt;Build a Simple Chat Application with Redis&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/live-streaming-explained"&gt;Live Streaming Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-design-a-system-for-internationalization"&gt;How to Design a System for Internationalization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-design-google-docs"&gt;How to Design Google Docs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/payment-system"&gt;Payment System&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/possible-experiment-platform-architecture"&gt;Experiment Platform Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/design-google-maps"&gt;Design Google Maps&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-design-a-chat-application-like-whatsapp-facebook-messenger-or-discord"&gt;Designing a Chat Application&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/design-stock-exchange"&gt;Design Stock Exchange&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-are-notifications-pushed-to-our-phones-or-pcs"&gt;How are Notifications Pushed to Our Phones or PCs?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-happens-when-you-upload-a-file-to-amazon-s3"&gt;What Happens When You Upload a File to Amazon S3?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/proximity-service"&gt;Proximity Service&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-search-engines-work"&gt;How Do Search Engines Work?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/devops-cicd"&gt;DevOps and CI/CD&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-10-k8s-design-patterns"&gt;Top 10 Kubernetes Design Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/some-devops-books-i-find-enlightening"&gt;Some DevOps Books I Find Enlightening&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/paradigm-shift-how-developer-to-tester-ratio-changed-from-11-to-1001"&gt;Paradigm Shift: Developer to Tester Ratio&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/push-vs-pull-in-metrics-collecting-systems"&gt;Push vs Pull in Metrics Collection Systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/choose-the-right-database-for-metric-collecting-system"&gt;Choose the Right Database for Metric Collection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-4-kubernetes-service-types-in-one-diagram"&gt;Top 4 Kubernetes Service Types&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cloud-native-anti-patterns"&gt;Cloud Native Anti-Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/kubernetes-tools-stack-wheel"&gt;Kubernetes Tools Stack Wheel&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/kubernetes-tools-ecosystem"&gt;Kubernetes Tools Ecosystem&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/kubernetes-periodic-table"&gt;Kubernetes Periodic Table&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/9-docker-best-practices-you-must-know"&gt;9 Docker Best Practices You Must Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/netflix-tech-stack-cicd-pipeline"&gt;Netflix Tech Stack - CI/CD Pipeline&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-8-must-know-docker-concepts"&gt;Top 8 Must-Know Docker Concepts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cicd-simplified-visual-guide"&gt;CI/CD Simplified Visual Guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-5-most-used-deployment-strategies"&gt;Top 5 Most-Used Deployment Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/the-ultimate-kubernetes-command-cheatsheet"&gt;Kubernetes Command Cheatsheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/kubernetes-deployment-strategies"&gt;Kubernetes Deployment Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-terraform-turn-code-into-cloud"&gt;How does Terraform turn Code into Cloud?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/devops-vs-sre-vs-paltform-engg"&gt;DevOps vs. SRE vs. Platform Engineering&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-deploy-services"&gt;Deployment Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/logging-tracing-metrics"&gt;Logging, Tracing, and Metrics&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/log-parsing-cheat-sheet"&gt;Log Parsing Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/devops-vs-noops"&gt;DevOps vs NoOps: What's the Difference?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/why-is-nginx-so-popular"&gt;Why is Nginx so Popular?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-k8s-kubernetes"&gt;What is Kubernetes (k8s)?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-docker-work"&gt;How does Docker work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cicd-pipeline-explained-in-simple-terms"&gt;CI/CD Pipeline Explained in Simple Terms&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/security"&gt;Security&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-devsecops"&gt;What is DevSecOps?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/encoding-vs-encryption-vs-tokenization"&gt;Encoding vs Encryption vs Tokenization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-to-store-passwords-in-the-database"&gt;Storing Passwords Safely: A Comprehensive Guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-design-a-permission-system"&gt;Designing a Permission System&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-a-password-manager-such-as-1password-or-lastpass-work"&gt;How Password Managers Work&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/is-passkey-shaping-a-passwordless-future"&gt;Is PassKey Shaping a Passwordless Future?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/firewall-explained-to-kids-and-adults"&gt;Firewall Explained to Kids and Adults&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-are-the-differences-between-cookies-and-sessions"&gt;Cookies vs Sessions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/http-cookies-explained-with-a-simple-diagram"&gt;HTTP Cookies Explained With a Simple Diagram&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/token-cookie-session"&gt;Token, Cookie, Session&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/explaining-sessions-tokens-jwt-sso-and-oauth-in-one-diagram"&gt;Sessions, Tokens, JWT, SSO, and OAuth Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-design-a-secure-system"&gt;How to Design a Secure System&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-6-firewall-use-cases"&gt;Top 6 Firewall Use Cases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-4-forms-of-authentication-mechanisms"&gt;Top 4 Authentication Mechanisms&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-digital-signatures-work"&gt;How Digital Signatures Work&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-do-we-manage-sensitive-data-in-a-system"&gt;How do we manage sensitive data in a system?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/https-ssl-handshake-and-data-encryption-explained-to-kids"&gt;HTTPS, SSL Handshake, and Data Encryption Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/symmetric-encryption-vs-asymmetric-encryption"&gt;Symmetric vs Asymmetric Encryption&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what's-the-difference-between-session-based-authentication-and-jwts"&gt;Session-based Authentication vs. JWT&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/jwt-101-key-to-stateless-authentication"&gt;JWT 101: Key to Stateless Authentication&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/is-https-safe"&gt;Is HTTPS Safe?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cybersecurity-101-in-one-picture"&gt;Cybersecurity 101&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/cookies-vs-sessions-vs-jwt-vs-paseto"&gt;Cookies vs Sessions vs JWT vs PASETO&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-ssh-work"&gt;How does SSH work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-a-vpn-work"&gt;How Does a VPN Work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-google-authenticator-or-other-types-of-2-factor-authenticators-work"&gt;How Google Authenticator Works&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/types-of-vpns"&gt;Types of VPNs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-a-cookie"&gt;What is a Cookie?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/oauth-20-flows"&gt;OAuth 2.0 Flows&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-network-security-cheatsheet"&gt;Top Network Security Cheatsheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/v1what-is-sso-single-sign-on"&gt;What is SSO (Single Sign-On)?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-https-work"&gt;How does HTTPS work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/session-cookie-jwt-token-sso-and-oauth-2"&gt;Session, Cookie, JWT, Token, SSO, and OAuth 2.0 Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/explaining-json-web-token-jwt-to-a-10-year-old-kid"&gt;Explaining JSON Web Token (JWT) to a 10 Year Old Kid&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/oauth-2-explained-with-siple-terms"&gt;OAuth 2.0 Explained With Simple Terms&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytebytego.com/guides/computer-fundamentals"&gt;Computer Fundamentals&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-are-the-differences-between-paging-and-segmentation"&gt;Paging vs Segmentation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/ipv4-vs-ipv6"&gt;IPv4 vs. IPv6: Differences&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/top-4-most-popular-use-cases-for-udp"&gt;Top 4 Most Popular Use Cases for UDP&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/how-does-the-domain-name-system-dns-lookup-work"&gt;How Does the Domain Name System (DNS) Lookup Work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/dns-record-types-you-should-know"&gt;DNS Record Types You Should Know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-protocol-does-online-gaming-use-to-transmit-data"&gt;TCP vs UDP for Online Gaming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-a-deadlock"&gt;What is a Deadlock?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-the-difference-between-process-and-thread"&gt;Process vs Thread: Key Differences&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-osi-model"&gt;OSI Model Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/visualizing-a-sql-query"&gt;Visualizing a SQL Query&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/explaining-8-popular-network-protocols-in-1-diagram"&gt;Explaining 8 Popular Network Protocols in 1 Diagram&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://bytebytego.com/guides/what-is-the-best-way-to-learn-sql"&gt;What is the Best Way to Learn SQL?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- /TOC --&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p xmlns:cc="http://creativecommons.org/ns#"&gt;This work is licensed under &lt;a href="http://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"&gt;CC BY-NC-ND 4.0&lt;img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" /&gt;&lt;img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" /&gt;&lt;img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" /&gt;&lt;img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>exo-explore/exo</title>
      <link>https://github.com/exo-explore/exo</link>
      <description>&lt;p&gt;Run your own AI cluster at home with everyday devices üì±üíª üñ•Ô∏è‚åö&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/exo-logo-black-bg.jpg" /&gt; 
  &lt;img alt="exo logo" src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/exo-logo-transparent.png" width="50%" height="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;exo: Run your own AI cluster at home with everyday devices. Maintained by &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt;.&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://discord.gg/EUnjGpsmWw"&gt;Discord&lt;/a&gt; | &lt;a href="https://t.me/+Kh-KqHTzFYg3MGNk"&gt;Telegram&lt;/a&gt; | &lt;a href="https://x.com/exolabs"&gt;X&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/exo-explore/exo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/exo-explore/exo" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://dl.circleci.com/status-badge/redirect/circleci/TrkofJDoGzdQAeL6yVHKsg/4i5hJuafuwZYZQxbRAWS71/tree/main"&gt;&lt;img src="https://dl.circleci.com/status-badge/img/circleci/TrkofJDoGzdQAeL6yVHKsg/4i5hJuafuwZYZQxbRAWS71/tree/main.svg?style=svg" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://www.gnu.org/licenses/gpl-3.0"&gt;&lt;img src="https://img.shields.io/badge/License-GPLv3-blue.svg?sanitize=true" alt="License: GPL v3" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11849" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11849" alt="exo-explore%2Fexo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;Unify your existing devices into one powerful GPU: iPhone, iPad, Android, Mac, NVIDIA, Raspberry Pi, pretty much any device!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;Update: exo is hiring. See &lt;a href="https://exolabs.net"&gt;here&lt;/a&gt; for more details.&lt;/h2&gt; 
 &lt;h2&gt;Interested in running exo in your business? &lt;a href="mailto:hello@exolabs.net"&gt;Contact us&lt;/a&gt; to discuss.&lt;/h2&gt; 
&lt;/div&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;p&gt;exo is &lt;strong&gt;experimental&lt;/strong&gt; software. Expect bugs early on. Create issues so they can be fixed. The &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt; team will strive to resolve issues quickly.&lt;/p&gt; 
&lt;p&gt;We also welcome contributions from the community. We have a list of bounties in &lt;a href="https://docs.google.com/spreadsheets/d/1cTCpTIp48UnnIvHeLEUNg1iMy_Q6lRybgECSFCoVJpE/edit?usp=sharing"&gt;this sheet&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Wide Model Support&lt;/h3&gt; 
&lt;p&gt;exo supports different models including LLaMA (&lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/mlx/models/llama.py"&gt;MLX&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/tinygrad/models/llama.py"&gt;tinygrad&lt;/a&gt;), Mistral, LlaVA, Qwen, and Deepseek.&lt;/p&gt; 
&lt;h3&gt;Dynamic Model Partitioning&lt;/h3&gt; 
&lt;p&gt;exo &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/ring_memory_weighted_partitioning_strategy.py"&gt;optimally splits up models&lt;/a&gt; based on the current network topology and device resources available. This enables you to run larger models than you would be able to on any single device.&lt;/p&gt; 
&lt;h3&gt;Automatic Device Discovery&lt;/h3&gt; 
&lt;p&gt;exo will &lt;a href="https://github.com/exo-explore/exo/raw/945f90f676182a751d2ad7bcf20987ab7fe0181e/exo/orchestration/node.py#L154"&gt;automatically discover&lt;/a&gt; other devices using the best method available. Zero manual configuration.&lt;/p&gt; 
&lt;h3&gt;ChatGPT-compatible API&lt;/h3&gt; 
&lt;p&gt;exo provides a &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/api/chatgpt_api.py"&gt;ChatGPT-compatible API&lt;/a&gt; for running models. It's a &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/examples/chatgpt_api.sh"&gt;one-line change&lt;/a&gt; in your application to run models on your own hardware using exo.&lt;/p&gt; 
&lt;h3&gt;Device Equality&lt;/h3&gt; 
&lt;p&gt;Unlike other distributed inference frameworks, exo does not use a master-worker architecture. Instead, exo devices &lt;a href="https://github.com/exo-explore/exo/raw/945f90f676182a751d2ad7bcf20987ab7fe0181e/exo/orchestration/node.py#L161"&gt;connect p2p&lt;/a&gt;. As long as a device is connected somewhere in the network, it can be used to run models.&lt;/p&gt; 
&lt;p&gt;Exo supports different &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/partitioning_strategy.py"&gt;partitioning strategies&lt;/a&gt; to split up a model across devices. The default partitioning strategy is &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/ring_memory_weighted_partitioning_strategy.py"&gt;ring memory weighted partitioning&lt;/a&gt;. This runs an inference in a ring where each device runs a number of model layers proportional to the memory of the device.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/exo-screenshot.jpg" alt="&amp;quot;A screenshot of exo running 5 nodes" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The current recommended way to install exo is from source.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python&amp;gt;=3.12.0 is required because of &lt;a href="https://github.com/exo-explore/exo/issues/5"&gt;issues with asyncio&lt;/a&gt; in previous versions.&lt;/li&gt; 
 &lt;li&gt;For Linux with NVIDIA GPU support (Linux-only, skip if not using Linux or NVIDIA): 
  &lt;ul&gt; 
   &lt;li&gt;NVIDIA driver - verify with &lt;code&gt;nvidia-smi&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;CUDA toolkit - install from &lt;a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-installation"&gt;NVIDIA CUDA guide&lt;/a&gt;, verify with &lt;code&gt;nvcc --version&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;cuDNN library - download from &lt;a href="https://developer.nvidia.com/cudnn-downloads"&gt;NVIDIA cuDNN page&lt;/a&gt;, verify installation by following &lt;a href="https://docs.nvidia.com/deeplearning/cudnn/latest/installation/linux.html#verifying-the-install-on-linux:~:text=at%20a%20time.-,Verifying%20the%20Install%20on%20Linux,Test%20passed!,-Upgrading%20From%20Older"&gt;these steps&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Hardware Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The only requirement to run exo is to have enough memory across all your devices to fit the entire model into memory. For example, if you are running llama 3.1 8B (fp16), you need 16GB of memory across all devices. Any of the following configurations would work since they each have more than 16GB of memory in total: 
  &lt;ul&gt; 
   &lt;li&gt;2 x 8GB M3 MacBook Airs&lt;/li&gt; 
   &lt;li&gt;1 x 16GB NVIDIA RTX 4070 Ti Laptop&lt;/li&gt; 
   &lt;li&gt;2 x Raspberry Pi 400 with 4GB of RAM each (running on CPU) + 1 x 8GB Mac Mini&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;exo is designed to run on devices with heterogeneous capabilities. For example, you can have some devices with powerful GPUs and others with integrated GPUs or even CPUs. Adding less capable devices will slow down individual inference latency but will increase the overall throughput of the cluster.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/exo-explore/exo.git
cd exo
pip install -e .
# alternatively, with venv
source install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;If running on Mac, MLX has an &lt;a href="https://ml-explore.github.io/mlx/build/html/install.html"&gt;install guide&lt;/a&gt; with troubleshooting steps.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;There are a number of things users have empirically found to improve performance on Apple Silicon Macs:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;Upgrade to the latest version of macOS Sequoia.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;./configure_mlx.sh&lt;/code&gt;. This runs commands to optimize GPU memory allocation on Apple Silicon Macs.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;h3&gt;Example Usage on Multiple macOS Devices&lt;/h3&gt; 
&lt;h4&gt;Device 1:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Device 2:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! No configuration required - exo will automatically discover the other device(s).&lt;/p&gt; 
&lt;p&gt;exo starts a ChatGPT-like WebUI (powered by &lt;a href="https://github.com/tinygrad/tinygrad/tree/master/examples/tinychat"&gt;tinygrad tinychat&lt;/a&gt;) on &lt;a href="http://localhost:52415"&gt;http://localhost:52415&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For developers, exo also starts a ChatGPT-compatible API endpoint on &lt;a href="http://localhost:52415/v1/chat/completions"&gt;http://localhost:52415/v1/chat/completions&lt;/a&gt;. Examples with curl:&lt;/p&gt; 
&lt;h4&gt;Llama 3.2 3B:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llama-3.2-3b",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Llama 3.1 405B:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llama-3.1-405b",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;DeepSeek R1 (full 671B):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "deepseek-r1",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Llava 1.5 7B (Vision Language Model):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llava-1.5-7b-hf",
     "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "What are these?"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "http://images.cocodataset.org/val2017/000000039769.jpg"
            }
          }
        ]
      }
    ],
     "temperature": 0.0
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example Usage on Multiple Heterogenous Devices (macOS + Linux)&lt;/h3&gt; 
&lt;h4&gt;Device 1 (macOS):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: We don't need to explicitly tell exo to use the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine. &lt;strong&gt;MLX&lt;/strong&gt; and &lt;strong&gt;tinygrad&lt;/strong&gt; are interoperable!&lt;/p&gt; 
&lt;h4&gt;Device 2 (Linux):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Linux devices will automatically default to using the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine.&lt;/p&gt; 
&lt;p&gt;You can read about tinygrad-specific env vars &lt;a href="https://docs.tinygrad.org/env_vars/"&gt;here&lt;/a&gt;. For example, you can configure tinygrad to use the cpu by specifying &lt;code&gt;CLANG=1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Example Usage on a single device with "exo run" command&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo run llama-3.2-3b
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With a custom prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo run llama-3.2-3b --prompt "What is the meaning of exo?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Model Storage&lt;/h3&gt; 
&lt;p&gt;Models by default are stored in &lt;code&gt;~/.cache/exo/downloads&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can set a different model storage location by setting the &lt;code&gt;EXO_HOME&lt;/code&gt; env var.&lt;/p&gt; 
&lt;h2&gt;Model Downloading&lt;/h2&gt; 
&lt;p&gt;Models are downloaded from Hugging Face. If you are running exo in a country with strict internet censorship, you may need to download the models manually and put them in the &lt;code&gt;~/.cache/exo/downloads&lt;/code&gt; directory.&lt;/p&gt; 
&lt;p&gt;To download models from a proxy endpoint, set the &lt;code&gt;HF_ENDPOINT&lt;/code&gt; environment variable. For example, to run exo with the huggingface mirror endpoint:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;HF_ENDPOINT=https://hf-mirror.com exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Debugging&lt;/h2&gt; 
&lt;p&gt;Enable debug logs with the DEBUG environment variable (0-9).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;DEBUG=9 exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine specifically, there is a separate DEBUG flag &lt;code&gt;TINYGRAD_DEBUG&lt;/code&gt; that can be used to enable debug logs (1-6).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;TINYGRAD_DEBUG=2 exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Formatting&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/google/yapf"&gt;yapf&lt;/a&gt; to format the code. To format the code, first install the formatting requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip3 install -e '.[formatting]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run the formatting script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 format.py ./exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Known Issues&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;On certain versions of Python on macOS, certificates may not installed correctly, potentially causing SSL errors (e.g., when accessing huggingface.co). To resolve this, run the &lt;code&gt;Install Certificates&lt;/code&gt; command, typicall as follows:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;/Applications/Python 3.x/Install Certificates.command
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöß As the library is evolving so quickly, the iOS implementation has fallen behind Python. We have decided for now not to put out the buggy iOS version and receive a bunch of GitHub issues for outdated code. We are working on solving this properly and will make an announcement when it's ready. If you would like access to the iOS implementation now, please email &lt;a href="mailto:alex@exolabs.net"&gt;alex@exolabs.net&lt;/a&gt; with your GitHub username explaining your use-case and you will be granted access on GitHub.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Inference Engines&lt;/h2&gt; 
&lt;p&gt;exo supports the following inference engines:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/mlx/sharded_inference_engine.py"&gt;MLX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/tinygrad/inference.py"&gt;tinygrad&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöß &lt;a href="https://github.com/exo-explore/exo/pull/139"&gt;PyTorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöß &lt;a href="https://github.com/exo-explore/exo/issues/167"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Discovery Modules&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/udp"&gt;UDP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/manual"&gt;Manual&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/tailscale"&gt;Tailscale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöß Radio&lt;/li&gt; 
 &lt;li&gt;üöß Bluetooth&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Peer Networking Modules&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/grpc"&gt;GRPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöß NCCL&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>