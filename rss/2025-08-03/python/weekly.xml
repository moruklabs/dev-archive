<rss version="2.0">
  <channel>
    <title>GitHub Python Weekly Trending</title>
    <description>Weekly Trending of Python in GitHub</description>
    <pubDate>Sat, 02 Aug 2025 01:42:25 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>roboflow/supervision</title>
      <link>https://github.com/roboflow/supervision</link>
      <description>&lt;p&gt;We write your reusable computer vision tools. ğŸ’œ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://supervision.roboflow.com"&gt; &lt;img width="100%" src="https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529"&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://github.com/roboflow/notebooks"&gt;notebooks&lt;/a&gt; | &lt;a href="https://github.com/roboflow/inference"&gt;inference&lt;/a&gt; | &lt;a href="https://github.com/autodistill/autodistill"&gt;autodistill&lt;/a&gt; | &lt;a href="https://github.com/roboflow/multimodal-maestro"&gt;maestro&lt;/a&gt;&lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://badge.fury.io/py/supervision.svg?sanitize=true" alt="version"&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/supervision"&gt;&lt;img src="https://img.shields.io/pypi/dm/supervision" alt="downloads"&gt;&lt;/a&gt; &lt;a href="https://snyk.io/advisor/python/supervision"&gt;&lt;img src="https://snyk.io/advisor/python/supervision/badge.svg?sanitize=true" alt="snyk"&gt;&lt;/a&gt; &lt;a href="https://github.com/roboflow/supervision/raw/main/LICENSE.md"&gt;&lt;img src="https://img.shields.io/pypi/l/supervision" alt="license"&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/supervision" alt="python-version"&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="colab"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/Roboflow/Annotators"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="gradio"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/GbfgXGJ8Bk"&gt;&lt;img src="https://img.shields.io/discord/1159501506232451173?logo=discord&amp;amp;label=discord&amp;amp;labelColor=fff&amp;amp;color=5865f2&amp;amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk" alt="discord"&gt;&lt;/a&gt; &lt;a href="https://squidfunk.github.io/mkdocs-material/"&gt;&lt;img src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white" alt="built-with-material-for-mkdocs"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/124" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/124" alt="roboflow%2Fsupervision | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ‘‹ hello&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ğŸ¤&lt;/p&gt; 
&lt;h2&gt;ğŸ’» install&lt;/h2&gt; 
&lt;p&gt;Pip install the supervision package in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.9&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install supervision
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href="https://roboflow.github.io/supervision/"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ”¥ quickstart&lt;/h2&gt; 
&lt;h3&gt;models&lt;/h3&gt; 
&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href="https://supervision.roboflow.com/latest/detection/core/#detections"&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO("yolov8s.pt")
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ more model connectors&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href="https://github.com/roboflow/inference"&gt;Inference&lt;/a&gt; requires a &lt;a href="https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key"&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from inference import get_model

image = cv2.imread(...)
model = get_model(model_id="yolov8s-640", api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;annotators&lt;/h3&gt; 
&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href="https://supervision.roboflow.com/latest/detection/annotators/"&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce"&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;datasets&lt;/h3&gt; 
&lt;p&gt;Supervision provides a set of &lt;a href="https://supervision.roboflow.com/latest/datasets/core/"&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&amp;lt;WORKSPACE_ID&amp;gt;).project(&amp;lt;PROJECT_ID&amp;gt;)
dataset = project.version(&amp;lt;PROJECT_VERSION&amp;gt;).download("coco")

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f"{dataset.location}/train",
    annotations_path=f"{dataset.location}/train/_annotations.coco.json",
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
&lt;/code&gt;&lt;/pre&gt; 
&lt;details close&gt; 
 &lt;summary&gt;ğŸ‘‰ more dataset utils&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
# (700, 150, 150)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;ds_1 = sv.DetectionDataset(...)
len(ds_1)
# 100
ds_1.classes
# ['dog', 'person']

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
# ['cat']

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
# 300
ds_merged.classes
# ['cat', 'dog', 'person']
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ¬ tutorials&lt;/h2&gt; 
&lt;p&gt;Want to learn how to use Supervision? Explore our &lt;a href="https://supervision.roboflow.com/develop/how_to/detect_and_annotate/"&gt;how-to guides&lt;/a&gt;, &lt;a href="https://github.com/roboflow/supervision/tree/develop/examples"&gt;end-to-end examples&lt;/a&gt;, &lt;a href="https://roboflow.github.io/cheatsheet-supervision/"&gt;cheatsheet&lt;/a&gt;, and &lt;a href="https://supervision.roboflow.com/develop/cookbooks/"&gt;cookbooks&lt;/a&gt;!&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1" alt="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.
&lt;p&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91" alt="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ’œ built with supervision&lt;/h2&gt; 
&lt;p&gt;Did you build something cool using supervision? &lt;a href="https://github.com/roboflow/supervision/discussions/categories/built-with-supervision"&gt;Let us know!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4"&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900"&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f"&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“š documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://roboflow.github.io/supervision"&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; 
&lt;h2&gt;ğŸ† contribution&lt;/h2&gt; 
&lt;p&gt;We love your input! Please see our &lt;a href="https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started. Thank you ğŸ™ to all our contributors!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/roboflow/supervision/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=roboflow/supervision"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://youtube.com/roboflow"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://www.linkedin.com/company/roboflow-ai/"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://docs.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://discuss.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584" width="3%"&gt; &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; &lt;/a&gt;
  &lt;a href="https://blog.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605" width="3%"&gt; &lt;/a&gt;  
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>QwenLM/Qwen3-Coder</title>
      <link>https://github.com/QwenLM/Qwen3-Coder</link>
      <description>&lt;p&gt;Qwen3-Coder is the code version of Qwen3, the large language model series developed by Qwen team, Alibaba Cloud.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3_coder.png" width="400"&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3-coder-main.jpg" width="800"&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; ğŸ’œ &lt;a href="https://chat.qwenlm.ai/"&gt;&lt;b&gt;Qwen Chat&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ğŸ¤— &lt;a href="https://huggingface.co/collections/Qwen/qwen3-coder-687fc861e53c939e52d52d10"&gt;Hugging Face&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ğŸ¤– &lt;a href="https://modelscope.cn/organization/qwen"&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; ğŸ“‘ &lt;a href="https://qwenlm.github.io/blog/qwen3-coder"&gt;Blog&lt;/a&gt; &amp;nbsp;&amp;nbsp; ï½œ &amp;nbsp;&amp;nbsp;ğŸ“– &lt;a href="https://qwen.readthedocs.io/"&gt;Documentation&lt;/a&gt; &lt;br&gt; &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; ğŸŒ &lt;a href="https://huggingface.co/spaces/Qwen/Qwen3-Coder-WebDev"&gt;WebDev&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ğŸ’¬ &lt;a href="https://github.com/QwenLM/Qwen/raw/main/assets/wechat.png"&gt;WeChat (å¾®ä¿¡)&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ğŸ«¨ &lt;a href="https://discord.gg/CV4E9rpNSD"&gt; Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; ğŸ“„ &lt;a href="https://arxiv.org/abs/2505.09388"&gt;Arxiv&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; ğŸ‘½ &lt;a href="https://github.com/QwenLM/qwen-code"&gt;Qwen Code&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Visit our Hugging Face or ModelScope organization (click links above), search checkpoints with names starting with &lt;code&gt;Qwen3-Coder-&lt;/code&gt;, and you will find all you need! Enjoy!&lt;/p&gt; 
&lt;h1&gt;Latest News&lt;/h1&gt; 
&lt;p&gt;ğŸ”¥ğŸ”¥ğŸ”¥ Qwen3-Coder-30B-A3B-Instruct has been released, for more information &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct/tree/main"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Qwen3-Coder: Agentic Coding in the World.&lt;/h1&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Today, we're announcing Qwen3-Coder, our most agentic code model to date. &lt;strong&gt;Qwen3-Coder&lt;/strong&gt; is available in multiple sizes, but we're excited to introduce its most powerful variant first: &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt; â€” a 480B-parameter Mixture-of-Experts model with 35B active parameters, offering exceptional performance in both coding and agentic tasks. &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt; sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet.&lt;/p&gt; 
&lt;p&gt;ğŸ’» &lt;strong&gt;Significant Performance&lt;/strong&gt;: among open models on &lt;strong&gt;Agentic Coding&lt;/strong&gt;, &lt;strong&gt;Agentic Browser-Use&lt;/strong&gt;, and other foundational coding tasks, achieving results comparable to Claude Sonnet;&lt;/p&gt; 
&lt;p&gt;ğŸ“š &lt;strong&gt;Long-context Capabilities&lt;/strong&gt;: with native support for &lt;strong&gt;256K&lt;/strong&gt; tokens, extendable up to &lt;strong&gt;1M&lt;/strong&gt; tokens using Yarn, optimized for repository-scale understanding;&lt;/p&gt; 
&lt;p&gt;ğŸ›  &lt;strong&gt;Agentic Coding&lt;/strong&gt;: supporting for most platform such as &lt;strong&gt;Qwen Code&lt;/strong&gt;, &lt;strong&gt;CLINE&lt;/strong&gt;, featuring a specially designed function call format;&lt;/p&gt; 
&lt;h2&gt;Basic information&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;âœ¨ Supporting long context understanding and generation with the context length of 256K tokens;&lt;/li&gt; 
 &lt;li&gt;âœ¨ Supporting 358 coding languages;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;['ABAP', 'ActionScript', 'Ada', 'Agda', 'Alloy', 'ApacheConf', 'AppleScript', 'Arc', 'Arduino', 'AsciiDoc', 'AspectJ', 'Assembly', 'Augeas', 'AutoHotkey', 'AutoIt', 'Awk', 'Batchfile', 'Befunge', 'Bison', 'BitBake', 'BlitzBasic', 'BlitzMax', 'Bluespec', 'Boo', 'Brainfuck', 'Brightscript', 'Bro', 'C', 'C#', 'C++', 'C2hs Haskell', 'CLIPS', 'CMake', 'COBOL', 'CSS', 'CSV', "Cap'n Proto", 'CartoCSS', 'Ceylon', 'Chapel', 'ChucK', 'Cirru', 'Clarion', 'Clean', 'Click', 'Clojure', 'CoffeeScript', 'ColdFusion', 'ColdFusion CFC', 'Common Lisp', 'Component Pascal', 'Coq', 'Creole', 'Crystal', 'Csound', 'Cucumber', 'Cuda', 'Cycript', 'Cython', 'D', 'DIGITAL Command Language', 'DM', 'DNS Zone', 'Darcs Patch', 'Dart', 'Diff', 'Dockerfile', 'Dogescript', 'Dylan', 'E', 'ECL', 'Eagle', 'Ecere Projects', 'Eiffel', 'Elixir', 'Elm', 'Emacs Lisp', 'EmberScript', 'Erlang', 'F#', 'FLUX', 'FORTRAN', 'Factor', 'Fancy', 'Fantom', 'Forth', 'FreeMarker', 'G-code', 'GAMS', 'GAP', 'GAS', 'GDScript', 'GLSL', 'Genshi', 'Gentoo Ebuild', 'Gentoo Eclass', 'Gettext Catalog', 'Glyph', 'Gnuplot', 'Go', 'Golo', 'Gosu', 'Grace', 'Gradle', 'Grammatical Framework', 'GraphQL', 'Graphviz (DOT)', 'Groff', 'Groovy', 'Groovy Server Pages', 'HCL', 'HLSL', 'HTML', 'HTML+Django', 'HTML+EEX', 'HTML+ERB', 'HTML+PHP', 'HTTP', 'Haml', 'Handlebars', 'Harbour', 'Haskell', 'Haxe', 'Hy', 'IDL', 'IGOR Pro', 'INI', 'IRC log', 'Idris', 'Inform 7', 'Inno Setup', 'Io', 'Ioke', 'Isabelle', 'J', 'JFlex', 'JSON', 'JSON5', 'JSONLD', 'JSONiq', 'JSX', 'Jade', 'Jasmin', 'Java', 'Java Server Pages', 'JavaScript', 'Julia', 'Jupyter Notebook', 'KRL', 'KiCad', 'Kit', 'Kotlin', 'LFE', 'LLVM', 'LOLCODE', 'LSL', 'LabVIEW', 'Lasso', 'Latte', 'Lean', 'Less', 'Lex', 'LilyPond', 'Linker Script', 'Liquid', 'Literate Agda', 'Literate CoffeeScript', 'Literate Haskell', 'LiveScript', 'Logos', 'Logtalk', 'LookML', 'Lua', 'M', 'M4', 'MAXScript', 'MTML', 'MUF', 'Makefile', 'Mako', 'Maple', 'Markdown', 'Mask', 'Mathematica', 'Matlab', 'Max', 'MediaWiki', 'Metal', 'MiniD', 'Mirah', 'Modelica', 'Module Management System', 'Monkey', 'MoonScript', 'Myghty', 'NSIS', 'NetLinx', 'NetLogo', 'Nginx', 'Nimrod', 'Ninja', 'Nit', 'Nix', 'Nu', 'NumPy', 'OCaml', 'ObjDump', 'Objective-C++', 'Objective-J', 'Octave', 'Omgrofl', 'Opa', 'Opal', 'OpenCL', 'OpenEdge ABL', 'OpenSCAD', 'Org', 'Ox', 'Oxygene', 'Oz', 'PAWN', 'PHP', 'POV-Ray SDL', 'Pan', 'Papyrus', 'Parrot', 'Parrot Assembly', 'Parrot Internal Representation', 'Pascal', 'Perl', 'Perl6', 'Pickle', 'PigLatin', 'Pike', 'Pod', 'PogoScript', 'Pony', 'PostScript', 'PowerShell', 'Processing', 'Prolog', 'Propeller Spin', 'Protocol Buffer', 'Public Key', 'Pure Data', 'PureBasic', 'PureScript', 'Python', 'Python traceback', 'QML', 'QMake', 'R', 'RAML', 'RDoc', 'REALbasic', 'RHTML', 'RMarkdown', 'Racket', 'Ragel in Ruby Host', 'Raw token data', 'Rebol', 'Red', 'Redcode', "Ren'Py", 'RenderScript', 'RobotFramework', 'Rouge', 'Ruby', 'Rust', 'SAS', 'SCSS', 'SMT', 'SPARQL', 'SQF', 'SQL', 'STON', 'SVG', 'Sage', 'SaltStack', 'Sass', 'Scala', 'Scaml', 'Scheme', 'Scilab', 'Self', 'Shell', 'ShellSession', 'Shen', 'Slash', 'Slim', 'Smali', 'Smalltalk', 'Smarty', 'Solidity', 'SourcePawn', 'Squirrel', 'Stan', 'Standard ML', 'Stata', 'Stylus', 'SuperCollider', 'Swift', 'SystemVerilog', 'TOML', 'TXL', 'Tcl', 'Tcsh', 'TeX', 'Tea', 'Text', 'Textile', 'Thrift', 'Turing', 'Turtle', 'Twig', 'TypeScript', 'Unified Parallel C', 'Unity3D Asset', 'Uno', 'UnrealScript', 'UrWeb', 'VCL', 'VHDL', 'Vala', 'Verilog', 'VimL', 'Visual Basic', 'Volt', 'Vue', 'Web Ontology Language', 'WebAssembly', 'WebIDL', 'X10', 'XC', 'XML', 'XPages', 'XProc', 'XQuery', 'XS', 'XSLT', 'Xojo', 'Xtend', 'YAML', 'YANG', 'Yacc', 'Zephir', 'Zig', 'Zimpl', 'desktop', 'eC', 'edn', 'fish', 'mupad', 'nesC', 'ooc', 'reStructuredText', 'wisp', 'xBase']
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;âœ¨ Retain strengths in math and general capabilities from base model.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important]&lt;/p&gt; 
 &lt;p&gt;Qwen3-coder function calling relies on our new tool parser &lt;code&gt;qwen3coder_tool_parser.py&lt;/code&gt; &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct/blob/main/qwen3coder_tool_parser.py"&gt;here&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;We updated both the special tokens and their corresponding token ids, in order to maintain consistency with Qwen3. Please make sure to use the new tokenizer.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;model name&lt;/th&gt; 
   &lt;th&gt;type&lt;/th&gt; 
   &lt;th&gt;length&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/td&gt; 
   &lt;td&gt;instruct&lt;/td&gt; 
   &lt;td&gt;256k&lt;/td&gt; 
   &lt;td&gt;ğŸ¤— &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct"&gt;Hugging Face&lt;/a&gt; â€¢ ğŸ¤– &lt;a href="https://modelscope.cn/models/Qwen/Qwen3-Coder-480B-A35B-Instruct"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qwen3-Coder-480B-A35B-Instruct-FP8&lt;/td&gt; 
   &lt;td&gt;instruct&lt;/td&gt; 
   &lt;td&gt;256k&lt;/td&gt; 
   &lt;td&gt;ğŸ¤— &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"&gt;Hugging Face&lt;/a&gt; â€¢ ğŸ¤– &lt;a href="https://modelscope.cn/models/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qwen3-Coder-30B-A3B-Instruct&lt;/td&gt; 
   &lt;td&gt;instruct&lt;/td&gt; 
   &lt;td&gt;256k&lt;/td&gt; 
   &lt;td&gt;ğŸ¤— &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"&gt;Hugging Face&lt;/a&gt; â€¢ ğŸ¤– &lt;a href="https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qwen3-Coder-30B-A3B-Instruct-FP8&lt;/td&gt; 
   &lt;td&gt;instruct&lt;/td&gt; 
   &lt;td&gt;256k&lt;/td&gt; 
   &lt;td&gt;ğŸ¤— &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8"&gt;Hugging Face&lt;/a&gt; â€¢ ğŸ¤– &lt;a href="https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Detailed performance and introduction are shown in this &lt;a href="https://qwenlm.github.io/blog/qwen3-coder"&gt; ğŸ“‘ blog&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt; are instruction models for chatting;&lt;/p&gt; 
 &lt;p&gt;This model supports only non-thinking mode and does not generate &lt;code&gt;&amp;lt;think&amp;gt;&amp;lt;/think&amp;gt;&lt;/code&gt; blocks in its output. Meanwhile, specifying &lt;code&gt;enable_thinking=False&lt;/code&gt; is no longer required.**&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ğŸ‘‰ğŸ» Chat with Qwen3-Coder&lt;/h3&gt; 
&lt;p&gt;You can just write several lines of code with &lt;code&gt;transformers&lt;/code&gt; to chat with Qwen3-Coder-480B-A35B-Instruct. Essentially, we build the tokenizer and the model with &lt;code&gt;from_pretrained&lt;/code&gt; method, and we use generate method to perform chatting with the help of chat template provided by the tokenizer. Below is an example of how to chat with &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen3-Coder-480B-A35B-Instruct"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = "write a quick sort algorithm."
messages = [
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=65536
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;apply_chat_template()&lt;/code&gt; function is used to convert the messages into a format that the model can understand. The &lt;code&gt;add_generation_prompt&lt;/code&gt; argument is used to add a generation prompt, which refers to &lt;code&gt;&amp;lt;|im_start|&amp;gt;assistant\n&lt;/code&gt; to the input. Notably, we apply ChatML template for chat models following our previous practice. The &lt;code&gt;max_new_tokens&lt;/code&gt; argument is used to set the maximum length of the response. The &lt;code&gt;tokenizer.batch_decode()&lt;/code&gt; function is used to decode the response. In terms of the input, the above messages is an example to show how to format your dialog history and system prompt. You can use the other size of instruct model in the same way.&lt;/p&gt; 
&lt;h4&gt;Fill in the middle with Qwen3-Coder&lt;/h4&gt; 
&lt;p&gt;The code insertion task, also referred to as the "fill-in-the-middle" challenge, requires the insertion of code segments in a manner that bridges the gaps within a given code context. For an approach aligned with best practices, we recommend adhering to the formatting guidelines outlined in the paper "Efficient Training of Language Models to Fill in the Middle"[&lt;a href="https://arxiv.org/abs/2207.14255"&gt;arxiv&lt;/a&gt;].&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] It should be noted that FIM is supported in every version of Qwen3-Coder. Qwen3-Coder-480B-A35B-Instruct is shown here as an example.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The prompt should be structured as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;prompt = '&amp;lt;|fim_prefix|&amp;gt;' + prefix_code + '&amp;lt;|fim_suffix|&amp;gt;' + suffix_code + '&amp;lt;|fim_middle|&amp;gt;'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Following the approach mentioned, an example would be structured in this manner:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from transformers import AutoTokenizer, AutoModelForCausalLM
# load model
device = "cuda" # the device to load the model onto

TOKENIZER = AutoTokenizer.from_pretrained("Qwen/Qwen3-Coder-480B-A35B-Instruct")
MODEL = AutoModelForCausalLM.from_pretrained("Qwen/Qwen3-Coder-480B-A35B-Instruct", device_map="auto").eval()


input_text = """&amp;lt;|fim_prefix|&amp;gt;def quicksort(arr):
    if len(arr) &amp;lt;= 1:
        return arr
    pivot = arr[len(arr) // 2]
    &amp;lt;|fim_suffix|&amp;gt;
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x &amp;gt; pivot]
    return quicksort(left) + middle + quicksort(right)&amp;lt;|fim_middle|&amp;gt;"""
            
messages = [
    {"role": "system", "content": "You are a code completion assistant."},
    {"role": "user", "content": input_text}
]


text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = TOKENIZER([text], return_tensors="pt").to(model.device)

# Use `max_new_tokens` to control the maximum output length.
eos_token_ids = [151659, 151661, 151662, 151663, 151664, 151643, 151645]
generated_ids = MODEL.generate(model_inputs.input_ids, max_new_tokens=512, do_sample=False, eos_token_id=eos_token_ids)[0]
# The generated_ids include prompt_ids, we only need to decode the tokens after prompt_ids.
output_text = TOKENIZER.decode(generated_ids[len(model_inputs.input_ids[0]):], skip_special_tokens=True)

print(f"Prompt: {input_text}\n\nGenerated text: {output_text}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Use Cases&lt;/h2&gt; 
&lt;h3&gt;Example: Physics-Based Chimney Demolition Simulation with Controlled Explosion&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Prompt with Qwen Chat Web Dev &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;ä½¿ç”¨ three.js, cannon-es.js ç”Ÿæˆä¸€ä¸ªéœ‡æ’¼çš„3Då»ºç­‘æ‹†é™¤æ¼”ç¤ºã€‚

## åœºæ™¯è®¾ç½®ï¼š
- åœ°é¢æ˜¯ä¸€ä¸ªæ·±ç°è‰²æ··å‡åœŸå¹³é¢ï¼Œå°ºå¯¸80*80ï¼Œ
- æ‰€æœ‰ç‰©ä½“ä¸¥æ ¼éµå¾ªç°å®ç‰©ç†è§„åˆ™ï¼ŒåŒ…æ‹¬é‡åŠ›ã€æ‘©æ“¦åŠ›ã€ç¢°æ’æ£€æµ‹å’ŒåŠ¨é‡å®ˆæ’

## å»ºç­‘ç»“æ„ï¼š
- ä¸€åº§åœ†å½¢é«˜å±‚å»ºç­‘ï¼Œå‘¨é•¿å¯¹åº”20ä¸ªæ–¹å—
- å»ºç­‘æ€»é«˜åº¦60ä¸ªæ–¹å—
- æ¯å±‚é‡‡ç”¨ç –ç Œç»“æ„ï¼Œæ–¹å—ä¸ç –ç»“æ„å»ºç­‘ä¸€è‡´, é”™å¼€50%æ’åˆ—ï¼Œå¢å¼ºç»“æ„ç¨³å®šæ€§
- å»ºç­‘å¤–å¢™ä½¿ç”¨ç±³è‰²æ–¹å—
- **é‡è¦ï¼šæ–¹å—åˆå§‹æ’åˆ—æ—¶å¿…é¡»ç¡®ä¿ç´§å¯†è´´åˆï¼Œæ— é—´éš™ï¼Œå¯ä»¥é€šè¿‡è½»å¾®é‡å æˆ–è°ƒæ•´åŠå¾„æ¥å®ç°**
- **é‡è¦ï¼šå»ºç­‘åˆå§‹åŒ–å®Œæˆåï¼Œæ‰€æœ‰æ–¹å—åº”è¯¥å¤„äºç‰©ç†"ç¡çœ "çŠ¶æ€ï¼Œç¡®ä¿å»ºç­‘åœ¨çˆ†ç‚¸å‰ä¿æŒå®Œç¾çš„é™æ­¢çŠ¶æ€ï¼Œä¸ä¼šå› é‡åŠ›è€Œä¸‹æ²‰æˆ–æ¾æ•£**
- å»ºç­‘ç –å—ä¹‹é—´ä½¿ç”¨ç²˜æ€§ææ–™å¡«å……ï¼ˆä¸å¯è§ï¼‰ï¼Œé€šè¿‡é«˜æ‘©æ“¦åŠ›ï¼ˆ0.8+ï¼‰å’Œä½å¼¹æ€§ï¼ˆ0.05ä»¥ä¸‹ï¼‰æ¥æ¨¡æ‹Ÿç²˜åˆæ•ˆæœ
- ç –å—åœ¨å»ºç­‘å€’å¡Œç¬é—´ä¸ä¼šæ•£æ‰ï¼Œè€Œæ˜¯å»ºç­‘ä½œä¸ºä¸€ä¸ªæ•´ä½“å€’åœ¨åœ°é¢çš„æ—¶å€™æ‰å› å—åŠ›è¿‡å¤§è€Œæ•£æ‰

## å®šå‘çˆ†ç ´ç³»ç»Ÿï¼š
- åœ¨å»ºç­‘çš„ç¬¬1å±‚çš„æœ€å³ä¾§æ–¹å—é™„è¿‘å®‰è£…çˆ†ç‚¸è£…ç½®ï¼ˆä¸å¯è§ï¼‰
- æä¾›æ“ä½œæŒ‰é’®ç‚¹å‡»çˆ†ç‚¸
- **çˆ†ç‚¸æ—¶å”¤é†’æ‰€æœ‰ç›¸å…³æ–¹å—çš„ç‰©ç†çŠ¶æ€**
- çˆ†ç‚¸ç‚¹äº§ç”ŸåŠå¾„2çš„å¼ºåŠ›å†²å‡»æ³¢ï¼Œå†²å‡»æ³¢å½±å“åˆ°çš„æ–¹å—, å—åˆ°2-5å•ä½çš„å†²å‡»åŠ›

## å»ºç­‘ç¨³å®šæ€§è¦æ±‚ï¼š
- **ç¡®ä¿å»ºç­‘åœ¨æœªçˆ†ç‚¸æ—¶å®Œå…¨é™æ­¢ï¼Œæ— ä»»ä½•æ™ƒåŠ¨æˆ–ä¸‹æ²‰**
- **ç‰©ç†ä¸–ç•Œåˆå§‹åŒ–åç»™å»ºç­‘å‡ ä¸ªç‰©ç†æ­¥éª¤æ¥è‡ªç„¶ç¨³å®šï¼Œæˆ–ä½¿ç”¨ç¡çœ æœºåˆ¶**
- **æ–¹å—é—´çš„æ¥è§¦ææ–™åº”å…·æœ‰é«˜æ‘©æ“¦åŠ›å’Œæä½å¼¹æ€§ï¼Œæ¨¡æ‹Ÿç –å—é—´çš„ç ‚æµ†ç²˜åˆ**

## éœ‡æ’¼çš„å€’å¡Œæ•ˆæœï¼š
- æ–¹å—åœ¨çˆ†ç‚¸å†²å‡»ä¸‹ä¸ä»…é£æ•£ï¼Œè¿˜ä¼šåœ¨ç©ºä¸­ç¿»æ»šå’Œç¢°æ’
- çƒŸå°˜ä¼šéšç€å»ºç­‘å€’å¡Œé€æ¸æ‰©æ•£ï¼Œè¥é€ çœŸå®çš„æ‹†é™¤ç°åœºæ°›å›´

## å¢å¼ºçš„è§†è§‰æ•ˆæœï¼š
- æ·»åŠ ç¯å¢ƒå…‰ç…§å˜åŒ–ï¼šçˆ†ç‚¸ç¬é—´äº®åº¦æ¿€å¢ï¼Œç„¶åè¢«çƒŸå°˜é®æŒ¡å˜æš—
- ç²’å­ç³»ç»ŸåŒ…æ‹¬ï¼šçƒŸé›¾ã€ç°å°˜

## æŠ€æœ¯è¦æ±‚ï¼š
- ç²’å­ç³»ç»Ÿç”¨äºçƒŸé›¾å’Œç°å°˜æ•ˆæœ
- æ‰€æœ‰ä»£ç é›†æˆåœ¨å•ä¸ªHTMLæ–‡ä»¶ä¸­ï¼ŒåŒ…å«å¿…è¦çš„CSSæ ·å¼
- æ·»åŠ ç®€å•çš„UIæ§åˆ¶ï¼šé‡ç½®æŒ‰é’®ã€ç›¸æœºè§’åº¦åˆ‡æ¢, çˆ†ç‚¸æŒ‰é’®, é¼ æ ‡å·¦é”®æ§åˆ¶æ‘„åƒæœºè§’åº¦ï¼Œå³é”®æ§åˆ¶æ‘„åƒæœºä½ç½®ï¼Œæ»šè½®æ§åˆ¶æ‘„åƒæœºç„¦è·
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo1.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example1.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: Multicolor and Interactive Animation&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Prompt with Cline [act mode] &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;Create an amazing animation multicolor and interactive using p5js

use this cdn:
https://cdn.jsdelivr.net/npm/p5@1.7.0/lib/p5.min.js
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo2.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example2.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: 3D Google Earth&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Prompt with Qwen Chat Web Dev &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;To create a 3D Google Earth, you need to load the terrain map correctly. You can use any online resource. The code is written into an HTML file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo3.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example3.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: Testing Your WPM with a Famous Quote&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt with Qwen-Code CLI &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;Create an interesting typing game with a keyboard in the lower middle of the screen and some famous articles in the upper middle. When the user types a word correctly, a cool reaction should be given to encourage him. Design a modern soft color scheme inspired by macarons. Come up with a very creative solution first, and then start writing code.
The game should be able to support typing, and you need to neglect upcase and lowercase.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo4.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example4.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: Bouncing Ball in Rotation Hypercube&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt with Qwen Chat Web Dev &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;Make a page in HTML that shows an animation of a ball bouncing in a rotating hypercube
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo5.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example5.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: Solar System Simulation&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt with Cline [act mode] &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;write a web page to show the solar system simulation
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo6.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example6.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: DUET Game&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt with Cline [act mode] &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;Create a complete, single-file HTML game with CSS and JavaScript. The game is inspired by "Duet".

Gameplay:

There are two balls, one red and one blue, rotating around a central point.
The player uses the 'A' and 'D' keys to rotate them counter-clockwise and clockwise.
White rectangular obstacles move down from the top of the screen.
The player must rotate the balls to avoid hitting the obstacles.
If a ball hits an obstacle, the game is over.
Visuals:

Make the visual effects amazing.
Use a dark background with neon glowing effects for the balls and obstacles.
Animations should be very smooth.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo7.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example7.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#QwenLM/Qwen3-Coder&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=QwenLM/Qwen3-Coder&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our work helpful, feel free to give us a cite.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{qwen3technicalreport,
      title={Qwen3 Technical Report}, 
      author={Qwen Team},
      year={2025},
      eprint={2505.09388},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.09388},
}
@article{hui2024qwen2,
  title={Qwen2. 5-Coder Technical Report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},
  journal={arXiv preprint arXiv:2409.12186},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;p&gt;If you are interested to leave a message to either our research team or product team, join our &lt;a href="https://discord.gg/z3GAxXZ9Ce"&gt;Discord&lt;/a&gt; or &lt;a href="https://github.com/QwenLM/Qwen/raw/main/assets/wechat.png"&gt;WeChat groups&lt;/a&gt;!&lt;/p&gt; 
&lt;p align="right" style="font-size: 14px; color: #555; margin-top: 20px;"&gt; &lt;a href="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;"&gt; â†‘ Back to Top â†‘ &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kijai/ComfyUI-WanVideoWrapper</title>
      <link>https://github.com/kijai/ComfyUI-WanVideoWrapper</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI wrapper nodes for &lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;WanVideo&lt;/a&gt; and related models.&lt;/h1&gt; 
&lt;h1&gt;WORK IN PROGRESS (perpetually)&lt;/h1&gt; 
&lt;h1&gt;Why should I use custom nodes when WanVideo works natively?&lt;/h1&gt; 
&lt;p&gt;Short answer: Unless it's a model/feature not available yet on native, you shouldn't.&lt;/p&gt; 
&lt;p&gt;Long answer: Due to the complexity of ComfyUI core code, and my lack of coding experience, in many cases it's far easier and faster to implement new models and features to a standalone wrapper, so this is a way to test things relatively quickly. I consider this my personal sandbox (which is obviously open for everyone) to play with without having to worry about compability issues etc, but as such this code is always work in progress and prone to have issues. Also not all new models end up being worth the trouble to implement in core Comfy, though I've also made some patcher nodes to allow using them in native workflows, such as the &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;ATI&lt;/a&gt; node available in this wrapper. This is also the end goal, idea isn't to compete or even offer alternatives to everything available in native workflows. All that said (this is clearly not a sales pitch) I do appreciate everyone using these nodes to explore new releases and possibilities with WanVideo.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repo into &lt;code&gt;custom_nodes&lt;/code&gt; folder.&lt;/li&gt; 
 &lt;li&gt;Install dependencies: &lt;code&gt;pip install -r requirements.txt&lt;/code&gt; or if you use the portable install, run this in ComfyUI_windows_portable -folder:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-WanVideoWrapper\requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Models&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy/tree/main"&gt;https://huggingface.co/Kijai/WanVideo_comfy/tree/main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;fp8 scaled models (personal recommendation):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled"&gt;https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Text encoders to &lt;code&gt;ComfyUI/models/text_encoders&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Clip vision to &lt;code&gt;ComfyUI/models/clip_vision&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Transformer (main video model) to &lt;code&gt;ComfyUI/models/diffusion_models&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Vae to &lt;code&gt;ComfyUI/models/vae&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can also use the native ComfyUI text encoding and clip vision loader with the wrapper instead of the original models:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/6a2fd9a5-8163-4c93-b362-92ef34dbd3a4" alt="image"&gt;&lt;/p&gt; 
&lt;p&gt;GGUF models can now be loaded in the main model loader as well.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Supported extra models:&lt;/p&gt; 
&lt;p&gt;SkyReels: &lt;a href="https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9"&gt;https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WanVideoFun: &lt;a href="https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17"&gt;https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ReCamMaster: &lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;https://github.com/KwaiVGI/ReCamMaster&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;VACE: &lt;a href="https://github.com/ali-vilab/VACE"&gt;https://github.com/ali-vilab/VACE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Phantom: &lt;a href="https://huggingface.co/bytedance-research/Phantom"&gt;https://huggingface.co/bytedance-research/Phantom&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ATI: &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;https://huggingface.co/bytedance-research/ATI&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Uni3C: &lt;a href="https://github.com/alibaba-damo-academy/Uni3C"&gt;https://github.com/alibaba-damo-academy/Uni3C&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MiniMaxRemover: &lt;a href="https://huggingface.co/zibojia/minimax-remover"&gt;https://huggingface.co/zibojia/minimax-remover&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MAGREF: &lt;a href="https://huggingface.co/MAGREF-Video/MAGREF"&gt;https://huggingface.co/MAGREF-Video/MAGREF&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;FantasyTalking: &lt;a href="https://github.com/Fantasy-AMAP/fantasy-talking"&gt;https://github.com/Fantasy-AMAP/fantasy-talking&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MultiTalk: &lt;a href="https://github.com/MeiGen-AI/MultiTalk"&gt;https://github.com/MeiGen-AI/MultiTalk&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;EchoShot: &lt;a href="https://github.com/D2I-ai/EchoShot"&gt;https://github.com/D2I-ai/EchoShot&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Examples:&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;ReCamMaster&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e"&gt;https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;TeaCache (with the old temporary WIP naive version, I2V):&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that with the new version the threshold values should be 10x higher&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Range of 0.25-0.30 seems good when using the coefficients, start step can be 0, with more aggressive threshold values it may make sense to start later to avoid any potential step skips early on, that generally ruin the motion.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46"&gt;https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Context window test:&lt;/p&gt; 
&lt;p&gt;1025 frames using window size of 81 frames, with 16 overlap. With the 1.3B T2V model this used under 5GB VRAM and took 10 minutes to gen on a 5090:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e"&gt;https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;This very first test was 512x512x81&lt;/p&gt; 
&lt;p&gt;~16GB used with 20/40 blocks offloaded&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f"&gt;https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Vid2vid example:&lt;/p&gt; 
&lt;p&gt;with 14B T2V model:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8"&gt;https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;with 1.3B T2V model&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e"&gt;https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>frappe/hrms</title>
      <link>https://github.com/frappe/hrms</link>
      <description>&lt;p&gt;Open Source HR and Payroll Software&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt; &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/frappe-hr-logo.png" height="80px" width="80px" alt="Frappe HR Logo"&gt; &lt;/a&gt; 
 &lt;h2&gt;Frappe HR&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;Open Source, modern, and easy-to-use HR and Payroll Software&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/frappe/hrms/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/frappe/hrms/actions/workflows/ci.yml/badge.svg?branch=develop" alt="CI"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/frappe/hrms"&gt;&lt;img src="https://codecov.io/gh/frappe/hrms/branch/develop/graph/badge.svg?token=0TwvyUg3I5" alt="codecov"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/10972" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10972" alt="frappe%2Fhrms | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-hero.png"&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt;Website&lt;/a&gt; - 
 &lt;a href="https://docs.frappe.io/hr/introduction"&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Frappe HR&lt;/h2&gt; 
&lt;p&gt;Frappe HR has everything you need to drive excellence within the company. It's a complete HRMS solution with over 13 different modules right from Employee Management, Onboarding, Leaves, to Payroll, Taxation, and more!&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;When Frappe team started growing in terms of size, we needed an open-source HR and Payroll software. We didn't find any "true" open-source HR software out there and so decided to build one ourselves. Initially, it was a set of modules within ERPNext but version 14 onwards, as the modules became more mature, Frappe HR was created as a separate product.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Employee Lifecycle&lt;/strong&gt;: From onboarding employees, managing promotions and transfers, all the way to documenting feedback with exit interviews, make life easier for employees throughout their life cycle.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leave and Attendance&lt;/strong&gt;: Configure leave policies, pull regional holidays with a click, check-in and check-out with geolocation capturing, track leave balances and attendance with reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expense Claims and Advances&lt;/strong&gt;: Manage employee advances, claim expenses, configure multi-level approval workflows, all this with seamless integration with ERPNext accounting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Management&lt;/strong&gt;: Track goals, align goals with key result areas (KRAs), enable employees to evaluate themselves, make managing appraisal cycles easy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Payroll &amp;amp; Taxation&lt;/strong&gt;: Create salary structures, configure income tax slabs, run standard payroll, accomodate additional salaries and off cycle payments, view income breakup on salary slips and so much more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frappe HR Mobile App&lt;/strong&gt;: Apply for and approve leaves on the go, check-in and check-out, access employee profile right from the mobile app.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;View Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-appraisal.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-requisition.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-attendance.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-salary.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-pwa.png"&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe"&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe-ui"&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href="https://frappecloud.com"&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href="https://github.com/frappe/press"&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://frappecloud.com/hrms/signup" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/try-on-fc-white.png"&gt; 
   &lt;img src="https://frappe.io/files/try-on-fc-black.png" alt="Try on Frappe Cloud" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Development setup&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;You need Docker, docker-compose and git setup on your machine. Refer &lt;a href="https://docs.docker.com/"&gt;Docker documentation&lt;/a&gt;. After that, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/hrms
cd hrms/docker
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for some time until the setup script creates a site. After that you can access &lt;code&gt;http://localhost:8000&lt;/code&gt; in your browser and the login screen for HR should show up.&lt;/p&gt; 
&lt;p&gt;Use the following credentials to log in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: &lt;code&gt;Administrator&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Password: &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Set up bench by following the &lt;a href="https://frappeframework.com/docs/user/en/installation"&gt;Installation Steps&lt;/a&gt; and start the server and keep it running &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;In a separate terminal window, run the following commands &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench new-site hrms.local
$ bench get-app erpnext
$ bench get-app hrms
$ bench --site hrms.local install-app hrms
$ bench --site hrms.local add-to-hosts
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;You can access the site at &lt;code&gt;http://hrms.local:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and Community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://frappe.school"&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.frappe.io/hr"&gt;Documentation&lt;/a&gt; - Extensive documentation for Frappe HR.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.erpnext.com/"&gt;User Forum&lt;/a&gt; - Engage with the community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/frappehr"&gt;Telegram Group&lt;/a&gt; - Get instant help from the community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines"&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext.com/security"&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/frappe/hrms/develop/TRADEMARK_POLICY.md"&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;div align="center" style="padding-top: 0.75rem;"&gt; 
 &lt;a href="https://frappe.io" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/Frappe-white.png"&gt; 
   &lt;img src="https://frappe.io/files/Frappe-black.png" alt="Frappe Technologies" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>nikmcfly/ANUS</title>
      <link>https://github.com/nikmcfly/ANUS</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸ‘ Anus: Autonomous Networked Utility System&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/nikmcfly/ANUS/main/assets/anus_logo.png" alt="Anus AI Logo" width="200"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/nikmcfly/ANUS/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" alt="License: MIT"&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.11+-blue.svg?sanitize=true" alt="Python version"&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black"&gt;&lt;/a&gt; &lt;a href="https://github.com/nikmcfly/ANUS/raw/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/contributions-welcome-brightgreen.svg?sanitize=true" alt="Contributions welcome"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/nikmcfly/ANUS/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/nikmcfly/ANUS.svg?style=social&amp;amp;label=Star" alt="GitHub stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/nikmcfly/ANUS/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/nikmcfly/ANUS.svg?style=social&amp;amp;label=Fork" alt="GitHub forks"&gt;&lt;/a&gt; &lt;a href="https://github.com/nikmcfly/ANUS/issues"&gt;&lt;img src="https://img.shields.io/github/issues/nikmcfly/ANUS.svg?sanitize=true" alt="GitHub issues"&gt;&lt;/a&gt; &lt;a href="https://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true" alt="PRs Welcome"&gt;&lt;/a&gt; &lt;a href="https://anus-ai.github.io/docs"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-brightgreen.svg?sanitize=true" alt="Documentation Status"&gt;&lt;/a&gt; &lt;a href="https://t.me/goanus"&gt;&lt;img src="https://img.shields.io/badge/Telegram-blue?logo=telegram&amp;amp;logoColor=white" alt="Telegram"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-why-anus"&gt;Why Anus?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-features--capabilities"&gt;Features &amp;amp; Capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-usage-examples"&gt;Usage Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸŒŸ Introduction&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Anus&lt;/strong&gt; (Autonomous Networked Utility System) is a powerful, flexible, and accessible open-source AI agent framework designed to revolutionize task automation. Built with modern AI technologies and best practices, Anus represents the next generation of AI agent frameworks, offering unparalleled capabilities and ease of use.&lt;/p&gt; 
&lt;p&gt;Anus empowers users to create AI agents that can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute complex tasks through natural language instructions&lt;/li&gt; 
 &lt;li&gt;Collaborate in multi-agent environments to solve problems&lt;/li&gt; 
 &lt;li&gt;Interact with web services, documents, and code&lt;/li&gt; 
 &lt;li&gt;Process multimodal inputs including text, images, and audio&lt;/li&gt; 
 &lt;li&gt;Adapt to different domains and use cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Whether you're a developer looking to build AI-powered applications, a researcher exploring agent-based systems, or an enthusiast interested in the latest AI technologies, Anus provides the tools and flexibility you need to succeed.&lt;/p&gt; 
&lt;h2&gt;ğŸ’¡ Why Anus?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Truly Open Source&lt;/strong&gt;: No barriers, no invite codes, just pure open-source goodness&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid Architecture&lt;/strong&gt;: Combines single-agent simplicity with multi-agent power&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Model Support&lt;/strong&gt;: Works with OpenAI models, open-source models, or your own&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Tool Ecosystem&lt;/strong&gt;: Web automation, document processing, code execution, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community-First Design&lt;/strong&gt;: Built for contributions and extensions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transparent Operation&lt;/strong&gt;: Clear explanations of all agent actions and decisions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Platform&lt;/strong&gt;: Works across different operating systems and environments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;âœ¨ Features &amp;amp; Capabilities&lt;/h2&gt; 
&lt;h3&gt;ğŸ§  Advanced AI Agent Architecture&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid Agent System&lt;/strong&gt;: Seamlessly switch between single-agent and multi-agent modes based on task complexity&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Task Planning&lt;/strong&gt;: Sophisticated planning system that breaks down complex tasks into manageable steps&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adaptive Resource Allocation&lt;/strong&gt;: Intelligently allocates computational resources based on task requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory Management&lt;/strong&gt;: Short-term and long-term memory systems for context retention across conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Explainable Actions&lt;/strong&gt;: Transparent reasoning and decision-making processes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ¤ Multi-Agent Collaboration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Specialized Agent Roles&lt;/strong&gt;: Pre-defined roles like Researcher, Coder, Planner, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Role Creation&lt;/strong&gt;: Define your own agent roles with specific capabilities and knowledge&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Inter-Agent Communication&lt;/strong&gt;: Structured protocols for efficient agent-to-agent communication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consensus Mechanisms&lt;/strong&gt;: Collaborative decision-making through agent voting and consensus&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conflict Resolution&lt;/strong&gt;: Sophisticated protocols for resolving disagreements between agents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ› ï¸ Comprehensive Tool Ecosystem&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Web Interaction&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full browser automation via Playwright&lt;/li&gt; 
   &lt;li&gt;Web scraping and data extraction&lt;/li&gt; 
   &lt;li&gt;Form filling and submission&lt;/li&gt; 
   &lt;li&gt;Authentication handling&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Information Retrieval&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Search engine integration&lt;/li&gt; 
   &lt;li&gt;Wikipedia access&lt;/li&gt; 
   &lt;li&gt;News and current events sources&lt;/li&gt; 
   &lt;li&gt;Specialized knowledge bases&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Document Processing&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;PDF parsing and analysis&lt;/li&gt; 
   &lt;li&gt;Office document handling (Word, Excel, PowerPoint)&lt;/li&gt; 
   &lt;li&gt;Image recognition and OCR&lt;/li&gt; 
   &lt;li&gt;Data extraction and transformation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Code Execution&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Secure Python execution sandbox&lt;/li&gt; 
   &lt;li&gt;Multiple language support&lt;/li&gt; 
   &lt;li&gt;Package management&lt;/li&gt; 
   &lt;li&gt;Output capture and analysis&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multimodal Processing&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Image analysis and generation&lt;/li&gt; 
   &lt;li&gt;Audio processing and transcription&lt;/li&gt; 
   &lt;li&gt;Video analysis and summarization&lt;/li&gt; 
   &lt;li&gt;Chart and graph interpretation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ”„ Flexible Model Integration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI API Support&lt;/strong&gt;: Seamless integration with GPT-4 and newer models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open-Source Models&lt;/strong&gt;: Support for Llama, Mistral, and other open-source models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Local Deployment&lt;/strong&gt;: Run models locally for privacy and reduced costs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Switching&lt;/strong&gt;: Automatically select the appropriate model based on task requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fallback Mechanisms&lt;/strong&gt;: Gracefully handle API issues by switching to alternative models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ‘¥ User-Friendly Interfaces&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Command-Line Interface&lt;/strong&gt;: Simple and intuitive commands for terminal users&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web Interface&lt;/strong&gt;: Optional browser-based dashboard for visual interaction&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Integration&lt;/strong&gt;: RESTful API for embedding Anus in other applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversation History&lt;/strong&gt;: Review and continue previous conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task Monitoring&lt;/strong&gt;: Track progress of long-running tasks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ”’ Privacy and Security&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local Execution&lt;/strong&gt;: Process sensitive data locally without sending to external APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Key Management&lt;/strong&gt;: Secure handling of API keys and credentials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Permission System&lt;/strong&gt;: Fine-grained control over agent capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Audit Logging&lt;/strong&gt;: Comprehensive logging of all agent actions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sandboxed Execution&lt;/strong&gt;: Secure environment for running untrusted code&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ§© Extensibility&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt;: Easily extend functionality with custom plugins&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Tools&lt;/strong&gt;: Create your own tools to expand agent capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Adapters&lt;/strong&gt;: Add support for new AI models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Middleware&lt;/strong&gt;: Insert custom processing steps in the agent workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Event Hooks&lt;/strong&gt;: React to specific events in the agent lifecycle&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”§ Installation&lt;/h2&gt; 
&lt;p&gt;Anus AI supports multiple installation methods to accommodate different user preferences and environments.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.11 or higher&lt;/li&gt; 
 &lt;li&gt;pip (Python package installer)&lt;/li&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Method 1: Pip Installation (Recommended for Users)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install from PyPI
pip install anus-ai

# Verify installation
anus --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Method 2: From Source (Recommended for Developers)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/nikmcfly/ANUS.git
cd ANUS

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e .

# Verify installation
anus --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Method 3: Using Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Pull the Docker image
docker pull anusai/anus:latest

# Run Anus in a container
docker run -it anusai/anus:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Method 4: Using Conda&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a new conda environment
conda create -n anus python=3.11
conda activate anus

# Install Anus
pip install anus-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Platform-Specific Instructions&lt;/h3&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install required system dependencies
pip install windows-curses

# If using browser automation
playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;macOS&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install required system dependencies
brew install python@3.11

# If using browser automation
playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Linux&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install required system dependencies
sudo apt-get update
sudo apt-get install -y python3.11 python3.11-venv

# If using browser automation
playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Dependencies&lt;/h3&gt; 
&lt;p&gt;Anus has several optional features that require additional dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For document processing
pip install anus-ai[documents]

# For browser automation
pip install anus-ai[browser]

# For code execution
pip install anus-ai[code]

# For all optional features
pip install anus-ai[all]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;After installation, you'll need to configure Anus with your API keys:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a configuration file:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;anus init
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Edit the generated &lt;code&gt;.anus/config.yaml&lt;/code&gt; file with your API keys:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;llm:
  provider: openai
  api_key: your_openai_api_key
  model: gpt-4o

# Optional: Configure other providers
anthropic:
  api_key: your_anthropic_api_key

# Optional: Configure tool-specific settings
browser:
  headless: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;p&gt;Once installed, you can start using Anus right away:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run Anus with a simple task
anus run "Find the latest news about artificial intelligence"

# Run in interactive mode
anus interactive

# Run with a specific configuration file
anus run --config custom_config.yaml "Summarize this article: https://example.com/article"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ“‹ Usage Examples&lt;/h2&gt; 
&lt;h3&gt;Basic Examples&lt;/h3&gt; 
&lt;h4&gt;Simple Question Answering&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent

# Create a single agent
agent = Agent()

# Ask a simple question
response = agent.run("What is the capital of France?")
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Web Search&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent
from anus.tools import SearchTool

# Create an agent with search capabilities
agent = Agent(tools=[SearchTool()])

# Search for information
response = agent.run("Find the latest research on quantum computing")
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Document Analysis&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent
from anus.tools import DocumentTool

# Create an agent with document processing capabilities
agent = Agent(tools=[DocumentTool()])

# Analyze a PDF document
response = agent.run("Summarize this PDF: /path/to/document.pdf")
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Examples&lt;/h3&gt; 
&lt;h4&gt;Multi-Agent Collaboration&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Society, Agent

# Create specialized agents
researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

# Create a society of agents
society = Society(agents=[researcher, analyst, writer])

# Execute a complex task with collaboration
response = society.run(
    "Research the impact of artificial intelligence on healthcare, " 
    "analyze the findings, and write a comprehensive report"
)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Browser Automation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent
from anus.tools import BrowserTool

# Create an agent with browser capabilities
agent = Agent(tools=[BrowserTool()])

# Perform a web task
response = agent.run(
    "Go to weather.com, check the weather forecast for New York City for the next 5 days, "
    "and create a summary table"
)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Code Generation and Execution&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent
from anus.tools import CodeTool

# Create an agent with code execution capabilities
agent = Agent(tools=[CodeTool()])

# Generate and execute code
response = agent.run(
    "Create a Python script that generates a fractal tree visualization using matplotlib"
)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Command-Line Interface Examples&lt;/h3&gt; 
&lt;h4&gt;Running Tasks&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Simple information retrieval
anus run "What is the population of Tokyo?"

# Web search with specific parameters
anus run --search-depth=3 "Find recent breakthroughs in fusion energy research"

# Document processing
anus run --file=/path/to/report.pdf "Extract all financial data from this report"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Interactive Mode&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start interactive session
anus interactive

# In interactive mode, you can have a conversation:
# &amp;gt; Tell me about the history of artificial intelligence
# &amp;gt; Now create a timeline of major AI milestones
# &amp;gt; Generate a visualization of this timeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Multi-Agent Mode&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run a complex task with multiple agents
anus run --mode=multi "Research, analyze, and summarize the current state of renewable energy technologies"

# Specify particular agent roles
anus run --mode=multi --roles=researcher,analyst,writer "Create a comprehensive market analysis for electric vehicles"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;API Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus.api import AnusAPI

# Initialize the API client
api = AnusAPI(api_key="your_api_key")

# Send a request
response = api.process_task(
    task="Generate a business plan for a sustainable fashion startup",
    mode="multi",
    output_format="markdown"
)

# Print or save the response
print(response.result)
with open("business_plan.md", "w") as f:
    f.write(response.result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent, Config

# Create a custom configuration
config = Config(
    llm={
        "provider": "anthropic",
        "model": "claude-3-opus",
        "temperature": 0.7,
    },
    memory={
        "type": "persistent",
        "path": "./agent_memory",
    },
    tools={
        "browser": {"headless": False},
        "code": {"sandbox": True},
    }
)

# Create an agent with custom configuration
agent = Agent(config=config)

# Run a task
response = agent.run("Create an interactive data visualization for climate change data")
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, visit our &lt;a href="https://anus-ai.github.io/docs"&gt;Documentation Site&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/installation"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/architecture"&gt;Architecture Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/api"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/contributing"&gt;Contributing Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘¥ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Anus is designed to be community-driven, and your input helps make it better for everyone.&lt;/p&gt; 
&lt;h3&gt;Ways to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Code Contributions&lt;/strong&gt;: Implement new features, fix bugs, or improve performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Improve or expand documentation, add examples, fix typos&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug Reports&lt;/strong&gt;: Report bugs or suggest improvements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Requests&lt;/strong&gt;: Suggest new features or enhancements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Support&lt;/strong&gt;: Help answer questions and support other users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Contributing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the Repository&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fork the repository on GitHub, then clone your fork
git clone https://github.com/your-username/anus.git
cd anus
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Set Up Development Environment&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install development dependencies
pip install -e ".[dev]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Branch&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a branch for your contribution
git checkout -b feature/your-feature-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;&lt;strong&gt;Make Your Changes&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the code style guidelines&lt;/li&gt; 
 &lt;li&gt;Add tests for new functionality&lt;/li&gt; 
 &lt;li&gt;Update documentation as needed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;&lt;strong&gt;Run Tests&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the test suite
pytest

# Run linting
flake8
mypy anus
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;&lt;strong&gt;Submit a Pull Request&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;Push your changes to your fork&lt;/li&gt; 
 &lt;li&gt;Submit a pull request from your branch to our main branch&lt;/li&gt; 
 &lt;li&gt;Provide a clear description of the changes and any related issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Code Style Guidelines&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://pep8.org/"&gt;PEP 8&lt;/a&gt; for Python code style&lt;/li&gt; 
 &lt;li&gt;Use type hints for all function parameters and return values&lt;/li&gt; 
 &lt;li&gt;Write docstrings for all functions, classes, and modules&lt;/li&gt; 
 &lt;li&gt;Keep functions focused and small (under 50 lines when possible)&lt;/li&gt; 
 &lt;li&gt;Use meaningful variable and function names&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Commit Message Guidelines&lt;/h3&gt; 
&lt;p&gt;We follow the &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; specification:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;type&amp;gt;(&amp;lt;scope&amp;gt;): &amp;lt;description&amp;gt;

[optional body]

[optional footer(s)]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Types include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;feat&lt;/code&gt;: A new feature&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fix&lt;/code&gt;: A bug fix&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;docs&lt;/code&gt;: Documentation changes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;style&lt;/code&gt;: Code style changes (formatting, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;refactor&lt;/code&gt;: Code changes that neither fix bugs nor add features&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;test&lt;/code&gt;: Adding or modifying tests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chore&lt;/code&gt;: Changes to the build process or auxiliary tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Pull Request Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Update the README.md or documentation with details of changes if appropriate&lt;/li&gt; 
 &lt;li&gt;Update the CHANGELOG.md with details of changes&lt;/li&gt; 
 &lt;li&gt;The PR should work for Python 3.11 and above&lt;/li&gt; 
 &lt;li&gt;PRs require approval from at least one maintainer&lt;/li&gt; 
 &lt;li&gt;Once approved, a maintainer will merge your PR&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;Please note that this project is released with a &lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project you agree to abide by its terms.&lt;/p&gt; 
&lt;h2&gt;ğŸŒ Community&lt;/h2&gt; 
&lt;p&gt;Join our community to get help, share ideas, and contribute to the project:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://t.me/goanus"&gt;Telegram Channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“ License&lt;/h2&gt; 
&lt;p&gt;Anus is released under the &lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MIT License

Copyright (c) 2025 Anus AI Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>dgtlmoon/changedetection.io</title>
      <link>https://github.com/dgtlmoon/changedetection.io</link>
      <description>&lt;p&gt;Best and simplest tool for website change detection, web page monitoring, and website change alerts. Perfect for tracking content changes, price drops, restock alerts, and website defacement monitoringâ€”all for free or enjoy our SaaS plan!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Detect Website Changes Automatically â€” Monitor Web Page Changes in Real Time&lt;/h1&gt; 
&lt;p&gt;Monitor websites for updates â€” get notified via Discord, Email, Slack, Telegram, Webhook and many more.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Detect web page content changes and get instant alerts.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Ideal for monitoring price changes, content edits, conditional changes and more.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://changedetection.io?src=github"&gt;&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/screenshot.png" style="max-width:100%;" alt="Web site page change monitoring" title="Web site page change monitoring"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dgtlmoon/changedetection.io/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/dgtlmoon/changedetection.io?style=for-the-badge" alt="Release Version"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dgtlmoon/changedetection.io"&gt;&lt;img src="https://img.shields.io/docker/pulls/dgtlmoon/changedetection.io?style=for-the-badge" alt="Docker Pulls"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/LICENSE.md"&gt;&lt;img src="https://img.shields.io/github/license/dgtlmoon/changedetection.io.svg?style=for-the-badge" alt="License"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/dgtlmoon/changedetection.io/actions/workflows/test-only.yml/badge.svg?branch=master" alt="changedetection.io"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://changedetection.io"&gt;&lt;strong&gt;Get started with website page change monitoring straight away. Don't have time? Try our $8.99/month subscription, use our proxies and support!&lt;/strong&gt;&lt;/a&gt; , &lt;em&gt;half the price of other website change monitoring services!&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chrome browser included.&lt;/li&gt; 
 &lt;li&gt;Nothing to install, access via browser login after signup.&lt;/li&gt; 
 &lt;li&gt;Super fast, no registration needed setup.&lt;/li&gt; 
 &lt;li&gt;Get started watching and receiving website change notifications straight away.&lt;/li&gt; 
 &lt;li&gt;See our &lt;a href="https://changedetection.io/tutorials"&gt;tutorials and how-to page for more inspiration&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Target specific parts of the webpage using the Visual Selector tool.&lt;/h3&gt; 
&lt;p&gt;Available when connected to a &lt;a href="https://github.com/dgtlmoon/changedetection.io/wiki/Playwright-content-fetcher"&gt;playwright content fetcher&lt;/a&gt; (included as part of our subscription service)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://changedetection.io?src=github"&gt;&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/visualselector-anim.gif" style="max-width:100%;" alt="Select parts and elements of a web page to monitor for changes" title="Select parts and elements of a web page to monitor for changes"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Easily see what changed, examine by word, line, or individual character.&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://changedetection.io?src=github"&gt;&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/screenshot-diff.png" style="max-width:100%;" alt="Self-hosted web page change monitoring context difference " title="Self-hosted web page change monitoring context difference "&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Perform interactive browser steps&lt;/h3&gt; 
&lt;p&gt;Fill in text boxes, click buttons and more, setup your changedetection scenario.&lt;/p&gt; 
&lt;p&gt;Using the &lt;strong&gt;Browser Steps&lt;/strong&gt; configuration, add basic steps before performing change detection, such as logging into websites, adding a product to a cart, accept cookie logins, entering dates and refining searches.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://changedetection.io?src=github"&gt;&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/browsersteps-anim.gif" style="max-width:100%;" alt="Website change detection with interactive browser steps, detect changes behind login and password, search queries and more" title="Website change detection with interactive browser steps, detect changes behind login and password, search queries and more"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;After &lt;strong&gt;Browser Steps&lt;/strong&gt; have been run, then visit the &lt;strong&gt;Visual Selector&lt;/strong&gt; tab to refine the content you're interested in. Requires Playwright to be enabled.&lt;/p&gt; 
&lt;h3&gt;Awesome restock and price change notifications&lt;/h3&gt; 
&lt;p&gt;Enable the &lt;em&gt;"Re-stock &amp;amp; Price detection for single product pages"&lt;/em&gt; option to activate the best way to monitor product pricing, this will extract any meta-data in the HTML page and give you many options to follow the pricing of the product.&lt;/p&gt; 
&lt;p&gt;Easily organise and monitor prices for products from the dashboard, get alerts and notifications when the price of a product changes or comes back in stock again!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://changedetection.io?src=github"&gt;&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/restock-overview.png" style="max-width:100%;" alt="Easily keep an eye on product price changes directly from the UI" title="Easily keep an eye on product price changes directly from the UI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Set price change notification parameters, upper and lower price, price change percentage and more. Always know when a product for sale drops in price.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://changedetection.io?src=github"&gt;&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/restock-settings.png" style="max-width:100%;" alt="Set upper lower and percentage price change notification values" title="Set upper lower and percentage price change notification values"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Example use cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Products and services have a change in pricing&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Out of stock notification&lt;/em&gt; and &lt;em&gt;Back In stock notification&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Monitor and track PDF file changes, know when a PDF file has text changes.&lt;/li&gt; 
 &lt;li&gt;Governmental department updates (changes are often only on their websites)&lt;/li&gt; 
 &lt;li&gt;New software releases, security advisories when you're not on their mailing list.&lt;/li&gt; 
 &lt;li&gt;Festivals with changes&lt;/li&gt; 
 &lt;li&gt;Discogs restock alerts and monitoring&lt;/li&gt; 
 &lt;li&gt;Realestate listing changes&lt;/li&gt; 
 &lt;li&gt;Know when your favourite whiskey is on sale, or other special deals are announced before anyone else&lt;/li&gt; 
 &lt;li&gt;COVID related news from government websites&lt;/li&gt; 
 &lt;li&gt;University/organisation news from their website&lt;/li&gt; 
 &lt;li&gt;Detect and monitor changes in JSON API responses&lt;/li&gt; 
 &lt;li&gt;JSON API monitoring and alerting&lt;/li&gt; 
 &lt;li&gt;Changes in legal and other documents&lt;/li&gt; 
 &lt;li&gt;Trigger API calls via notifications when text appears on a website&lt;/li&gt; 
 &lt;li&gt;Glue together APIs using the JSON filter and JSON notifications&lt;/li&gt; 
 &lt;li&gt;Create RSS feeds based on changes in web content&lt;/li&gt; 
 &lt;li&gt;Monitor HTML source code for unexpected changes, strengthen your PCI compliance&lt;/li&gt; 
 &lt;li&gt;You have a very sensitive list of URLs to watch and you do &lt;em&gt;not&lt;/em&gt; want to use the paid alternatives. (Remember, &lt;em&gt;you&lt;/em&gt; are the product)&lt;/li&gt; 
 &lt;li&gt;Get notified when certain keywords appear in Twitter search results&lt;/li&gt; 
 &lt;li&gt;Proactively search for jobs, get notified when companies update their careers page, search job portals for keywords.&lt;/li&gt; 
 &lt;li&gt;Get alerts when new job positions are open on Bamboo HR and other job platforms&lt;/li&gt; 
 &lt;li&gt;Website defacement monitoring&lt;/li&gt; 
 &lt;li&gt;PokÃ©mon Card Restock Tracker / PokÃ©mon TCG Tracker&lt;/li&gt; 
 &lt;li&gt;RegTech - stay ahead of regulatory changes, regulatory compliance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Need an actual Chrome runner with Javascript support? We support fetching via WebDriver and Playwright!&lt;/em&gt;&lt;/p&gt; 
&lt;h4&gt;Key Features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Lots of trigger filters, such as "Trigger on text", "Remove text by selector", "Ignore text", "Extract text", also using regular-expressions!&lt;/li&gt; 
 &lt;li&gt;Target elements with xPath 1 and xPath 2, CSS Selectors, Easily monitor complex JSON with JSONPath or jq&lt;/li&gt; 
 &lt;li&gt;Switch between fast non-JS and Chrome JS based "fetchers"&lt;/li&gt; 
 &lt;li&gt;Track changes in PDF files (Monitor text changed in the PDF, Also monitor PDF filesize and checksums)&lt;/li&gt; 
 &lt;li&gt;Easily specify how often a site should be checked&lt;/li&gt; 
 &lt;li&gt;Execute JS before extracting text (Good for logging in, see examples in the UI!)&lt;/li&gt; 
 &lt;li&gt;Override Request Headers, Specify &lt;code&gt;POST&lt;/code&gt; or &lt;code&gt;GET&lt;/code&gt; and other methods&lt;/li&gt; 
 &lt;li&gt;Use the "Visual Selector" to help target specific elements&lt;/li&gt; 
 &lt;li&gt;Configurable &lt;a href="https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration"&gt;proxy per watch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Send a screenshot with the notification when a change is detected in the web page&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We &lt;a href="https://brightdata.grsm.io/n0r16zf7eivq"&gt;recommend and use Bright Data&lt;/a&gt; global proxy services, Bright Data will match any first deposit up to $150 using our signup link.&lt;/p&gt; 
&lt;p&gt;Please &lt;span&gt;â­&lt;/span&gt; star &lt;span&gt;â­&lt;/span&gt; this project and help it grow! &lt;a href="https://github.com/dgtlmoon/changedetection.io/"&gt;https://github.com/dgtlmoon/changedetection.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Conditional web page changes&lt;/h3&gt; 
&lt;p&gt;Easily &lt;a href="https://changedetection.io/tutorial/conditional-actions-web-page-changes"&gt;configure conditional actions&lt;/a&gt;, for example, only trigger when a price is above or below a preset amount, or &lt;a href="https://changedetection.io/tutorial/how-monitor-keywords-any-website"&gt;when a web page includes (or does not include) a keyword&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/web-page-change-conditions.png" style="max-width:80%;" alt="Conditional web page changes" title="Conditional web page changes"&gt; 
&lt;h3&gt;Schedule web page watches in any timezone, limit by day of week and time.&lt;/h3&gt; 
&lt;p&gt;Easily set a re-check schedule, for example you could limit the web page change detection to only operate during business hours. Or perhaps based on a foreign timezone (for example, you want to check for the latest news-headlines in a foreign country at 0900 AM),&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/scheduler.png" style="max-width:80%;" alt="How to monitor web page changes according to a schedule" title="How to monitor web page changes according to a schedule"&gt; 
&lt;p&gt;Includes quick short-cut buttons to setup a schedule for &lt;strong&gt;business hours only&lt;/strong&gt;, or &lt;strong&gt;weekends&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;We have a Chrome extension!&lt;/h3&gt; 
&lt;p&gt;Easily add the current web page to your changedetection.io tool, simply install the extension and click "Sync" to connect it to your existing changedetection.io install.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://chromewebstore.google.com/detail/changedetectionio-website/kefcfmgmlhmankjmnbijimhofdjekbop"&gt;&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/chrome-extension-screenshot.png" style="max-width:80%;" alt="Chrome Extension to easily add the current web-page to detect a change." title="Chrome Extension to easily add the current web-page to detect a change."&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://chromewebstore.google.com/detail/changedetectionio-website/kefcfmgmlhmankjmnbijimhofdjekbop"&gt;Goto the Chrome Webstore to download the extension.&lt;/a&gt; ( Or check out the &lt;a href="https://github.com/dgtlmoon/changedetection.io-browser-extension"&gt;GitHub repo&lt;/a&gt; )&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;With Docker composer, just clone this repository and..&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Docker standalone&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ docker run -d --restart always -p "127.0.0.1:5000:5000" -v datastore-volume:/datastore --name changedetection.io dgtlmoon/changedetection.io
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;:latest&lt;/code&gt; tag is our latest stable release, &lt;code&gt;:dev&lt;/code&gt; tag is our bleeding edge &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; 
&lt;p&gt;Alternative docker repository over at ghcr - &lt;a href="https://ghcr.io/dgtlmoon/changedetection.io"&gt;ghcr.io/dgtlmoon/changedetection.io&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;See the install instructions at the wiki &lt;a href="https://github.com/dgtlmoon/changedetection.io/wiki/Microsoft-Windows"&gt;https://github.com/dgtlmoon/changedetection.io/wiki/Microsoft-Windows&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Python Pip&lt;/h3&gt; 
&lt;p&gt;Check out our pypi page &lt;a href="https://pypi.org/project/changedetection.io/"&gt;https://pypi.org/project/changedetection.io/&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ pip3 install changedetection.io
$ changedetection.io -d /path/to/empty/data/dir -p 5000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;a href="http://127.0.0.1:5000"&gt;http://127.0.0.1:5000&lt;/a&gt; , You should now be able to access the UI.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Now with per-site configurable support for using a fast built in HTTP fetcher or use a Chrome based fetcher for monitoring of JavaScript websites!&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Updating changedetection.io&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;docker pull dgtlmoon/changedetection.io
docker kill $(docker ps -a -f name=changedetection.io -q)
docker rm $(docker ps -a -f name=changedetection.io -q)
docker run -d --restart always -p "127.0.0.1:5000:5000" -v datastore-volume:/datastore --name changedetection.io dgtlmoon/changedetection.io
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;docker compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose pull &amp;amp;&amp;amp; docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the wiki for more information &lt;a href="https://github.com/dgtlmoon/changedetection.io/wiki"&gt;https://github.com/dgtlmoon/changedetection.io/wiki&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filters&lt;/h2&gt; 
&lt;p&gt;XPath(1.0), JSONPath, jq, and CSS support comes baked in! You can be as specific as you need, use XPath exported from various XPath element query creation tools. (We support LXML &lt;code&gt;re:test&lt;/code&gt;, &lt;code&gt;re:match&lt;/code&gt; and &lt;code&gt;re:replace&lt;/code&gt;.)&lt;/p&gt; 
&lt;h2&gt;Notifications&lt;/h2&gt; 
&lt;p&gt;ChangeDetection.io supports a massive amount of notifications (including email, office365, custom APIs, etc) when a web-page has a change detected thanks to the &lt;a href="https://github.com/caronc/apprise"&gt;apprise&lt;/a&gt; library. Simply set one or more notification URL's in the &lt;em&gt;[edit]&lt;/em&gt; tab of that watch.&lt;/p&gt; 
&lt;p&gt;Just some examples&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;discord://webhook_id/webhook_token
flock://app_token/g:channel_id
gitter://token/room
gchat://workspace/key/token
msteams://TokenA/TokenB/TokenC/
o365://TenantID:AccountEmail/ClientID/ClientSecret/TargetEmail
rocket://user:password@hostname/#Channel
mailto://user:pass@example.com?to=receivingAddress@example.com
json://someserver.com/custom-api
syslog://
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/caronc/apprise#popular-notification-services"&gt;And everything else in this list!&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/screenshot-notifications.png" style="max-width:100%;" alt="Self-hosted web page change monitoring notifications" title="Self-hosted web page change monitoring notifications"&gt; 
&lt;p&gt;Now you can also customise your notification content and use &lt;a target="_new" href="https://jinja.palletsprojects.com/en/3.0.x/templates/"&gt;Jinja2 templating&lt;/a&gt; for their title and body!&lt;/p&gt; 
&lt;h2&gt;JSON API Monitoring&lt;/h2&gt; 
&lt;p&gt;Detect changes and monitor data in JSON API's by using either JSONPath or jq to filter, parse, and restructure JSON as needed.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/json-filter-field-example.png" alt="image"&gt;&lt;/p&gt; 
&lt;p&gt;This will re-parse the JSON and apply formatting to the text, making it super easy to monitor and detect changes in JSON API results&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/dgtlmoon/changedetection.io/master/docs/json-diff-example.png" alt="image"&gt;&lt;/p&gt; 
&lt;h3&gt;JSONPath or jq?&lt;/h3&gt; 
&lt;p&gt;For more complex parsing, filtering, and modifying of JSON data, jq is recommended due to the built-in operators and functions. Refer to the &lt;a href="https://stedolan.github.io/jq/manual/"&gt;documentation&lt;/a&gt; for more specific information on jq.&lt;/p&gt; 
&lt;p&gt;One big advantage of &lt;code&gt;jq&lt;/code&gt; is that you can use logic in your JSON filter, such as filters to only show items that have a value greater than/less than etc.&lt;/p&gt; 
&lt;p&gt;See the wiki &lt;a href="https://github.com/dgtlmoon/changedetection.io/wiki/JSON-Selector-Filter-help"&gt;https://github.com/dgtlmoon/changedetection.io/wiki/JSON-Selector-Filter-help&lt;/a&gt; for more information and examples&lt;/p&gt; 
&lt;h3&gt;Parse JSON embedded in HTML!&lt;/h3&gt; 
&lt;p&gt;When you enable a &lt;code&gt;json:&lt;/code&gt; or &lt;code&gt;jq:&lt;/code&gt; filter, you can even automatically extract and parse embedded JSON inside a HTML page! Amazingly handy for sites that build content based on JSON, such as many e-commerce websites.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;
...
&amp;lt;script type="application/ld+json"&amp;gt;

{
   "@context":"http://schema.org/",
   "@type":"Product",
   "offers":{
      "@type":"Offer",
      "availability":"http://schema.org/InStock",
      "price":"3949.99",
      "priceCurrency":"USD",
      "url":"https://www.newegg.com/p/3D5-000D-001T1"
   },
   "description":"Cobratype King Cobra Hero Desktop Gaming PC",
   "name":"Cobratype King Cobra Hero Desktop Gaming PC",
   "sku":"3D5-000D-001T1",
   "itemCondition":"NewCondition"
}
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;json:$..price&lt;/code&gt; or &lt;code&gt;jq:..price&lt;/code&gt; would give &lt;code&gt;3949.99&lt;/code&gt;, or you can extract the whole structure (use a JSONpath test website to validate with)&lt;/p&gt; 
&lt;p&gt;The application also supports notifying you that it can follow this information automatically&lt;/p&gt; 
&lt;h2&gt;Proxy Configuration&lt;/h2&gt; 
&lt;p&gt;See the wiki &lt;a href="https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration"&gt;https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration&lt;/a&gt; , we also support using &lt;a href="https://github.com/dgtlmoon/changedetection.io/wiki/Proxy-configuration#brightdata-proxy-support"&gt;Bright Data proxy services where possible&lt;/a&gt; and &lt;a href="https://oxylabs.go2cloud.org/SH2d"&gt;Oxylabs&lt;/a&gt; proxy services.&lt;/p&gt; 
&lt;h2&gt;Raspberry Pi support?&lt;/h2&gt; 
&lt;p&gt;Raspberry Pi and linux/arm/v6 linux/arm/v7 arm64 devices are supported! See the wiki for &lt;a href="https://github.com/dgtlmoon/changedetection.io/wiki/Fetching-pages-with-WebDriver"&gt;details&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Import support&lt;/h2&gt; 
&lt;p&gt;Easily &lt;a href="https://changedetection.io/tutorial/how-import-your-website-change-detection-lists-excel"&gt;import your list of websites to watch for changes in Excel .xslx file format&lt;/a&gt;, or paste in lists of website URLs as plaintext.&lt;/p&gt; 
&lt;p&gt;Excel import is recommended - that way you can better organise tags/groups of websites and other features.&lt;/p&gt; 
&lt;h2&gt;API Support&lt;/h2&gt; 
&lt;p&gt;Supports managing the website watch list &lt;a href="https://changedetection.io/docs/api_v1/index.html"&gt;via our API&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support us&lt;/h2&gt; 
&lt;p&gt;Do you use changedetection.io to make money? does it save you time or money? Does it make your life easier? less stressful? Remember, we write this software when we should be doing actual paid work, we have to buy food and pay rent just like you.&lt;/p&gt; 
&lt;p&gt;Consider taking out an officially supported &lt;a href="https://changedetection.io?src=github"&gt;website change detection subscription&lt;/a&gt; , even if you don't use it, you still get the warm fuzzy feeling of helping out the project. (And who knows, you might just use it!)&lt;/p&gt; 
&lt;h2&gt;Commercial Support&lt;/h2&gt; 
&lt;p&gt;I offer commercial support, this software is depended on by network security, aerospace , data-science and data-journalist professionals just to name a few, please reach out at &lt;a href="mailto:dgtlmoon@gmail.com"&gt;dgtlmoon@gmail.com&lt;/a&gt; for any enquiries, I am more than glad to work with your organisation to further the possibilities of what can be done with changedetection.io&lt;/p&gt; 
&lt;h2&gt;Commercial Licencing&lt;/h2&gt; 
&lt;p&gt;If you are reselling this software either in part or full as part of any commercial arrangement, you must abide by our COMMERCIAL_LICENCE.md found in our code repository, please contact &lt;a href="mailto:dgtlmoon@gmail.com"&gt;dgtlmoon@gmail.com&lt;/a&gt; and &lt;a href="mailto:contact@changedetection.io"&gt;contact@changedetection.io&lt;/a&gt; .&lt;/p&gt; 
&lt;h2&gt;Third-party licenses&lt;/h2&gt; 
&lt;p&gt;changedetectionio.html_tools.elementpath_tostring: Copyright (c), 2018-2021, SISSA (Scuola Internazionale Superiore di Studi Avanzati), Licensed under &lt;a href="https://github.com/sissaschool/elementpath/raw/master/LICENSE"&gt;MIT license&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Recognition of fantastic contributors to the project&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Constantin Hong &lt;a href="https://github.com/Constantin1489"&gt;https://github.com/Constantin1489&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>microsoft/mcp-for-beginners</title>
      <link>https://github.com/microsoft/mcp-for-beginners</link>
      <description>&lt;p&gt;This open-source curriculum introduces the fundamentals of Model Context Protocol (MCP) through real-world, cross-language examples in .NET, Java, TypeScript, JavaScript, and Python. Designed for developers, it focuses on practical techniques for building modular, scalable, and secure AI workflows from session setup to service orchestration.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/images/mcp-beginners.png" alt="MCP-for-beginners"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub contributors"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/issues"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub issues"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub pull-requests"&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/fork"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/mcp-for-beginners?style=social&amp;amp;label=Star" alt="GitHub stars"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.com/invite/ByRwuEEgH4"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/ByRwuEEgH4" alt="Microsoft Azure AI Foundry Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Follow these steps to get started using these resources:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the Repository&lt;/strong&gt;: Click &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/fork"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks"&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt;: &lt;code&gt;git clone https://github.com/microsoft/mcp-for-beginners.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.com/invite/ByRwuEEgH4"&gt;&lt;strong&gt;Join The Azure AI Foundry Discord and meet experts and fellow developers&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸŒ Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;ğŸš€ Model Context Protocol (MCP) Curriculum for Beginners&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;Learn MCP with Hands-on Code Examples in C#, Java, JavaScript, Python, and TypeScript&lt;/strong&gt;&lt;/h2&gt; 
&lt;h2&gt;ğŸ§  Overview of the Model Context Protocol Curriculum&lt;/h2&gt; 
&lt;p&gt;The &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; is a cutting-edge framework designed to standardize interactions between AI models and client applications. This open-source curriculum offers a structured learning path, complete with practical coding examples and real-world use cases, across popular programming languages including C#, Java, JavaScript, TypeScript, and Python.&lt;/p&gt; 
&lt;p&gt;Whether you're an AI developer, system architect, or software engineer, this guide is your comprehensive resource for mastering MCP fundamentals and implementation strategies.&lt;/p&gt; 
&lt;h2&gt;ğŸ”— Official MCP Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“˜ &lt;a href="https://modelcontextprotocol.io/"&gt;MCP Documentation&lt;/a&gt; â€“ Detailed tutorials and user guides&lt;/li&gt; 
 &lt;li&gt;ğŸ“œ &lt;a href="https://modelcontextprotocol.io/docs/"&gt;MCP Specification&lt;/a&gt; â€“ Protocol architecture and technical references&lt;/li&gt; 
 &lt;li&gt;ğŸ“œ &lt;a href="https://spec.modelcontextprotocol.io/"&gt;Original MCP Specification&lt;/a&gt; â€“ Legacy technical references (may contain additional details)&lt;/li&gt; 
 &lt;li&gt;ğŸ§‘â€ğŸ’» &lt;a href="https://github.com/modelcontextprotocol"&gt;MCP GitHub Repository&lt;/a&gt; â€“ Open-source SDKs, tools, and code samples&lt;/li&gt; 
 &lt;li&gt;ğŸŒ &lt;a href="https://github.com/orgs/modelcontextprotocol/discussions"&gt;MCP Community&lt;/a&gt; â€“ Join discussions and contribute to the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Join us for MCP Dev Days 29-30th July 2025&lt;/h2&gt; 
&lt;p&gt;Get ready for two days of deep technical insight, community connection, and hands-on learning at MCP Dev Days, a virtual event dedicated to the Model Context Protocol (MCP) â€” the emerging standard that bridges AI models and the tools they rely on.&lt;/p&gt; 
&lt;p&gt;â¡ï¸ &lt;a href="https://developer.microsoft.com/en-us/reactor/series/S-1563/"&gt;Register for MCP Dev Days&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can watch MCP Dev Days by registering on our event page: &lt;a href="https://aka.ms/mcpdevdays"&gt;https://aka.ms/mcpdevdays&lt;/a&gt;. From there, youâ€™ll be able to join a live stream on YouTube or Twitch. All of the content is recorded and will be available afterwards on the Microsoft Developer YouTube channel. Source code for the demos will be available on GitHub too.&lt;/p&gt; 
&lt;h3&gt;Event Details&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Dates: July 29 (Day 1) &amp;amp; July 30 (Day 2)&lt;/li&gt; 
 &lt;li&gt;Time: 9:00 AM PST daily&lt;/li&gt; 
 &lt;li&gt;Where: Online â€“ join from anywhere!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Day 1: MCP Productivity, DevTools, &amp;amp; Community:&lt;/h4&gt; 
&lt;p&gt;Is all about empowering developers to use MCP in their developer workflow and celebrating the amazing MCP community. Weâ€™ll be joined with community members and partners such as Arcade, Block, Okta, and Neon to see how they are collaborating with Microsoft to shape an open, extensible MCP ecosystem. Real-world demos across VS Code, Visual Studio, GitHub Copilot, and popular community tools Practical, context-driven dev workflows Community-led sessions and insights Whether youâ€™re just getting started with MCP or already building with it, Day 1 will set the stage with inspiration and actionable takeaways.&lt;/p&gt; 
&lt;h4&gt;Day 2: Build MCP Servers with Confidence&lt;/h4&gt; 
&lt;p&gt;Is for MCP builders. Weâ€™ll go deep into implementation strategies and best practices for creating MCP servers and integrating MCP into your AI workflows.&lt;/p&gt; 
&lt;h3&gt;Topics include:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building MCP Servers and integrating them into agent experiences&lt;/li&gt; 
 &lt;li&gt;Prompt-driven development&lt;/li&gt; 
 &lt;li&gt;Security best practices&lt;/li&gt; 
 &lt;li&gt;Using building blocks like Functions, ACA, and API Management&lt;/li&gt; 
 &lt;li&gt;Registry alignment and tooling (1P + 3P)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If youâ€™re a developer, tool builder, or AI product strategist, this day is packed with the insights you need to build scalable, secure, and future-ready MCP solutions.&lt;/p&gt; 
&lt;h2&gt;ğŸ§­ MCP Curriculum Overview&lt;/h2&gt; 
&lt;h3&gt;ğŸ“š Complete Curriculum Structure&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 1-3: Fundamentals&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;00&lt;/td&gt; 
   &lt;td&gt;Introduction to MCP&lt;/td&gt; 
   &lt;td&gt;Overview of the Model Context Protocol and its significance in AI pipelines&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/00-Introduction/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td&gt;Core Concepts Explained&lt;/td&gt; 
   &lt;td&gt;In-depth exploration of core MCP concepts&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/01-CoreConcepts/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td&gt;Security in MCP&lt;/td&gt; 
   &lt;td&gt;Security threats and best practices&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/02-Security/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td&gt;Getting Started with MCP&lt;/td&gt; 
   &lt;td&gt;Environment setup, basic servers/clients, integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 3: Building Your First Server &amp;amp; Client&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.1&lt;/td&gt; 
   &lt;td&gt;First Server&lt;/td&gt; 
   &lt;td&gt;Create your first MCP server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/01-first-server/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.2&lt;/td&gt; 
   &lt;td&gt;First Client&lt;/td&gt; 
   &lt;td&gt;Develop a basic MCP client&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/02-client/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.3&lt;/td&gt; 
   &lt;td&gt;Client with LLM&lt;/td&gt; 
   &lt;td&gt;Integrate large language models&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/03-llm-client/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.4&lt;/td&gt; 
   &lt;td&gt;VS Code Integration&lt;/td&gt; 
   &lt;td&gt;Consume MCP servers in VS Code&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/04-vscode/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.5&lt;/td&gt; 
   &lt;td&gt;SSE Server&lt;/td&gt; 
   &lt;td&gt;Create servers using Server-Sent Events&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/05-sse-server/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.6&lt;/td&gt; 
   &lt;td&gt;HTTP Streaming&lt;/td&gt; 
   &lt;td&gt;Implement HTTP streaming in MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/06-http-streaming/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.7&lt;/td&gt; 
   &lt;td&gt;AI Toolkit&lt;/td&gt; 
   &lt;td&gt;Use AI Toolkit with MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/07-aitk/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.8&lt;/td&gt; 
   &lt;td&gt;Testing&lt;/td&gt; 
   &lt;td&gt;Test your MCP server implementation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/08-testing/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.9&lt;/td&gt; 
   &lt;td&gt;Deployment&lt;/td&gt; 
   &lt;td&gt;Deploy MCP servers to production&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/09-deployment/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 4-5: Practical &amp;amp; Advanced&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td&gt;Practical Implementation&lt;/td&gt; 
   &lt;td&gt;SDKs, debugging, testing, reusable prompt templates&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td&gt;Advanced Topics in MCP&lt;/td&gt; 
   &lt;td&gt;Multi-modal AI, scaling, enterprise use&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;Azure Integration&lt;/td&gt; 
   &lt;td&gt;MCP Integration with Azure&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-integration/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;Multi-modality&lt;/td&gt; 
   &lt;td&gt;Working with multiple modalities&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-multi-modality/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;OAuth2 Demo&lt;/td&gt; 
   &lt;td&gt;Implement OAuth2 authentication&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-oauth2-demo/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.4&lt;/td&gt; 
   &lt;td&gt;Root Contexts&lt;/td&gt; 
   &lt;td&gt;Understand and implement root contexts&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-root-contexts/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.5&lt;/td&gt; 
   &lt;td&gt;Routing&lt;/td&gt; 
   &lt;td&gt;MCP routing strategies&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-routing/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.6&lt;/td&gt; 
   &lt;td&gt;Sampling&lt;/td&gt; 
   &lt;td&gt;Sampling techniques in MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-sampling/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.7&lt;/td&gt; 
   &lt;td&gt;Scaling&lt;/td&gt; 
   &lt;td&gt;Scale MCP implementations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-scaling/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.8&lt;/td&gt; 
   &lt;td&gt;Security&lt;/td&gt; 
   &lt;td&gt;Advanced security considerations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-security/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.9&lt;/td&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;Implement web search capabilities&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/web-search-mcp/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.10&lt;/td&gt; 
   &lt;td&gt;Realtime Streaming&lt;/td&gt; 
   &lt;td&gt;Build realtime streaming functionality&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-realtimestreaming/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.11&lt;/td&gt; 
   &lt;td&gt;Realtime Search&lt;/td&gt; 
   &lt;td&gt;Implement realtime search&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-realtimesearch/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.12&lt;/td&gt; 
   &lt;td&gt;Entra ID Auth&lt;/td&gt; 
   &lt;td&gt;Authentication with Microsoft Entra ID&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-security-entra/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.13&lt;/td&gt; 
   &lt;td&gt;Foundry Integration&lt;/td&gt; 
   &lt;td&gt;Integrate with Azure AI Foundry&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-foundry-agent-integration/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.14&lt;/td&gt; 
   &lt;td&gt;Context Engineering&lt;/td&gt; 
   &lt;td&gt;Techniques for effective context engineering&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-contextengineering/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 6-10: Community &amp;amp; Best Practices&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td&gt;Community Contributions&lt;/td&gt; 
   &lt;td&gt;How to contribute to the MCP ecosystem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/06-CommunityContributions/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td&gt;Insights from Early Adoption&lt;/td&gt; 
   &lt;td&gt;Real-world implementation stories&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/07-LessonsFromEarlyAdoption/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td&gt;Best Practices for MCP&lt;/td&gt; 
   &lt;td&gt;Performance, fault-tolerance, resilience&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/08-BestPractices/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td&gt;MCP Case Studies&lt;/td&gt; 
   &lt;td&gt;Practical implementation examples&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/09-CaseStudy/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;Hands-on Workshop&lt;/td&gt; 
   &lt;td&gt;Building an MCP Server with AI Toolkit&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/10-StreamliningAIWorkflowsBuildingAnMCPServerWithAIToolkit/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ğŸ’» Sample Code Projects&lt;/h3&gt; 
&lt;h4&gt;Basic MCP Calculator Samples&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;C#&lt;/td&gt; 
   &lt;td&gt;MCP Server Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/csharp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Java&lt;/td&gt; 
   &lt;td&gt;MCP Calculator&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/java/calculator/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript&lt;/td&gt; 
   &lt;td&gt;MCP Demo&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/javascript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;MCP Server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/python/mcp_calculator_server.py"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;MCP Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/typescript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Advanced MCP Implementations&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;C#&lt;/td&gt; 
   &lt;td&gt;Advanced Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/csharp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Java&lt;/td&gt; 
   &lt;td&gt;Container App Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/java/containerapp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript&lt;/td&gt; 
   &lt;td&gt;Advanced Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/javascript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;Complex Implementation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/python/mcp_sample.py"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;Container Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/typescript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ğŸ¯ Prerequisites for Learning MCP&lt;/h2&gt; 
&lt;p&gt;To get the most out of this curriculum, you should have:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Basic knowledge of programming in at least one of the following languages: C#, Java, JavaScript, Python, or TypeScript&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Understanding of client-server model and APIs&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Familiarity with REST and HTTP concepts&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) Background in AI/ML concepts&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Joining our community discussions for support&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“š Study Guide &amp;amp; Resources&lt;/h2&gt; 
&lt;p&gt;This repository includes several resources to help you navigate and learn effectively:&lt;/p&gt; 
&lt;h3&gt;Study Guide&lt;/h3&gt; 
&lt;p&gt;A comprehensive &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/study_guide.md"&gt;Study Guide&lt;/a&gt; is available to help you navigate this repository effectively. The guide includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A visual curriculum map showing all topics covered&lt;/li&gt; 
 &lt;li&gt;Detailed breakdown of each repository section&lt;/li&gt; 
 &lt;li&gt;Guidance on how to use sample projects&lt;/li&gt; 
 &lt;li&gt;Recommended learning paths for different skill levels&lt;/li&gt; 
 &lt;li&gt;Additional resources to complement your learning journey&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Changelog&lt;/h3&gt; 
&lt;p&gt;We maintain a detailed &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/changelog.md"&gt;Changelog&lt;/a&gt; that tracks all significant updates to the curriculum materials, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;New content additions&lt;/li&gt; 
 &lt;li&gt;Structural changes&lt;/li&gt; 
 &lt;li&gt;Feature improvements&lt;/li&gt; 
 &lt;li&gt;Documentation updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ› ï¸ How to Use This Curriculum Effectively&lt;/h2&gt; 
&lt;p&gt;Each lesson in this guide includes:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clear explanations of MCP concepts&lt;/li&gt; 
 &lt;li&gt;Live code examples in multiple languages&lt;/li&gt; 
 &lt;li&gt;Exercises to build real MCP applications&lt;/li&gt; 
 &lt;li&gt;Extra resources for advanced learners&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸŒŸ Community Thanks&lt;/h2&gt; 
&lt;p&gt;Thanks to Microsoft Valued Professional &lt;a href="https://www.linkedin.com/in/shivam2003/"&gt;Shivam Goyal&lt;/a&gt; for contributing important code samples.&lt;/p&gt; 
&lt;h2&gt;ğŸ“œ License Information&lt;/h2&gt; 
&lt;p&gt;This content is licensed under the &lt;strong&gt;MIT License&lt;/strong&gt;. For terms and conditions, see the &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Contribution Guidelines&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;ğŸ“‚ Repository Structure&lt;/h2&gt; 
&lt;p&gt;The repository is organized as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Curriculum (00-10)&lt;/strong&gt;: The main content organized in ten sequential modules&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;images/&lt;/strong&gt;: Diagrams and illustrations used throughout the curriculum&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;translations/&lt;/strong&gt;: Multi-language support with automated translations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;translated_images/&lt;/strong&gt;: Localized versions of diagrams and illustrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;study_guide.md&lt;/strong&gt;: Comprehensive guide to navigating the repository&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;changelog.md&lt;/strong&gt;: Record of all significant changes to the curriculum materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;mcp.json&lt;/strong&gt;: Configuration file for MCP specification&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CODE_OF_CONDUCT.md, LICENSE, SECURITY.md, SUPPORT.md&lt;/strong&gt;: Project governance documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ’ Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI Agents For Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;â„¢ï¸ Trademark Notice&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos is subject to those third-parties' policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Investment Research for Everyone, Everywhere.&lt;/p&gt;&lt;hr&gt;&lt;br&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://x.com/openbb_finance"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/xPHTuHCmuV"&gt;&lt;img src="https://img.shields.io/discord/831165782750789672" alt="Discord Shield"&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers"&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/OpenBB-finance/OpenBB"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" height="20"&gt; &lt;/a&gt; &lt;a target="_blank" href="https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/openbb/"&gt;&lt;img src="https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package" alt="PyPI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The first financial Platform that is open source.&lt;/p&gt; 
&lt;p&gt;The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.&lt;/p&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openbb import obb
output = obb.equity.price.historical("AAPL")
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can sign up to the &lt;a href="https://my.openbb.co/login"&gt;OpenBB Hub&lt;/a&gt; to get the most out of the OpenBB ecosystem.&lt;/p&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href="https://docs.openbb.co/platform/reference"&gt;https://docs.openbb.co/platform/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.&lt;/p&gt; 
&lt;p&gt;If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;a href="https://pro.openbb.co"&gt;https://pro.openbb.co&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png" alt="Logo" width="1000"&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href="https://docs.openbb.co/workspace"&gt;docs&lt;/a&gt; or &lt;a href="https://github.com/OpenBB-finance/backends-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href="https://github.com/OpenBB-finance/agents-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating OpenBB Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run OpenBB Platform backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "openbb[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate OpenBB Platform backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href="https://pro.openbb.co/"&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069" alt="CleanShot 2025-05-17 at 09 51 56@2x"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the "Apps" tab&lt;/li&gt; 
 &lt;li&gt;Click on "Connect backend"&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: OpenBB Platform URL: &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on "Test". You should get a "Test successful" with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on "Add".&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it.&lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed="closed"&gt; 
 &lt;summary&gt;&lt;h2 style="display: inline-block"&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts"&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The OpenBB Platform can be installed as a &lt;a href="https://pypi.org/project/openbb/"&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href="https://docs.openbb.co/platform/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenBB Platform CLI installation&lt;/h3&gt; 
&lt;p&gt;The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href="https://docs.openbb.co/cli/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now â­ï¸)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href="https://docs.openbb.co/platform/developer_guide/misc/contributing"&gt;Contributing Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn't exist already &lt;a href="https://github.com/OpenBB-finance/OpenBB/issues"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D"&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D"&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href="https://openbb.co/discord"&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href="https://openbb.co/links"&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the OpenBB Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href="https://openbb.co/links"&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href="https://openbb.co/open"&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB" width="800"&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>BerriAI/litellm</title>
      <link>https://github.com/BerriAI/litellm</link>
      <description>&lt;p&gt;Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; ğŸš… LiteLLM &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://render.com/deploy?repo=https://github.com/BerriAI/litellm" target="_blank" rel="nofollow"&gt;&lt;img src="https://render.com/images/deploy-to-render-button.svg?sanitize=true" alt="Deploy to Render"&gt;&lt;/a&gt; &lt;a href="https://railway.app/template/HLP0Ub?referralCode=jch2ME"&gt; &lt;img src="https://railway.app/button.svg?sanitize=true" alt="Deploy on Railway"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.] &lt;br&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt;&lt;a href="https://docs.litellm.ai/docs/simple_proxy" target="_blank"&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt; | &lt;a href="https://docs.litellm.ai/docs/hosted" target="_blank"&gt; Hosted Proxy (Preview)&lt;/a&gt; | &lt;a href="https://docs.litellm.ai/docs/enterprise" target="_blank"&gt;Enterprise Tier&lt;/a&gt;&lt;/h4&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://pypi.org/project/litellm/" target="_blank"&gt; &lt;img src="https://img.shields.io/pypi/v/litellm.svg?sanitize=true" alt="PyPI Version"&gt; &lt;/a&gt; &lt;a href="https://www.ycombinator.com/companies/berriai"&gt; &lt;img src="https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square" alt="Y Combinator W23"&gt; &lt;/a&gt; &lt;a href="https://wa.link/huol9n"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=WhatsApp&amp;amp;color=success&amp;amp;logo=WhatsApp&amp;amp;style=flat-square" alt="Whatsapp"&gt; &lt;/a&gt; &lt;a href="https://discord.gg/wuPM9dRgDw"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Discord&amp;amp;color=blue&amp;amp;logo=Discord&amp;amp;style=flat-square" alt="Discord"&gt; &lt;/a&gt; &lt;a href="https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Slack&amp;amp;color=black&amp;amp;logo=Slack&amp;amp;style=flat-square" alt="Slack"&gt; &lt;/a&gt; &lt;/h4&gt; 
&lt;p&gt;LiteLLM manages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Translate inputs to provider's &lt;code&gt;completion&lt;/code&gt;, &lt;code&gt;embedding&lt;/code&gt;, and &lt;code&gt;image_generation&lt;/code&gt; endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/completion/output"&gt;Consistent output&lt;/a&gt;, text responses will always be available at &lt;code&gt;['choices'][0]['message']['content']&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - &lt;a href="https://docs.litellm.ai/docs/routing"&gt;Router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Set Budgets &amp;amp; Rate limits per project, api key, model &lt;a href="https://docs.litellm.ai/docs/simple_proxy"&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs"&gt;&lt;strong&gt;Jump to LiteLLM Proxy (LLM Gateway) Docs&lt;/strong&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs"&gt;&lt;strong&gt;Jump to Supported LLM Providers&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸš¨ &lt;strong&gt;Stable Release:&lt;/strong&gt; Use docker images with the &lt;code&gt;-stable&lt;/code&gt; tag. These have undergone 12 hour load tests, before being published. &lt;a href="https://docs.litellm.ai/docs/proxy/release_cycle"&gt;More information about the release cycle here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Support for more providers. Missing a provider or LLM Platform, raise a &lt;a href="https://github.com/BerriAI/litellm/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;projects=&amp;amp;template=feature_request.yml&amp;amp;title=%5BFeature%5D%3A+"&gt;feature request&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Usage (&lt;a href="https://docs.litellm.ai/docs/"&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt;)&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] LiteLLM v1.0.0 now requires &lt;code&gt;openai&amp;gt;=1.0.0&lt;/code&gt;. Migration guide &lt;a href="https://docs.litellm.ai/docs/migration"&gt;here&lt;/a&gt;&lt;br&gt; LiteLLM v1.40.14+ now requires &lt;code&gt;pydantic&amp;gt;=2.0.0&lt;/code&gt;. No changes required.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a target="_blank" href="https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt; &lt;/a&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install litellm
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion
import os

## set ENV variables
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["ANTHROPIC_API_KEY"] = "your-anthropic-key"

messages = [{ "content": "Hello, how are you?","role": "user"}]

# openai call
response = completion(model="openai/gpt-4o", messages=messages)

# anthropic call
response = completion(model="anthropic/claude-sonnet-4-20250514", messages=messages)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "id": "chatcmpl-1214900a-6cdd-4148-b663-b5e2f642b4de",
    "created": 1751494488,
    "model": "claude-sonnet-4-20250514",
    "object": "chat.completion",
    "system_fingerprint": null,
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "Hello! I'm doing well, thank you for asking. I'm here and ready to help with whatever you'd like to discuss or work on. How are you doing today?",
                "role": "assistant",
                "tool_calls": null,
                "function_call": null
            }
        }
    ],
    "usage": {
        "completion_tokens": 39,
        "prompt_tokens": 13,
        "total_tokens": 52,
        "completion_tokens_details": null,
        "prompt_tokens_details": {
            "audio_tokens": null,
            "cached_tokens": 0
        },
        "cache_creation_input_tokens": 0,
        "cache_read_input_tokens": 0
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Call any model supported by a provider, with &lt;code&gt;model=&amp;lt;provider_name&amp;gt;/&amp;lt;model_name&amp;gt;&lt;/code&gt;. There might be provider-specific details here, so refer to &lt;a href="https://docs.litellm.ai/docs/providers"&gt;provider docs for more information&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Async (&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-completion"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import acompletion
import asyncio

async def test_get_response():
    user_message = "Hello, how are you?"
    messages = [{"content": user_message, "role": "user"}]
    response = await acompletion(model="openai/gpt-4o", messages=messages)
    return response

response = asyncio.run(test_get_response())
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Streaming (&lt;a href="https://docs.litellm.ai/docs/completion/stream"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;liteLLM supports streaming the model response back, pass &lt;code&gt;stream=True&lt;/code&gt; to get a streaming iterator in response.&lt;br&gt; Streaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion
response = completion(model="openai/gpt-4o", messages=messages, stream=True)
for part in response:
    print(part.choices[0].delta.content or "")

# claude sonnet 4
response = completion('anthropic/claude-sonnet-4-20250514', messages, stream=True)
for part in response:
    print(part)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response chunk (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "id": "chatcmpl-fe575c37-5004-4926-ae5e-bfbc31f356ca",
    "created": 1751494808,
    "model": "claude-sonnet-4-20250514",
    "object": "chat.completion.chunk",
    "system_fingerprint": null,
    "choices": [
        {
            "finish_reason": null,
            "index": 0,
            "delta": {
                "provider_specific_fields": null,
                "content": "Hello",
                "role": "assistant",
                "function_call": null,
                "tool_calls": null,
                "audio": null
            },
            "logprobs": null
        }
    ],
    "provider_specific_fields": null,
    "stream_options": null,
    "citations": null
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging Observability (&lt;a href="https://docs.litellm.ai/docs/observability/callbacks"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;LiteLLM exposes pre defined callbacks to send data to Lunary, MLflow, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion

## set env variables for logging tools (when using MLflow, no API key set up is required)
os.environ["LUNARY_PUBLIC_KEY"] = "your-lunary-public-key"
os.environ["HELICONE_API_KEY"] = "your-helicone-auth-key"
os.environ["LANGFUSE_PUBLIC_KEY"] = ""
os.environ["LANGFUSE_SECRET_KEY"] = ""
os.environ["ATHINA_API_KEY"] = "your-athina-api-key"

os.environ["OPENAI_API_KEY"] = "your-openai-key"

# set callbacks
litellm.success_callback = ["lunary", "mlflow", "langfuse", "athina", "helicone"] # log input/output to lunary, langfuse, supabase, athina, helicone etc

#openai call
response = completion(model="openai/gpt-4o", messages=[{"role": "user", "content": "Hi ğŸ‘‹ - i'm openai"}])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;LiteLLM Proxy Server (LLM Gateway) - (&lt;a href="https://docs.litellm.ai/docs/simple_proxy"&gt;Docs&lt;/a&gt;)&lt;/h1&gt; 
&lt;p&gt;Track spend + Load Balance across multiple projects&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/hosted"&gt;Hosted Proxy (Preview)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The proxy provides:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth"&gt;Hooks for auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class"&gt;Hooks for logging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend"&gt;Cost tracking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/users#set-rate-limits"&gt;Rate Limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ“– Proxy Endpoints - &lt;a href="https://litellm-api.up.railway.app/"&gt;Swagger Docs&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Quick Start Proxy - CLI&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install 'litellm[proxy]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 1: Start litellm proxy&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ litellm --model huggingface/bigcode/starcoder

#INFO: Proxy running on http://0.0.0.0:4000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Make ChatCompletions Request to Proxy&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] ğŸ’¡ &lt;a href="https://docs.litellm.ai/docs/proxy/user_keys"&gt;Use LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import openai # openai v1.0.0+
client = openai.OpenAI(api_key="anything",base_url="http://0.0.0.0:4000") # set proxy to base_url
# request sent to model set on litellm proxy, `litellm --model`
response = client.chat.completions.create(model="gpt-3.5-turbo", messages = [
    {
        "role": "user",
        "content": "this is a test request, write a short poem"
    }
])

print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Proxy Key Management (&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;Connect the proxy with a Postgres DB to create proxy keys&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Get the code
git clone https://github.com/BerriAI/litellm

# Go to folder
cd litellm

# Add the master key - you can change this after setup
echo 'LITELLM_MASTER_KEY="sk-1234"' &amp;gt; .env

# Add the litellm salt key - you cannot change this after adding a model
# It is used to encrypt / decrypt your LLM API Key credentials
# We recommend - https://1password.com/password-generator/ 
# password generator to get a random hash for litellm salt key
echo 'LITELLM_SALT_KEY="sk-1234"' &amp;gt;&amp;gt; .env

source .env

# Start
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;UI on &lt;code&gt;/ui&lt;/code&gt; on your proxy server &lt;img src="https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033" alt="ui_3"&gt;&lt;/p&gt; 
&lt;p&gt;Set budgets and rate limits across multiple projects &lt;code&gt;POST /key/generate&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Request&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl 'http://0.0.0.0:4000/key/generate' \
--header 'Authorization: Bearer sk-1234' \
--header 'Content-Type: application/json' \
--data-raw '{"models": ["gpt-3.5-turbo", "gpt-4", "claude-2"], "duration": "20m","metadata": {"user": "ishaan@berri.ai", "team": "core-infra"}}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Expected Response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;{
    "key": "sk-kdEXbIqZRwEeEiHwdg7sFA", # Bearer token
    "expires": "2023-11-19T01:38:25.838000+00:00" # datetime object
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported Providers (&lt;a href="https://docs.litellm.ai/docs/providers"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/#basic-usage"&gt;Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#streaming-responses"&gt;Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-completion"&gt;Async Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-streaming"&gt;Async Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/embedding/supported_embedding"&gt;Async Embedding&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/image_generation"&gt;Async Image Generation&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/openai"&gt;openai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/meta_llama"&gt;Meta - Llama API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/azure"&gt;azure&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aiml"&gt;AI/ML API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aws_sagemaker"&gt;aws - sagemaker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/bedrock"&gt;aws - bedrock&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/vertex"&gt;google - vertex_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/palm"&gt;google - palm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/gemini"&gt;google AI Studio - gemini&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/mistral"&gt;mistral ai api&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/cloudflare_workers"&gt;cloudflare AI Workers&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/cohere"&gt;cohere&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/anthropic"&gt;anthropic&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/empower"&gt;empower&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/huggingface"&gt;huggingface&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/replicate"&gt;replicate&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/togetherai"&gt;together_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/openrouter"&gt;openrouter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/ai21"&gt;ai21&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/baseten"&gt;baseten&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/vllm"&gt;vllm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/nlp_cloud"&gt;nlp_cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aleph_alpha"&gt;aleph alpha&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/petals"&gt;petals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/ollama"&gt;ollama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/deepinfra"&gt;deepinfra&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/perplexity"&gt;perplexity-ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/groq"&gt;Groq AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/deepseek"&gt;Deepseek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/anyscale"&gt;anyscale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/watsonx"&gt;IBM - watsonx.ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/voyage"&gt;voyage ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/xinference"&gt;xinference [Xorbits Inference]&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/friendliai"&gt;FriendliAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/galadriel"&gt;Galadriel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://novita.ai/models/llm?utm_source=github_litellm&amp;amp;utm_medium=github_readme&amp;amp;utm_campaign=github_link"&gt;Novita AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/featherless_ai"&gt;Featherless AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/nebius"&gt;Nebius AI Studio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/"&gt;&lt;strong&gt;Read the Docs&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing? Contributions to LiteLLM Python SDK, Proxy Server, and LLM integrations are both accepted and highly encouraged!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick start:&lt;/strong&gt; &lt;code&gt;git clone&lt;/code&gt; â†’ &lt;code&gt;make install-dev&lt;/code&gt; â†’ &lt;code&gt;make format&lt;/code&gt; â†’ &lt;code&gt;make lint&lt;/code&gt; â†’ &lt;code&gt;make test-unit&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;See our comprehensive &lt;a href="https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md"&gt;Contributing Guide (CONTRIBUTING.md)&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h1&gt;Enterprise&lt;/h1&gt; 
&lt;p&gt;For companies that need better security, user management and professional support&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat"&gt;Talk to founders&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This covers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;Features under the &lt;a href="https://docs.litellm.ai/docs/proxy/enterprise"&gt;LiteLLM Commercial License&lt;/a&gt;:&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;Feature Prioritization&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;Custom Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;Professional Support - Dedicated discord + slack&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;Custom SLAs&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;Secure access with Single Sign-On&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome contributions to LiteLLM! Whether you're fixing bugs, adding features, or improving documentation, we appreciate your help.&lt;/p&gt; 
&lt;h2&gt;Quick Start for Contributors&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/BerriAI/litellm.git
cd litellm
make install-dev    # Install development dependencies
make format         # Format your code
make lint           # Run all linting checks
make test-unit      # Run unit tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed contributing guidelines, see &lt;a href="https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Code Quality / Linting&lt;/h2&gt; 
&lt;p&gt;LiteLLM follows the &lt;a href="https://google.github.io/styleguide/pyguide.html"&gt;Google Python Style Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Our automated checks include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Black&lt;/strong&gt; for code formatting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ruff&lt;/strong&gt; for linting and code quality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MyPy&lt;/strong&gt; for type checking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Circular import detection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import safety checks&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run all checks locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make lint           # Run all linting (matches CI)
make format-check   # Check formatting only
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;All these checks must pass before your PR can be merged.&lt;/p&gt; 
&lt;h1&gt;Support / talk with founders&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version"&gt;Schedule Demo ğŸ‘‹&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/wuPM9dRgDw"&gt;Community Discord ğŸ’­&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3"&gt;Community Slack ğŸ’­&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Our numbers ğŸ“ +1 (770) 8783-106 / â€­+1 (412) 618-6238â€¬&lt;/li&gt; 
 &lt;li&gt;Our emails âœ‰ï¸ &lt;a href="mailto:ishaan@berri.ai"&gt;ishaan@berri.ai&lt;/a&gt; / &lt;a href="mailto:krrish@berri.ai"&gt;krrish@berri.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Why did we build this&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Need for simplicity&lt;/strong&gt;: Our code started to get extremely complicated managing &amp;amp; translating calls between Azure, OpenAI and Cohere.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;a href="https://github.com/BerriAI/litellm/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=BerriAI/litellm"&gt; &lt;/a&gt; 
&lt;h2&gt;Run in Developer mode&lt;/h2&gt; 
&lt;h3&gt;Services&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Setup .env file in root&lt;/li&gt; 
 &lt;li&gt;Run dependant services &lt;code&gt;docker-compose up db prometheus&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Backend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;(In root) create virtual environment &lt;code&gt;python -m venv .venv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Activate virtual environment &lt;code&gt;source .venv/bin/activate&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;pip install -e ".[all]"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Start proxy backend &lt;code&gt;uvicorn litellm.proxy.proxy_server:app --host localhost --port 4000 --reload&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;ui/litellm-dashboard&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm run dev&lt;/code&gt; to start the dashboard&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>srbhr/Resume-Matcher</title>
      <link>https://github.com/srbhr/Resume-Matcher</link>
      <description>&lt;p&gt;Improve your resumes with Resume Matcher. Get insights, keyword suggestions and tune your resumes to job descriptions.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.resumematcher.fyi"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/page_2.png" alt="Resume Matcher"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;Resume Matcher&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://dsc.gg/resume-matcher"&gt;ğ™¹ğš˜ğš’ğš— ğ™³ğš’ğšœğšŒğš˜ğš›ğš&lt;/a&gt; âœ¦ &lt;a href="https://resumematcher.fyi"&gt;ğš†ğšğš‹ğšœğš’ğšğš&lt;/a&gt; âœ¦ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#how-to-install"&gt;ğ™·ğš˜ğš  ğšğš˜ ğ™¸ğš—ğšœğšğšŠğš•ğš• &lt;/a&gt; âœ¦ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#contributors"&gt;ğ™²ğš˜ğš—ğšğš›ğš’ğš‹ğšğšğš˜ğš›ğšœ&lt;/a&gt; âœ¦ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#support-the-development-by-donating"&gt;ğ™³ğš˜ğš—ğšŠğšğš&lt;/a&gt; âœ¦ &lt;a href="https://twitter.com/_srbhr_"&gt;ğšƒğš ğš’ğšğšğšğš›/ğš‡&lt;/a&gt; âœ¦ &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;ğ™»ğš’ğš—ğš”ğšğšğ™¸ğš—&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Stop getting auto-rejected by ATS bots.&lt;/strong&gt; Resume Matcher is the AI-powered platform that reverse-engineers hiring algorithms to show you exactly how to tailor your resume. Get the keywords, formatting, and insights that actually get you past the first screen and into human hands.&lt;/p&gt; 
 &lt;p&gt;Hoping to make this, &lt;strong&gt;VS Code for making resumes&lt;/strong&gt;.&lt;/p&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Stars"&gt; &lt;img src="https://img.shields.io/github/license/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Apache 2.0"&gt; &lt;img src="https://img.shields.io/github/forks/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Forks"&gt; &lt;img src="https://img.shields.io/badge/Version-0.1%20Veridis%20Quo-FFF?labelColor=black&amp;amp;logo=LinkedIn&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="version"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://dsc.gg/resume-matcher"&gt;&lt;img src="https://img.shields.io/discord/1122069176962531400?labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=c20a71&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://resumematcher.fyi"&gt;&lt;img src="https://img.shields.io/badge/website-Resume%20Matcher-FFF?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Website"&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-Resume%20Matcher-FFF?labelColor=black&amp;amp;logo=LinkedIn&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="LinkedIn"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/565" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/565" alt="srbhr%2FResume-Matcher | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;This project is in active development. New features are being added continuously, and we welcome contributions from the community. There are some breaking changes on the &lt;code&gt;main&lt;/code&gt; branch. If you have any suggestions or feature requests, please feel free to open an issue on GitHub or discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started with Resume Matcher&lt;/h2&gt; 
&lt;p&gt;Resume Matcher is designed to help you optimize your resume with the aim to highlight your skills and experience in a way that resonates with potential employers.&lt;/p&gt; 
&lt;p&gt;We're working on actively improving the platform, towards building a &lt;strong&gt;VS Code for making resumes&lt;/strong&gt;, and adding new features. The best way to stay updated is to join the discord discussion and be part of the active development community.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Join our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; community ğŸ‘‡ &lt;a href="https://dsc.gg/resume-matcher"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_discord.png" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Follow us on &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;LinkedIn&lt;/a&gt; âœ¨ &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_linkedin.png" alt="LinkedIn"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;â­ Star Resume Matcher to support the development and get updates on GitHub. &lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/star_resume_matcher.png" alt="Star Resume Matcher"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_features.png" alt="resume_matcher_features"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Works locally&lt;/strong&gt;: No need to upload your resume to a server. Everything runs on your machine with open source AI models by Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ATS Compatibility&lt;/strong&gt;: Get a detailed analysis of your resume's compatibility with ATS systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instant Match Score&lt;/strong&gt;: Upload resume &amp;amp; job description for a quick match score and key improvement areas.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Keyword Optimizer&lt;/strong&gt;: Align your resume with job keywords and identify critical content gaps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Guided Improvements&lt;/strong&gt;: Get clear suggestions to make your resume stand out.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Roadmap&lt;/h3&gt; 
&lt;p&gt;If you have any suggestions or feature requests, please feel free to open an issue on GitHub. And discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visual keyword highlighting.&lt;/li&gt; 
 &lt;li&gt;AI Canvas, which can help to craft impactful, metric-driven resume content.&lt;/li&gt; 
 &lt;li&gt;Multi-job description optimization.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/how_to_install_resumematcher.png" alt="Installation"&gt;&lt;/p&gt; 
&lt;p&gt;Follow the instructions in the &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/SETUP.md"&gt;SETUP.md&lt;/a&gt; file to set up the project locally. The setup script will install all the necessary dependencies and configure your environment.&lt;/p&gt; 
&lt;p&gt;The project is built using:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;FastAPI for the backend.&lt;/li&gt; 
 &lt;li&gt;Next.js for the frontend.&lt;/li&gt; 
 &lt;li&gt;Ollama for local AI model serving.&lt;/li&gt; 
 &lt;li&gt;Tailwind CSS for styling.&lt;/li&gt; 
 &lt;li&gt;SQLite for the database.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Technology&lt;/th&gt; 
   &lt;th&gt;Info/Version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;3.12+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Next.js&lt;/td&gt; 
   &lt;td&gt;15+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;0.6.7&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Join Us and Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/how_to_contribute.png" alt="how to contribute"&gt;&lt;/p&gt; 
&lt;p&gt;We welcome contributions from everyone! Whether you're a developer, designer, or just someone who wants to help out. All the contributors are listed in the &lt;a href="https://resumematcher.fyi/about"&gt;about page&lt;/a&gt; on our website and on the GitHub Readme here.&lt;/p&gt; 
&lt;p&gt;Checkout the roadmap if you would like to work on the features that are planned for the future. If you have any suggestions or feature requests, please feel free to open an issue on GitHub. And discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/contributors.png" alt="Contributors"&gt;&lt;/p&gt; 
&lt;a href="https://github.com/srbhr/Resume-Matcher/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=srbhr/Resume-Matcher"&gt; &lt;/a&gt; 
&lt;h2&gt;Support the Development by Donating&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/supporting_resume_matcher.png" alt="donate"&gt;&lt;/p&gt; 
&lt;p&gt;If you would like to support the development of Resume Matcher, you can do so by donating. Your contributions will help us keep the project alive and continue adding new features.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GitHub&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/sponsors/srbhr"&gt;&lt;img src="https://img.shields.io/github/sponsors/srbhr?style=for-the-badge&amp;amp;color=c20a71&amp;amp;labelColor=black&amp;amp;logo=github" alt="GitHub Sponsors"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Buy Me a Coffee&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.buymeacoffee.com/srbhr"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;color=c20a72&amp;amp;logoColor=white" alt="BuyMeACoffee"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;amp;theme=dark&amp;amp;type=Date"&gt; 
  &lt;img width="100%" src="https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;amp;theme=dark&amp;amp;type=Date"&gt; 
 &lt;/picture&gt; 
&lt;/details&gt; 
&lt;h2&gt;Resume Matcher is a part of &lt;a href="https://vercel.com/oss"&gt;Vercel Open Source Program&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://vercel.com/oss/program-badge.svg?sanitize=true" alt="Vercel OSS Program"&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>daveebbelaar/ai-cookbook</title>
      <link>https://github.com/daveebbelaar/ai-cookbook</link>
      <description>&lt;p&gt;Examples and tutorials to help developers build AI systems&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;This Cookbook contains examples and tutorials to help developers build AI systems, offering copy/paste code snippets that you can easily integrate into your own projects.&lt;/p&gt; 
&lt;h2&gt;About Me&lt;/h2&gt; 
&lt;p&gt;Hi! I'm Dave, AI Engineer and founder of DataluminaÂ®. On my &lt;a href="https://www.youtube.com/@daveebbelaar?sub_confirmation=1"&gt;YouTube channel&lt;/a&gt;, I share practical tutorials that teach developers how to build AI systems that actually work in the real world. Beyond these tutorials, I also help people start successful freelancing careers. Check out the links below to learn more!&lt;/p&gt; 
&lt;h3&gt;Explore More Resources&lt;/h3&gt; 
&lt;p&gt;Whether you're a learner, a freelancer, or a business looking for AI expertise, we've got something for you:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Learning Python for AI and Data Science?&lt;/strong&gt;&lt;br&gt; Join our &lt;strong&gt;free community, Data Alchemy&lt;/strong&gt;, where you'll find resources, tutorials, and support&lt;br&gt; â–¶ï¸ &lt;a href="https://www.skool.com/data-alchemy"&gt;Learn Python for AI&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ready to start or scale your freelancing career?&lt;/strong&gt;&lt;br&gt; Learn how to land clients and grow your business&lt;br&gt; â–¶ï¸ &lt;a href="https://www.datalumina.com/data-freelancer"&gt;Find freelance projects&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Need expert help on your next project?&lt;/strong&gt;&lt;br&gt; Work with me and my team to solve your data and AI challenges&lt;br&gt; â–¶ï¸ &lt;a href="https://www.datalumina.com/solutions"&gt;Work with me&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Already building AI applications?&lt;/strong&gt;&lt;br&gt; Explore the &lt;strong&gt;GenAI Launchpad&lt;/strong&gt;, our production framework for AI systems&lt;br&gt; â–¶ï¸ &lt;a href="https://launchpad.datalumina.com/"&gt;Explore the GenAI Launchpad&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>Shubhamsaboo/awesome-llm-apps</title>
      <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
      <description>&lt;p&gt;Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="http://www.theunwindai.com"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/unwind_black.png" width="900px" alt="Unwind AI"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/in/shubhamsaboo/"&gt; &lt;img src="https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;amp;style=flat-square" alt="LinkedIn"&gt; &lt;/a&gt; &lt;a href="https://twitter.com/Saboo_Shubham_"&gt; &lt;img src="https://img.shields.io/twitter/follow/Shubham_Saboo" alt="Twitter"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es"&gt;EspaÃ±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr"&gt;franÃ§ais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt"&gt;PortuguÃªs&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru"&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh"&gt;ä¸­æ–‡&lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;h1&gt;ğŸŒŸ Awesome LLM Apps&lt;/h1&gt; 
&lt;p&gt;A curated collection of &lt;strong&gt;Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.&lt;/strong&gt; This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/9876" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/9876" alt="Shubhamsaboo%2Fawesome-llm-apps | Trendshift" style="width: 250px; height: 55px;"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;ğŸ¤” Why Awesome LLM Apps?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ’¡ Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.&lt;/li&gt; 
 &lt;li&gt;ğŸ”¥ Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp;amp; RAG.&lt;/li&gt; 
 &lt;li&gt;ğŸ“ Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“‚ Featured AI Projects&lt;/h2&gt; 
&lt;h3&gt;AI Agents&lt;/h3&gt; 
&lt;h3&gt;ğŸŒ± Starter AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_blog_to_podcast_agent/"&gt;ğŸ™ï¸ AI Blog to Podcast Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_breakup_recovery_agent/"&gt;â¤ï¸â€ğŸ©¹ AI Breakup Recovery Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_data_analysis_agent/"&gt;ğŸ“Š AI Data Analysis Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_medical_imaging_agent/"&gt;ğŸ©» AI Medical Imaging Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_meme_generator_agent_browseruse/"&gt;ğŸ˜‚ AI Meme Generator Agent (Browser)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_music_generator_agent/"&gt;ğŸµ AI Music Generator Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_travel_agent/"&gt;ğŸ›« AI Travel Agent (Local &amp;amp; Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/gemini_multimodal_agent_demo/"&gt;âœ¨ Gemini Multimodal Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/local_news_agent_openai_swarm/"&gt;ğŸŒ Local News Agent (OpenAI Swarm)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/mixture_of_agents/"&gt;ğŸ”„ Mixture of Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/xai_finance_agent/"&gt;ğŸ“Š xAI Finance Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/opeani_research_agent/"&gt;ğŸ” OpenAI Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/web_scrapping_ai_agent/"&gt;ğŸ•¸ï¸ Web Scrapping AI Agent (Local &amp;amp; Cloud)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸš€ Advanced AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_deep_research_agent/"&gt;ğŸ” AI Deep Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_consultant_agent"&gt;ğŸ¤ AI Consultant Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_system_architect_r1/"&gt;ğŸ—ï¸ AI System Architect Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/"&gt;ğŸ¯ AI Lead Generation Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/"&gt;ğŸ’° AI Financial Coach Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_movie_production_agent/"&gt;ğŸ¬ AI Movie Production Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_investment_agent/"&gt;ğŸ“ˆ AI Investment Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/"&gt;ğŸ‹ï¸â€â™‚ï¸ AI Health &amp;amp; Fitness Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent"&gt;ğŸš€ AI Product Launch Intelligence Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_journalist_agent/"&gt;ğŸ—ï¸ AI Journalist Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/"&gt;ğŸ§  AI Mental Wellbeing Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_meeting_agent/"&gt;ğŸ“‘ AI Meeting Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/"&gt;ğŸ§¬ AI Self-Evolving Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/"&gt;ğŸ§ AI Social Media News and Podcast Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ® Autonomous Game Playing Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/"&gt;ğŸ® AI 3D Pygame Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/"&gt;â™œ AI Chess Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/"&gt;ğŸ² AI Tic-Tac-Toe Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ¤ Multi-agent Teams&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/"&gt;ğŸ§² AI Competitor Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/"&gt;ğŸ’² AI Finance Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/"&gt;ğŸ¨ AI Game Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/"&gt;ğŸ‘¨â€âš–ï¸ AI Legal Agent Team (Cloud &amp;amp; Local)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/"&gt;ğŸ’¼ AI Recruitment Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/"&gt;ğŸ‘¨â€ğŸ’¼ AI Services Agency (CrewAI)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/"&gt;ğŸ‘¨â€ğŸ« AI Teaching Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/"&gt;ğŸ’» Multimodal Coding Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/"&gt;âœ¨ Multimodal Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/"&gt;ğŸŒ AI Travel Planner Agent Team&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ—£ï¸ Voice AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/ai_audio_tour_agent/"&gt;ğŸ—£ï¸ AI Audio Tour Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/customer_support_voice_agent/"&gt;ğŸ“ Customer Support Voice Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/voice_rag_openaisdk/"&gt;ğŸ”Š Voice RAG Agent (OpenAI SDK)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸŒ MCP AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/browser_mcp_agent/"&gt;â™¾ï¸ Browser MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/github_mcp_agent/"&gt;ğŸ™ GitHub MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/notion_mcp_agent"&gt;ğŸ“‘ Notion MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/ai_travel_planner_mcp_agent_team"&gt;ğŸŒ AI Travel Planner MCP Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ“€ RAG (Retrieval Augmented Generation)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag/"&gt;ğŸ”— Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag_with_reasoning/"&gt;ğŸ§ Agentic RAG with Reasoning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/ai_blog_search/"&gt;ğŸ“° AI Blog Search (RAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/autonomous_rag/"&gt;ğŸ” Autonomous RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/corrective_rag/"&gt;ğŸ”„ Corrective RAG (CRAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/deepseek_local_rag_agent/"&gt;ğŸ‹ Deepseek Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/gemini_agentic_rag/"&gt;ğŸ¤” Gemini Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/hybrid_search_rag/"&gt;ğŸ‘€ Hybrid Search RAG (Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/llama3.1_local_rag/"&gt;ğŸ”„ Llama 3.1 Local RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_hybrid_search_rag/"&gt;ğŸ–¥ï¸ Local Hybrid Search RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_rag_agent/"&gt;ğŸ¦™ Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag-as-a-service/"&gt;ğŸ§© RAG-as-a-Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_agent_cohere/"&gt;âœ¨ RAG Agent with Cohere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_chain/"&gt;â›“ï¸ Basic RAG Chain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_database_routing/"&gt;ğŸ“  RAG with Database Routing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/vision_rag/"&gt;ğŸ–¼ï¸ Vision RAG&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ’¾ LLM Apps with Memory Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/"&gt;ğŸ’¾ AI ArXiv Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/"&gt;ğŸ›©ï¸ AI Travel Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/"&gt;ğŸ’¬ Llama3 Stateful Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/"&gt;ğŸ“ LLM App with Personalized Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/"&gt;ğŸ—„ï¸ Local ChatGPT Clone with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/"&gt;ğŸ§  Multi-LLM Application with Shared Memory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ’¬ Chat with X Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_github/"&gt;ğŸ’¬ Chat with GitHub (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/"&gt;ğŸ“¨ Chat with Gmail&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/"&gt;ğŸ“„ Chat with PDF (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/"&gt;ğŸ“š Chat with Research Papers (ArXiv) (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/"&gt;ğŸ“ Chat with Substack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/"&gt;ğŸ“½ï¸ Chat with YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ”§ LLM Fine-tuning Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/"&gt;ğŸ”§ Llama 3.2 Fine-tuning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš€ Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Navigate to the desired project directory&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the required dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Follow the project-specific instructions&lt;/strong&gt; in each project's &lt;code&gt;README.md&lt;/code&gt; file to set up and run the app.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ¤ Contributing to Open Source&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new &lt;a href="https://github.com/Shubhamsaboo/awesome-llm-apps/issues"&gt;GitHub Issue&lt;/a&gt; or submit a pull request. Make sure to follow the existing project structure and include a detailed &lt;code&gt;README.md&lt;/code&gt; for each new app.&lt;/p&gt; 
&lt;h3&gt;Thank You, Community, for the Support! ğŸ™&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸŒŸ &lt;strong&gt;Donâ€™t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Genesis-Embodied-AI/Genesis</title>
      <link>https://github.com/Genesis-Embodied-AI/Genesis</link>
      <description>&lt;p&gt;A generative world for general-purpose robotics &amp; embodied AI learning.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/imgs/big_text.png" alt="Genesis"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/imgs/teaser.png" alt="Teaser"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/genesis-world/"&gt;&lt;img src="https://img.shields.io/pypi/v/genesis-world" alt="PyPI - Version"&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/genesis-world"&gt;&lt;img src="https://static.pepy.tech/badge/genesis-world" alt="PyPI Downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/issues"&gt;&lt;img src="https://img.shields.io/github/issues/Genesis-Embodied-AI/Genesis" alt="GitHub Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/Genesis-Embodied-AI/Genesis" alt="GitHub Discussions"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/nukCuhB47p"&gt;&lt;img src="https://img.shields.io/discord/1322086972302430269?logo=discord" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://drive.google.com/uc?export=view&amp;amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white" height="20" style="display:inline"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/English-d9d9d9" alt="README in English"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_FR.md"&gt;&lt;img src="https://img.shields.io/badge/Francais-d9d9d9" alt="README en FranÃ§ais"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_KR.md"&gt;&lt;img src="https://img.shields.io/badge/%ED%95%9C%EA%B5%AD%EC%96%B4-d9d9d9" alt="í•œêµ­ì–´ README"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_CN.md"&gt;&lt;img src="https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-d9d9d9" alt="ç®€ä½“ä¸­æ–‡ç‰ˆè‡ªè¿°æ–‡ä»¶"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_JA.md"&gt;&lt;img src="https://img.shields.io/badge/%E6%97%A5%E6%9C%AC%E8%AA%9E-d9d9d9" alt="æ—¥æœ¬èªç‰ˆ README"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Genesis&lt;/h1&gt; 
&lt;h2&gt;ğŸ”¥ News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025-07-02] The development of Genesis is now officially supported by &lt;a href="https://genesis-ai.company/"&gt;Genesis AI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025-01-09] We released a &lt;a href="https://github.com/zhouxian/genesis-speed-benchmark"&gt;detailed performance benchmarking and comparison report&lt;/a&gt; on Genesis, together with all the test scripts.&lt;/li&gt; 
 &lt;li&gt;[2025-01-08] Released v0.2.1 ğŸŠ ğŸ‰&lt;/li&gt; 
 &lt;li&gt;[2025-01-08] Created &lt;a href="https://discord.gg/nukCuhB47p"&gt;Discord&lt;/a&gt; and &lt;a href="https://drive.google.com/uc?export=view&amp;amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ"&gt;Wechat&lt;/a&gt; group.&lt;/li&gt; 
 &lt;li&gt;[2024-12-25] Added a &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#docker"&gt;docker&lt;/a&gt; including support for the ray-tracing renderer&lt;/li&gt; 
 &lt;li&gt;[2024-12-24] Added guidelines for &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/raw/main/.github/CONTRIBUTING.md"&gt;contributing to Genesis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#what-is-genesis"&gt;What is Genesis?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#quick-installation"&gt;Quick Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#contributing-to-genesis"&gt;Contributing to Genesis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#support"&gt;Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#license-and-acknowledgments"&gt;License and Acknowledgments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#associated-papers"&gt;Associated Papers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;What is Genesis?&lt;/h2&gt; 
&lt;p&gt;Genesis is a physics platform designed for general-purpose &lt;em&gt;Robotics/Embodied AI/Physical AI&lt;/em&gt; applications. It is simultaneously multiple things:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A &lt;strong&gt;universal physics engine&lt;/strong&gt; re-built from the ground up, capable of simulating a wide range of materials and physical phenomena.&lt;/li&gt; 
 &lt;li&gt;A &lt;strong&gt;lightweight&lt;/strong&gt;, &lt;strong&gt;ultra-fast&lt;/strong&gt;, &lt;strong&gt;pythonic&lt;/strong&gt;, and &lt;strong&gt;user-friendly&lt;/strong&gt; robotics simulation platform.&lt;/li&gt; 
 &lt;li&gt;A powerful and fast &lt;strong&gt;photo-realistic rendering system&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;A &lt;strong&gt;generative data engine&lt;/strong&gt; that transforms user-prompted natural language description into various modalities of data.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Powered by a universal physics engine re-designed and re-built from the ground up, Genesis integrates various physics solvers and their coupling into a unified framework. This core physics engine is further enhanced by a generative agent framework that operates at an upper level, aiming towards fully automated data generation for robotics and beyond.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Currently, we are open-sourcing the &lt;em&gt;underlying physics engine&lt;/em&gt; and the &lt;em&gt;simulation platform&lt;/em&gt;. Our &lt;em&gt;generative framework&lt;/em&gt; is a modular system that incorporates many different generative modules, each handling a certain range of data modalities, routed by a high level agent. Some of the modules integrated existing papers and some are still under submission. Access to our generative feature will be gradually rolled out in the near future. If you are interested, feel free to explore more in the &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#associated-papers"&gt;paper list&lt;/a&gt; below.&lt;/p&gt; 
&lt;p&gt;Genesis aims to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lower the barrier&lt;/strong&gt; to using physics simulations, making robotics research accessible to everyone. See our &lt;a href="https://genesis-world.readthedocs.io/en/latest/user_guide/overview/mission.html"&gt;mission statement&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unify diverse physics solvers&lt;/strong&gt; into a single framework to recreate the physical world with the highest fidelity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automate data generation&lt;/strong&gt;, reducing human effort and letting the data flywheel spin on its own.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Project Page: &lt;a href="https://genesis-embodied-ai.github.io/"&gt;https://genesis-embodied-ai.github.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Over 43 million FPS when simulating a Franka robotic arm with a single RTX 4090 (430,000 times faster than real-time).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-platform&lt;/strong&gt;: Runs on Linux, macOS, Windows, and supports multiple compute backends (CPU, Nvidia/AMD GPUs, Apple Metal).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integration of diverse physics solvers&lt;/strong&gt;: Rigid body, MPM, SPH, FEM, PBD, Stable Fluid.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wide range of material models&lt;/strong&gt;: Simulation and coupling of rigid bodies, liquids, gases, deformable objects, thin-shell objects, and granular materials.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compatibility with various robots&lt;/strong&gt;: Robotic arms, legged robots, drones, &lt;em&gt;soft robots&lt;/em&gt;, and support for loading &lt;code&gt;MJCF (.xml)&lt;/code&gt;, &lt;code&gt;URDF&lt;/code&gt;, &lt;code&gt;.obj&lt;/code&gt;, &lt;code&gt;.glb&lt;/code&gt;, &lt;code&gt;.ply&lt;/code&gt;, &lt;code&gt;.stl&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Photo-realistic rendering&lt;/strong&gt;: Native ray-tracing-based rendering.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Differentiability&lt;/strong&gt;: Genesis is designed to be fully differentiable. Currently, our MPM solver and Tool Solver support differentiability, with other solvers planned for future versions (starting with rigid &amp;amp; articulated body solver).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Physics-based tactile simulation&lt;/strong&gt;: Differentiable &lt;a href="https://github.com/Genesis-Embodied-AI/DiffTactile"&gt;tactile sensor simulation&lt;/a&gt; coming soon (expected in version 0.3.0).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User-friendliness&lt;/strong&gt;: Designed for simplicity, with intuitive installation and APIs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Installation&lt;/h2&gt; 
&lt;p&gt;Install &lt;strong&gt;PyTorch&lt;/strong&gt; first following the &lt;a href="https://pytorch.org/get-started/locally/"&gt;official instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Then, install Genesis via PyPI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install genesis-world  # Requires Python&amp;gt;=3.10,&amp;lt;3.13;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the latest version to date, make sure that &lt;code&gt;pip&lt;/code&gt; is up-to-date via &lt;code&gt;pip install --upgrade pip&lt;/code&gt;, then run command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/Genesis-Embodied-AI/Genesis.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the package must still be updated manually to sync with main branch.&lt;/p&gt; 
&lt;p&gt;Users seeking to edit the source code of Genesis are encourage to install Genesis in editable mode. First, make sure that &lt;code&gt;genesis-world&lt;/code&gt; has been uninstalled, then clone the repository and install locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Genesis-Embodied-AI/Genesis.git
cd Genesis
pip install -e ".[dev]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;If you want to use Genesis from Docker, you can first build the Docker image as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t genesis -f docker/Dockerfile docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the examples inside the docker image (mounted to &lt;code&gt;/workspace/examples&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;xhost +local:root # Allow the container to access the display

docker run --gpus all --rm -it \
-e DISPLAY=$DISPLAY \
-v /dev/dri:/dev/dri \
-v /tmp/.X11-unix/:/tmp/.X11-unix \
-v $PWD:/workspace \
genesis
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AMD users&lt;/h3&gt; 
&lt;p&gt;AMD users can use Genesis using the &lt;code&gt;docker/Dockerfile.amdgpu&lt;/code&gt; file, which is built by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker build -t genesis-amd -f docker/Dockerfile.amdgpu docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and can then be used by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xhost"&gt;docker run -it --network=host \
 --device=/dev/kfd \
 --device=/dev/dri \
 --group-add=video \
 --ipc=host \
 --cap-add=SYS_PTRACE \
 --security-opt seccomp=unconfined \
 --shm-size 8G \
 -v $PWD:/workspace \
 -e DISPLAY=$DISPLAY \
 genesis-amd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The examples will be accessible from &lt;code&gt;/workspace/examples&lt;/code&gt;. Note: AMD users should use the vulkan backend. This means you will need to call &lt;code&gt;gs.init(vulkan)&lt;/code&gt; to initialise Genesis.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Comprehensive documentation is available in &lt;a href="https://genesis-world.readthedocs.io/en/latest/user_guide/index.html"&gt;English&lt;/a&gt;, &lt;a href="https://genesis-world.readthedocs.io/zh-cn/latest/user_guide/index.html"&gt;Chinese&lt;/a&gt;, and &lt;a href="https://genesis-world.readthedocs.io/ja/latest/user_guide/index.html"&gt;Japanese&lt;/a&gt;. This includes detailed installation steps, tutorials, and API references.&lt;/p&gt; 
&lt;h2&gt;Contributing to Genesis&lt;/h2&gt; 
&lt;p&gt;The Genesis project is an open and collaborative effort. We welcome all forms of contributions from the community, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pull requests&lt;/strong&gt; for new features or bug fixes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug reports&lt;/strong&gt; through GitHub Issues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Suggestions&lt;/strong&gt; to improve Genesis's usability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Refer to our &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/raw/main/.github/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Report bugs or request features via GitHub &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/issues"&gt;Issues&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join discussions or ask questions on GitHub &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/discussions"&gt;Discussions&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License and Acknowledgments&lt;/h2&gt; 
&lt;p&gt;The Genesis source code is licensed under Apache 2.0.&lt;/p&gt; 
&lt;p&gt;Genesis's development has been made possible thanks to these open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taichi-dev/taichi"&gt;Taichi&lt;/a&gt;: High-performance cross-platform compute backend. Kudos to the Taichi team for their technical support!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zhouxian/FluidLab"&gt;FluidLab&lt;/a&gt;: Reference MPM solver implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/erizmr/SPH_Taichi"&gt;SPH_Taichi&lt;/a&gt;: Reference SPH solver implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://matthias-research.github.io/pages/tenMinutePhysics/index.html"&gt;Ten Minute Physics&lt;/a&gt; and &lt;a href="https://github.com/WASD4959/PBF3D"&gt;PBF3D&lt;/a&gt;: Reference PBD solver implementations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google-deepmind/mujoco"&gt;MuJoCo&lt;/a&gt;: Reference for rigid body dynamics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danfis/libccd"&gt;libccd&lt;/a&gt;: Reference for collision detection.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmatl/pyrender"&gt;PyRender&lt;/a&gt;: Rasterization-based renderer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuisaGroup/LuisaCompute"&gt;LuisaCompute&lt;/a&gt; and &lt;a href="https://github.com/LuisaGroup/LuisaRender"&gt;LuisaRender&lt;/a&gt;: Ray-tracing DSL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Associated Papers&lt;/h2&gt; 
&lt;p&gt;Genesis is a large scale effort that integrates state-of-the-art technologies of various existing and on-going research work into a single system. Here we include a non-exhaustive list of all the papers that contributed to the Genesis project in one way or another:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Xian, Zhou, et al. "Fluidlab: A differentiable environment for benchmarking complex fluid manipulation." arXiv preprint arXiv:2303.02346 (2023).&lt;/li&gt; 
 &lt;li&gt;Xu, Zhenjia, et al. "Roboninja: Learning an adaptive cutting policy for multi-material objects." arXiv preprint arXiv:2302.11553 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Yufei, et al. "Robogen: Towards unleashing infinite data for automated robot learning via generative simulation." arXiv preprint arXiv:2311.01455 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Tsun-Hsuan, et al. "Softzoo: A soft robot co-design benchmark for locomotion in diverse environments." arXiv preprint arXiv:2303.09555 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Tsun-Hsuan Johnson, et al. "Diffusebot: Breeding soft robots with physics-augmented generative diffusion models." Advances in Neural Information Processing Systems 36 (2023): 44398-44423.&lt;/li&gt; 
 &lt;li&gt;Katara, Pushkal, Zhou Xian, and Katerina Fragkiadaki. "Gen2sim: Scaling up robot learning in simulation with generative models." 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024.&lt;/li&gt; 
 &lt;li&gt;Si, Zilin, et al. "DiffTactile: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation." arXiv preprint arXiv:2403.08716 (2024).&lt;/li&gt; 
 &lt;li&gt;Wang, Yian, et al. "Thin-Shell Object Manipulations With Differentiable Physics Simulations." arXiv preprint arXiv:2404.00451 (2024).&lt;/li&gt; 
 &lt;li&gt;Lin, Chunru, et al. "UBSoft: A Simulation Platform for Robotic Skill Learning in Unbounded Soft Environments." arXiv preprint arXiv:2411.12711 (2024).&lt;/li&gt; 
 &lt;li&gt;Zhou, Wenyang, et al. "EMDM: Efficient motion diffusion model for fast and high-quality motion generation." European Conference on Computer Vision. Springer, Cham, 2025.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. "Scalable differentiable physics for learning and control." International Conference on Machine Learning. PMLR, 2020.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. "Efficient differentiable simulation of articulated bodies." In International Conference on Machine Learning, PMLR, 2021.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming Lin. "Differentiable simulation of soft multi-body systems." Advances in Neural Information Processing Systems 34 (2021).&lt;/li&gt; 
 &lt;li&gt;Wan, Weilin, et al. "Tlcontrol: Trajectory and language control for human motion synthesis." arXiv preprint arXiv:2311.17135 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Yian, et al. "Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical 2D Inpainting." arXiv preprint arXiv:2411.09823 (2024).&lt;/li&gt; 
 &lt;li&gt;Zheng, Shaokun, et al. "LuisaRender: A high-performance rendering framework with layered and unified interfaces on stream architectures." ACM Transactions on Graphics (TOG) 41.6 (2022): 1-19.&lt;/li&gt; 
 &lt;li&gt;Fan, Yingruo, et al. "Faceformer: Speech-driven 3d facial animation with transformers." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.&lt;/li&gt; 
 &lt;li&gt;Wu, Sichun, Kazi Injamamul Haque, and Zerrin Yumak. "ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE." Proceedings of the 17th ACM SIGGRAPH Conference on Motion, Interaction, and Games. 2024.&lt;/li&gt; 
 &lt;li&gt;Dou, Zhiyang, et al. "CÂ· ase: Learning conditional adversarial skill embeddings for physics-based characters." SIGGRAPH Asia 2023 Conference Papers. 2023.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;... and many more on-going work.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use Genesis in your research, please consider citing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{Genesis,
  author = {Genesis Authors},
  title = {Genesis: A Generative and Universal Physics Engine for Robotics and Beyond},
  month = {December},
  year = {2024},
  url = {https://github.com/Genesis-Embodied-AI/Genesis}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>