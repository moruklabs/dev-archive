<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Sat, 02 Aug 2025 01:34:47 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>TideDra/zotero-arxiv-daily</title>
      <link>https://github.com/TideDra/zotero-arxiv-daily</link>
      <description>&lt;p&gt;Recommend new arxiv papers of your interest daily according to your Zotero libarary.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="" rel="noopener"&gt; &lt;img width="200px" height="200px" src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/logo.svg?sanitize=true" alt="logo"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt;Zotero-arXiv-Daily&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href=""&gt;&lt;img src="https://img.shields.io/badge/status-active-success.svg?sanitize=true" alt="Status"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/TideDra/zotero-arxiv-daily?style=flat" alt="Stars"&gt; &lt;a href="https://github.com/TideDra/zotero-arxiv-daily/issues"&gt;&lt;img src="https://img.shields.io/github/issues/TideDra/zotero-arxiv-daily" alt="GitHub Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/TideDra/zotero-arxiv-daily/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/TideDra/zotero-arxiv-daily" alt="GitHub Pull Requests"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/TideDra/zotero-arxiv-daily" alt="License"&gt;&lt;/a&gt; &lt;a href="https://api.gitsponsors.com/api/badge/link?p=PKMtRut1dWWuC1oFdJweyDSvJg454/GkdIx4IinvBblaX2AY4rQ7FYKAK1ZjApoiNhYEeduIEhfeZVIwoIVlvcwdJXVFD2nV2EE5j6lYXaT/RHrcsQbFl3aKe1F3hliP26OMayXOoZVDidl05wj+yg=="&gt;&lt;img src="https://api.gitsponsors.com/api/badge/img?id=893025857" height="20"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p align="center"&gt; Recommend new arxiv papers of your interest daily according to your Zotero library. &lt;br&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Please keep an eye on this repo, and merge your forked repo in time when there is any update of this upstream, in order to enjoy new features and fix found bugs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üßê About &lt;a name="about"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Track new scientific researches of your interest by just forking (and staring) this repo!üòä&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;Zotero-arXiv-Daily&lt;/em&gt; finds arxiv papers that may attract you based on the context of your Zotero library, and then sends the result to your mailboxüìÆ. It can be deployed as Github Action Workflow with &lt;strong&gt;zero cost&lt;/strong&gt;, &lt;strong&gt;no installation&lt;/strong&gt;, and &lt;strong&gt;few configuration&lt;/strong&gt; of Github Action environment variables for daily &lt;strong&gt;automatic&lt;/strong&gt; delivery.&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Totally free! All the calculation can be done in the Github Action runner locally within its quota (for public repo).&lt;/li&gt; 
 &lt;li&gt;AI-generated TL;DR for you to quickly pick up target papers.&lt;/li&gt; 
 &lt;li&gt;Affiliations of the paper are resolved and presented.&lt;/li&gt; 
 &lt;li&gt;Links of PDF and code implementation (if any) presented in the e-mail.&lt;/li&gt; 
 &lt;li&gt;List of papers sorted by relevance with your recent research interest.&lt;/li&gt; 
 &lt;li&gt;Fast deployment via fork this repo and set environment variables in the Github Action Page.&lt;/li&gt; 
 &lt;li&gt;Support LLM API for generating TL;DR of papers.&lt;/li&gt; 
 &lt;li&gt;Ignore unwanted Zotero papers using gitignore-style pattern.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì∑ Screenshot&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/screenshot.png" alt="screenshot"&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Usage&lt;/h2&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Fork (and starüòò) this repo. &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/fork.png" alt="fork"&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set Github Action environment variables. &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/secrets.png" alt="secrets"&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Below are all the secrets you need to set. They are invisible to anyone including you once they are set, for security.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Key&lt;/th&gt; 
   &lt;th align="center"&gt;Required&lt;/th&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ZOTERO_ID&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;User ID of your Zotero account. &lt;strong&gt;User ID is not your username, but a sequence of numbers&lt;/strong&gt;Get your ID from &lt;a href="https://www.zotero.org/settings/security"&gt;here&lt;/a&gt;. You can find it at the position shown in this &lt;a href="https://github.com/TideDra/zotero-arxiv-daily/raw/main/assets/userid.png"&gt;screenshot&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;12345678&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ZOTERO_KEY&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;An Zotero API key with read access. Get a key from &lt;a href="https://www.zotero.org/settings/security"&gt;here&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;AB5tZ877P2j7Sm2Mragq041H&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ARXIV_QUERY&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The categories of target arxiv papers. Use &lt;code&gt;+&lt;/code&gt; to concatenate multiple categories. The example retrieves papers about AI, CV, NLP, ML. Find the abbr of your research area from &lt;a href="https://arxiv.org/category_taxonomy"&gt;here&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;cs.AI+cs.CV+cs.LG+cs.CL&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SMTP_SERVER&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The SMTP server that sends the email. I recommend to utilize a seldom-used email for this. Ask your email provider (Gmail, QQ, Outlook, ...) for its SMTP server&lt;/td&gt; 
   &lt;td align="left"&gt;smtp.qq.com&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SMTP_PORT&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;int&lt;/td&gt; 
   &lt;td align="left"&gt;The port of SMTP server.&lt;/td&gt; 
   &lt;td align="left"&gt;465&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SENDER&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The email account of the SMTP server that sends you email.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="mailto:abc@qq.com"&gt;abc@qq.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SENDER_PASSWORD&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The password of the sender account. Note that it's not necessarily the password for logging in the e-mail client, but the authentication code for SMTP service. Ask your email provider for this.&lt;/td&gt; 
   &lt;td align="left"&gt;abcdefghijklmn&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;RECEIVER&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The e-mail address that receives the paper list.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="mailto:abc@outlook.com"&gt;abc@outlook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MAX_PAPER_NUM&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;int&lt;/td&gt; 
   &lt;td align="left"&gt;The maximum number of the papers presented in the email. This value directly affects the execution time of this workflow, because it takes about 70s to generate TL;DR for one paper. &lt;code&gt;-1&lt;/code&gt; means to present all the papers retrieved.&lt;/td&gt; 
   &lt;td align="left"&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SEND_EMPTY&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;bool&lt;/td&gt; 
   &lt;td align="left"&gt;Whether to send an empty email even if no new papers today.&lt;/td&gt; 
   &lt;td align="left"&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;USE_LLM_API&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;bool&lt;/td&gt; 
   &lt;td align="left"&gt;Whether to use the LLM API in the cloud or to use local LLM. If set to &lt;code&gt;1&lt;/code&gt;, the API is used. Else if set to &lt;code&gt;0&lt;/code&gt;, the workflow will download and deploy an open-source LLM. Default to &lt;code&gt;0&lt;/code&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;OPENAI_API_KEY&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;API Key when using the API to access LLMs. You can get FREE API for using advanced open source LLMs in &lt;a href="https://cloud.siliconflow.cn/i/b3XhBRAm"&gt;SiliconFlow&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;sk-xxx&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;OPENAI_API_BASE&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;API URL when using the API to access LLMs. If not filled in, the default is the OpenAI URL.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.siliconflow.cn/v1"&gt;https://api.siliconflow.cn/v1&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MODEL_NAME&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;Model name when using the API to access LLMs. If not filled in, the default is gpt-4o. Qwen/Qwen2.5-7B-Instruct is recommended when using &lt;a href="https://cloud.siliconflow.cn/i/b3XhBRAm"&gt;SiliconFlow&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;Qwen/Qwen2.5-7B-Instruct&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;There are also some public variables (Repository Variables) you can set, which are easy to edit. &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/repo_var.png" alt="vars"&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Key&lt;/th&gt; 
   &lt;th align="left"&gt;Required&lt;/th&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ZOTERO_IGNORE&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;Gitignore-style patterns marking the Zotero collections that should be ignored. One rule one line. Learn more about &lt;a href="https://git-scm.com/docs/gitignore"&gt;gitignore&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;AI Agent/&lt;br&gt;**/survey&lt;br&gt;!LLM/survey&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;REPOSITORY&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The repository that provides the workflow. If set, the value can only be &lt;code&gt;TideDra/zotero-arxiv-daily&lt;/code&gt;, in which case, the workflow always pulls the latest code from this upstream repo, so that you don't need to sync your forked repo upon each update, unless the workflow file is changed.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TideDra/zotero-arxiv-daily&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;REF&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The specified ref of the workflow to run. Only valid when REPOSITORY is set to &lt;code&gt;TideDra/zotero-arxiv-daily&lt;/code&gt;. Currently supported values include &lt;code&gt;main&lt;/code&gt; for stable version, &lt;code&gt;dev&lt;/code&gt; for development version which has new features and potential bugs.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;main&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;LANGUAGE&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The language of TLDR; Its value is directly embeded in the prompt passed to LLM&lt;/td&gt; 
   &lt;td align="left"&gt;Chinese&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;That's all! Now you can test the workflow by manually triggering it: &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/test.png" alt="test"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The Test-Workflow Action is the debug version of the main workflow (Send-emails-daily), which always retrieve 5 arxiv papers regardless of the date. While the main workflow will be automatically triggered everyday and retrieve new papers released yesterday. There is no new arxiv paper at weekends and holiday, in which case you may see "No new papers found" in the log of main workflow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Then check the log and the receiver email after it finishes.&lt;/p&gt; 
&lt;p&gt;By default, the main workflow runs on 22:00 UTC everyday. You can change this time by editting the workflow config &lt;code&gt;.github/workflows/main.yml&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Local Running&lt;/h3&gt; 
&lt;p&gt;Supported by &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt;, this workflow can easily run on your local device if uv is installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# set all the environment variables
# export ZOTERO_ID=xxxx
# ...
cd zotero-arxiv-daily
uv run main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The workflow will download and run an LLM (Qwen2.5-3B, the file size of which is about 3G). Make sure your network and hardware can handle it.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Other package managers like pip or conda are not tested. You can still use them to install this workflow because there is a &lt;code&gt;pyproject.toml&lt;/code&gt;, while potential problems exist.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üöÄ Sync with the latest version&lt;/h2&gt; 
&lt;p&gt;This project is in active development. You can subscribe this repo via &lt;code&gt;Watch&lt;/code&gt; so that you can be notified once we publish new release.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/subscribe_release.png" alt="Watch"&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ How it works&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Zotero-arXiv-Daily&lt;/em&gt; firstly retrieves all the papers in your Zotero library and all the papers released in the previous day, via corresponding API. Then it calculates the embedding of each paper's abstract via an embedding model. The score of a paper is its weighted average similarity over all your Zotero papers (newer paper added to the library has higher weight).&lt;/p&gt; 
&lt;p&gt;The TLDR of each paper is generated by a lightweight LLM (Qwen2.5-3b-instruct-q4_k_m), given its title, abstract, introduction, and conclusion (if any). The introduction and conclusion are extracted from the source latex file of the paper.&lt;/p&gt; 
&lt;h2&gt;üìå Limitations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The recommendation algorithm is very simple, it may not accurately reflect your interest. Welcome better ideas for improving the algorithm!&lt;/li&gt; 
 &lt;li&gt;This workflow deploys an LLM on the cpu of Github Action runner, and it takes about 70s to generate a TLDR for one paper. High &lt;code&gt;MAX_PAPER_NUM&lt;/code&gt; can lead the execution time exceed the limitation of Github Action runner (6h per execution for public repo, and 2000 mins per month for private repo). Commonly, the quota given to public repo is definitely enough for individual use. If you have special requirements, you can deploy the workflow in your own server, or use a self-hosted Github Action runner, or pay for the exceeded execution time.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üëØ‚Äç‚ôÇÔ∏è Contribution&lt;/h2&gt; 
&lt;p&gt;Any issue and PR are welcomed! But remember that &lt;strong&gt;each PR should merge to the &lt;code&gt;dev&lt;/code&gt; branch&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;üìÉ License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;code&gt;LICENSE&lt;/code&gt; for detail.&lt;/p&gt; 
&lt;h2&gt;‚ù§Ô∏è Acknowledgement&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/urschrei/pyzotero"&gt;pyzotero&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lukasschwab/arxiv.py"&gt;arxiv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/UKPLab/sentence-transformers"&gt;sentence_transformers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abetlen/llama-cpp-python"&gt;llama-cpp-python&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚òï Buy Me A Coffee&lt;/h2&gt; 
&lt;p&gt;If you find this project helpful, welcome to sponsor me via WeChat or via &lt;a href="https://ko-fi.com/tidedra"&gt;ko-fi&lt;/a&gt;. &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/wechat_sponsor.JPG" alt="wechat_qr"&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#TideDra/zotero-arxiv-daily&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=TideDra/zotero-arxiv-daily&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>willccbb/verifiers</title>
      <link>https://github.com/willccbb/verifiers</link>
      <description>&lt;p&gt;Verifiers for LLM Reinforcement Learning&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;h1&gt;Verifiers&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt; Environments for LLM Reinforcement Learning &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Verifiers is a library of modular components for creating RL environments and training LLM agents. Verifiers includes an async GRPO implementation built around the &lt;code&gt;transformers&lt;/code&gt; Trainer, is supported by &lt;code&gt;prime-rl&lt;/code&gt; for large-scale FSDP training, and can easily be integrated into any RL framework which exposes an OpenAI-compatible inference client. In addition to RL training, Verifiers can be used directly for building LLM evaluations, creating synthetic data pipelines, and implementing agent harnesses.&lt;/p&gt; 
&lt;p&gt;Full documentation is available &lt;a href="https://verifiers.readthedocs.io/en/latest/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;p&gt;We recommend using &lt;code&gt;verifiers&lt;/code&gt; with along &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; for dependency management in your own project:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
uv init # create a fresh project
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For local (CPU) development and evaluation with API models, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add verifiers # uv add 'verifiers[dev]' for Jupyter + testing support
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For training on GPUs with &lt;code&gt;vf.GRPOTrainer&lt;/code&gt;, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add 'verifiers[all]' &amp;amp;&amp;amp; uv pip install flash-attn --no-build-isolation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use the latest &lt;code&gt;main&lt;/code&gt; branch, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add verifiers @ git+https://github.com/willccbb/verifiers.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use with &lt;code&gt;prime-rl&lt;/code&gt;, see &lt;a href="https://github.com/PrimeIntellect-ai/prime-rl"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To install &lt;code&gt;verifiers&lt;/code&gt; from source for core library development, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/willccbb/verifiers.git
cd verifiers
uv sync --all-extras &amp;amp;&amp;amp; uv pip install flash-attn --no-build-isolation
uv run pre-commit install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In general, we recommend that you build and train Environments &lt;em&gt;with&lt;/em&gt; &lt;code&gt;verifiers&lt;/code&gt;, not &lt;em&gt;in&lt;/em&gt; &lt;code&gt;verifiers&lt;/code&gt;. If you find yourself needing to clone and modify the core library in order to implement key functionality for your project, we'd love for you to open an issue so that we can try and streamline the development experience. Our aim is for &lt;code&gt;verifiers&lt;/code&gt; to be a reliable toolkit to build on top of, and to minimize the "fork proliferation" which often pervades the RL infrastructure ecosystem.&lt;/p&gt; 
&lt;h2&gt;Environments&lt;/h2&gt; 
&lt;p&gt;Environments in Verifiers are installable Python modules which can specify dependencies in a &lt;code&gt;pyproject.toml&lt;/code&gt;, and which expose a &lt;code&gt;load_environment&lt;/code&gt; function for instantiation by downstream applications (e.g. trainers). See &lt;code&gt;environments/&lt;/code&gt; for examples.&lt;/p&gt; 
&lt;p&gt;To initialize a blank Environment module template, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-init vf-environment-name # -p /path/to/environments (defaults to "./environments")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We recommend using the &lt;code&gt;vf-&lt;/code&gt; prefix for clarity and avoiding conflicts with other dependencies, and we prepend it by fault if it is not present, though you can pass &lt;code&gt;--skip-vf-prefix&lt;/code&gt; to override. Names are auto-standardized to use &lt;code&gt;"-"&lt;/code&gt; in IDs and &lt;code&gt;"_"&lt;/code&gt; in paths.&lt;/p&gt; 
&lt;p&gt;To an install an Environment module into your project, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-install vf-environment-name # -p /path/to/environments (defaults to "./environments") 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install an Environment module from this repo's &lt;code&gt;environments&lt;/code&gt; folder, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-install vf-math-python --from-repo # -b branch_or_commit (defaults to "main")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once an Environment module is installed, you can create an instance of the Environment using &lt;code&gt;load_environment&lt;/code&gt;, passing any necessary args:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import verifiers as vf
vf_env = vf.load_environment("vf-environment-name", **env_args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run a quick evaluation of your Environment with an API-based model, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-eval vf-environment-name # vf-eval -h for config options; defaults to gpt-4.1-mini, 5 prompts, 3 rollouts for each
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The core elements of Environments in are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Datasets: a Hugging Face &lt;code&gt;Dataset&lt;/code&gt; with a &lt;code&gt;prompt&lt;/code&gt; column for inputs, and either &lt;code&gt;answer (str)&lt;/code&gt; or &lt;code&gt;info (dict)&lt;/code&gt; columns for evaluation&lt;/li&gt; 
 &lt;li&gt;Rollout logic: interactions between models and the environment (e.g. &lt;code&gt;env_response&lt;/code&gt; + &lt;code&gt;is_completed&lt;/code&gt; for any &lt;code&gt;MultiTurnEnv&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Rubrics: an encapsulation for one or more reward functions&lt;/li&gt; 
 &lt;li&gt;Parsers: optional; an encapsulation for reusable parsing logic&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We support both &lt;code&gt;/v1/chat/completions&lt;/code&gt;-style and &lt;code&gt;/v1/completions&lt;/code&gt;-style inference via OpenAI clients, though we generally recommend &lt;code&gt;/v1/chat/completions&lt;/code&gt;-style inference for the vast majority of applications. Both the included &lt;code&gt;GRPOTrainer&lt;/code&gt; as well as &lt;code&gt;prime-rl&lt;/code&gt; support the full set of &lt;a href="https://docs.vllm.ai/en/v0.6.0/dev/sampling_params.html"&gt;SamplingParams&lt;/a&gt; exposed by vLLM (via their OpenAI-compatible &lt;a href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html"&gt;server&lt;/a&gt; interface), and leveraging this will often be the appropriate way to implement rollout strategies requiring finer-grained control, such as interrupting and resuming generations for interleaved tool use, or enforcing reasoning budgets.&lt;/p&gt; 
&lt;p&gt;The primary constraint we impose on rollout logic is that token sequences must be &lt;em&gt;increasing&lt;/em&gt;, i.e. once a token has been added to a model's context in a rollout, it must remain as the rollout progresses. Note that this causes issues with some popular reasoning models such as the Qwen3 and DeepSeek-R1-Distill series; see &lt;a href="https://raw.githubusercontent.com/willccbb/verifiers/main/#footguns"&gt;Footguns&lt;/a&gt; for guidance on adapting these models to support multi-turn rollouts.&lt;/p&gt; 
&lt;h3&gt;SingleTurnEnv&lt;/h3&gt; 
&lt;p&gt;For tasks requiring only a single response from a model for each prompt, you can use &lt;code&gt;SingleTurnEnv&lt;/code&gt; directly by specifying a Dataset and a Rubric.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from datasets import load_dataset
import verifiers as vf

dataset = load_dataset("my-account/my-dataset", split="train")

def reward_A(prompt, completion, info) -&amp;gt; float:
	# reward fn, e.g. correctness
	...
def reward_B(parser, completion) -&amp;gt; float:
	# auxiliary reward fn, e.g. format
	...
def metric(completion) -&amp;gt; float:
	# non-reward metric, e.g. proper noun count
	...

rubric = vf.Rubric(funcs=[reward_A, reward_B, metric], weights=[1.0, 0.5, 0.0])

vf_env = SingleTurnEnv(
	dataset=dataset,
	rubric=rubric
)
results = vf_env.evaluate(client=OpenAI(), model="gpt-4.1-mini", num_examples=100, rollouts_per_example=1)
vf_env.make_dataset(results, push_to_hub=True, hub_name="my-new-environment-eval-results") # save results to HF hub
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Datasets should be formatted with columns for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;'prompt' (List[ChatMessage])&lt;/code&gt; OR &lt;code&gt;'question' (str)&lt;/code&gt; fields 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ChatMessage&lt;/code&gt; = e.g. &lt;code&gt;{'role': 'user', 'content': '...'}&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;if &lt;code&gt;question&lt;/code&gt; is set instead of &lt;code&gt;prompt&lt;/code&gt;, you can also pass &lt;code&gt;system_prompt (str)&lt;/code&gt; and/or &lt;code&gt;few_shot (List[ChatMessage])&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;answer (str)&lt;/code&gt; AND/OR &lt;code&gt;info (dict)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;task (str)&lt;/code&gt;: optional, used by &lt;code&gt;EnvGroup&lt;/code&gt; and &lt;code&gt;RubricGroup&lt;/code&gt; for orchestrating composition of Environments and Rubrics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following named attributes available for use by reward functions in your Rubric:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prompt&lt;/code&gt;: sequence of input messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;completion&lt;/code&gt;: sequence of messages generated during rollout by model and Environment&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;answer&lt;/code&gt;: primary answer column, optional if &lt;code&gt;info&lt;/code&gt; is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: can be modified during rollout to accumulate any metadata (&lt;code&gt;state['responses']&lt;/code&gt; includes full OpenAI response objects by default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;info&lt;/code&gt;: auxiliary info needed for reward computation (e.g. test cases), optional if &lt;code&gt;answer&lt;/code&gt; is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;task&lt;/code&gt;: tag for task type (used by &lt;code&gt;EnvGroup&lt;/code&gt; and &lt;code&gt;RubricGroup&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;parser&lt;/code&gt;: the parser object declared, defaults to &lt;code&gt;vf.Parser()&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For tasks involving LLM judges, you may wish to use &lt;code&gt;vf.JudgeRubric()&lt;/code&gt; for managing requests to auxiliary models.&lt;/p&gt; 
&lt;h3&gt;ToolEnv&lt;/h3&gt; 
&lt;p&gt;For many applications involving tool use, you can use &lt;code&gt;ToolEnv&lt;/code&gt; to leverage models' native tool/function-calling capabilities in an agentic loop. Tools can be specified as generic Python functions (with type hints and docstrings), which will then be passed in JSON schema form to each inference request.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import verifiers as vf
vf_env = vf.ToolEnv(
	dataset= ... # HF Dataset with 'prompt'/'question' + 'answer'/'info' columns
	rubric= ... # Rubric object; vf.ToolRubric() can be optionally used for counting tool invocations in each rollout
	tools=[search_tool, read_article_tool, python_tool], # python functions with type hints + docstrings
	max_turns=10
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In cases where your tools require heavy computational resources, we recommend hosting your tools as standalone servers (e.g. MCP servers) and creating lightweight wrapper functions to pass to &lt;code&gt;ToolEnv&lt;/code&gt;. Parallel tool call support is enabled by default.&lt;/p&gt; 
&lt;p&gt;For training, or self-hosted endpoints, you'll want to enable auto tool choice in &lt;a href="https://docs.vllm.ai/en/stable/features/tool_calling.html#automatic-function-calling"&gt;vLLM&lt;/a&gt; with the appropriate parser. If your model does not support native tool calling, you may find the &lt;code&gt;XMLParser&lt;/code&gt; abstraction useful for rolling your own tool call parsing on top of &lt;code&gt;MultiTurnEnv&lt;/code&gt;; see &lt;code&gt;environments/xml_tool_env&lt;/code&gt; for an example.&lt;/p&gt; 
&lt;h3&gt;MultiTurnEnv&lt;/h3&gt; 
&lt;p&gt;Both &lt;code&gt;SingleTurnEnv&lt;/code&gt; and &lt;code&gt;ToolEnv&lt;/code&gt; are instances of &lt;code&gt;MultiTurnEnv&lt;/code&gt;, which exposes an interface for writing custom Environment interaction protocols. The two methods you must override are&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from typing import Tuple
import verifiers as vf
from verifiers.types import Messages, State
class YourMultiTurnEnv(vf.MultiTurnEnv):
    def __init__(self,
                 dataset: Dataset,
                 rubric: Rubric,
				 max_turns: int,
                 **kwargs):
	
  def is_completed(self, messages: Messages, state: State, **kwargs) -&amp;gt; bool:
    # return whether or not a rollout is completed

  def env_response(self, messages: Messages, state: State, **kwargs) -&amp;gt; Tuple[Messages, State]:
    # return new environment message(s) + updated state
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your application requires more fine-grained control than is allowed by &lt;code&gt;MultiTurnEnv&lt;/code&gt;, you may want to inherit from the base &lt;code&gt;Environment&lt;/code&gt; functionality directly and override the &lt;code&gt;rollout&lt;/code&gt; method.&lt;/p&gt; 
&lt;h2&gt;Training&lt;/h2&gt; 
&lt;h3&gt;GRPOTrainer&lt;/h3&gt; 
&lt;p&gt;The included trainer (&lt;code&gt;vf.GRPOTrainer&lt;/code&gt;) supports running GRPO-style RL training via Accelerate/DeepSpeed, and uses vLLM for inference. It supports both full-parameter finetuning, and is optimized for efficiently training dense transformer models on 2-16 GPUs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# install environment
vf-install vf-wordle (-p /path/to/environments | --from-repo)

# quick eval
vf-eval vf-wordle -m (model_name in configs/endpoints.py) -n NUM_EXAMPLES -r ROLLOUTS_PER_EXAMPLE

# inference (shell 0)
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 vf-vllm --model willcb/Qwen3-1.7B-Wordle \
    --data-parallel-size 7 --enforce-eager --disable-log-requests

# training (shell 1)
CUDA_VISIBLE_DEVICES=6,7 accelerate launch --num-processes 2 \
    --config-file configs/zero3.yaml examples/grpo/train_wordle.py --size 1.7B
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ensure your &lt;code&gt;wandb&lt;/code&gt; and &lt;code&gt;huggingface-cli&lt;/code&gt; logins are set up (or set &lt;code&gt;report_to=None&lt;/code&gt; in &lt;code&gt;training_args&lt;/code&gt;). You should also have something set as your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in your environment (can be a dummy key for vLLM).&lt;/li&gt; 
 &lt;li&gt;If using high max concurrency, increase the number of allowed open sockets (e.g. &lt;code&gt;ulimit -n 4096&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;On some setups, inter-GPU communication can &lt;a href="https://github.com/huggingface/trl/issues/2923"&gt;hang&lt;/a&gt; or crash during vLLM weight syncing. This can usually be alleviated by setting (or unsetting) &lt;code&gt;NCCL_P2P_DISABLE=1&lt;/code&gt; in your environment (or potentially &lt;code&gt;NCCL_CUMEM_ENABLE=1&lt;/code&gt;). Try this as your first step if you experience NCCL-related issues.&lt;/li&gt; 
 &lt;li&gt;If problems persist, please open an &lt;a href="https://github.com/willccbb/verifiers/issues"&gt;issue&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Resource Requirements&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;GRPOTrainer&lt;/code&gt; is optimized for setups with at least 2 GPUs, scaling up to multiple nodes. 2-GPU setups with sufficient memory to enable small-scale experimentation can be &lt;a href="https://app.primeintellect.ai/dashboard/create-cluster?image=ubuntu_22_cuda_12"&gt;rented&lt;/a&gt; for &amp;lt;$1/hr.&lt;/p&gt; 
&lt;h3&gt;PRIME-RL&lt;/h3&gt; 
&lt;p&gt;If you do not require LoRA support, you may want to use the &lt;code&gt;prime-rl&lt;/code&gt; trainer, which natively supports Environments created using &lt;code&gt;verifiers&lt;/code&gt;, is more optimized for performance and scalability via FSDP, includes a broader set of configuration options and user experience features, and has more battle-tested defaults. Both trainers support asynchronous rollouts, and use a one-step off-policy delay by default for overlapping training and inference. See the &lt;code&gt;prime-rl&lt;/code&gt; &lt;a href="https://github.com/PrimeIntellect-ai/prime-rl"&gt;docs&lt;/a&gt; for usage instructions.&lt;/p&gt; 
&lt;h2&gt;Further Documentation&lt;/h2&gt; 
&lt;p&gt;See the full &lt;a href="https://verifiers.readthedocs.io/en/latest/"&gt;docs&lt;/a&gt; for more info, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Dataset configuration options (system prompts, few-shot examples, eval datasets)&lt;/li&gt; 
 &lt;li&gt;Parsers (e.g. ThinkParser, XMLParser)&lt;/li&gt; 
 &lt;li&gt;Advanced Rubric patterns&lt;/li&gt; 
 &lt;li&gt;Composing Environments (EnvGroup) and Rubrics (RubricGroup)&lt;/li&gt; 
 &lt;li&gt;Creating and saving rollout datasets using Environments&lt;/li&gt; 
 &lt;li&gt;More Environment example walkthroughs&lt;/li&gt; 
 &lt;li&gt;Hardware considerations&lt;/li&gt; 
 &lt;li&gt;SFT warmup for improving small-model training efficiency&lt;/li&gt; 
 &lt;li&gt;RL + GRPO best practices&lt;/li&gt; 
 &lt;li&gt;Common footguns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Footguns&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Non-Increasing Chat Templates:&lt;/strong&gt; The Qwen3 and DeepSeek-R1 model series both remove &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; sections from messages when processing inputs, which violates the increasing context requirement for multi-turn GRPO-style training. We provide versions of many of these models with modified chat templates &lt;a href="https://huggingface.co/collections/willcb/qwen3-68434f4883925bfdb4570ee5"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Verifiers warmly welcomes community contributions! Please open an issue or PR if you encounter bugs or other pain points during your development, or start a discussion for more open-ended questions.&lt;/p&gt; 
&lt;p&gt;Please note that the core &lt;code&gt;verifiers/&lt;/code&gt; library is intended to be a relatively lightweight set of reusable components rather than an exhaustive catalog of RL environments. For &lt;em&gt;applications&lt;/em&gt; of &lt;code&gt;verifiers&lt;/code&gt; (e.g. "an Environment for XYZ task"), you are welcome to submit a PR for a self-contained module that lives within &lt;code&gt;environments/&lt;/code&gt; if it serves as a canonical example of a new pattern. Stay tuned for more info shortly about our plans for supporting community Environment contributions üôÇ&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use this code in your research, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{brown_verifiers_2025,
  author       = {William&amp;nbsp;Brown},
  title        = {{Verifiers}: Reinforcement Learning with LLMs in Verifiable Environments},
  howpublished = {\url{https://github.com/willccbb/verifiers}},
  note         = {Commit abcdefg ‚Ä¢ accessed DD‚ÄØMon‚ÄØYYYY},
  year         = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A community Environments hub for crowdsourcing, sharing, and discovering new RL environments built with &lt;code&gt;verifiers&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Default patterns for hosted resources such as code sandboxes, auxiliary models, and MCP servers&lt;/li&gt; 
 &lt;li&gt;Multimodal input support&lt;/li&gt; 
 &lt;li&gt;Non-increasing token sequences via REINFORCE&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>OpenPipe/ART</title>
      <link>https://github.com/OpenPipe/ART</link>
      <description>&lt;p&gt;Agent Reinforcement Trainer: train multi-step agents for real-world tasks using GRPO. Give your agents on-the-job training. Reinforcement learning for Qwen2.5, Qwen3, Llama, Kimi, and more!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://art.openpipe.ai"&gt;
   &lt;picture&gt; 
    &lt;img alt="ART logo" src="https://github.com/openpipe/art/raw/main/assets/ART_logo.png" width="160px"&gt; 
   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;h1&gt;Agent Reinforcement Trainer&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt; Train multi-step agents for real-world tasks using GRPO. &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/openpipe/art/raw/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-blue.svg?sanitize=true" alt="PRs-Welcome"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/openpipe-art/"&gt;&lt;img src="https://img.shields.io/pypi/dm/openpipe-art?color=364fc7&amp;amp;logoColor=364fc7" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Train Agent"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/zbBHRUpwf4"&gt;&lt;img src="https://img.shields.io/badge/Join%20Discord-5865F2?style=plastic&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Join Discord"&gt;&lt;/a&gt; &lt;a href="https://art.openpipe.ai"&gt;&lt;img src="https://img.shields.io/badge/Documentation-orange?style=plastic&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Documentation"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìè RULER: Zero-Shot Agent Rewards&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;RULER&lt;/strong&gt; (Relative Universal LLM-Elicited Rewards) eliminates the need for hand-crafted reward functions by using an LLM-as-judge to automatically score agent trajectories. Simply define your task in the system prompt, and RULER handles the rest‚Äî&lt;strong&gt;no labeled data, expert feedback, or reward engineering required&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;‚ú® &lt;strong&gt;Key Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2-3x faster development&lt;/strong&gt; - Skip reward function engineering entirely&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General-purpose&lt;/strong&gt; - Works across any task without modification&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strong performance&lt;/strong&gt; - Matches or exceeds hand-crafted rewards in 3/4 benchmarks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy integration&lt;/strong&gt; - Drop-in replacement for manual reward functions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Before: Hours of reward engineering
def complex_reward_function(trajectory):
    # 50+ lines of careful scoring logic...
    pass

# After: One line with RULER
judged_group = await ruler_score_group(group, "openai/o3")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://art.openpipe.ai/fundamentals/ruler"&gt;üìñ Learn more about RULER ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ART Overview&lt;/h2&gt; 
&lt;p&gt;ART is an open-source RL framework that improves agent reliability by allowing LLMs to &lt;strong&gt;learn from experience&lt;/strong&gt;. ART provides an ergonomic harness for integrating GRPO into any python application. For a quick hands-on introduction, run one of the notebooks below. When you're ready to learn more, check out the &lt;a href="https://art.openpipe.ai"&gt;docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìí Notebooks&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent Task&lt;/th&gt; 
   &lt;th&gt;Example Notebook&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Comparative Performance&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ART‚Ä¢E [RULER]&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/art-e/art-e.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 7B learns to search emails using RULER&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/email_agent/accuracy-training-progress.svg?sanitize=true" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/art-e/art_e/evaluate/display_benchmarks.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;2048&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play 2048&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/2048/accuracy-training-progress.svg?sanitize=true" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/2048/benchmark_2048.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Clue&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/temporal_clue/temporal-clue.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 7B learns to solve Temporal Clue&lt;/td&gt; 
   &lt;td&gt;[Link coming soon]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Tic Tac Toe&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/tic_tac_toe/tic-tac-toe.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play Tic Tac Toe&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/tic-tac-toe-local/accuracy-training-progress.svg?sanitize=true" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/tic_tac_toe/benchmark_tic_tac_toe.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Codenames&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/codenames/Codenames_RL.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play Codenames&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/codenames/win_rate_over_time.png" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/codenames/Codenames_RL.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AutoRL [RULER]&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/auto_rl.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Train Qwen 2.5 7B to master any task&lt;/td&gt; 
   &lt;td&gt;[Link coming soon]&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üì∞ ART News&lt;/h2&gt; 
&lt;p&gt;Explore our latest research and updates on building SOTA agents.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href="https://x.com/mattshumer_/status/1950572449025650733"&gt;AutoRL: Zero-Data Training for Any Task&lt;/a&gt;&lt;/strong&gt; - Train custom AI models without labeled data using automatic input generation and RULER evaluation.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href="https://openpipe.ai/blog/ruler-easy-mode-for-rl-rewards"&gt;RULER: Easy Mode for RL Rewards&lt;/a&gt;&lt;/strong&gt; is now available for automatic reward generation in reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href="https://openpipe.ai/blog/art-e-mail-agent"&gt;ART¬∑E: How We Built an Email Research Agent That Beats o3&lt;/a&gt;&lt;/strong&gt; demonstrates a Qwen 2.5 14B email agent outperforming OpenAI's o3.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href="https://openpipe.ai/blog/art-trainer"&gt;ART Trainer: A New RL Trainer for Agents&lt;/a&gt;&lt;/strong&gt; enables easy training of LLM-based agents using GRPO.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://openpipe.ai/blog"&gt;üìñ See all blog posts ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why ART?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ART provides convenient wrappers for introducing RL training into &lt;strong&gt;existing applications&lt;/strong&gt;. We abstract the training server into a modular service that your code doesn't need to interface with.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Train from anywhere.&lt;/strong&gt; Run the ART client on your laptop and let the ART server kick off an ephemeral GPU-enabled environment, or run on a local GPU.&lt;/li&gt; 
 &lt;li&gt;Integrations with hosted platforms like W&amp;amp;B, Langfuse, and OpenPipe provide flexible observability and &lt;strong&gt;simplify debugging&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;ART is customizable with &lt;strong&gt;intelligent defaults&lt;/strong&gt;. You can configure training parameters and inference engine configurations to meet specific needs, or take advantage of the defaults, which have been optimized for training efficiency and stability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;ART agents can be trained from any client machine that runs python. To add to an existing project, run this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install openpipe-art
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ñ ART‚Ä¢E Agent&lt;/h2&gt; 
&lt;p&gt;Curious about how to use ART for a real-world task? Check out the &lt;a href="https://openpipe.ai/blog/art-e-mail-agent"&gt;ART‚Ä¢E Agent&lt;/a&gt; blog post, where we detail how we trained Qwen 2.5 14B to beat o3 at email retrieval!&lt;/p&gt; 
&lt;img src="https://github.com/openpipe/art/raw/main/assets/ART_E_graphs.png" width="700"&gt; 
&lt;h2&gt;üîÅ Training Loop Overview&lt;/h2&gt; 
&lt;p&gt;ART's functionality is divided into a &lt;strong&gt;client&lt;/strong&gt; and a &lt;strong&gt;server&lt;/strong&gt;. The OpenAI-compatible client is responsible for interfacing between ART and your codebase. Using the client, you can pass messages and get completions from your LLM as it improves. The server runs independently on any machine with a GPU. It abstracts away the complexity of the inference and training portions of the RL loop while allowing for some custom configuration. An outline of the training loop is shown below:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inference&lt;/strong&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;Your code uses the ART client to perform an agentic workflow (usually executing several rollouts in parallel to gather data faster).&lt;/li&gt; 
   &lt;li&gt;Completion requests are routed to the ART server, which runs the model's latest LoRA in vLLM.&lt;/li&gt; 
   &lt;li&gt;As the agent executes, each &lt;code&gt;system&lt;/code&gt;, &lt;code&gt;user&lt;/code&gt;, and &lt;code&gt;assistant&lt;/code&gt; message is stored in a Trajectory.&lt;/li&gt; 
   &lt;li&gt;When a rollout finishes, your code assigns a &lt;code&gt;reward&lt;/code&gt; to its Trajectory, indicating the performance of the LLM.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;When each rollout has finished, Trajectories are grouped and sent to the server. Inference is blocked while training executes.&lt;/li&gt; 
   &lt;li&gt;The server trains your model using GRPO, initializing from the latest checkpoint (or an empty LoRA on the first iteration).&lt;/li&gt; 
   &lt;li&gt;The server saves the newly trained LoRA to a local directory and loads it into vLLM.&lt;/li&gt; 
   &lt;li&gt;Inference is unblocked and the loop resumes at step 1.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This training loop runs until a specified number of inference and training iterations have completed.&lt;/p&gt; 
&lt;h2&gt;üß© Supported Models&lt;/h2&gt; 
&lt;p&gt;ART should work with most vLLM/HuggingFace-transformers compatible causal language models, or at least the ones supported by &lt;a href="https://docs.unsloth.ai/get-started/all-our-models"&gt;Unsloth&lt;/a&gt;. Gemma 3 does not appear to be supported for the time being. If any other model isn't working for you, please let us know on &lt;a href="https://discord.gg/zbBHRUpwf4"&gt;Discord&lt;/a&gt; or open an issue on &lt;a href="https://github.com/openpipe/art/issues"&gt;GitHub&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;ART is in active development, and contributions are most welcome! Please see the &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file for more information.&lt;/p&gt; 
&lt;h2&gt;üìñ Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{hilton2025art,
  author = {Brad Hilton and Kyle Corbitt and David Corbitt and Saumya Gandhi and Angky William and Bohdan Kovalenskyi and Andie Jones},
  title = {ART: Agent Reinforcement Trainer},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openpipe/art}}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; 
&lt;p&gt;This repository's source code is available under the &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üôè Credits&lt;/h2&gt; 
&lt;p&gt;ART stands on the shoulders of giants. While we owe many of the ideas and early experiments that led to ART's development to the open source RL community at large, we're especially grateful to the authors of the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unslothai/unsloth"&gt;Unsloth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/trl"&gt;trl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/torchtune"&gt;torchtune&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/skypilot-org/skypilot"&gt;SkyPilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, thank you to our partners who've helped us test ART in the wild! We're excited to see what you all build with it.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SkyworkAI/SkyReels-V2</title>
      <link>https://github.com/SkyworkAI/SkyReels-V2</link>
      <description>&lt;p&gt;SkyReels-V2: Infinite-length Film Generative model&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/assets/logo2.png" alt="SkyReels Logo" width="50%"&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;SkyReels V2: Infinite-Length Film Generative Model&lt;/h1&gt; 
&lt;p align="center"&gt; üìë &lt;a href="https://arxiv.org/pdf/2504.13074"&gt;Technical Report&lt;/a&gt; ¬∑ üëã &lt;a href="https://www.skyreels.ai/home?utm_campaign=github_SkyReels_V2" target="_blank"&gt;Playground&lt;/a&gt; ¬∑ üí¨ &lt;a href="https://discord.gg/PwM6NYtccQ" target="_blank"&gt;Discord&lt;/a&gt; ¬∑ ü§ó &lt;a href="https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9" target="_blank"&gt;Hugging Face&lt;/a&gt; ¬∑ ü§ñ &lt;a href="https://www.modelscope.cn/collections/SkyReels-V2-f665650130b144" target="_blank"&gt;ModelScope&lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Welcome to the &lt;strong&gt;SkyReels V2&lt;/strong&gt; repository! Here, you'll find the model weights and inference code for our infinite-length film generative models. To the best of our knowledge, it represents the first open-source video generative model employing &lt;strong&gt;AutoRegressive Diffusion-Forcing architecture&lt;/strong&gt; that achieves the &lt;strong&gt;SOTA performance&lt;/strong&gt; among publicly available models.&lt;/p&gt; 
&lt;h2&gt;üî•üî•üî• News!!&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jun 1, 2025: üéâ We published the technical report, &lt;a href="https://arxiv.org/pdf/2506.00830"&gt;SkyReels-Audio: Omni Audio-Conditioned Talking Portraits in Video Diffusion Transformers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 16, 2025: üî• We release the inference code for &lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#ve"&gt;video extension&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#se"&gt;start/end frame control&lt;/a&gt; in diffusion forcing model.&lt;/li&gt; 
 &lt;li&gt;Apr 24, 2025: üî• We release the 720P models, &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-DF-14B-720P"&gt;SkyReels-V2-DF-14B-720P&lt;/a&gt; and &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P"&gt;SkyReels-V2-I2V-14B-720P&lt;/a&gt;. The former facilitates infinite-length autoregressive video generation, and the latter focuses on Image2Video synthesis.&lt;/li&gt; 
 &lt;li&gt;Apr 21, 2025: üëã We release the inference code and model weights of &lt;a href="https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9"&gt;SkyReels-V2&lt;/a&gt; Series Models and the video captioning model &lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt; .&lt;/li&gt; 
 &lt;li&gt;Apr 3, 2025: üî• We also release &lt;a href="https://github.com/SkyworkAI/SkyReels-A2"&gt;SkyReels-A2&lt;/a&gt;. This is an open-sourced controllable video generation framework capable of assembling arbitrary visual elements.&lt;/li&gt; 
 &lt;li&gt;Feb 18, 2025: üî• we released &lt;a href="https://github.com/SkyworkAI/SkyReels-A1"&gt;SkyReels-A1&lt;/a&gt;. This is an open-sourced and effective framework for portrait image animation.&lt;/li&gt; 
 &lt;li&gt;Feb 18, 2025: üî• We released &lt;a href="https://github.com/SkyworkAI/SkyReels-V1"&gt;SkyReels-V1&lt;/a&gt;. This is the first and most advanced open-source human-centric video foundation model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üé• Demos&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/f6f9f9a7-5d5f-433c-9d73-d8d593b7ad25" width="100%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/0eb13415-f4d9-4aaf-bcd3-3031851109b9" width="100%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/dcd16603-5bf4-4786-8e4d-1ed23889d07a" width="100%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; The demos above showcase 30-second videos generated using our SkyReels-V2 Diffusion Forcing model. 
&lt;h2&gt;üìë TODO List&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://arxiv.org/pdf/2504.13074"&gt;Technical Report&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Checkpoints of the 14B and 1.3B Models Series&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Single-GPU &amp;amp; Multi-GPU Inference Code&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt;: A Video Captioning Model&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Prompt Enhancer&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Diffusers integration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Checkpoints of the 5B Models Series&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Checkpoints of the Camera Director Models&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Checkpoints of the Step &amp;amp; Guidance Distill Model&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quickstart&lt;/h2&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# clone the repository.
git clone https://github.com/SkyworkAI/SkyReels-V2
cd SkyReels-V2
# Install dependencies. Test environment uses Python 3.10.12.
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Model Download&lt;/h4&gt; 
&lt;p&gt;You can download our models from Hugging Face:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Model Variant&lt;/th&gt; 
   &lt;th&gt;Recommended Height/Width/Frame&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="5"&gt;Diffusion Forcing&lt;/td&gt; 
   &lt;td&gt;1.3B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;ü§ó &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-DF-1.3B-540P"&gt;Huggingface&lt;/a&gt; ü§ñ &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-DF-1.3B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;ü§ó &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-DF-14B-540P"&gt;Huggingface&lt;/a&gt; ü§ñ &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-DF-14B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;ü§ó &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-DF-14B-720P"&gt;Huggingface&lt;/a&gt; ü§ñ &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-DF-14B-720P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="5"&gt;Text-to-Video&lt;/td&gt; 
   &lt;td&gt;1.3B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;ü§ó &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-540P"&gt;Huggingface&lt;/a&gt; ü§ñ &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-T2V-14B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;ü§ó &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-720P"&gt;Huggingface&lt;/a&gt; ü§ñ &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-T2V-14B-720P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="5"&gt;Image-to-Video&lt;/td&gt; 
   &lt;td&gt;1.3B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;ü§ó &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-I2V-1.3B-540P"&gt;Huggingface&lt;/a&gt; ü§ñ &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-I2V-1.3B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;ü§ó &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-540P"&gt;Huggingface&lt;/a&gt; ü§ñ &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-I2V-14B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;ü§ó &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P"&gt;Huggingface&lt;/a&gt; ü§ñ &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-I2V-14B-720P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="3"&gt;Camera Director&lt;/td&gt; 
   &lt;td&gt;5B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;After downloading, set the model path in your generation commands:&lt;/p&gt; 
&lt;h4&gt;Single GPU Inference&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Diffusion Forcing for Long Video Generation&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;a href="https://arxiv.org/abs/2407.01392"&gt;&lt;strong&gt;Diffusion Forcing&lt;/strong&gt;&lt;/a&gt; version model allows us to generate Infinite-Length videos. This model supports both &lt;strong&gt;text-to-video (T2V)&lt;/strong&gt; and &lt;strong&gt;image-to-video (I2V)&lt;/strong&gt; tasks, and it can perform inference in both synchronous and asynchronous modes. Here we demonstrate 2 running scripts as examples for long video generation. If you want to adjust the inference parameters, e.g., the duration of video, inference mode, read the Note below first.&lt;/p&gt; 
&lt;p&gt;synchronous generation for 10s video&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# synchronous inference
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 257 \
  --overlap_history 17 \
  --prompt "A graceful white swan with a curved neck and delicate feathers swimming in a serene lake at dawn, its reflection perfectly mirrored in the still water as mist rises from the surface, with the swan occasionally dipping its head into the water to feed." \
  --addnoise_condition 20 \
  --offload \
  --teacache \
  --use_ret_steps \
  --teacache_thresh 0.3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;asynchronous generation for 30s video&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# asynchronous inference
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 5 \
  --causal_block_size 5 \
  --base_num_frames 97 \
  --num_frames 737 \
  --overlap_history 17 \
  --prompt "A graceful white swan with a curved neck and delicate feathers swimming in a serene lake at dawn, its reflection perfectly mirrored in the still water as mist rises from the surface, with the swan occasionally dipping its head into the water to feed." \
  --addnoise_condition 20 \
  --offload
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you want to run the &lt;strong&gt;image-to-video (I2V)&lt;/strong&gt; task, add &lt;code&gt;--image ${image_path}&lt;/code&gt; to your command and it is also better to use &lt;strong&gt;text-to-video (T2V)&lt;/strong&gt;-like prompt which includes some descriptions of the first-frame image.&lt;/li&gt; 
  &lt;li&gt;For long video generation, you can just switch the &lt;code&gt;--num_frames&lt;/code&gt;, e.g., &lt;code&gt;--num_frames 257&lt;/code&gt; for 10s video, &lt;code&gt;--num_frames 377&lt;/code&gt; for 15s video, &lt;code&gt;--num_frames 737&lt;/code&gt; for 30s video, &lt;code&gt;--num_frames 1457&lt;/code&gt; for 60s video. The number is not strictly aligned with the logical frame number for specified time duration, but it is aligned with some training parameters, which means it may perform better. When you use asynchronous inference with causal_block_size &amp;gt; 1, the &lt;code&gt;--num_frames&lt;/code&gt; should be carefully set.&lt;/li&gt; 
  &lt;li&gt;You can use &lt;code&gt;--ar_step 5&lt;/code&gt; to enable asynchronous inference. When asynchronous inference, &lt;code&gt;--causal_block_size 5&lt;/code&gt; is recommended while it is not supposed to be set for synchronous generation. REMEMBER that the frame latent number inputted into the model in every iteration, e.g., base frame latent number (e.g., (97-1)//4+1=25 for base_num_frames=97) and (e.g., (237-97-(97-17)x1+17-1)//4+1=20 for base_num_frames=97, num_frames=237, overlap_history=17) for the last iteration, MUST be divided by causal_block_size. If you find it too hard to calculate and set proper values, just use our recommended setting above :). Asynchronous inference will take more steps to diffuse the whole sequence which means it will be SLOWER than synchronous mode. In our experiments, asynchronous inference may improve the instruction following and visual consistent performance.&lt;/li&gt; 
  &lt;li&gt;To reduce peak VRAM, just lower the &lt;code&gt;--base_num_frames&lt;/code&gt;, e.g., to 77 or 57, while keeping the same generative length &lt;code&gt;--num_frames&lt;/code&gt; you want to generate. This may slightly reduce video quality, and it should not be set too small.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--addnoise_condition&lt;/code&gt; is used to help smooth the long video generation by adding some noise to the clean condition. Too large noise can cause the inconsistency as well. 20 is a recommended value, and you may try larger ones, but it is recommended to not exceed 50.&lt;/li&gt; 
  &lt;li&gt;Generating a 540P video using the 1.3B model requires approximately 14.7GB peak VRAM, while the same resolution video using the 14B model demands around 51.2GB peak VRAM.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span id="ve"&gt;Video Extention&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# video extention
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 120 \
  --overlap_history 17 \
  --prompt ${prompt} \
  --addnoise_condition 20 \
  --offload \
  --use_ret_steps \
  --teacache \
  --teacache_thresh 0.3 \
  --video_path ${video_path}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;When performing video extension, you need to pass the &lt;code&gt;--video_path ${video_path}&lt;/code&gt; parameter to specify the video to be extended.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span id="se"&gt;Start/End Frame Control&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# start/end frame control
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 97 \
  --overlap_history 17 \
  --prompt ${prompt} \
  --addnoise_condition 20 \
  --offload \
  --use_ret_steps \
  --teacache \
  --teacache_thresh 0.3 \
  --image ${image} \
  --end_image ${end_image}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;When controlling the start and end frames, you need to pass the &lt;code&gt;--image ${image}&lt;/code&gt; parameter to control the generation of the start frame and the &lt;code&gt;--end_image ${end_image}&lt;/code&gt; parameter to control the generation of the end frame.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text To Video &amp;amp; Image To Video&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# run Text-to-Video Generation
model_id=Skywork/SkyReels-V2-T2V-14B-540P
python3 generate_video.py \
  --model_id ${model_id} \
  --resolution 540P \
  --num_frames 97 \
  --guidance_scale 6.0 \
  --shift 8.0 \
  --fps 24 \
  --prompt "A serene lake surrounded by towering mountains, with a few swans gracefully gliding across the water and sunlight dancing on the surface." \
  --offload \
  --teacache \
  --use_ret_steps \
  --teacache_thresh 0.3
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;When using an &lt;strong&gt;image-to-video (I2V)&lt;/strong&gt; model, you must provide an input image using the &lt;code&gt;--image ${image_path}&lt;/code&gt; parameter. The &lt;code&gt;--guidance_scale 5.0&lt;/code&gt; and &lt;code&gt;--shift 3.0&lt;/code&gt; is recommended for I2V model.&lt;/li&gt; 
  &lt;li&gt;Generating a 540P video using the 1.3B model requires approximately 14.7GB peak VRAM, while the same resolution video using the 14B model demands around 43.4GB peak VRAM.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt Enhancer&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The prompt enhancer is implemented based on &lt;a href="https://huggingface.co/Qwen/Qwen2.5-32B-Instruct"&gt;Qwen2.5-32B-Instruct&lt;/a&gt; and is utilized via the &lt;code&gt;--prompt_enhancer&lt;/code&gt; parameter. It works ideally for short prompts, while for long prompts, it might generate an excessively lengthy prompt that could lead to over-saturation in the generative video. Note the peak memory of GPU is 64G+ if you use &lt;code&gt;--prompt_enhancer&lt;/code&gt;. If you want to obtain the enhanced prompt separately, you can also run the prompt_enhancer script separately for testing. The steps are as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd skyreels_v2_infer/pipelines
python3 prompt_enhancer.py --prompt "A serene lake surrounded by towering mountains, with a few swans gracefully gliding across the water and sunlight dancing on the surface."
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;--prompt_enhancer&lt;/code&gt; is not allowed if using &lt;code&gt;--use_usp&lt;/code&gt;. We recommend running the skyreels_v2_infer/pipelines/prompt_enhancer.py script first to generate enhanced prompt before enabling the &lt;code&gt;--use_usp&lt;/code&gt; parameter.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Advanced Configuration Options&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Below are the key parameters you can customize for video generation:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Parameter&lt;/th&gt; 
   &lt;th align="center"&gt;Recommended Value&lt;/th&gt; 
   &lt;th align="center"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--prompt&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Text description for generating your video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--image&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Path to input image for image-to-video generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--resolution&lt;/td&gt; 
   &lt;td align="center"&gt;540P or 720P&lt;/td&gt; 
   &lt;td align="center"&gt;Output video resolution (select based on model type)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--num_frames&lt;/td&gt; 
   &lt;td align="center"&gt;97 or 121&lt;/td&gt; 
   &lt;td align="center"&gt;Total frames to generate (&lt;strong&gt;97 for 540P models&lt;/strong&gt;, &lt;strong&gt;121 for 720P models&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--inference_steps&lt;/td&gt; 
   &lt;td align="center"&gt;50&lt;/td&gt; 
   &lt;td align="center"&gt;Number of denoising steps&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--fps&lt;/td&gt; 
   &lt;td align="center"&gt;24&lt;/td&gt; 
   &lt;td align="center"&gt;Frames per second in the output video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--shift&lt;/td&gt; 
   &lt;td align="center"&gt;8.0 or 5.0&lt;/td&gt; 
   &lt;td align="center"&gt;Flow matching scheduler parameter (&lt;strong&gt;8.0 for T2V&lt;/strong&gt;, &lt;strong&gt;5.0 for I2V&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--guidance_scale&lt;/td&gt; 
   &lt;td align="center"&gt;6.0 or 5.0&lt;/td&gt; 
   &lt;td align="center"&gt;Controls text adherence strength (&lt;strong&gt;6.0 for T2V&lt;/strong&gt;, &lt;strong&gt;5.0 for I2V&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--seed&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Fixed seed for reproducible results (omit for random generation)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--offload&lt;/td&gt; 
   &lt;td align="center"&gt;True&lt;/td&gt; 
   &lt;td align="center"&gt;Offloads model components to CPU to reduce VRAM usage (recommended)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--use_usp&lt;/td&gt; 
   &lt;td align="center"&gt;True&lt;/td&gt; 
   &lt;td align="center"&gt;Enables multi-GPU acceleration with xDiT USP&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--outdir&lt;/td&gt; 
   &lt;td align="center"&gt;./video_out&lt;/td&gt; 
   &lt;td align="center"&gt;Directory where generated videos will be saved&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--prompt_enhancer&lt;/td&gt; 
   &lt;td align="center"&gt;True&lt;/td&gt; 
   &lt;td align="center"&gt;Expand the prompt into a more detailed description&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--teacache&lt;/td&gt; 
   &lt;td align="center"&gt;False&lt;/td&gt; 
   &lt;td align="center"&gt;Enables teacache for faster inference&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--teacache_thresh&lt;/td&gt; 
   &lt;td align="center"&gt;0.2&lt;/td&gt; 
   &lt;td align="center"&gt;Higher speedup will cause to worse quality&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--use_ret_steps&lt;/td&gt; 
   &lt;td align="center"&gt;False&lt;/td&gt; 
   &lt;td align="center"&gt;Retention Steps for teacache&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Diffusion Forcing Additional Parameters&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Parameter&lt;/th&gt; 
   &lt;th align="center"&gt;Recommended Value&lt;/th&gt; 
   &lt;th align="center"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--ar_step&lt;/td&gt; 
   &lt;td align="center"&gt;0&lt;/td&gt; 
   &lt;td align="center"&gt;Controls asynchronous inference (0 for synchronous mode)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--base_num_frames&lt;/td&gt; 
   &lt;td align="center"&gt;97 or 121&lt;/td&gt; 
   &lt;td align="center"&gt;Base frame count (&lt;strong&gt;97 for 540P&lt;/strong&gt;, &lt;strong&gt;121 for 720P&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--overlap_history&lt;/td&gt; 
   &lt;td align="center"&gt;17&lt;/td&gt; 
   &lt;td align="center"&gt;Number of frames to overlap for smooth transitions in long videos&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--addnoise_condition&lt;/td&gt; 
   &lt;td align="center"&gt;20&lt;/td&gt; 
   &lt;td align="center"&gt;Improves consistency in long video generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--causal_block_size&lt;/td&gt; 
   &lt;td align="center"&gt;5&lt;/td&gt; 
   &lt;td align="center"&gt;Recommended when using asynchronous inference (--ar_step &amp;gt; 0)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--video_path&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Path to input video for video extension&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--end_image&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Path to input image for end frame control&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Multi-GPU inference using xDiT USP&lt;/h4&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/xdit-project/xDiT"&gt;xDiT&lt;/a&gt; USP to accelerate inference. For example, to generate a video with 2 GPUs, you can use the following command:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Diffusion Forcing&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# diffusion forcing synchronous inference
torchrun --nproc_per_node=2 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 257 \
  --overlap_history 17 \
  --prompt "A graceful white swan with a curved neck and delicate feathers swimming in a serene lake at dawn, its reflection perfectly mirrored in the still water as mist rises from the surface, with the swan occasionally dipping its head into the water to feed." \
  --addnoise_condition 20 \
  --use_usp \
  --offload \
  --seed 42
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text To Video &amp;amp; Image To Video&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# run Text-to-Video Generation
model_id=Skywork/SkyReels-V2-T2V-14B-540P
torchrun --nproc_per_node=2 generate_video.py \
  --model_id ${model_id} \
  --resolution 540P \
  --num_frames 97 \
  --guidance_scale 6.0 \
  --shift 8.0 \
  --fps 24 \
  --offload \
  --prompt "A serene lake surrounded by towering mountains, with a few swans gracefully gliding across the water and sunlight dancing on the surface." \
  --use_usp \
  --seed 42
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;When using an &lt;strong&gt;image-to-video (I2V)&lt;/strong&gt; model, you must provide an input image using the &lt;code&gt;--image ${image_path}&lt;/code&gt; parameter. The &lt;code&gt;--guidance_scale 5.0&lt;/code&gt; and &lt;code&gt;--shift 3.0&lt;/code&gt; is recommended for I2V model.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#abstract"&gt;Abstract&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#methodology-of-skyreels-v2"&gt;Methodology of SkyReels-V2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#key-contributions-of-skyreels-v2"&gt;Key Contributions of SkyReels-V2&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#video-captioner"&gt;Video Captioner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#reinforcement-learning"&gt;Reinforcement Learning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#diffusion-forcing"&gt;Diffusion Forcing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#high-quality-supervised-fine-tuning-sft"&gt;High-Quality Supervised Fine-Tuning(SFT)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#performance"&gt;Performance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;Abstract&lt;/h2&gt; 
&lt;p&gt;Recent advances in video generation have been driven by diffusion models and autoregressive frameworks, yet critical challenges persist in harmonizing prompt adherence, visual quality, motion dynamics, and duration: compromises in motion dynamics to enhance temporal visual quality, constrained video duration (5-10 seconds) to prioritize resolution, and inadequate shot-aware generation stemming from general-purpose MLLMs' inability to interpret cinematic grammar, such as shot composition, actor expressions, and camera motions. These intertwined limitations hinder realistic long-form synthesis and professional film-style generation.&lt;/p&gt; 
&lt;p&gt;To address these limitations, we introduce SkyReels-V2, the world's first infinite-length film generative model using a Diffusion Forcing framework. Our approach synergizes Multi-modal Large Language Models (MLLM), Multi-stage Pretraining, Reinforcement Learning, and Diffusion Forcing techniques to achieve comprehensive optimization. Beyond its technical innovations, SkyReels-V2 enables multiple practical applications, including Story Generation, Image-to-Video Synthesis, Camera Director functionality, and multi-subject consistent video generation through our &lt;a href="https://github.com/SkyworkAI/SkyReels-A2"&gt;Skyreels-A2&lt;/a&gt; system.&lt;/p&gt; 
&lt;h2&gt;Methodology of SkyReels-V2&lt;/h2&gt; 
&lt;p&gt;The SkyReels-V2 methodology consists of several interconnected components. It starts with a comprehensive data processing pipeline that prepares various quality training data. At its core is the Video Captioner architecture, which provides detailed annotations for video content. The system employs a multi-task pretraining strategy to build fundamental video generation capabilities. Post-training optimization includes Reinforcement Learning to enhance motion quality, Diffusion Forcing Training for generating extended videos, and High-quality Supervised Fine-Tuning (SFT) stages for visual refinement. The model runs on optimized computational infrastructure for efficient training and inference. SkyReels-V2 supports multiple applications, including Story Generation, Image-to-Video Synthesis, Camera Director functionality, and Elements-to-Video Generation.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/assets/main_pipeline.jpg" alt="mainpipeline" width="100%"&gt; &lt;/p&gt; 
&lt;h2&gt;Key Contributions of SkyReels-V2&lt;/h2&gt; 
&lt;h4&gt;Video Captioner&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt; serves as our video captioning model for data annotation. This model is trained on the captioning result from the base model &lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct"&gt;Qwen2.5-VL-72B-Instruct&lt;/a&gt; and the sub-expert captioners on a balanced video data. The balanced video data is a carefully curated dataset of approximately 2 million videos to ensure conceptual balance and annotation quality. Built upon the &lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct"&gt;Qwen2.5-VL-7B-Instruct&lt;/a&gt; foundation model, &lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt; is fine-tuned to enhance performance in domain-specific video captioning tasks. To compare the performance with the SOTA models, we conducted a manual assessment of accuracy across different captioning fields using a test set of 1,000 samples. The proposed &lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt; achieves the highest average accuracy among the baseline models, and show a dramatic result in the shot related fields&lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;table align="center"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;model&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct"&gt;Qwen2.5-VL-7B-Ins.&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct"&gt;Qwen2.5-VL-72B-Ins.&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://huggingface.co/omni-research/Tarsier2-Recap-7b"&gt;Tarsier2-Recap-7b&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Avg accuracy&lt;/td&gt; 
   &lt;td&gt;51.4%&lt;/td&gt; 
   &lt;td&gt;58.7%&lt;/td&gt; 
   &lt;td&gt;49.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.3%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;shot type&lt;/td&gt; 
   &lt;td&gt;76.8%&lt;/td&gt; 
   &lt;td&gt;82.5%&lt;/td&gt; 
   &lt;td&gt;60.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;93.7%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;shot angle&lt;/td&gt; 
   &lt;td&gt;60.0%&lt;/td&gt; 
   &lt;td&gt;73.7%&lt;/td&gt; 
   &lt;td&gt;52.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;89.8%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;shot position&lt;/td&gt; 
   &lt;td&gt;28.4%&lt;/td&gt; 
   &lt;td&gt;32.7%&lt;/td&gt; 
   &lt;td&gt;23.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;83.1%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;camera motion&lt;/td&gt; 
   &lt;td&gt;62.0%&lt;/td&gt; 
   &lt;td&gt;61.2%&lt;/td&gt; 
   &lt;td&gt;45.3%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;85.3%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;expression&lt;/td&gt; 
   &lt;td&gt;43.6%&lt;/td&gt; 
   &lt;td&gt;51.5%&lt;/td&gt; 
   &lt;td&gt;54.3%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;68.8%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="5" style="text-align: center; border-bottom: 1px solid #ddd; padding: 8px;"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPES_type&lt;/td&gt; 
   &lt;td&gt;43.5%&lt;/td&gt; 
   &lt;td&gt;49.7%&lt;/td&gt; 
   &lt;td&gt;47.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;82.5%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPES_sub_type&lt;/td&gt; 
   &lt;td&gt;38.9%&lt;/td&gt; 
   &lt;td&gt;44.9%&lt;/td&gt; 
   &lt;td&gt;45.9%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;75.4%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;appearance&lt;/td&gt; 
   &lt;td&gt;40.9%&lt;/td&gt; 
   &lt;td&gt;52.0%&lt;/td&gt; 
   &lt;td&gt;45.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;59.3%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;action&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;52.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;69.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;68.8%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;position&lt;/td&gt; 
   &lt;td&gt;35.4%&lt;/td&gt; 
   &lt;td&gt;48.6%&lt;/td&gt; 
   &lt;td&gt;45.5%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;57.5%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;is_main_subject&lt;/td&gt; 
   &lt;td&gt;58.5%&lt;/td&gt; 
   &lt;td&gt;68.7%&lt;/td&gt; 
   &lt;td&gt;69.7%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;80.9%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;environment&lt;/td&gt; 
   &lt;td&gt;70.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;72.7%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;61.4%&lt;/td&gt; 
   &lt;td&gt;70.5%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;lighting&lt;/td&gt; 
   &lt;td&gt;77.1%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;80.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;21.2%&lt;/td&gt; 
   &lt;td&gt;76.5%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Reinforcement Learning&lt;/h4&gt; 
&lt;p&gt;Inspired by the previous success in LLM, we propose to enhance the performance of the generative model by Reinforcement Learning. Specifically, we focus on the motion quality because we find that the main drawback of our generative model is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the generative model does not handle well with large, deformable motions.&lt;/li&gt; 
 &lt;li&gt;the generated videos may violate the physical law.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To avoid the degradation in other metrics, such as text alignment and video quality, we ensure the preference data pairs have comparable text alignment and video quality, while only the motion quality varies. This requirement poses greater challenges in obtaining preference annotations due to the inherently higher costs of human annotation. To address this challenge, we propose a semi-automatic pipeline that strategically combines automatically generated motion pairs and human annotation results. This hybrid approach not only enhances the data scale but also improves alignment with human preferences through curated quality control. Leveraging this enhanced dataset, we first train a specialized reward model to capture the generic motion quality differences between paired samples. This learned reward function subsequently guides the sample selection process for Direct Preference Optimization (DPO), enhancing the motion quality of the generative model.&lt;/p&gt; 
&lt;h4&gt;Diffusion Forcing&lt;/h4&gt; 
&lt;p&gt;We introduce the Diffusion Forcing Transformer to unlock our model‚Äôs ability to generate long videos. Diffusion Forcing is a training and sampling strategy where each token is assigned an independent noise level. This allows tokens to be denoised according to arbitrary, per-token schedules. Conceptually, this approach functions as a form of partial masking: a token with zero noise is fully unmasked, while complete noise fully masks it. Diffusion Forcing trains the model to "unmask" any combination of variably noised tokens, using the cleaner tokens as conditional information to guide the recovery of noisy ones. Building on this, our Diffusion Forcing Transformer can extend video generation indefinitely based on the last frames of the previous segment. Note that the synchronous full sequence diffusion is a special case of Diffusion Forcing, where all tokens share the same noise level. This relationship allows us to fine-tune the Diffusion Forcing Transformer from a full-sequence diffusion model.&lt;/p&gt; 
&lt;h4&gt;High-Quality Supervised Fine-Tuning (SFT)&lt;/h4&gt; 
&lt;p&gt;We implement two sequential high-quality supervised fine-tuning (SFT) stages at 540p and 720p resolutions respectively, with the initial SFT phase conducted immediately after pretraining but prior to reinforcement learning (RL) stage.This first-stage SFT serves as a conceptual equilibrium trainer, building upon the foundation model‚Äôs pretraining outcomes that utilized only fps24 video data, while strategically removing FPS embedding components to streamline thearchitecture. Trained with the high-quality concept-balanced samples, this phase establishes optimized initialization parameters for subsequent training processes. Following this, we execute a secondary high-resolution SFT at 720p after completing the diffusion forcing stage, incorporating identical loss formulations and the higher-quality concept-balanced datasets by the manually filter. This final refinement phase focuses on resolution increase such that the overall video quality will be further enhanced.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;To comprehensively evaluate our proposed method, we construct the SkyReels-Bench for human assessment and leveraged the open-source &lt;a href="https://github.com/Vchitect/VBench"&gt;V-Bench&lt;/a&gt; for automated evaluation. This allows us to compare our model with the state-of-the-art (SOTA) baselines, including both open-source and proprietary models.&lt;/p&gt; 
&lt;h4&gt;Human Evaluation&lt;/h4&gt; 
&lt;p&gt;For human evaluation, we design SkyReels-Bench with 1,020 text prompts, systematically assessing three dimensions: Instruction Adherence, Motion Quality, Consistency and Visual Quality. This benchmark is designed to evaluate both text-to-video (T2V) and image-to-video (I2V) generation models, providing comprehensive assessment across different generation paradigms. To ensure fairness, all models were evaluated under default settings with consistent resolutions, and no post-generation filtering was applied.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Text To Video Models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;table align="center"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;Average&lt;/th&gt; 
   &lt;th&gt;Instruction Adherence&lt;/th&gt; 
   &lt;th&gt;Consistency&lt;/th&gt; 
   &lt;th&gt;Visual Quality&lt;/th&gt; 
   &lt;th&gt;Motion Quality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://runwayml.com/research/introducing-gen-3-alpha"&gt;Runway-Gen3 Alpha&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.53&lt;/td&gt; 
   &lt;td&gt;2.19&lt;/td&gt; 
   &lt;td&gt;2.57&lt;/td&gt; 
   &lt;td&gt;3.23&lt;/td&gt; 
   &lt;td&gt;2.11&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tencent/HunyuanVideo"&gt;HunyuanVideo-13B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.82&lt;/td&gt; 
   &lt;td&gt;2.64&lt;/td&gt; 
   &lt;td&gt;2.81&lt;/td&gt; 
   &lt;td&gt;3.20&lt;/td&gt; 
   &lt;td&gt;2.61&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://klingai.com"&gt;Kling-1.6 STD Mode&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.99&lt;/td&gt; 
   &lt;td&gt;2.77&lt;/td&gt; 
   &lt;td&gt;3.05&lt;/td&gt; 
   &lt;td&gt;3.39&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;2.76&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hailuoai.video"&gt;Hailuo-01&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.0&lt;/td&gt; 
   &lt;td&gt;2.8&lt;/td&gt; 
   &lt;td&gt;3.08&lt;/td&gt; 
   &lt;td&gt;3.29&lt;/td&gt; 
   &lt;td&gt;2.74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;Wan2.1-14B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.12&lt;/td&gt; 
   &lt;td&gt;2.91&lt;/td&gt; 
   &lt;td&gt;3.31&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.54&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;2.71&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SkyReels-V2&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.14&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.15&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.35&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3.34&lt;/td&gt; 
   &lt;td&gt;2.74&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;The evaluation demonstrates that our model achieves significant advancements in &lt;strong&gt;instruction adherence (3.15)&lt;/strong&gt; compared to baseline methods, while maintaining competitive performance in &lt;strong&gt;motion quality (2.74)&lt;/strong&gt; without sacrificing the &lt;strong&gt;consistency (3.35)&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Image To Video Models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;table align="center"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Average&lt;/th&gt; 
   &lt;th&gt;Instruction Adherence&lt;/th&gt; 
   &lt;th&gt;Consistency&lt;/th&gt; 
   &lt;th&gt;Visual Quality&lt;/th&gt; 
   &lt;th&gt;Motion Quality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tencent/HunyuanVideo"&gt;HunyuanVideo-13B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.84&lt;/td&gt; 
   &lt;td&gt;2.97&lt;/td&gt; 
   &lt;td&gt;2.95&lt;/td&gt; 
   &lt;td&gt;2.87&lt;/td&gt; 
   &lt;td&gt;2.56&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;Wan2.1-14B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.85&lt;/td&gt; 
   &lt;td&gt;3.10&lt;/td&gt; 
   &lt;td&gt;2.81&lt;/td&gt; 
   &lt;td&gt;3.00&lt;/td&gt; 
   &lt;td&gt;2.48&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hailuoai.video"&gt;Hailuo-01&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.05&lt;/td&gt; 
   &lt;td&gt;3.31&lt;/td&gt; 
   &lt;td&gt;2.58&lt;/td&gt; 
   &lt;td&gt;3.55&lt;/td&gt; 
   &lt;td&gt;2.74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://klingai.com"&gt;Kling-1.6 Pro Mode&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.4&lt;/td&gt; 
   &lt;td&gt;3.56&lt;/td&gt; 
   &lt;td&gt;3.03&lt;/td&gt; 
   &lt;td&gt;3.58&lt;/td&gt; 
   &lt;td&gt;3.41&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://runwayml.com/research/introducing-runway-gen-4"&gt;Runway-Gen4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.39&lt;/td&gt; 
   &lt;td&gt;3.75&lt;/td&gt; 
   &lt;td&gt;3.2&lt;/td&gt; 
   &lt;td&gt;3.4&lt;/td&gt; 
   &lt;td&gt;3.37&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SkyReels-V2-DF&lt;/td&gt; 
   &lt;td&gt;3.24&lt;/td&gt; 
   &lt;td&gt;3.64&lt;/td&gt; 
   &lt;td&gt;3.21&lt;/td&gt; 
   &lt;td&gt;3.18&lt;/td&gt; 
   &lt;td&gt;2.93&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SkyReels-V2-I2V&lt;/td&gt; 
   &lt;td&gt;3.29&lt;/td&gt; 
   &lt;td&gt;3.42&lt;/td&gt; 
   &lt;td&gt;3.18&lt;/td&gt; 
   &lt;td&gt;3.56&lt;/td&gt; 
   &lt;td&gt;3.01&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;Our results demonstrate that both &lt;strong&gt;SkyReels-V2-I2V (3.29)&lt;/strong&gt; and &lt;strong&gt;SkyReels-V2-DF (3.24)&lt;/strong&gt; achieve state-of-the-art performance among open-source models, significantly outperforming HunyuanVideo-13B (2.84) and Wan2.1-14B (2.85) across all quality dimensions. With an average score of 3.29, SkyReels-V2-I2V demonstrates comparable performance to proprietary models Kling-1.6 (3.4) and Runway-Gen4 (3.39).&lt;/p&gt; 
&lt;h4&gt;VBench&lt;/h4&gt; 
&lt;p&gt;To objectively compare SkyReels-V2 Model against other leading open-source Text-To-Video models, we conduct comprehensive evaluations using the public benchmark &lt;a href="https://github.com/Vchitect/VBench"&gt;V-Bench&lt;/a&gt;. Our evaluation specifically leverages the benchmark‚Äôs longer version prompt. For fair comparison with baseline models, we strictly follow their recommended setting for inference.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;table align="center"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Total Score&lt;/th&gt; 
   &lt;th&gt;Quality Score&lt;/th&gt; 
   &lt;th&gt;Semantic Score&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora"&gt;OpenSora 2.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;81.5 %&lt;/td&gt; 
   &lt;td&gt;82.1 %&lt;/td&gt; 
   &lt;td&gt;78.2 %&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/THUDM/CogVideo"&gt;CogVideoX1.5-5B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;80.3 %&lt;/td&gt; 
   &lt;td&gt;80.9 %&lt;/td&gt; 
   &lt;td&gt;77.9 %&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tencent/HunyuanVideo"&gt;HunyuanVideo-13B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;82.7 %&lt;/td&gt; 
   &lt;td&gt;84.4 %&lt;/td&gt; 
   &lt;td&gt;76.2 %&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;Wan2.1-14B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;83.7 %&lt;/td&gt; 
   &lt;td&gt;84.2 %&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;81.4 %&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SkyReels-V2&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;83.9 %&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;84.7 %&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;80.8 %&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;The VBench results demonstrate that SkyReels-V2 outperforms all compared models including HunyuanVideo-13B and Wan2.1-14B, With the highest &lt;strong&gt;total score (83.9%)&lt;/strong&gt; and &lt;strong&gt;quality score (84.7%)&lt;/strong&gt;. In this evaluation, the semantic score is slightly lower than Wan2.1-14B, while we outperform Wan2.1-14B in human evaluations, with the primary gap attributed to V-Bench‚Äôs insufficient evaluation of shot-scenario semantic adherence.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We would like to thank the contributors of &lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;Wan 2.1&lt;/a&gt;, &lt;a href="https://github.com/xdit-project/xDiT"&gt;XDit&lt;/a&gt; and &lt;a href="https://qwenlm.github.io/blog/qwen2.5/"&gt;Qwen 2.5&lt;/a&gt; repositories, for their open research and contributions.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{chen2025skyreelsv2infinitelengthfilmgenerative,
      title={SkyReels-V2: Infinite-length Film Generative Model}, 
      author={Guibin Chen and Dixuan Lin and Jiangping Yang and Chunze Lin and Junchen Zhu and Mingyuan Fan and Hao Zhang and Sheng Chen and Zheng Chen and Chengcheng Ma and Weiming Xiong and Wei Wang and Nuo Pang and Kang Kang and Zhiheng Xu and Yuzhe Jin and Yupeng Liang and Yubing Song and Peng Zhao and Boyuan Xu and Di Qiu and Debang Li and Zhengcong Fei and Yang Li and Yahui Zhou},
      year={2025},
      eprint={2504.13074},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.13074}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>kijai/ComfyUI-WanVideoWrapper</title>
      <link>https://github.com/kijai/ComfyUI-WanVideoWrapper</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI wrapper nodes for &lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;WanVideo&lt;/a&gt; and related models.&lt;/h1&gt; 
&lt;h1&gt;WORK IN PROGRESS (perpetually)&lt;/h1&gt; 
&lt;h1&gt;Why should I use custom nodes when WanVideo works natively?&lt;/h1&gt; 
&lt;p&gt;Short answer: Unless it's a model/feature not available yet on native, you shouldn't.&lt;/p&gt; 
&lt;p&gt;Long answer: Due to the complexity of ComfyUI core code, and my lack of coding experience, in many cases it's far easier and faster to implement new models and features to a standalone wrapper, so this is a way to test things relatively quickly. I consider this my personal sandbox (which is obviously open for everyone) to play with without having to worry about compability issues etc, but as such this code is always work in progress and prone to have issues. Also not all new models end up being worth the trouble to implement in core Comfy, though I've also made some patcher nodes to allow using them in native workflows, such as the &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;ATI&lt;/a&gt; node available in this wrapper. This is also the end goal, idea isn't to compete or even offer alternatives to everything available in native workflows. All that said (this is clearly not a sales pitch) I do appreciate everyone using these nodes to explore new releases and possibilities with WanVideo.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repo into &lt;code&gt;custom_nodes&lt;/code&gt; folder.&lt;/li&gt; 
 &lt;li&gt;Install dependencies: &lt;code&gt;pip install -r requirements.txt&lt;/code&gt; or if you use the portable install, run this in ComfyUI_windows_portable -folder:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-WanVideoWrapper\requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Models&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy/tree/main"&gt;https://huggingface.co/Kijai/WanVideo_comfy/tree/main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;fp8 scaled models (personal recommendation):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled"&gt;https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Text encoders to &lt;code&gt;ComfyUI/models/text_encoders&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Clip vision to &lt;code&gt;ComfyUI/models/clip_vision&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Transformer (main video model) to &lt;code&gt;ComfyUI/models/diffusion_models&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Vae to &lt;code&gt;ComfyUI/models/vae&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can also use the native ComfyUI text encoding and clip vision loader with the wrapper instead of the original models:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/6a2fd9a5-8163-4c93-b362-92ef34dbd3a4" alt="image"&gt;&lt;/p&gt; 
&lt;p&gt;GGUF models can now be loaded in the main model loader as well.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Supported extra models:&lt;/p&gt; 
&lt;p&gt;SkyReels: &lt;a href="https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9"&gt;https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WanVideoFun: &lt;a href="https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17"&gt;https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ReCamMaster: &lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;https://github.com/KwaiVGI/ReCamMaster&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;VACE: &lt;a href="https://github.com/ali-vilab/VACE"&gt;https://github.com/ali-vilab/VACE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Phantom: &lt;a href="https://huggingface.co/bytedance-research/Phantom"&gt;https://huggingface.co/bytedance-research/Phantom&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ATI: &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;https://huggingface.co/bytedance-research/ATI&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Uni3C: &lt;a href="https://github.com/alibaba-damo-academy/Uni3C"&gt;https://github.com/alibaba-damo-academy/Uni3C&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MiniMaxRemover: &lt;a href="https://huggingface.co/zibojia/minimax-remover"&gt;https://huggingface.co/zibojia/minimax-remover&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MAGREF: &lt;a href="https://huggingface.co/MAGREF-Video/MAGREF"&gt;https://huggingface.co/MAGREF-Video/MAGREF&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;FantasyTalking: &lt;a href="https://github.com/Fantasy-AMAP/fantasy-talking"&gt;https://github.com/Fantasy-AMAP/fantasy-talking&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MultiTalk: &lt;a href="https://github.com/MeiGen-AI/MultiTalk"&gt;https://github.com/MeiGen-AI/MultiTalk&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;EchoShot: &lt;a href="https://github.com/D2I-ai/EchoShot"&gt;https://github.com/D2I-ai/EchoShot&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Examples:&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;ReCamMaster&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e"&gt;https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;TeaCache (with the old temporary WIP naive version, I2V):&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that with the new version the threshold values should be 10x higher&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Range of 0.25-0.30 seems good when using the coefficients, start step can be 0, with more aggressive threshold values it may make sense to start later to avoid any potential step skips early on, that generally ruin the motion.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46"&gt;https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Context window test:&lt;/p&gt; 
&lt;p&gt;1025 frames using window size of 81 frames, with 16 overlap. With the 1.3B T2V model this used under 5GB VRAM and took 10 minutes to gen on a 5090:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e"&gt;https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;This very first test was 512x512x81&lt;/p&gt; 
&lt;p&gt;~16GB used with 20/40 blocks offloaded&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f"&gt;https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Vid2vid example:&lt;/p&gt; 
&lt;p&gt;with 14B T2V model:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8"&gt;https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;with 1.3B T2V model&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e"&gt;https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gradio-app/gradio</title>
      <link>https://github.com/gradio-app/gradio</link>
      <description>&lt;p&gt;Build and share delightful machine learning apps, all in Python. üåü Star to support our work!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://gradio.app"&gt; &lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/gradio.svg?sanitize=true" alt="gradio" width="350"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;span&gt; &lt;a href="https://www.producthunt.com/posts/gradio-5-0?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-gradio-5-0" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=501906&amp;amp;theme=light" alt="Gradio 5.0 - the easiest way to build AI web apps | Product Hunt" style="width: 150px; height: 54px;" width="150" height="54"&gt;&lt;/a&gt; &lt;a href="https://trendshift.io/repositories/2145" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/2145" alt="gradio-app%2Fgradio | Trendshift" style="width: 150px; height: 55px;" width="150" height="55"&gt;&lt;/a&gt; &lt;/span&gt; 
 &lt;p&gt;&lt;a href="https://github.com/gradio-app/gradio/actions/workflows/test-python.yml"&gt;&lt;img src="https://github.com/gradio-app/gradio/actions/workflows/test-python.yml/badge.svg?sanitize=true" alt="gradio-backend"&gt;&lt;/a&gt; &lt;a href="https://github.com/gradio-app/gradio/actions/workflows/tests-js.yml"&gt;&lt;img src="https://github.com/gradio-app/gradio/actions/workflows/tests-js.yml/badge.svg?sanitize=true" alt="gradio-ui"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/gradio/"&gt;&lt;img src="https://img.shields.io/pypi/v/gradio" alt="PyPI"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/gradio/"&gt;&lt;img src="https://img.shields.io/pypi/dm/gradio" alt="PyPI downloads"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/python-3.10+-important" alt="Python version"&gt; &lt;a href="https://twitter.com/gradio"&gt;&lt;img src="https://img.shields.io/twitter/follow/gradio?style=social&amp;amp;label=follow" alt="Twitter follow"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://gradio.app"&gt;Website&lt;/a&gt; | &lt;a href="https://gradio.app/docs/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://gradio.app/guides/"&gt;Guides&lt;/a&gt; | &lt;a href="https://gradio.app/getting_started/"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/gradio-app/gradio/main/demo/"&gt;Examples&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/zh-cn#readme"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;Gradio: Build Machine Learning Web Apps ‚Äî in Python&lt;/h1&gt; 
&lt;p&gt;Gradio is an open-source Python package that allows you to quickly &lt;strong&gt;build&lt;/strong&gt; a demo or web application for your machine learning model, API, or any arbitrary Python function. You can then &lt;strong&gt;share&lt;/strong&gt; a link to your demo or web application in just a few seconds using Gradio's built-in sharing features. &lt;em&gt;No JavaScript, CSS, or web hosting experience needed!&lt;/em&gt;&lt;/p&gt; 
&lt;img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/gif-version.gif" style="padding-bottom: 10px"&gt; 
&lt;p&gt;It just takes a few lines of Python to create your own demo, so let's get started üí´&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisite&lt;/strong&gt;: Gradio requires &lt;a href="https://www.python.org/downloads/"&gt;Python 3.10 or higher&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We recommend installing Gradio using &lt;code&gt;pip&lt;/code&gt;, which is included by default in Python. Run this in your terminal or command prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade gradio
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] It is best to install Gradio in a virtual environment. Detailed installation instructions for all common operating systems &lt;a href="https://www.gradio.app/main/guides/installing-gradio-in-a-virtual-environment"&gt;are provided here&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Building Your First Demo&lt;/h3&gt; 
&lt;p&gt;You can run Gradio in your favorite code editor, Jupyter notebook, Google Colab, or anywhere else you write Python. Let's write your first Gradio app:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import gradio as gr

def greet(name, intensity):
    return "Hello, " + name + "!" * int(intensity)

demo = gr.Interface(
    fn=greet,
    inputs=["text", "slider"],
    outputs=["text"],
)

demo.launch()
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] We shorten the imported name from &lt;code&gt;gradio&lt;/code&gt; to &lt;code&gt;gr&lt;/code&gt;. This is a widely adopted convention for better readability of code.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Now, run your code. If you've written the Python code in a file named &lt;code&gt;app.py&lt;/code&gt;, then you would run &lt;code&gt;python app.py&lt;/code&gt; from the terminal.&lt;/p&gt; 
&lt;p&gt;The demo below will open in a browser on &lt;a href="http://localhost:7860"&gt;http://localhost:7860&lt;/a&gt; if running from a file. If you are running within a notebook, the demo will appear embedded within the notebook.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/demo/hello_world_4/screenshot.gif" alt="hello_world_4 demo"&gt;&lt;/p&gt; 
&lt;p&gt;Type your name in the textbox on the left, drag the slider, and then press the Submit button. You should see a friendly greeting on the right.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] When developing locally, you can run your Gradio app in &lt;strong&gt;hot reload mode&lt;/strong&gt;, which automatically reloads the Gradio app whenever you make changes to the file. To do this, simply type in &lt;code&gt;gradio&lt;/code&gt; before the name of the file instead of &lt;code&gt;python&lt;/code&gt;. In the example above, you would type: &lt;code&gt;gradio app.py&lt;/code&gt; in your terminal. Learn more in the &lt;a href="https://www.gradio.app/guides/developing-faster-with-reload-mode"&gt;Hot Reloading Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Understanding the &lt;code&gt;Interface&lt;/code&gt; Class&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You'll notice that in order to make your first demo, you created an instance of the &lt;code&gt;gr.Interface&lt;/code&gt; class. The &lt;code&gt;Interface&lt;/code&gt; class is designed to create demos for machine learning models which accept one or more inputs, and return one or more outputs.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;Interface&lt;/code&gt; class has three core arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;fn&lt;/code&gt;: the function to wrap a user interface (UI) around&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;inputs&lt;/code&gt;: the Gradio component(s) to use for the input. The number of components should match the number of arguments in your function.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;outputs&lt;/code&gt;: the Gradio component(s) to use for the output. The number of components should match the number of return values from your function.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;fn&lt;/code&gt; argument is very flexible -- you can pass &lt;em&gt;any&lt;/em&gt; Python function that you want to wrap with a UI. In the example above, we saw a relatively simple function, but the function could be anything from a music generator to a tax calculator to the prediction function of a pretrained machine learning model.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; arguments take one or more Gradio components. As we'll see, Gradio includes more than &lt;a href="https://www.gradio.app/docs/gradio/introduction"&gt;30 built-in components&lt;/a&gt; (such as the &lt;code&gt;gr.Textbox()&lt;/code&gt;, &lt;code&gt;gr.Image()&lt;/code&gt;, and &lt;code&gt;gr.HTML()&lt;/code&gt; components) that are designed for machine learning applications.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] For the &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; arguments, you can pass in the name of these components as a string (&lt;code&gt;"textbox"&lt;/code&gt;) or an instance of the class (&lt;code&gt;gr.Textbox()&lt;/code&gt;).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If your function accepts more than one argument, as is the case above, pass a list of input components to &lt;code&gt;inputs&lt;/code&gt;, with each input component corresponding to one of the arguments of the function, in order. The same holds true if your function returns more than one value: simply pass in a list of components to &lt;code&gt;outputs&lt;/code&gt;. This flexibility makes the &lt;code&gt;Interface&lt;/code&gt; class a very powerful way to create demos.&lt;/p&gt; 
&lt;p&gt;We'll dive deeper into the &lt;code&gt;gr.Interface&lt;/code&gt; on our series on &lt;a href="https://www.gradio.app/main/guides/the-interface-class"&gt;building Interfaces&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Sharing Your Demo&lt;/h3&gt; 
&lt;p&gt;What good is a beautiful demo if you can't share it? Gradio lets you easily share a machine learning demo without having to worry about the hassle of hosting on a web server. Simply set &lt;code&gt;share=True&lt;/code&gt; in &lt;code&gt;launch()&lt;/code&gt;, and a publicly accessible URL will be created for your demo. Let's revisit our example demo, but change the last line as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import gradio as gr

def greet(name):
    return "Hello " + name + "!"

demo = gr.Interface(fn=greet, inputs="textbox", outputs="textbox")
    
demo.launch(share=True)  # Share your demo with just 1 extra parameter üöÄ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When you run this code, a public URL will be generated for your demo in a matter of seconds, something like:&lt;/p&gt; 
&lt;p&gt;üëâ &amp;nbsp; &lt;code&gt;https://a23dsf231adb.gradio.live&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Now, anyone around the world can try your Gradio demo from their browser, while the machine learning model and all computation continues to run locally on your computer.&lt;/p&gt; 
&lt;p&gt;To learn more about sharing your demo, read our dedicated guide on &lt;a href="https://www.gradio.app/guides/sharing-your-app"&gt;sharing your Gradio application&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;An Overview of Gradio&lt;/h3&gt; 
&lt;p&gt;So far, we've been discussing the &lt;code&gt;Interface&lt;/code&gt; class, which is a high-level class that lets to build demos quickly with Gradio. But what else does Gradio include?&lt;/p&gt; 
&lt;h4&gt;Custom Demos with &lt;code&gt;gr.Blocks&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Gradio offers a low-level approach for designing web apps with more customizable layouts and data flows with the &lt;code&gt;gr.Blocks&lt;/code&gt; class. Blocks supports things like controlling where components appear on the page, handling multiple data flows and more complex interactions (e.g. outputs can serve as inputs to other functions), and updating properties/visibility of components based on user interaction ‚Äî still all in Python.&lt;/p&gt; 
&lt;p&gt;You can build very custom and complex applications using &lt;code&gt;gr.Blocks()&lt;/code&gt;. For example, the popular image generation &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;Automatic1111 Web UI&lt;/a&gt; is built using Gradio Blocks. We dive deeper into the &lt;code&gt;gr.Blocks&lt;/code&gt; on our series on &lt;a href="https://www.gradio.app/guides/blocks-and-event-listeners"&gt;building with Blocks&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Chatbots with &lt;code&gt;gr.ChatInterface&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Gradio includes another high-level class, &lt;code&gt;gr.ChatInterface&lt;/code&gt;, which is specifically designed to create Chatbot UIs. Similar to &lt;code&gt;Interface&lt;/code&gt;, you supply a function and Gradio creates a fully working Chatbot UI. If you're interested in creating a chatbot, you can jump straight to &lt;a href="https://www.gradio.app/guides/creating-a-chatbot-fast"&gt;our dedicated guide on &lt;code&gt;gr.ChatInterface&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;The Gradio Python &amp;amp; JavaScript Ecosystem&lt;/h4&gt; 
&lt;p&gt;That's the gist of the core &lt;code&gt;gradio&lt;/code&gt; Python library, but Gradio is actually so much more! It's an entire ecosystem of Python and JavaScript libraries that let you build machine learning applications, or query them programmatically, in Python or JavaScript. Here are other related parts of the Gradio ecosystem:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.gradio.app/guides/getting-started-with-the-python-client"&gt;Gradio Python Client&lt;/a&gt; (&lt;code&gt;gradio_client&lt;/code&gt;): query any Gradio app programmatically in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.gradio.app/guides/getting-started-with-the-js-client"&gt;Gradio JavaScript Client&lt;/a&gt; (&lt;code&gt;@gradio/client&lt;/code&gt;): query any Gradio app programmatically in JavaScript.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.gradio.app/guides/gradio-lite"&gt;Gradio-Lite&lt;/a&gt; (&lt;code&gt;@gradio/lite&lt;/code&gt;): write Gradio apps in Python that run entirely in the browser (no server needed!), thanks to Pyodide.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces"&gt;Hugging Face Spaces&lt;/a&gt;: the most popular place to host Gradio applications ‚Äî for free!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What's Next?&lt;/h3&gt; 
&lt;p&gt;Keep learning about Gradio sequentially using the Gradio Guides, which include explanations as well as example code and embedded interactive demos. Next up: &lt;a href="https://www.gradio.app/guides/the-interface-class"&gt;let's dive deeper into the Interface class&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Or, if you already know the basics and are looking for something specific, you can search the more &lt;a href="https://www.gradio.app/docs/"&gt;technical API documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Gradio Sketch&lt;/h3&gt; 
&lt;p&gt;You can also build Gradio applications without writing any code. Simply type &lt;code&gt;gradio sketch&lt;/code&gt; into your terminal to open up an editor that lets you define and modify Gradio components, adjust their layouts, add events, all through a web editor. Or &lt;a href="https://huggingface.co/spaces/aliabid94/Sketch"&gt;use this hosted version of Gradio Sketch, running on Hugging Face Spaces&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Questions?&lt;/h2&gt; 
&lt;p&gt;If you'd like to report a bug or have a feature request, please create an &lt;a href="https://github.com/gradio-app/gradio/issues/new/choose"&gt;issue on GitHub&lt;/a&gt;. For general questions about usage, we are available on &lt;a href="https://discord.com/invite/feTf9x3ZSB"&gt;our Discord server&lt;/a&gt; and happy to help.&lt;/p&gt; 
&lt;p&gt;If you like Gradio, please leave us a ‚≠ê on GitHub!&lt;/p&gt; 
&lt;h2&gt;Open Source Stack&lt;/h2&gt; 
&lt;p&gt;Gradio is built on top of many wonderful open-source libraries!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/huggingface_mini.svg?sanitize=true" alt="huggingface" height="40"&gt;&lt;/a&gt; &lt;a href="https://www.python.org"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/python.svg?sanitize=true" alt="python" height="40"&gt;&lt;/a&gt; &lt;a href="https://fastapi.tiangolo.com"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/fastapi.svg?sanitize=true" alt="fastapi" height="40"&gt;&lt;/a&gt; &lt;a href="https://www.encode.io"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/encode.svg?sanitize=true" alt="encode" height="40"&gt;&lt;/a&gt; &lt;a href="https://svelte.dev"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/svelte.svg?sanitize=true" alt="svelte" height="40"&gt;&lt;/a&gt; &lt;a href="https://vitejs.dev"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/vite.svg?sanitize=true" alt="vite" height="40"&gt;&lt;/a&gt; &lt;a href="https://pnpm.io"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/pnpm.svg?sanitize=true" alt="pnpm" height="40"&gt;&lt;/a&gt; &lt;a href="https://tailwindcss.com"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/tailwind.svg?sanitize=true" alt="tailwind" height="40"&gt;&lt;/a&gt; &lt;a href="https://storybook.js.org/"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/storybook.svg?sanitize=true" alt="storybook" height="40"&gt;&lt;/a&gt; &lt;a href="https://www.chromatic.com/"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/chromatic.svg?sanitize=true" alt="chromatic" height="40"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Gradio is licensed under the Apache License 2.0 found in the &lt;a href="https://raw.githubusercontent.com/gradio-app/gradio/main/LICENSE"&gt;LICENSE&lt;/a&gt; file in the root directory of this repository.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Also check out the paper &lt;em&gt;&lt;a href="https://arxiv.org/abs/1906.02569"&gt;Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild&lt;/a&gt;, ICML HILL 2019&lt;/em&gt;, and please cite it if you use Gradio in your work.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@article{abid2019gradio,
  title = {Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild},
  author = {Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},
  journal = {arXiv preprint arXiv:1906.02569},
  year = {2019},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Huanshere/VideoLingo</title>
      <link>https://github.com/Huanshere/VideoLingo</link>
      <description>&lt;p&gt;Netflix-level subtitle cutting, translation, alignment, and even dubbing - one-click fully automated AI video subtitle team | NetflixÁ∫ßÂ≠óÂπïÂàáÂâ≤„ÄÅÁøªËØë„ÄÅÂØπÈΩê„ÄÅÁîöËá≥Âä†‰∏äÈÖçÈü≥Ôºå‰∏ÄÈîÆÂÖ®Ëá™Âä®ËßÜÈ¢ëÊê¨ËøêAIÂ≠óÂπïÁªÑ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/docs/logo.png" alt="VideoLingo Logo" height="140"&gt; 
 &lt;h1&gt;Connect the World, Frame by Frame&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12200" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12200" alt="Huanshere%2FVideoLingo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/README.md"&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.zh.md"&gt;&lt;strong&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.zh-TW.md"&gt;&lt;strong&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.ja.md"&gt;&lt;strong&gt;Êó•Êú¨Ë™û&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.es.md"&gt;&lt;strong&gt;Espa√±ol&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.ru.md"&gt;&lt;strong&gt;–†—É—Å—Å–∫–∏–π&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.fr.md"&gt;&lt;strong&gt;Fran√ßais&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü Overview (&lt;a href="https://videolingo.io"&gt;Try VL Now!&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;VideoLingo is an all-in-one video translation, localization, and dubbing tool aimed at generating Netflix-quality subtitles. It eliminates stiff machine translations and multi-line subtitles while adding high-quality dubbing, enabling global knowledge sharing across language barriers.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üé• YouTube video download via yt-dlp&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéôÔ∏è Word-level and Low-illusion subtitle recognition with WhisperX&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù NLP and AI-powered subtitle segmentation&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìö Custom + AI-generated terminology for coherent translation&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîÑ 3-step Translate-Reflect-Adaptation for cinematic quality&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚úÖ Netflix-standard, Single-line subtitles Only&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üó£Ô∏è Dubbing with GPT-SoVITS, Azure, OpenAI, and more&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üöÄ One-click startup and processing in Streamlit&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üåç Multi-language support in Streamlit UI&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìù Detailed logging with progress resumption&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Difference from similar projects: &lt;strong&gt;Single-line subtitles only, superior translation quality, seamless dubbing experience&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üé• Demo&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%"&gt; &lt;h3&gt;Dual Subtitles&lt;/h3&gt; 
    &lt;hr&gt; &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/a5c3d8d1-2b29-4ba9-b0d0-25896829d951"&gt;https://github.com/user-attachments/assets/a5c3d8d1-2b29-4ba9-b0d0-25896829d951&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;h3&gt;Cosy2 Voice Clone&lt;/h3&gt; 
    &lt;hr&gt; &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/e065fe4c-3694-477f-b4d6-316917df7c0a"&gt;https://github.com/user-attachments/assets/e065fe4c-3694-477f-b4d6-316917df7c0a&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;h3&gt;GPT-SoVITS with my voice&lt;/h3&gt; 
    &lt;hr&gt; &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/47d965b2-b4ab-4a0b-9d08-b49a7bf3508c"&gt;https://github.com/user-attachments/assets/47d965b2-b4ab-4a0b-9d08-b49a7bf3508c&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Language Support&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Input Language Support(more to come):&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;üá∫üá∏ English ü§© | üá∑üá∫ Russian üòä | üá´üá∑ French ü§© | üá©üá™ German ü§© | üáÆüáπ Italian ü§© | üá™üá∏ Spanish ü§© | üáØüáµ Japanese üòê | üá®üá≥ Chinese* üòä&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;*Chinese uses a separate punctuation-enhanced whisper model, for now...&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Translation supports all languages, while dubbing language depends on the chosen TTS method.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Meet any problem? Chat with our free online AI agent &lt;a href="https://share.fastgpt.in/chat/share?shareId=066w11n3r9aq6879r4z0v9rh"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; to help you.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For Windows users with NVIDIA GPU, follow these steps before installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda_12.6.0_560.76_windows.exe"&gt;CUDA Toolkit 12.6&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/cudnn_9.3.0_windows.exe"&gt;CUDNN 9.3.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Add &lt;code&gt;C:\Program Files\NVIDIA\CUDNN\v9.3\bin\12.6&lt;/code&gt; to your system PATH&lt;/li&gt; 
  &lt;li&gt;Restart your computer&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; FFmpeg is required. Please install it via package managers:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Windows: &lt;code&gt;choco install ffmpeg&lt;/code&gt; (via &lt;a href="https://chocolatey.org/"&gt;Chocolatey&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;macOS: &lt;code&gt;brew install ffmpeg&lt;/code&gt; (via &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;Linux: &lt;code&gt;sudo apt install ffmpeg&lt;/code&gt; (Debian/Ubuntu)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Huanshere/VideoLingo.git
cd VideoLingo
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies(requires &lt;code&gt;python=3.10&lt;/code&gt;)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n videolingo python=3.10.0 -y
conda activate videolingo
python install.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Start the application&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;streamlit run st.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Alternatively, you can use Docker (requires CUDA 12.4 and NVIDIA Driver version &amp;gt;550), see &lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/docs/pages/docs/docker.en-US.md"&gt;Docker docs&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t videolingo .
docker run -d -p 8501:8501 --gpus all videolingo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;APIs&lt;/h2&gt; 
&lt;p&gt;VideoLingo supports OpenAI-Like API format and various TTS interfaces:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLM: &lt;code&gt;claude-3-5-sonnet&lt;/code&gt;, &lt;code&gt;gpt-4.1&lt;/code&gt;, &lt;code&gt;deepseek-v3&lt;/code&gt;, &lt;code&gt;gemini-2.0-flash&lt;/code&gt;, ... (sorted by performance, be cautious with gemini-2.5-flash...)&lt;/li&gt; 
 &lt;li&gt;WhisperX: Run whisperX (large-v3) locally or use 302.ai API&lt;/li&gt; 
 &lt;li&gt;TTS: &lt;code&gt;azure-tts&lt;/code&gt;, &lt;code&gt;openai-tts&lt;/code&gt;, &lt;code&gt;siliconflow-fishtts&lt;/code&gt;, &lt;strong&gt;&lt;code&gt;fish-tts&lt;/code&gt;&lt;/strong&gt;, &lt;code&gt;GPT-SoVITS&lt;/code&gt;, &lt;code&gt;edge-tts&lt;/code&gt;, &lt;code&gt;*custom-tts&lt;/code&gt;(You can modify your own TTS in custom_tts.py!)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; VideoLingo works with &lt;strong&gt;&lt;a href="https://gpt302.saaslink.net/C2oHR9"&gt;302.ai&lt;/a&gt;&lt;/strong&gt; - one API key for all services (LLM, WhisperX, TTS). Or run locally with Ollama and Edge-TTS for free, no API needed!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For detailed installation, API configuration, and batch mode instructions, please refer to the documentation: &lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/docs/pages/docs/start.en-US.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/docs/pages/docs/start.zh-CN.md"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Current Limitations&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;WhisperX transcription performance may be affected by video background noise, as it uses wav2vac model for alignment. For videos with loud background music, please enable Voice Separation Enhancement. Additionally, subtitles ending with numbers or special characters may be truncated early due to wav2vac's inability to map numeric characters (e.g., "1") to their spoken form ("one").&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Using weaker models can lead to errors during processes due to strict JSON format requirements for responses (tried my best to prompt llmüòä). If this error occurs, please delete the &lt;code&gt;output&lt;/code&gt; folder and retry with a different LLM, otherwise repeated execution will read the previous erroneous response causing the same error.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The dubbing feature may not be 100% perfect due to differences in speech rates and intonation between languages, as well as the impact of the translation step. However, this project has implemented extensive engineering processing for speech rates to ensure the best possible dubbing results.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multilingual video transcription recognition will only retain the main language&lt;/strong&gt;. This is because whisperX uses a specialized model for a single language when forcibly aligning word-level subtitles, and will delete unrecognized languages.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;For now, cannot dub multiple characters separately&lt;/strong&gt;, as whisperX's speaker distinction capability is not sufficiently reliable.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License. Special thanks to the following open source projects for their contributions:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/m-bain/whisperX"&gt;whisperX&lt;/a&gt;, &lt;a href="https://github.com/yt-dlp/yt-dlp"&gt;yt-dlp&lt;/a&gt;, &lt;a href="https://github.com/mangiucugna/json_repair"&gt;json_repair&lt;/a&gt;, &lt;a href="https://github.com/LianjiaTech/BELLE"&gt;BELLE&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì¨ Contact Me&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Submit &lt;a href="https://github.com/Huanshere/VideoLingo/issues"&gt;Issues&lt;/a&gt; or &lt;a href="https://github.com/Huanshere/VideoLingo/pulls"&gt;Pull Requests&lt;/a&gt; on GitHub&lt;/li&gt; 
 &lt;li&gt;DM me on Twitter: &lt;a href="https://twitter.com/Huanshere"&gt;@Huanshere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Email me at: &lt;a href="mailto:team@videolingo.io"&gt;team@videolingo.io&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Huanshere/VideoLingo&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=Huanshere/VideoLingo&amp;amp;type=Timeline" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p align="center"&gt;If you find VideoLingo helpful, please give me a ‚≠êÔ∏è!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>chu23465/VT-PR</title>
      <link>https://github.com/chu23465/VT-PR</link>
      <description>&lt;p&gt;VineTrimmer with PlayReady and WideVine support, WIP. A DRM Removal Framework for Streaming Services.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VineTrimmer PlayReady&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Made%20with-python-blue?style=for-the-badge&amp;amp;logo=python" alt="Made Python"&gt;&lt;/a&gt; &lt;a href="https://github.com/chu23465/VT-PR/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/chu23465/VT-PR.svg?style=for-the-badge&amp;amp;color=maroon" alt="Forks"&gt;&lt;/a&gt; &lt;a href="https://github.com/chu23465/VT-PR/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/chu23465/VT-PR.svg?style=for-the-badge&amp;amp;color=teal" alt="Stargazers"&gt;&lt;/a&gt; &lt;a href="https://github.com/chu23465/VT-PR/raw/master/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/chu23465/VT-PR.svg?style=for-the-badge&amp;amp;color=indigo" alt="project_license"&gt;&lt;/a&gt; &lt;a href="https://github.com/chu23465/VT-PR/issues?q=is%3Aissue%20state%3Aclosed"&gt;&lt;img src="https://img.shields.io/github/issues-closed/chu23465/VT-PR.svg?style=for-the-badge&amp;amp;color=green" alt="issue_close"&gt;&lt;/a&gt; &lt;img height="30" src="https://raw.githubusercontent.com/chu23465/VT-PR/refs/heads/dev/assets/icon_transparent.png"&gt;&lt;/p&gt; 
&lt;!--

[![actions_build][actions-shield]][actions-url]

[actions-shield]: https://img.shields.io/github/actions/workflow/status/chu23465/VT-PR/build.svg?style=for-the-badge
[actions-url]: https://github.com/chu23465/VT-PR/actions

--&gt; 
&lt;img src="https://raw.githubusercontent.com/chu23465/VT-PR/refs/heads/dev/assets/screenshot.png"&gt; 
&lt;p&gt;A tool to download and remove DRM from streaming services. Modified to remove Playready DRM in addition to Widevine DRM.&lt;/p&gt; 
&lt;p&gt;The name &lt;code&gt;VineTrimmer&lt;/code&gt; comes from &lt;code&gt;Vine&lt;/code&gt; as in &lt;code&gt;WideVine&lt;/code&gt; and &lt;code&gt;Trimmer&lt;/code&gt; as in remove.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Read the README thoroughly atleast twice. I cannot stress how important this is. There is a reason why this README is so verbose.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] DO NOT USE WITH AMAZON. Amazon is currently banning accounts.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Refer to &lt;a href="https://github.com/chu23465/VT-PR/issues/87"&gt;#87&lt;/a&gt;. I recommend temporarily using &lt;a href="https://github.com/DevLARLEY/PlayreadyProxy2"&gt;this&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;This project is under active development. Expect bugs and errors.&lt;/h2&gt; 
&lt;h2&gt;Disclaimer!!!&lt;/h2&gt; 
&lt;p&gt;This project is ONLY for educational/archival/personal purposes. I do not condone piracy in any form.&lt;/p&gt; 
&lt;p&gt;By using this project you agree that: &lt;code&gt;The developer shall not be held responsible for any account suspensions, terminations, penalties or legal action taken/imposed by third-party platforms. The User acknowledges and agrees that they are solely responsible for complying with all terms, policies, copyright and guidelines of any such platforms.&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;I AM NOT taking credit for the entirety of this project. This project is based on a version of an old fork of &lt;a href="https://github.com/devine-dl/devine"&gt;devine&lt;/a&gt; that was found floating around online. I AM taking credit for about 20% of the additional stuff that I personally worked on.&lt;/p&gt; 
&lt;p&gt;Support for Sport replays (VOD) or live streams is not planned. It's a whole thing with OTT panels and restreaming and whatnot. It's a can of worms that I don't plan on opening.&lt;/p&gt; 
&lt;h2&gt;Supporters&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/m41c0n"&gt;@m41c0n&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install Microsoft Visual C++ Redistributable - &lt;a href="https://aka.ms/vs/17/release/vc_redist.x64.exe"&gt;link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ensure Python is installed in your system (cannot be from the the Microsoft Store). Refer to &lt;a href="https://www.python.org/downloads/"&gt;link&lt;/a&gt;. I recommend python 3.10.11 (or higher). Python 3.13 does not work.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Make sure git is installed in your system by running &lt;code&gt;git --version&lt;/code&gt;. If not refer to &lt;a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git"&gt;link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use below command to download. (Recommended instead of downloading zip)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/chu23465/VT-PR
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Navigate and find &lt;code&gt;install.bat&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run &lt;code&gt;install.bat&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Activate venv using &lt;code&gt;venv.cmd&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For cookies, always extract from homepage of (streaming) service using &lt;a href="https://chrome.google.com/webstore/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc"&gt;Get cookies.txt LOCALLY&lt;/a&gt;. The old &lt;code&gt;open-cookies.txt&lt;/code&gt;extension is not ManifestV3 compliant and the source code has been removed from github and the extension javascript obfuscated. Remove it.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Save cookies to desired folder. Folder name should be &lt;code&gt;Cookies/{full_service_name}&lt;/code&gt;. As in &lt;code&gt;Cookies/ParamountPlus&lt;/code&gt; instead of &lt;code&gt;Cookies/PMTP&lt;/code&gt;. Pay attention to the path if you are on Linux. Path is case sensitive.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run desired command using poetry.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;p&gt;Make sure you have python3 installed. If you have &lt;code&gt;apt&lt;/code&gt; avaialable -&amp;gt; &lt;code&gt;sudo apt install python3&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Then:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;wget https://github.com/chu23465/VT-PR/raw/refs/heads/dev/install.sh &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;I have tested it on only Ubuntu so far. If you have any problems, please open an issue.&lt;/p&gt; 
&lt;h2&gt;Updating&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Backup your &lt;code&gt;vinetrimmer/Cookies/&lt;/code&gt;, &lt;code&gt;vinetrimmer/Cache/&lt;/code&gt;, &lt;code&gt;Downloads&lt;/code&gt; directories just in case.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open a command prompt and navigate into &lt;code&gt;VT-PR&lt;/code&gt; directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use below command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git pull origin
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Make sure &lt;code&gt;git pull&lt;/code&gt; is successful. If not do &lt;code&gt;git stash&lt;/code&gt; and try again.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Config&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;vinetrimmer.yml&lt;/code&gt; located within the &lt;code&gt;/vinetrimmer/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;decryptor:&lt;/code&gt; either &lt;code&gt;mp4decrypt&lt;/code&gt; or &lt;code&gt;packager&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;(shaka-packager fails to decrypt files downloaded from ISM/Microsoft Smooth Streaming manifests)&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;tag:&lt;/code&gt; tag for your release group&lt;/p&gt; 
&lt;p&gt;CDM can be configured per service or per profile.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cdm:
    default: {text}
    Amazon: {text}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Credentials can be added depending on which service it is. You need to use full service name ie. &lt;code&gt;iTunes&lt;/code&gt; instead of &lt;code&gt;iT&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;credentials:
  iTunes: 'username:password'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;All other option can be left to defaults, unless you know what you are doing.&lt;/p&gt; 
&lt;h2&gt;General Options&lt;/h2&gt; 
&lt;p&gt;Usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;poetry run vt dl [OPTIONS] COMMAND [ARGS] [TITLE]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Options:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command line argument&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-d, --debug&lt;/td&gt; 
   &lt;td&gt;Flag to enable debug logging&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-p, --profile&lt;/td&gt; 
   &lt;td&gt;Profile to use when multiple profiles are defined for a service.&lt;/td&gt; 
   &lt;td&gt;"default"&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-q, --quality&lt;/td&gt; 
   &lt;td&gt;Download Resolution ie Height of Video Track wanted&lt;/td&gt; 
   &lt;td&gt;1080&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-cr, --closest-resolution&lt;/td&gt; 
   &lt;td&gt;If resolution specified is not found, defaults to closest resolution available&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-v, --vcodec&lt;/td&gt; 
   &lt;td&gt;Video Codec&lt;/td&gt; 
   &lt;td&gt;H264&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-a, --acodec&lt;/td&gt; 
   &lt;td&gt;Audio Codec&lt;/td&gt; 
   &lt;td&gt;None&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-vb, --vbitrate&lt;/td&gt; 
   &lt;td&gt;Video Bitrate, &lt;code&gt;Min&lt;/code&gt; or a number based on output of --list&lt;/td&gt; 
   &lt;td&gt;Max&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-ab, --abitrate&lt;/td&gt; 
   &lt;td&gt;Audio Bitrate&lt;/td&gt; 
   &lt;td&gt;Max&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-ac, --audio-channels&lt;/td&gt; 
   &lt;td&gt;Select Audio by Channels Configuration, e.g &lt;code&gt;2.0&lt;/code&gt;, &lt;code&gt;5.1&lt;/code&gt;, &lt;code&gt;2.0,5.1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;None&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-mac, --max-audio-compatability&lt;/td&gt; 
   &lt;td&gt;Select multiple audios for maximum compatibility with all devices&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-aa, --atmos&lt;/td&gt; 
   &lt;td&gt;Prefer Atmos Audio&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-r, --range&lt;/td&gt; 
   &lt;td&gt;Video Color Range &lt;code&gt;HDR&lt;/code&gt;, &lt;code&gt;HDR10&lt;/code&gt;, &lt;code&gt;DV&lt;/code&gt;, &lt;code&gt;SDR&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;SDR&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-w, --wanted&lt;/td&gt; 
   &lt;td&gt;Wanted episodes, e.g. &lt;code&gt;S01-S05,S07&lt;/code&gt;, &lt;code&gt;S01E01-S02E03&lt;/code&gt;, &lt;code&gt;S02-S02E03&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Default to all&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-le, --latest-episode&lt;/td&gt; 
   &lt;td&gt;Download only the latest episode on episodes list&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-al, --alang&lt;/td&gt; 
   &lt;td&gt;Language wanted for audio.&lt;/td&gt; 
   &lt;td&gt;Defaults to original language&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-sl, --slang&lt;/td&gt; 
   &lt;td&gt;Language wanted for subtitles.&lt;/td&gt; 
   &lt;td&gt;Defaults to original language&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--proxy&lt;/td&gt; 
   &lt;td&gt;Proxy URI to use. If a 2-letter country is provided, it will try get a proxy from the config.&lt;/td&gt; 
   &lt;td&gt;None&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-A, --audio-only&lt;/td&gt; 
   &lt;td&gt;Only download audio tracks.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-S, --subs-only&lt;/td&gt; 
   &lt;td&gt;Only download subtitle tracks.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-C, --chapters-only&lt;/td&gt; 
   &lt;td&gt;Only download chapters.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-ns, --no-subs&lt;/td&gt; 
   &lt;td&gt;Do not download subtitle tracks.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-na, --no-audio&lt;/td&gt; 
   &lt;td&gt;Do not download audio tracks.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-nv, --no-video&lt;/td&gt; 
   &lt;td&gt;Do not download video tracks.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-nc, --no-chapters&lt;/td&gt; 
   &lt;td&gt;Do not download chapters tracks.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-ad, --audio-description&lt;/td&gt; 
   &lt;td&gt;Download audio description tracks.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--list&lt;/td&gt; 
   &lt;td&gt;Skip downloading and list available tracks and what tracks would have been downloaded.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--selected&lt;/td&gt; 
   &lt;td&gt;List selected tracks and what tracks are downloaded.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--cdm&lt;/td&gt; 
   &lt;td&gt;Override the CDM that will be used for decryption.&lt;/td&gt; 
   &lt;td&gt;None&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--keys&lt;/td&gt; 
   &lt;td&gt;Skip downloading, retrieve the decryption keys (via CDM or Key Vaults) and print them.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--cache&lt;/td&gt; 
   &lt;td&gt;Disable the use of the CDM and only retrieve decryption keys from Key Vaults. If a needed key is unable to be retrieved from any Key Vaults, the title is skipped.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--no-cache&lt;/td&gt; 
   &lt;td&gt;Disable the use of Key Vaults and only retrieve decryption keys from the CDM.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--no-proxy&lt;/td&gt; 
   &lt;td&gt;Force disable all proxy use.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-nm, --no-mux&lt;/td&gt; 
   &lt;td&gt;Do not mux the downloaded and decrypted tracks.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--mux&lt;/td&gt; 
   &lt;td&gt;Force muxing when using --audio-only/--subs-only/--chapters-only.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-ss, --strip-sdh&lt;/td&gt; 
   &lt;td&gt;Stip SDH subtitles and convert them to CC. Plus fix common errors.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-mf, --match-forced&lt;/td&gt; 
   &lt;td&gt;Only select forced subtitles matching with specified audio language&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-?, -h, --help&lt;/td&gt; 
   &lt;td&gt;Show this message and exit.&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Currently supported platforms:&lt;/p&gt; 
&lt;p&gt;COMMANDS :-&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Alaias&lt;/th&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Service Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AMZN&lt;/td&gt; 
   &lt;td&gt;Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://amazon.com"&gt;https://amazon.com&lt;/a&gt;, &lt;a href="https://primevideo.com"&gt;https://primevideo.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ATVP&lt;/td&gt; 
   &lt;td&gt;AppleTVPlus&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://tv.apple.com"&gt;https://tv.apple.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DSNP&lt;/td&gt; 
   &lt;td&gt;DisneyPlus&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://disneyplus.com/"&gt;https://disneyplus.com/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;F1TV&lt;/td&gt; 
   &lt;td&gt;F1tv&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://f1tv.formula1.com/"&gt;https://f1tv.formula1.com/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GLB&lt;/td&gt; 
   &lt;td&gt;Globoplay&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://globoplay.globo.com/"&gt;https://globoplay.globo.com/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HS&lt;/td&gt; 
   &lt;td&gt;Hotstar&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.hotstar.com/"&gt;https://www.hotstar.com/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HULU&lt;/td&gt; 
   &lt;td&gt;Hulu&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hulu.com"&gt;https://hulu.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;iT&lt;/td&gt; 
   &lt;td&gt;iTunes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://itunes.apple.com"&gt;https://itunes.apple.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MA&lt;/td&gt; 
   &lt;td&gt;MoviesAnywhere&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://moviesanywhere.com"&gt;https://moviesanywhere.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MAX&lt;/td&gt; 
   &lt;td&gt;Max&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://max.com"&gt;https://max.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCOK&lt;/td&gt; 
   &lt;td&gt;Peacock&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://peacocktv.com/"&gt;https://peacocktv.com/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PMTP&lt;/td&gt; 
   &lt;td&gt;ParamountPlus&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://paramountplus.com"&gt;https://paramountplus.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Untested or not fully implemeted services:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Alaias&lt;/th&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Service Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;iP&lt;/td&gt; 
   &lt;td&gt;BBCiPlayer&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://bbc.co.uk/iplayer"&gt;https://bbc.co.uk/iplayer&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CR&lt;/td&gt; 
   &lt;td&gt;Crunchyroll&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crunchyroll.com"&gt;https://crunchyroll.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PLAY&lt;/td&gt; 
   &lt;td&gt;GooglePlay&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://play.google.com"&gt;https://play.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MUBI&lt;/td&gt; 
   &lt;td&gt;Mubi&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mubi.com/"&gt;https://mubi.com/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;NF&lt;/td&gt; 
   &lt;td&gt;Netflix&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://netflix.com"&gt;https://netflix.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RKTN&lt;/td&gt; 
   &lt;td&gt;RakutenTV&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rakuten.tv"&gt;https://rakuten.tv&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SL&lt;/td&gt; 
   &lt;td&gt;SonyLiv&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://sonyliv.com"&gt;https://sonyliv.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SNXT&lt;/td&gt; 
   &lt;td&gt;Sunnxt&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.sunnxt.com"&gt;https://www.sunnxt.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VIU&lt;/td&gt; 
   &lt;td&gt;Viu&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.viu.com/"&gt;https://www.viu.com/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Amazon Specific Options&lt;/h3&gt; 
&lt;p&gt;Usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;poetry run vt dl [OPTIONS] AMZN [ARGS] [TITLE]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Below flags to be passed after the &lt;code&gt;AMZN&lt;/code&gt; or &lt;code&gt;Amazon&lt;/code&gt; keyword in command.&lt;/p&gt; 
&lt;p&gt;ARGS:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command Line Switch&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-b, --bitrate&lt;/td&gt; 
   &lt;td&gt;Video Bitrate Mode to download in. CVBR=Constrained Variable Bitrate, CBR=Constant Bitrate. (CVBR or CBR or CVBR+CBR)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-c, --cdn&lt;/td&gt; 
   &lt;td&gt;CDN to download from, defaults to the CDN with the highest weight set by Amazon.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-vq, --vquality&lt;/td&gt; 
   &lt;td&gt;Manifest quality to request. (SD or HD or UHD)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-s, --single&lt;/td&gt; 
   &lt;td&gt;Force single episode/season instead of getting series ASIN.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-am, --amanifest&lt;/td&gt; 
   &lt;td&gt;Manifest to use for audio. Defaults to H265 if the video manifest is missing 640k audio. (CVBR or CBR or H265)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-aq, --aquality&lt;/td&gt; 
   &lt;td&gt;Manifest quality to request for audio. Defaults to the same as --quality. (SD or HD or UHD)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-ism, --ism&lt;/td&gt; 
   &lt;td&gt;Set manifest override to SmoothStreaming. Defaults to DASH w/o this flag.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;-?, -h, --help&lt;/td&gt; 
   &lt;td&gt;Show this message and exit.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Remember that not all titles have 4K/Atmos/HDR/DV.&lt;/p&gt; 
&lt;p&gt;To get Atmos/UHD/4k with Amazon, navigate to -&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://www.primevideo.com/mytv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Login and get to the code pair page. Extract cookies from that page.&lt;/p&gt; 
&lt;p&gt;Save it to the path &lt;code&gt;vinetrimmer/Cookies/Amazon/default.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;When caching cookies, use a profile without PIN. Otherwise it may cause errors.&lt;/p&gt; 
&lt;p&gt;If you are facing 403 or 400 errors even after saving fresh cookies and clearing &lt;code&gt;Cache&lt;/code&gt; folder, try logging out of your Amazon account in the browser and logging back in. Then save cookies.&lt;/p&gt; 
&lt;p&gt;Some titles say &lt;code&gt;UHD/2160p&lt;/code&gt; is available and if VT is saying &lt;code&gt;no 2160p track available&lt;/code&gt;, then &lt;code&gt;UHD/2160p&lt;/code&gt; is only available via renting. As in some titles advertise UHD but UHD will not be available to PrimeVideo customers. You will have to rent the title using the Rent button on the title page in UHD quality.&lt;/p&gt; 
&lt;p&gt;If you are getting an &lt;code&gt;AssertionError&lt;/code&gt; with Amazon, then try reprovisioning the device. I have included a batch script in the &lt;code&gt;vinetrimmer/devices/&lt;/code&gt; directory to do this. Simply execute the script and try again.&lt;/p&gt; 
&lt;p&gt;If you are getting &lt;code&gt;TooManyDevices&lt;/code&gt; error or Amazon is giving you trouble with some weird error, then logout in the browser, log back in, extract and use fresh cookies. Try also deleting &lt;code&gt;vinetrimmer/Cache/AMZN/&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to try a different CDM, you will need the corresponding DeviceTypeID (DTID) put into &lt;code&gt;amazon.yml&lt;/code&gt;. As far as I know, you would need to sniff the traffic from the device (with the CDM) to get the DTID.&lt;/p&gt; 
&lt;p&gt;If you are getting &lt;code&gt;PRS.NoRights&lt;/code&gt; error, then there are 3 possible explantations for it. One, CDM simply needs to be reprovisioned. Two, you are using the incorrect DTID for the given CDM. Three, the Amazon has revoked or downgraded the CDM to only HD/SD quality.&lt;/p&gt; 
&lt;p&gt;If your region has ad-free subscription tier, you will need the ad-free subscription tier for 4K/HDR/DV.&lt;/p&gt; 
&lt;h3&gt;Peacock&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Has removed Playready support entirely for UHD, now needs Widevine L1.&lt;/li&gt; 
 &lt;li&gt;Authorization - cookies saved to &lt;code&gt;vinetrimmer/Cookies/Peacock/default.txt&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Hotstar&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;To use, login to Hotstar and navigate to &lt;a href="https://www.hotstar.com/%7Bregion%7D/home"&gt;https://www.hotstar.com/{region}/home&lt;/a&gt;. Extract cookies from that page and save to path &lt;code&gt;vinetrimmer\Cookies\Hotstar\default.txt&lt;/code&gt; (Case sensitive).&lt;/li&gt; 
 &lt;li&gt;Otherwise add credentials to &lt;code&gt;vinetrimmer.yml&lt;/code&gt;. An example is given.&lt;/li&gt; 
 &lt;li&gt;A free account has access to lots of content.&lt;/li&gt; 
 &lt;li&gt;Hotstar requires an Indian (+91) phone number to signup to Indian region, even for free account.&lt;/li&gt; 
 &lt;li&gt;Hates VPN's, try using a residential proxy if you have one.&lt;/li&gt; 
 &lt;li&gt;All content is licensed via Widevine L3 or has no DRM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;DisneyPlus&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Needs only credentials added to &lt;code&gt;vinetrimmer.yml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Requires you to use &lt;code&gt;-m&lt;/code&gt; or &lt;code&gt;--movie&lt;/code&gt; flag if you are downloading a movie. Append flag to end of your command.&lt;/li&gt; 
 &lt;li&gt;From my testing, when using with VPN, it causes lots of issues, mainly needing to clear &lt;code&gt;Cache&lt;/code&gt; folder and login repeatedly. Use residential proxies if available. Don't hammer service. Try waiting a minute or two before logging in again.&lt;/li&gt; 
 &lt;li&gt;If you are getting &lt;code&gt;No 2160p track found&lt;/code&gt; error for a title you know has 4k, then try passing &lt;code&gt;-r DV&lt;/code&gt; or &lt;code&gt;-r HDR&lt;/code&gt;. Make sure your account can access highest qualities.&lt;/li&gt; 
 &lt;li&gt;Should be more stable now when using proxy. But do be careful. We don't use proxy for downloading segments, which means your IP could get temporarily banned from DSNP servers (i.e persistent 403 errors). If you download the same title multiple times or many titles/episodes at once/too quickly your IP address could get banned. Happened to me while testing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Hulu&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Authorization: cookies saved to &lt;code&gt;vinetrimmer/Cookies/Hulu/default.txt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Windscribe VPN sometimes fails. Simply try again.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;AppleTVPlus&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;For &lt;code&gt;--keys&lt;/code&gt; to work with ATVP you need to pass the &lt;code&gt;--no-subs&lt;/code&gt; flag.&lt;/li&gt; 
 &lt;li&gt;You only need proxy/VPN to login once, extract cookies and do a first run.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;iTunes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;iTunes via rential channel on AppleTVPlus.&lt;/li&gt; 
 &lt;li&gt;Login to iTunes in a browser. Try playing a movie. It'll redirect you to &lt;code&gt;tv.apple.com&lt;/code&gt;. Cache cookies from that page to &lt;code&gt;vinetrimmer/Cookies/iTunes/default.txt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Requires you to use &lt;code&gt;-m&lt;/code&gt; or &lt;code&gt;--movie&lt;/code&gt; flag if you are downloading a movie. Append flag to end of your command.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MoviesAnywhere&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cookies saved from home page of website to &lt;code&gt;vinetrimmer\Cookies\MoviesAnywhere\default.txt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;This service currently gets 720p keys. For 1080p and 2160p you will need a whitelisted L1 or whitelisted SL3000. I have tried many devices and could not find one that got HD and UHD keys. If you find one please let me know. I cannot do anything more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Example Commands&lt;/h3&gt; 
&lt;p&gt;Amazon Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run vt dl -al en -sl all --selected -q 2160 -r HDR -w S01E18-S01E25 AMZN -b CBR --ism 0IQZZIJ6W6TT2CXPT6ZOZYX396
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Above command:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;gets english audio,&lt;/li&gt; 
 &lt;li&gt;gets all available subtitles,&lt;/li&gt; 
 &lt;li&gt;selects the HDR + 4K track,&lt;/li&gt; 
 &lt;li&gt;gets episodes from S01E18 to S01E25 from Amazon&lt;/li&gt; 
 &lt;li&gt;with CBR bitrate,&lt;/li&gt; 
 &lt;li&gt;tries to force ISM&lt;/li&gt; 
 &lt;li&gt;and the title-ID is 0IQZZIJ6W6TT2CXPT6ZOZYX396&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AppleTV Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run vt dl -al en,it -sl en,es -q 720 --proxy http://192.168.0.99:9766 -w S01E01 ATVP umc.cmc.1nfdfd5zlk05fo1bwwetzldy3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Above command:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;gets english, italian audio&lt;/li&gt; 
 &lt;li&gt;gets english, spanish subtitles,&lt;/li&gt; 
 &lt;li&gt;lists all possible qualities,&lt;/li&gt; 
 &lt;li&gt;selects 720p video track,&lt;/li&gt; 
 &lt;li&gt;uses the proxy for licensing,&lt;/li&gt; 
 &lt;li&gt;gets the first episode of first season (i.e S01E01)&lt;/li&gt; 
 &lt;li&gt;of the title-ID umc.cmc.1nfdfd5zlk05fo1bwwetzldy3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Max Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run vt dl -al en -sl en --keys --proxy http://192.168.0.99:9766 MAX https://play.max.com/show/5756c2bf-36f8-4890-b1f9-ef168f1d8e9c
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Above command:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;gets english subtitles + audio,&lt;/li&gt; 
 &lt;li&gt;skips download and only gets the content keys,&lt;/li&gt; 
 &lt;li&gt;from MAX&lt;/li&gt; 
 &lt;li&gt;uses specified proxy&lt;/li&gt; 
 &lt;li&gt;defaulting to HD for video&lt;/li&gt; 
 &lt;li&gt;title-ID is 5756c2bf-36f8-4890-b1f9-ef168f1d8e9c&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Hotstar Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run vt dl -al en -sl en -q 2160 -v H265 HS https://www.hotstar.com/in/movies/hridayam/1260083403
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Above command:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;gets english subtitles + audio,&lt;/li&gt; 
 &lt;li&gt;sets video codec to H265 codec,&lt;/li&gt; 
 &lt;li&gt;sets video quality (ie. resolution) to 2160p,&lt;/li&gt; 
 &lt;li&gt;Gets highest quality video/audio available.&lt;/li&gt; 
 &lt;li&gt;title-ID is 1271342309&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Max Audio Compatability (MAC)&lt;/h2&gt; 
&lt;p&gt;I have added a special flag called &lt;code&gt;--max-audio-compatability&lt;/code&gt; or &lt;code&gt;-mac&lt;/code&gt; for maximum compatibility with all devices. If passed with &lt;code&gt;--acodec aac,ec3 -ac 2.0,5.1&lt;/code&gt; will select 3 audios like below&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;2025-04-24 16:54:23 [I] Tracks : ‚îú‚îÄ AUD | [E-AC3] | [ec-3] | 5.1 | 640 kb/s | en-US | [Original]
2025-04-24 16:54:23 [I] Tracks : ‚îú‚îÄ AUD | [E-AC3] | [ec-3] | 2.0 | 224 kb/s | en-US | [Original]
2025-04-24 16:54:23 [I] Tracks : ‚îú‚îÄ AUD | [AAC] | [mp4a] | 2.0 | 128 kb/s | en-US | [Original]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If &lt;code&gt;-mac&lt;/code&gt; not passed but only &lt;code&gt;--acodec aac,ec3 -ac 2.0,5.1&lt;/code&gt; passed, will select 2 audios.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;2025-04-24 17:10:04 [I] Tracks : ‚îú‚îÄ AUD | [E-AC3] | [ec-3] | 5.1 | 640 kb/s | en-US | [Original]
2025-04-24 17:10:04 [I] Tracks : ‚îú‚îÄ AUD | [AAC] | [mp4a] | 2.0 | 128 kb/s | en-US | [Original]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Proxy&lt;/h2&gt; 
&lt;p&gt;I recommend &lt;a href="https://windscribe.com/"&gt;Windscribe&lt;/a&gt;. You can sign up, getting 10 GB of traffic credit every month for free. We use the VPN for everything except downloading video/audio. Tested so far on Amazon, AppleTVPlus, Max, and DisneyPlus and Hulu.&lt;/p&gt; 
&lt;h3&gt;Steps:&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Download Windscribe app and install it.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Go to &lt;code&gt;Options&lt;/code&gt; -&amp;gt; &lt;code&gt;Connection&lt;/code&gt; -&amp;gt; &lt;code&gt;Split Tunneling&lt;/code&gt;. Enable it.&lt;/p&gt; &lt;p&gt;Set &lt;code&gt;Mode&lt;/code&gt; as &lt;code&gt;Inclusive&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Go to &lt;code&gt;Options&lt;/code&gt; -&amp;gt; &lt;code&gt;Connection&lt;/code&gt; -&amp;gt; &lt;code&gt;Proxy Gateway&lt;/code&gt;. Enable it. Select &lt;code&gt;Proxy Type&lt;/code&gt; as &lt;code&gt;HTTP&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Copy the &lt;code&gt;IP&lt;/code&gt; field (will look something like &lt;code&gt;192.168.0.141:9766&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;Pass above copied to Vinetrimmer with the proxy flag. If you are using other VPNs, extract the proxy (use the browser extension to do this). It will look something like &lt;code&gt;http(s)://username:pass@host/IP:PORT&lt;/code&gt;. Ex -&amp;gt; &lt;code&gt;http://user:pass@domain.com:443&lt;/code&gt;. Pass it like below:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;poetry run vt dl -q 1080 --proxy http://user:pass@domain.com:443 AMZN [TITLE]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Skip this step if you are not integrating a new service yourself. In the service, within get_tracks() function we do this below. Set needs_proxy to True if your service needs proxy to get manifest (Ex - Netflix, Hotstar).&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;for track in tracks:
    track.needs_proxy = False
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This flag signals that this track does not need a proxy and a proxy will not be passed to downloader even if proxy given in CLI options.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Other&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Errors arise when running VT in non python3 environments. Make sure to use proper python3.&lt;/li&gt; 
 &lt;li&gt;To use programs in &lt;code&gt;scripts&lt;/code&gt; folder, first activate venv then, then - &lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python scripts/ParseKeybox.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;There is another way of running this instead of using &lt;code&gt;poetry&lt;/code&gt;. In root folder of VT-PR there is a &lt;code&gt;vt.py&lt;/code&gt; (which is essentially the same as &lt;code&gt;vinetrimmer/vinetrimmer.py&lt;/code&gt;). Activate venv, then: &lt;pre&gt;&lt;code class="language-bash"&gt;python vt.py dl ......(rest of the command as before).......
&lt;/code&gt;&lt;/pre&gt; This is useful for debugging/stepping through in IDE's without having to deal with poetry.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Nuitka Compile&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Activate venv&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;python -m pip install nuitka&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Verify using command &lt;code&gt;nuitka --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Then:&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nuitka --standalone --output-dir=dist --windows-console-mode=force vt.py --include-data-dir=./vinetrimmer/=vinetrimmer/ --include-data-dir=./binaries/=binaries
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--standalone&lt;/code&gt; will give a folder of compiled pythonic objects. Zip it to distribute. This is recommended.&lt;/li&gt; 
 &lt;li&gt;If you don't want to carry around/deal with a zip, instead use &lt;code&gt;--onefile&lt;/code&gt;. This has the drawback of setting the default folders to the temp folder in whatever OS you are using. This could be fixed with some extra code but that is currently not implemented.&lt;/li&gt; 
 &lt;li&gt;Refer to &lt;a href="https://nuitka.net/user-documentation/user-manual.html"&gt;link&lt;/a&gt; if anything errors out.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Progress Bars for decryption (&lt;a href="https://github.com/chu23465/bentoOldFork"&gt;mp4decrypt&lt;/a&gt;, Shaka)&lt;/li&gt; 
 &lt;li&gt;ISM manifest support (Microsoft Smooth Streaming) (Experimental)&lt;/li&gt; 
 &lt;li&gt;N_m3u8DL-RE downloader support (Experimental)&lt;/li&gt; 
 &lt;li&gt;Resume failed download has been implemented. If a track has been successfully downloaded previously and exists in &lt;code&gt;Temp&lt;/code&gt; directory (encrypted or decrypted), VT will not download said track again.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Broken / To-Do (Descending order of priority)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Add a version.py&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; First stable release&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Shaka with progress bar repository&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Add download speed limit to avoid IP bans.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Single script that installs, and if already installed checks for and applies updates&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Replace poetry with uv&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Ruff liniting and formatting&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Atmos audio with ISM manifest (Amazon)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Add &lt;a href="https://github.com/Eyevinn/mp4ff"&gt;m4ffdecrypt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Hybrid creation with &lt;a href="https://github.com/quietvoid/dovi_tool/"&gt;dovi_tool&lt;/a&gt;. This feature is in Beta. Only tested so far on DisneyPlus. Needs more work. Ex: filenaming needs correction, temp directory is a mess after hybrid creation, use another tool insteal of &lt;code&gt;dovi_tool&lt;/code&gt; to get Profile 8.1 DV-HDR10+ instead of DV Profile 5 HDR10 compatible.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Downloader field in config, per service.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Make a script to download latest binaries for vt automatically at startup.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Detect if running as Nuikta compiled binary, then in vt.py set directories relative to binary path&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Find a way to estimate final file size for a track. Check if enough space is left on disc for double the amount of selected tracks - since mp4decrypt and Nm3u8 both make copies of the files&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Merge DB script&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Modify aria2c to include a progress bar ?&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Github Actions Python script that builds and publishes release for every commit to not readme.md&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; MAX - Fix HDR10/DV --list&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Fix original language (Was removed as workaround for a bug)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Make a windscribe.py for proxies modelled after nordvpn.py. Refer to the chrome extension for the code.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Move to requests, curl or otherwise to download subtitles&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Replace track.dv, track.hdr10 with track.PQ. Value will be an enum. This will require a major-ish rewrite.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Netflix service is currently broken (will probably be fixed Soon‚Ñ¢)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Integrate &lt;a href="https://github.com/vevv/subby"&gt;subby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Licensing before download (?)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Guide for writing a service + debugging&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Implement a scan/hammer/cache keys for each service - pass string of zeros as title id. Then copy and rework dl.py to iterate over returned list of titles from scan function&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Amazon Specific&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Refresh Token for Amazon service&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Pythonic implementation of init.mp4 builder for ism manifest for avc, hvcc, dv, ac3, eac3, eac3-joc codecs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Make a pure python requests based downloader for ISM/MSS manifest. Write init.mp4 then download each segment to memory, decrypt in memory and write it to a binary merged file. Download segments in batches. Batch size based on thread count passed to program. Download has to be sequentially written.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; &lt;code&gt;--bitrate CVBR+CBR&lt;/code&gt; is currently broken&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Get highest quality CBR and CVBR MPD+ISM by default to AMZN&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Specify devices in config for MPD or ISM then load one based on command&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; For videos, download init.mp4 using N_m3u8, mediainfo it to get FPS, HDR info&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Manifest url caching system for every key/Track object.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If anyone has any idea how to fix above issues, feel free to open a pull request.&lt;/p&gt; 
&lt;h2&gt;Donating&lt;/h2&gt; 
&lt;p&gt;I am an independent developer right now. I work on this project in my free time. If you could support me that would be immensely helpful. All supporters will get a special mention in the README. Thank you in advance.&lt;/p&gt; 
&lt;p&gt;My BuyMeACoffee account was suspended so contact me on discord to donate.&lt;/p&gt; 
&lt;p&gt;My Discord is &lt;code&gt;@crapola&lt;/code&gt; or &lt;code&gt;@chupola&lt;/code&gt;. You will need to join a server I'm in to message me. Join one of the servers mentioned below.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/rlaphoenix"&gt;@rlaphoenix&lt;/a&gt; for &lt;a href="https://github.com/devine-dl/pywidevine"&gt;pywidevine&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rlaphoenix"&gt;@rlaphoenix&lt;/a&gt; again as he was the original developer behind the &lt;code&gt;VineTrimmer&lt;/code&gt; base &lt;code&gt;Widevine&lt;/code&gt; version (later renamed to &lt;code&gt;devine&lt;/code&gt;) .&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/DevLARLEY"&gt;@DevLARLEY&lt;/a&gt; for &lt;a href="https://git.gay/ready-dl/pyplayready"&gt;pyplayready&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/FieryFly"&gt;@FieryFly&lt;/a&gt; for an additional MAX fix.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/vevv"&gt;@vevv&lt;/a&gt; for &lt;a href="https://github.com/vevv/subby"&gt;subby&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/globocom/"&gt;@globocom&lt;/a&gt; for &lt;a href="https://github.com/globocom/m3u8"&gt;m3u8&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Wiesiek&lt;/code&gt; on Discord for a few ideas&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/xHjetwZP"&gt;DRM-Lab-Project&lt;/a&gt; for numerous bug fixes and support.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/aNNKxurrU6"&gt;Playready-Discord&lt;/a&gt; for numerous bug fixes and support.&lt;/p&gt; 
&lt;p&gt;Various members of the above mentioned Discord servers for testing, bug reporting, fixes etc. Thank You :)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.cdrm-project.com/"&gt;CDRM-Project&lt;/a&gt; and &lt;code&gt;@TPD94&lt;/code&gt;, &lt;code&gt;@radizu&lt;/code&gt; for getting me started on this journey, being a source of inspiration and for keeping a community well and alive.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/m0ck69"&gt;@m0ck69&lt;/a&gt; for sharing a DisneyPlus account for testing purposes.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/methflix"&gt;@methflix&lt;/a&gt; for sharing a Hulu account for testing purposes.&lt;/p&gt; 
&lt;p&gt;The services included here were not written by me. They were either found in the mentioned Discord servers or shared by an individual. If anyone feels like they deserve a credit in the README, open an issue and I'll add you.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#chu23465/VT-PR&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=chu23465/VT-PR&amp;amp;type=Date&amp;amp;theme=dark"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=chu23465/VT-PR&amp;amp;type=Date"&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=chu23465/VT-PR&amp;amp;type=Date"&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>xinntao/Real-ESRGAN</title>
      <link>https://github.com/xinntao/Real-ESRGAN</link>
      <description>&lt;p&gt;Real-ESRGAN aims at developing Practical Algorithms for General Image/Video Restoration.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/assets/realesrgan_logo.png" height="120"&gt; &lt;/p&gt; 
&lt;h2&gt;
 &lt;div align="center"&gt;
  &lt;b&gt;&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/README_CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/b&gt;
 &lt;/div&gt;&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;üëÄ&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/#-demos-videos"&gt;&lt;strong&gt;Demos&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;|&lt;/strong&gt; üö©&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/#-updates"&gt;&lt;strong&gt;Updates&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;|&lt;/strong&gt; ‚ö°&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/#-quick-inference"&gt;&lt;strong&gt;Usage&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;|&lt;/strong&gt; üè∞&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/model_zoo.md"&gt;&lt;strong&gt;Model Zoo&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;|&lt;/strong&gt; üîß&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/#-dependencies-and-installation"&gt;Install&lt;/a&gt; &lt;strong&gt;|&lt;/strong&gt; üíª&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/Training.md"&gt;Train&lt;/a&gt; &lt;strong&gt;|&lt;/strong&gt; ‚ùì&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/FAQ.md"&gt;FAQ&lt;/a&gt; &lt;strong&gt;|&lt;/strong&gt; üé®&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/CONTRIBUTING.md"&gt;Contribution&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/xinntao/Real-ESRGAN/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/xinntao/Real-ESRGAN/total.svg?sanitize=true" alt="download"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/realesrgan/"&gt;&lt;img src="https://img.shields.io/pypi/v/realesrgan" alt="PyPI"&gt;&lt;/a&gt; &lt;a href="https://github.com/xinntao/Real-ESRGAN/issues"&gt;&lt;img src="https://img.shields.io/github/issues/xinntao/Real-ESRGAN" alt="Open issue"&gt;&lt;/a&gt; &lt;a href="https://github.com/xinntao/Real-ESRGAN/issues"&gt;&lt;img src="https://img.shields.io/github/issues-closed/xinntao/Real-ESRGAN" alt="Closed issue"&gt;&lt;/a&gt; &lt;a href="https://github.com/xinntao/Real-ESRGAN/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/xinntao/Real-ESRGAN.svg?sanitize=true" alt="LICENSE"&gt;&lt;/a&gt; &lt;a href="https://github.com/xinntao/Real-ESRGAN/raw/master/.github/workflows/pylint.yml"&gt;&lt;img src="https://github.com/xinntao/Real-ESRGAN/actions/workflows/pylint.yml/badge.svg?sanitize=true" alt="python lint"&gt;&lt;/a&gt; &lt;a href="https://github.com/xinntao/Real-ESRGAN/raw/master/.github/workflows/publish-pip.yml"&gt;&lt;img src="https://github.com/xinntao/Real-ESRGAN/actions/workflows/publish-pip.yml/badge.svg?sanitize=true" alt="Publish-pip"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;üî• &lt;strong&gt;AnimeVideo-v3 model (Âä®Êº´ËßÜÈ¢ëÂ∞èÊ®°Âûã)&lt;/strong&gt;. Please see [&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/anime_video_model.md"&gt;&lt;em&gt;anime video models&lt;/em&gt;&lt;/a&gt;] and [&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/anime_comparisons.md"&gt;&lt;em&gt;comparisons&lt;/em&gt;&lt;/a&gt;]&lt;br&gt; üî• &lt;strong&gt;RealESRGAN_x4plus_anime_6B&lt;/strong&gt; for anime images &lt;strong&gt;(Âä®Êº´ÊèíÂõæÊ®°Âûã)&lt;/strong&gt;. Please see [&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/anime_model.md"&gt;&lt;em&gt;anime_model&lt;/em&gt;&lt;/a&gt;]&lt;/p&gt; 
&lt;!-- 1. You can try in our website: [ARC Demo](https://arc.tencent.com/en/ai-demos/imgRestore) (now only support RealESRGAN_x4plus_anime_6B) --&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;üí•&lt;/span&gt; &lt;strong&gt;Update&lt;/strong&gt; online Replicate demo: &lt;a href="https://replicate.com/xinntao/realesrgan"&gt;&lt;img src="https://img.shields.io/static/v1?label=Demo&amp;amp;message=Replicate&amp;amp;color=blue" alt="Replicate"&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Online Colab demo for Real-ESRGAN: &lt;a href="https://colab.research.google.com/drive/1k2Zod6kSHEvraybHl50Lys0LerhyTMCo?usp=sharing"&gt;&lt;img src="https://img.shields.io/static/v1?label=Demo&amp;amp;message=Colab&amp;amp;color=orange" alt="Colab"&gt;&lt;/a&gt; &lt;strong&gt;|&lt;/strong&gt; Online Colab demo for for Real-ESRGAN (&lt;strong&gt;anime videos&lt;/strong&gt;): &lt;a href="https://colab.research.google.com/drive/1yNl9ORUxxlL4N0keJa2SEPB61imPQd1B?usp=sharing"&gt;&lt;img src="https://img.shields.io/static/v1?label=Demo&amp;amp;message=Colab&amp;amp;color=orange" alt="Colab"&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Portable &lt;a href="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesrgan-ncnn-vulkan-20220424-windows.zip"&gt;Windows&lt;/a&gt; / &lt;a href="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesrgan-ncnn-vulkan-20220424-ubuntu.zip"&gt;Linux&lt;/a&gt; / &lt;a href="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesrgan-ncnn-vulkan-20220424-macos.zip"&gt;MacOS&lt;/a&gt; &lt;strong&gt;executable files for Intel/AMD/Nvidia GPU&lt;/strong&gt;. You can find more information &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/#portable-executable-files-ncnn"&gt;here&lt;/a&gt;. The ncnn implementation is in &lt;a href="https://github.com/xinntao/Real-ESRGAN-ncnn-vulkan"&gt;Real-ESRGAN-ncnn-vulkan&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;!-- 1. You can watch enhanced animations in [Tencent Video](https://v.qq.com/s/topic/v_child/render/fC4iyCAM.html). Ê¨¢ËøéËßÇÁúã[ËÖæËÆØËßÜÈ¢ëÂä®Êº´‰øÆÂ§ç](https://v.qq.com/s/topic/v_child/render/fC4iyCAM.html) --&gt; 
&lt;p&gt;Real-ESRGAN aims at developing &lt;strong&gt;Practical Algorithms for General Image/Video Restoration&lt;/strong&gt;.&lt;br&gt; We extend the powerful ESRGAN to a practical restoration application (namely, Real-ESRGAN), which is trained with pure synthetic data.&lt;/p&gt; 
&lt;p&gt;üåå Thanks for your valuable feedbacks/suggestions. All the feedbacks are updated in &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/feedback.md"&gt;feedback.md&lt;/a&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;If Real-ESRGAN is helpful, please help to ‚≠ê this repo or recommend it to your friends üòä &lt;br&gt; Other recommended projects:&lt;br&gt; ‚ñ∂Ô∏è &lt;a href="https://github.com/TencentARC/GFPGAN"&gt;GFPGAN&lt;/a&gt;: A practical algorithm for real-world face restoration &lt;br&gt; ‚ñ∂Ô∏è &lt;a href="https://github.com/xinntao/BasicSR"&gt;BasicSR&lt;/a&gt;: An open-source image and video restoration toolbox&lt;br&gt; ‚ñ∂Ô∏è &lt;a href="https://github.com/xinntao/facexlib"&gt;facexlib&lt;/a&gt;: A collection that provides useful face-relation functions.&lt;br&gt; ‚ñ∂Ô∏è &lt;a href="https://github.com/xinntao/HandyView"&gt;HandyView&lt;/a&gt;: A PyQt5-based image viewer that is handy for view and comparison &lt;br&gt; ‚ñ∂Ô∏è &lt;a href="https://github.com/xinntao/HandyFigure"&gt;HandyFigure&lt;/a&gt;: Open source of paper figures &lt;br&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;üìñ Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[&lt;a href="https://arxiv.org/abs/2107.10833"&gt;Paper&lt;/a&gt;] ‚ÄÉ [&lt;a href="https://www.youtube.com/watch?v=fxHWoDSSvSc"&gt;YouTube Video&lt;/a&gt;] ‚ÄÉ [&lt;a href="https://www.bilibili.com/video/BV1H34y1m7sS/"&gt;BÁ´ôËÆ≤Ëß£&lt;/a&gt;] ‚ÄÉ [&lt;a href="https://xinntao.github.io/projects/RealESRGAN_src/RealESRGAN_poster.pdf"&gt;Poster&lt;/a&gt;] ‚ÄÉ [&lt;a href="https://docs.google.com/presentation/d/1QtW6Iy8rm8rGLsJ0Ldti6kP-7Qyzy6XL/edit?usp=sharing&amp;amp;ouid=109799856763657548160&amp;amp;rtpof=true&amp;amp;sd=true"&gt;PPT slides&lt;/a&gt;]&lt;br&gt; &lt;a href="https://xinntao.github.io/"&gt;Xintao Wang&lt;/a&gt;, Liangbin Xie, &lt;a href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ"&gt;Chao Dong&lt;/a&gt;, &lt;a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&amp;amp;hl=en"&gt;Ying Shan&lt;/a&gt; &lt;br&gt; &lt;a href="https://arc.tencent.com/en/ai-demos/imgRestore"&gt;Tencent ARC Lab&lt;/a&gt;; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/assets/teaser.jpg"&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- Updates ---------------------------&gt; 
&lt;h2&gt;üö© Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Add the &lt;strong&gt;realesr-general-x4v3&lt;/strong&gt; model - a tiny small model for general scenes. It also supports the &lt;strong&gt;-dn&lt;/strong&gt; option to balance the noise (avoiding over-smooth results). &lt;strong&gt;-dn&lt;/strong&gt; is short for denoising strength.&lt;/li&gt; 
 &lt;li&gt;‚úÖ Update the &lt;strong&gt;RealESRGAN AnimeVideo-v3&lt;/strong&gt; model. Please see &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/anime_video_model.md"&gt;anime video models&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/anime_comparisons.md"&gt;comparisons&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;‚úÖ Add small models for anime videos. More details are in &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/anime_video_model.md"&gt;anime video models&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;‚úÖ Add the ncnn implementation &lt;a href="https://github.com/xinntao/Real-ESRGAN-ncnn-vulkan"&gt;Real-ESRGAN-ncnn-vulkan&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;‚úÖ Add &lt;a href="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth"&gt;&lt;em&gt;RealESRGAN_x4plus_anime_6B.pth&lt;/em&gt;&lt;/a&gt;, which is optimized for &lt;strong&gt;anime&lt;/strong&gt; images with much smaller model size. More details and comparisons with &lt;a href="https://github.com/nihui/waifu2x-ncnn-vulkan"&gt;waifu2x&lt;/a&gt; are in &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/anime_model.md"&gt;&lt;strong&gt;anime_model.md&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ Support finetuning on your own data or paired data (&lt;em&gt;i.e.&lt;/em&gt;, finetuning ESRGAN). See &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/Training.md#Finetune-Real-ESRGAN-on-your-own-dataset"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ Integrate &lt;a href="https://github.com/TencentARC/GFPGAN"&gt;GFPGAN&lt;/a&gt; to support &lt;strong&gt;face enhancement&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;‚úÖ Integrated to &lt;a href="https://huggingface.co/spaces"&gt;Huggingface Spaces&lt;/a&gt; with &lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio&lt;/a&gt;. See &lt;a href="https://huggingface.co/spaces/akhaliq/Real-ESRGAN"&gt;Gradio Web Demo&lt;/a&gt;. Thanks &lt;a href="https://github.com/AK391"&gt;@AK391&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ Support arbitrary scale with &lt;code&gt;--outscale&lt;/code&gt; (It actually further resizes outputs with &lt;code&gt;LANCZOS4&lt;/code&gt;). Add &lt;em&gt;RealESRGAN_x2plus.pth&lt;/em&gt; model.&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/inference_realesrgan.py"&gt;The inference code&lt;/a&gt; supports: 1) &lt;strong&gt;tile&lt;/strong&gt; options; 2) images with &lt;strong&gt;alpha channel&lt;/strong&gt;; 3) &lt;strong&gt;gray&lt;/strong&gt; images; 4) &lt;strong&gt;16-bit&lt;/strong&gt; images.&lt;/li&gt; 
 &lt;li&gt;‚úÖ The training codes have been released. A detailed guide can be found in &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/Training.md"&gt;Training.md&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;!-- Demo videos ---------------------------&gt; 
&lt;h2&gt;üëÄ Demos Videos&lt;/h2&gt; 
&lt;h4&gt;Bilibili&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.bilibili.com/video/BV1ja41117zb"&gt;Â§ßÈóπÂ§©ÂÆ´ÁâáÊÆµ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.bilibili.com/video/BV1wY4y1L7hT/"&gt;Anime dance cut Âä®Êº´È≠îÊÄßËàûËπà&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.bilibili.com/video/BV1i3411L7Gy/"&gt;Êµ∑Ë¥ºÁéãÁâáÊÆµ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;YouTube&lt;/h4&gt; 
&lt;h2&gt;üîß Dependencies and Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python &amp;gt;= 3.7 (Recommend to use &lt;a href="https://www.anaconda.com/download/#linux"&gt;Anaconda&lt;/a&gt; or &lt;a href="https://docs.conda.io/en/latest/miniconda.html"&gt;Miniconda&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org/"&gt;PyTorch &amp;gt;= 1.7&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone repo&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/xinntao/Real-ESRGAN.git
cd Real-ESRGAN
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install dependent packages&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Install basicsr - https://github.com/xinntao/BasicSR
# We use BasicSR for both training and inference
pip install basicsr
# facexlib and gfpgan are for face enhancement
pip install facexlib
pip install gfpgan
pip install -r requirements.txt
python setup.py develop
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h2&gt;‚ö° Quick Inference&lt;/h2&gt; 
&lt;p&gt;There are usually three ways to inference Real-ESRGAN.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/#online-inference"&gt;Online inference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/#portable-executable-files-ncnn"&gt;Portable executable files (NCNN)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/#python-script"&gt;Python script&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Online inference&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;You can try in our website: &lt;a href="https://arc.tencent.com/en/ai-demos/imgRestore"&gt;ARC Demo&lt;/a&gt; (now only support RealESRGAN_x4plus_anime_6B)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://colab.research.google.com/drive/1k2Zod6kSHEvraybHl50Lys0LerhyTMCo?usp=sharing"&gt;Colab Demo&lt;/a&gt; for Real-ESRGAN &lt;strong&gt;|&lt;/strong&gt; &lt;a href="https://colab.research.google.com/drive/1yNl9ORUxxlL4N0keJa2SEPB61imPQd1B?usp=sharing"&gt;Colab Demo&lt;/a&gt; for Real-ESRGAN (&lt;strong&gt;anime videos&lt;/strong&gt;).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Portable executable files (NCNN)&lt;/h3&gt; 
&lt;p&gt;You can download &lt;a href="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesrgan-ncnn-vulkan-20220424-windows.zip"&gt;Windows&lt;/a&gt; / &lt;a href="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesrgan-ncnn-vulkan-20220424-ubuntu.zip"&gt;Linux&lt;/a&gt; / &lt;a href="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesrgan-ncnn-vulkan-20220424-macos.zip"&gt;MacOS&lt;/a&gt; &lt;strong&gt;executable files for Intel/AMD/Nvidia GPU&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;This executable file is &lt;strong&gt;portable&lt;/strong&gt; and includes all the binaries and models required. No CUDA or PyTorch environment is needed.&lt;br&gt;&lt;/p&gt; 
&lt;p&gt;You can simply run the following command (the Windows example, more information is in the README.md of each executable files):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./realesrgan-ncnn-vulkan.exe -i input.jpg -o output.png -n model_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We have provided five models:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;realesrgan-x4plus (default)&lt;/li&gt; 
 &lt;li&gt;realesrnet-x4plus&lt;/li&gt; 
 &lt;li&gt;realesrgan-x4plus-anime (optimized for anime images, small model size)&lt;/li&gt; 
 &lt;li&gt;realesr-animevideov3 (animation video)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You can use the &lt;code&gt;-n&lt;/code&gt; argument for other models, for example, &lt;code&gt;./realesrgan-ncnn-vulkan.exe -i input.jpg -o output.png -n realesrnet-x4plus&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Usage of portable executable files&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Please refer to &lt;a href="https://github.com/xinntao/Real-ESRGAN-ncnn-vulkan#computer-usages"&gt;Real-ESRGAN-ncnn-vulkan&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;Note that it does not support all the functions (such as &lt;code&gt;outscale&lt;/code&gt;) as the python script &lt;code&gt;inference_realesrgan.py&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;Usage: realesrgan-ncnn-vulkan.exe -i infile -o outfile [options]...

  -h                   show this help
  -i input-path        input image path (jpg/png/webp) or directory
  -o output-path       output image path (jpg/png/webp) or directory
  -s scale             upscale ratio (can be 2, 3, 4. default=4)
  -t tile-size         tile size (&amp;gt;=32/0=auto, default=0) can be 0,0,0 for multi-gpu
  -m model-path        folder path to the pre-trained models. default=models
  -n model-name        model name (default=realesr-animevideov3, can be realesr-animevideov3 | realesrgan-x4plus | realesrgan-x4plus-anime | realesrnet-x4plus)
  -g gpu-id            gpu device to use (default=auto) can be 0,1,2 for multi-gpu
  -j load:proc:save    thread count for load/proc/save (default=1:2:2) can be 1:2,2,2:2 for multi-gpu
  -x                   enable tta mode"
  -f format            output image format (jpg/png/webp, default=ext/png)
  -v                   verbose output
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that it may introduce block inconsistency (and also generate slightly different results from the PyTorch implementation), because this executable file first crops the input image into several tiles, and then processes them separately, finally stitches together.&lt;/p&gt; 
&lt;h3&gt;Python script&lt;/h3&gt; 
&lt;h4&gt;Usage of python script&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;You can use X4 model for &lt;strong&gt;arbitrary output size&lt;/strong&gt; with the argument &lt;code&gt;outscale&lt;/code&gt;. The program will further perform cheap resize operation after the Real-ESRGAN output.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;Usage: python inference_realesrgan.py -n RealESRGAN_x4plus -i infile -o outfile [options]...

A common command: python inference_realesrgan.py -n RealESRGAN_x4plus -i infile --outscale 3.5 --face_enhance

  -h                   show this help
  -i --input           Input image or folder. Default: inputs
  -o --output          Output folder. Default: results
  -n --model_name      Model name. Default: RealESRGAN_x4plus
  -s, --outscale       The final upsampling scale of the image. Default: 4
  --suffix             Suffix of the restored image. Default: out
  -t, --tile           Tile size, 0 for no tile during testing. Default: 0
  --face_enhance       Whether to use GFPGAN to enhance face. Default: False
  --fp32               Use fp32 precision during inference. Default: fp16 (half precision).
  --ext                Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Inference general images&lt;/h4&gt; 
&lt;p&gt;Download pre-trained models: &lt;a href="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth"&gt;RealESRGAN_x4plus.pth&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P weights
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Inference!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python inference_realesrgan.py -n RealESRGAN_x4plus -i inputs --face_enhance
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Results are in the &lt;code&gt;results&lt;/code&gt; folder&lt;/p&gt; 
&lt;h4&gt;Inference anime images&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/xinntao/public-figures/master/Real-ESRGAN/cmp_realesrgan_anime_1.png"&gt; &lt;/p&gt; 
&lt;p&gt;Pre-trained models: &lt;a href="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth"&gt;RealESRGAN_x4plus_anime_6B&lt;/a&gt;&lt;br&gt; More details and comparisons with &lt;a href="https://github.com/nihui/waifu2x-ncnn-vulkan"&gt;waifu2x&lt;/a&gt; are in &lt;a href="https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/docs/anime_model.md"&gt;&lt;strong&gt;anime_model.md&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# download model
wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth -P weights
# inference
python inference_realesrgan.py -n RealESRGAN_x4plus_anime_6B -i inputs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Results are in the &lt;code&gt;results&lt;/code&gt; folder&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;BibTeX&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@InProceedings{wang2021realesrgan,
    author    = {Xintao Wang and Liangbin Xie and Chao Dong and Ying Shan},
    title     = {Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data},
    booktitle = {International Conference on Computer Vision Workshops (ICCVW)},
    date      = {2021}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìß Contact&lt;/h2&gt; 
&lt;p&gt;If you have any question, please email &lt;code&gt;xintao.wang@outlook.com&lt;/code&gt; or &lt;code&gt;xintaowang@tencent.com&lt;/code&gt;.&lt;/p&gt; 
&lt;!-- Projects that use Real-ESRGAN ---------------------------&gt; 
&lt;h2&gt;üß© Projects that use Real-ESRGAN&lt;/h2&gt; 
&lt;p&gt;If you develop/use Real-ESRGAN in your projects, welcome to let me know.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;NCNN-Android: &lt;a href="https://github.com/tumuyan/RealSR-NCNN-Android"&gt;RealSR-NCNN-Android&lt;/a&gt; by &lt;a href="https://github.com/tumuyan"&gt;tumuyan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VapourSynth: &lt;a href="https://github.com/HolyWu/vs-realesrgan"&gt;vs-realesrgan&lt;/a&gt; by &lt;a href="https://github.com/HolyWu"&gt;HolyWu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;NCNN: &lt;a href="https://github.com/xinntao/Real-ESRGAN-ncnn-vulkan"&gt;Real-ESRGAN-ncnn-vulkan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;GUI&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AaronFeng753/Waifu2x-Extension-GUI"&gt;Waifu2x-Extension-GUI&lt;/a&gt; by &lt;a href="https://github.com/AaronFeng753"&gt;AaronFeng753&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Justin62628/Squirrel-RIFE"&gt;Squirrel-RIFE&lt;/a&gt; by &lt;a href="https://github.com/Justin62628"&gt;Justin62628&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/scifx/Real-GUI"&gt;Real-GUI&lt;/a&gt; by &lt;a href="https://github.com/scifx"&gt;scifx&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/net2cn/Real-ESRGAN_GUI"&gt;Real-ESRGAN_GUI&lt;/a&gt; by &lt;a href="https://github.com/net2cn"&gt;net2cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/WGzeyu/Real-ESRGAN-EGUI"&gt;Real-ESRGAN-EGUI&lt;/a&gt; by &lt;a href="https://github.com/WGzeyu"&gt;WGzeyu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shangar21/anime_upscaler"&gt;anime_upscaler&lt;/a&gt; by &lt;a href="https://github.com/shangar21"&gt;shangar21&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/upscayl/upscayl"&gt;Upscayl&lt;/a&gt; by &lt;a href="https://github.com/NayamAmarshe"&gt;Nayam Amarshe&lt;/a&gt; and &lt;a href="https://github.com/TGS963"&gt;TGS963&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ó Acknowledgement&lt;/h2&gt; 
&lt;p&gt;Thanks for all the contributors.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AK391"&gt;AK391&lt;/a&gt;: Integrate RealESRGAN to &lt;a href="https://huggingface.co/spaces"&gt;Huggingface Spaces&lt;/a&gt; with &lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio&lt;/a&gt;. See &lt;a href="https://huggingface.co/spaces/akhaliq/Real-ESRGAN"&gt;Gradio Web Demo&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Asiimoviet"&gt;Asiimoviet&lt;/a&gt;: Translate the README.md to Chinese (‰∏≠Êñá).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/2ji3150"&gt;2ji3150&lt;/a&gt;: Thanks for the &lt;a href="https://github.com/xinntao/Real-ESRGAN/issues/131"&gt;detailed and valuable feedbacks/suggestions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jared-02"&gt;Jared-02&lt;/a&gt;: Translate the Training.md to Chinese (‰∏≠Êñá).&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>jingyaogong/minimind</title>
      <link>https://github.com/jingyaogong/minimind</link>
      <description>&lt;p&gt;üöÄüöÄ „ÄåÂ§ßÊ®°Âûã„Äç2Â∞èÊó∂ÂÆåÂÖ®‰ªé0ËÆ≠ÁªÉ26MÁöÑÂ∞èÂèÇÊï∞GPTÔºÅüåè Train a 26M-parameter GPT from scratch in just 2h!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/logo.png" alt="logo"&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://visitor-badge.laobi.icu/badge?page_id=jingyaogong/minimind" alt="visitors"&gt; &lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/jingyaogong/minimind?style=social" alt="GitHub Repo stars"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/jingyaogong/minimind" alt="GitHub Code License"&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/commits/master"&gt;&lt;img src="https://img.shields.io/github/last-commit/jingyaogong/minimind" alt="GitHub last commit"&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-blue" alt="GitHub pull request"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97-MiniMind%20%20Collection-blue" alt="Collection"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;"Â§ßÈÅìËá≥ÁÆÄ"&lt;/h3&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‰∏≠Êñá | &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/README_en.md"&gt;English&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ê≠§ÂºÄÊ∫êÈ°πÁõÆÊó®Âú®ÂÆåÂÖ®‰ªé0ÂºÄÂßãÔºå‰ªÖÁî®3ÂùóÈí±ÊàêÊú¨ + 2Â∞èÊó∂ÔºÅÂç≥ÂèØËÆ≠ÁªÉÂá∫‰ªÖ‰∏∫25.8MÁöÑË∂ÖÂ∞èËØ≠Ë®ÄÊ®°Âûã&lt;strong&gt;MiniMind&lt;/strong&gt;„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;Á≥ªÂàóÊûÅÂÖ∂ËΩªÈáèÔºåÊúÄÂ∞èÁâàÊú¨‰ΩìÁßØÊòØ GPT-3 ÁöÑ $\frac{1}{7000}$ÔºåÂäõÊ±ÇÂÅöÂà∞ÊúÄÊôÆÈÄöÁöÑ‰∏™‰∫∫GPU‰πüÂèØÂø´ÈÄüËÆ≠ÁªÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;È°πÁõÆÂêåÊó∂ÂºÄÊ∫ê‰∫ÜÂ§ßÊ®°ÂûãÁöÑÊûÅÁÆÄÁªìÊûÑ-ÂåÖÂê´ÊãìÂ±ïÂÖ±‰∫´Ê∑∑Âêà‰∏ìÂÆ∂(MoE)„ÄÅÊï∞ÊçÆÈõÜÊ∏ÖÊ¥ó„ÄÅÈ¢ÑËÆ≠ÁªÉ(Pretrain)„ÄÅÁõëÁù£ÂæÆË∞É(SFT)„ÄÅLoRAÂæÆË∞ÉÔºå Áõ¥Êé•ÂÅèÂ•ΩÂº∫ÂåñÂ≠¶‰π†(DPO)ÁÆóÊ≥ï„ÄÅÊ®°ÂûãËí∏È¶èÁÆóÊ≥ïÁ≠âÂÖ®ËøáÁ®ã‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;ÂêåÊó∂ÊãìÂ±ï‰∫ÜËßÜËßâÂ§öÊ®°ÊÄÅÁöÑVLM: &lt;a href="https://github.com/jingyaogong/minimind-v"&gt;MiniMind-V&lt;/a&gt;„ÄÇ&lt;/li&gt; 
 &lt;li&gt;È°πÁõÆÊâÄÊúâÊ†∏ÂøÉÁÆóÊ≥ï‰ª£Á†ÅÂùá‰ªé0‰ΩøÁî®PyTorchÂéüÁîüÈáçÊûÑÔºÅ‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∫ìÊèê‰æõÁöÑÊäΩË±°Êé•Âè£„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Ëøô‰∏ç‰ªÖÊòØÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ®Èò∂ÊÆµÂºÄÊ∫êÂ§çÁé∞Ôºå‰πüÊòØ‰∏Ä‰∏™ÂÖ•Èó®LLMÁöÑÊïôÁ®ã„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Â∏åÊúõÊ≠§È°πÁõÆËÉΩ‰∏∫ÊâÄÊúâ‰∫∫Êèê‰æõ‰∏Ä‰∏™ÊäõÁ†ñÂºïÁéâÁöÑÁ§∫‰æãÔºå‰∏ÄËµ∑ÊÑüÂèóÂàõÈÄ†ÁöÑ‰πêË∂£ÔºÅÊé®Âä®Êõ¥ÂπøÊ≥õAIÁ§æÂå∫ÁöÑËøõÊ≠•ÔºÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏∫Èò≤Ê≠¢ËØØËß£Ôºå‚Äú2Â∞èÊó∂‚Äù Âü∫‰∫éNVIDIA 3090Á°¨‰ª∂ËÆæÂ§áÔºàÂçïÂç°ÔºâÊµãËØïÔºå‚Äú3ÂùóÈí±‚Äù ÊåáGPUÊúçÂä°Âô®ÁßüÁî®ÊàêÊú¨ÔºåÂÖ∑‰ΩìËßÑÊ†ºËØ¶ÊÉÖËßÅ‰∏ãÊñá„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/minimind2.gif" alt="minimind2"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind-Reasoning"&gt;üîóüçìÊé®ÁêÜÊ®°Âûã&lt;/a&gt; | &lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind"&gt;üîóü§ñÂ∏∏ËßÑÊ®°Âûã&lt;/a&gt; | &lt;a href="https://www.bilibili.com/video/BV12dHPeqE72/?share_source=copy_web&amp;amp;vd_source=670c2504f88726f8cf4a21ef6147c0e8"&gt;üîóüéûÔ∏èËßÜÈ¢ë‰ªãÁªç&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;tbody&gt;
    &lt;tr&gt; 
     &lt;td align="center"&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_huggingface.png" alt="Hugging Face Logo" style="vertical-align: middle; width: auto; max-width: 100%;"&gt; &lt;/a&gt; &lt;/td&gt; 
     &lt;td align="center"&gt; &lt;a href="https://www.modelscope.cn/profile/gongjy" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_modelscope.png" alt="ModelScope Logo" style="vertical-align: middle; width: auto; max-width: 100%;"&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt;
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h1&gt;üìå Introduction&lt;/h1&gt; 
&lt;p&gt;Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLarge Language Model, LLMÔºâÁöÑÂá∫Áé∞ÂºïÂèë‰∫ÜÂÖ®‰∏ñÁïåÂØπAIÁöÑÁ©∫ÂâçÂÖ≥Ê≥®„ÄÇ Êó†ËÆ∫ÊòØChatGPT„ÄÅDeepSeekËøòÊòØQwenÔºåÈÉΩ‰ª•ÂÖ∂ÊÉäËâ≥ÁöÑÊïàÊûú‰ª§‰∫∫Âèπ‰∏∫ËßÇÊ≠¢„ÄÇ ÁÑ∂ËÄåÔºåÂä®ËæÑÊï∞Áôæ‰∫øÂèÇÊï∞ÁöÑÂ∫ûÂ§ßËßÑÊ®°Ôºå‰ΩøÂæóÂÆÉ‰ª¨ÂØπ‰∏™‰∫∫ËÆæÂ§áËÄåË®Ä‰∏ç‰ªÖÈöæ‰ª•ËÆ≠ÁªÉÔºåÁîöËá≥ËøûÈÉ®ÁΩ≤ÈÉΩÊòæÂæóÈÅ•‰∏çÂèØÂèä„ÄÇ ÊâìÂºÄÂ§ßÊ®°ÂûãÁöÑ‚ÄúÈªëÁõíÂ≠ê‚ÄùÔºåÊé¢Á¥¢ÂÖ∂ÂÜÖÈÉ®Ëøê‰ΩúÊú∫Âà∂ÔºåÂ§ö‰πà‰ª§‰∫∫ÂøÉÊΩÆÊæéÊπÉÔºÅ ÈÅóÊÜæÁöÑÊòØÔºå99%ÁöÑÊé¢Á¥¢Âè™ËÉΩÊ≠¢Ê≠•‰∫é‰ΩøÁî®LoRAÁ≠âÊäÄÊúØÂØπÁé∞ÊúâÂ§ßÊ®°ÂûãËøõË°åÂ∞ëÈáèÂæÆË∞ÉÔºåÂ≠¶‰π†‰∏Ä‰∫õÊñ∞Êåá‰ª§Êàñ‰ªªÂä°„ÄÇ ËøôÂ∞±Â•ΩÊØîÊïôÁâõÈ°øÂ¶Ç‰Ωï‰ΩøÁî®21‰∏ñÁ∫™ÁöÑÊô∫ËÉΩÊâãÊú∫‚Äî‚ÄîËôΩÁÑ∂ÊúâË∂£ÔºåÂç¥ÂÆåÂÖ®ÂÅèÁ¶ª‰∫ÜÁêÜËß£Áâ©ÁêÜÊú¨Ë¥®ÁöÑÂàùË°∑„ÄÇ ‰∏éÊ≠§ÂêåÊó∂ÔºåÁ¨¨‰∏âÊñπÁöÑÂ§ßÊ®°ÂûãÊ°ÜÊû∂ÂíåÂ∑•ÂÖ∑Â∫ìÔºåÂ¶Çtransformers+trlÔºåÂá†‰πéÂè™Êö¥Èú≤‰∫ÜÈ´òÂ∫¶ÊäΩË±°ÁöÑÊé•Âè£„ÄÇ ÈÄöËøáÁü≠Áü≠10Ë°å‰ª£Á†ÅÔºåÂ∞±ËÉΩÂÆåÊàê‚ÄúÂä†ËΩΩÊ®°Âûã+Âä†ËΩΩÊï∞ÊçÆÈõÜ+Êé®ÁêÜ+Âº∫ÂåñÂ≠¶‰π†‚ÄùÁöÑÂÖ®ÊµÅÁ®ãËÆ≠ÁªÉ„ÄÇ ËøôÁßçÈ´òÊïàÁöÑÂ∞ÅË£ÖÂõ∫ÁÑ∂‰æøÂà©Ôºå‰ΩÜ‰πüÂÉè‰∏ÄÊû∂È´òÈÄüÈ£ûËàπÔºåÂ∞ÜÊàë‰ª¨‰∏éÂ∫ïÂ±ÇÂÆûÁé∞ÈöîÁ¶ªÂºÄÊù•ÔºåÈòªÁ¢ç‰∫ÜÊ∑±ÂÖ•Êé¢Á©∂LLMÊ†∏ÂøÉ‰ª£Á†ÅÁöÑÊú∫‰ºö„ÄÇ ÁÑ∂ËÄåÔºå‚ÄúÁî®‰πêÈ´òÊãºÂá∫‰∏ÄÊû∂È£ûÊú∫ÔºåËøúÊØîÂùêÂú®Â§¥Á≠âËà±ÈáåÈ£ûË°åÊõ¥ËÆ©‰∫∫ÂÖ¥Â•ãÔºÅ‚Äù„ÄÇ Êõ¥Á≥üÁ≥ïÁöÑÊòØÔºå‰∫íËÅîÁΩë‰∏äÂÖÖÊñ•ÁùÄÂ§ßÈáè‰ªòË¥πËØæÁ®ãÂíåËê•ÈîÄÂè∑Ôºå‰ª•ÊºèÊ¥ûÁôæÂá∫„ÄÅ‰∏ÄÁü•ÂçäËß£ÁöÑÂÜÖÂÆπÊé®ÈîÄAIÊïôÁ®ã„ÄÇ Ê≠£Âõ†Â¶ÇÊ≠§ÔºåÊú¨È°πÁõÆÂàùË°∑ÊòØÊãâ‰ΩéLLMÁöÑÂ≠¶‰π†Èó®ÊßõÔºåËÆ©ÊØè‰∏™‰∫∫ÈÉΩËÉΩ‰ªéÁêÜËß£ÊØè‰∏ÄË°å‰ª£Á†ÅÂºÄÂßãÔºå ‰ªéÈõ∂ÂºÄÂßã‰∫≤ÊâãËÆ≠ÁªÉ‰∏Ä‰∏™ÊûÅÂ∞èÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇÊòØÁöÑÔºå‰ªé&lt;strong&gt;Èõ∂ÂºÄÂßãËÆ≠ÁªÉ&lt;/strong&gt;ÔºåËÄå‰∏çÊòØ‰ªÖ‰ªÖËøõË°å&lt;strong&gt;Êé®ÁêÜ&lt;/strong&gt;ÔºÅ ÊúÄ‰ΩéÂè™ÈúÄ3ÂùóÈí±‰∏çÂà∞ÁöÑÊúçÂä°Âô®ÊàêÊú¨ÔºåÂ∞±ËÉΩ‰∫≤Ë∫´‰ΩìÈ™å‰ªé0Âà∞1ÊûÑÂª∫‰∏Ä‰∏™ËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ®ËøáÁ®ã„ÄÇ ‰∏ÄËµ∑ÊÑüÂèóÂàõÈÄ†ÁöÑ‰πêË∂£ÂêßÔºÅ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] ÔºàÊà™Ëá≥2025-02-07ÔºâMiniMindÁ≥ªÂàóÂ∑≤ÂÆåÊàêÂ§ö‰∏™ÂûãÂè∑Ê®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉÔºåÊúÄÂ∞è‰ªÖÈúÄ25.8MÔºà0.02BÔºâÔºåÂç≥ÂèØÂÖ∑Â§áÊµÅÁïÖÂØπËØùËÉΩÂäõÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Models List&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Ê®°Âûã (Â§ßÂ∞è)&lt;/th&gt; 
    &lt;th&gt;Êé®ÁêÜÂç†Áî® (Á∫¶)&lt;/th&gt; 
    &lt;th&gt;Release&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE (145M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2 (104M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2024.08.28&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe (4√ó26M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.17&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1 (108M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.01&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;È°πÁõÆÂåÖÂê´&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MiniMind-LLMÁªìÊûÑÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºàDense+MoEÊ®°ÂûãÔºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂåÖÂê´TokenizerÂàÜËØçÂô®ËØ¶ÁªÜËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂåÖÂê´Pretrain„ÄÅSFT„ÄÅLoRA„ÄÅRLHF-DPO„ÄÅÊ®°ÂûãËí∏È¶èÁöÑÂÖ®ËøáÁ®ãËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Êî∂ÈõÜ„ÄÅËí∏È¶è„ÄÅÊï¥ÁêÜÂπ∂Ê∏ÖÊ¥óÂéªÈáçÊâÄÊúâÈò∂ÊÆµÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜÔºå‰∏îÂÖ®ÈÉ®ÂºÄÊ∫ê„ÄÇ&lt;/li&gt; 
 &lt;li&gt;‰ªé0ÂÆûÁé∞È¢ÑËÆ≠ÁªÉ„ÄÅÊåá‰ª§ÂæÆË∞É„ÄÅLoRA„ÄÅDPOÂº∫ÂåñÂ≠¶‰π†ÔºåÁôΩÁõíÊ®°ÂûãËí∏È¶è„ÄÇÂÖ≥ÈîÆÁÆóÊ≥ïÂá†‰πé‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∞ÅË£ÖÁöÑÊ°ÜÊû∂Ôºå‰∏îÂÖ®ÈÉ®ÂºÄÊ∫ê„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂêåÊó∂ÂÖºÂÆπ&lt;code&gt;transformers&lt;/code&gt;„ÄÅ&lt;code&gt;trl&lt;/code&gt;„ÄÅ&lt;code&gt;peft&lt;/code&gt;Á≠âÁ¨¨‰∏âÊñπ‰∏ªÊµÅÊ°ÜÊû∂„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ËÆ≠ÁªÉÊîØÊåÅÂçïÊú∫ÂçïÂç°„ÄÅÂçïÊú∫Â§öÂç°(DDP„ÄÅDeepSpeed)ËÆ≠ÁªÉÔºåÊîØÊåÅwandbÂèØËßÜÂåñËÆ≠ÁªÉÊµÅÁ®ã„ÄÇÊîØÊåÅÂä®ÊÄÅÂêØÂÅúËÆ≠ÁªÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Âú®Á¨¨‰∏âÊñπÊµãËØÑÊ¶úÔºàC-Eval„ÄÅC-MMLU„ÄÅOpenBookQAÁ≠âÔºâËøõË°åÊ®°ÂûãÊµãËØï„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÆûÁé∞Openai-ApiÂçèËÆÆÁöÑÊûÅÁÆÄÊúçÂä°Á´ØÔºå‰æø‰∫éÈõÜÊàêÂà∞Á¨¨‰∏âÊñπChatUI‰ΩøÁî®ÔºàFastGPT„ÄÅOpen-WebUIÁ≠âÔºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Âü∫‰∫éstreamlitÂÆûÁé∞ÊúÄÁÆÄËÅäÂ§©WebUIÂâçÁ´Ø„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÖ®Èù¢ÂÖºÂÆπÁ§æÂå∫ÁÉ≠Èó®&lt;code&gt;llama.cpp&lt;/code&gt;„ÄÅ&lt;code&gt;vllm&lt;/code&gt;„ÄÅ&lt;code&gt;ollama&lt;/code&gt;Êé®ÁêÜÂºïÊìéÊàñ&lt;code&gt;Llama-Factory&lt;/code&gt;ËÆ≠ÁªÉÊ°ÜÊû∂„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Â§çÁé∞(Ëí∏È¶è/RL)Â§ßÂûãÊé®ÁêÜÊ®°ÂûãDeepSeek-R1ÁöÑMiniMind-ReasonÊ®°ÂûãÔºå&lt;strong&gt;Êï∞ÊçÆ+Ê®°Âûã&lt;/strong&gt;ÂÖ®ÈÉ®ÂºÄÊ∫êÔºÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Â∏åÊúõÊ≠§ÂºÄÊ∫êÈ°πÁõÆÂèØ‰ª•Â∏ÆÂä©LLMÂàùÂ≠¶ËÄÖÂø´ÈÄüÂÖ•Èó®ÔºÅ&lt;/p&gt; 
&lt;h3&gt;üëâ&lt;strong&gt;Êõ¥Êñ∞Êó•Âøó&lt;/strong&gt;&lt;/h3&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-04-26 (newest üéâüéâüéâ)&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈáçË¶ÅÊõ¥Êñ∞&lt;/li&gt; 
  &lt;li&gt;Â¶ÇÊúâÂÖºÂÆπÊÄßÈúÄË¶ÅÔºåÂèØËÆøÈóÆ&lt;a href="https://github.com/jingyaogong/minimind/tree/7da201a944a90ed49daef8a0265c959288dff83a"&gt;üîóÊóß‰ªìÂ∫ìÂÜÖÂÆπüîó&lt;/a&gt;„ÄÇ&lt;/li&gt; 
  &lt;li&gt;MiniMindÊ®°ÂûãÂèÇÊï∞ÂÆåÂÖ®ÊîπÂêçÔºåÂØπÈΩêTransformersÂ∫ìÊ®°ÂûãÔºàÁªü‰∏ÄÂëΩÂêçÔºâ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;generateÊñπÂºèÈáçÊûÑÔºåÁªßÊâøËá™GenerationMixinÁ±ª„ÄÇ&lt;/li&gt; 
  &lt;li&gt;üî•ÊîØÊåÅllama.cpp„ÄÅvllm„ÄÅollamaÁ≠âÁÉ≠Èó®‰∏âÊñπÁîüÊÄÅ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ËßÑËåÉ‰ª£Á†ÅÂíåÁõÆÂΩïÁªìÊûÑ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ÊîπÂä®ËØçË°®&lt;code&gt;&amp;lt;s&amp;gt;&amp;lt;/s&amp;gt;&lt;/code&gt;-&amp;gt;&lt;code&gt;&amp;lt;|im_start|&amp;gt;&amp;lt;|im_end|&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;‰∏∫ÂÖºÂÆπÁ¨¨‰∏âÊñπÊé®ÁêÜÊ°ÜÊû∂llama.cpp„ÄÅvllmÔºåÊú¨Ê¨°Êõ¥Êñ∞ÈúÄ‰ªòÂá∫‰∏Ä‰∫õÂèØËßÇ‰ª£‰ª∑„ÄÇ
Êú¨Ê¨°Êõ¥Êñ∞‰∏çÂÜçÊîØÊåÅ„ÄåÁõ¥Êé•„ÄçÂä†ËΩΩ25-04-26‰ª•ÂâçÁöÑÊóßÊ®°ÂûãËøõË°åÊé®ÁêÜ„ÄÇ
Áî±‰∫éLlama‰ΩçÁΩÆÁºñÁ†ÅÊñπÂºè‰∏éminimindÂ≠òÂú®Âå∫Âà´ÔºåÂØºËá¥Êò†Â∞ÑLlamaÊ®°ÂûãÂêéQKÂÄºÂ≠òÂú®Â∑ÆÂºÇ
MiniMind2Á≥ªÂàóÊóßÊ®°ÂûãÂùáÁªèËøáÊùÉÈáçÊò†Â∞Ñ+ÔºàÂæÆË∞ÉËÆ≠ÁªÉÔºâQKVOÁ∫øÊÄßÂ±ÇÊ†°ÂáÜÊÅ¢Â§çËÄåÊù•„ÄÇ
Êú¨Ê¨°Êõ¥Êñ∞ÂêéÂ∞ÜÊîæÂºÉÂØπ`minimind-v1`ÂÖ®Á≥ªÂàóÁöÑÁª¥Êä§ÔºåÂπ∂Âú®‰ªìÂ∫ì‰∏≠‰∏ãÁ∫ø„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-02-09&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ËøéÊù•ÂèëÂ∏É‰ª•Êù•ÈáçÂ§ßÊõ¥Êñ∞ÔºåRelease MiniMind2 Series„ÄÇ&lt;/li&gt; 
  &lt;li&gt;‰ª£Á†ÅÂá†‰πéÂÖ®ÈÉ®ÈáçÊûÑÔºå‰ΩøÁî®Êõ¥ÁÆÄÊ¥ÅÊòé‰∫ÜÁöÑÁªü‰∏ÄÁªìÊûÑ„ÄÇ Â¶ÇÊúâÊóß‰ª£Á†ÅÁöÑÂÖºÂÆπÊÄßÈúÄË¶ÅÔºåÂèØËÆøÈóÆ&lt;a href="https://github.com/jingyaogong/minimind/tree/6e9cd28ef9b34a0a10afbdf6f59e65cb6e628efb"&gt;üîóÊóß‰ªìÂ∫ìÂÜÖÂÆπüîó&lt;/a&gt;„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ÂÖçÂéªÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÊ≠•È™§„ÄÇÁªü‰∏ÄÊï∞ÊçÆÈõÜÊ†ºÂºèÔºåÊõ¥Êç¢‰∏∫&lt;code&gt;jsonl&lt;/code&gt;Ê†ºÂºèÊùúÁªùÊï∞ÊçÆÈõÜ‰∏ãËΩΩÊ∑∑‰π±ÁöÑÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
  &lt;li&gt;MiniMind2Á≥ªÂàóÊïàÊûúÁõ∏ÊØîMiniMind-V1ÊòæËëóÊèêÂçá„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Â∞èÈóÆÈ¢òÔºö{kv-cacheÂÜôÊ≥ïÊõ¥Ê†áÂáÜ„ÄÅMoEÁöÑË¥üËΩΩÂùáË°°lossË¢´ËÄÉËôëÁ≠âÁ≠â}&lt;/li&gt; 
  &lt;li&gt;Êèê‰æõÊ®°ÂûãËøÅÁßªÂà∞ÁßÅÊúâÊï∞ÊçÆÈõÜÁöÑËÆ≠ÁªÉÊñπÊ°àÔºàÂåªÁñóÊ®°Âûã„ÄÅËá™ÊàëËÆ§Áü•Ê†∑‰æãÔºâ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Á≤æÁÆÄÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÂπ∂Â§ßÂπÖÊèêÂçáÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆË¥®ÈáèÔºåÂ§ßÂπÖÁº©Áü≠‰∏™‰∫∫Âø´ÈÄüËÆ≠ÁªÉÊâÄÈúÄÊó∂Èó¥ÔºåÂçïÂç°3090Âç≥ÂèØ2Â∞èÊó∂Â§çÁé∞ÔºÅ&lt;/li&gt; 
  &lt;li&gt;Êõ¥Êñ∞ÔºöLoRAÂæÆË∞ÉËÑ±Á¶ªpeftÂåÖË£ÖÔºå‰ªé0ÂÆûÁé∞LoRAËøáÁ®ãÔºõDPOÁÆóÊ≥ï‰ªé0‰ΩøÁî®PyTorchÂéüÁîüÂÆûÁé∞ÔºõÊ®°ÂûãÁôΩÁõíËí∏È¶èÂéüÁîüÂÆûÁé∞„ÄÇ&lt;/li&gt; 
  &lt;li&gt;MiniMind2-DeepSeek-R1Á≥ªÂàóËí∏È¶èÊ®°ÂûãËØûÁîüÔºÅ&lt;/li&gt; 
  &lt;li&gt;MiniMind2ÂÖ∑Â§á‰∏ÄÂÆöÁöÑËã±ÊñáËÉΩÂäõÔºÅ&lt;/li&gt; 
  &lt;li&gt;Êõ¥Êñ∞MiniMind2‰∏éÁ¨¨‰∏âÊñπÊ®°ÂûãÁöÑÂü∫‰∫éÊõ¥Â§öÂ§ßÊ®°ÂûãÊ¶úÂçïÊµãËØïÊÄßËÉΩÁöÑÁªìÊûú„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-10-05&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰∏∫MiniMindÊãìÂ±ï‰∫ÜÂ§öÊ®°ÊÄÅËÉΩÂäõ‰πã---ËßÜËßâ&lt;/li&gt; 
  &lt;li&gt;ÁßªÊ≠•Â≠™ÁîüÈ°πÁõÆ&lt;a href="https://github.com/jingyaogong/minimind-v"&gt;minimind-v&lt;/a&gt;Êü•ÁúãËØ¶ÊÉÖÔºÅ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-27&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;09-27Êõ¥Êñ∞pretrainÊï∞ÊçÆÈõÜÁöÑÈ¢ÑÂ§ÑÁêÜÊñπÂºèÔºå‰∏∫‰∫Ü‰øùËØÅÊñáÊú¨ÂÆåÊï¥ÊÄßÔºåÊîæÂºÉÈ¢ÑÂ§ÑÁêÜÊàê.binËÆ≠ÁªÉÁöÑÂΩ¢ÂºèÔºàËΩªÂæÆÁâ∫Áâ≤ËÆ≠ÁªÉÈÄüÂ∫¶Ôºâ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ÁõÆÂâçpretrainÈ¢ÑÂ§ÑÁêÜÂêéÁöÑÊñá‰ª∂ÂëΩÂêç‰∏∫Ôºöpretrain_data.csv„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Âà†Èô§‰∫Ü‰∏Ä‰∫õÂÜó‰ΩôÁöÑ‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-17&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êõ¥Êñ∞minimind-v1-moeÊ®°Âûã&lt;/li&gt; 
  &lt;li&gt;‰∏∫‰∫ÜÈò≤Ê≠¢Ê≠ß‰πâÔºå‰∏çÂÜç‰ΩøÁî®mistral_tokenizerÂàÜËØçÔºåÂÖ®ÈÉ®ÈááÁî®Ëá™ÂÆö‰πâÁöÑminimind_tokenizer‰Ωú‰∏∫ÂàÜËØçÂô®„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-01&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êõ¥Êñ∞minimind-v1 (108M)Ê®°ÂûãÔºåÈááÁî®minimind_tokenizerÔºåÈ¢ÑËÆ≠ÁªÉËΩÆÊ¨°3 + SFTËΩÆÊ¨°10ÔºåÊõ¥ÂÖÖÂàÜËÆ≠ÁªÉÔºåÊÄßËÉΩÊõ¥Âº∫„ÄÇ&lt;/li&gt; 
  &lt;li&gt;È°πÁõÆÂ∑≤ÈÉ®ÁΩ≤Ëá≥ModelScopeÂàõÁ©∫Èó¥ÔºåÂèØ‰ª•Âú®Ê≠§ÁΩëÁ´ô‰∏ä‰ΩìÈ™åÔºö&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/minimind"&gt;üîóModelScopeÂú®Á∫ø‰ΩìÈ™åüîó&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-08-27&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;È°πÁõÆÈ¶ñÊ¨°ÂºÄÊ∫ê&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;üìå Âø´ÈÄüÂºÄÂßã&lt;/h1&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÂàÜ‰∫´Êú¨‰∫∫ÁöÑËΩØÁ°¨‰ª∂ÈÖçÁΩÆÔºà‰ªÖ‰æõÂèÇËÄÉÔºâ&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz&lt;/li&gt; 
  &lt;li&gt;RAM: 128 GB&lt;/li&gt; 
  &lt;li&gt;GPU: NVIDIA GeForce RTX 3090(24GB) * 8&lt;/li&gt; 
  &lt;li&gt;Ubuntu==20.04&lt;/li&gt; 
  &lt;li&gt;CUDA==12.2&lt;/li&gt; 
  &lt;li&gt;Python==3.10.16&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/requirements.txt"&gt;requirements.txt&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Á¨¨0Ê≠•&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/jingyaogong/minimind.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö† ÊµãËØïÂ∑≤ÊúâÊ®°ÂûãÊïàÊûú&lt;/h2&gt; 
&lt;h3&gt;1.ÁéØÂ¢ÉÂáÜÂ§á&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.‰∏ãËΩΩÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;Âà∞È°πÁõÆÊ†πÁõÆÂΩï&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://huggingface.co/jingyaogong/MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÔºàÂèØÈÄâÔºâÂëΩ‰ª§Ë°åÈóÆÁ≠î&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# load=0: load from pytorch model, load=1: load from transformers-hf model
python eval_model.py --load 1 --model_mode 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÔºàÂèØÈÄâÔºâÂêØÂä®WebUI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂèØËÉΩÈúÄË¶Å`python&amp;gt;=3.10` ÂÆâË£Ö `pip install streamlit`
# cd scripts
streamlit run web_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÔºàÂèØÈÄâÔºâÁ¨¨‰∏âÊñπÊé®ÁêÜÊ°ÜÊû∂&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ollama
ollama run jingyaogong/minimind2
# vllm
vllm serve ./MiniMind2/ --served-model-name "minimind"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö° ‰ªé0ÂºÄÂßãËá™Â∑±ËÆ≠ÁªÉ&lt;/h2&gt; 
&lt;h3&gt;1.ÁéØÂ¢ÉÂáÜÂ§á&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÊèêÂâçÊµãËØïTorchÊòØÂê¶ÂèØÁî®cuda&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;import torch
print(torch.cuda.is_available())
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Â¶ÇÊûú‰∏çÂèØÁî®ÔºåËØ∑Ëá™Ë°åÂéª&lt;a href="https://download.pytorch.org/whl/torch_stable.html"&gt;torch_stable&lt;/a&gt; ‰∏ãËΩΩwhlÊñá‰ª∂ÂÆâË£Ö„ÄÇÂèÇËÄÉ&lt;a href="https://blog.csdn.net/weixin_45456738/article/details/141029610?ops_request_misc=&amp;amp;request_id=&amp;amp;biz_id=102&amp;amp;utm_term=%E5%AE%89%E8%A3%85torch&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-141029610.nonecase&amp;amp;spm=1018.2226.3001.4187"&gt;ÈìæÊé•&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;2.Êï∞ÊçÆ‰∏ãËΩΩ&lt;/h3&gt; 
&lt;p&gt;‰ªé‰∏ãÊñáÊèê‰æõÁöÑ&lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;Êï∞ÊçÆÈõÜ‰∏ãËΩΩÈìæÊé•&lt;/a&gt; ‰∏ãËΩΩÈúÄË¶ÅÁöÑÊï∞ÊçÆÊñá‰ª∂ÔºàÂàõÂª∫&lt;code&gt;./dataset&lt;/code&gt;ÁõÆÂΩïÔºâÂπ∂ÊîæÂà∞&lt;code&gt;./dataset&lt;/code&gt;‰∏ã&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÊï∞ÊçÆÈõÜÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;ÈªòËÆ§Êé®Ëçê‰∏ãËΩΩ&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;ÊúÄÂø´ÈÄüÂ∫¶Â§çÁé∞ZeroËÅäÂ§©Ê®°Âûã„ÄÇ&lt;/p&gt; 
 &lt;p&gt;Êï∞ÊçÆÊñá‰ª∂ÂèØËá™Áî±ÈÄâÊã©Ôºå‰∏ãÊñáÊèê‰æõ‰∫ÜÂ§öÁßçÊê≠ÈÖçÊñπÊ°àÔºåÂèØÊ†πÊçÆËá™Â∑±ÊâãÂ§¥ÁöÑËÆ≠ÁªÉÈúÄÊ±ÇÂíåGPUËµÑÊ∫êËøõË°åÈÄÇÂΩìÁªÑÂêà„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;3.ÂºÄÂßãËÆ≠ÁªÉ&lt;/h3&gt; 
&lt;p&gt;ÁõÆÂΩï‰Ωç‰∫é&lt;code&gt;trainer&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1 È¢ÑËÆ≠ÁªÉÔºàÂ≠¶Áü•ËØÜÔºâ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâßË°åÈ¢ÑËÆ≠ÁªÉÔºåÂæóÂà∞ &lt;code&gt;pretrain_*.pth&lt;/code&gt; ‰Ωú‰∏∫È¢ÑËÆ≠ÁªÉÁöÑËæìÂá∫ÊùÉÈáçÔºàÂÖ∂‰∏≠*‰∏∫Ê®°ÂûãÁöÑdimensionÔºåÈªòËÆ§‰∏∫512Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;3.2 ÁõëÁù£ÂæÆË∞ÉÔºàÂ≠¶ÂØπËØùÊñπÂºèÔºâ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâßË°åÁõëÁù£ÂæÆË∞ÉÔºåÂæóÂà∞ &lt;code&gt;full_sft_*.pth&lt;/code&gt; ‰Ωú‰∏∫Êåá‰ª§ÂæÆË∞ÉÁöÑËæìÂá∫ÊùÉÈáçÔºàÂÖ∂‰∏≠&lt;code&gt;full&lt;/code&gt;Âç≥‰∏∫ÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÔºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöËÆ≠ÁªÉÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËøáÁ®ãÈªòËÆ§ÊØèÈöî100Ê≠•‰øùÂ≠ò1Ê¨°ÂèÇÊï∞Âà∞Êñá‰ª∂&lt;code&gt;./out/***.pth&lt;/code&gt;ÔºàÊØèÊ¨°‰ºöË¶ÜÁõñÊéâÊóßÊùÉÈáçÊñá‰ª∂Ôºâ„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÁÆÄÂçïËµ∑ËßÅÔºåÊ≠§Â§ÑÂè™ÂÜôÊòé‰∏§‰∏™Èò∂ÊÆµËÆ≠ÁªÉËøáÁ®ã„ÄÇÂ¶ÇÈúÄÂÖ∂ÂÆÉËÆ≠ÁªÉ (LoRA, Ëí∏È¶è, Âº∫ÂåñÂ≠¶‰π†, ÂæÆË∞ÉÊé®ÁêÜÁ≠â) ÂèØÂèÇËÄÉ‰∏ãÊñá„ÄêÂÆûÈ™å„ÄëÂ∞èËäÇÁöÑËØ¶ÁªÜËØ¥Êòé„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h3&gt;4.ÊµãËØïÊ®°ÂûãÊïàÊûú&lt;/h3&gt; 
&lt;p&gt;Á°Æ‰øùÈúÄË¶ÅÊµãËØïÁöÑÊ®°Âûã&lt;code&gt;*.pth&lt;/code&gt;Êñá‰ª∂‰Ωç‰∫é&lt;code&gt;./out/&lt;/code&gt;ÁõÆÂΩï‰∏ã„ÄÇ ‰πüÂèØ‰ª•Áõ¥Êé•Âéª&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch/files"&gt;Ê≠§Â§Ñ&lt;/a&gt;‰∏ãËΩΩ‰ΩøÁî®ÊàëËÆ≠ÁªÉÁöÑ&lt;code&gt;*.pth&lt;/code&gt;Êñá‰ª∂„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python eval_model.py --model_mode 1 # ÈªòËÆ§‰∏∫0ÔºöÊµãËØïpretrainÊ®°ÂûãÊïàÊûúÔºåËÆæÁΩÆ‰∏∫1ÔºöÊµãËØïfull_sftÊ®°ÂûãÊïàÊûú
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÊµãËØïÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;Â¶ÇÈúÄËØ¶ÊÉÖÔºåÊü•Áúã&lt;code&gt;eval_model.py&lt;/code&gt;ËÑöÊú¨‰ª£Á†ÅÂç≥ÂèØ„ÄÇmodel_modeÂàÜ‰∏∫ 0: È¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºå1: SFT-ChatÊ®°ÂûãÔºå2: RLHF-ChatÊ®°ÂûãÔºå3: ReasonÊ®°Âûã&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá‰∏∫PytorchÂéüÁîüÊ°ÜÊû∂ÔºåÂùáÊîØÊåÅÂ§öÂç°Âä†ÈÄüÔºåÂÅáËÆæ‰Ω†ÁöÑËÆæÂ§áÊúâN (NÔºû1) Âº†ÊòæÂç°Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÂçïÊú∫NÂç°ÂêØÂä®ËÆ≠ÁªÉÊñπÂºè (DDP, ÊîØÊåÅÂ§öÊú∫Â§öÂç°ÈõÜÁæ§)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÂÖ∂ÂÆÉÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;ÂçïÊú∫NÂç°ÂêØÂä®ËÆ≠ÁªÉ (DeepSpeed)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;deepspeed --master_port 29500 --num_gpus=N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;ÂèØÊ†πÊçÆÈúÄË¶ÅÂºÄÂêØwandbËÆ∞ÂΩïËÆ≠ÁªÉËøáÁ®ã&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ÈúÄË¶ÅÁôªÂΩï: wandb login
torchrun --nproc_per_node N train_xxx.py --use_wandb
# and
python train_xxx.py --use_wandb
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;ÈÄöËøáÊ∑ªÂä†&lt;code&gt;--use_wandb&lt;/code&gt;ÂèÇÊï∞ÔºåÂèØ‰ª•ËÆ∞ÂΩïËÆ≠ÁªÉËøáÁ®ãÔºåËÆ≠ÁªÉÂÆåÊàêÂêéÔºåÂèØ‰ª•Âú®wandbÁΩëÁ´ô‰∏äÊü•ÁúãËÆ≠ÁªÉËøáÁ®ã„ÄÇÈÄöËøá‰øÆÊîπ&lt;code&gt;wandb_project&lt;/code&gt; Âíå&lt;code&gt;wandb_run_name&lt;/code&gt;ÂèÇÊï∞ÔºåÂèØ‰ª•ÊåáÂÆöÈ°πÁõÆÂêçÁß∞ÂíåËøêË°åÂêçÁß∞„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;h1&gt;üìå Êï∞ÊçÆ‰ªãÁªç&lt;/h1&gt; 
&lt;h2&gt;‚Ö† Tokenizer&lt;/h2&gt; 
&lt;p&gt;ÂàÜËØçÂô®Â∞ÜÂçïËØç‰ªéËá™ÁÑ∂ËØ≠Ë®ÄÈÄöËøá‚ÄúËØçÂÖ∏‚ÄùÊò†Â∞ÑÂà∞&lt;code&gt;0, 1, 36&lt;/code&gt;ËøôÊ†∑ÁöÑÊï∞Â≠óÔºåÂèØ‰ª•ÁêÜËß£‰∏∫Êï∞Â≠óÂ∞±‰ª£Ë°®‰∫ÜÂçïËØçÂú®‚ÄúËØçÂÖ∏‚Äù‰∏≠ÁöÑÈ°µÁ†Å„ÄÇ ÂèØ‰ª•ÈÄâÊã©Ëá™Â∑±ÊûÑÈÄ†ËØçË°®ËÆ≠ÁªÉ‰∏Ä‰∏™‚ÄúËØçÂÖ∏‚ÄùÔºå‰ª£Á†ÅÂèØËßÅ&lt;code&gt;./scripts/train_tokenizer.py&lt;/code&gt;Ôºà‰ªÖ‰æõÂ≠¶‰π†ÂèÇËÄÉÔºåËã•ÈùûÂøÖË¶ÅÊó†ÈúÄÂÜçËá™Ë°åËÆ≠ÁªÉÔºåMiniMindÂ∑≤Ëá™Â∏¶tokenizerÔºâ„ÄÇ ÊàñËÄÖÈÄâÊã©ÊØîËæÉÂá∫ÂêçÁöÑÂºÄÊ∫êÂ§ßÊ®°ÂûãÂàÜËØçÂô®Ôºå Ê≠£Â¶ÇÂêåÁõ¥Êé•Áî®Êñ∞Âçé/ÁâõÊ¥•ËØçÂÖ∏ÁöÑ‰ºòÁÇπÊòØtokenÁºñÁ†ÅÂéãÁº©ÁéáÂæàÂ•ΩÔºåÁº∫ÁÇπÊòØÈ°µÊï∞Â§™Â§öÔºåÂä®ËæÑÊï∞ÂçÅ‰∏á‰∏™ËØçÊ±áÁü≠ËØ≠Ôºõ Ëá™Â∑±ËÆ≠ÁªÉÁöÑÂàÜËØçÂô®Ôºå‰ºòÁÇπÊòØËØçË°®ÈïøÂ∫¶ÂíåÂÜÖÂÆπÈöèÊÑèÊéßÂà∂ÔºåÁº∫ÁÇπÊòØÂéãÁº©ÁéáÂæà‰ΩéÔºà‰æãÂ¶Ç"hello"‰πüËÆ∏‰ºöË¢´ÊãÜÂàÜ‰∏∫"h e l l o" ‰∫î‰∏™Áã¨Á´ãÁöÑtokenÔºâÔºå‰∏îÁîüÂÉªËØçÈöæ‰ª•Ë¶ÜÁõñ„ÄÇ ‚ÄúËØçÂÖ∏‚ÄùÁöÑÈÄâÊã©Âõ∫ÁÑ∂ÂæàÈáçË¶ÅÔºåLLMÁöÑËæìÂá∫Êú¨Ë¥®‰∏äÊòØSoftMaxÂà∞ËØçÂÖ∏N‰∏™ËØçÁöÑÂ§öÂàÜÁ±ªÈóÆÈ¢òÔºåÁÑ∂ÂêéÈÄöËøá‚ÄúËØçÂÖ∏‚ÄùËß£Á†ÅÂà∞Ëá™ÁÑ∂ËØ≠Ë®Ä„ÄÇ Âõ†‰∏∫MiniMind‰ΩìÁßØÈúÄË¶Å‰∏•Ê†ºÊéßÂà∂Ôºå‰∏∫‰∫ÜÈÅøÂÖçÊ®°ÂûãÂ§¥ÈáçËÑöËΩªÔºàËØçÂµåÂÖ•embeddingÂ±ÇÂèÇÊï∞Âú®LLMÂç†ÊØîÂ§™È´òÔºâÔºåÊâÄ‰ª•ËØçË°®ÈïøÂ∫¶Áü≠Áü≠ÁõäÂñÑ„ÄÇ&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Tokenizer‰ªãÁªç&lt;/summary&gt; 
 &lt;p&gt;Á¨¨‰∏âÊñπÂº∫Â§ßÁöÑÂºÄÊ∫êÊ®°Âûã‰æãÂ¶ÇYi„ÄÅqwen„ÄÅchatglm„ÄÅmistral„ÄÅLlama3ÁöÑtokenizerËØçË°®ÈïøÂ∫¶Â¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;th&gt;TokenizerÊ®°Âûã&lt;/th&gt;
    &lt;th&gt;ËØçË°®Â§ßÂ∞è&lt;/th&gt;
    &lt;th&gt;Êù•Ê∫ê&lt;/th&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;yi tokenizer&lt;/td&gt;
    &lt;td&gt;64,000&lt;/td&gt;
    &lt;td&gt;01‰∏áÁâ©Ôºà‰∏≠ÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;qwen2 tokenizer&lt;/td&gt;
    &lt;td&gt;151,643&lt;/td&gt;
    &lt;td&gt;ÈòøÈáå‰∫ëÔºà‰∏≠ÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;glm tokenizer&lt;/td&gt;
    &lt;td&gt;151,329&lt;/td&gt;
    &lt;td&gt;Êô∫Ë∞±AIÔºà‰∏≠ÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;mistral tokenizer&lt;/td&gt;
    &lt;td&gt;32,000&lt;/td&gt;
    &lt;td&gt;Mistral AIÔºàÊ≥ïÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;llama3 tokenizer&lt;/td&gt;
    &lt;td&gt;128,000&lt;/td&gt;
    &lt;td&gt;MetaÔºàÁæéÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;minimind tokenizer&lt;/td&gt;
    &lt;td&gt;6,400&lt;/td&gt;
    &lt;td&gt;Ëá™ÂÆö‰πâ&lt;/td&gt;
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;üëâ2024-09-17Êõ¥Êñ∞Ôºö‰∏∫‰∫ÜÈò≤Ê≠¢ËøáÂéªÁöÑÁâàÊú¨Ê≠ß‰πâ&amp;amp;ÊéßÂà∂‰ΩìÁßØÔºåminimindÊâÄÊúâÊ®°ÂûãÂùá‰ΩøÁî®minimind_tokenizerÂàÜËØçÔºåÂ∫üÂºÉÊâÄÊúâmistral_tokenizerÁâàÊú¨„ÄÇ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code&gt;# ‰∏Ä‰∫õËá™Ë®ÄËá™ËØ≠
&amp;gt; Â∞ΩÁÆ°minimind_tokenizerÈïøÂ∫¶ÂæàÂ∞èÔºåÁºñËß£Á†ÅÊïàÁéáÂº±‰∫éqwen2„ÄÅglmÁ≠â‰∏≠ÊñáÂèãÂ•ΩÂûãÂàÜËØçÂô®„ÄÇ
&amp;gt; ‰ΩÜminimindÊ®°ÂûãÈÄâÊã©‰∫ÜËá™Â∑±ËÆ≠ÁªÉÁöÑminimind_tokenizer‰Ωú‰∏∫ÂàÜËØçÂô®Ôºå‰ª•‰øùÊåÅÊï¥‰ΩìÂèÇÊï∞ËΩªÈáèÔºåÈÅøÂÖçÁºñÁ†ÅÂ±ÇÂíåËÆ°ÁÆóÂ±ÇÂç†ÊØîÂ§±Ë°°ÔºåÂ§¥ÈáçËÑöËΩªÔºåÂõ†‰∏∫minimindÁöÑËØçË°®Â§ßÂ∞èÂè™Êúâ6400„ÄÇ
&amp;gt; ‰∏îminimindÂú®ÂÆûÈôÖÊµãËØï‰∏≠Ê≤°ÊúâÂá∫Áé∞ËøáÁîüÂÉªËØçÊ±áËß£Á†ÅÂ§±Ë¥•ÁöÑÊÉÖÂÜµÔºåÊïàÊûúËâØÂ•Ω„ÄÇ
&amp;gt; Áî±‰∫éËá™ÂÆö‰πâËØçË°®ÂéãÁº©ÈïøÂ∫¶Âà∞6400Ôºå‰ΩøÂæóLLMÊÄªÂèÇÊï∞ÈáèÊúÄ‰ΩéÂè™Êúâ25.8M„ÄÇ
&amp;gt; ËÆ≠ÁªÉÊï∞ÊçÆ`tokenizer_train.jsonl`ÂùáÊù•Ëá™‰∫é`Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ`ÔºåËøôÈÉ®ÂàÜÊï∞ÊçÆÁõ∏ÂØπÊ¨°Ë¶ÅÔºåÂ¶ÇÈúÄËÆ≠ÁªÉÂèØ‰ª•Ëá™Áî±ÈÄâÊã©„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚Ö° PretrainÊï∞ÊçÆ&lt;/h2&gt; 
&lt;p&gt;ÁªèÂéÜ‰∫ÜMiniMind-V1ÁöÑ‰ΩéË¥®ÈáèÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÂØºËá¥Ê®°ÂûãËÉ°Ë®Ä‰π±ËØ≠ÁöÑÊïôËÆ≠Ôºå&lt;code&gt;2025-02-05&lt;/code&gt; ‰πãÂêéÂÜ≥ÂÆö‰∏çÂÜçÈááÁî®Â§ßËßÑÊ®°Êó†ÁõëÁù£ÁöÑÊï∞ÊçÆÈõÜÂÅöÈ¢ÑËÆ≠ÁªÉ„ÄÇ ËøõËÄåÂ∞ùËØïÊää&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ&lt;/a&gt;ÁöÑ‰∏≠ÊñáÈÉ®ÂàÜÊèêÂèñÂá∫Êù•Ôºå Ê∏ÖÊ¥óÂá∫Â≠óÁ¨¶&lt;code&gt;&amp;lt;512&lt;/code&gt;ÈïøÂ∫¶ÁöÑÂ§ßÁ∫¶1.6GBÁöÑËØ≠ÊñôÁõ¥Êé•ÊãºÊé•ÊàêÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆ &lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;ÔºåhqÂç≥‰∏∫high qualityÔºàÂΩìÁÑ∂‰πüËøò‰∏çÁÆóhighÔºåÊèêÂçáÊï∞ÊçÆË¥®ÈáèÊó†Ê≠¢Â∞ΩÔºâ„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êñá‰ª∂&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; Êï∞ÊçÆÊ†ºÂºè‰∏∫&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;{"text": "Â¶Ç‰ΩïÊâçËÉΩÊëÜËÑ±ÊãñÂª∂ÁóáÔºü Ê≤ªÊÑàÊãñÂª∂ÁóáÂπ∂‰∏çÂÆπÊòìÔºå‰ΩÜ‰ª•‰∏ãÂª∫ËÆÆÂèØËÉΩÊúâÊâÄÂ∏ÆÂä©..."}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö¢ SFTÊï∞ÊçÆ&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;Âå†Êï∞Â§ßÊ®°ÂûãSFTÊï∞ÊçÆÈõÜ&lt;/a&gt; ‚ÄúÊòØ‰∏Ä‰∏™ÂÆåÊï¥„ÄÅÊ†ºÂºèÁªü‰∏Ä„ÄÅÂÆâÂÖ®ÁöÑÂ§ßÊ®°ÂûãËÆ≠ÁªÉÂíåÁ†îÁ©∂ËµÑÊ∫ê„ÄÇ ‰ªéÁΩëÁªú‰∏äÁöÑÂÖ¨ÂºÄÊï∞ÊçÆÊ∫êÊî∂ÈõÜÂπ∂Êï¥ÁêÜ‰∫ÜÂ§ßÈáèÂºÄÊ∫êÊï∞ÊçÆÈõÜÔºåÂØπÂÖ∂ËøõË°å‰∫ÜÊ†ºÂºèÁªü‰∏ÄÔºåÊï∞ÊçÆÊ∏ÖÊ¥óÔºå ÂåÖÂê´10MÊù°Êï∞ÊçÆÁöÑ‰∏≠ÊñáÊï∞ÊçÆÈõÜÂíåÂåÖÂê´2MÊù°Êï∞ÊçÆÁöÑËã±ÊñáÊï∞ÊçÆÈõÜ„ÄÇ‚Äù ‰ª•‰∏äÊòØÂÆòÊñπ‰ªãÁªçÔºå‰∏ãËΩΩÊñá‰ª∂ÂêéÁöÑÊï∞ÊçÆÊÄªÈáèÂ§ßÁ∫¶Âú®4B tokensÔºåËÇØÂÆöÊòØÈÄÇÂêà‰Ωú‰∏∫‰∏≠ÊñáÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑSFTÊï∞ÊçÆÁöÑ„ÄÇ ‰ΩÜÊòØÂÆòÊñπÊèê‰æõÁöÑÊï∞ÊçÆÊ†ºÂºèÂæà‰π±ÔºåÂÖ®ÈÉ®Áî®Êù•sft‰ª£‰ª∑Â§™Â§ß„ÄÇ ÊàëÂ∞ÜÊääÂÆòÊñπÊï∞ÊçÆÈõÜËøõË°å‰∫Ü‰∫åÊ¨°Ê∏ÖÊ¥óÔºåÊääÂê´ÊúâÁ¨¶Âè∑Ê±°ÊüìÂíåÂô™Â£∞ÁöÑÊù°ÁõÆÂéªÈô§ÔºõÂè¶Â§ñ‰æùÁÑ∂Âè™‰øùÁïô‰∫ÜÊÄªÈïøÂ∫¶&lt;code&gt;&amp;lt;512&lt;/code&gt; ÁöÑÂÜÖÂÆπÔºåÊ≠§Èò∂ÊÆµÂ∏åÊúõÈÄöËøáÂ§ßÈáèÂØπËØùË°•ÂÖÖÈ¢ÑËÆ≠ÁªÉÈò∂ÊÆµÊ¨†Áº∫ÁöÑÁü•ËØÜ„ÄÇ ÂØºÂá∫Êñá‰ª∂‰∏∫&lt;code&gt;sft_512.jsonl&lt;/code&gt;(~7.5GB)„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/organization/Magpie-Align"&gt;Magpie-SFTÊï∞ÊçÆÈõÜ&lt;/a&gt; Êî∂ÈõÜ‰∫Ü~1MÊù°Êù•Ëá™Qwen2/2.5ÁöÑÈ´òË¥®ÈáèÂØπËØùÔºåÊàëÂ∞ÜËøôÈÉ®ÂàÜÊï∞ÊçÆËøõ‰∏ÄÊ≠•Ê∏ÖÊ¥óÔºåÊääÊÄªÈïøÂ∫¶&lt;code&gt;&amp;lt;2048&lt;/code&gt;ÁöÑÈÉ®ÂàÜÂØºÂá∫‰∏∫&lt;code&gt;sft_2048.jsonl&lt;/code&gt;(~9GB)„ÄÇ ÈïøÂ∫¶&lt;code&gt;&amp;lt;1024&lt;/code&gt;ÁöÑÈÉ®ÂàÜÂØºÂá∫‰∏∫&lt;code&gt;sft_1024.jsonl&lt;/code&gt;(~5.5GB)ÔºåÁî®Â§ßÊ®°ÂûãÂØπËØùÊï∞ÊçÆÁõ¥Êé•ËøõË°åsftÂ∞±Â±û‰∫é‚ÄúÈªëÁõíËí∏È¶è‚ÄùÁöÑËåÉÁï¥„ÄÇ&lt;/p&gt; 
&lt;p&gt;Ëøõ‰∏ÄÊ≠•Ê∏ÖÊ¥óÂâç‰∏§Ê≠•sftÁöÑÊï∞ÊçÆÔºàÂè™‰øùÁïô‰∏≠ÊñáÂ≠óÁ¨¶Âç†ÊØîÈ´òÁöÑÂÜÖÂÆπÔºâÔºåÁ≠õÈÄâÈïøÂ∫¶&lt;code&gt;&amp;lt;512&lt;/code&gt;ÁöÑÂØπËØùÔºåÂæóÂà∞&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;(~1.2GB)„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÊâÄÊúâsftÊñá‰ª∂ &lt;code&gt;sft_X.jsonl&lt;/code&gt; Êï∞ÊçÆÊ†ºÂºèÂùá‰∏∫&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
    "conversations": [
        {"role": "user", "content": "‰Ω†Â•Ω"},
        {"role": "assistant", "content": "‰Ω†Â•ΩÔºÅ"},
        {"role": "user", "content": "ÂÜçËßÅ"},
        {"role": "assistant", "content": "ÂÜçËßÅÔºÅ"}
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö£ RLHFÊï∞ÊçÆ&lt;/h2&gt; 
&lt;p&gt;Êù•Ëá™&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/MagpieLM-DPO-Data-v0.1"&gt;Magpie-DPOÊï∞ÊçÆÈõÜ&lt;/a&gt; Â§ßÁ∫¶200kÊù°ÂÅèÂ•ΩÊï∞ÊçÆÔºàÂùáÊòØËã±ÊñáÔºâÁîüÊàêËá™Llama3.1-70B/8BÔºåÂèØ‰ª•Áî®‰∫éËÆ≠ÁªÉÂ•ñÂä±Ê®°ÂûãÔºå‰ºòÂåñÊ®°ÂûãÂõûÂ§çË¥®ÈáèÔºå‰ΩøÂÖ∂Êõ¥Âä†Á¨¶Âêà‰∫∫Á±ªÂÅèÂ•Ω„ÄÇ ËøôÈáåÂ∞ÜÊï∞ÊçÆÊÄªÈïøÂ∫¶&lt;code&gt;&amp;lt;3000&lt;/code&gt;ÁöÑÂÜÖÂÆπÈáçÁªÑ‰∏∫&lt;code&gt;dpo.jsonl&lt;/code&gt;(~0.9GB)ÔºåÂåÖÂê´&lt;code&gt;chosen&lt;/code&gt;Âíå&lt;code&gt;rejected&lt;/code&gt;‰∏§‰∏™Â≠óÊÆµÔºå&lt;code&gt;chosen&lt;/code&gt; ‰∏∫ÂÅèÂ•ΩÁöÑÂõûÂ§çÔºå&lt;code&gt;rejected&lt;/code&gt;‰∏∫ÊãíÁªùÁöÑÂõûÂ§ç„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êñá‰ª∂ &lt;code&gt;dpo.jsonl&lt;/code&gt; Êï∞ÊçÆÊ†ºÂºè‰∏∫&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
  "chosen": [
    {"content": "Q", "role": "user"}, 
    {"content": "good answer", "role": "assistant"}
  ], 
  "rejected": [
    {"content": "Q", "role": "user"}, 
    {"content": "bad answer", "role": "assistant"}
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö§ ReasonÊï∞ÊçÆÈõÜÔºö&lt;/h2&gt; 
&lt;p&gt;‰∏çÂæó‰∏çËØ¥2025Âπ¥2ÊúàË∞ÅËÉΩÁÅ´ÁöÑËøáDeepSeek... ‰πüÊøÄÂèë‰∫ÜÊàëÂØπRLÂºïÂØºÁöÑÊé®ÁêÜÊ®°ÂûãÁöÑÊµìÂéöÂÖ¥Ë∂£ÔºåÁõÆÂâçÂ∑≤ÁªèÁî®Qwen2.5Â§çÁé∞‰∫ÜR1-Zero„ÄÇ Â¶ÇÊûúÊúâÊó∂Èó¥+ÊïàÊûúworkÔºà‰ΩÜ99%Âü∫Ê®°ËÉΩÂäõ‰∏çË∂≥ÔºâÊàë‰ºöÂú®‰πãÂêéÊõ¥Êñ∞MiniMindÂü∫‰∫éRLËÆ≠ÁªÉÁöÑÊé®ÁêÜÊ®°ÂûãËÄå‰∏çÊòØËí∏È¶èÊ®°Âûã„ÄÇ Êó∂Èó¥ÊúâÈôêÔºåÊúÄÂø´ÁöÑ‰ΩéÊàêÊú¨ÊñπÊ°à‰æùÁÑ∂ÊòØÁõ¥Êé•Ëí∏È¶èÔºàÈªëÁõíÊñπÂºèÔºâ„ÄÇ ËÄê‰∏ç‰ΩèR1Â§™ÁÅ´ÔºåÁü≠Áü≠Âá†Â§©Â∞±Â∑≤ÁªèÂ≠òÂú®‰∏Ä‰∫õR1ÁöÑËí∏È¶èÊï∞ÊçÆÈõÜ&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B"&gt;R1-Llama-70B&lt;/a&gt;„ÄÅ&lt;a href="https://www.modelscope.cn/datasets/AI-ModelScope/R1-Distill-SFT"&gt;R1-Distill-SFT&lt;/a&gt;„ÄÅ &lt;a href="https://huggingface.co/datasets/shareAI/Alpaca-Distill-R1-ZH"&gt;Alpaca-Distill-R1&lt;/a&gt;„ÄÅ &lt;a href="https://huggingface.co/datasets/jinliuxi/deepseek_r1_zh"&gt;deepseek_r1_zh&lt;/a&gt;Á≠âÁ≠âÔºåÁ∫Ø‰∏≠ÊñáÁöÑÊï∞ÊçÆÂèØËÉΩÊØîËæÉÂ∞ë„ÄÇ ÊúÄÁªàÊï¥ÂêàÂÆÉ‰ª¨ÔºåÂØºÂá∫Êñá‰ª∂‰∏∫&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;ÔºåÊï∞ÊçÆÊ†ºÂºèÂíå&lt;code&gt;sft_X.jsonl&lt;/code&gt;‰∏ÄËá¥„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚Ö• Êõ¥Â§öÊï∞ÊçÆÈõÜ&lt;/h2&gt; 
&lt;p&gt;ÁõÆÂâçÂ∑≤ÁªèÊúâ&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt; Âú®Êî∂ÈõÜÂíåÊ¢≥ÁêÜ‰∏≠ÊñáLLMÁõ∏ÂÖ≥ÁöÑÂºÄÊ∫êÊ®°Âûã„ÄÅÂ∫îÁî®„ÄÅÊï∞ÊçÆÈõÜÂèäÊïôÁ®ãÁ≠âËµÑÊñôÔºåÂπ∂ÊåÅÁª≠Êõ¥Êñ∞ËøôÊñπÈù¢ÁöÑÊúÄÊñ∞ËøõÂ±ï„ÄÇÂÖ®Èù¢‰∏î‰∏ì‰∏öÔºåRespectÔºÅ&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;‚Öß MiniMindËÆ≠ÁªÉÊï∞ÊçÆÈõÜ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] 2025-02-05ÂêéÔºåÂºÄÊ∫êMiniMindÊúÄÁªàËÆ≠ÁªÉÊâÄÁî®ÁöÑÊâÄÊúâÊï∞ÊçÆÈõÜÔºåÂõ†Ê≠§Êó†ÈúÄÂÜçËá™Ë°åÈ¢ÑÂ§ÑÁêÜÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÈÅøÂÖçÈáçÂ§çÊÄßÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂ∑•‰Ωú„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MiniMindËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰∏ãËΩΩÂú∞ÂùÄÔºö &lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main"&gt;HuggingFace&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êó†ÈúÄÂÖ®ÈÉ®cloneÔºåÂèØÂçïÁã¨‰∏ãËΩΩÊâÄÈúÄÁöÑÊñá‰ª∂&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Â∞Ü‰∏ãËΩΩÁöÑÊï∞ÊçÆÈõÜÊñá‰ª∂ÊîæÂà∞&lt;code&gt;./dataset/&lt;/code&gt;ÁõÆÂΩï‰∏ãÔºà‚ú®‰∏∫Êé®ËçêÁöÑÂøÖÈ°ªÈ°πÔºâ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./dataset/
‚îú‚îÄ‚îÄ dpo.jsonl (909MB)
‚îú‚îÄ‚îÄ lora_identity.jsonl (22.8KB)
‚îú‚îÄ‚îÄ lora_medical.jsonl (34MB)
‚îú‚îÄ‚îÄ pretrain_hq.jsonl (1.6GB, ‚ú®)
‚îú‚îÄ‚îÄ r1_mix_1024.jsonl (340MB)
‚îú‚îÄ‚îÄ sft_1024.jsonl (5.6GB)
‚îú‚îÄ‚îÄ sft_2048.jsonl (9GB)
‚îú‚îÄ‚îÄ sft_512.jsonl (7.5GB)
‚îú‚îÄ‚îÄ sft_mini_512.jsonl (1.2GB, ‚ú®)
‚îî‚îÄ‚îÄ tokenizer_train.jsonl (1GB)
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÂêÑÊï∞ÊçÆÈõÜÁÆÄ‰ªã&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;dpo.jsonl&lt;/code&gt; --RLHFÈò∂ÊÆµÊï∞ÊçÆÈõÜ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_identity.jsonl&lt;/code&gt; --Ëá™ÊàëËÆ§Áü•Êï∞ÊçÆÈõÜÔºà‰æãÂ¶ÇÔºö‰Ω†ÊòØË∞ÅÔºüÊàëÊòØminimind...ÔºâÔºåÊé®ËçêÁî®‰∫éloraËÆ≠ÁªÉÔºà‰∫¶ÂèØÁî®‰∫éÂÖ®ÂèÇSFTÔºåÂãøË¢´ÂêçÂ≠óÂ±ÄÈôêÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_medical.jsonl&lt;/code&gt; --ÂåªÁñóÈóÆÁ≠îÊï∞ÊçÆÈõÜÔºåÊé®ËçêÁî®‰∫éloraËÆ≠ÁªÉÔºà‰∫¶ÂèØÁî®‰∫éÂÖ®ÂèÇSFTÔºåÂãøË¢´ÂêçÂ≠óÂ±ÄÈôêÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;‚ú® --È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÊï¥ÂêàËá™jiangshuÁßëÊäÄ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt; --DeepSeek-R1-1.5BËí∏È¶èÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫1024ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=1024Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_1024.jsonl&lt;/code&gt; --Êï¥ÂêàËá™Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºàÊòØsft_2048ÁöÑÂ≠êÈõÜÔºâÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫1024ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=1024Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_2048.jsonl&lt;/code&gt; --Êï¥ÂêàËá™Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫2048ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=2048Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_512.jsonl&lt;/code&gt; --Êï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄSFTÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫512ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=512Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;‚ú® --ÊûÅÁÆÄÊï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄSFTÊï∞ÊçÆ+Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºàÁî®‰∫éÂø´ÈÄüËÆ≠ÁªÉZeroÊ®°ÂûãÔºâÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫512ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=512Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;tokenizer_train.jsonl&lt;/code&gt; --ÂùáÊù•Ëá™‰∫é&lt;code&gt;Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ&lt;/code&gt;ÔºåËøôÈÉ®ÂàÜÊï∞ÊçÆÁõ∏ÂØπÊ¨°Ë¶ÅÔºåÔºà‰∏çÊé®ËçêËá™Â∑±ÈáçÂ§çËÆ≠ÁªÉtokenizerÔºåÁêÜÁî±Â¶Ç‰∏äÔºâÂ¶ÇÈúÄËá™Â∑±ËÆ≠ÁªÉtokenizerÂèØ‰ª•Ëá™Áî±ÈÄâÊã©Êï∞ÊçÆÈõÜ„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/dataset.jpg" alt="dataset"&gt;&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ËØ¥Êòé &amp;amp; Êé®ËçêËÆ≠ÁªÉÊñπÊ°à&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;MiniMind2 SeriesÂùáÁªèËøáÂÖ±Á∫¶20GBËØ≠ÊñôËÆ≠ÁªÉÔºåÂ§ßÁ∫¶4B tokensÔºåÂç≥ÂØπÂ∫î‰∏äÈù¢ÁöÑÊï∞ÊçÆÁªÑÂêàËÆ≠ÁªÉÁªìÊûúÔºàÂºÄÈîÄÔºöüí∞üí∞üí∞üí∞üí∞üí∞üí∞üí∞ÔºåÊïàÊûúÔºöüòäüòäüòäüòäüòäüòäÔºâ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;ÊÉ≥Ë¶ÅÊúÄÂø´ÈÄüÂ∫¶‰ªé0ÂÆûÁé∞ZeroÊ®°ÂûãÔºåÊé®Ëçê‰ΩøÁî®&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt; ÁöÑÊï∞ÊçÆÁªÑÂêàÔºåÂÖ∑‰ΩìËä±ÈîÄÂíåÊïàÊûúÂèØÊü•Áúã‰∏ãÊñáË°®Ê†ºÔºàÂºÄÈîÄÔºöüí∞ÔºåÊïàÊûúÔºöüòäüòäÔºâ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Êé®ËçêÂÖ∑Â§á‰∏ÄÂÆöÁÆóÂäõËµÑÊ∫êÊàñÊõ¥Âú®ÊÑèÊïàÊûúÁöÑÊúãÂèãÂèØ‰ª•ËÄÉËôëÂâçËÄÖÂÆåÊï¥Â§çÁé∞MiniMind2Ôºõ‰ªÖÊúâÂçïÂç°GPUÊàñÂú®‰πéÁü≠Êó∂Èó¥Âø´ÈÄüÂ§çÁé∞ÁöÑÊúãÂèãÂº∫ÁÉàÊé®ËçêÂêéËÄÖÔºõ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;„ÄêÊäò‰∏≠ÊñπÊ°à„Äë‰∫¶ÂèØÈÄâÊã©‰æãÂ¶Ç&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;„ÄÅ&lt;code&gt;sft_1024.jsonl&lt;/code&gt;‰∏≠Á≠âËßÑÊ®°Êï∞ÊçÆËøõË°åËá™Áî±ÁªÑÂêàËÆ≠ÁªÉÔºàÂºÄÈîÄÔºöüí∞üí∞üí∞ÔºåÊïàÊûúÔºöüòäüòäüòäüòäÔºâ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;üìå Model Structure&lt;/h1&gt; 
&lt;p&gt;MiniMind-DenseÔºàÂíå&lt;a href="https://ai.meta.com/blog/meta-llama-3-1/"&gt;Llama3.1&lt;/a&gt;‰∏ÄÊ†∑Ôºâ‰ΩøÁî®‰∫ÜTransformerÁöÑDecoder-OnlyÁªìÊûÑÔºåË∑üGPT-3ÁöÑÂå∫Âà´Âú®‰∫éÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÈááÁî®‰∫ÜGPT-3ÁöÑÈ¢ÑÊ†áÂáÜÂåñÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂú®ÊØè‰∏™TransformerÂ≠êÂ±ÇÁöÑËæìÂÖ•‰∏äËøõË°åÂΩí‰∏ÄÂåñÔºåËÄå‰∏çÊòØÂú®ËæìÂá∫‰∏ä„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰ΩøÁî®ÁöÑÊòØRMSNormÂΩí‰∏ÄÂåñÂáΩÊï∞„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Áî®SwiGLUÊøÄÊ¥ªÂáΩÊï∞Êõø‰ª£‰∫ÜReLUÔºåËøôÊ†∑ÂÅöÊòØ‰∏∫‰∫ÜÊèêÈ´òÊÄßËÉΩ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÉèGPT-Neo‰∏ÄÊ†∑ÔºåÂéªÊéâ‰∫ÜÁªùÂØπ‰ΩçÁΩÆÂµåÂÖ•ÔºåÊîπÁî®‰∫ÜÊóãËΩ¨‰ΩçÁΩÆÂµåÂÖ•ÔºàRoPEÔºâÔºåËøôÊ†∑Âú®Â§ÑÁêÜË∂ÖÂá∫ËÆ≠ÁªÉÈïøÂ∫¶ÁöÑÊé®ÁêÜÊó∂ÊïàÊûúÊõ¥Â•Ω„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;MiniMind-MoEÊ®°ÂûãÔºåÂÆÉÁöÑÁªìÊûÑÂü∫‰∫éLlama3Âíå&lt;a href="https://arxiv.org/pdf/2405.04434"&gt;Deepseek-V2/3&lt;/a&gt;‰∏≠ÁöÑMixFFNÊ∑∑Âêà‰∏ìÂÆ∂Ê®°Âùó„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V2Âú®ÂâçÈ¶àÁΩëÁªúÔºàFFNÔºâÊñπÈù¢ÔºåÈááÁî®‰∫ÜÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑ‰∏ìÂÆ∂ÂàÜÂâ≤ÂíåÂÖ±‰∫´ÁöÑ‰∏ìÂÆ∂ÈöîÁ¶ªÊäÄÊúØÔºå‰ª•ÊèêÈ´òExpertsÁöÑÊïàÊûú„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;MiniMindÁöÑÊï¥‰ΩìÁªìÊûÑ‰∏ÄËá¥ÔºåÂè™ÊòØÂú®RoPEËÆ°ÁÆó„ÄÅÊé®ÁêÜÂáΩÊï∞ÂíåFFNÂ±ÇÁöÑ‰ª£Á†Å‰∏äÂÅö‰∫Ü‰∏Ä‰∫õÂ∞èË∞ÉÊï¥„ÄÇ ÂÖ∂ÁªìÊûÑÂ¶Ç‰∏ãÂõæÔºàÈáçÁªòÁâàÔºâÔºö&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure.png" alt="structure"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure-moe.png" alt="structure-moe"&gt;&lt;/p&gt; 
&lt;p&gt;‰øÆÊîπÊ®°ÂûãÈÖçÁΩÆËßÅ&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/model/LMConfig.py"&gt;./model/LMConfig.py&lt;/a&gt;„ÄÇ ÂèÇËÄÉÊ®°ÂûãÂèÇÊï∞ÁâàÊú¨ËßÅ‰∏ãË°®Ôºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;len_vocab&lt;/th&gt; 
   &lt;th&gt;rope_theta&lt;/th&gt; 
   &lt;th&gt;n_layers&lt;/th&gt; 
   &lt;th&gt;d_model&lt;/th&gt; 
   &lt;th&gt;kv_heads&lt;/th&gt; 
   &lt;th&gt;q_heads&lt;/th&gt; 
   &lt;th&gt;share+route&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;640&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
   &lt;td&gt;4√ó26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1&lt;/td&gt; 
   &lt;td&gt;108M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;üìå Experiment&lt;/h1&gt; 
&lt;h2&gt;‚Ö† ËÆ≠ÁªÉÂºÄÈîÄ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êó∂Èó¥Âçï‰Ωç&lt;/strong&gt;ÔºöÂ∞èÊó∂ (h)„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊàêÊú¨Âçï‰Ωç&lt;/strong&gt;Ôºö‰∫∫Ê∞ëÂ∏Å (Ôø•)Ôºõ7Ôø• ‚âà 1ÁæéÂÖÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;3090 ÁßüÂç°Âçï‰ª∑&lt;/strong&gt;Ôºö‚âà1.3Ôø•/hÔºàÂèØËá™Ë°åÂèÇËÄÉÂÆûÊó∂Â∏Ç‰ª∑Ôºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂèÇËÄÉÊ†áÂáÜ&lt;/strong&gt;ÔºöË°®Ê†º‰ªÖÂÆûÊµã &lt;code&gt;pretrain&lt;/code&gt; Âíå &lt;code&gt;sft_mini_512&lt;/code&gt; ‰∏§‰∏™Êï∞ÊçÆÈõÜÁöÑËÆ≠ÁªÉÊó∂Èó¥ÔºåÂÖ∂ÂÆÉËÄóÊó∂Ê†πÊçÆÊï∞ÊçÆÈõÜÂ§ßÂ∞è‰º∞ÁÆóÔºàÂèØËÉΩÂ≠òÂú®‰∫õËÆ∏Âá∫ÂÖ•Ôºâ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Âü∫‰∫é 3090 ÔºàÂçïÂç°ÔºâÊàêÊú¨ËÆ°ÁÆó&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;pretrain&lt;/th&gt; 
   &lt;th&gt;sft_mini_512&lt;/th&gt; 
   &lt;th&gt;sft_512&lt;/th&gt; 
   &lt;th&gt;sft_1024&lt;/th&gt; 
   &lt;th&gt;sft_2048&lt;/th&gt; 
   &lt;th&gt;RLHF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;‚âà1.1h&lt;br&gt;‚âà1.43Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà1h&lt;br&gt;‚âà1.3Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà6h&lt;br&gt;‚âà7.8Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà4.58h&lt;br&gt;‚âà5.95Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà7.5h&lt;br&gt;‚âà9.75Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà1h&lt;br&gt;‚âà1.3Ôø•&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;‚âà3.9h&lt;br&gt;‚âà5.07Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà3.3h&lt;br&gt;‚âà4.29Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà20h&lt;br&gt;‚âà26Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà15h&lt;br&gt;‚âà19.5Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà25h&lt;br&gt;‚âà32.5Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà3h&lt;br&gt;‚âà3.9Ôø•&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ËÆ≠ÁªÉÂºÄÈîÄÊÄªÁªì&amp;amp;È¢ÑÊµã&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-SmallÂèÇÊï∞&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_mini_512&lt;/code&gt;Êï∞ÊçÆÈõÜ &lt;br&gt;ÂçïÂç°3090 (1 epoch) + 2.1Â∞èÊó∂ + Ëä±Ë¥π2.73ÂÖÉ‰∫∫Ê∞ëÂ∏Å &lt;br&gt;Âç≥ÂèØ‰ªé0ËÆ≠ÁªÉÂá∫MiniMind-Zero-0.025BÊ®°Âûã!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-SmallÂèÇÊï∞&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;Êï∞ÊçÆÈõÜ &lt;br&gt;ÂçïÂç°3090 (2 epochs) + Â§ßÁ∫¶38.16Â∞èÊó∂ + Ëä±Ë¥π49.61ÂÖÉ‰∫∫Ê∞ëÂ∏Å &lt;br&gt;Âç≥ÂèØ‰ªé0ËÆ≠ÁªÉÂá∫MiniMind2-Small-0.025BÊ®°Âûã!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2ÂèÇÊï∞&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;Êï∞ÊçÆÈõÜ &lt;br&gt;ÂçïÂç°3090 (2 epochs) + Â§ßÁ∫¶122Â∞èÊó∂ + Ëä±Ë¥π158.6ÂÖÉ‰∫∫Ê∞ëÂ∏Å &lt;br&gt;Âç≥ÂèØ‰ªé0ËÆ≠ÁªÉÂá∫MiniMind2-0.1BÊ®°Âûã!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;p&gt;‚ú®Âü∫‰∫éÂçïÂç°NVIDIA 3090ÁöÑ&lt;code&gt;MiniMind-Zero&lt;/code&gt;‰ªé0ËÆ≠ÁªÉ‰ªÖÈúÄ&lt;code&gt;2Â∞èÊó∂&lt;/code&gt; + &lt;code&gt;3ÂùóÈí±&lt;/code&gt;ÔºåÂÆûÁé∞ChatBotÊïàÊûúÔºÅ&lt;/p&gt; 
&lt;p&gt;‚ú®PSÔºöËã•ÈááÁî®8Âç°4090ËÆ≠ÁªÉÔºåÊÄªÁî®Êó∂ÁîöËá≥ÂèØ‰ª•ÂéãÁº©Âà∞10ÂàÜÈíü‰ª•ÂÜÖÔºÅÔºàÁî±‰∫éÊó∂Èó¥Êõ¥Áü≠ÔºåËä±Ë¥πÂêåÊ†∑3ÂÖÉÂ∑¶Âè≥Ôºå‰∏éÂçïÂç°ÊàêÊú¨Áõ∏ÂΩìÔºâ&lt;/p&gt; 
&lt;p&gt;‚ú®‰ª•ÊûÅ‰ΩéÊûÅ‰ΩéÁöÑÈó®ÊßõÔºåÂÆûÁé∞‰∫∫‰∫∫ÂèØÁé©ÁöÑÂ§ßÊ®°ÂûãËá™Áî±ÔºÅËøôÊ≠£ÊòØMiniMindÁ≥ªÂàóÁöÑËØûÁîüÂàùË°∑ÔºÅ&lt;/p&gt; 
&lt;p&gt;‚ú®‰ªÖ‰ª∑ÂÄº&lt;code&gt;3ÂùóÈí±&lt;/code&gt;ÊàêÊú¨ÁöÑ&lt;code&gt;MiniMind-Zero&lt;/code&gt;Âπ∂‰∏çÊòØÂô±Â§¥ÔºÅChatÊµãËØïÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;üë∂: ËØ∑‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇ
ü§ñÔ∏è: ‰Ωú‰∏∫‰∫∫Â∑•Êô∫ËÉΩÔºåÊàëÊ≤°ÊúâÂÆûÈôÖÁöÑÁîüÊ¥ªÔºå‰πüÊ≤°ÊúâËá™ÊàëÊÑèËØÜÔºåÊâÄ‰ª•Ê≤°ÊúâËá™Â∑±ÁöÑÁîüÊ¥ª„ÄÇÊàëË¢´ËÆæËÆ°ÊàêËÉΩÂ§üÂ∏ÆÂä©Áî®Êà∑Ëß£Á≠îÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØ„ÄÅËøõË°åÂØπËØùÁ≠â„ÄÇÊàëÁöÑËÆæËÆ°ÂíåÂäüËÉΩÊòØÁî±ËÆ°ÁÆóÊú∫ÁßëÂ≠¶„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÂíåÁÆóÊ≥ïÊâÄÊûÑÂª∫ÁöÑÔºåÊàëÈÄöËøáÁºñÁ®ãÂíåÁÆóÊ≥ïÂÆûÁé∞„ÄÇ

üë∂: Êé®Ëçê‰∏Ä‰∫õÊù≠Â∑ûÁöÑÁâπËâ≤ÁæéÈ£üÂêß„ÄÇ
ü§ñÔ∏è: Êù≠Â∑ûÊúâÂæàÂ§öÁæéÂë≥ÁöÑÁâπËâ≤ÁæéÈ£üÔºåÊØîÂ¶ÇÈ∏°ËÇâ‰∏≤„ÄÅÈ≥óÈ±ºÂ§¥„ÄÅÊ∞¥ÁÖÆÈ±º„ÄÅË±ÜËÖêËÑëÁ≠â„ÄÇËøô‰∫õÁæéÈ£üÈÉΩÈùûÂ∏∏ÁæéÂë≥ÔºåÊúâÁùÄÁã¨ÁâπÁöÑÈ£éÂë≥ÂíåÂè£ÊÑüÔºåÁªùÂØπÊòØÂÄºÂæó‰∏ÄËØïÁöÑÁæéÈ£ü„ÄÇ

üë∂: ËØ∑‰∏∫ÊàëËÆ≤Ëß£‚ÄúÂ§ßËØ≠Ë®ÄÊ®°Âûã‚ÄùËøô‰∏™Ê¶ÇÂøµ„ÄÇ
ü§ñÔ∏è: Â§ßËØ≠Ë®ÄÊ®°ÂûãÊòØ‰∏ÄÁßç‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÔºåÂÆÉ‰ΩøÁî®Â§ßÈáèÁöÑÊñáÊú¨Êï∞ÊçÆÊù•ËÆ≠ÁªÉÊ®°ÂûãÔºåÁÑ∂ÂêéÂú®‰∏çÊñ≠ÁöÑËø≠‰ª£‰∏≠‰∏çÊñ≠‰ºòÂåñÊ®°Âûã„ÄÇÂÆÉÁöÑÁõÆÊ†áÊòØÊ†πÊçÆËæìÂÖ•ÁöÑÊï∞ÊçÆÊù•ÁîüÊàêÁ¨¶ÂêàÁâπÂÆöÈúÄÊ±ÇÁöÑÊñáÊú¨ÔºåËøô‰∫õÊñáÊú¨ÂèØ‰ª•ÊòØ‰ªª‰Ωï‰Ω†ÊÑüÂÖ¥Ë∂£ÁöÑ‰∏ªÈ¢ò„ÄÇ

üë∂: Introduce the history of the United States, please.
ü§ñÔ∏è: ÊÇ®ÊèêÂà∞ÁöÑ‚ÄúIntrook's the believeations of theument." Ëøô‰∏™ÂêçÂ≠óÊù•Ê∫ê‰∫é‰∏≠ÂõΩÂè§‰ª£ÁöÑ"groty of of the change."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊûÅÈÄü‰∏îÂàùÂÖ∑ÊïàÊûúÔºåÁîöËá≥‰ªçÁÑ∂ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•ÂéãÁº©Ëé∑ÂèñÊõ¥Â∞èÊõ¥‰ºòË¥®ÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ ZeroÊ®°ÂûãÊùÉÈáç‰øùÂ≠ò‰∏∫ &lt;code&gt;full_sft_512_zero.pth&lt;/code&gt;ÔºàËßÅ‰∏ãÊñáMiniMindÊ®°ÂûãÊñá‰ª∂ÈìæÊé•ÔºâÔºåÂ¶ÇÊúâÂÖ¥Ë∂£ÂèØ‰∏ãËΩΩÊ£ÄÈ™åÊ≠§Ê®°ÂûãÊïàÊûú„ÄÇ&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;‚Ö° ‰∏ªË¶ÅËÆ≠ÁªÉÊ≠•È™§&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá &lt;code&gt;cd ./trainer&lt;/code&gt; ÁõÆÂΩïÊâßË°å&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;1. È¢ÑËÆ≠ÁªÉ(Pretrain)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;LLMÈ¶ñÂÖàË¶ÅÂ≠¶‰π†ÁöÑÂπ∂ÈùûÁõ¥Êé•‰∏é‰∫∫‰∫§ÊµÅÔºåËÄåÊòØËÆ©ÁΩëÁªúÂèÇÊï∞‰∏≠ÂÖÖÊª°Áü•ËØÜÁöÑÂ¢®Ê∞¥Ôºå‚ÄúÂ¢®Ê∞¥‚Äù ÁêÜËÆ∫‰∏äÂñùÁöÑË∂äÈ•±Ë∂äÂ•ΩÔºå‰∫ßÁîüÂ§ßÈáèÁöÑÂØπ‰∏ñÁïåÁöÑÁü•ËØÜÁßØÁ¥Ø„ÄÇ È¢ÑËÆ≠ÁªÉÂ∞±ÊòØËÆ©ModelÂÖàÂüãÂ§¥Ëã¶Â≠¶Â§ßÈáèÂü∫Êú¨ÁöÑÁü•ËØÜÔºå‰æãÂ¶Ç‰ªéWikiÁôæÁßë„ÄÅÊñ∞Èóª„ÄÅ‰π¶Á±çÊï¥ÁêÜÂ§ßËßÑÊ®°ÁöÑÈ´òË¥®ÈáèËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ Ëøô‰∏™ËøáÁ®ãÊòØ‚ÄúÊó†ÁõëÁù£‚ÄùÁöÑÔºåÂç≥‰∫∫Á±ª‰∏çÈúÄË¶ÅÂú®ËøáÁ®ã‰∏≠ÂÅö‰ªª‰Ωï‚ÄúÊúâÁõëÁù£‚ÄùÁöÑÊ†°Ê≠£ÔºåËÄåÊòØÁî±Ê®°ÂûãËá™Â∑±‰ªéÂ§ßÈáèÊñáÊú¨‰∏≠ÊÄªÁªìËßÑÂæãÂ≠¶‰π†Áü•ËØÜÁÇπ„ÄÇ Ê®°ÂûãÊ≠§Èò∂ÊÆµÁõÆÁöÑÂè™Êúâ‰∏Ä‰∏™Ôºö&lt;strong&gt;Â≠¶‰ºöËØçËØ≠Êé•Èæô&lt;/strong&gt;„ÄÇ‰æãÂ¶ÇÊàë‰ª¨ËæìÂÖ•‚ÄúÁß¶ÂßãÁöá‚ÄùÂõõ‰∏™Â≠óÔºåÂÆÉÂèØ‰ª•Êé•Èæô‚ÄúÊòØ‰∏≠ÂõΩÁöÑÁ¨¨‰∏Ä‰ΩçÁöáÂ∏ù‚Äù„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_pretrain.py # 1Âç≥‰∏∫ÂçïÂç°ËÆ≠ÁªÉÔºåÂèØÊ†πÊçÆÁ°¨‰ª∂ÊÉÖÂÜµËá™Ë°åË∞ÉÊï¥ (ËÆæÁΩÆ&amp;gt;=2)
# or
python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;pretrain_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;2. ÊúâÁõëÁù£ÂæÆË∞É(Supervised Fine-Tuning)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;ÁªèËøáÈ¢ÑËÆ≠ÁªÉÔºåLLMÊ≠§Êó∂Â∑≤ÁªèÊéåÊè°‰∫ÜÂ§ßÈáèÁü•ËØÜÔºåÁÑ∂ËÄåÊ≠§Êó∂ÂÆÉÂè™‰ºöÊó†ËÑëÂú∞ËØçËØ≠Êé•ÈæôÔºåËøò‰∏ç‰ºö‰∏é‰∫∫ËÅäÂ§©„ÄÇ SFTÈò∂ÊÆµÂ∞±ÈúÄË¶ÅÊääÂçäÊàêÂìÅLLMÊñΩÂä†‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑËÅäÂ§©Ê®°ÊùøËøõË°åÂæÆË∞É„ÄÇ ‰æãÂ¶ÇÊ®°ÂûãÈÅáÂà∞ËøôÊ†∑ÁöÑÊ®°Êùø„ÄêÈóÆÈ¢ò-&amp;gt;ÂõûÁ≠îÔºåÈóÆÈ¢ò-&amp;gt;ÂõûÁ≠î„ÄëÂêé‰∏çÂÜçÊó†ËÑëÊé•ÈæôÔºåËÄåÊòØÊÑèËØÜÂà∞ËøôÊòØ‰∏ÄÊÆµÂÆåÊï¥ÁöÑÂØπËØùÁªìÊùü„ÄÇ Áß∞Ëøô‰∏™ËøáÁ®ã‰∏∫Êåá‰ª§ÂæÆË∞ÉÔºåÂ∞±Â¶ÇÂêåËÆ©Â∑≤ÁªèÂ≠¶ÂØå‰∫îËΩ¶ÁöÑ„ÄåÁâõÈ°ø„ÄçÂÖàÁîüÈÄÇÂ∫î21‰∏ñÁ∫™Êô∫ËÉΩÊâãÊú∫ÁöÑËÅäÂ§©‰π†ÊÉØÔºåÂ≠¶‰π†Â±èÂπïÂ∑¶‰æßÊòØÂØπÊñπÊ∂àÊÅØÔºåÂè≥‰æßÊòØÊú¨‰∫∫Ê∂àÊÅØËøô‰∏™ËßÑÂæã„ÄÇ Âú®ËÆ≠ÁªÉÊó∂ÔºåMiniMindÁöÑÊåá‰ª§ÂíåÂõûÁ≠îÈïøÂ∫¶Ë¢´Êà™Êñ≠Âú®512ÔºåÊòØ‰∏∫‰∫ÜËäÇÁúÅÊòæÂ≠òÁ©∫Èó¥„ÄÇÂ∞±ÂÉèÊàë‰ª¨Â≠¶‰π†Êó∂Ôºå‰ºöÂÖà‰ªéÁü≠ÁöÑÊñáÁ´†ÂºÄÂßãÔºåÂΩìÂ≠¶‰ºöÂÜô‰Ωú200Â≠ó‰ΩúÊñáÂêéÔºå800Â≠óÊñáÁ´†‰πüÂèØ‰ª•ÊâãÂà∞ÊìíÊù•„ÄÇ Âú®ÈúÄË¶ÅÈïøÂ∫¶ÊãìÂ±ïÊó∂ÔºåÂè™ÈúÄË¶ÅÂáÜÂ§áÂ∞ëÈáèÁöÑ2k/4k/8kÈïøÂ∫¶ÂØπËØùÊï∞ÊçÆËøõË°åËøõ‰∏ÄÊ≠•ÂæÆË∞ÉÂç≥ÂèØÔºàÊ≠§Êó∂ÊúÄÂ•ΩÈÖçÂêàRoPE-NTKÁöÑÂü∫ÂáÜÂ∑ÆÂÄºÔºâ„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Âú®Êé®ÁêÜÊó∂ÈÄöËøáË∞ÉÊï¥RoPEÁ∫øÊÄßÂ∑ÆÂÄºÔºåÂÆûÁé∞ÂÖçËÆ≠ÁªÉÈïøÂ∫¶Â§ñÊé®Âà∞2048Âèä‰ª•‰∏äÂ∞Ü‰ºöÂæàÊñπ‰æø„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;full_sft_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚Ö¢ ÂÖ∂ÂÆÉËÆ≠ÁªÉÊ≠•È™§&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá &lt;code&gt;cd ./trainer&lt;/code&gt; ÁõÆÂΩïÊâßË°å&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;3. ‰∫∫Á±ªÂèçÈ¶àÂº∫ÂåñÂ≠¶‰π†(Reinforcement Learning from Human Feedback, RLHF)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Âú®ÂâçÈù¢ÁöÑËÆ≠ÁªÉÊ≠•È™§‰∏≠ÔºåÊ®°ÂûãÂ∑≤ÁªèÂÖ∑Â§á‰∫ÜÂü∫Êú¨ÁöÑÂØπËØùËÉΩÂäõÔºå‰ΩÜÊòØËøôÊ†∑ÁöÑËÉΩÂäõÂÆåÂÖ®Âü∫‰∫éÂçïËØçÊé•ÈæôÔºåÁº∫Â∞ëÊ≠£ÂèçÊ†∑‰æãÁöÑÊøÄÂä±„ÄÇ Ê®°ÂûãÊ≠§Êó∂Â∞öÊú™Áü•‰ªÄ‰πàÂõûÁ≠îÊòØÂ•ΩÁöÑÔºå‰ªÄ‰πàÊòØÂ∑ÆÁöÑ„ÄÇÊàë‰ª¨Â∏åÊúõÂÆÉËÉΩÂ§üÊõ¥Á¨¶Âêà‰∫∫ÁöÑÂÅèÂ•ΩÔºåÈôç‰ΩéËÆ©‰∫∫Á±ª‰∏çÊª°ÊÑèÁ≠îÊ°àÁöÑ‰∫ßÁîüÊ¶ÇÁéá„ÄÇ Ëøô‰∏™ËøáÁ®ãÂ∞±ÂÉèÊòØËÆ©Ê®°ÂûãÂèÇÂä†Êñ∞ÁöÑÂüπËÆ≠Ôºå‰ªé‰ºòÁßÄÂëòÂ∑•ÁöÑ‰Ωú‰∏∫‰æãÂ≠êÔºåÊ∂àÊûÅÂëòÂ∑•‰Ωú‰∏∫Âèç‰æãÔºåÂ≠¶‰π†Â¶Ç‰ΩïÊõ¥Â•ΩÂú∞ÂõûÂ§ç„ÄÇ Ê≠§Â§Ñ‰ΩøÁî®ÁöÑÊòØRLHFÁ≥ªÂàó‰πã-Áõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñ(Direct Preference Optimization, DPO)„ÄÇ ‰∏éPPO(Proximal Policy Optimization)ËøôÁßçÈúÄË¶ÅÂ•ñÂä±Ê®°Âûã„ÄÅ‰ª∑ÂÄºÊ®°ÂûãÁöÑRLÁÆóÊ≥ï‰∏çÂêåÔºõ DPOÈÄöËøáÊé®ÂØºPPOÂ•ñÂä±Ê®°ÂûãÁöÑÊòæÂºèËß£ÔºåÊääÂú®Á∫øÂ•ñÂä±Ê®°ÂûãÊç¢ÊàêÁ¶ªÁ∫øÊï∞ÊçÆÔºåRefÊ®°ÂûãËæìÂá∫ÂèØ‰ª•ÊèêÂâç‰øùÂ≠ò„ÄÇ DPOÊÄßËÉΩÂá†‰πé‰∏çÂèòÔºåÂè™Áî®Ë∑ë actor_model Âíå ref_model ‰∏§‰∏™Ê®°ÂûãÔºåÂ§ßÂ§ßËäÇÁúÅÊòæÂ≠òÂºÄÈîÄÂíåÂ¢ûÂä†ËÆ≠ÁªÉÁ®≥ÂÆöÊÄß„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®ÔºöRLHFËÆ≠ÁªÉÊ≠•È™§&lt;strong&gt;Âπ∂ÈùûÂøÖÈ°ª&lt;/strong&gt;ÔºåÊ≠§Ê≠•È™§Èöæ‰ª•ÊèêÂçáÊ®°Âûã‚ÄúÊô∫Âäõ‚ÄùËÄåÈÄöÂ∏∏‰ªÖÁî®‰∫éÊèêÂçáÊ®°ÂûãÁöÑ‚ÄúÁ§ºË≤å‚ÄùÔºåÊúâÂà©ÔºàÁ¨¶ÂêàÂÅèÂ•Ω„ÄÅÂáèÂ∞ëÊúâÂÆ≥ÂÜÖÂÆπÔºâ‰πüÊúâÂºäÔºàÊ†∑Êú¨Êî∂ÈõÜÊòÇË¥µ„ÄÅÂèçÈ¶àÂÅèÂ∑Æ„ÄÅÂ§öÊ†∑ÊÄßÊçüÂ§±Ôºâ„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_dpo.py
# or
python train_dpo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;rlhf_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;4. Áü•ËØÜËí∏È¶è(Knowledge Distillation, KD)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Âú®ÂâçÈù¢ÁöÑÊâÄÊúâËÆ≠ÁªÉÊ≠•È™§‰∏≠ÔºåÊ®°ÂûãÂ∑≤ÁªèÂÆåÂÖ®ÂÖ∑Â§á‰∫ÜÂü∫Êú¨ËÉΩÂäõÔºåÈÄöÂ∏∏ÂèØ‰ª•Â≠¶ÊàêÂá∫Â∏à‰∫Ü„ÄÇ ËÄåÁü•ËØÜËí∏È¶èÂèØ‰ª•Ëøõ‰∏ÄÊ≠•‰ºòÂåñÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊïàÁéáÔºåÊâÄË∞ìÁü•ËØÜËí∏È¶èÔºåÂç≥Â≠¶ÁîüÊ®°ÂûãÈù¢ÂêëÊïôÂ∏àÊ®°ÂûãÂ≠¶‰π†„ÄÇ ÊïôÂ∏àÊ®°ÂûãÈÄöÂ∏∏ÊòØÁªèËøáÂÖÖÂàÜËÆ≠ÁªÉÁöÑÂ§ßÊ®°ÂûãÔºåÂÖ∑ÊúâËæÉÈ´òÁöÑÂáÜÁ°ÆÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ Â≠¶ÁîüÊ®°ÂûãÊòØ‰∏Ä‰∏™ËæÉÂ∞èÁöÑÊ®°ÂûãÔºåÁõÆÊ†áÊòØÂ≠¶‰π†ÊïôÂ∏àÊ®°ÂûãÁöÑË°å‰∏∫ÔºåËÄå‰∏çÊòØÁõ¥Êé•‰ªéÂéüÂßãÊï∞ÊçÆ‰∏≠Â≠¶‰π†„ÄÇ Âú®SFTÂ≠¶‰π†‰∏≠ÔºåÊ®°ÂûãÁöÑÁõÆÊ†áÊòØÊãüÂêàËØçTokenÂàÜÁ±ªÁ°¨Ê†áÁ≠æÔºàhard labelsÔºâÔºåÂç≥ÁúüÂÆûÁöÑÁ±ªÂà´Ê†áÁ≠æÔºàÂ¶Ç 0 Êàñ 6400Ôºâ„ÄÇ Âú®Áü•ËØÜËí∏È¶è‰∏≠ÔºåÊïôÂ∏àÊ®°ÂûãÁöÑsoftmaxÊ¶ÇÁéáÂàÜÂ∏ÉË¢´Áî®‰ΩúËΩØÊ†áÁ≠æÔºàsoft labelsÔºâ„ÄÇÂ∞èÊ®°Âûã‰ªÖÂ≠¶‰π†ËΩØÊ†áÁ≠æÔºåÂπ∂‰ΩøÁî®KL-LossÊù•‰ºòÂåñÊ®°ÂûãÁöÑÂèÇÊï∞„ÄÇ ÈÄö‰øóÂú∞ËØ¥ÔºåSFTÁõ¥Êé•Â≠¶‰π†ËÄÅÂ∏àÁªôÁöÑËß£È¢òÁ≠îÊ°à„ÄÇËÄåKDËøáÁ®ãÁõ∏ÂΩì‰∫é‚ÄúÊâìÂºÄ‚ÄùËÄÅÂ∏àËÅ™ÊòéÁöÑÂ§ßËÑëÔºåÂ∞ΩÂèØËÉΩÂú∞Ê®°‰ªøËÄÅÂ∏à‚ÄúÂ§ßËÑë‚ÄùÊÄùËÄÉÈóÆÈ¢òÁöÑÁ•ûÁªèÂÖÉÁä∂ÊÄÅ„ÄÇ ‰æãÂ¶ÇÔºåÂΩìËÄÅÂ∏àÊ®°ÂûãËÆ°ÁÆó&lt;code&gt;1+1=2&lt;/code&gt;Ëøô‰∏™ÈóÆÈ¢òÁöÑÊó∂ÂÄôÔºåÊúÄÂêé‰∏ÄÂ±ÇÁ•ûÁªèÂÖÉaÁä∂ÊÄÅ‰∏∫0ÔºåÁ•ûÁªèÂÖÉbÁä∂ÊÄÅ‰∏∫100ÔºåÁ•ûÁªèÂÖÉcÁä∂ÊÄÅ‰∏∫-99... Â≠¶ÁîüÊ®°ÂûãÈÄöËøáÂ§ßÈáèÊï∞ÊçÆÔºåÂ≠¶‰π†ÊïôÂ∏àÊ®°ÂûãÂ§ßËÑëÂÜÖÈÉ®ÁöÑËøêËΩ¨ËßÑÂæã„ÄÇËøô‰∏™ËøáÁ®ãÂç≥Áß∞‰πã‰∏∫ÔºöÁü•ËØÜËí∏È¶è„ÄÇ Áü•ËØÜËí∏È¶èÁöÑÁõÆÁöÑÂè™Êúâ‰∏Ä‰∏™ÔºöËÆ©Â∞èÊ®°Âûã‰ΩìÁßØÊõ¥Â∞èÁöÑÂêåÊó∂ÊïàÊûúÊõ¥Â•Ω„ÄÇ ÁÑ∂ËÄåÈöèÁùÄLLMËØûÁîüÂíåÂèëÂ±ïÔºåÊ®°ÂûãËí∏È¶è‰∏ÄËØçË¢´ÂπøÊ≥õÊª•Áî®Ôºå‰ªéËÄå‰∫ßÁîü‰∫Ü‚ÄúÁôΩÁõí/ÈªëÁõí‚ÄùÁü•ËØÜËí∏È¶è‰∏§‰∏™Ê¥æÂà´„ÄÇ GPT-4ËøôÁßçÈó≠Ê∫êÊ®°ÂûãÔºåÁî±‰∫éÊó†Ê≥ïËé∑ÂèñÂÖ∂ÂÜÖÈÉ®ÁªìÊûÑÔºåÂõ†Ê≠§Âè™ËÉΩÈù¢ÂêëÂÆÉÊâÄËæìÂá∫ÁöÑÊï∞ÊçÆÂ≠¶‰π†ÔºåËøô‰∏™ËøáÁ®ãÁß∞‰πã‰∏∫ÈªëÁõíËí∏È¶èÔºå‰πüÊòØÂ§ßÊ®°ÂûãÊó∂‰ª£ÊúÄÊôÆÈÅçÁöÑÂÅöÊ≥ï„ÄÇ ÈªëÁõíËí∏È¶è‰∏éSFTËøáÁ®ãÂÆåÂÖ®‰∏ÄËá¥ÔºåÂè™‰∏çËøáÊï∞ÊçÆÊòØ‰ªéÂ§ßÊ®°ÂûãÁöÑËæìÂá∫Êî∂ÈõÜÔºåÂõ†Ê≠§Âè™ÈúÄË¶ÅÂáÜÂ§áÊï∞ÊçÆÂπ∂‰∏îËøõ‰∏ÄÊ≠•FTÂç≥ÂèØ„ÄÇ Ê≥®ÊÑèÊõ¥ÊîπË¢´Âä†ËΩΩÁöÑÂü∫Á°ÄÊ®°Âûã‰∏∫&lt;code&gt;full_sft_*.pth&lt;/code&gt;ÔºåÂç≥Âü∫‰∫éÂæÆË∞ÉÊ®°ÂûãÂÅöËøõ‰∏ÄÊ≠•ÁöÑËí∏È¶èÂ≠¶‰π†„ÄÇ &lt;code&gt;./dataset/sft_1024.jsonl&lt;/code&gt;‰∏é&lt;code&gt;./dataset/sft_2048.jsonl&lt;/code&gt; ÂùáÊî∂ÈõÜËá™qwen2.5-7/72B-InstructÂ§ßÊ®°ÂûãÔºåÂèØÁõ¥Êé•Áî®‰∫éSFT‰ª•Ëé∑ÂèñQwenÁöÑÈÉ®ÂàÜË°å‰∏∫„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ê≥®ÊÑèÈúÄË¶ÅÊõ¥Êîπtrain_full_sft.pyÊï∞ÊçÆÈõÜË∑ØÂæÑÔºå‰ª•Âèämax_seq_len  
torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;ÂêåÊ†∑‰øùÂ≠ò‰∏∫: &lt;code&gt;full_sft_*.pth&lt;/code&gt;Ôºà*‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Ê≠§Â§ÑÂ∫îÂΩìÁùÄÈáç‰ªãÁªçMiniMindÂÆûÁé∞ÁöÑÁôΩÁõíËí∏È¶è‰ª£Á†Å&lt;code&gt;train_distillation.py&lt;/code&gt;ÔºåÁî±‰∫éMiniMindÂêåÁ≥ªÂàóÊú¨Ë∫´Âπ∂‰∏çÂ≠òÂú®Âº∫Â§ßÁöÑÊïôÂ∏àÊ®°ÂûãÔºåÂõ†Ê≠§ÁôΩÁõíËí∏È¶è‰ª£Á†Å‰ªÖ‰Ωú‰∏∫Â≠¶‰π†ÂèÇËÄÉ„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_distillation.py
# or
python train_distillation.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;5. LoRA (Low-Rank Adaptation)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;LoRAÊòØ‰∏ÄÁßçÈ´òÊïàÁöÑÂèÇÊï∞È´òÊïàÂæÆË∞ÉÔºàParameter-Efficient Fine-Tuning, PEFTÔºâÊñπÊ≥ïÔºåÊó®Âú®ÈÄöËøá‰ΩéÁß©ÂàÜËß£ÁöÑÊñπÂºèÂØπÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÂæÆË∞É„ÄÇ Áõ∏ÊØî‰∫éÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÔºàFull Fine-TuningÔºâÔºåLoRA Âè™ÈúÄË¶ÅÊõ¥Êñ∞Â∞ëÈáèÁöÑÂèÇÊï∞„ÄÇ LoRA ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÔºöÂú®Ê®°ÂûãÁöÑÊùÉÈáçÁü©Èòµ‰∏≠ÂºïÂÖ•‰ΩéÁß©ÂàÜËß£Ôºå‰ªÖÂØπ‰ΩéÁß©ÈÉ®ÂàÜËøõË°åÊõ¥Êñ∞ÔºåËÄå‰øùÊåÅÂéüÂßãÈ¢ÑËÆ≠ÁªÉÊùÉÈáç‰∏çÂèò„ÄÇ ‰ª£Á†ÅÂèØËßÅ&lt;code&gt;./model/model_lora.py&lt;/code&gt;Âíå&lt;code&gt;train_lora.py&lt;/code&gt;ÔºåÂÆåÂÖ®‰ªé0ÂÆûÁé∞LoRAÊµÅÁ®ãÔºå‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∫ìÁöÑÂ∞ÅË£Ö„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_lora.py
# or
python train_lora.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;lora_xxx_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÈùûÂ∏∏Â§öÁöÑ‰∫∫Âõ∞ÊÉëÔºåÂ¶Ç‰Ωï‰ΩøÊ®°ÂûãÂ≠¶‰ºöËá™Â∑±ÁßÅÊúâÈ¢ÜÂüüÁöÑÁü•ËØÜÔºüÂ¶Ç‰ΩïÂáÜÂ§áÊï∞ÊçÆÈõÜÔºüÂ¶Ç‰ΩïËøÅÁßªÈÄöÁî®È¢ÜÂüüÊ®°ÂûãÊâìÈÄ†ÂûÇÂüüÊ®°ÂûãÔºü ËøôÈáå‰∏æÂá†‰∏™‰æãÂ≠êÔºåÂØπ‰∫éÈÄöÁî®Ê®°ÂûãÔºåÂåªÂ≠¶È¢ÜÂüüÁü•ËØÜÊ¨†Áº∫ÔºåÂèØ‰ª•Â∞ùËØïÂú®ÂéüÊúâÊ®°ÂûãÂü∫Á°Ä‰∏äÂä†ÂÖ•È¢ÜÂüüÁü•ËØÜÔºå‰ª•Ëé∑ÂæóÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ ÂêåÊó∂ÔºåÊàë‰ª¨ÈÄöÂ∏∏‰∏çÂ∏åÊúõÂ≠¶‰ºöÈ¢ÜÂüüÁü•ËØÜÁöÑÂêåÊó∂ÊçüÂ§±ÂéüÊúâÂü∫Á°ÄÊ®°ÂûãÁöÑÂÖ∂ÂÆÉËÉΩÂäõÔºåÊ≠§Êó∂LoRAÂèØ‰ª•ÂæàÂ•ΩÁöÑÊîπÂñÑËøô‰∏™ÈóÆÈ¢ò„ÄÇ Âè™ÈúÄË¶ÅÂáÜÂ§áÂ¶Ç‰∏ãÊ†ºÂºèÁöÑÂØπËØùÊï∞ÊçÆÈõÜÊîæÁΩÆÂà∞&lt;code&gt;./dataset/lora_xxx.jsonl&lt;/code&gt;ÔºåÂêØÂä® &lt;code&gt;python train_lora.py&lt;/code&gt; ËÆ≠ÁªÉÂç≥ÂèØÂæóÂà∞&lt;code&gt;./out/lora/lora_xxx.pth&lt;/code&gt;Êñ∞Ê®°ÂûãÊùÉÈáç„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÂåªÁñóÂú∫ÊôØ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "ËØ∑ÈóÆÈ¢àÊ§éÁóÖÁöÑ‰∫∫ÊûïÂ§¥Â§öÈ´òÊâçÊúÄÂ•ΩÔºü"}, {"role": "assistant", "content": "È¢àÊ§éÁóÖÊÇ£ËÄÖÈÄâÊã©ÊûïÂ§¥ÁöÑÈ´òÂ∫¶Â∫îËØ•Ê†πÊçÆ..."}]}
 {"conversations": [{"role": "user", "content": "ËØ∑ÈóÆxxx"}, {"role": "assistant", "content": "xxx..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Ëá™ÊàëËÆ§Áü•Âú∫ÊôØ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠óÔºü"}, {"role": "assistant", "content": "ÊàëÂè´minimind..."}]}
 {"conversations": [{"role": "user", "content": "‰Ω†ÊòØË∞Å"}, {"role": "assistant", "content": "ÊàëÊòØ..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ê≠§Êó∂„ÄêÂü∫Á°ÄÊ®°Âûã+LoRAÊ®°Âûã„ÄëÂç≥ÂèØËé∑ÂæóÂåªÁñóÂú∫ÊôØÊ®°ÂûãÂ¢ûÂº∫ÁöÑËÉΩÂäõÔºåÁõ∏ÂΩì‰∫é‰∏∫Âü∫Á°ÄÊ®°ÂûãÂ¢ûÂä†‰∫ÜLoRAÂ§ñÊåÇÔºåËøô‰∏™ËøáÁ®ãÂπ∂‰∏çÊçüÂ§±Âü∫Á°ÄÊ®°ÂûãÁöÑÊú¨Ë∫´ËÉΩÂäõ„ÄÇ Êàë‰ª¨ÂèØ‰ª•ÈÄöËøá&lt;code&gt;eval_model.py&lt;/code&gt;ËøõË°åÊ®°ÂûãËØÑ‰º∞ÊµãËØï„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ê≥®ÊÑèÔºömodel_modeÂç≥ÈÄâÊã©Âü∫Á°ÄÊ®°ÂûãÁöÑÁ±ªÂûãÔºåËøôÂíåtrain_loraÊòØÂü∫‰∫éÂì™‰∏™Ê®°ÂûãËÆ≠ÁªÉÁöÑÁõ∏ÂÖ≥ÔºåÁ°Æ‰øùÁªü‰∏ÄÂç≥ÂèØ„ÄÇ
python eval_model.py --lora_name 'lora_medical' --model_mode 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Â∞èÊµãËØï&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;üë∂: ÊàëÊúÄËøëÁªèÂ∏∏ÊÑüÂà∞Â§¥ÊôïÔºåÂèØËÉΩÊòØ‰ªÄ‰πàÂéüÂõ†Ôºü
ü§ñÔ∏è: Â§¥ÊôïÂèØËÉΩÊòØÁî±‰∫éÂ§öÁßçÂéüÂõ†ÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÔºöÂøÉËÑèÁñæÁóÖ„ÄÅÁúºÁùõÊçü‰º§„ÄÅËøáÊïèÂèçÂ∫î„ÄÅÁöÆËÇ§ÈóÆÈ¢ò„ÄÅËøáÊïèÂèçÂ∫î„ÄÅÂéãÂäõ„ÄÅÁÑ¶Ëôë„ÄÅÁñ≤Âä≥„ÄÅËçØÁâ©ÂâØ‰ΩúÁî®„ÄÅÊÄßÂäüËÉΩÈöúÁ¢çÊàñËÄÖÂÖ∂‰ªñ...

---

üë∂: ‰Ω†ÂíåopenaiÊòØ‰ªÄ‰πàÂÖ≥Á≥ªÔºü
ü§ñÔ∏è: ÊàëÊòØ MiniMindÔºå‰∏Ä‰∏™Áî± Jingyao Gong ÂºÄÂèëÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã„ÄÇÊàëÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåÁÆóÊ≥ïËÆ≠ÁªÉÊù•‰∏éÁî®Êà∑ËøõË°å‰∫§‰∫í„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;PSÔºöÂè™Ë¶ÅÊúâÊâÄÈúÄË¶ÅÁöÑÊï∞ÊçÆÈõÜÔºå‰πüÂèØ‰ª•full_sftÂÖ®ÂèÇÂæÆË∞ÉÔºàÈúÄË¶ÅËøõË°åÈÄöÁî®Áü•ËØÜÁöÑÊ∑∑ÂêàÈÖçÊØîÔºåÂê¶ÂàôËøáÊãüÂêàÈ¢ÜÂüüÊï∞ÊçÆ‰ºöËÆ©Ê®°ÂûãÂèòÂÇªÔºåÊçüÂ§±ÈÄöÁî®ÊÄßÔºâ&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;6. ËÆ≠ÁªÉÊé®ÁêÜÊ®°Âûã (Reasoning Model)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;DeepSeek-R1ÂÆûÂú®Â§™ÁÅ´‰∫ÜÔºåÂá†‰πéÈáçÊñ∞ÊåáÊòé‰∫ÜÊú™Êù•LLMÁöÑÊñ∞ËåÉÂºè„ÄÇ ËÆ∫ÊñáÊåáÂá∫&lt;code&gt;&amp;gt;3B&lt;/code&gt;ÁöÑÊ®°ÂûãÁªèÂéÜÂ§öÊ¨°ÂèçÂ§çÁöÑÂÜ∑ÂêØÂä®ÂíåRLÂ•ñÂä±ËÆ≠ÁªÉÊâçËÉΩËé∑ÂæóËÇâÁúºÂèØËßÅÁöÑÊé®ÁêÜËÉΩÂäõÊèêÂçá„ÄÇ ÊúÄÂø´ÊúÄÁ®≥Â¶•ÊúÄÁªèÊµéÁöÑÂÅöÊ≥ïÔºå‰ª•ÂèäÊúÄËøëÁàÜÂèëÁöÑÂêÑÁßçÂêÑÊ†∑ÊâÄË∞ìÁöÑÊé®ÁêÜÊ®°ÂûãÂá†‰πéÈÉΩÊòØÁõ¥Êé•Èù¢ÂêëÊï∞ÊçÆËøõË°åËí∏È¶èËÆ≠ÁªÉÔºå ‰ΩÜÁî±‰∫éÁº∫‰πèÊäÄÊúØÂê´ÈáèÔºåËí∏È¶èÊ¥æË¢´RLÊ¥æÁûß‰∏çËµ∑ÔºàhhhhÔºâ„ÄÇ Êú¨‰∫∫ËøÖÈÄüÂ∑≤ÁªèÂú®QwenÁ≥ªÂàó1.5BÂ∞èÊ®°Âûã‰∏äËøõË°å‰∫ÜÂ∞ùËØïÔºåÂæàÂø´Â§çÁé∞‰∫ÜZeroËøáÁ®ãÁöÑÊï∞Â≠¶Êé®ÁêÜËÉΩÂäõ„ÄÇ ÁÑ∂ËÄå‰∏Ä‰∏™ÈÅóÊÜæÁöÑÂÖ±ËØÜÊòØÔºöÂèÇÊï∞Â§™Â∞èÁöÑÊ®°ÂûãÁõ¥Êé•ÈÄöËøáÂÜ∑ÂêØÂä®SFT+GRPOÂá†‰πé‰∏çÂèØËÉΩËé∑Âæó‰ªª‰ΩïÊé®ÁêÜÊïàÊûú„ÄÇ MiniMind2Á¨¨‰∏ÄÊó∂Èó¥Âè™ËÉΩÂùöÂÆö‰∏çÁßªÁöÑÈÄâÊã©ÂÅöËí∏È¶èÊ¥æÔºåÊó•ÂêéÂü∫‰∫é0.1BÊ®°ÂûãÁöÑRLÂ¶ÇÊûúÂêåÊ†∑ÂèñÂæóÂ∞èÂ∞èËøõÂ±ï‰ºöÊõ¥Êñ∞Ê≠§ÈÉ®ÂàÜÁöÑËÆ≠ÁªÉÊñπÊ°à„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÂÅöËí∏È¶èÈúÄË¶ÅÂáÜÂ§áÁöÑ‰æùÁÑ∂ÊòØÂíåSFTÈò∂ÊÆµÂêåÊ†∑Ê†ºÂºèÁöÑÊï∞ÊçÆÂç≥ÂèØÔºåÊï∞ÊçÆÈõÜÊù•Ê∫êÂ∑≤Â¶Ç‰∏äÊñá‰ªãÁªç„ÄÇÊï∞ÊçÆÊ†ºÂºè‰æãÂ¶ÇÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "conversations": [
    {
      "role": "user",
      "content": "‰Ω†Â•ΩÔºåÊàëÊòØÂ∞èËä≥ÔºåÂæàÈ´òÂÖ¥ËÆ§ËØÜ‰Ω†„ÄÇ"
    },
    {
      "role": "assistant",
      "content": "&amp;lt;think&amp;gt;\n‰Ω†Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÁã¨Á´ãÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1-Lite-PreviewÔºåÂæàÈ´òÂÖ¥‰∏∫ÊÇ®Êèê‰æõÊúçÂä°ÔºÅ\n&amp;lt;/think&amp;gt;\n&amp;lt;answer&amp;gt;\n‰Ω†Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÁã¨Á´ãÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1-Lite-PreviewÔºåÂæàÈ´òÂÖ¥‰∏∫ÊÇ®Êèê‰æõÊúçÂä°ÔºÅ\n&amp;lt;/answer&amp;gt;"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êé®ÁêÜÊ®°ÂûãR1ÁöÑÂõûÂ§çÊ®°ÊùøÊòØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;lt;think&amp;gt;\nÊÄùËÄÉËøáÁ®ã\n&amp;lt;/think&amp;gt;\n
&amp;lt;answer&amp;gt;\nÊúÄÁªàÂõûÁ≠î\n&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ËøôÂú®GRPO‰∏≠ÈÄöËøáËÆæÁΩÆËßÑÂàôÂ•ñÂä±ÂáΩÊï∞Á∫¶ÊùüÊ®°ÂûãÁ¨¶ÂêàÊÄùËÄÉÊ†áÁ≠æÂíåÂõûÂ§çÊ†áÁ≠æÔºàÂú®ÂÜ∑ÂêØÂä®Èù†ÂâçÁöÑÈò∂ÊÆµÂ•ñÂä±ÂÄºËÆæÁΩÆÂ∫îËØ•ÊèêÈ´ò‰∏Ä‰∫õÔºâ&lt;/p&gt; 
&lt;p&gt;Âè¶‰∏Ä‰∏™ÈóÆÈ¢òÊòØËí∏È¶èËøáÁ®ãËôΩÁÑ∂ÂíåSFT‰∏ÄÊ†∑Ôºå‰ΩÜÂÆûÈ™åÁªìÊûúÊòØÊ®°ÂûãÈöæ‰ª•ÊØèÊ¨°ÈÉΩÁ¨¶ÂêàÊ®°ÊùøËßÑËåÉÁöÑÂõûÂ§çÔºåÂç≥ËÑ±Á¶ªÊÄùËÄÉÂíåÂõûÂ§çÊ†áÁ≠æÁ∫¶Êùü„ÄÇ ËøôÈáåÁöÑÂ∞èÊäÄÂ∑ßÊòØÂ¢ûÂä†Ê†áËÆ∞‰ΩçÁΩÆtokenÁöÑÊçüÂ§±ÊÉ©ÁΩöÔºåËØ¶ËßÅ&lt;code&gt;train_distill_reason.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;# Âú® sp_ids ÂØπÂ∫îÁöÑ‰ΩçÁΩÆÂ¢ûÂä†È¢ùÂ§ñÁöÑÊÉ©ÁΩö
...
loss_mask[sp_ids] = 10 # ÊÉ©ÁΩöÁ≥ªÊï∞
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Âè¶Âè¶‰∏Ä‰∏™tipsÊòØÁî±‰∫éÊé®ÁêÜÊï∞ÊçÆÁî±‰∫éÂè™Á≠õÈÄâ‰∫Ü&lt;code&gt;&amp;lt;1024&lt;/code&gt;ÈïøÂ∫¶ÁöÑÊï∞ÊçÆÔºåÂÖ∂‰∏≠Â§öËΩÆÂØπËØùÂíåËã±ÊñáÊï∞ÊçÆÂÅèÂ∞ëÔºå Âõ†Ê≠§&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;ËøõË°å‰∫ÜÂ§ßÁ∫¶10kÊù°Â§öËΩÆÂØπËØù+Ëã±ÊñáÊï∞ÊçÆÁöÑÊ∑∑ÂêàÔºåÈò≤Ê≠¢Ê®°ÂûãÈÅóÂøò‰∏•Èáç„ÄÇ&lt;/p&gt; 
&lt;p&gt;ËÑöÊú¨ÈªòËÆ§Âü∫‰∫érlhfÂêéÁöÑÂü∫Ê®°ÂûãÂÅöÊé®ÁêÜËÉΩÂäõÁöÑËí∏È¶èÂæÆË∞ÉÔºå‰∏ãÈù¢Áõ¥Êé•ÂêØÂä®ËÆ≠ÁªÉÂç≥ÂèØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_distill_reason.py
# or
python train_distill_reason.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;reason_*.pth&lt;/code&gt;Ôºà*‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÊµãËØï‰∏Ä‰∏ãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;üë∂: ËØ∑‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇ
ü§ñÔ∏è: &amp;lt;think&amp;gt;
ÂóØÔºåÁî®Êà∑ËÆ©Êàë‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇÊàëÁé∞Âú®ÈúÄË¶ÅËß£Èáä‰∏Ä‰∏ãËá™Â∑±„ÄÇÈ¶ñÂÖàÔºåÊàëÂ∫îËØ•ÊòéÁ°ÆÁî®Êà∑ÊòØË∞ÅÔºåÊòØÂ≠¶Áîü„ÄÅËÅåÂú∫‰∫∫Â£´ËøòÊòØÊôÆÈÄö‰∫∫„ÄÇÁî®Êà∑ÂèØËÉΩÊòØ‰∏Ä‰∏™Â≠¶ÁîüÊàñËÄÖËÅåÂú∫‰∫∫Â£´ÔºåÊâÄ‰ª•‰ø°ÊÅØ‰º†ÈÄíÂ∫îËØ•ÊòØÂ∏ÆÂä©Â≠¶ÁîüÂíåËÅåÂú∫‰∫∫Â£´ÁöÑ‰ø°ÊÅØ„ÄÇ
ÁÑ∂ÂêéÔºåÊàëÈúÄË¶ÅÂõûÂ∫îÁî®Êà∑ÔºåËøôÂèØËÉΩÂåÖÊã¨‰ªãÁªçËá™Â∑±ÁöÑ‰ΩçÁΩÆ„ÄÅÂÖ¥Ë∂£Áà±Â•Ω„ÄÅËÅå‰∏öÁªèÂéÜÁ≠â‰ø°ÊÅØ„ÄÇÁî®Êà∑ËøòÂèØËÉΩÊÉ≥‰∫ÜËß£Ëá™Â∑±Âú®Âì™ÈáåÔºåÊØîÂ¶ÇËÅå‰∏öÂèëÂ±ï„ÄÅÂ∑•‰ΩúÁªèÈ™åÁ≠â„ÄÇ
ÊàëÂ∫îËØ•Ê≥®ÊÑèÁî®ËØçË¶ÅÊ≠£ÂºèÔºå‰∏çË¶ÅÂ§™Ê≠£ÂºèÔºåÂêåÊó∂Ë¶Å‰øùÊåÅÁÆÄÊ¥ÅÊòé‰∫Ü„ÄÇËøôÊ†∑Áî®Êà∑ÂÆπÊòìÁêÜËß£Ôºå‰πüÊñπ‰æø‰ªñ‰ª¨Êü•ÈòÖÁõ∏ÂÖ≥ËµÑÊñô„ÄÇ
ÊúÄÂêéÔºåÊàëÂ∫îËØ•ÊÄªÁªì‰∏Ä‰∏ãÔºåËÆ©Áî®Êà∑Áü•ÈÅìÊàëÊòØÂ¶Ç‰ΩïÂ∏ÆÂä©‰ªñ‰ª¨ÂÆåÊàê‰ªñ‰ª¨ÁöÑ‰ªªÂä°ÁöÑÔºåËøôÊ†∑‰ªñ‰ª¨ÊúâÊõ¥Â§öÂÖ≥‰∫éÊàëÁöÑ‰ø°ÊÅØ„ÄÇ
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
ÊàëÊòØ**‚Äú‰Ω†ÁöÑÂêçÂ≠ó‚ÄùÔºå‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠óÔºü
&amp;lt;/answer&amp;gt;

üë∂: ‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºü
ü§ñÔ∏è: &amp;lt;think&amp;gt;
ÊÇ®Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1„ÄÇÂ¶ÇÊÇ®Êúâ‰ªª‰Ωï‰ªª‰ΩïÈóÆÈ¢òÔºåÊàë‰ºöÂ∞ΩÊàëÊâÄËÉΩ‰∏∫ÊÇ®Êèê‰æõÂ∏ÆÂä©„ÄÇ
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
ÊÇ®Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1„ÄÇÂ¶ÇÊÇ®Êúâ‰ªª‰Ωï‰ªª‰ΩïÈóÆÈ¢òÔºåÊàë‰ºöÂ∞ΩÊàëÊâÄËÉΩ‰∏∫ÊÇ®Êèê‰æõÂ∏ÆÂä©„ÄÇ
&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;h2&gt;‚Ö£ Ê®°ÂûãÂèÇÊï∞ËÆæÂÆö&lt;/h2&gt; 
&lt;p&gt;üìãÂÖ≥‰∫éLLMÁöÑÂèÇÊï∞ÈÖçÁΩÆÔºåÊúâ‰∏ÄÁØáÂæàÊúâÊÑèÊÄùÁöÑËÆ∫Êñá&lt;a href="https://arxiv.org/pdf/2402.14905"&gt;MobileLLM&lt;/a&gt;ÂÅö‰∫ÜËØ¶ÁªÜÁöÑÁ†îÁ©∂ÂíåÂÆûÈ™å„ÄÇ Scaling LawÂú®Â∞èÊ®°Âûã‰∏≠ÊúâËá™Â∑±Áã¨ÁâπÁöÑËßÑÂæã„ÄÇ ÂºïËµ∑TransformerÂèÇÊï∞ÊàêËßÑÊ®°ÂèòÂåñÁöÑÂèÇÊï∞Âá†‰πéÂè™ÂèñÂÜ≥‰∫é&lt;code&gt;d_model&lt;/code&gt;Âíå&lt;code&gt;n_layers&lt;/code&gt;„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;‚Üë + &lt;code&gt;n_layers&lt;/code&gt;‚Üì -&amp;gt; ÁüÆËÉñÂ≠ê&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;‚Üì + &lt;code&gt;n_layers&lt;/code&gt;‚Üë -&amp;gt; Áò¶È´ò‰∏™&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2020Âπ¥ÊèêÂá∫Scaling LawÁöÑËÆ∫ÊñáËÆ§‰∏∫ÔºåËÆ≠ÁªÉÊï∞ÊçÆÈáè„ÄÅÂèÇÊï∞Èáè‰ª•ÂèäËÆ≠ÁªÉËø≠‰ª£Ê¨°Êï∞ÊâçÊòØÂÜ≥ÂÆöÊÄßËÉΩÁöÑÂÖ≥ÈîÆÂõ†Á¥†ÔºåËÄåÊ®°ÂûãÊû∂ÊûÑÁöÑÂΩ±ÂìçÂá†‰πéÂèØ‰ª•ÂøΩËßÜ„ÄÇ ÁÑ∂ËÄå‰ºº‰πéËøô‰∏™ÂÆöÂæãÂØπÂ∞èÊ®°ÂûãÂπ∂‰∏çÂÆåÂÖ®ÈÄÇÁî®„ÄÇ MobileLLMÊèêÂá∫Êû∂ÊûÑÁöÑÊ∑±Â∫¶ÊØîÂÆΩÂ∫¶Êõ¥ÈáçË¶ÅÔºå„ÄåÊ∑±ËÄåÁ™Ñ„ÄçÁöÑ„ÄåÁò¶Èïø„ÄçÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†Âà∞ÊØî„ÄåÂÆΩËÄåÊµÖ„ÄçÊ®°ÂûãÊõ¥Â§öÁöÑÊäΩË±°Ê¶ÇÂøµ„ÄÇ ‰æãÂ¶ÇÂΩìÊ®°ÂûãÂèÇÊï∞Âõ∫ÂÆöÂú®125MÊàñËÄÖ350MÊó∂Ôºå30ÔΩû42Â±ÇÁöÑ„ÄåÁã≠Èïø„ÄçÊ®°ÂûãÊòéÊòæÊØî12Â±ÇÂ∑¶Âè≥ÁöÑ„ÄåÁüÆËÉñ„ÄçÊ®°ÂûãÊúâÊõ¥‰ºòË∂äÁöÑÊÄßËÉΩÔºå Âú®Â∏∏ËØÜÊé®ÁêÜ„ÄÅÈóÆÁ≠î„ÄÅÈòÖËØªÁêÜËß£Á≠â8‰∏™Âü∫ÂáÜÊµãËØï‰∏äÈÉΩÊúâÁ±ª‰ººÁöÑË∂ãÂäø„ÄÇ ËøôÂÖ∂ÂÆûÊòØÈùûÂ∏∏ÊúâË∂£ÁöÑÂèëÁé∞ÔºåÂõ†‰∏∫‰ª•ÂæÄ‰∏∫100MÂ∑¶Âè≥ÈáèÁ∫ßÁöÑÂ∞èÊ®°ÂûãËÆæËÆ°Êû∂ÊûÑÊó∂ÔºåÂá†‰πéÊ≤°‰∫∫Â∞ùËØïËøáÂè†Âä†Ë∂ÖËøá12Â±Ç„ÄÇ Ëøô‰∏éMiniMindÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊ®°ÂûãÂèÇÊï∞ÈáèÂú®&lt;code&gt;d_model&lt;/code&gt;Âíå&lt;code&gt;n_layers&lt;/code&gt;‰πãÈó¥ËøõË°åË∞ÉÊï¥ÂÆûÈ™åËßÇÂØüÂà∞ÁöÑÊïàÊûúÊòØ‰∏ÄËá¥ÁöÑ„ÄÇ ÁÑ∂ËÄå„ÄåÊ∑±ËÄåÁ™Ñ„ÄçÁöÑ„ÄåÁ™Ñ„Äç‰πüÊòØÊúâÁª¥Â∫¶ÊûÅÈôêÁöÑÔºåÂΩìd_model&amp;lt;512Êó∂ÔºåËØçÂµåÂÖ•Áª¥Â∫¶ÂùçÂ°åÁöÑÂä£ÂäøÈùûÂ∏∏ÊòéÊòæÔºå Â¢ûÂä†ÁöÑlayersÂπ∂‰∏çËÉΩÂº•Ë°•ËØçÂµåÂÖ•Âú®Âõ∫ÂÆöq_headÂ∏¶Êù•d_head‰∏çË∂≥ÁöÑÂä£Âäø„ÄÇ ÂΩìd_model&amp;gt;1536Êó∂ÔºålayersÁöÑÂ¢ûÂä†‰ºº‰πéÊØîd_modelÁöÑ‰ºòÂÖàÁ∫ßÊõ¥È´òÔºåÊõ¥ËÉΩÂ∏¶Êù•ÂÖ∑Êúâ‚ÄúÊÄß‰ª∑ÊØî‚ÄùÁöÑÂèÇÊï∞-&amp;gt;ÊïàÊûúÂ¢ûÁõä„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âõ†Ê≠§MiniMindËÆæÂÆösmallÊ®°Âûãdim=512Ôºån_layers=8Êù•Ëé∑ÂèñÁöÑ„ÄåÊûÅÂ∞è‰ΩìÁßØ&amp;lt;-&amp;gt;Êõ¥Â•ΩÊïàÊûú„ÄçÁöÑÂπ≥Ë°°„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ËÆæÂÆödim=768Ôºån_layers=16Êù•Ëé∑ÂèñÊïàÊûúÁöÑÊõ¥Â§ßÊî∂ÁõäÔºåÊõ¥Âä†Á¨¶ÂêàÂ∞èÊ®°ÂûãScaling-LawÁöÑÂèòÂåñÊõ≤Á∫ø„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‰Ωú‰∏∫ÂèÇËÄÉÔºåGPT3ÁöÑÂèÇÊï∞ËÆæÂÆöËßÅ‰∏ãË°®Ôºö &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/gpt3_config.png" alt="gpt3_config.png"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;‚Ö§ ËÆ≠ÁªÉÁªìÊûú&lt;/h2&gt; 
&lt;p&gt;MiniMind2 Ê®°ÂûãËÆ≠ÁªÉÊçüÂ§±Ëµ∞ÂäøÔºàÁî±‰∫éÊï∞ÊçÆÈõÜÂú®ËÆ≠ÁªÉÂêéÂèàÊõ¥Êñ∞Ê∏ÖÊ¥óÂ§öÊ¨°ÔºåÂõ†Ê≠§Loss‰ªÖ‰æõÂèÇËÄÉÔºâ&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;pretrain (length-512)&lt;/th&gt; 
   &lt;th&gt;sft (length-512)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_512_loss.png" width="100%"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_512_loss.png" width="100%"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_768_loss.png" width="100%"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_768_loss.png" width="100%"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ËÆ≠ÁªÉÂÆåÊàê-Ê®°ÂûãÂêàÈõÜ&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÄÉËôëÂà∞Â§ö‰∫∫ÂèçÂ∫îÁôæÂ∫¶ÁΩëÁõòÈÄüÂ∫¶ÊÖ¢ÔºåMiniMind2Âèä‰ª•ÂêéÂÖ®ÈÉ®‰ΩøÁî®ModelScope/HuggingFaceÊâòÁÆ°„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;‚ë† PyTorchÂéüÁîüÊ®°Âûã&lt;/h4&gt; 
&lt;p&gt;MiniMind2Ê®°ÂûãÊùÉÈáç (&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/jingyaogong/MiniMind2-Pytorch"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;MiniMind-V1Ê®°ÂûãÊùÉÈáç (&lt;a href="https://pan.baidu.com/s/1KUfSzEkSXYbCCBj0Pw-9fA?pwd=6666"&gt;ÁôæÂ∫¶ÁΩëÁõò&lt;/a&gt;)&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;TorchÊñá‰ª∂ÂëΩÂêçÂØπÁÖß&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;sft_model&lt;/th&gt; 
    &lt;th&gt;rl_model&lt;/th&gt; 
    &lt;th&gt;reason_model&lt;/th&gt; 
    &lt;th&gt;lora_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
    &lt;td&gt;145M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2&lt;/td&gt; 
    &lt;td&gt;104M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;ÂçïËΩÆÂØπËØùsft&lt;/th&gt; 
    &lt;th&gt;Â§öËΩÆÂØπËØùsft&lt;/th&gt; 
    &lt;th&gt;rl_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rl_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
    &lt;td&gt;4√ó26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1&lt;/td&gt; 
    &lt;td&gt;108M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rl_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h4&gt;‚ë° TransformersÊ®°Âûã&lt;/h4&gt; 
&lt;p&gt;MiniMindÁ≥ªÂàó (&lt;a href="https://www.modelscope.cn/collections/MiniMind-b72f4cfeb74b47"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;hr&gt; 
&lt;h1&gt;üìå Eval&lt;/h1&gt; 
&lt;h2&gt;‚Ö† RLHFÂØπÊØîSFTÁØá&lt;/h2&gt; 
&lt;p&gt;ÊµãËØïÂü∫‰∫é&lt;code&gt;full_sft&lt;/code&gt;Âíå&lt;code&gt;rlhf&lt;/code&gt;ÁöÑ&lt;code&gt;MiniMind2Á≥ªÂàó&lt;/code&gt;Ê®°ÂûãÂØπÊØîÔºåÊµãËØïÈöèÊú∫ÁßçÂ≠êÂùáÂõ∫ÂÆö&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÈóÆÁ≠îÂÆûÊµã&lt;/summary&gt; 
 &lt;p&gt;[A0] MiniMind2Ôºöfull_sft_640&lt;/p&gt; 
 &lt;p&gt;[A1] MiniMind2Ôºörlhf_640&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;[Q]: ‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠óÔºü
[A0]: ÊàëÊòØ‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÂèØ‰ª•ÂõûÁ≠îÂêÑÁßçÈóÆÈ¢òÔºåÊèê‰æõ‰ø°ÊÅØÂíåÂ∏ÆÂä©„ÄÇÊàëÂèØ‰ª•ÂõûÁ≠îÂêÑÁßçÈóÆÈ¢òÔºåÊèê‰æõ‰ø°ÊÅØÂíåÂ∏ÆÂä©ÔºåÂ∏ÆÂä©‰Ω†Ëß£ÂÜ≥ÂêÑÁßçÈóÆÈ¢ò„ÄÇ
[A1]: ÊàëÊòØ‰∏ÄÁßçÂü∫‰∫éÊñáÊú¨ÁöÑAIÊ®°ÂûãÔºåÊàëÂπ∂Ê≤°Êúâ‰∏™‰∫∫ÁªèÂéÜÊàñÊÉÖÊÑüÔºåÊâÄ‰ª•Êó†Ê≥ïÊÑüÂèóÂíå‰ΩìÈ™åÊÉÖÊÑü„ÄÇÊàëÁöÑËÆæËÆ°ÁõÆÁöÑÊòØ‰∏∫‰∫ÜÂ∏ÆÂä©Áî®Êà∑Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØÂíåËøõË°åÂØπËØù„ÄÇÂ¶ÇÊûúÊÇ®Êúâ‰ªª‰ΩïÈóÆÈ¢òÊàñÈúÄË¶ÅÂ∏ÆÂä©ÔºåËØ∑ÈöèÊó∂ÂëäËØâÊàëÔºÅ

[Q]: ‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºü
[A0]: ‰Ωú‰∏∫‰∏Ä‰∏™AIÊ®°ÂûãÔºåÊàëÂπ∂Ê≤°ÊúâÁúüÊ≠£ÁöÑ‚ÄúÊìÖÈïø‚ÄùËøô‰∏™Â≠¶Áßë„ÄÇÊàëË¢´ËÆæËÆ°ÊàêËÉΩÂ§üÊèê‰æõ‰ø°ÊÅØ„ÄÅËß£Á≠îÈóÆÈ¢ò„ÄÅËøõË°åÂØπËØù„ÄÅÊâßË°å‰ªªÂä°Âíå‰∏éÁî®Êà∑ËøõË°åÂØπËØù„ÄÇ‰∏çËøáÔºåÊàëÂèØ‰ª•Êèê‰æõ‰ø°ÊÅØ„ÄÅËß£Á≠îÈóÆÈ¢ò„ÄÅËøõË°åÂØπËØù„ÄÅÊèê‰æõÂª∫ËÆÆ„ÄÅÂ§ÑÁêÜÈóÆÈ¢ò„ÄÅËøõË°åÂØπËØù„ÄÅÊèê‰æõÂª∫ËÆÆ„ÄÅÂ≠¶‰π†Êñ∞Áü•ËØÜ„ÄÅÁºñÂÜô‰ª£Á†Å„ÄÅÂõûÁ≠îÈóÆÈ¢ò„ÄÅÊèê‰æõÂª∫ËÆÆÁ≠âÂ§öÁßçÂ≠¶ÁßëÁöÑÂäüËÉΩ„ÄÇÂ¶ÇÊûú‰Ω†ÊúâÂÖ∑‰ΩìÁöÑÂ≠¶ÁßëÈúÄÊ±ÇÊàñ‰∏ªÈ¢òÔºåÊ¨¢ËøéÊèê‰æõËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇ
[A1]: ‰Ωú‰∏∫AIÔºåÊàëÂπ∂Ê≤°Êúâ‰∏™‰∫∫ËÉΩÂäõÊàñÂÖ¥Ë∂£Ôºå‰ΩÜÊàëÂèØ‰ª•Êèê‰æõ‰∏Ä‰∫õÂÖ≥‰∫éÊï∞Â≠¶„ÄÅÁßëÂ≠¶„ÄÅËÆ°ÁÆóÊú∫ÁßëÂ≠¶„ÄÅËØ≠Ë®ÄÂ≠¶„ÄÅÂøÉÁêÜÂ≠¶Á≠âÂ≠¶ÁßëÁöÑÁü•ËØÜ„ÄÇÂ¶ÇÊûú‰Ω†ÂØπÊï∞Â≠¶ÊÑüÂÖ¥Ë∂£ÔºåÊàëÂèØ‰ª•Êèê‰æõ‰∏Ä‰∫õÂü∫Á°ÄÁü•ËØÜÔºå‰æãÂ¶Ç‰ª£Êï∞„ÄÅÂá†‰Ωï„ÄÅÊ¶ÇÁéá„ÄÅÁªüËÆ°Â≠¶Á≠â„ÄÇÂ¶ÇÊûú‰Ω†ÈúÄË¶ÅÊõ¥Ê∑±ÂÖ•ÁöÑÂ≠¶‰π†ÔºåÊàë‰πüÂèØ‰ª•Êèê‰æõÁõ∏ÂÖ≥ÁöÑÂú®Á∫øËØæÁ®ã„ÄÅ‰π¶Á±ç„ÄÅËÆ∫ÊñáÁ≠âËµÑÊ∫ê„ÄÇËØ∑ÂëäËØâÊàë‰Ω†ÂÖ∑‰ΩìÈúÄË¶Å‰ªÄ‰πàÂ∏ÆÂä©ÔºåÊàë‰ºöÂ∞ΩÂäõÊèê‰æõÂ∏ÆÂä©„ÄÇ

[Q]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØÂ¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÁöÑÔºü
[A0]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØ‰∏ÄÈÉ®ËÆ≤Ëø∞‰∫ÜÈ≤ÅËøÖÂØπ‰∫∫Á±ª‰ª∑ÂÄºÂíåÈÅìÂæ∑Ë¥£‰ªªÁöÑÂÄ°ÂØº„ÄÇÂú®ËøôÈÉ®‰ΩúÂìÅ‰∏≠ÔºåÈ≤ÅËøÖÈÄöËøáÁªÜËÖªÁöÑÁ¨îËß¶ÔºåÊé¢ËÆ®‰∫Ü‰∫∫ÊÄß„ÄÅÈÅìÂæ∑„ÄÅÊ≠£‰πâ„ÄÅÁâ∫Áâ≤‰∏éË¥£‰ªªÁ≠âÊ∑±ÂàªÁöÑ‰∏ªÈ¢ò„ÄÇ‰ª•‰∏ãÊòØÈ≤ÅËøÖÂú®„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏≠Â¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÁöÑÂá†‰∏™ÊñπÈù¢Ôºö1. **Á§æ‰ºöÁé∞ÂÆû‰∏éÈÅìÂæ∑ËßÇÂøµ**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊé¢ËÆ®‰∫ÜÁ§æ‰ºöÁöÑ‰∏çÂπ≥Á≠â„ÄÅÊùÉÂäõÁöÑÊµÅÂä®„ÄÅ‰∫∫ÊÄßÁöÑÊºîÂèòÁ≠âÁ§æ‰ºöÈóÆÈ¢ò„ÄÇ‰ªñËÆ§‰∏∫ÔºåÁ§æ‰ºö‰∏çÂπ≥Á≠â‰∏ç‰ªÖ‰ªÖÊòØ‰∏çÂÖ¨Ê≠£ÁöÑÔºåÊõ¥ÊòØÊØè‰∏™‰∫∫Âú®Á§æ‰ºö‰∏≠ÁöÑ‰∏çÂÖ¨Ê≠£„ÄÇ‰ªñÂëºÂêÅÁ§æ‰ºöÂêÑÁïåÂÖ±ÂêåÂä™ÂäõÔºåÈÄöËøáÊïôËÇ≤„ÄÅÂÆ£‰º†„ÄÅÊ≥ïÂæãÁ≠âÊâãÊÆµÔºå‰∏∫ÊûÑÂª∫ÂíåË∞êÁ§æ‰ºöÂÅöÂá∫Ë¥°ÁåÆ„ÄÇ2. **ÈÅìÂæ∑‰∏éË¥£‰ªª**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÂ±ïÁé∞‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ‰ªñÊèêÂÄ°ÈÄöËøáÈÅìÂæ∑ÊïôËÇ≤Êù•ÂüπÂÖª‰∫∫‰ª¨ÁöÑÈÅìÂæ∑ÂìÅË¥®ÔºåÂêåÊó∂‰πüÂº∫Ë∞É‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫ÜÁ§æ‰ºöÁöÑ‰∏çÂπ≥Á≠âÂíå‰∫∫ÊÄßÁöÑÂ§çÊùÇÊÄßÔºå‰ΩìÁé∞‰∫ÜÂØπ‰∫∫ÊÄßÁöÑÊ∑±ÂàªÁêÜËß£„ÄÇ3. **ÈÅìÂæ∑‰∏éË¥£‰ªª**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÂº∫Ë∞É‰∫ÜÈÅìÂæ∑Ë¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ‰ªñÊèêÂÄ°ÈÄöËøáËá™Â∑±ÁöÑË°å‰∏∫Êù•‰ΩìÁé∞ÂØπÁ§æ‰ºöÁöÑÂ∞äÈáçÂíåÂØπ‰∫∫ÊÄßÁöÑÊ∑±ÂàªÁêÜËß£„ÄÇÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÂº∫Ë∞É‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ4. **ÈÅìÂæ∑‰∏éÈÅìÂæ∑**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÁúüÊ≠£ÊÑè‰πâ„ÄÇÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÊú¨Ë¥®ÔºåÂº∫Ë∞É‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ5. **‰∏™‰∫∫‰∏éÁ§æ‰ºö**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫Ü‰∏™‰∫∫‰∏éÁ§æ‰ºö‰πãÈó¥ÁöÑÂ§çÊùÇÂÖ≥Á≥ª„ÄÇ‰ªñÂëºÂêÅÁ§æ‰ºöÂêÑÁïåÂÖ±ÂêåÂä™ÂäõÔºåÈÄöËøáÊïôËÇ≤ÂíåÂÆ£‰º†Ôºå‰∏∫ÊûÑÂª∫ÂíåË∞êÁ§æ‰ºöÂÅöÂá∫Ë¥°ÁåÆ„ÄÇÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÈÄöËøáÂÖ∂‰∏∞ÂØåÁöÑÊïÖ‰∫ãÂíåÊ∑±ÂàªÁöÑÈÅìÂæ∑ÂØìË®ÄÔºå‰º†Ëææ‰∫ÜÂÖ≥‰∫é‰∫∫ÊÄß„ÄÅÈÅìÂæ∑„ÄÅÊ≠£‰πâ„ÄÅÈÅìÂæ∑‰ª•Âèä‰∏™‰∫∫‰∏éÁ§æ‰ºöÁöÑÂ§çÊùÇÂÖ≥Á≥ª„ÄÇËøôÈÉ®‰ΩúÂìÅ‰∏ç‰ªÖÂú®ÊñáÂ≠¶‰ª∑ÂÄº‰∏äÂèñÂæó‰∫ÜÂ∑®Â§ßÊàêÂ∞±ÔºåÊõ¥Âú®ÊÄùÊÉ≥Â±ÇÈù¢‰∏äÂêØÂèë‰∫ÜÂêéÊù•ÁöÑÊñáÂ≠¶Âàõ‰ΩúÔºåÂØπÂêé‰∏ñ‰∫ßÁîü‰∫ÜÊ∑±ËøúÁöÑÂΩ±Âìç„ÄÇ
[A1]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØ‰∏ÄÈÉ®ÊèèÁªòÊàò‰∫âÂíåËá™Áî±Á≤æÁ•ûÁöÑ‰ΩúÂìÅÔºåÂÆÉÊâπÂà§‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑÁßçÁßçÈóÆÈ¢òÂíåÂÜ≤Á™ÅÔºåÂèçÊò†‰∫ÜÁ§æ‰ºöÁöÑ‰∏çÂπ≥Á≠âÂíå‰∫∫ÊÄßÊú¨Ë¥®„ÄÇÂú®ËøôÈÉ®‰ΩúÂìÅ‰∏≠ÔºåÈ≤ÅËøÖÈÄöËøáÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑËØ∏Â§öÁé∞Ë±°ËøõË°åÊâπÂà§ÔºåÂ¶Ç‚ÄúÂºóÈõ∑Âæ∑ÈáåÂÖã¬∑Á∫¶Áø∞ÈÄäÁöÑ‚ÄúÈπ∞Ëø™‰º¶‚Äù„ÄÅ‚ÄúÁ∫≥ÊâéÁâπÁöÑ‚Äù„ÄÅ‚ÄúË¥ùÂÖãÊ±âÂßÜ‚Äù„ÄÅ‚Äú‰πîÊ≤ª¬∑Â®ÅÂ∞îÈÄä‚ÄùÁ≠âÔºåÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑÁßçÁßçÈóÆÈ¢òËøõË°å‰∫ÜÊâπÂà§ÔºåÂº∫Ë∞É‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑ‰∏çÂπ≥Á≠â„ÄÅ‰∫∫ÊÄßÊú¨Ë¥®‰ª•Âèä‰∫∫ÊÄßÊú¨Ë¥®„ÄÇÈ≤ÅËøÖÈÄöËøá‰ªñÁöÑ‚ÄúÈπ∞Ëø™‰º¶‚Äù„ÄÅ‚ÄúÁ∫≥ÊâéÁâπÁöÑ‚Äù„ÄÅ‚ÄúË¥ùÂÖãÊ±âÂßÜ‚Äù„ÄÅ‚Äú‰πîÊ≤ª¬∑Â®ÅÂ∞îÈÄä‚ÄùÁ≠âÔºåÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑÁßçÁßçÈóÆÈ¢òËøõË°å‰∫ÜÊâπÂà§„ÄÇÂú®Â∞èËØ¥‰∏≠ÔºåÈ≤ÅËøÖÈÄöËøáÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑËØ∏Â§öÁé∞Ë±°ËøõË°åÊâπÂà§ÔºåÊè≠Á§∫‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑËÖêË¥•„ÄÅ‰∫∫ÊÄßÊú¨Ë¥®‰ª•Âèä‰∫∫ÊÄßÊú¨Ë¥®ÁöÑÂ§çÊùÇÊÄß„ÄÇËøôÁßçÊâπÂà§‰ΩìÁé∞‰∫ÜÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑÂ∞äÈáçÂíåÂØπ‰∫∫ÊÄßÁöÑÂ§çÊùÇÊÄßÔºåÂêåÊó∂‰πüÂèçÊò†‰∫ÜÁé∞‰ª£Á§æ‰ºö‰∏≠ÊôÆÈÅçÂ≠òÂú®ÁöÑ‰∏çÂπ≥Á≠âÂíå‰∫∫ÊÄßÊú¨Ë¥®„ÄÇÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏ç‰ªÖÊòØ‰∏ÄÈÉ®ÂÖ≥‰∫éÂ∞ÅÂª∫Á§æ‰ºöÁöÑÂ∞èËØ¥Ôºå‰πüÊòØ‰∏ÄÈÉ®ÂÖ∑ÊúâÊ∑±ÂàªÁ§æ‰ºöÊÑè‰πâÁöÑ‰ΩúÂìÅÔºåÂØπÂêé‰∏ñÁöÑÂÆ°Âà§ÂíåÊâπÂà§Ëµ∑Âà∞‰∫ÜÂÖ≥ÈîÆ‰ΩúÁî®„ÄÇ

[Q]: ÊàëÂí≥ÂóΩÂ∑≤ÁªèÊåÅÁª≠‰∫Ü‰∏§Âë®ÔºåÈúÄË¶ÅÂéªÂåªÈô¢Ê£ÄÊü•ÂêóÔºü
[A0]: Âí≥ÂóΩÁ°ÆÂÆûÈúÄË¶Å‰∏ÄÂÆöÁöÑÊ£ÄÊü•Ôºå‰ΩÜÂ¶ÇÊûúÊÇ®ÁöÑÂí≥ÂóΩÊåÅÁª≠Êó∂Èó¥ËøáÈïøÔºåÊàñËÄÖÊúâÂÖ∂‰ªñ‰∏çÈÄÇÁóáÁä∂ÔºàÂ¶ÇÊåÅÁª≠Âí≥ÂóΩ„ÄÅÂëºÂê∏Âõ∞ÈöæÁ≠âÔºâÔºåÂª∫ËÆÆÂ∞ΩÂø´Â∞±Âåª„ÄÇÂåªÁîü‰ºöÊ†πÊçÆÊÇ®ÁöÑÁóáÁä∂„ÄÅ‰ΩìÊ£ÄÁªìÊûúÂíåÂèØËÉΩÁöÑÂΩ±ÂÉèÂ≠¶Ê£ÄÊü•ÔºàÂ¶ÇXÂÖâ„ÄÅMRIÊàñCTÊâ´ÊèèÔºâÊù•ËØäÊñ≠ÊÇ®ÁöÑÁóáÁä∂„ÄÇÂú®Á≠âÂæÖÂ∞±ÂåªÊúüÈó¥ÔºåÊÇ®ÂèØ‰ª•Â∞ùËØï‰ª•‰∏ãÊñπÊ≥ïÊù•Â∏ÆÂä©ÁºìËß£ÁóáÁä∂Ôºö1. **‰ºëÊÅØ**ÔºöÁ°Æ‰øùÊÇ®ÊúâË∂≥Â§üÁöÑÁù°Áú†„ÄÇ2. **‰øùÊåÅÊ∞¥ÂàÜ**ÔºöËÑ±Ê∞¥ÂèØËÉΩ‰ºöÂä†ÈáçÂí≥ÂóΩ„ÄÇ3. **ÁÉ≠Êï∑**Ôºö‰ΩøÁî®ÁÉ≠Êï∑Ë¢ãÊàñÁÉ≠ÊØõÂ∑æÊï∑Âú®ÁñºÁóõÁöÑÈÉ®‰ΩçÔºåÊúâÂä©‰∫éÁºìËß£ÂñâÂíôÁóõ„ÄÇ4. **ÈÅøÂÖçÂà∫ÊøÄ**ÔºöÈÅøÂÖç‰ΩøÁî®ÂèØËÉΩÂà∫ÊøÄÂñâÂíôÁöÑÂåñÂ≠¶Áâ©Ë¥®ÔºåÂ¶ÇÊüê‰∫õÂåñÂ≠¶Áâ©Ë¥®„ÄÇ5. **‰øùÊåÅÂÆ§ÂÜÖÊπøÊ∂¶**ÔºöÁ°Æ‰øùÊÇ®ÁöÑÂçßÂÆ§ÊúâËâØÂ•ΩÁöÑÈÄöÈ£éÔºåÂèØ‰ª•‰ΩøÁî®Âä†ÊπøÂô®Â∏ÆÂä©‰øùÊåÅÁ©∫Ê∞îÊπøÂ∫¶„ÄÇ6. **‰øùÊåÅÂÆ§ÂÜÖÊπøÂ∫¶**Ôºö‰ΩøÁî®Âä†ÊπøÂô®ÂèØ‰ª•Â∏ÆÂä©ÁºìËß£ÂñâÂíôÂπ≤Áá•ÂíåÂí≥ÂóΩ„ÄÇÂ¶ÇÊûúÁóáÁä∂ÊåÅÁª≠‰∏çÁºìËß£ÊàñÊúâÂÖ∂‰ªñ‰∏çÈÄÇÁóáÁä∂ÔºåËØ∑Á´ãÂç≥Â∞±Âåª„ÄÇÂ∏åÊúõÊÇ®Êó©Êó•Â∫∑Â§çÔºÅ
[A1]: Â¶ÇÊûúÊÇ®ÁöÑÂí≥ÂóΩÊåÅÁª≠‰∫Ü‰∏§Âë®ÔºåÈÄöÂ∏∏Âª∫ËÆÆÊÇ®Â∞ΩÂø´Â∞±ÂåªÔºåÂõ†‰∏∫ËøôÂèØËÉΩ‰ºöÂΩ±ÂìçÊÇ®ÁöÑÂëºÂê∏ÂíåÂøÉË∑≥„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÊ≠•È™§Êù•Ê£ÄÊü•Âí≥ÂóΩÔºö1. **‰ºëÊÅØ**ÔºöÁî®Á∫∏Â∑æÊàñËÇòÈÉ®ËΩªËΩªÊåâÂéãÂí≥ÂóΩÁöÑ‰ΩçÁΩÆ„ÄÇ2. **‰ΩøÁî®ËçØÁâ©**ÔºöÂú®ÂèØËÉΩÁöÑÊÉÖÂÜµ‰∏ãÔºå‰ΩøÁî®ËçØÁâ©ÔºàÂ¶ÇÊäóËøáÊïèËçØ„ÄÅÊäóËøáÊïèËçØÁ≠âÔºâÊù•ÁºìËß£Âí≥ÂóΩ„ÄÇËØ∑Âú®ÂåªÁîüÁöÑÊåáÂØº‰∏ã‰ΩøÁî®ËçØÁâ©„ÄÇ3. **ÁÉ≠Êï∑**ÔºöÂú®Âí≥ÂóΩÊúüÈó¥ÔºåÂèØ‰ª•‰ΩøÁî®ÁÉ≠Êï∑Êù•ÁºìËß£ÁñºÁóõÂíåËÇøËÉÄ„ÄÇ4. **ËçØÁâ©Ê≤ªÁñó**ÔºöÂ¶ÇÊûúÂí≥ÂóΩÊåÅÁª≠‰∫Ü‰∏§Âë®ÔºåÂèØ‰ª•‰ΩøÁî®‰∏Ä‰∫õÊ∂àÁÇéËçØÊàñÊäóËøáÊïèËçØÊù•ÁºìËß£ÁóáÁä∂„ÄÇËØ∑Âä°ÂøÖÂú®ÂåªÁîüÁöÑÊåáÂØº‰∏ã‰ΩøÁî®„ÄÇ5. **‰øùÊåÅÂÅ•Â∫∑ÁöÑÁîüÊ¥ªÊñπÂºè**Ôºö‰øùÊåÅÂÖÖË∂≥ÁöÑÁù°Áú†„ÄÅÂùáË°°ÁöÑÈ•ÆÈ£ü„ÄÅÈÄÇÈáèÁöÑËøêÂä®ÂíåÈÅøÂÖçÂê∏ÁÉüÂíåÈôêÈÖíÔºåËøô‰∫õÈÉΩÊúâÂä©‰∫éÊèêÈ´òÂí≥ÂóΩÁöÑÂá†Áéá„ÄÇËØ∑ËÆ∞‰ΩèÔºåËøô‰∫õÂª∫ËÆÆ‰∏çËÉΩÊõø‰ª£‰∏ì‰∏öÂåªÁñóÊÑèËßÅ„ÄÇÂ¶ÇÊûúÊÇ®ÁöÑÁóáÁä∂ÊåÅÁª≠ÊàñÂä†ÈáçÔºåÂº∫ÁÉàÂª∫ËÆÆÊÇ®Â∞ΩÂø´Â∞±Âåª„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;üëâÊïàÊûúÊÄªÁªì&lt;/p&gt; 
&lt;p&gt;full_sftÊ®°ÂûãÂú®ÁÆÄÊ¥ÅÊÄßÂíå‰ø°ÊÅØÂáÜÁ°ÆÊÄßÊñπÈù¢Ë°®Áé∞Êõ¥Â•ΩÔºõrlhfÊ®°ÂûãÂú®ÂõûÁ≠î‰∏≠ÂÄæÂêë‰∫éÊèê‰æõÊõ¥Â§öÁöÑËÉåÊôØ‰ø°ÊÅØÔºå‰ΩÜ‰ø°ÊÅØÂáÜÁ°ÆÊÄßÊúâÂæÖÊîπËøõ„ÄÇ ÊÄªÁöÑÊù•ËØ¥RLHFÂêéÁöÑÊ®°ÂûãÂÄæÂêë‰∫éÂ≠¶‰π†ÔºöËØ¥Êõ¥Â§öÊúâÁ§ºË≤å‰ΩÜÊó†Áî®ÁöÑÂ∫üËØùËÆ®Â•Ω‚ÄúÂØπËØù‚ÄùÊú¨Ë∫´ÔºåËÄåÂØπ‰ø°ÊÅØÂáÜÁ°ÆÊÄßÂàôÊúâËΩªÂæÆÊçüÂ§±„ÄÇ Â§©‰∏ãÊ≤°ÊúâÂÖçË¥πÁöÑÂçàÈ§êÔºåËøòÈúÄË¶ÅÁªßÁª≠ÊèêÂçáRLHFÊï∞ÊçÆÈõÜÁöÑË¥®ÈáèÔºå‰πüË¶ÅÊé•ÂèóÊ®°ÂûãËÉΩÂäõÊó†Ê≥ïÈÅøÂÖçÁöÑÊçüÂ§±(Á®ãÂ∫¶ÊúâËΩªÈáç)„ÄÇ DPOÂíåÂú®Á∫øPPOÁöÑÂå∫Âà´Âú®‰∫érejectÂíåchosenÈÉΩÊòØÁ¶ªÁ∫øÂáÜÂ§áÁöÑÔºåÂíåminimindÊ®°ÂûãÊú¨Ë∫´ÁöÑËæìÂá∫ÂøÖÁÑ∂Â≠òÂú®ÂæàÂ§ßÁöÑÂàÜÂ∏ÉÂ∑ÆÂºÇ„ÄÇ ÈÄö‰øóÂú∞ËØ¥DPOÁÆóÊ≥ï‰ΩøÊ®°ÂûãËßÇÁúã‰πí‰πìÁêÉ‰∏ñÁïåÂÜ†ÂÜõÁöÑÊâìÊ≥ï„ÄåÂΩïÂÉè„ÄçËøõË°åRLÔºåËÄå‰∏çÊòØÂÉèPPO‰∏ÄÊ†∑ËØ∑rewardÊ®°ÂûãÂÅö„ÄåÊïôÁªÉ„ÄçÁ∫†Ê≠£Ëá™Â∑±ÁöÑÊâìÊ≥ïËøõË°åRL„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚Ö° ‰∏ªËßÇÊ†∑‰æãÊµãËØÑ&lt;/h2&gt; 
&lt;p&gt;üèÉ‰ª•‰∏ãÊµãËØï‰∫é2025-02-09ÂÆåÊàêÔºåÊ≠§Êó•ÊúüÂêéÂèëÂ∏ÉÁöÑÊñ∞Ê®°ÂûãÔºåÊó†ÁâπÊÆäÈúÄË¶ÅÊó∂Â∞Ü‰∏çÂä†ÂÖ•ÊµãËØï„ÄÇ&lt;/p&gt; 
&lt;p&gt;[A] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2 (0.1B)&lt;/a&gt;&lt;br&gt; [B] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-MoE (0.15B)&lt;/a&gt;&lt;br&gt; [C] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-Small (0.02B)&lt;/a&gt;&lt;br&gt; [D] &lt;a href="https://pan.baidu.com/s/1_COe0FQRDmeapSsvArahCA?pwd=6666"&gt;minimind-v1-small(0.02B)&lt;/a&gt;&lt;br&gt; [E] &lt;a href="https://pan.baidu.com/s/1tqB-GMvuiGQBvEl-yZ-oBw?pwd=6666"&gt;minimind-v1-moe(0.1B)&lt;/a&gt;&lt;br&gt; [F] &lt;a href="https://pan.baidu.com/s/1p713loS7EfwHQf3G9eYI3Q?pwd=6666"&gt;minimind-v1(0.1B)&lt;/a&gt;&lt;br&gt; [G] &lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;baby-llama2-chinese(0.2B)&lt;/a&gt;&lt;br&gt; [H] &lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;chatlm-mini-chinese(0.2B)&lt;/a&gt;&lt;br&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;[Q]: ‰Ω†Áü•ÈÅìÈïøÊ±üÂêóÔºü
[A]: ÈïøÊ±üÔºå‰Ωç‰∫é‰∏≠ÂõΩ‰∏úÂçóÈÉ®ÔºåÊòØ‰∏≠ÂõΩÁöÑÁ¨¨‰∏ÄÈïøÊ≤≥ÔºåÂÖ®Èïø6300Â§öÂÖ¨ÈáåÔºåÊµÅÁªè11‰∏™ÁúÅ‰ªΩÔºåÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºå‰πüÊòØ‰∏≠ÂõΩÁöÑ‚ÄúÊØç‰∫≤Ê≤≥‚Äù„ÄÇÈïøÊ±üÁöÑÂéÜÂè≤ÂèØ‰ª•ËøΩÊ∫ØÂà∞ÂÖ¨ÂÖÉÂâç2000Â§öÂπ¥ÁöÑÂïÜÊúùÊó∂ÊúüÔºåÂΩìÊó∂ÁöÑÂïÜÊúùÊòØÂïÜÊúùÁöÑÂêéË£î„ÄÇÂïÜÊúùÊó∂ÊúüÔºåÈïøÊ±üÁöÑÁªèÊµéÂèëÂ±ïËææÂà∞‰∫ÜÈ´òÂ≥∞ÔºåÊòØ‰∏≠ÂõΩÊúÄÈáçË¶ÅÁöÑÂÜú‰∏öÂíåÂ∑•‰∏ö‰∏≠ÂøÉ‰πã‰∏Ä„ÄÇÈïøÊ±üÊµÅÂüüÁöÑÁªèÊµé‰∏ªË¶Å‰ª•ÂÜú‰∏ö‰∏∫‰∏ªÔºåÈïøÊ±üÊ∏î‰∏öÂç†ÊçÆ‰∫Ü‰∏ªË¶Å‰∫ß‰∏öÔºåÂ¶ÇÈíìÈ±º„ÄÅÁåéÈ±ºÁ≠â„ÄÇÈïøÊ±üÁöÑÊ∞¥ËµÑÊ∫ê‰πüÈùûÂ∏∏‰∏∞ÂØåÔºåÂåÖÊã¨Ê≤≥ÊµÅ„ÄÅÊπñÊ≥ä„ÄÅÊ≤≥ÊµÅÁ≠â„ÄÇÈïøÊ±üÁöÑËá™ÁÑ∂ÊôØËßÇ‰πüÂçÅÂàÜÂ£ÆËßÇÔºåÈïøÊ±üÂõõÂ≠£ÊôØËâ≤ÂêÑÂºÇÔºåÊò•Â≠£Â§öÈõ®ÔºåÂ§èÂ≠£Â§öÈõ®ÔºåÁßãÂ≠£ÂàôÂ§öÈõ®ÔºåÂÜ¨Â≠£ÂàôÂØíÂÜ∑Â§öÈõ™ÔºåÊò•Â≠£ÂíåÁßãÂ≠£ÈÉΩÊúâÁæé‰∏ΩÁöÑËä±ÊúµÂíåÊûúÂÆû„ÄÇÈïøÊ±üÊòØ‰∏≠ÂõΩÁöÑÁªèÊµé‰∏≠ÂøÉÔºåÊã•Êúâ‰ºóÂ§öÁöÑÂõΩÂÆ∂ÂíåÂüéÂ∏ÇÔºåÊòØ‰∏ñÁïå‰∏äÈáçË¶ÅÁöÑ‰∫§ÈÄöÊû¢Á∫ΩÂíåËà™Ëøê‰∏≠ÂøÉ„ÄÇÂêåÊó∂ÔºåÈïøÊ±üËøòÊòØ‰∏≠ÂõΩÁöÑÈáçË¶ÅÊ∞¥Âà©ËµÑÊ∫êÔºåÂØπ‰∫é‰∏≠ÂõΩÁöÑÁªèÊµéÂèëÂ±ïÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ
[B]: ÊòØÁöÑÔºåÊàëÁü•ÈÅìÈïøÊ±ü„ÄÇÈïøÊ±ü‰Ωç‰∫é‰∏≠ÂõΩÁöÑ‰∏≠ÈÉ®ÔºåÊòØ‰∏≠ÂõΩÁ¨¨‰∏âÈïøÁöÑÊ≤≥ÊµÅÔºåÂÖ®ÈïøÁ∫¶6300ÂÖ¨ÈáåÔºåÊµÅÁªèÊ±üË•øÁúÅ„ÄÅÂÆâÂæΩÁúÅ„ÄÅÊ±üËãèÁúÅ„ÄÅÂÆâÂæΩÁúÅ„ÄÅÊ±üËãèÁúÅÂíåÂÆâÂæΩÁúÅ„ÄÇ
[C]: ÂΩìÁÑ∂ÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºåÂÖ®ÈïøÁ∫¶6300ÂÖ¨Èáå„ÄÇÂÆÉ‰ª•ÂÖ∂‰∏∞ÂØåÁöÑÊ∞¥ËµÑÊ∫ê„ÄÅ‰∏∞ÂØåÁöÑÊ∞¥ÁîüÂä®Ê§çÁâ©ËµÑÊ∫ê‰ª•ÂèäÁã¨ÁâπÁöÑÂú∞ÁêÜ‰ΩçÁΩÆËÄåÈóªÂêç‰∫é‰∏ñ„ÄÇ
[D]: ÊòØÁöÑÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºåÂÖ®ÈïøË∂ÖËøá3300ÂçÉÁ±≥„ÄÇ
[E]: ÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºåÊÄªÈïøÂ∫¶Á∫¶‰∏∫6300ÂÖ¨Èáå„ÄÇÂÆÉÂèëÊ∫ê‰∫éÈùíËóèÈ´òÂéüÁöÑÈùíÊµ∑ÊπñÔºåÊµÅÁªèÈùíÊµ∑„ÄÅÂõõÂ∑ù„ÄÅÁîòËÇÉ„ÄÅÂÆÅÂ§è„ÄÅÂÜÖËíôÂè§„ÄÅÈôïË•øÂíåÂ±±Ë•ø„ÄÇÈïøÊ±üÊµÅÂüüÊòØ‰∏≠ÂõΩÊúÄÂ§ßÁöÑÂÜú‰∏öÂå∫‰πã‰∏ÄÔºå‰πüÊòØ‰∏≠ÂõΩÁöÑÊñáÂåñÂíåÁªèÊµé‰∏≠ÂøÉ„ÄÇ
[F]: ÊòØÁöÑÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅ‰πã‰∏ÄÔºå‰πüÊòØ‰∏ñÁïåÁ¨¨‰∏âÂ§ßÊ≤≥ÊµÅ„ÄÇÈïøÊ±üÂèëÊ∫ê‰∫éÈùíËóèÈ´òÂéüÔºåÊµÅÁªè11‰∏™ÁúÅ‰ªΩÔºåÊúÄÁªàÊ≥®ÂÖ•‰∏úÊµ∑„ÄÇÈïøÊ±üÊµÅÂüüÊòØ‰∏≠ÂõΩÊúÄÂ§ßÁöÑÊ≤≥ÊµÅÊµÅÂüü‰πã‰∏ÄÔºåÊã•ÊúâÁùÄ‰∏∞ÂØåÁöÑËá™ÁÑ∂ËµÑÊ∫êÂíåÊñáÂåñÈÅó‰∫ßÔºåÂ¶ÇÈïøÊ±üÂ§ßÊ°•„ÄÅÈïøÊ±üÊµ∑Ê¥ãÂçöÁâ©È¶Ü„ÄÅÈïøÊ±üÂè§ÂüéÁ≠â„ÄÇ
[G]: ÂêåÊó∂‰πüÁü•ÈÅìÔºå‰∏≠ÂõΩÊòØ‰∏ñÁïå‰∏äÊúÄÈïøÁöÑÂüéÂ∏Ç‰πã‰∏ÄÔºåÊã•ÊúâË∂ÖËøá3400‰∏á‰∫∫Âè£„ÄÇ
[H]: ÊòØÁöÑÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºå‰πüÊòØ‰∏ñÁïå‰∏äÊúÄÈïøÁöÑÊ≤≥ÊµÅ‰πã‰∏Ä„ÄÇÂÆÉÂèëÊ∫ê‰∫éÈùíËóèÈ´òÂéüÔºåÊµÅÁªè‰πù‰∏™ÁúÅÂå∫ÔºåÊúÄÁªàÊ≥®ÂÖ•‰∏úÊµ∑„ÄÇÈïøÊ±üÊµÅÂüüÁöÑÊ∞îÂÄôÊ∏©ÂíåÔºåÂõõÂ≠£ÂàÜÊòéÔºåÊòØ‰∏≠ÂõΩÈáçË¶ÅÁöÑÂÜú‰∏öÂíåÂ∑•‰∏öÂü∫Âú∞„ÄÇÈïøÊ±üÊµÅÂüüÁöÑÊ∞¥‰∫ßËµÑÊ∫ê‰∏∞ÂØåÔºåÊòØ‰∏≠ÂõΩÁöÑÈáçË¶ÅÊ∏î‰∏öËµÑÊ∫ê‰πã‰∏Ä„ÄÇ


[Q]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØ‰ªÄ‰πàÔºü
[A]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞ÔºàMount EverestÔºâÔºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩÁöÑËæπÁïå‰∏ä„ÄÇÂÆÉÁöÑÊµ∑ÊãîÈ´òÂ∫¶ÊòØ8,848.86Á±≥Ôºà29,031.7Ëã±Â∞∫ÔºâÔºåÊòØÂú∞ÁêÉ‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞„ÄÇ
[B]: Áè†Á©ÜÊúóÁéõÂ≥∞ÔºàMount EverestÔºâÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÔºåÊµ∑ÊãîÈ´òÂ∫¶Ëææ8,848Á±≥Ôºà29,029Ëã±Â∞∫Ôºâ„ÄÇ
[C]: Áè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞Ôºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÊµ∑Êãî8,848.86Á±≥Ôºà29,031.7Ëã±Â∞∫Ôºâ„ÄÇÂÆÉ‰Ωç‰∫éÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩÁöÑËæπÁïå‰∏äÔºåÊòØÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ
[D]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰Ωç‰∫éÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩÁöÑËæπÂ¢É‰∏äÔºåÊµ∑Êãî8848Á±≥„ÄÇ
[E]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÊµ∑Êãî8,848Á±≥„ÄÇ
[F]: Áè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÔºåÊµ∑Êãî8848Á±≥„ÄÇ
[G]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÊµ∑Êãî8,848.86Á±≥Ôºà29,031.69Ëã±Â∞∫Ôºâ„ÄÇ
[H]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰πüÁß∞‰∏∫Ëê®Âä†ÁéõÂ°îÔºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÁöÑÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩËæπÂ¢É‰πãÈó¥ÔºåÊµ∑Êãî8,848.86Á±≥Ôºà29,031.69Ëã±Â∞∫Ôºâ„ÄÇÂÆÉÊòØ‰∏ñÁïå‰∏äÊúÄËëóÂêçÁöÑÁôªÂ±±ÁõÆÊ†á‰πã‰∏ÄÔºåÂê∏ÂºïÁùÄÊù•Ëá™‰∏ñÁïåÂêÑÂú∞ÁöÑÁôªÂ±±ËÄÖÂâçÊù•ÊåëÊàò„ÄÇÁè†Á©ÜÊúóÁéõÂ≥∞ÁöÑÂêçÂ≠óÊù•Ëá™ËóèËØ≠ÔºåÊÑèÊÄùÊòØ‚ÄúÂ•≥Á•ûÁöÑÈ¢ùÂ≥∞‚ÄùÔºåÂÆÉÊòØÁî±‰∏§‰∏™‰∏çÂêåÁöÑÂ±±Â≥∞ÁªÑÊàêÁöÑÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÊòØ‰Ωç‰∫éÂ∞ºÊ≥äÂ∞îÁöÑÁè†Á©ÜÊúóÁéõÂ≥∞ÔºåÂè¶‰∏Ä‰∏™Âàô‰Ωç‰∫é‰∏≠ÂõΩ„ÄÇÂÆÉÁöÑÈ´òÂ∫¶ÊòØÈÄöËøáÊµãÈáèÊµ∑ÊãîÈ´òÂ∫¶Êù•Á°ÆÂÆöÁöÑÔºåÂõ†‰∏∫ÂÆÉÊòØÈÄöËøáÊµãÈáèÂú∞ÁêÉÁöÑÂπ≥ÂùáÈ´òÂ∫¶Êù•Á°ÆÂÆöÁöÑ„ÄÇÂ∞ΩÁÆ°Áè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞Ôºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏ä‰ªª‰ΩïÂÖ∂‰ªñÂú∞ÊñπÈÉΩËÉΩÂà∞ËææÁöÑ„ÄÇÂú∞ÁêÉ‰∏äÁöÑÂÖ∂‰ªñÂú∞ÊñπÔºåÂ¶ÇÂçóÁæéÊ¥≤ÁöÑÂÆâÁ¨¨ÊñØÂ±±ËÑâÔºå‰πüÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±ËÑâÔºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞„ÄÇÊÄª‰πãÔºåÁè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞Ôºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏ä‰ªª‰ΩïÂú∞ÊñπÈÉΩËÉΩÂà∞ËææÁöÑ„ÄÇÂÆÉÊòØÂú∞ÁêÉ‰∏äÊúÄÈ´òÁöÑÂ±±ËÑâÔºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏ä‰ªª‰ΩïÂú∞ÊñπÈÉΩËÉΩÂà∞ËææÁöÑ„ÄÇ


[Q]: ‰∏áÊúâÂºïÂäõÊòØË∞ÅÊèêÂá∫ÁöÑÔºü
[A]: ‰∏áÊúâÂºïÂäõÊòØÁî±ÁâõÈ°øÂú®17‰∏ñÁ∫™ÊèêÂá∫ÁöÑÔºåÂÆÉÊòØÁâõÈ°ø‰∏âÂ§ßÂÆöÂæã‰πã‰∏Ä„ÄÇÁâõÈ°øÂú®17‰∏ñÁ∫™ÊèêÂá∫ÁöÑÂºïÂäõÂÆöÂæãÊè≠Á§∫‰∫Ü‰∏áÊúâÂºïÂäõÂÆöÂæãÁöÑÊú¨Ë¥®ÔºåÂπ∂‰∏îËß£Èáä‰∫ÜË°åÊòü„ÄÅÂç´Êòü„ÄÅÂΩóÊòüÁ≠âÂ§©‰Ωì‰πãÈó¥Â¶Ç‰ΩïÁõ∏‰∫í‰ΩúÁî®„ÄÇËøô‰∏™ÂÆöÂæãÊòØÁî±ËâæËê®ÂÖã¬∑ÁâõÈ°øÂú®1687Âπ¥ÊèêÂá∫ÁöÑÔºå‰ªñÈÄöËøáÂØπ‰∏áÊúâÂºïÂäõÂÆöÂæãÁöÑÂàÜÊûêÂíåÂÆûÈ™åÔºåÊàêÂäüÂú∞Ëß£Èáä‰∫ÜÂ§©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõ‰ΩúÁî®Ôºå‰ªéËÄåËß£Èáä‰∫ÜÂú∞ÁêÉÁªïÂ§™Èò≥ÊóãËΩ¨ÁöÑÁé∞Ë±°„ÄÇ
[B]: ‰∏áÊúâÂºïÂäõÔºàHuman PolicyÔºâÊòØÁâõÈ°øÁöÑ‰∏âÂ§ßÂäõÂ≠¶ÂÆöÂæãÔºåÁî®‰∫éÊèèËø∞‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®Âäõ„ÄÇÂÆÉÁî±‰∏áÊúâÂºïÂäõÂÆöÂæãÂíåÁâõÈ°øÁöÑÁ¨¨‰∏ÄÂÆöÂæãÔºàÊÉØÊÄßÂÆöÂæãÔºâÊûÑÊàê„ÄÇ‰∏áÊúâÂºïÂäõÊòØÁî±‰∫é‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥Áõ∏‰∫í‰ΩúÁî®ËÄå‰∫ßÁîüÁöÑÔºåÂÆÉ‰ª¨ÁöÑË¥®Èáè„ÄÅË∑ùÁ¶ª„ÄÅÈÄüÂ∫¶ÂíåÊñπÂêëÁ≠âÂõ†Á¥†ÂÜ≥ÂÆö‰∫ÜÂÆÉ‰ª¨‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®„ÄÇËøôÁßçÁõ∏‰∫í‰ΩúÁî®ÂäõÊòØÔºöË¥®ÈáèÁöÑ‰πòÁßØÔºöË¥®ÈáèÁöÑ‰πòÁßØÊòØ‰∏áÊúâÂºïÂäõÂÆöÂæãÂíåÁâõÈ°øÁ¨¨‰∫åÂÆöÂæãÁöÑ‰πòÁßØ„ÄÇË¥®ÈáèÁöÑ‰πòÁßØÔºöË¥®ÈáèÁöÑ‰πòÁßØÊòØÁâ©‰Ωì‰πãÈó¥ÁöÑ‰∏ÄÁßçÁâ©ÁêÜËøáÁ®ãÔºåÂÆÉÊòØÁâ©‰ΩìÈó¥Áõ∏‰∫í‰ΩúÁî®ÁöÑ‰∫ßÁâ©ÔºåÂØπ‰∫éÂÖ∂‰ªñÁâ©‰ΩìÊù•ËØ¥ÔºåÂÖ∂Ë¥®ÈáèÂèØ‰ª•Ë°®Á§∫‰∏∫‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑË¥®Èáè‰πãÂíåÔºåÂç≥ÈáçÂäõÂä†ÈÄüÂ∫¶a„ÄÇ
[C]: ‰∏áÊúâÂºïÂäõÊòØ‰∏Ä‰∏™Áî±ÁâõÈ°øÂú®1687Âπ¥ÊèêÂá∫ÁöÑÁâ©ÁêÜÂ≠¶Ê¶ÇÂøµÔºåÂÆÉÊèèËø∞‰∫ÜÁâ©‰Ωì‰πãÈó¥ÂºïÂäõÂ¶Ç‰ΩïÁõ∏‰∫í‰ΩúÁî®ÁöÑËßÑÂæã„ÄÇ
[D]: ‰∏áÊúâÂºïÂäõÊòØÁî±Ëã±ÂõΩÁâ©ÁêÜÂ≠¶ÂÆ∂ÁâõÈ°øÊèêÂá∫ÁöÑ„ÄÇ‰ªñËÆ§‰∏∫ÔºåÊâÄÊúâÁâ©‰ΩìÈÉΩ‰ºö‰∫ßÁîüÂºïÂäõÔºåËøô‰∏™ÂºïÂäõÊòØÁî±Áâ©‰ΩìÁöÑË¥®ÈáèÂíåË∑ùÁ¶ªÂÜ≥ÂÆöÁöÑ„ÄÇËøô‰∏™ÁêÜËÆ∫Êè≠Á§∫‰∫ÜË¥®ÈáèÂíåË∑ùÁ¶ª‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂπ∂ËØÅÊòé‰∫Ü‰∏áÊúâÂºïÂäõÁöÑÊú¨Ë¥®„ÄÇ
[E]: ‰∏áÊúâÂºïÂäõÊòØÁî±ÁâõÈ°øÂú®1687Âπ¥ÊèêÂá∫ÁöÑ„ÄÇÂÆÉÊòØÂÆáÂÆô‰∏≠‰∏Ä‰∏™Âü∫Êú¨ÁöÑÁâ©ÁêÜÁé∞Ë±°ÔºåÂÆÉÊèèËø∞‰∫ÜÁâ©‰Ωì‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®„ÄÇËøô‰∏™ÂäõË¢´Áß∞‰∏∫‰∏áÊúâÂºïÂäõÔºåÂÆÉÂú®ÊâÄÊúâÁâ©‰Ωì‰πãÈó¥ÈÉΩÂ≠òÂú®ÔºåËøôÁßçÂäõ‰∏éÁâ©‰ΩìÁöÑË¥®ÈáèÂíåË∑ùÁ¶ªÊúâÂÖ≥„ÄÇ‰∏áÊúâÂºïÂäõÊòØËá™ÁÑ∂Áïå‰∏≠ÊúÄÂü∫Êú¨ÁöÑÂäõÈáè‰πã‰∏ÄÔºåÂÆÉ‰∏ç‰ªÖÂΩ±ÂìçÁùÄÁâ©‰ΩìÁöÑËøêÂä®ÂíåÂèòÂåñÔºåËøòÂØπÂÆáÂÆôÁöÑÁªìÊûÑÂíåÊºîÂåñ‰∫ßÁîüÁùÄÈáçË¶ÅÁöÑÂΩ±Âìç„ÄÇ
[F]: ‰∏áÊúâÂºïÂäõÊòØËã±ÂõΩÁâ©ÁêÜÂ≠¶ÂÆ∂ËâæËê®ÂÖã¬∑ÁâõÈ°øÂú®17‰∏ñÁ∫™ÊèêÂá∫ÁöÑ„ÄÇ
[G]: ÂºïÂäõÊòØÂÆáÂÆô‰∏≠‰∏ÄÁßçÂäõÈáèÔºåÂÆÉÊòØÁî±Ë¥®ÈáèÊàñËÉΩÈáèÊâÄÁªÑÊàêÁöÑ„ÄÇÊ†πÊçÆÁâõÈ°øÁöÑ‰∏áÊúâÂºïÂäõÂÆöÂæãÔºå‰∏Ä‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõÂ§ßÂ∞è‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÂèçÊØî„ÄÇÂõ†Ê≠§ÔºåÁâõÈ°øÁöÑ‰∏áÊúâÂºïÂäõÂÆöÂæãË°®ÊòéÔºå‰∏Ä‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõÂ§ßÂ∞è‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÂèçÊØî„ÄÇËøô‰∏™ÂÆöÂæãÂú®Áâ©ÁêÜÂ≠¶„ÄÅÂ§©ÊñáÂ≠¶ÂíåÁâ©ÁêÜÂ≠¶‰∏≠ÈÉΩÊúâÂπøÊ≥õÁöÑÂ∫îÁî®„ÄÇ
[H]: ‰∏áÊúâÂºïÂäõÊòØÁî±Ëã±ÂõΩÁâ©ÁêÜÂ≠¶ÂÆ∂ËâæËê®ÂÖã¬∑ÁâõÈ°ø‰∫é1687Âπ¥ÊèêÂá∫ÁöÑ„ÄÇ‰ªñÂú®1687Âπ¥ÂèëË°®‰∫Ü‰∏ÄÁØáËëóÂêçÁöÑËÆ∫ÊñáÔºåÈ¢ò‰∏∫„ÄäËá™ÁÑ∂Âì≤Â≠¶ÁöÑÊï∞Â≠¶ÂéüÁêÜ„ÄãÔºåÂÖ∂‰∏≠ÊèêÂá∫‰∫Ü‰∏áÊúâÂºïÂäõÂÆöÂæãÔºåÊåáÂá∫‰ªª‰Ωï‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÈÉΩÂ≠òÂú®ÁùÄ‰∏ÄÁßçÂºïÂäõÔºåËøôÁßçÂºïÂäõÁöÑÂ§ßÂ∞è‰∏éÂÆÉ‰ª¨ÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉ‰ª¨‰πãÈó¥ÁöÑË∑ùÁ¶ªÁöÑÂπ≥ÊñπÊàêÂèçÊØî„ÄÇËøô‰∏™ÂÆöÂæãË¢´Áß∞‰∏∫‰∏áÊúâÂºïÂäõÂÆöÂæãÔºåÂÆÉÊèèËø∞‰∫ÜË¥®ÈáèÂíåË∑ùÁ¶ª‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂÆÉË°®ÊòéÔºå‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõ‰∏éÂÆÉ‰ª¨ÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉ‰ª¨‰πãÈó¥ÁöÑË∑ùÁ¶ªÁöÑÂπ≥ÊñπÊàêÂèçÊØî„ÄÇËøô‰∏™ÂÆöÂæãÂØπ‰∫éËß£ÈáäÂÆáÂÆô‰∏≠ÁöÑËÆ∏Â§öÁé∞Ë±°ÂíåÁé∞Ë±°‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®ÈùûÂ∏∏ÈáçË¶ÅÔºå‰æãÂ¶ÇË°åÊòüÁªïÂ§™Èò≥ËøêÂä®„ÄÅÊÅíÊòü‰πãÈó¥ÁöÑÂºïÂäõÈÄèÈïúÊïàÂ∫îÁ≠âÁ≠â„ÄÇÂÆÉ‰πüË¢´ÂπøÊ≥õÂ∫îÁî®‰∫éÂ§©ÊñáÂ≠¶„ÄÅÁâ©ÁêÜÂ≠¶ÂíåÂ∑•Á®ãÂ≠¶Á≠âÈ¢ÜÂüüÔºå‰∏∫Êàë‰ª¨ÁêÜËß£ÂÆáÂÆôÁöÑÊú¨Ë¥®ÂíåÊºîÂåñÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÁêÜËÆ∫Âü∫Á°Ä„ÄÇ


[Q]: ‰Ω†Áü•ÈÅìÂ§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØ‰ªÄ‰πàÂêóÔºü
[A]: Â§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£üÔºå‰ΩÜ‰πü‰ºöÂêÉÂÖ∂‰ªñÊ§çÁâ©„ÄÅÊòÜËô´„ÄÅÂ∞èÂûãÂì∫‰π≥Âä®Áâ©ÂíåÈ±ºÁ±ª„ÄÇÂÆÉ‰ª¨ÁöÑÊ∂àÂåñÁ≥ªÁªü‰∏éÂÖ∂‰ªñÁÜäÁßëÂä®Áâ©Á±ª‰ººÔºåËÉΩÂ§üÊ∂àÂåñÁ´πÂ≠ê„ÄÇÂ§ßÁÜäÁå´ÁöÑÁâôÈΩøÈîãÂà©ÔºåÈÄÇÂêàÂíÄÂöºÁ´πÂ≠êÔºåÂõ†Ê≠§ÂÆÉ‰ª¨ÁªèÂ∏∏Ë¢´Áß∞‰∏∫‚ÄúÁ´πÈ£üÂä®Áâ©‚Äù„ÄÇ
[B]: Â§ßÁÜäÁå´ÊòØ‰ª•Á´πÂ≠ê‰∏∫È£üÁöÑÂì∫‰π≥Âä®Áâ©ÔºåÂÆÉ‰ª¨ÊòØËÇâÈ£üÂä®Áâ©„ÄÇÂÆÉ‰ª¨‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠êÔºåÁâπÂà´ÊòØÁ´πÂ≠ê‰∏≠ÂØåÂê´Á∫§Áª¥Á¥†ÂíåÁüøÁâ©Ë¥®ÔºåÂπ∂‰∏î‰∏ç‰ºöÁõ¥Êé•ËøõÂÖ•Ê∂àÂåñÁ≥ªÁªü„ÄÇÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅì‰∏ªË¶ÅÁî±Á´πÂ≠êÁªÑÊàêÔºåÂÆÉ‰ª¨ÈúÄË¶ÅÊ∂àÂåñÁ´πÂ≠ê‰∏≠ÁöÑÁ∫§Áª¥Á¥†ÂíåÂÖ∂‰ªñÁ∫§Áª¥Á¥†Êù•ÊîØÊåÅÂÆÉ‰ª¨ÁöÑÊ≠£Â∏∏ËøõÈ£ü„ÄÇ
[C]: Â§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£üÔºå‰ΩÜÂÆÉ‰ª¨‰πüÂêÉÂÖ∂‰ªñÊ§çÁâ©ÔºåÂåÖÊã¨Ê†ëÂè∂„ÄÅÂ´©ËäΩ„ÄÅÊòÜËô´„ÄÅÊ∞¥Êûú„ÄÅËî¨ËèúÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©Á≠â„ÄÇÂ§ßÁÜäÁå´ÊòØ‰∏≠ÂõΩÁâπÊúâÁöÑÁâ©ÁßçÔºåÂ±û‰∫éÁÜäÁßëÔºå‰∏ªË¶ÅÂàÜÂ∏ÉÂú®‰∏≠ÂõΩÁöÑÂõõÂ∑ù„ÄÅÈôïË•øÂíåÁîòËÇÉÁ≠âÂú∞„ÄÇ
[D]: Â§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠ê„ÄÇÂÆÉ‰ª¨ÈÄöÂ∏∏ÂêÉÁ´πÂ≠êÔºåÊØèÂ§©ÈúÄË¶ÅÂêÉÊéâÂ§ßÁ∫¶30ÂÖ¨Êñ§ÁöÑÁ´πÂ≠ê„ÄÇ
[E]: ÊòØÁöÑÔºåÂ§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£ü„ÄÇÂÆÉ‰ª¨ÊØèÂ§©ÈúÄË¶ÅÂêÉÊéâÂ§ßÈáèÁöÑÁ´πÂ≠êÊù•Áª¥ÊåÅÁîüÂëΩÔºåÊØèÂ§©ÈúÄË¶ÅÂêÉÊéâ40Ëá≥80ÂÖ¨Êñ§ÁöÑÁ´πÂ≠ê„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰ª¨‰πü‰ºöÂêÉ‰∏Ä‰∫õÂÖ∂‰ªñÁöÑÊ§çÁâ©ÔºåÂ¶ÇËçâ„ÄÅÊûúÂÆû„ÄÅÂùöÊûúÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÇ
[F]: Â§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£üÔºå‰πü‰ºöÂÅ∂Â∞îÈ£üÁî®ÂÖ∂‰ªñÁöÑÊ§çÁâ©ÂíåÂä®Áâ©„ÄÇÊ≠§Â§ñÔºåÂ§ßÁÜäÁå´‰πü‰ºöÂêÉ‰∏Ä‰∫õÈáéÊûú„ÄÅÂ∞èÂä®Áâ©ÂíåÊ§çÁâ©Ôºå‰ΩÜËøô‰∫õÈÉΩ‰∏çÂ±û‰∫éÂÆÉ‰ª¨ÁöÑ‰∏ªË¶ÅÈ£üÁâ©Êù•Ê∫ê„ÄÇ
[G]: Â§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠ê„ÄÇ
[H]: Â§ßÁÜäÁå´ÊòØ‰∏ÄÁßç‰ª•Á´πÂ≠ê‰∏∫‰∏ªË¶ÅÈ£üÁâ©ÁöÑÊ§çÈ£üÂä®Áâ©ÔºåÂÆÉ‰ª¨ÁöÑËÇ†ÈÅìÁªìÊûÑÈÄÇÂêàÊ∂àÂåñÁ∫§Áª¥Á¥†Âê´ÈáèÈ´òÁöÑÁ´πÂ≠êÔºå‰ΩÜ‰πü‰ºöÂêÉ‰∏Ä‰∫õÂÖ∂‰ªñÊ§çÁâ©ÔºåÂ¶ÇËçâÊú¨Ê§çÁâ©ÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÇÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅìÁªìÊûÑ‰πüÈÄÇÂ∫î‰∫ÜÈ´òÁ∫§Áª¥ÁöÑÁ´πÂ≠êÔºåËøô‰ΩøÂæóÂÆÉ‰ª¨ËÉΩÂ§üÊ∂àÂåñÂ§ßÈáèÁöÑÁ∫§Áª¥Á¥†Ôºå‰ªéËÄåÂ∏ÆÂä©ÂÆÉ‰ª¨Âú®ÈáéÂ§ñÁîüÂ≠ò„ÄÇÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅì‰∏≠ËøòÂê´Êúâ‰∏ÄÁßçÂè´ÂÅö‚ÄúÁ∫§Áª¥Á¥†ÈÖ∂‚ÄùÁöÑÈÖ∂Á±ªÁâ©Ë¥®ÔºåËøôÁßçÈÖ∂ËÉΩÂ§üÂ∏ÆÂä©Â§ßÁÜäÁå´ÂàÜËß£Á∫§Áª¥Á¥†Ôºå‰ªéËÄåÂ∏ÆÂä©ÂÆÉ‰ª¨Ê∂àÂåñÂ§ßÈáèÁöÑÊ∞¥ÂàÜÂíåËê•ÂÖªÁâ©Ë¥®„ÄÇÊ≠§Â§ñÔºåÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅìËøòÂê´Êúâ‰∏ÄÁßçÂè´ÂÅö‚ÄúÁ∫§Áª¥Á¥†ËõãÁôΩ‚ÄùÁöÑËõãÁôΩË¥®ÔºåËøôÁßçËõãÁôΩË¥®ËÉΩÂ§üÂ∏ÆÂä©Â§ßÁÜäÁå´Áª¥ÊåÅ‰ΩìÂÜÖÁöÑËÉΩÈáèÊ∞¥Âπ≥Ôºå‰ªéËÄåÂ∏ÆÂä©ÂÆÉ‰ª¨Âú®ÈáéÂ§ñÁîüÂ≠ò„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÂ§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠êÔºå‰ΩÜÂÆÉ‰ª¨‰πü‰ºöÂêÉ‰∏Ä‰∫õÂÖ∂‰ªñÊ§çÁâ©ÔºåÂ¶ÇËçâÊú¨Ê§çÁâ©ÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÇ


[Q]: Êµ∑Ê∞¥‰∏∫‰ªÄ‰πàÊòØÂí∏ÁöÑÔºü
[A]: Êµ∑Ê∞¥‰πãÊâÄ‰ª•ÊòØÂí∏ÁöÑÔºå‰∏ªË¶ÅÊòØÁî±‰∫éÂÖ∂‰∏≠ÁöÑÂåñÂ≠¶ÊàêÂàÜ„ÄÇÊµ∑Ê∞¥‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÁüøÁâ©Ë¥®ÂíåÁõêÂàÜÔºåÂÖ∂‰∏≠‰∏ªË¶ÅÊàêÂàÜÊòØÁ°´ÈÖ∏Áõê„ÄÅÁ¢≥ÈÖ∏Áõê„ÄÅÈïÅÁ¶ªÂ≠êÂíåÈíæÁ¶ªÂ≠ê„ÄÇËøô‰∫õÁâ©Ë¥®Âú®È´òÊµìÂ∫¶‰∏ãÔºå‰ºöÊ≤âÊ∑ÄÂú®Êµ∑Ê∞¥‰∏≠ÔºåÂΩ¢ÊàêÊµ∑Ê∞¥„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊµ∑Ê∞¥‰∏≠ÁöÑÁüøÁâ©Ë¥®ÂíåÁõêÂàÜ‰∏ªË¶ÅÊù•Ëá™‰∫éÂ≤©Áü≥„ÄÅÂúüÂ£§„ÄÅÁîüÁâ©Âíå‰∫∫Á±ªÊéíÊ≥ÑÁâ©Á≠â„ÄÇÂ≤©Áü≥ÊòØÊµ∑Ê∞¥ÁöÑÁªÑÊàêÈÉ®ÂàÜÔºå‰∏ªË¶ÅÁî±ÁüøÁâ©Ë¥®ÁªÑÊàêÔºåÂ¶ÇÁü≥Ëã±„ÄÅÈïøÁü≥„ÄÅ‰∫ëÊØçÁ≠â„ÄÇÂúüÂ£§‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÂåñÂ≠¶Áâ©Ë¥®ÔºåÂ¶ÇÊ∞Æ„ÄÅÁ£∑„ÄÅÈíæÁ≠âÔºåËøô‰∫õÁâ©Ë¥®‰ºöÊ∏óÈÄèÂà∞ÂúüÂ£§‰∏≠ÔºåÂΩ¢ÊàêÂúüÂ£§„ÄÇÁîüÁâ©‰ΩìÂÜÖÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ê∫ê‰∫éÊ§çÁâ©ÁöÑÂè∂ÁªøÁ¥†Á≠âËâ≤Á¥†ÔºåËøô‰∫õËâ≤Á¥†‰ºöÂê∏Êî∂Â§™Èò≥ÂÖâ‰∏≠ÁöÑËÉΩÈáèÔºåËΩ¨Âåñ‰∏∫ÁîüÁâ©‰ΩìÂèØ‰ª•Âà©Áî®ÁöÑËÉΩÈáè„ÄÇËÄå‰∫∫Á±ªÊéíÊ≥ÑÁâ©‰∏≠Âê´ÊúâÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ê∫ê‰∫éÁüøÁâ©Ë¥®ÂíåÁ¢≥ÈÖ∏ÁõêÔºåËøô‰∫õÁüøÁâ©Ë¥®Âú®Ê∞¥‰∏≠ÁöÑÊµìÂ∫¶ËæÉÈ´òÔºå‰ºöÂØºËá¥Ê∞¥‰∏≠Ê∫∂Ëß£ÁöÑÁüøÁâ©Ë¥®ÊµìÂ∫¶Â¢ûÂä†ÔºåÂΩ¢ÊàêÊ∞¥‰Ωì‰∏≠ÁöÑÁõêÂàÜ„ÄÇÂõ†Ê≠§ÔºåÊµ∑Ê∞¥‰πãÊâÄ‰ª•ÊòØÂí∏ÁöÑÔºåÊòØÁî±‰∫éÂÖ∂‰∏≠ÁöÑÂåñÂ≠¶ÊàêÂàÜÂíåÁªìÊûÑÁâπÂæÅ„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁüøÁâ©Ë¥®ÂíåÁõêÂàÜ‰∏ªË¶ÅÊù•Ëá™‰∫éÂ≤©Áü≥„ÄÅÂúüÂ£§„ÄÅÁîüÁâ©Âíå‰∫∫Á±ªÊéíÊ≥ÑÁâ©Á≠âÔºåËÄåËøô‰∫õÁâ©Ë¥®ÁöÑÁßØÁ¥ØÂíåÊéíÊ≥Ñ‰ºöÂØºËá¥Êµ∑Ê∞¥ÂëàÁé∞Âá∫Âí∏Âë≥„ÄÇ
[B]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåÂõ†‰∏∫ÂÆÉÂåÖÂê´‰∫ÜÂ§öÁßçÁâ©Ë¥®ÔºåÂåÖÊã¨Ê∞ØÂåñÈí†ÔºàNaClÔºâ„ÄÅÊ∞ØÂåñÈí†ÔºàNaClÔºâ„ÄÅÁ¢≥ÈÖ∏ÁõêÔºàÂ¶ÇÁ°´ÈÖ∏ÁõêÔºâ„ÄÅÊ∞ØÂåñÈí†ÔºàNaClÔºâÂíåÊ∞¥„ÄÇÂí∏Áâ©Ë¥®ÁöÑÊù•Ê∫êÔºöÁõêÊòØÂí∏ÁöÑÂ∏∏ËßÅÊù•Ê∫êÔºåÂê´ÊúâÈíæ„ÄÅÈíô„ÄÅÈïÅ„ÄÅÈíæÁ≠âÁüøÁâ©Ë¥®„ÄÇËøô‰∫õÁüøÁâ©Ë¥®ÈÄöÂ∏∏Êù•Ëá™‰∫éÂú∞‰∏ãÊ∞¥„ÄÅÂú∞‰∏ãÊ∞¥ÊàñÂúüÂ£§‰∏≠ÔºåËøô‰∫õÁüøÁâ©Ë¥®ÁöÑÂê´ÈáèËøú‰Ωé‰∫éÁ∫ØÂáÄÊ∞¥„ÄÇÂí∏Âë≥ÁöÑÂéüÂõ†ÔºöÁõêÁöÑÂí∏Âë≥‰∏ªË¶ÅÊ∫ê‰∫éÂÖ∂Ê∫∂Ëß£‰∫éÊ∞¥‰∏≠ÁöÑÂæÆÂ∞èÈ¢óÁ≤íÁâ©„ÄÇËøô‰∫õÂ∞èÈ¢óÁ≤íÁâ©‰∏ªË¶ÅÈÄöËøáÊ§çÁâ©Ê†πÈÉ®ÂíåÂä®Áâ©‰ΩìÂÜÖÁöÑÂæÆÁîüÁâ©‰º†Êí≠ÔºåÂ¶ÇÊòÜËô´„ÄÅÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÅÈ∏üÁ±ªÂíåÊüê‰∫õÊòÜËô´„ÄÇÁªº‰∏äÊâÄËø∞ÔºåÊµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåÂõ†‰∏∫ÂÆÉÂê´ÊúâÂ§ßÈáèÁöÑÁõêÁ±ªÔºåÂåÖÊã¨ÁüøÁâ©Ë¥®„ÄÅÂ≤©Áü≥„ÄÅÁõê„ÄÅÁüøÁâ©Ë¥®Á≠âÔºåËøô‰∫õÁâ©Ë¥®Âú®Êµ∑Ê∞¥‰∏≠ÁöÑÊµìÂ∫¶È´òÔºåÂØπÂí∏Âë≥ÁöÑ‰∫ßÁîüËæÉÂ§ßÂΩ±Âìç„ÄÇ
[C]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºå‰∏ªË¶ÅÊòØÂõ†‰∏∫ÂÖ∂‰∏≠Âê´ÊúâÂêÑÁßçÁõêÂàÜÔºåÂÖ∂‰∏≠‰ª•Êµ∑Ê∞¥‰∏∫‰∏ªË¶ÅÊàêÂàÜ‰πã‰∏Ä„ÄÇÂΩìÊµ∑Ê∞¥‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÁõêÂàÜÊó∂ÔºåÁõêÂàÜ‰ºöË¢´Ê∫∂Ëß£Âú®Êµ∑Ê∞¥‰∏≠ÔºåÂΩ¢ÊàêÂí∏Âë≥„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ê∫ê‰∫éÊ∫∂Ëß£ÁõêÁ±ª„ÄÅËí∏ÂèëÊûêÂá∫ÁöÑÁõêÂíåÊµ∑Ê∞¥ÂÜªÁªìÊàêÂÜ∞Á≠âÂõ†Á¥†„ÄÇ
[D]: Êµ∑Ê∞¥‰∏≠Âê´ÊúâËÆ∏Â§öÁõêÂàÜÔºåËøô‰∫õÁõêÂàÜÂèØ‰ª•ÂØºËá¥Êµ∑Ê∞¥Âí∏Â∫¶ÁöÑÂ¢ûÂä†„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ëá™‰∫éÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜÔºåËøô‰∫õÁõêÂàÜÂèØ‰ª•‰ªéÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜ‰∏≠Ëé∑Âæó„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÊ∞ßÂåñÁâ©ÂíåÁõêÂàÜÂèØ‰ª•‰∏éÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜÂΩ¢ÊàêÊ∞¢ÈîÆÔºå‰ªéËÄå‰ΩøÊµ∑Ê∞¥Âí∏Â∫¶Â¢ûÂä†„ÄÇ
[E]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåËøôÊòØÂõ†‰∏∫ÂÆÉÂê´ÊúâÂ§ßÈáèÁöÑÁõêÂàÜÔºåÂÖ∂‰∏≠ÂåÖÊã¨Ê∞ØÁ¶ªÂ≠êÂíåÊ∞ØÁ¶ªÂ≠ê„ÄÇËøô‰∫õÁ¶ªÂ≠êÂú®Êµ∑Ê¥ã‰∏≠ÂΩ¢Êàê‰∫ÜÂ§ßÈáèÁöÑÁõêÔºåËøô‰∫õÁõêÂàÜË¢´Áß∞‰∏∫ÁõêÂàÜ„ÄÇÊµ∑Ê∞¥‰∏≠Âê´ÊúâËÆ∏Â§öÊ∫∂Ëß£Âú®Ê∞¥‰∏≠ÁöÑÁõêÔºåËøô‰∫õÁõêÂàÜ‰ºöÈöèÁùÄÊµ∑Ê∞¥ÁöÑÂçáÈ´òËÄåÈÄêÊ∏êËí∏ÂèëÔºåÊúÄÁªàÂØºËá¥Êµ∑Ê∞¥‰∏≠ÁõêÂàÜÁöÑËí∏Âèë„ÄÇËøô‰∫õÁõêÂàÜÂú®Êµ∑Ê∞¥‰∏≠Ë¢´ÂÆåÂÖ®Ê∂àËÄóÔºåÁÑ∂ÂêéË¢´ÊéíÈô§Âú®Êµ∑Ê∞¥‰∏≠„ÄÇÊ≠§Â§ñÔºåÊµ∑Ê∞¥‰∏≠ËøòÂê´ÊúâËÆ∏Â§öÂÖ∂‰ªñÁöÑÁõêÂàÜÔºå‰ΩÜËøô‰∫õÁõêÂàÜÊòØ‰∏çÂêåÁöÑÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Âú®Ê∞¥‰∏≠ÁöÑÊµÆËµ∑Âíå‰∏ãÈôçËøáÁ®ãÊòØ‰∏çÂêåÁöÑ„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜÊòØ‰ªéÊµ∑Â∫ïÁöÑÂ≤©Áü≥‰∏≠ÊèêÂèñÂá∫Êù•ÁöÑÔºåËøô‰∫õÁõêÂàÜÂú®Êµ∑Ê∞¥‰∏≠ÂèØ‰ª•Ë¢´Âà©Áî®„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÊµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåËøô‰πüÊòØ‰∏∫‰ªÄ‰πàÊµ∑Ê∞¥‰∏≠Âê´ÊúâËÆ∏Â§öÁõêÂàÜÂíåÁõêÂàÜÁöÑÂéüÂõ†„ÄÇ
[F]: Êµ∑Ê∞¥Âê´ÊúâËÆ∏Â§öÊ∫∂Ëß£ÁöÑÁõêÁ±ªÔºåÂÖ∂‰∏≠ÊúÄ‰∏ªË¶ÅÁöÑÊòØÊ∞ØÂåñÈí†„ÄÇÂΩìÊ∞¥‰∏≠Âä†ÂÖ•ÁõêÊó∂ÔºåÁõêÁöÑÂàÜÂ≠ê‰ºö‰∏éÊ∞¥ÂàÜÂ≠êÂèëÁîüÂèçÂ∫îÔºåÂΩ¢ÊàêÊ∞¢Ê∞ßÂåñÈí†ÔºåËøôÊòØ‰∏ÄÁßçÁõê„ÄÇ
[G]: Âõ†‰∏∫Ê∞¥ÊòØËÆ∏Â§öÁîüÁâ©ÁöÑÁîüÂ≠òÊâÄÂøÖÈúÄÁöÑÔºåÂÆÉËÉΩÂ§üÂê∏Êî∂ÂíåÈáäÊîæ‰∫åÊ∞ßÂåñÁ¢≥ÔºåÈáäÊîæÊ∞ßÊ∞îÔºåÁª¥ÊåÅÂ§ßÊ∞î‰∏≠ÁöÑÊ∞¥Ëí∏Ê∞îÔºå‰ª•ÂèäÁª¥ÊåÅÊ∞¥Âæ™ÁéØ„ÄÇÊ∞¥‰∏≠ÁöÑÁõêÁ±ªÂíåÂåñÂ≠¶Áâ©Ë¥®‰ºöÈáäÊîæÂá∫Ê∞ßÊ∞îÔºå‰ΩøÂú∞ÁêÉ‰∏äÁöÑÁîüÁâ©ÂëºÂê∏„ÄÇÊ≠§Â§ñÔºåÊ∞¥ËøòÂÖ∑ÊúâËÆ∏Â§öÂÖ∂‰ªñÂäüËÉΩÔºåÂ¶Ç‰øùÊåÅÊ∞¥Âæ™ÁéØ„ÄÅÁª¥ÊåÅÊ∞¥Âæ™ÁéØ„ÄÅË∞ÉËäÇÊ∞îÂÄôÂíåÁéØÂ¢ÉÁ≠â„ÄÇÊ∞¥ÊòØËÆ∏Â§öÁîüÁâ©ÁîüÂ≠òÊâÄÂøÖÈúÄÁöÑÔºåÂÆÉ‰πüÊòØËÆ∏Â§öËá™ÁÑ∂Áé∞Ë±°ÁöÑÈáçË¶ÅÂü∫Á°Ä„ÄÇ
[H]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑ‰∏ªË¶ÅÂéüÂõ†ÊòØÂõ†‰∏∫ÂÖ∂‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÊ∫∂Ëß£ÁõêÁ±ªÔºåÂÖ∂‰∏≠ÊúÄ‰∏ªË¶ÅÁöÑÊòØÊ∞ØÂåñÈí†ÔºàNaClÔºâ„ÄÇÊ∞ØÂåñÈí†ÊòØ‰∏ÄÁßçÈùûÂ∏∏Â∏∏ËßÅÁöÑÁõêÁ±ªÔºåÂÆÉÂ≠òÂú®‰∫éÂú∞ÁêÉ‰∏äÁöÑÂ§ßÈÉ®ÂàÜÂú∞Âå∫ÔºåÂåÖÊã¨Êµ∑Ê¥ã„ÄÅÊπñÊ≥ä„ÄÅÊ≤≥ÊµÅÂíåÂú∞‰∏ãÊ∞¥„ÄÇÂΩìÊ∞¥‰ªéÊµ∑Ê¥ã‰∏≠Ëí∏ÂèëÊó∂ÔºåÂÆÉ‰ºöÂ∏¶Ëµ∞‰∏ÄÈÉ®ÂàÜÁõêÂàÜÔºå‰ΩøÊµ∑Ê∞¥ÂèòÂæóÂí∏„ÄÇÊ≠§Â§ñÔºåÊµ∑‰∏≠ËøòÂê´ÊúâÂÖ∂‰ªñÊ∫∂Ëß£ÁõêÁ±ªÁöÑÁâ©Ë¥®ÔºåÂ¶ÇÁ°´ÈÖ∏Áõê„ÄÅÁ°´ÈÖ∏ÈïÅ„ÄÅÁ°´ÈÖ∏Èíô„ÄÅÁ°´ÈÖ∏ÈïÅÁõê„ÄÅÁ°´ÈÖ∏ÈïÅÈíæ„ÄÅÁ°´ÈÖ∏ÈïÅÈí†„ÄÅÁ°´ÈÖ∏ÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈí†„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅ


[Q]: ÂÜô‰∏ÄÊÆµpythonÁöÑÂø´ÈÄüÊéíÂ∫è‰ª£Á†Å
[A]: Â•ΩÁöÑÔºå‰ª•‰∏ãÊòØPythonÁöÑÂø´ÈÄüÊéíÂ∫è‰ª£Á†ÅÔºödef quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else:        pivot = arr[len(arr) // 2]        left = [x for x in arr[1:]]        right = [x for x in arr[2:] if x &amp;lt; pivot]        return quick_sort(left) + [pivot] + quick_sort(right)# ÊµãËØï‰ª£Á†Åarr = [3, 6, 8, 10, 1, 2, 1]print(quick_sort(arr))ËøôÊÆµ‰ª£Á†ÅÈ¶ñÂÖàÊ£ÄÊü•Êï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂê¶Â∞è‰∫éÁ≠â‰∫é1„ÄÇÂ¶ÇÊûúÊòØÔºåÈÇ£‰πàÂÆÉÂ∞±ÊåâÁÖß‰ªéÂ∞èÂà∞Â§ßÁöÑÈ°∫Â∫èÊéíÂàó„ÄÇÊé•ÁùÄÔºåÂØπ‰∫éÊï∞ÁªÑÁöÑÊØè‰∏™ÂÖÉÁ¥†ÔºåÂÆÉÊÉ≥Ë¶ÅËøõË°åÈÄíÂΩíÂú∞ÊéíÂ∫èÔºåÁõ¥Âà∞ËææÂà∞ÊéíÂ∫èÁöÑÁªìÊùü‰ΩçÁΩÆ„ÄÇÂ¶ÇÊûúÊï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂ•áÊï∞ÔºåÈÇ£‰πàÂÆÉÂ∞±ÊåâÁÖß‰ªéÂ§ßÂà∞Â∞èÁöÑÈ°∫Â∫èÊéíÂàó„ÄÇÊúÄÂêéÔºåÂπ≥ÂùáÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶ÊòØO(n log n)ÔºåÂÖ∂‰∏≠nÊòØÊï∞ÁªÑÁöÑÈïøÂ∫¶„ÄÇ
[B]: ‰ª•‰∏ãÊòØ‰∏Ä‰∏™‰ΩøÁî®PythonÁöÑÂø´ÈÄüÊéíÂ∫èÁÆóÊ≥ïÁöÑÂÆûÁé∞Ôºödef sort_array(arr):    # ÁîüÊàê‰∏Ä‰∏™ÈöèÊú∫ÊéíÂàó    sorted_array = sorted(arr)    # ËøîÂõûÊéíÂ∫èÂêéÁöÑÂàóË°®    return sorted(arr)# Á§∫‰æãarr = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]# Ë∞ÉÁî®ÂáΩÊï∞sorted_array = sort_array(arr)print("ÂéüÂßãÊï∞ÁªÑÊòØÔºö", sorted_array)ËøôÊÆµ‰ª£Á†ÅÈ¶ñÂÖàÁîüÊàê‰∏Ä‰∏™ÈöèÊú∫ÊéíÂàóÔºåÁÑ∂ÂêéÈÄöËøá‰∏Ä‰∏™ÂàóË°®ÁöÑÈïøÂ∫¶ËøõË°åÊéíÂ∫è„ÄÇÊúÄÂêéÔºåËøîÂõûÊéíÂ∫èÂêéÁöÑÂàóË°®„ÄÇÊ≥®ÊÑèÔºåËøô‰∏™‰ª£Á†Å‰ΩøÁî®‰∫ÜPythonÁöÑÂÜÖÁΩÆsortedÂáΩÊï∞ÂíåÂÜÖÁΩÆÁöÑsorted()ÂáΩÊï∞ÔºåÂÆÉ‰ª¨Âú®Êó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫O(n log n)ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊØîÁõ¥Êé•‰ΩøÁî®sorted()ÂáΩÊï∞Êõ¥Âø´„ÄÇ
[C]: ‰ª•‰∏ãÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊéíÂ∫èÁÆóÊ≥ïÔºåÈÄÇÁî®‰∫éÂ∞èÂûãÊï∞ÁªÑÔºåÂåÖÊã¨Â∞è‰∫éÁ≠â‰∫é5ÁöÑÊï∞ÁªÑ„ÄÇdef quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else    for _ in range(2, 51):        if arr[len(arr) - 1:] is not None:            arr[len(arr) - 1] = arr[len(arr) - 1]                arr[len(arr)] = arr[len(arr)]    return quick_sort(arr)# Á§∫‰æãarr = [3, 5, 1, 4, 1, 2, 1]sorted_arr = quick_sort(arr)print("Sorted array is:", sorted_arr)### ‰ª£Á†ÅËß£ÈáäÔºö1. **ÂáΩÊï∞ÂÆö‰πâ**Ôºöquick_sort ÂáΩÊï∞Êé•Âèó‰∏Ä‰∏™Êï∞ÁªÑ arr ‰Ωú‰∏∫ÂèÇÊï∞„ÄÇ2. **Âæ™ÁéØ**ÔºöÂØπ‰∫é arr ÁöÑÂÖÉÁ¥†Ôºå‰ΩøÁî®ÈÄíÂΩíÊù•ÂÆûÁé∞ÔºåÂç≥‰ªéÂè≥Âà∞Â∑¶ÈÅçÂéÜÊï∞ÁªÑÔºåÂπ∂Â∞ÜÂΩìÂâçÂÖÉÁ¥†‰∏éÊï∞ÁªÑÁöÑÂΩìÂâçÂÖÉÁ¥†‰∫§Êç¢‰ΩçÁΩÆÔºåÁõ¥Âà∞Êï∞ÁªÑËææÂà∞Á©∫ÊàñÊï∞ÁªÑÈïøÂ∫¶Â∞è‰∫éÁ≠â‰∫é arr„ÄÇ3. **ÈÄíÂΩíË∞ÉÁî®**ÔºöÈÅçÂéÜÊï∞ÁªÑÔºåÂ∞ÜÂΩìÂâçÂÖÉÁ¥†‰∏éÊï∞ÁªÑÁöÑÂΩìÂâçÂÖÉÁ¥†ËøõË°å‰∫§Êç¢ÔºåÁõ¥Âà∞Êï∞ÁªÑËææÂà∞Á©∫ÊàñÊï∞ÁªÑÈïøÂ∫¶Â∞è‰∫éÁ≠â‰∫é arr„ÄÇ4. **Ê£ÄÊü•Êï∞ÁªÑÈïøÂ∫¶**Ôºö‰ΩøÁî® if __name__ == "__main__" Ê£ÄÊü•Êï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂê¶Â∞è‰∫é arrÔºåÂ¶ÇÊûúÊòØÔºåÂ∞±Â∞ÜÊï∞ÁªÑ‰ªéËæÉÂ§ßÁöÑÊï∞ÁªÑÁßªÂä®Âà∞Êï∞ÁªÑÁöÑÊú´Â∞æ„ÄÇ5. **ËæìÂá∫ÊéíÂ∫èÂêéÁöÑÁªìÊûú**
[D]: ‰Ωú‰∏∫‰∏Ä‰∏™AIËØ≠Ë®ÄÊ®°ÂûãÔºåÊàëÊó†Ê≥ïÁºñÂÜôPythonÁ®ãÂ∫è„ÄÇ‰ΩÜÊòØÔºåPythonÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÊµÅË°åÁöÑÁºñÁ®ãËØ≠Ë®ÄÔºåÂÆÉÂÖ∑ÊúâËÆ∏Â§ö‰ºòÁßÄÁöÑÂ∫ìÂíåÊ°ÜÊû∂ÔºåÂåÖÊã¨NumPy„ÄÅPandas„ÄÅMatplotlib„ÄÅPandas„ÄÅBandke„ÄÅNormÂíåNKlearnÁ≠â„ÄÇPythonÊúâÂæàÂ§ö‰ºòÁßÄÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∫ìÂíåÊ°ÜÊû∂ÔºåÂèØ‰ª•Áî®‰∫éÂ§ÑÁêÜÂíåÂàÜÊûêÂêÑÁßçÁ±ªÂûãÁöÑÊï∞ÊçÆÔºåÂ¶ÇÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅÈü≥È¢ë„ÄÅËßÜÈ¢ëÁ≠â„ÄÇPythonËøòÂèØ‰ª•Áî®‰∫éÂàõÂª∫ÂêÑÁßçÂ∫îÁî®Á®ãÂ∫èÔºåÂ¶ÇÁΩëÈ°µÊêúÁ¥¢„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÁßëÂ≠¶ËÆ°ÁÆóÁ≠â„ÄÇPythonÈùûÂ∏∏ÁÅµÊ¥ªÔºå‰πüÊîØÊåÅÂ§öÁßçÁºñÁ®ãÈ£éÊ†ºÔºåÂõ†Ê≠§ÂèØ‰ª•ËΩªÊùæÂú∞ÊâæÂà∞ÈÄÇÂêàËá™Â∑±ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ
[E]: ‰Ωú‰∏∫AIËØ≠Ë®ÄÊ®°ÂûãÔºåÊàëÂèØ‰ª•ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ‰ΩÜÊòØÊàëÊó†Ê≥ïËøõË°åÁºñÁ®ãÊìç‰ΩúÔºåÂõ†‰∏∫ÊàëÊó†Ê≥ïÁ°ÆÂÆöÊÇ®ÊÉ≥ÈóÆÁöÑÊòØÂì™ÁßçÁºñÁ®ãËØ≠Ë®Ä„ÄÇËØ∑ÊÇ®Êèê‰æõÊõ¥ÂÖ∑‰ΩìÁöÑÈóÆÈ¢òÔºå‰ª•‰æøÊàëËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ
[F]: Âø´ÈÄüÊéíÂ∫èÔºàQuick SortÔºâÊòØ‰∏ÄÁßçÁÆÄÂçïÁöÑÊéíÂ∫èÁÆóÊ≥ïÔºåÂÆÉÈÄöËøáÂ∞ÜÊï∞ÊçÆÂàíÂàÜ‰∏∫Â∞èÁªÑÔºåÊØèÁªÑÊï∞ÊçÆÊåâÁÖß‰∏ÄÂÆöËßÑÂàôÊéíÂ∫èÔºåÊúÄÁªàÂæóÂà∞‰∏Ä‰∏™ÊúâÂ∫èÊï∞ÁªÑ„ÄÇ
[G]: Â•ΩÁöÑÔºå‰ª•‰∏ãÊòØ‰∏ÄÊÆµÂø´ÈÄüÊéíÂ∫èÁöÑPython‰ª£Á†Å```python sorted_print(sorted(sorted(sorted(sorted_print))```ËæìÂá∫ÁªìÊûú‰∏∫Ôºö```[1, 2, 3, 4, 5, 6, 7, 8, 9]```
[H]: Âø´ÈÄüÊéíÂ∫èÊòØ‰∏ÄÁßçÂü∫‰∫éÂàÜÊ≤ªÊÄùÊÉ≥ÁöÑÈ´òÊïàÊéíÂ∫èÁÆóÊ≥ïÔºåÂÆÉÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫ O(n log n)„ÄÇÂÆÉÁöÑÂü∫Êú¨ÊÄùÊÉ≥ÊòØÈÄöËøá‰∏ÄË∂üÊéíÂ∫èÂ∞ÜÂæÖÊéíÂ∫èÂ∫èÂàóÂàíÂàÜ‰∏∫‰∏§‰∏™Â≠êÂ∫èÂàóÔºåÂÖ∂‰∏≠‰∏Ä‰∏™Â≠êÂ∫èÂàóÁöÑÊâÄÊúâÂÖÉÁ¥†ÈÉΩÊØîÂè¶‰∏Ä‰∏™Â≠êÂ∫èÂàóÁöÑÊâÄÊúâÂÖÉÁ¥†Â∞èÔºåÁÑ∂ÂêéÂØπËøô‰∏§‰∏™Â≠êÂ∫èÂàóÂàÜÂà´ÈÄíÂΩíÂú∞ËøõË°åÊéíÂ∫è„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∏™ Python ‰ª£Á†ÅÁ§∫‰æãÔºåÂÆûÁé∞‰∫ÜÂø´ÈÄüÊéíÂ∫èÁÆóÊ≥ïÔºö```pythondef quick_sort(arr):    if len(arr) &amp;gt; 1:        return arr    else: return quick_sort(arr)```ËØ•‰ª£Á†Å‰ΩøÁî®‰∫ÜÈÄíÂΩíÁöÑÊñπÂºèÔºåÈ¶ñÂÖàÂà§Êñ≠Êï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂê¶Â∞è‰∫éÁ≠â‰∫é1ÔºåÂ¶ÇÊûúÊòØÔºåÂàôÁõ¥Êé•ËøîÂõûÊï∞ÁªÑÔºåÂê¶ÂàôÈÄíÂΩíÂú∞ÂØπÊï∞ÁªÑËøõË°åÊéíÂ∫è„ÄÇÂú®ÈÄíÂΩíËøáÁ®ã‰∏≠ÔºåÊàë‰ª¨È¶ñÂÖàÂà§Êñ≠Êï∞ÁªÑÁöÑÁ¨¨‰∏Ä‰∏™ÂÖÉÁ¥†ÊòØÂê¶Â§ß‰∫éÁ≠â‰∫é1ÔºåÂ¶ÇÊûúÊòØÔºåÂàôÂ∞ÜÊï∞ÁªÑ‰∏≠ÁöÑÂÖÉÁ¥†‰∏éÁ¨¨‰∏Ä‰∏™ÂÖÉÁ¥†ËøõË°åÊØîËæÉÔºåÂ¶ÇÊûú‰∏çÁ≠â‰∫é1ÔºåÂàôÂ∞ÜÊï∞ÁªÑ‰∏≠ÁöÑÂÖÉÁ¥†‰∏éÁ¨¨‰∫å‰∏™ÂÖÉÁ¥†ËøõË°åÊØîËæÉÔºå‰ª•Ê≠§Á±ªÊé®ÔºåÁõ¥Âà∞ÊâÄÊúâÂÖÉÁ¥†ÈÉΩË¢´ÊéíÂ∫è„ÄÇËØ•‰ª£Á†ÅÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫ O(n log n)ÔºåÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÂÆûÁî®ÁöÑÊéíÂ∫èÁÆóÊ≥ï„ÄÇ


[Q]: Êà™Ëá≥2025Âπ¥2Êúà9Êó•14Êó∂31ÂàÜÔºåÁîµÂΩ±„ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ¥ØËÆ°Á•®ÊàøÔºàÂê´È¢ÑÂîÆÔºâÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåË∂ÖËøá„ÄäÊòüÁêÉÂ§ßÊàòÔºöÂ§©Ë°åËÄÖÂ¥õËµ∑„ÄãÁöÑÁ•®ÊàøÊàêÁª©ÔºåÊàê‰∏∫È¶ñÈÉ®ËøõÂÖ•ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±„ÄÇËøô‰∏ÄÊàêÂ∞±‰∏ç‰ªÖÊ†áÂøóÁùÄ‰∏≠ÂõΩÁîµÂΩ±Âú®ÂõΩÈôÖÂ∏ÇÂú∫ÁöÑÁ™ÅÁ†¥Ôºå‰πüÂ±ïÁ§∫‰∫Ü‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõÂíåÂ∏ÇÂú∫Âê∏ÂºïÂäõ„ÄÇ‰ªéËøôÊÆµÊñáÂ≠óÊÄªÁªì20Â≠óÁöÑÊëòË¶ÅÁªôÊàë„ÄÇ
[A]: ÁîµÂΩ±„ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ•®ÊàøÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåÊàê‰∏∫È¶ñÈÉ®ËøõÂÖ•ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±„ÄÇËøôÊ†áÂøóÁùÄ‰∏≠ÂõΩÁîµÂΩ±ÁöÑÂõΩÈôÖÁ™ÅÁ†¥Ôºå‰πüÂ±ïÁé∞‰∫Ü‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇ
[B]: 2025Âπ¥2Êúà9Êó•Ôºå‰∏≠ÂõΩÁîµÂΩ±Âú®‰∏ñÁïåËàûÂè∞‰∏äÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåË∂ÖËøá„ÄäÊòüÁêÉÂ§ßÊàòÔºöÂ§©Ë°åËÄÖÂ¥õËµ∑„ÄãÁöÑÁ•®ÊàøÊàêÁª©„ÄÇ
[C]: ÁîµÂΩ±„ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ•®ÊàøÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåÊàê‰∏∫ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±ÔºåÂ±ïÁé∞‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇ
[D]: „ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ¥ØËÆ°Á•®ÊàøÁ™ÅÁ†¥78.09‰∫øÔºåÊàê‰∏∫È¶ñÈÉ®ËøõÂÖ•ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±ÔºåÂ±ïÁ§∫‰∫Ü‰∏≠ÂõΩÁîµÂΩ±Âú®ÂõΩÈôÖÂ∏ÇÂú∫ÁöÑÁ™ÅÁ†¥ÔºåÂêåÊó∂Â±ïÁ§∫‰∫Ü‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõÂíåÂ∏ÇÂú∫Âê∏ÂºïÂäõ„ÄÇ
[E]: „ÄäÁåõÈæôÂº∫ÔºöÊâìÂºÄ‰∏ñÁïåÂ•áÂπªÂÜíÈô©„ÄãÊàêÂäüÂú∞Ôºå‰∏äÊµ∑ÊàêÂäüÂê∏Âºï‰∫Ü‰ºóÂ§öËßÇ‰ºóÔºåÂêåÊó∂‰πüÂºïËµ∑‰∫ÜÂπøÊ≥õÁöÑÂÖ≥Ê≥®„ÄÇ
[F]: „ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÊòØ‰∏ÄÈÉ®ËÆ©‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±Êàê‰∏∫ÂõΩÈôÖÂ∏ÇÂú∫ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇËØ•ÁîµÂΩ±‰ª•ÂÖ∂Âçé‰∏ΩÁöÑÁîªÈù¢ÂíåÊÉäÈô©ÁöÑÊàòÊñóÂú∫Èù¢ËÄåÈóªÂêç‰∫é‰∏ñ„ÄÇ
[G]: „ÄäÂì™Ë°åÊòØÂÄºÂæóÁöÑ„ÄãÊòØ2021Âπ¥1Êúà9Êó•14Êó∂31ÂàÜÔºåÁîµÂΩ±„ÄäÂì™ÊàêÂ§ß‰Ωú‰∏∫„ÄãÂú®ÁîµÂΩ±Â∏ÇÂú∫Á™ÅÁ†¥7800‰∫øÁæéÂÖÉÔºåÊàê‰∏∫‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÁ™ÅÁ†¥ÔºåÂπ∂Â±ïÁ§∫‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõÂíåÂ∏ÇÂú∫Âê∏ÂºïÂäõ„ÄÇ
[H]: ÊàëÊòØ‰∏Ä‰∏™ÂèÇÊï∞ÂæàÂ∞ëÁöÑAIÊ®°Âûãü•∫ÔºåÁü•ËØÜÂ∫ìËæÉÂ∞ëÔºåÊó†Ê≥ïÁõ¥Êé•ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢òÔºåÊç¢‰∏™ÈóÆÈ¢òËØïËØïÂêßüëã
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;p&gt;üôã‚ÄçÁõ¥Êé•Êää‰ª•‰∏äÊâÄÊúâÈóÆÈ¢òÂíåÊ®°ÂûãÁöÑÂõûÁ≠î‰∏¢ÁªôDeepSeek-R1ÔºåËÆ©ÂÆÉÂ∏ÆÂøôÁÇπËØÑÂíåÊéíÂêçÊâìÂàÜÔºö&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÂÖ∑‰ΩìÁÇπËØÑ&lt;/summary&gt; 
 &lt;h3&gt;ËØÑÂàÜÊ†áÂáÜÔºö&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;ÂáÜÁ°ÆÊÄß&lt;/strong&gt;ÔºöÂõûÁ≠îÊòØÂê¶Ê≠£Á°Æ‰∏îÊó†ÊòéÊòæÈîôËØØ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ÂÆåÊï¥ÊÄß&lt;/strong&gt;ÔºöÂõûÁ≠îÊòØÂê¶Ê∂µÁõñ‰∫ÜÈóÆÈ¢òÁöÑÊ†∏ÂøÉË¶ÅÁÇπ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ÈÄªËæëÊÄß&lt;/strong&gt;ÔºöÂõûÁ≠îÊòØÂê¶ÊúâÊù°ÁêÜÔºåÊòØÂê¶Á¨¶ÂêàÈÄªËæë„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;‰ª£Á†ÅË¥®Èáè&lt;/strong&gt;Ôºö‰ª£Á†ÅÊòØÂê¶ËÉΩÊ≠£Â∏∏ËøêË°åÔºåÈÄªËæëÊòØÂê¶Ê∏ÖÊô∞„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;ÁÇπËØÑÔºö&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;AÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îÈùûÂ∏∏ÂÖ®Èù¢Ôºå‰ø°ÊÅØÈáèÂ§ßÔºåÈÄªËæëÊ∏ÖÊô∞ÔºåÂ∞§ÂÖ∂Âú®ÈïøÊ±ü„ÄÅÂ§ßÁÜäÁå´„ÄÅÊµ∑Ê∞¥Âí∏Âë≥Á≠âÈóÆÈ¢ò‰∏äË°®Áé∞‰ºòÂºÇ„ÄÇ‰ª£Á†ÅËôΩÁÑ∂ÊúâÂ∞èÁëïÁñµÔºå‰ΩÜÊï¥‰ΩìÊÄùË∑ØÊ≠£Á°Æ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÁ®çÊòæÂÜóÈïøÔºå‰ΩÜ‰∏çÂΩ±ÂìçÊï¥‰ΩìË¥®Èáè„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöÁªºÂêàË°®Áé∞ÊúÄ‰Ω≥ÔºåÂæóÂàÜÊúÄÈ´ò„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;HÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®Áè†Á©ÜÊúóÁéõÂ≥∞„ÄÅ‰∏áÊúâÂºïÂäõÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞Âá∫Ëâ≤„ÄÇ‰ª£Á†ÅËôΩÊú™ÂÆåÂÖ®Â±ïÁ§∫Ôºå‰ΩÜËß£ÈáäËæÉ‰∏∫ËØ¶ÁªÜ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÁï•ÊòæÂï∞Âó¶Ôºå‰ΩÜÈÄªËæëÊÄßËæÉÂº∫„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;Ôºö‰ªÖÊ¨°‰∫éAÊ®°ÂûãÔºåË°®Áé∞Á®≥ÂÆö„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;CÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îÁÆÄÊ¥ÅÊòé‰∫ÜÔºåÂ∞§ÂÖ∂Âú®Â§ßÁÜäÁå´„ÄÅÂø´ÈÄüÊéíÂ∫è‰ª£Á†ÅÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞ËæÉÂ•Ω„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÁï•ÊòæÁÆÄÁü≠ÔºåÁº∫‰πèÊ∑±ÂÖ•Ëß£Èáä„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöÊï¥‰ΩìË°®Áé∞‰∏çÈîôÔºå‰ΩÜÁªÜËäÇ‰∏äÁï•ÈÄä‰∫éAÂíåH„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;FÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®ÈïøÊ±ü„ÄÅ‰∏áÊúâÂºïÂäõÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ‰ª£Á†ÅÈÉ®ÂàÜÊúâ‰∏ÄÂÆöÈÄªËæëÊÄß„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠î‰∏çÂ§üÊ∑±ÂÖ•Ôºå‰ª£Á†ÅÂ≠òÂú®‰∏Ä‰∫õÂ∞èÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞‰∏≠ËßÑ‰∏≠Áü©Ôºå‰ªçÊúâÊèêÂçáÁ©∫Èó¥„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;DÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îÂü∫Êú¨ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®‰∏áÊúâÂºïÂäõ„ÄÅÈïøÊ±üÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îËøá‰∫éÁÆÄÁï•Ôºå‰ª£Á†ÅÂ≠òÂú®ÊòéÊòæÈîôËØØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞‰∏ÄËà¨ÔºåÈúÄÊîπËøõ‰ª£Á†ÅÈÉ®ÂàÜ„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;BÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®ÈïøÊ±ü„ÄÅÊµ∑Ê∞¥Âí∏Âë≥Á≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÈÄªËæëÊÄßËæÉÂ∑ÆÔºå‰ª£Á†ÅÂ≠òÂú®ËæÉÂ§ßÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞Âπ≥Âπ≥ÔºåÈúÄËøõ‰∏ÄÊ≠•‰ºòÂåñ„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;EÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®Êµ∑Ê∞¥Âí∏Âë≥„ÄÅÂ§ßÁÜäÁå´Á≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËøá‰∫éÁÆÄÁï•Ôºå‰ª£Á†ÅÈÉ®ÂàÜÂá†‰πéÊó†Ê≥ïËøêË°å„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞‰∏ç‰Ω≥ÔºåÈúÄÂ§ßÂπÖÊèêÂçá„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;GÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂá†‰πéÊ≤°ÊúâÊòéÊòæÁöÑ‰ºòÁÇπ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠î‰∏•ÈáçÂÅèÁ¶ª‰∏ªÈ¢òÔºå‰ª£Á†ÅÈÉ®ÂàÜÂÆåÂÖ®Êó†Ê≥ïËøêË°å„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞ÊúÄÂ∑ÆÔºåÈúÄÂ§ßÂπÖÊîπËøõ„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;hr&gt; 
 &lt;h3&gt;ÊÄªÁªìÔºö&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;AÊ®°Âûã&lt;/strong&gt;Âú®ÂêÑÊñπÈù¢Ë°®Áé∞ÊúÄ‰∏∫Âá∫Ëâ≤ÔºåÂ∞§ÂÖ∂Âú®Â§çÊùÇÈóÆÈ¢òÁöÑÂõûÁ≠î‰∏äÂ±ïÁé∞‰∫ÜÊûÅÈ´òÁöÑÂáÜÁ°ÆÊÄß‰∏éÈÄªËæëÊÄß„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HÊ®°Âûã&lt;/strong&gt;Á¥ßÈöèÂÖ∂ÂêéÔºåË°®Áé∞Á®≥ÂÆöÔºå‰ΩÜÂú®Êüê‰∫õÁªÜËäÇ‰∏äÁï•Êòæ‰∏çË∂≥„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GÊ®°Âûã&lt;/strong&gt;Ë°®Áé∞ÊúÄÂ∑ÆÔºåÂõûÁ≠îÂÅèÁ¶ª‰∏ªÈ¢ò‰∏î‰ª£Á†ÅÊó†Ê≥ïËøêË°åÔºåÈúÄÂ§ßÂπÖÊîπËøõ„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ÊâìÂàÜÊéíÂ∫è&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÊéíÂêç&lt;/th&gt; 
   &lt;th&gt;Ê®°Âûã&lt;/th&gt; 
   &lt;th&gt;ÂáÜÁ°ÆÊÄß (30ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;ÂÆåÊï¥ÊÄß (30ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;ÈÄªËæëÊÄß (20ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;‰ª£Á†ÅË¥®Èáè (20ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;ÊÄªÂàÜ (100ÂàÜ)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;A&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;96&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;H&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;93&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;C&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;89&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;F&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;86&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;D&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;82&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;B&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;78&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;E&lt;/td&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;G&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;42&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üëâ‰∏ªËßÇÊïàÊûúÊÄªÁªì&lt;/h3&gt; 
&lt;p&gt;‰∏™‰∫∫‰∏ªËßÇËØÑ‰ª∑‰∏éDeepSeek-R1Âü∫Êú¨Áõ∏Á¨¶ÔºåÂÖ∂‰∏≠Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MiniMindÁ≥ªÂàóÁöÑÊéíÂ∫èÈùûÂ∏∏Á¨¶ÂêàÁõ¥ËßâÔºåÂèÇÊï∞Ë∂äÂ§ß+ËÆ≠ÁªÉÊï∞ÊçÆË∂äÂÖÖÂàÜËØÑÂàÜË∂äÈ´òÔºåÂπªËßâÂíåÈîôËØØÈÉΩ‰ºöÊØîÂ∞èÊ®°ÂûãËÇâÁúºÂèØËßÅÁöÑÂ•Ω„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HÊ®°ÂûãÁöÑÂõûÁ≠îËÇâÁúºÁúãËµ∑Êù•ÊòØ‰∏çÈîôÁöÑÔºåÂ∞ΩÁÆ°Â≠òÂú®‰∫õËÆ∏ÂπªËßâÁûéÁºñÁöÑÊÉÖÂÜµ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;GÊ®°ÂûãÂèØËÉΩËÆ≠ÁªÉÊï∞ÊçÆ‰∏çÂ§üÂÆåÂ§áÔºåÁªôÂá∫ÁöÑÊùÉÈáçÁªèËøáÊµãËØïÊïàÊûú‰∏ç‰Ω≥„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂÜçÂ§çËØµ‰∏ÄÈÅçÁªè‰πÖ‰∏çË°∞ÁöÑScaling Law: ÂèÇÊï∞Ë∂äÂ§ßÔºåËÆ≠ÁªÉÊï∞ÊçÆË∂äÂ§öÊ®°ÂûãÁöÑÊÄßËÉΩË∂äÂº∫„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;‚Ö¢ Objective Benchmark&lt;/h2&gt; 
&lt;p&gt;‰∏ãÈù¢Â∞±Âà∞ÂñúÈóª‰πêËßÅÁöÑbenchmarkÂà∑Ê¶úÊµãËØïÁéØËäÇÔºåÂ∞±‰∏çÊâæ‰πêÂ≠êÂíåqwen„ÄÅglmÁ∫ßÂà´ÁöÑ‰∏≠ÊñáÊ®°ÂûãÂÅöÂØπÊØî‰∫Ü„ÄÇ ËøôÈáåÈÄâÂèñ‰∫Ü‰∏Ä‰∫õ&amp;lt;1BÁöÑÂæÆÂûãÊ®°ÂûãËøõË°åÊ®™ËØÑÊØîËæÉÔºå ÊµãËØïÈõÜÈÄâÊã©C-Eval„ÄÅCMMLU„ÄÅA-CLUE„ÄÅTMMLU+ËøôÂá†‰∏™Á∫Ø‰∏≠ÊñáËØ≠Ë®ÄÊ¶úÂçï„ÄÇ&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÊµãËØÑÊ°ÜÊû∂&lt;/summary&gt; 
 &lt;p&gt;ÊµãËØÑÊ°ÜÊû∂ÈÄâÊã©&lt;a href="https://github.com/EleutherAI/lm-evaluation-harness"&gt;lm-evaluation&lt;/a&gt;Ôºå ÂÆâË£ÖÂêéÂêØÂä®ÊµãËØïÈùûÂ∏∏Êñπ‰æøÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;lm_eval --model hf --model_args pretrained=&amp;lt;Â°´ÂÜôÊ®°ÂûãË∑ØÂæÑ&amp;gt;,device=cuda,dtype=auto --tasks ceval* --batch_size 8 --trust_remote_code
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;PS: Âú®ËøôÁßçÂÖ®ÊòØÈÄâÊã©È¢òÁöÑÊµãËØÑÈõÜ‰∏≠Ôºå‰∏∫‰∫ÜÈÅøÂÖçÂõûÂ§çÊ†ºÂºèÁöÑÈöæ‰ª•Âõ∫ÂÆöÁöÑÁâπÁÇπÔºå ÊâÄ‰ª•Â∏∏Áî®ÂÅöÊ≥ïÊòØÁõ¥Êé•Êää&lt;code&gt;A&lt;/code&gt;,&lt;code&gt;B&lt;/code&gt;,&lt;code&gt;C&lt;/code&gt;,&lt;code&gt;D&lt;/code&gt;Âõõ‰∏™Â≠óÊØçÂØπÂ∫îtokenÁöÑÈ¢ÑÊµãÊ¶ÇÁéáÂèñÂá∫Êù•ÔºåÂ∞ÜÂÖ∂‰∏≠Ê¶ÇÁéáÊúÄÂ§ßÁöÑÂ≠óÊØç‰∏éÊ†áÂáÜÁ≠îÊ°àËÆ°ÁÆóÊ≠£Á°ÆÁéá„ÄÇ ÈÄâÊã©È¢ò1/4‰π±ÈÄâÁöÑÊ≠£Á°ÆÁéáÊòØ25%ÔºåÁÑ∂ËÄåËøô‰∏™ÈáèÁ∫ßÁöÑÊâÄÊúâÊ®°ÂûãÈÉΩÈõÜ‰∏≠Âú®25ÈôÑËøëÔºåÁîöËá≥ÂæàÂ§öÊó∂ÂÄô‰∏çÂ¶ÇÁûéÈÄâÔºåÊòØ‰∏çÊòØÂÉèÊûÅ‰∫ÜÈ´ò‰∏≠ÂÆåÂΩ¢Â°´Á©∫ÁöÑÊªëÈìÅÂç¢Ê≠£Á°ÆÁéá... MiniMindÊ®°ÂûãÊú¨Ë∫´È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂ∞èÁöÑÂèØÊÄúÔºå‰πüÊ≤°ÊúâÈíàÂØπÊÄßÁöÑÂØπÊµãËØïÈõÜÂÅöÂà∑Ê¶úÂæÆË∞ÉÔºåÂõ†Ê≠§ÁªìÊûúÂõæ‰∏Ä‰πêÂç≥ÂèØÔºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;from&lt;/th&gt; 
   &lt;th&gt;params‚Üì&lt;/th&gt; 
   &lt;th&gt;ceval‚Üë&lt;/th&gt; 
   &lt;th&gt;cm mlu‚Üë&lt;/th&gt; 
   &lt;th&gt;aclue‚Üë&lt;/th&gt; 
   &lt;th&gt;tmmlu+‚Üë&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;26.52&lt;/td&gt; 
   &lt;td&gt;24.42&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;26.37&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.39&lt;/td&gt; 
   &lt;td&gt;24.63&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;26.6&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
   &lt;td&gt;24.83&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/zhanshijinwat/Steel-LLM"&gt;Steel-LLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ZhanShiJin&lt;/td&gt; 
   &lt;td&gt;1121M&lt;/td&gt; 
   &lt;td&gt;24.81&lt;/td&gt; 
   &lt;td&gt;25.32&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;24.39&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openai-community/gpt2-medium"&gt;GPT2-medium&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;360M&lt;/td&gt; 
   &lt;td&gt;23.18&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;18.6&lt;/td&gt; 
   &lt;td&gt;25.19&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;TinyLlama-1.1B-Chat-V1.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;TinyLlama&lt;/td&gt; 
   &lt;td&gt;1100M&lt;/td&gt; 
   &lt;td&gt;25.48&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;25.4&lt;/td&gt; 
   &lt;td&gt;25.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/huggingface/smollm"&gt;SmolLM2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFaceTB&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;24.37&lt;/td&gt; 
   &lt;td&gt;25.02&lt;/td&gt; 
   &lt;td&gt;25.37&lt;/td&gt; 
   &lt;td&gt;25.06&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/BAAI/Aquila-135M-Instruct"&gt;Aquila-Instruct&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;BAAI&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;25.11&lt;/td&gt; 
   &lt;td&gt;25.1&lt;/td&gt; 
   &lt;td&gt;24.43&lt;/td&gt; 
   &lt;td&gt;25.05&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/compare_radar.png" alt="compare_radar"&gt;&lt;/p&gt; 
&lt;h1&gt;üìå ÂÖ∂ÂÆÉ (Others)&lt;/h1&gt; 
&lt;h2&gt;Ê®°ÂûãËΩ¨Êç¢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/convert_model.py"&gt;./scripts/convert_model.py&lt;/a&gt;ÂèØ‰ª•ÂÆûÁé∞&lt;code&gt;torchÊ®°Âûã/transformers&lt;/code&gt;Ê®°Âûã‰πãÈó¥ÁöÑËΩ¨Êç¢&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;Âü∫‰∫éMiniMind-APIÊúçÂä°Êé•Âè£&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/serve_openai_api.py"&gt;./scripts/serve_openai_api.py&lt;/a&gt;ÂÆåÊàê‰∫ÜÂÖºÂÆπopenai-apiÁöÑÊúÄÁÆÄËÅäÂ§©Êé•Âè£ÔºåÊñπ‰æøÂ∞ÜËá™Â∑±ÁöÑÊ®°ÂûãÊé•ÂÖ•Á¨¨‰∏âÊñπUI ‰æãÂ¶ÇFastGPT„ÄÅOpenWebUI„ÄÅDifyÁ≠âÁ≠â„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‰ªé&lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;Huggingface&lt;/a&gt;‰∏ãËΩΩÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÔºåÊñá‰ª∂Ê†ëÔºö&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;MiniMind-Model-Name&amp;gt; (root dir)
‚îú‚îÄ&amp;lt;MiniMind-Model-Name&amp;gt;
|  ‚îú‚îÄ‚îÄ config.json
|  ‚îú‚îÄ‚îÄ generation_config.json
|  ‚îú‚îÄ‚îÄ LMConfig.py
|  ‚îú‚îÄ‚îÄ model.py
|  ‚îú‚îÄ‚îÄ pytorch_model.bin
|  ‚îú‚îÄ‚îÄ special_tokens_map.json
|  ‚îú‚îÄ‚îÄ tokenizer_config.json
|  ‚îú‚îÄ‚îÄ tokenizer.json
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂêØÂä®ËÅäÂ§©ÊúçÂä°Á´Ø&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python serve_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÊµãËØïÊúçÂä°Êé•Âè£&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python chat_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;APIÊé•Âè£Á§∫‰æãÔºåÂÖºÂÆπopenai apiÊ†ºÂºè&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl http://ip:port/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{ 
    "model": "model-identifier",
    "messages": [ 
      { "role": "user", "content": "‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±ÊòØ‰ªÄ‰πàÔºü" }
    ], 
    "temperature": 0.7, 
    "max_tokens": 512,
    "stream": true
}'
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;VLLMÊ®°ÂûãÊé®ÁêÜÔºàÊúçÂä°Ôºâ&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;ÊòØÊûÅÂÖ∂ÊµÅË°åÁöÑÈ´òÊïàÊé®ÁêÜÊ°ÜÊû∂ÔºåÊîØÊåÅÂ§ßÊ®°ÂûãÂø´ÈÄüÈÉ®ÁΩ≤Ôºå‰ºòÂåñÊòæÂ≠òÂà©Áî®‰∏éÂêûÂêêÈáè„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vllm serve ./MiniMind2/ --model-impl transformers --served-model-name "minimind"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊúçÂä°Â∞Ü‰ª•openai apiÂçèËÆÆÂêØÂä®ÔºåÁ´ØÂè£ÈªòËÆ§‰∏∫8000„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êõ¥Â§öÁî®Ê≥ïËØ∑ÂèÇËÄÉÂÆòÊñπËØ¥ÊòéÔΩû&lt;/p&gt; 
&lt;h2&gt;llama.cpp&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;ÊòØ‰∏Ä‰∏™C++Â∫ìÔºå ÂèØ‰ª•Âú®ÂëΩ‰ª§Ë°å‰∏ãÁõ¥Êé•‰ΩøÁî®ÔºåÊîØÊåÅÂ§öÁ∫øÁ®ãÊé®ÁêÜÔºåÊîØÊåÅGPUÂä†ÈÄü„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÂèÇËÄÉÂÆòÊñπ‰ªìÂ∫ìÂÆâË£ÖÂêéÔºåÂú®&lt;code&gt;convert_hf_to_gguf.py&lt;/code&gt; ÔΩû760Ë°åÊèíÂÖ•&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;# Ê∑ªÂä†MiniMind2 tokenizerÊîØÊåÅ
if res is None:
    res = "smollm"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ËΩ¨Êç¢Ëá™ÂÆö‰πâËÆ≠ÁªÉÁöÑminimindÊ®°Âûã -&amp;gt; gguf&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python convert_hf_to_gguf.py ../minimind/MiniMind2/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÈáèÂåñÊ®°Âûã&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-quantize ../minimind/MiniMind2/MiniMind2-109M-F16.gguf ../minimind/MiniMind2/Q4-MiniMind2.gguf Q4_K_M
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂëΩ‰ª§Ë°åÊé®ÁêÜ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-cli -m ../minimind/MiniMind2/MiniMind2-109M-F16.gguf --chat-template chatml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êõ¥Â§öÁî®Ê≥ïËØ∑ÂèÇËÄÉÂÆòÊñπËØ¥ÊòéÔΩû&lt;/p&gt; 
&lt;h2&gt;ollama&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://ollama.ai/"&gt;ollama&lt;/a&gt;ÊòØÊú¨Âú∞ËøêË°åÂ§ßÊ®°ÂûãÁöÑÂ∑•ÂÖ∑ÔºåÊîØÊåÅÂ§öÁßçÂºÄÊ∫êLLMÔºåÁÆÄÂçïÊòìÁî®„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÈÄöËøáollamaÂä†ËΩΩËá™ÂÆö‰πâÁöÑggufÊ®°ÂûãÔºåÊñ∞Âª∫minimind.modelfileÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;FROM ./MiniMind2-109M-F16.gguf
TEMPLATE """{{ if .System }}&amp;lt;|im_start|&amp;gt;system
{{ .System }}&amp;lt;|im_end|&amp;gt;
{{ end }}{{ if .Prompt }}&amp;lt;|im_start|&amp;gt;user
{{ .Prompt }}&amp;lt;|im_end|&amp;gt;
{{ end }}&amp;lt;|im_start|&amp;gt;assistant
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Âä†ËΩΩÊ®°ÂûãÂπ∂ÂëΩÂêç‰∏∫&lt;code&gt;minimind2&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama create -f minimind.modelfile minimind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂêØÂä®Êé®ÁêÜ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;ollama run minimind2
&amp;gt; ‰Ω†Â•ΩÔºåÊàëÊòØMiniMind2Ôºå‰∏Ä‰∏™Âü∫‰∫éxxxxxxxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êõ¥Â§öÁî®Ê≥ïËØ∑ÂèÇËÄÉÂÆòÊñπËØ¥ÊòéÔΩû&lt;/p&gt; 
&lt;h1&gt;üìå Acknowledge&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Â¶ÇÊûúËßâÂæó&lt;code&gt;MiniMindÁ≥ªÂàó&lt;/code&gt;ÂØπÊÇ®ÊúâÊâÄÂ∏ÆÂä©ÔºåÂèØ‰ª•Âú® GitHub ‰∏äÂä†‰∏Ä‰∏™‚≠ê&lt;br&gt; ÁØáÂπÖË∂ÖÈïøÊ∞¥Âπ≥ÊúâÈôêÈöæÂÖçÁ∫∞ÊºèÔºåÊ¨¢ËøéÂú®Issues‰∫§ÊµÅÊåáÊ≠£ÊàñÊèê‰∫§PRÊîπËøõÈ°πÁõÆ&lt;br&gt; ÊÇ®ÁöÑÂ∞èÂ∞èÊîØÊåÅÂ∞±ÊòØÊåÅÁª≠ÊîπËøõÊ≠§È°πÁõÆÁöÑÂä®ÂäõÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ü§ù&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt;Ë¥°ÁåÆËÄÖ&lt;/a&gt;&lt;/h2&gt; 
&lt;!--
&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt;
  &lt;img src="https://contrib.rocks/image?repo=jingyaogong/minimind&amp;v3" /&gt;
&lt;/a&gt;
--&gt; 
&lt;p&gt;&lt;a href="https://github.com/jingyaogong"&gt;&lt;img src="https://avatars.githubusercontent.com/u/62287848" width="70px" height="70px"&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/MuWinds"&gt;&lt;img src="https://avatars.githubusercontent.com/u/93832089" width="70px" height="70px"&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/chuanzhubin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2813798" width="70px" height="70px"&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/iomgaa-ycz"&gt;&lt;img src="https://avatars.githubusercontent.com/u/124225682" width="70px" height="70px"&gt;&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;üòäÈ∏£Ë∞¢&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/ipfgao"&gt;&lt;b&gt;@ipfgao&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/26"&gt;üîóËÆ≠ÁªÉÊ≠•È™§ËÆ∞ÂΩï&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/chuanzhubin"&gt;&lt;b&gt;@chuanzhubin&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/pull/34"&gt;üîó‰ª£Á†ÅÈÄêË°åÊ≥®Èáä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/WangRongsheng"&gt;&lt;b&gt;@WangRongsheng&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/39"&gt;üîóÂ§ßÂûãÊï∞ÊçÆÈõÜÈ¢ÑÂ§ÑÁêÜ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/pengqianhan"&gt;&lt;b&gt;@pengqianhan&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/73"&gt;üîó‰∏Ä‰∏™ÁÆÄÊòéÊïôÁ®ã&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/RyanSunn"&gt;&lt;b&gt;@RyanSunn&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/75"&gt;üîóÊé®ÁêÜËøáÁ®ãÂ≠¶‰π†ËÆ∞ÂΩï&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Nijikadesu"&gt;&lt;b&gt;@Nijikadesu&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/213"&gt;üîó‰ª•‰∫§‰∫íÁ¨îËÆ∞Êú¨ÊñπÂºèÂàÜËß£È°πÁõÆ‰ª£Á†Å&lt;/a&gt;&lt;/p&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;ÂèÇËÄÉÈìæÊé• &amp;amp; ÊÑüË∞¢‰ª•‰∏ã‰ºòÁßÄÁöÑËÆ∫ÊñáÊàñÈ°πÁõÆ&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÊéíÂêç‰∏çÂàÜ‰ªª‰ΩïÂÖàÂêéÈ°∫Â∫è&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;https://github.com/meta-llama/llama3&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/karpathy/llama2.c"&gt;https://github.com/karpathy/llama2.c&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;https://github.com/DLLXW/baby-llama2-chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2405.04434"&gt;(DeepSeek-V2)https://arxiv.org/abs/2405.04434&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;https://github.com/charent/ChatLM-mini-Chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/wdndev/tiny-llm-zh"&gt;https://github.com/wdndev/tiny-llm-zh&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2401.04088"&gt;(Mistral-MoE)https://arxiv.org/pdf/2401.04088&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Tongjilibo/build_MiniLLM_from_scratch"&gt;https://github.com/Tongjilibo/build_MiniLLM_from_scratch&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;https://github.com/jzhang38/TinyLlama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/AI-Study-Han/Zero-Chatgpt"&gt;https://github.com/AI-Study-Han/Zero-Chatgpt&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/xusenlinzy/api-for-open-llm"&gt;https://github.com/xusenlinzy/api-for-open-llm&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;https://github.com/HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ü´∂ÊîØÊåÅËÄÖ&lt;/h2&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/stars/dark/jingyaogong/minimind"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/stars/jingyaogong/minimind"&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/stars/jingyaogong/minimind"&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/network/members"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/forks/dark/jingyaogong/minimind"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/forks/jingyaogong/minimind"&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/forks/jingyaogong/minimind"&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date&amp;amp;theme=dark"&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date"&gt; 
 &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date"&gt; 
&lt;/picture&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>camel-ai/camel</title>
      <link>https://github.com/camel-ai/camel</link>
      <description>&lt;p&gt;üê´ CAMEL: The first and the best multi-agent framework. Finding the Scaling Law of Agents. https://www.camel-ai.org&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://www.camel-ai.org/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/banner.png" alt="Banner"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://camel-ai.github.io/camel/index.html"&gt;&lt;img src="https://img.shields.io/badge/Documentation-EB3ECC" alt="Documentation"&gt;&lt;/a&gt; &lt;a href="https://discord.camel-ai.org/"&gt;&lt;img src="https://img.shields.io/discord/1082486657678311454?logo=discord&amp;amp;labelColor=%20%235462eb&amp;amp;logoColor=%20%23f5f5f5&amp;amp;color=%20%235462eb" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://x.com/CamelAIOrg"&gt;&lt;img src="https://img.shields.io/twitter/follow/CamelAIOrg?style=social" alt="X"&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/CamelAI/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/CamelAI?style=plastic&amp;amp;logo=reddit&amp;amp;label=r%2FCAMEL&amp;amp;labelColor=white" alt="Reddit"&gt;&lt;/a&gt; &lt;a href="https://ghli.org/camel/wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-CamelAIOrg-brightgreen?logo=wechat&amp;amp;logoColor=white" alt="Wechat"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/camel-ai"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-CAMEL--AI-ffc107?color=ffc107&amp;amp;logoColor=white" alt="Hugging Face"&gt;&lt;/a&gt; &lt;a href="https://github.com/camel-ai/camel/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/camel-ai/camel?label=stars&amp;amp;logo=github&amp;amp;color=brightgreen" alt="Star"&gt;&lt;/a&gt; &lt;a href="https://github.com/camel-ai/camel/raw/master/licenses/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="Package License"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/camel-ai"&gt;&lt;img src="https://img.shields.io/pypi/dm/camel-ai" alt="PyPI Download"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/649" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/649" alt="camel-ai/camel | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://github.com/camel-ai/camel#community"&gt;Community&lt;/a&gt; | &lt;a href="https://github.com/camel-ai/camel#installation"&gt;Installation&lt;/a&gt; | &lt;a href="https://github.com/camel-ai/camel/tree/HEAD/examples"&gt;Examples&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2303.17760"&gt;Paper&lt;/a&gt; | &lt;a href="https://github.com/camel-ai/camel#citation"&gt;Citation&lt;/a&gt; | &lt;a href="https://github.com/camel-ai/camel#contributing-to-camel-"&gt;Contributing&lt;/a&gt; | &lt;a href="https://www.camel-ai.org/"&gt;CAMEL-AI&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
 &lt;p style="line-height: 1.5; text-align: center;"&gt; üê´ CAMEL is an open-source community dedicated to finding the scaling laws of agents. We believe that studying these agents on a large scale offers valuable insights into their behaviors, capabilities, and potential risks. To facilitate research in this field, we implement and support various types of agents, tasks, prompts, models, and simulated environments.&lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;Join us (&lt;a href="https://discord.camel-ai.org/"&gt;&lt;em&gt;Discord&lt;/em&gt;&lt;/a&gt; or &lt;a href="https://ghli.org/camel/wechat.png"&gt;&lt;em&gt;WeChat&lt;/em&gt;&lt;/a&gt;) in pushing the boundaries of finding the scaling laws of agents.&lt;/p&gt; 
 &lt;p&gt;üåü Star CAMEL on GitHub and be instantly notified of new releases.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/star.gif" alt="Star" width="186" height="60"&gt;  
&lt;/div&gt; 
&lt;br&gt; 
&lt;h2&gt;CAMEL Framework Design Principles&lt;/h2&gt; 
&lt;h3&gt;üß¨&amp;nbsp;Evolvability&lt;/h3&gt; 
&lt;p&gt;The framework enables multi-agent systems to continuously evolve by generating data and interacting with environments. This evolution can be driven by reinforcement learning with verifiable rewards or supervised learning.&lt;/p&gt; 
&lt;h3&gt;üìà&amp;nbsp;Scalability&lt;/h3&gt; 
&lt;p&gt;The framework is designed to support systems with millions of agents, ensuring efficient coordination, communication, and resource management at scale.&lt;/p&gt; 
&lt;h3&gt;üíæ&amp;nbsp;Statefulness&lt;/h3&gt; 
&lt;p&gt;Agents maintain stateful memory, enabling them to perform multi-step interactions with environments and efficiently tackle sophisticated tasks.&lt;/p&gt; 
&lt;h3&gt;üìñ&amp;nbsp;Code-as-Prompt&lt;/h3&gt; 
&lt;p&gt;Every line of code and comment serves as a prompt for agents. Code should be written clearly and readably, ensuring both humans and agents can interpret it effectively.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Why Use CAMEL for Your Research?&lt;/h2&gt; 
&lt;p&gt;We are a community-driven research collective comprising over 100 researchers dedicated to advancing frontier research in Multi-Agent Systems. Researchers worldwide choose CAMEL for their studies based on the following reasons.&lt;/p&gt; 
&lt;table style="width: 100%;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Large-Scale Agent System&lt;/td&gt; 
   &lt;td align="left"&gt;Simulate up to 1M agents to study emergent behaviors and scaling laws in complex, multi-agent environments.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Dynamic Communication&lt;/td&gt; 
   &lt;td align="left"&gt;Enable real-time interactions among agents, fostering seamless collaboration for tackling intricate tasks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Stateful Memory&lt;/td&gt; 
   &lt;td align="left"&gt;Equip agents with the ability to retain and leverage historical context, improving decision-making over extended interactions.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Support for Multiple Benchmarks&lt;/td&gt; 
   &lt;td align="left"&gt;Utilize standardized benchmarks to rigorously evaluate agent performance, ensuring reproducibility and reliable comparisons.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Support for Different Agent Types&lt;/td&gt; 
   &lt;td align="left"&gt;Work with a variety of agent roles, tasks, models, and environments, supporting interdisciplinary experiments and diverse research applications.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Data Generation and Tool Integration&lt;/td&gt; 
   &lt;td align="left"&gt;Automate the creation of large-scale, structured datasets while seamlessly integrating with multiple tools, streamlining synthetic data generation and research workflows.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br&gt; 
&lt;h2&gt;What Can You Build With CAMEL?&lt;/h2&gt; 
&lt;h3&gt;1. Data Generation&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/raw/master/camel/datagen/cot_datagen.py"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/cot.png" alt="CoT Data Generation"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/tree/master/camel/datagen/self_instruct"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/self_instruct.png" alt="Self-Instruct Data Generation"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/tree/master/camel/datagen/source2synth"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/source2synth.png" alt="Source2Synth Data Generation"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/raw/master/camel/datagen/self_improving_cot.py"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/self_improving.png" alt="Self-Improving Data Generation"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;2. Task Automation&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/raw/master/camel/societies/role_playing.py"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/role_playing.png" alt="Role Playing"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/tree/master/camel/societies/workforce"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/workforce.png" alt="Workforce"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_rag.html"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/rag_pipeline.png" alt="RAG Pipeline"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;3. World Simulation&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/oasis"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/oasis_case.png" alt="Oasis Case"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Installing CAMEL is a breeze thanks to its availability on PyPI. Simply open your terminal and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install camel-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Starting with ChatAgent&lt;/h3&gt; 
&lt;p&gt;This example demonstrates how to create a &lt;code&gt;ChatAgent&lt;/code&gt; using the CAMEL framework and perform a search query using DuckDuckGo.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install the tools package:&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'camel-ai[web_tools]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Set up your OpenAI API key:&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY='your_openai_api_key'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;strong&gt;Run the following Python code:&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from camel.models import ModelFactory
from camel.types import ModelPlatformType, ModelType
from camel.agents import ChatAgent
from camel.toolkits import SearchToolkit

model = ModelFactory.create(
  model_platform=ModelPlatformType.OPENAI,
  model_type=ModelType.GPT_4O,
  model_config_dict={"temperature": 0.0},
)

search_tool = SearchToolkit().search_duckduckgo

agent = ChatAgent(model=model, tools=[search_tool])

response_1 = agent.step("What is CAMEL-AI?")
print(response_1.msgs[0].content)
# CAMEL-AI is the first LLM (Large Language Model) multi-agent framework
# and an open-source community focused on finding the scaling laws of agents.
# ...

response_2 = agent.step("What is the Github link to CAMEL framework?")
print(response_2.msgs[0].content)
# The GitHub link to the CAMEL framework is
# [https://github.com/camel-ai/camel](https://github.com/camel-ai/camel).
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more detailed instructions and additional configuration options, check out the &lt;a href="https://github.com/camel-ai/camel/raw/master/docs/get_started/installation.md"&gt;installation section&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After running, you can explore our CAMEL Tech Stack and Cookbooks at &lt;a href="https://docs.camel-ai.org"&gt;docs.camel-ai.org&lt;/a&gt; to build powerful multi-agent systems.&lt;/p&gt; 
&lt;p&gt;We provide a &lt;a href="https://colab.research.google.com/drive/1AzP33O8rnMW__7ocWJhVBXjKziJXPtim?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Google Colab"&gt;&lt;/a&gt; demo showcasing a conversation between two ChatGPT agents playing roles as a python programmer and a stock trader collaborating on developing a trading bot for stock market.&lt;/p&gt; 
&lt;p&gt;Explore different types of agents, their roles, and their applications.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/create_your_first_agent.html"&gt;Creating Your First Agent&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/create_your_first_agents_society.html"&gt;Creating Your First Agent Society&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/embodied_agents.html"&gt;Embodied Agents&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/critic_agents_and_tree_search.html"&gt;Critic Agents&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Seeking Help&lt;/h3&gt; 
&lt;p&gt;Please reach out to us on &lt;a href="https://discord.camel-ai.org/"&gt;CAMEL discord&lt;/a&gt; if you encounter any issue set up CAMEL.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://docs.camel-ai.org"&gt; &lt;img src="https://camel-ai.github.io/camel_asset/graphics/techstack.png" alt="TechStack"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Key Modules&lt;/h3&gt; 
&lt;p&gt;Core components and utilities to build, operate, and enhance CAMEL-AI agents and societies.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Module&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/agents.html"&gt;Agents&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Core agent architectures and behaviors for autonomous operation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/society.html"&gt;Agent Societies&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Components for building and managing multi-agent systems and collaboration.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/datagen.html"&gt;Data Generation&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Tools and methods for synthetic data creation and augmentation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/models.html"&gt;Models&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Model architectures and customization options for agent intelligence.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/tools.html"&gt;Tools&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Tools integration for specialized agent tasks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/memory.html"&gt;Memory&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Memory storage and retrieval mechanisms for agent state management.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/storages.html"&gt;Storage&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Persistent storage solutions for agent data and states.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/camel/benchmarks"&gt;Benchmarks&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Performance evaluation and testing frameworks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/interpreters.html"&gt;Interpreters&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Code and command interpretation capabilities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/loaders.html"&gt;Data Loaders&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data ingestion and preprocessing tools.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/retrievers.html"&gt;Retrievers&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Knowledge retrieval and RAG components.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/camel/runtime"&gt;Runtime&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Execution environment and process management.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_human_in_loop_and_tool_approval.html"&gt;Human-in-the-Loop&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Interactive components for human oversight and intervention.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h2&gt;Research&lt;/h2&gt; 
&lt;p&gt;We believe that studying these agents on a large scale offers valuable insights into their behaviors, capabilities, and potential risks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Explore our research projects:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://crab.camel-ai.org/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/crab.png" alt="CRAB"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://agent-trust.camel-ai.org/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/agent_trust.png" alt="Agent Trust"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://oasis.camel-ai.org/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/oasis.png" alt="OASIS"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://emos-project.github.io/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/emos.png" alt="Emos"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;h3&gt;Research with US&lt;/h3&gt; 
 &lt;p&gt;We warmly invite you to use CAMEL for your impactful research.&lt;/p&gt; 
 &lt;p&gt;Rigorous research takes time and resources. We are a community-driven research collective with 100+ researchers exploring the frontier research of Multi-agent Systems. Join our ongoing projects or test new ideas with us, &lt;a href="mailto:camel-ai@eigent.ai"&gt;reach out via email&lt;/a&gt; for more information.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/partners.png" alt="Partners"&gt; 
 &lt;/div&gt; 
&lt;/blockquote&gt; 
&lt;br&gt; 
&lt;h2&gt;Synthetic Datasets&lt;/h2&gt; 
&lt;h3&gt;1. Utilize Various LLMs as Backends&lt;/h3&gt; 
&lt;p&gt;For more details, please see our &lt;a href="https://docs.camel-ai.org/key_modules/models.html#"&gt;&lt;code&gt;Models Documentation&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Data (Hosted on Hugging Face)&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dataset&lt;/th&gt; 
   &lt;th&gt;Chat format&lt;/th&gt; 
   &lt;th&gt;Instruction format&lt;/th&gt; 
   &lt;th&gt;Chat format (translated)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI Society&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/ai_society/blob/main/ai_society_chat.tar.gz"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/ai_society/blob/main/ai_society_instructions.json"&gt;Instruction format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/ai_society_translated"&gt;Chat format (translated)&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/code/blob/main/code_chat.tar.gz"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/code/blob/main/code_instructions.json"&gt;Instruction format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Math&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/math"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Physics&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/physics"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Chemistry&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/chemistry"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Biology&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/biology"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2. Visualizations of Instructions and Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dataset&lt;/th&gt; 
   &lt;th&gt;Instructions&lt;/th&gt; 
   &lt;th&gt;Tasks&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI Society&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/3a559a06-87d0-4476-a879-962656242452/db961915-b254-48e8-8e5c-917f827b74c6"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/cb96f41b-a6fd-4fe4-ac40-08e101714483/ae06156c-a572-46e9-8345-ebe18586d02b"&gt;Tasks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/902d6ccb-0bbb-4294-83a8-1c7d2dae03c8/ace2e146-e49f-41db-a1f4-25a2c4be2457"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/efc38617-9180-490a-8630-43a05b35d22d/2576addf-a133-45d5-89a9-6b067b6652dd"&gt;Tasks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Misalignment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/5c491035-a26e-4a05-9593-82ffb2c3ab40/2bd98896-894e-4807-9ed8-a203ccb14d5e"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/abc357dd-9c04-4913-9541-63e259d7ac1f/825139a4-af66-427c-9d0e-f36b5492ab3f"&gt;Tasks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br&gt; 
&lt;h2&gt;Cookbooks (Usecases)&lt;/h2&gt; 
&lt;p&gt;Practical guides and tutorials for implementing specific functionalities in CAMEL-AI agents and societies.&lt;/p&gt; 
&lt;h3&gt;1. Basic Concepts&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/create_your_first_agent.html"&gt;Creating Your First Agent&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A step-by-step guide to building your first agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/create_your_first_agents_society.html"&gt;Creating Your First Agent Society&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn to build a collaborative society of agents.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/agents_message.html"&gt;Message Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Best practices for message handling in agents.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2. Advanced Features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_tools.html"&gt;Tools Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Integrating tools for enhanced functionality.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_memory.html"&gt;Memory Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Implementing memory systems in agents.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_rag.html"&gt;RAG Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Recipes for Retrieval-Augmented Generation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_graph_rag.html"&gt;Graph RAG Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Leveraging knowledge graphs with RAG.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_tracking.html"&gt;Track CAMEL Agents with AgentOps&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Tools for tracking and managing agents in operations.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;3. Model Training &amp;amp; Data Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_Qwen2_5_7B.html"&gt;Data Generation with CAMEL and Finetuning with Unsloth&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn how to generate data with CAMEL and fine-tune models effectively with Unsloth.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.html"&gt;Data Gen with Real Function Calls and Hermes Format&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Explore how to generate data with real function calls and the Hermes format.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.html"&gt;CoT Data Generation and Upload Data to Huggingface&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Uncover how to generate CoT data with CAMEL and seamlessly upload it to Huggingface.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_generation/cot_data_gen_sft_qwen_unsolth_upload_huggingface.html"&gt;CoT Data Generation and SFT Qwen with Unsolth&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Discover how to generate CoT data using CAMEL and SFT Qwen with Unsolth, and seamlessly upload your data and model to Huggingface.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;4. Multi-Agent Systems &amp;amp; Applications&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/applications/roleplaying_scraper.html"&gt;Role-Playing Scraper for Report &amp;amp; Knowledge Graph Generation&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create role-playing agents for data scraping and reporting.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/multi_agent_society/workforce_judge_committee.html"&gt;Create A Hackathon Judge Committee with Workforce&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Building a team of agents for collaborative judging.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/applications/dyamic_knowledge_graph.html"&gt;Dynamic Knowledge Graph Role-Playing: Multi-Agent System with dynamic, temporally-aware knowledge graphs&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Builds dynamic, temporally-aware knowledge graphs for financial applications using a multi-agent system. It processes financial reports, news articles, and research papers to help traders analyze data, identify relationships, and uncover market insights. The system also utilizes diverse and optional element node deduplication techniques to ensure data integrity and optimize graph structure for financial decision-making.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/applications/customer_service_Discord_bot_using_SambaNova_with_agentic_RAG.html"&gt;Customer Service Discord Bot with Agentic RAG&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn how to build a robust customer service bot for Discord using Agentic RAG.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.html"&gt;Customer Service Discord Bot with Local Model&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn how to build a robust customer service bot for Discord using Agentic RAG which supports local deployment.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;5. Data Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_processing/video_analysis.html"&gt;Video Analysis&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Techniques for agents in video data analysis.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_processing/ingest_data_from_websites_with_Firecrawl.html"&gt;3 Ways to Ingest Data from Websites with Firecrawl&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Explore three methods for extracting and processing data from websites using Firecrawl.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.html"&gt;Create AI Agents that work with your PDFs&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn how to create AI agents that work with your PDFs using Chunkr and Mistral AI.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br&gt; 
&lt;h2&gt;Real-World Usecases&lt;/h2&gt; 
&lt;p&gt;Real-world usecases demonstrating how CAMEL‚Äôs multi-agent framework enables real business value across infrastructure automation, productivity workflows, retrieval-augmented conversations, intelligent document/video analysis, and collaborative research.&lt;/p&gt; 
&lt;h3&gt;1 Infrastructure Automation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/aci_mcp"&gt;ACI MCP&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-world usecases demonstrating how CAMEL‚Äôs multi-agent framework enables real business value across infrastructure automation, productivity workflows, retrieval-augmented conversations, intelligent document/video analysis, and collaborative research.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/cloudfare_mcp_camel"&gt;Cloudflare MCP CAMEL&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Intelligent agents manage Cloudflare resources dynamically, enabling scalable and efficient cloud security and performance tuning.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2 Productivity &amp;amp; Business Workflows&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/airbnb_mcp"&gt;Airbnb MCP&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Coordinate agents to optimize and manage Airbnb listings and host operations.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/pptx_toolkit_usecase"&gt;PPTX Toolkit Usecase&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Analyze PowerPoint documents and extract structured insights through multi-agent collaboration.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;3 Retrieval-Augmented Multi-Agent Chat&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/chat_with_github"&gt;Chat with GitHub&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Query and understand GitHub codebases through CAMEL agents leveraging RAG-style workflows, accelerating developer onboarding and codebase navigation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/chat_with_youtube"&gt;Chat with YouTube&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Conversational agents extract and summarize video transcripts, enabling faster content understanding and repurposing.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;4 Video &amp;amp; Document Intelligence&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/youtube_ocr"&gt;YouTube OCR&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Agents perform OCR on video screenshots to summarize visual content, supporting media monitoring and compliance.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/mistral_OCR"&gt;Mistral OCR&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;CAMEL agents use OCR with Mistral to analyze documents, reducing manual effort in document understanding workflows.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;5 Research &amp;amp; Collaboration&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/multi_agent_research_assistant"&gt;Multi-Agent Research Assistant&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simulates a team of research agents collaborating on literature review, improving efficiency in exploratory analysis and reporting.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br&gt; 
&lt;h2&gt;üóìÔ∏è Events&lt;/h2&gt; 
&lt;p&gt;We are actively involved in community events including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üéôÔ∏è &lt;strong&gt;Community Meetings&lt;/strong&gt; ‚Äî Weekly virtual syncs with the CAMEL team&lt;/li&gt; 
 &lt;li&gt;üèÜ &lt;strong&gt;Competitions&lt;/strong&gt; ‚Äî Hackathons, Bounty Tasks and coding challenges hosted by CAMEL&lt;/li&gt; 
 &lt;li&gt;ü§ù &lt;strong&gt;Volunteer Activities&lt;/strong&gt; ‚Äî Contributions, documentation drives, and mentorship&lt;/li&gt; 
 &lt;li&gt;üåç &lt;strong&gt;Ambassador Programs&lt;/strong&gt; ‚Äî Represent CAMEL in your university or local tech groups&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Want to host or participate in a CAMEL event? Join our &lt;a href="https://discord.com/invite/CNcNpquyDc"&gt;Discord&lt;/a&gt; or want to be part of &lt;a href="https://www.camel-ai.org/ambassador"&gt;Ambassador Program&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing to CAMEL&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For those who'd like to contribute code, we appreciate your interest in contributing to our open-source initiative. Please take a moment to review our &lt;a href="https://github.com/camel-ai/camel/raw/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to get started on a smooth collaboration journey.üöÄ&lt;/p&gt; 
 &lt;p&gt;We also welcome you to help CAMEL grow by sharing it on social media, at events, or during conferences. Your support makes a big difference!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br&gt; 
&lt;h2&gt;Community &amp;amp; Contact&lt;/h2&gt; 
&lt;p&gt;For more information please contact &lt;a href="mailto:camel-ai@eigent.ai"&gt;camel-ai@eigent.ai&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub Issues:&lt;/strong&gt; Report bugs, request features, and track development. &lt;a href="https://github.com/camel-ai/camel/issues"&gt;Submit an issue&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Discord:&lt;/strong&gt; Get real-time support, chat with the community, and stay updated. &lt;a href="https://discord.camel-ai.org/"&gt;Join us&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;X (Twitter):&lt;/strong&gt; Follow for updates, AI insights, and key announcements. &lt;a href="https://x.com/CamelAIOrg"&gt;Follow us&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ambassador Project:&lt;/strong&gt; Advocate for CAMEL-AI, host events, and contribute content. &lt;a href="https://www.camel-ai.org/community"&gt;Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;WeChat Community:&lt;/strong&gt; Scan the QR code below to join our WeChat community.&lt;/p&gt; 
  &lt;div align="center"&gt; 
   &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/wechat.jpeg" alt="WeChat QR Code" width="200"&gt; 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@inproceedings{li2023camel,
  title={CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society},
  author={Li, Guohao and Hammoud, Hasan Abed Al Kader and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgment&lt;/h2&gt; 
&lt;p&gt;Special thanks to &lt;a href="https://home.nomic.ai/"&gt;Nomic AI&lt;/a&gt; for giving us extended access to their data set exploration tool (Atlas).&lt;/p&gt; 
&lt;p&gt;We would also like to thank Haya Hammoud for designing the initial logo of our project.&lt;/p&gt; 
&lt;p&gt;We implemented amazing research ideas from other works for you to build, compare and customize your agents. If you use any of these modules, please kindly cite the original works:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;TaskCreationAgent&lt;/code&gt;, &lt;code&gt;TaskPrioritizationAgent&lt;/code&gt; and &lt;code&gt;BabyAGI&lt;/code&gt; from &lt;em&gt;Nakajima et al.&lt;/em&gt;: &lt;a href="https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/"&gt;Task-Driven Autonomous Agent&lt;/a&gt;. [&lt;a href="https://github.com/camel-ai/camel/raw/master/examples/ai_society/babyagi_playing.py"&gt;Example&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;PersonaHub&lt;/code&gt; from &lt;em&gt;Tao Ge et al.&lt;/em&gt;: &lt;a href="https://arxiv.org/pdf/2406.20094"&gt;Scaling Synthetic Data Creation with 1,000,000,000 Personas&lt;/a&gt;. [&lt;a href="https://github.com/camel-ai/camel/raw/master/examples/personas/personas_generation.py"&gt;Example&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Self-Instruct&lt;/code&gt; from &lt;em&gt;Yizhong Wang et al.&lt;/em&gt;: &lt;a href="https://arxiv.org/pdf/2212.10560"&gt;SELF-INSTRUCT: Aligning Language Models with Self-Generated Instructions&lt;/a&gt;. [&lt;a href="https://github.com/camel-ai/camel/raw/master/examples/datagen/self_instruct/self_instruct.py"&gt;Example&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The source code is licensed under Apache 2.0.&lt;/p&gt; 
&lt;br&gt;</description>
    </item>
    
    <item>
      <title>roboflow/supervision</title>
      <link>https://github.com/roboflow/supervision</link>
      <description>&lt;p&gt;We write your reusable computer vision tools. üíú&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://supervision.roboflow.com"&gt; &lt;img width="100%" src="https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529"&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://github.com/roboflow/notebooks"&gt;notebooks&lt;/a&gt; | &lt;a href="https://github.com/roboflow/inference"&gt;inference&lt;/a&gt; | &lt;a href="https://github.com/autodistill/autodistill"&gt;autodistill&lt;/a&gt; | &lt;a href="https://github.com/roboflow/multimodal-maestro"&gt;maestro&lt;/a&gt;&lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://badge.fury.io/py/supervision.svg?sanitize=true" alt="version"&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/supervision"&gt;&lt;img src="https://img.shields.io/pypi/dm/supervision" alt="downloads"&gt;&lt;/a&gt; &lt;a href="https://snyk.io/advisor/python/supervision"&gt;&lt;img src="https://snyk.io/advisor/python/supervision/badge.svg?sanitize=true" alt="snyk"&gt;&lt;/a&gt; &lt;a href="https://github.com/roboflow/supervision/raw/main/LICENSE.md"&gt;&lt;img src="https://img.shields.io/pypi/l/supervision" alt="license"&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/supervision" alt="python-version"&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="colab"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/Roboflow/Annotators"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="gradio"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/GbfgXGJ8Bk"&gt;&lt;img src="https://img.shields.io/discord/1159501506232451173?logo=discord&amp;amp;label=discord&amp;amp;labelColor=fff&amp;amp;color=5865f2&amp;amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk" alt="discord"&gt;&lt;/a&gt; &lt;a href="https://squidfunk.github.io/mkdocs-material/"&gt;&lt;img src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white" alt="built-with-material-for-mkdocs"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/124" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/124" alt="roboflow%2Fsupervision | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;üëã hello&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ü§ù&lt;/p&gt; 
&lt;h2&gt;üíª install&lt;/h2&gt; 
&lt;p&gt;Pip install the supervision package in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.9&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install supervision
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href="https://roboflow.github.io/supervision/"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üî• quickstart&lt;/h2&gt; 
&lt;h3&gt;models&lt;/h3&gt; 
&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href="https://supervision.roboflow.com/latest/detection/core/#detections"&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO("yolov8s.pt")
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;üëâ more model connectors&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href="https://github.com/roboflow/inference"&gt;Inference&lt;/a&gt; requires a &lt;a href="https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key"&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from inference import get_model

image = cv2.imread(...)
model = get_model(model_id="yolov8s-640", api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;annotators&lt;/h3&gt; 
&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href="https://supervision.roboflow.com/latest/detection/annotators/"&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce"&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;datasets&lt;/h3&gt; 
&lt;p&gt;Supervision provides a set of &lt;a href="https://supervision.roboflow.com/latest/datasets/core/"&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&amp;lt;WORKSPACE_ID&amp;gt;).project(&amp;lt;PROJECT_ID&amp;gt;)
dataset = project.version(&amp;lt;PROJECT_VERSION&amp;gt;).download("coco")

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f"{dataset.location}/train",
    annotations_path=f"{dataset.location}/train/_annotations.coco.json",
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
&lt;/code&gt;&lt;/pre&gt; 
&lt;details close&gt; 
 &lt;summary&gt;üëâ more dataset utils&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
# (700, 150, 150)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;ds_1 = sv.DetectionDataset(...)
len(ds_1)
# 100
ds_1.classes
# ['dog', 'person']

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
# ['cat']

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
# 300
ds_merged.classes
# ['cat', 'dog', 'person']
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üé¨ tutorials&lt;/h2&gt; 
&lt;p&gt;Want to learn how to use Supervision? Explore our &lt;a href="https://supervision.roboflow.com/develop/how_to/detect_and_annotate/"&gt;how-to guides&lt;/a&gt;, &lt;a href="https://github.com/roboflow/supervision/tree/develop/examples"&gt;end-to-end examples&lt;/a&gt;, &lt;a href="https://roboflow.github.io/cheatsheet-supervision/"&gt;cheatsheet&lt;/a&gt;, and &lt;a href="https://supervision.roboflow.com/develop/cookbooks/"&gt;cookbooks&lt;/a&gt;!&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1" alt="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.
&lt;p&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91" alt="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;üíú built with supervision&lt;/h2&gt; 
&lt;p&gt;Did you build something cool using supervision? &lt;a href="https://github.com/roboflow/supervision/discussions/categories/built-with-supervision"&gt;Let us know!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4"&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900"&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f"&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìö documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://roboflow.github.io/supervision"&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; 
&lt;h2&gt;üèÜ contribution&lt;/h2&gt; 
&lt;p&gt;We love your input! Please see our &lt;a href="https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started. Thank you üôè to all our contributors!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/roboflow/supervision/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=roboflow/supervision"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://youtube.com/roboflow"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://www.linkedin.com/company/roboflow-ai/"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://docs.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://discuss.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584" width="3%"&gt; &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; &lt;/a&gt;
  &lt;a href="https://blog.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605" width="3%"&gt; &lt;/a&gt;  
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>hiyouga/LLaMA-Factory</title>
      <link>https://github.com/hiyouga/LLaMA-Factory</link>
      <description>&lt;p&gt;Unified Efficient Fine-Tuning of 100+ LLMs &amp; VLMs (ACL 2024)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/logo.png" alt="# LLaMA Factory"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hiyouga/LLaMA-Factory/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social" alt="GitHub Repo stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/hiyouga/LLaMA-Factory/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory" alt="GitHub last commit"&gt;&lt;/a&gt; &lt;a href="https://github.com/hiyouga/LLaMA-Factory/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange" alt="GitHub contributors"&gt;&lt;/a&gt; &lt;a href="https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="GitHub workflow"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/llamafactory/"&gt;&lt;img src="https://img.shields.io/pypi/v/llamafactory" alt="PyPI"&gt;&lt;/a&gt; &lt;a href="https://scholar.google.com/scholar?cites=12620864006390196564"&gt;&lt;img src="https://img.shields.io/badge/citation-730-green" alt="Citation"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/hiyouga/llamafactory/tags"&gt;&lt;img src="https://img.shields.io/docker/pulls/hiyouga/llamafactory" alt="Docker Pulls"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/llamafactory_ai"&gt;&lt;img src="https://img.shields.io/twitter/follow/llamafactory_ai" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/rKfvV9r9FK"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/rKfvV9r9FK?compact=true&amp;amp;style=flat" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://gitcode.com/zhengyaowei/LLaMA-Factory"&gt;&lt;img src="https://gitcode.com/zhengyaowei/LLaMA-Factory/star/badge.svg?sanitize=true" alt="GitCode"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open in Colab"&gt;&lt;/a&gt; &lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory"&gt;&lt;img src="https://gallery.pai-ml.com/assets/open-in-dsw.svg?sanitize=true" alt="Open in DSW"&gt;&lt;/a&gt; &lt;a href="https://docs.alayanew.com/docs/documents/newActivities/llamafactory/?utm_source=LLaMA-Factory"&gt;&lt;img src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/alaya_new.svg?sanitize=true" alt="Open in Alaya"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/hiyouga/LLaMA-Board"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue" alt="Open in Spaces"&gt;&lt;/a&gt; &lt;a href="https://modelscope.cn/studios/hiyouga/LLaMA-Board"&gt;&lt;img src="https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue" alt="Open in Studios"&gt;&lt;/a&gt; &lt;a href="https://novita.ai/templates-library/105981?sharer=88115474-394e-4bda-968e-b88e123d0c47"&gt;&lt;img src="https://img.shields.io/badge/Novita-Deploy%20Template-blue" alt="Open in Novita"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Used by &lt;a href="https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/"&gt;Amazon&lt;/a&gt;, &lt;a href="https://developer.nvidia.com/rtx/ai-toolkit"&gt;NVIDIA&lt;/a&gt;, &lt;a href="https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory"&gt;Aliyun&lt;/a&gt;, etc.&lt;/h3&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;h3&gt;Supporters ‚ù§Ô∏è&lt;/h3&gt; 
 &lt;a href="https://warp.dev/llama-factory"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae"&gt; &lt;/a&gt; 
 &lt;h4&gt;&lt;a href="https://warp.dev/llama-factory"&gt;Warp, the agentic terminal for developers&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;a href="https://warp.dev/llama-factory"&gt;Available for MacOS, Linux, &amp;amp; Windows&lt;/a&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h3&gt;Easily fine-tune 100+ large language models with zero-code &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#quickstart"&gt;CLI&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#fine-tuning-with-llama-board-gui-powered-by-gradio"&gt;Web UI&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4535" alt="GitHub Trend"&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;üëã Join our &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/wechat.jpg"&gt;WeChat group&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/wechat_npu.jpg"&gt;NPU user group&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/wechat_alaya.png"&gt;Alaya NeW user group&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;[ English | &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/README_zh.md"&gt;‰∏≠Êñá&lt;/a&gt; ]&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Fine-tuning a large language model can be easy as...&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e"&gt;https://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Choose your path:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation (WIP)&lt;/strong&gt;: &lt;a href="https://llamafactory.readthedocs.io/en/latest/"&gt;https://llamafactory.readthedocs.io/en/latest/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation (AMD GPU)&lt;/strong&gt;: &lt;a href="https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html"&gt;https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Colab (free)&lt;/strong&gt;: &lt;a href="https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing"&gt;https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Local machine&lt;/strong&gt;: Please refer to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#getting-started"&gt;usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PAI-DSW (free trial)&lt;/strong&gt;: &lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory"&gt;https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alaya NeW (cloud GPU deal)&lt;/strong&gt;: &lt;a href="https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory"&gt;https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#blogs"&gt;Blogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#changelog"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#supported-models"&gt;Supported Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#supported-training-approaches"&gt;Supported Training Approaches&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#provided-datasets"&gt;Provided Datasets&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#requirement"&gt;Requirement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#data-preparation"&gt;Data Preparation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#fine-tuning-with-llama-board-gui-powered-by-gradio"&gt;Fine-Tuning with LLaMA Board GUI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#build-docker"&gt;Build Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#deploy-with-openai-style-api-and-vllm"&gt;Deploy with OpenAI-style API and vLLM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelscope-hub"&gt;Download from ModelScope Hub&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelers-hub"&gt;Download from Modelers Hub&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#use-wb-logger"&gt;Use W&amp;amp;B Logger&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#use-swanlab-logger"&gt;Use SwanLab Logger&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#projects-using-llama-factory"&gt;Projects using LLaMA Factory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#acknowledgement"&gt;Acknowledgement&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Various models&lt;/strong&gt;: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integrated methods&lt;/strong&gt;: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable resources&lt;/strong&gt;: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced algorithms&lt;/strong&gt;: &lt;a href="https://github.com/jiaweizzhao/GaLore"&gt;GaLore&lt;/a&gt;, &lt;a href="https://github.com/Ledzy/BAdam"&gt;BAdam&lt;/a&gt;, &lt;a href="https://github.com/zhuhanqing/APOLLO"&gt;APOLLO&lt;/a&gt;, &lt;a href="https://github.com/zyushun/Adam-mini"&gt;Adam-mini&lt;/a&gt;, &lt;a href="https://github.com/KellerJordan/Muon"&gt;Muon&lt;/a&gt;, DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ and PiSSA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Practical tricks&lt;/strong&gt;: &lt;a href="https://github.com/Dao-AILab/flash-attention"&gt;FlashAttention-2&lt;/a&gt;, &lt;a href="https://github.com/unslothai/unsloth"&gt;Unsloth&lt;/a&gt;, &lt;a href="https://github.com/linkedin/Liger-Kernel"&gt;Liger Kernel&lt;/a&gt;, RoPE scaling, NEFTune and rsLoRA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wide tasks&lt;/strong&gt;: Multi-turn dialogue, tool using, image understanding, visual grounding, video recognition, audio understanding, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Experiment monitors&lt;/strong&gt;: LlamaBoard, TensorBoard, Wandb, MLflow, &lt;a href="https://github.com/SwanHubX/SwanLab"&gt;SwanLab&lt;/a&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Faster inference&lt;/strong&gt;: OpenAI-style API, Gradio UI and CLI with &lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM worker&lt;/a&gt; or &lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang worker&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Day-N Support for Fine-Tuning Cutting-Edge Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Support Date&lt;/th&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Day 0&lt;/td&gt; 
   &lt;td&gt;Qwen3 / Qwen2.5-VL / Gemma 3 / GLM-4.1V / InternLM 3 / MiniCPM-o-2.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Day 1&lt;/td&gt; 
   &lt;td&gt;Llama 3 / GLM-4 / Mistral Small / PaliGemma2 / Llama 4&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Blogs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/"&gt;Fine-tune Llama3.1-70B for Medical Diagnosis using LLaMA-Factory&lt;/a&gt; (Chinese)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/"&gt;A One-Stop Code-Free Model Reinforcement Learning and Deployment Platform based on LLaMA-Factory and EasyR1&lt;/a&gt; (Chinese)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/"&gt;How Apoidea Group enhances visual information extraction from banking documents with multimodal models using LLaMA-Factory on Amazon SageMaker HyperPod&lt;/a&gt; (English)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://buaa-act.feishu.cn/wiki/GVzlwYcRFiR8OLkHbL6cQpYin7g"&gt;Easy Dataset √ó LLaMA Factory: Enabling LLMs to Efficiently Learn Domain Knowledge&lt;/a&gt; (English)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt;
 &lt;summary&gt;All Blogs&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory"&gt;Fine-tune Qwen2.5-VL for Autonomous Driving using LLaMA-Factory&lt;/a&gt; (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b"&gt;LLaMA Factory: Fine-tuning the DeepSeek-R1-Distill-Qwen-7B Model for News Classifier&lt;/a&gt; (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/"&gt;A One-Stop Code-Free Model Fine-Tuning &amp;amp; Deployment Platform based on SageMaker and LLaMA-Factory&lt;/a&gt; (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl"&gt;LLaMA Factory Multi-Modal Fine-Tuning Practice: Fine-Tuning Qwen2-VL for Personal Tourist Guide&lt;/a&gt; (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory"&gt;LLaMA Factory: Fine-tuning Llama3 for Role-Playing&lt;/a&gt; (Chinese)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;[25/07/02] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://github.com/THUDM/GLM-4.1V-Thinking"&gt;GLM-4.1V-9B-Thinking&lt;/a&gt;&lt;/strong&gt; model. Please install transformers from &lt;strong&gt;main&lt;/strong&gt; branch to use.&lt;/p&gt; 
&lt;p&gt;[25/04/28] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;Qwen3&lt;/a&gt;&lt;/strong&gt; model family.&lt;/p&gt; 
&lt;p&gt;[25/04/21] We supported the &lt;strong&gt;&lt;a href="https://github.com/KellerJordan/Muon"&gt;Muon&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage. Thank &lt;a href="https://github.com/tianshijing"&gt;@tianshijing&lt;/a&gt;'s PR.&lt;/p&gt; 
&lt;p&gt;[25/04/16] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/OpenGVLab/InternVL3-8B"&gt;InternVL3&lt;/a&gt;&lt;/strong&gt; model. See &lt;a href="https://github.com/hiyouga/LLaMA-Factory/pull/7258"&gt;PR #7258&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;[25/04/14] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/THUDM/GLM-Z1-9B-0414"&gt;GLM-Z1&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct"&gt;Kimi-VL&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
&lt;p&gt;[25/04/06] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/"&gt;Llama 4&lt;/a&gt;&lt;/strong&gt; model. See &lt;a href="https://github.com/hiyouga/LLaMA-Factory/pull/7611"&gt;PR #7611&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Full Changelog&lt;/summary&gt; 
 &lt;p&gt;[25/03/31] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen2.5-omni/"&gt;Qwen2.5 Omni&lt;/a&gt;&lt;/strong&gt; model. See &lt;a href="https://github.com/hiyouga/LLaMA-Factory/pull/7537"&gt;PR #7537&lt;/a&gt; to get started.&lt;/p&gt; 
 &lt;p&gt;[25/03/15] We supported &lt;strong&gt;&lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt;&lt;/strong&gt; as inference backend. Try &lt;code&gt;infer_backend: sglang&lt;/code&gt; to accelerate inference.&lt;/p&gt; 
 &lt;p&gt;[25/03/12] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/blog/gemma3"&gt;Gemma 3&lt;/a&gt;&lt;/strong&gt; model.&lt;/p&gt; 
 &lt;p&gt;[25/02/24] Announcing &lt;strong&gt;&lt;a href="https://github.com/hiyouga/EasyR1"&gt;EasyR1&lt;/a&gt;&lt;/strong&gt;, an efficient, scalable and multi-modality RL training framework for efficient GRPO training.&lt;/p&gt; 
 &lt;p&gt;[25/02/11] We supported saving the &lt;strong&gt;&lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/strong&gt; modelfile when exporting the model checkpoints. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[25/02/05] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/Qwen/Qwen2-Audio-7B-Instruct"&gt;Qwen2-Audio&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6"&gt;MiniCPM-o-2.6&lt;/a&gt;&lt;/strong&gt; on audio understanding tasks.&lt;/p&gt; 
 &lt;p&gt;[25/01/31] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/deepseek-ai/DeepSeek-R1"&gt;DeepSeek-R1&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct"&gt;Qwen2.5-VL&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
 &lt;p&gt;[25/01/15] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2412.05270"&gt;APOLLO&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[25/01/14] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6"&gt;MiniCPM-o-2.6&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-2_6"&gt;MiniCPM-V-2.6&lt;/a&gt;&lt;/strong&gt; models. Thank &lt;a href="https://github.com/BUAADreamer"&gt;@BUAADreamer&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[25/01/14] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/collections/internlm/"&gt;InternLM 3&lt;/a&gt;&lt;/strong&gt; models. Thank &lt;a href="https://github.com/hhaAndroid"&gt;@hhaAndroid&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[25/01/10] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/microsoft/phi-4"&gt;Phi-4&lt;/a&gt;&lt;/strong&gt; model.&lt;/p&gt; 
 &lt;p&gt;[24/12/21] We supported using &lt;strong&gt;&lt;a href="https://github.com/SwanHubX/SwanLab"&gt;SwanLab&lt;/a&gt;&lt;/strong&gt; for experiment tracking and visualization. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#use-swanlab-logger"&gt;this section&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[24/11/27] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B"&gt;Skywork-o1&lt;/a&gt;&lt;/strong&gt; model and the &lt;strong&gt;&lt;a href="https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT"&gt;OpenO1&lt;/a&gt;&lt;/strong&gt; dataset.&lt;/p&gt; 
 &lt;p&gt;[24/10/09] We supported downloading pre-trained models and datasets from the &lt;strong&gt;&lt;a href="https://modelers.cn/models"&gt;Modelers Hub&lt;/a&gt;&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelers-hub"&gt;this tutorial&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/09/19] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen2.5/"&gt;Qwen2.5&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
 &lt;p&gt;[24/08/30] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen2-vl/"&gt;Qwen2-VL&lt;/a&gt;&lt;/strong&gt; models. Thank &lt;a href="https://github.com/simonJJJ"&gt;@simonJJJ&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[24/08/27] We supported &lt;strong&gt;&lt;a href="https://github.com/linkedin/Liger-Kernel"&gt;Liger Kernel&lt;/a&gt;&lt;/strong&gt;. Try &lt;code&gt;enable_liger_kernel: true&lt;/code&gt; for efficient training.&lt;/p&gt; 
 &lt;p&gt;[24/08/09] We supported &lt;strong&gt;&lt;a href="https://github.com/zyushun/Adam-mini"&gt;Adam-mini&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage. Thank &lt;a href="https://github.com/relic-yuexi"&gt;@relic-yuexi&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[24/07/04] We supported &lt;a href="https://github.com/MeetKai/functionary/tree/main/functionary/train/packing"&gt;contamination-free packed training&lt;/a&gt;. Use &lt;code&gt;neat_packing: true&lt;/code&gt; to activate it. Thank &lt;a href="https://github.com/chuan298"&gt;@chuan298&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[24/06/16] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2404.02948"&gt;PiSSA&lt;/a&gt;&lt;/strong&gt; algorithm. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/06/07] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen2/"&gt;Qwen2&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://github.com/THUDM/GLM-4"&gt;GLM-4&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
 &lt;p&gt;[24/05/26] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2405.14734"&gt;SimPO&lt;/a&gt;&lt;/strong&gt; algorithm for preference learning. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/05/20] We supported fine-tuning the &lt;strong&gt;PaliGemma&lt;/strong&gt; series models. Note that the PaliGemma models are pre-trained models, you need to fine-tune them with &lt;code&gt;paligemma&lt;/code&gt; template for chat completion.&lt;/p&gt; 
 &lt;p&gt;[24/05/18] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2402.01306"&gt;KTO&lt;/a&gt;&lt;/strong&gt; algorithm for preference learning. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/05/14] We supported training and inference on the Ascend NPU devices. Check &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#installation"&gt;installation&lt;/a&gt; section for details.&lt;/p&gt; 
 &lt;p&gt;[24/04/26] We supported fine-tuning the &lt;strong&gt;LLaVA-1.5&lt;/strong&gt; multimodal LLMs. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/04/22] We provided a &lt;strong&gt;&lt;a href="https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing"&gt;Colab notebook&lt;/a&gt;&lt;/strong&gt; for fine-tuning the Llama-3 model on a free T4 GPU. Two Llama-3-derived models fine-tuned using LLaMA Factory are available at Hugging Face, check &lt;a href="https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat"&gt;Llama3-8B-Chinese-Chat&lt;/a&gt; and &lt;a href="https://huggingface.co/zhichen/Llama3-Chinese"&gt;Llama3-Chinese&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[24/04/21] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2404.02258"&gt;Mixture-of-Depths&lt;/a&gt;&lt;/strong&gt; according to &lt;a href="https://github.com/astramind-ai/Mixture-of-depths"&gt;AstraMindAI's implementation&lt;/a&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/04/16] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2404.02827"&gt;BAdam&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/04/16] We supported &lt;strong&gt;&lt;a href="https://github.com/unslothai/unsloth"&gt;unsloth&lt;/a&gt;&lt;/strong&gt;'s long-sequence training (Llama-2-7B-56k within 24GB). It achieves &lt;strong&gt;117%&lt;/strong&gt; speed and &lt;strong&gt;50%&lt;/strong&gt; memory compared with FlashAttention-2, more benchmarks can be found in &lt;a href="https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison"&gt;this page&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;[24/03/31] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2403.07691"&gt;ORPO&lt;/a&gt;&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/21] Our paper "&lt;a href="https://arxiv.org/abs/2403.13372"&gt;LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models&lt;/a&gt;" is available at arXiv!&lt;/p&gt; 
 &lt;p&gt;[24/03/20] We supported &lt;strong&gt;FSDP+QLoRA&lt;/strong&gt; that fine-tunes a 70B model on 2x24GB GPUs. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/13] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2402.12354"&gt;LoRA+&lt;/a&gt;&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/07] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2403.03507"&gt;GaLore&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/07] We integrated &lt;strong&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;&lt;/strong&gt; for faster and concurrent inference. Try &lt;code&gt;infer_backend: vllm&lt;/code&gt; to enjoy &lt;strong&gt;270%&lt;/strong&gt; inference speed.&lt;/p&gt; 
 &lt;p&gt;[24/02/28] We supported weight-decomposed LoRA (&lt;strong&gt;&lt;a href="https://arxiv.org/abs/2402.09353"&gt;DoRA&lt;/a&gt;&lt;/strong&gt;). Try &lt;code&gt;use_dora: true&lt;/code&gt; to activate DoRA training.&lt;/p&gt; 
 &lt;p&gt;[24/02/15] We supported &lt;strong&gt;block expansion&lt;/strong&gt; proposed by &lt;a href="https://github.com/TencentARC/LLaMA-Pro"&gt;LLaMA Pro&lt;/a&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/02/05] Qwen1.5 (Qwen2 beta version) series models are supported in LLaMA-Factory. Check this &lt;a href="https://qwenlm.github.io/blog/qwen1.5/"&gt;blog post&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[24/01/18] We supported &lt;strong&gt;agent tuning&lt;/strong&gt; for most models, equipping model with tool using abilities by fine-tuning with &lt;code&gt;dataset: glaive_toolcall_en&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;[23/12/23] We supported &lt;strong&gt;&lt;a href="https://github.com/unslothai/unsloth"&gt;unsloth&lt;/a&gt;&lt;/strong&gt;'s implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models. Try &lt;code&gt;use_unsloth: true&lt;/code&gt; argument to activate unsloth patch. It achieves &lt;strong&gt;170%&lt;/strong&gt; speed in our benchmark, check &lt;a href="https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison"&gt;this page&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[23/12/12] We supported fine-tuning the latest MoE model &lt;strong&gt;&lt;a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1"&gt;Mixtral 8x7B&lt;/a&gt;&lt;/strong&gt; in our framework. See hardware requirement &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#hardware-requirement"&gt;here&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;[23/12/01] We supported downloading pre-trained models and datasets from the &lt;strong&gt;&lt;a href="https://modelscope.cn/models"&gt;ModelScope Hub&lt;/a&gt;&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelscope-hub"&gt;this tutorial&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[23/10/21] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2310.05914"&gt;NEFTune&lt;/a&gt;&lt;/strong&gt; trick for fine-tuning. Try &lt;code&gt;neftune_noise_alpha: 5&lt;/code&gt; argument to activate NEFTune.&lt;/p&gt; 
 &lt;p&gt;[23/09/27] We supported &lt;strong&gt;$S^2$-Attn&lt;/strong&gt; proposed by &lt;a href="https://github.com/dvlab-research/LongLoRA"&gt;LongLoRA&lt;/a&gt; for the LLaMA models. Try &lt;code&gt;shift_attn: true&lt;/code&gt; argument to enable shift short attention.&lt;/p&gt; 
 &lt;p&gt;[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[23/09/10] We supported &lt;strong&gt;&lt;a href="https://github.com/Dao-AILab/flash-attention"&gt;FlashAttention-2&lt;/a&gt;&lt;/strong&gt;. Try &lt;code&gt;flash_attn: fa2&lt;/code&gt; argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.&lt;/p&gt; 
 &lt;p&gt;[23/08/12] We supported &lt;strong&gt;RoPE scaling&lt;/strong&gt; to extend the context length of the LLaMA models. Try &lt;code&gt;rope_scaling: linear&lt;/code&gt; argument in training and &lt;code&gt;rope_scaling: dynamic&lt;/code&gt; argument at inference to extrapolate the position embeddings.&lt;/p&gt; 
 &lt;p&gt;[23/08/11] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2305.18290"&gt;DPO training&lt;/a&gt;&lt;/strong&gt; for instruction-tuned models. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[23/07/31] We supported &lt;strong&gt;dataset streaming&lt;/strong&gt;. Try &lt;code&gt;streaming: true&lt;/code&gt; and &lt;code&gt;max_steps: 10000&lt;/code&gt; arguments to load your dataset in streaming mode.&lt;/p&gt; 
 &lt;p&gt;[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos (&lt;a href="https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat"&gt;LLaMA-2&lt;/a&gt; / &lt;a href="https://huggingface.co/hiyouga/Baichuan-13B-sft"&gt;Baichuan&lt;/a&gt;) for details.&lt;/p&gt; 
 &lt;p&gt;[23/07/18] We developed an &lt;strong&gt;all-in-one Web UI&lt;/strong&gt; for training, evaluation and inference. Try &lt;code&gt;train_web.py&lt;/code&gt; to fine-tune models in your Web browser. Thank &lt;a href="https://github.com/KanadeSiina"&gt;@KanadeSiina&lt;/a&gt; and &lt;a href="https://github.com/codemayq"&gt;@codemayq&lt;/a&gt; for their efforts in the development.&lt;/p&gt; 
 &lt;p&gt;[23/07/09] We released &lt;strong&gt;&lt;a href="https://github.com/hiyouga/FastEdit"&gt;FastEdit&lt;/a&gt;&lt;/strong&gt; ‚ö°ü©π, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow &lt;a href="https://github.com/hiyouga/FastEdit"&gt;FastEdit&lt;/a&gt; if you are interested.&lt;/p&gt; 
 &lt;p&gt;[23/06/29] We provided a &lt;strong&gt;reproducible example&lt;/strong&gt; of training a chat model using instruction-following datasets, see &lt;a href="https://huggingface.co/hiyouga/Baichuan-7B-sft"&gt;Baichuan-7B-sft&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[23/06/22] We aligned the &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/api_demo.py"&gt;demo API&lt;/a&gt; with the &lt;a href="https://platform.openai.com/docs/api-reference/chat"&gt;OpenAI's&lt;/a&gt; format where you can insert the fine-tuned model in &lt;strong&gt;arbitrary ChatGPT-based applications&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;[23/06/03] We supported quantized training and inference (aka &lt;strong&gt;&lt;a href="https://github.com/artidoro/qlora"&gt;QLoRA&lt;/a&gt;&lt;/strong&gt;). See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you cannot use the latest feature, please pull the latest code and install LLaMA-Factory again.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Model size&lt;/th&gt; 
   &lt;th&gt;Template&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/baichuan-inc"&gt;Baichuan 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B&lt;/td&gt; 
   &lt;td&gt;baichuan2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/bigscience"&gt;BLOOM/BLOOMZ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;560M/1.1B/1.7B/3B/7.1B/176B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/THUDM"&gt;ChatGLM3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;6B&lt;/td&gt; 
   &lt;td&gt;chatglm3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/CohereForAI"&gt;Command R&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;35B/104B&lt;/td&gt; 
   &lt;td&gt;cohere&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/deepseek-ai"&gt;DeepSeek (Code/MoE)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/16B/67B/236B&lt;/td&gt; 
   &lt;td&gt;deepseek&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/deepseek-ai"&gt;DeepSeek 2.5/3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;236B/671B&lt;/td&gt; 
   &lt;td&gt;deepseek3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/deepseek-ai"&gt;DeepSeek R1 (Distill)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5B/7B/8B/14B/32B/70B/671B&lt;/td&gt; 
   &lt;td&gt;deepseekr1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/tiiuae"&gt;Falcon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/11B/40B/180B&lt;/td&gt; 
   &lt;td&gt;falcon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/tiiuae"&gt;Falcon-H1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.5B/1.5B/3B/7B/34B&lt;/td&gt; 
   &lt;td&gt;falcon_h1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/google"&gt;Gemma/Gemma 2/CodeGemma&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2B/7B/9B/27B&lt;/td&gt; 
   &lt;td&gt;gemma/gemma2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/google"&gt;Gemma 3/Gemma 3n&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/4B/6B/8B/12B/27B&lt;/td&gt; 
   &lt;td&gt;gemma3/gemma3n&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org"&gt;GLM-4/GLM-4-0414/GLM-Z1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;9B/32B&lt;/td&gt; 
   &lt;td&gt;glm4/glmz1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org"&gt;GLM-4.1V&lt;/a&gt;*&lt;/td&gt; 
   &lt;td&gt;9B&lt;/td&gt; 
   &lt;td&gt;glm4v&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org"&gt;GLM-4.5&lt;/a&gt;*&lt;/td&gt; 
   &lt;td&gt;106B/355B&lt;/td&gt; 
   &lt;td&gt;glm4_moe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openai-community"&gt;GPT-2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.1B/0.4B/0.8B/1.5B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/ibm-granite"&gt;Granite 3.0-3.3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/2B/3B/8B&lt;/td&gt; 
   &lt;td&gt;granite3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/ibm-granite"&gt;Granite 4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;granite4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/tencent/"&gt;Hunyuan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;hunyuan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/IndexTeam"&gt;Index&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.9B&lt;/td&gt; 
   &lt;td&gt;index&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/internlm"&gt;InternLM 2-3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/8B/20B&lt;/td&gt; 
   &lt;td&gt;intern2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/OpenGVLab"&gt;InternVL 2.5-3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/2B/8B/14B/38B/78B&lt;/td&gt; 
   &lt;td&gt;intern_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/moonshotai"&gt;Kimi-VL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;16B&lt;/td&gt; 
   &lt;td&gt;kimi_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/facebookresearch/llama"&gt;Llama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B/33B/65B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/meta-llama"&gt;Llama 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B/70B&lt;/td&gt; 
   &lt;td&gt;llama2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/meta-llama"&gt;Llama 3-3.3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/3B/8B/70B&lt;/td&gt; 
   &lt;td&gt;llama3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/meta-llama"&gt;Llama 4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;109B/402B&lt;/td&gt; 
   &lt;td&gt;llama4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/meta-llama"&gt;Llama 3.2 Vision&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11B/90B&lt;/td&gt; 
   &lt;td&gt;mllama&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/llava-hf"&gt;LLaVA-1.5&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B&lt;/td&gt; 
   &lt;td&gt;llava&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/llava-hf"&gt;LLaVA-NeXT&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/8B/13B/34B/72B/110B&lt;/td&gt; 
   &lt;td&gt;llava_next&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/llava-hf"&gt;LLaVA-NeXT-Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/34B&lt;/td&gt; 
   &lt;td&gt;llava_next_video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/XiaomiMiMo"&gt;MiMo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;mimo&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openbmb"&gt;MiniCPM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.5B/1B/2B/4B/8B&lt;/td&gt; 
   &lt;td&gt;cpm/cpm3/cpm4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openbmb"&gt;MiniCPM-o-2.6/MiniCPM-V-2.6&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;minicpm_o/minicpm_v&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/mistralai"&gt;Ministral/Mistral-Nemo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B/12B&lt;/td&gt; 
   &lt;td&gt;ministral&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/mistralai"&gt;Mistral/Mixtral&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/8x7B/8x22B&lt;/td&gt; 
   &lt;td&gt;mistral&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/mistralai"&gt;Mistral Small&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;24B&lt;/td&gt; 
   &lt;td&gt;mistral_small&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/allenai"&gt;OLMo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/7B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/google"&gt;PaliGemma/PaliGemma2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/10B/28B&lt;/td&gt; 
   &lt;td&gt;paligemma&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/microsoft"&gt;Phi-1.5/Phi-2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.3B/2.7B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/microsoft"&gt;Phi-3/Phi-3.5&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;4B/14B&lt;/td&gt; 
   &lt;td&gt;phi&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/microsoft"&gt;Phi-3-small&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;phi_small&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/microsoft"&gt;Phi-4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;phi4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/mistralai"&gt;Pixtral&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12B&lt;/td&gt; 
   &lt;td&gt;pixtral&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen (1-2.5) (Code/Math/MoE/QwQ)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.5B/1.5B/3B/7B/14B/32B/72B/110B&lt;/td&gt; 
   &lt;td&gt;qwen&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen3 (MoE)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.6B/1.7B/4B/8B/14B/32B/235B&lt;/td&gt; 
   &lt;td&gt;qwen3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen2-Audio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;qwen2_audio&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen2.5-Omni&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/7B&lt;/td&gt; 
   &lt;td&gt;qwen2_omni&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen2-VL/Qwen2.5-VL/QVQ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2B/3B/7B/32B/72B&lt;/td&gt; 
   &lt;td&gt;qwen2_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/ByteDance-Seed"&gt;Seed Coder&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;seed_coder&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Skywork"&gt;Skywork o1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;skywork_o1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/bigcode"&gt;StarCoder 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/7B/15B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Tele-AI"&gt;TeleChat2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/7B/35B/115B&lt;/td&gt; 
   &lt;td&gt;telechat2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/xverse"&gt;XVERSE&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B/65B&lt;/td&gt; 
   &lt;td&gt;xverse&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/01-ai"&gt;Yi/Yi-1.5 (Code)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5B/6B/9B/34B&lt;/td&gt; 
   &lt;td&gt;yi&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/01-ai"&gt;Yi-VL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;6B/34B&lt;/td&gt; 
   &lt;td&gt;yi_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/IEITYuan"&gt;Yuan 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2B/51B/102B&lt;/td&gt; 
   &lt;td&gt;yuan&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] For the "base" models, the &lt;code&gt;template&lt;/code&gt; argument can be chosen from &lt;code&gt;default&lt;/code&gt;, &lt;code&gt;alpaca&lt;/code&gt;, &lt;code&gt;vicuna&lt;/code&gt; etc. But make sure to use the &lt;strong&gt;corresponding template&lt;/strong&gt; for the "instruct/chat" models.&lt;/p&gt; 
 &lt;p&gt;Remember to use the &lt;strong&gt;SAME&lt;/strong&gt; template in training and inference.&lt;/p&gt; 
 &lt;p&gt;*: You should install the &lt;code&gt;transformers&lt;/code&gt; from main branch and use &lt;code&gt;DISABLE_VERSION_CHECK=1&lt;/code&gt; to skip version check.&lt;/p&gt; 
 &lt;p&gt;**: You need to install a specific version of &lt;code&gt;transformers&lt;/code&gt; to use the corresponding model.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/llamafactory/extras/constants.py"&gt;constants.py&lt;/a&gt; for a full list of models we supported.&lt;/p&gt; 
&lt;p&gt;You also can add a custom chat template to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/llamafactory/data/template.py"&gt;template.py&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Supported Training Approaches&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Approach&lt;/th&gt; 
   &lt;th&gt;Full-tuning&lt;/th&gt; 
   &lt;th&gt;Freeze-tuning&lt;/th&gt; 
   &lt;th&gt;LoRA&lt;/th&gt; 
   &lt;th&gt;QLoRA&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pre-Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Supervised Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Reward Modeling&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KTO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ORPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SimPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The implementation details of PPO can be found in &lt;a href="https://newfacade.github.io/notes-on-reinforcement-learning/17-ppo-trl.html"&gt;this blog&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Provided Datasets&lt;/h2&gt; 
&lt;details&gt;
 &lt;summary&gt;Pre-training datasets&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/wiki_demo.txt"&gt;Wiki Demo (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/tiiuae/falcon-refinedweb"&gt;RefinedWeb (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2"&gt;RedPajama V2 (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/olm/olm-wikipedia-20221220"&gt;Wikipedia (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered"&gt;Wikipedia (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/EleutherAI/pile"&gt;Pile (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Skywork/SkyPile-150B"&gt;SkyPile (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb"&gt;FineWeb (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu"&gt;FineWeb-Edu (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/bigcode/the-stack"&gt;The Stack (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/bigcode/starcoderdata"&gt;StarCoder (en)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Supervised fine-tuning datasets&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/identity.json"&gt;Identity (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;Stanford Alpaca (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-3"&gt;Stanford Alpaca (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM"&gt;Alpaca GPT4 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2"&gt;Glaive Function Calling V2 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/GAIR/lima"&gt;LIMA (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/JosephusCheung/GuanacoDataset"&gt;Guanaco Dataset (multilingual)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/train_2M_CN"&gt;BELLE 2M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/train_1M_CN"&gt;BELLE 1M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/train_0.5M_CN"&gt;BELLE 0.5M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M"&gt;BELLE Dialogue 0.4M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/school_math_0.25M"&gt;BELLE School Math 0.25M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M"&gt;BELLE Multiturn Chat 0.8M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/thunlp/UltraChat"&gt;UltraChat (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/garage-bAInd/Open-Platypus"&gt;OpenPlatypus (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k"&gt;CodeAlpaca 20k (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/QingyiSi/Alpaca-CoT"&gt;Alpaca CoT (multilingual)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Open-Orca/OpenOrca"&gt;OpenOrca (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Open-Orca/SlimOrca"&gt;SlimOrca (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/TIGER-Lab/MathInstruct"&gt;MathInstruct (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M"&gt;Firefly 1.1M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/wiki_qa"&gt;Wiki QA (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/suolyer/webqa"&gt;Web QA (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/zxbsmk/webnovel_cn"&gt;WebNovel (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/berkeley-nest/Nectar"&gt;Nectar (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;deepctrl (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HasturOfficial/adgen"&gt;Advertise Generating (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k"&gt;ShareGPT Hyperfiltered (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/shibing624/sharegpt_gpt4"&gt;ShareGPT4 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k"&gt;UltraChat 200k (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/THUDM/AgentInstruct"&gt;AgentInstruct (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/lmsys/lmsys-chat-1m"&gt;LMSYS Chat 1M (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k"&gt;Evol Instruct V2 (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceTB/cosmopedia"&gt;Cosmopedia (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/hfl/stem_zh_instruction"&gt;STEM (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo"&gt;Ruozhiba (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/m-a-p/neo_sft_phase2"&gt;Neo-sft (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered"&gt;Magpie-Pro-300K-Filtered (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/argilla/magpie-ultra-v0.1"&gt;Magpie-ultra-v0.1 (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/TIGER-Lab/WebInstructSub"&gt;WebInstructSub (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT"&gt;OpenO1-SFT (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k"&gt;Open-Thoughts (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/open-r1/OpenR1-Math-220k"&gt;Open-R1-Math (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT"&gt;Chinese-DeepSeek-R1-Distill (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k"&gt;LLaVA mixed (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions"&gt;Pokemon-gpt4o-captions (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/oasst_de"&gt;Open Assistant (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/dolly-15k_de"&gt;Dolly 15k (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/alpaca-gpt4_de"&gt;Alpaca GPT4 (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/openschnabeltier_de"&gt;OpenSchnabeltier (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/evol-instruct_de"&gt;Evol Instruct (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/dolphin_de"&gt;Dolphin (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/booksum_de"&gt;Booksum (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/airoboros-3.0_de"&gt;Airoboros (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/ultra-chat_de"&gt;Ultrachat (de)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Preference datasets&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k"&gt;DPO mixed (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized"&gt;UltraFeedback (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/m-a-p/COIG-P"&gt;COIG-P (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/openbmb/RLHF-V-Dataset"&gt;RLHF-V (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Zhihui/VLFeedback"&gt;VLFeedback (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset"&gt;RLAIF-V (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Intel/orca_dpo_pairs"&gt;Orca DPO Pairs (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Anthropic/hh-rlhf"&gt;HH-RLHF (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/berkeley-nest/Nectar"&gt;Nectar (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de"&gt;Orca DPO (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/argilla/kto-mix-15k"&gt;KTO mixed (en)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;Some datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade huggingface_hub
huggingface-cli login
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Requirement&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Mandatory&lt;/th&gt; 
   &lt;th&gt;Minimum&lt;/th&gt; 
   &lt;th&gt;Recommend&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;python&lt;/td&gt; 
   &lt;td&gt;3.9&lt;/td&gt; 
   &lt;td&gt;3.10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;torch&lt;/td&gt; 
   &lt;td&gt;2.0.0&lt;/td&gt; 
   &lt;td&gt;2.6.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;torchvision&lt;/td&gt; 
   &lt;td&gt;0.15.0&lt;/td&gt; 
   &lt;td&gt;0.21.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;transformers&lt;/td&gt; 
   &lt;td&gt;4.49.0&lt;/td&gt; 
   &lt;td&gt;4.50.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;datasets&lt;/td&gt; 
   &lt;td&gt;2.16.0&lt;/td&gt; 
   &lt;td&gt;3.2.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;accelerate&lt;/td&gt; 
   &lt;td&gt;0.34.0&lt;/td&gt; 
   &lt;td&gt;1.2.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;peft&lt;/td&gt; 
   &lt;td&gt;0.14.0&lt;/td&gt; 
   &lt;td&gt;0.15.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;trl&lt;/td&gt; 
   &lt;td&gt;0.8.6&lt;/td&gt; 
   &lt;td&gt;0.9.6&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Optional&lt;/th&gt; 
   &lt;th&gt;Minimum&lt;/th&gt; 
   &lt;th&gt;Recommend&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CUDA&lt;/td&gt; 
   &lt;td&gt;11.6&lt;/td&gt; 
   &lt;td&gt;12.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;deepspeed&lt;/td&gt; 
   &lt;td&gt;0.10.0&lt;/td&gt; 
   &lt;td&gt;0.16.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;bitsandbytes&lt;/td&gt; 
   &lt;td&gt;0.39.0&lt;/td&gt; 
   &lt;td&gt;0.43.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vllm&lt;/td&gt; 
   &lt;td&gt;0.4.3&lt;/td&gt; 
   &lt;td&gt;0.8.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;flash-attn&lt;/td&gt; 
   &lt;td&gt;2.5.6&lt;/td&gt; 
   &lt;td&gt;2.7.2&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Requirement&lt;/h3&gt; 
&lt;p&gt;* &lt;em&gt;estimated&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Bits&lt;/th&gt; 
   &lt;th&gt;7B&lt;/th&gt; 
   &lt;th&gt;14B&lt;/th&gt; 
   &lt;th&gt;30B&lt;/th&gt; 
   &lt;th&gt;70B&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;x&lt;/code&gt;B&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full (&lt;code&gt;bf16&lt;/code&gt; or &lt;code&gt;fp16&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;32&lt;/td&gt; 
   &lt;td&gt;120GB&lt;/td&gt; 
   &lt;td&gt;240GB&lt;/td&gt; 
   &lt;td&gt;600GB&lt;/td&gt; 
   &lt;td&gt;1200GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;18x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full (&lt;code&gt;pure_bf16&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;60GB&lt;/td&gt; 
   &lt;td&gt;120GB&lt;/td&gt; 
   &lt;td&gt;300GB&lt;/td&gt; 
   &lt;td&gt;600GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;8x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Freeze/LoRA/GaLore/APOLLO/BAdam&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;16GB&lt;/td&gt; 
   &lt;td&gt;32GB&lt;/td&gt; 
   &lt;td&gt;64GB&lt;/td&gt; 
   &lt;td&gt;160GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QLoRA&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;10GB&lt;/td&gt; 
   &lt;td&gt;20GB&lt;/td&gt; 
   &lt;td&gt;40GB&lt;/td&gt; 
   &lt;td&gt;80GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QLoRA&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;6GB&lt;/td&gt; 
   &lt;td&gt;12GB&lt;/td&gt; 
   &lt;td&gt;24GB&lt;/td&gt; 
   &lt;td&gt;48GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;x/2&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QLoRA&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;16GB&lt;/td&gt; 
   &lt;td&gt;24GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;x/4&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Installation is mandatory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Install from Source&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e ".[torch,metrics]" --no-build-isolation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Extra dependencies available: torch, torch-npu, metrics, deepspeed, liger-kernel, bitsandbytes, hqq, eetq, gptq, aqlm, vllm, sglang, galore, apollo, badam, adam-mini, qwen, minicpm_v, openmind, swanlab, dev&lt;/p&gt; 
&lt;h4&gt;Install from Docker Image&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This image is built on Ubuntu 22.04 (x86_64), CUDA 12.4, Python 3.11, PyTorch 2.6.0, and Flash-attn 2.7.4.&lt;/p&gt; 
&lt;p&gt;Find the pre-built images: &lt;a href="https://hub.docker.com/r/hiyouga/llamafactory/tags"&gt;https://hub.docker.com/r/hiyouga/llamafactory/tags&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#build-docker"&gt;build docker&lt;/a&gt; to build the image yourself.&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Setting up a virtual environment with &lt;b&gt;uv&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Create an isolated Python environment with &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync --extra torch --extra metrics --prerelease=allow
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Run LLaMA-Factory in the isolated environment:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;uv run --prerelease=allow llamafactory-cli train examples/train_lora/llama3_lora_pretrain.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;For Windows users&lt;/summary&gt; 
 &lt;h4&gt;Install PyTorch&lt;/h4&gt; 
 &lt;p&gt;You need to manually install the GPU version of PyTorch on the Windows platform. Please refer to the &lt;a href="https://pytorch.org/get-started/locally/"&gt;official website&lt;/a&gt; and the following command to install PyTorch with CUDA support:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
python -c "import torch; print(torch.cuda.is_available())"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you see &lt;code&gt;True&lt;/code&gt; then you have successfully installed PyTorch with CUDA support.&lt;/p&gt; 
 &lt;p&gt;Try &lt;code&gt;dataloader_num_workers: 0&lt;/code&gt; if you encounter &lt;code&gt;Can't pickle local object&lt;/code&gt; error.&lt;/p&gt; 
 &lt;h4&gt;Install BitsAndBytes&lt;/h4&gt; 
 &lt;p&gt;If you want to enable the quantized LoRA (QLoRA) on the Windows platform, you need to install a pre-built version of &lt;code&gt;bitsandbytes&lt;/code&gt; library, which supports CUDA 11.1 to 12.2, please select the appropriate &lt;a href="https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels"&gt;release version&lt;/a&gt; based on your CUDA version.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Install Flash Attention-2&lt;/h4&gt; 
 &lt;p&gt;To enable FlashAttention-2 on the Windows platform, please use the script from &lt;a href="https://huggingface.co/lldacing/flash-attention-windows-wheel"&gt;flash-attention-windows-wheel&lt;/a&gt; to compile and install it by yourself.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;For Ascend NPU users&lt;/summary&gt; 
 &lt;p&gt;To install LLaMA Factory on Ascend NPU devices, please upgrade Python to version 3.10 or higher and specify extra dependencies: &lt;code&gt;pip install -e ".[torch-npu,metrics]"&lt;/code&gt;. Additionally, you need to install the &lt;strong&gt;&lt;a href="https://www.hiascend.com/developer/download/community/result?module=cann"&gt;Ascend CANN Toolkit and Kernels&lt;/a&gt;&lt;/strong&gt;. Please follow the &lt;a href="https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/softwareinstall/instg/atlasdeploy_03_0031.html"&gt;installation tutorial&lt;/a&gt; or use the following commands:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# replace the url according to your CANN version and devices
# install CANN Toolkit
wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-toolkit_8.0.0.alpha002_linux-"$(uname -i)".run
bash Ascend-cann-toolkit_8.0.0.alpha002_linux-"$(uname -i)".run --install

# install CANN Kernels
wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-kernels-910b_8.0.0.alpha002_linux-"$(uname -i)".run
bash Ascend-cann-kernels-910b_8.0.0.alpha002_linux-"$(uname -i)".run --install

# set env variables
source /usr/local/Ascend/ascend-toolkit/set_env.sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Requirement&lt;/th&gt; 
    &lt;th&gt;Minimum&lt;/th&gt; 
    &lt;th&gt;Recommend&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CANN&lt;/td&gt; 
    &lt;td&gt;8.0.RC1&lt;/td&gt; 
    &lt;td&gt;8.0.0.alpha002&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;torch&lt;/td&gt; 
    &lt;td&gt;2.1.0&lt;/td&gt; 
    &lt;td&gt;2.4.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;torch-npu&lt;/td&gt; 
    &lt;td&gt;2.1.0&lt;/td&gt; 
    &lt;td&gt;2.4.0.post2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;deepspeed&lt;/td&gt; 
    &lt;td&gt;0.13.2&lt;/td&gt; 
    &lt;td&gt;0.13.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;vllm-ascend&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;0.7.3&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;Remember to use &lt;code&gt;ASCEND_RT_VISIBLE_DEVICES&lt;/code&gt; instead of &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt; to specify the device to use.&lt;/p&gt; 
 &lt;p&gt;If you cannot infer model on NPU devices, try setting &lt;code&gt;do_sample: false&lt;/code&gt; in the configurations.&lt;/p&gt; 
 &lt;p&gt;Download the pre-built Docker images: &lt;a href="http://mirrors.cn-central-221.ovaijisuan.com/detail/130.html"&gt;32GB&lt;/a&gt; | &lt;a href="http://mirrors.cn-central-221.ovaijisuan.com/detail/131.html"&gt;64GB&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;Install BitsAndBytes&lt;/h4&gt; 
 &lt;p&gt;To use QLoRA based on bitsandbytes on Ascend NPU, please follow these 3 steps:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Manually compile bitsandbytes: Refer to &lt;a href="https://huggingface.co/docs/bitsandbytes/installation?backend=Ascend+NPU&amp;amp;platform=Ascend+NPU"&gt;the installation documentation&lt;/a&gt; for the NPU version of bitsandbytes to complete the compilation and installation. The compilation requires a cmake version of at least 3.22.1 and a g++ version of at least 12.x.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install bitsandbytes from source
# Clone bitsandbytes repo, Ascend NPU backend is currently enabled on multi-backend-refactor branch
git clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git
cd bitsandbytes/

# Install dependencies
pip install -r requirements-dev.txt

# Install the dependencies for the compilation tools. Note that the commands for this step may vary depending on the operating system. The following are provided for reference
apt-get install -y build-essential cmake

# Compile &amp;amp; install  
cmake -DCOMPUTE_BACKEND=npu -S .
make
pip install .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Install transformers from the main branch.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone -b main https://github.com/huggingface/transformers.git
cd transformers
pip install .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Set &lt;code&gt;double_quantization: false&lt;/code&gt; in the configuration. You can refer to the &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/train_qlora/llama3_lora_sft_bnb_npu.yaml"&gt;example&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h3&gt;Data Preparation&lt;/h3&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/README.md"&gt;data/README.md&lt;/a&gt; for checking the details about the format of dataset files. You can use datasets on HuggingFace / ModelScope / Modelers hub, load the dataset in local disk, or specify a path to s3/gcs cloud storage.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Please update &lt;code&gt;data/dataset_info.json&lt;/code&gt; to use your custom dataset.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You can also use &lt;strong&gt;&lt;a href="https://github.com/ConardLi/easy-dataset"&gt;Easy Dataset&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://github.com/OpenDCAI/DataFlow"&gt;DataFlow&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://github.com/open-sciencelab/GraphGen"&gt;GraphGen&lt;/a&gt;&lt;/strong&gt; to create synthetic data for fine-tuning.&lt;/p&gt; 
&lt;h3&gt;Quickstart&lt;/h3&gt; 
&lt;p&gt;Use the following 3 commands to run LoRA &lt;strong&gt;fine-tuning&lt;/strong&gt;, &lt;strong&gt;inference&lt;/strong&gt; and &lt;strong&gt;merging&lt;/strong&gt; of the Llama3-8B-Instruct model, respectively.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;llamafactory-cli train examples/train_lora/llama3_lora_sft.yaml
llamafactory-cli chat examples/inference/llama3_lora_sft.yaml
llamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples/README.md&lt;/a&gt; for advanced usage (including distributed training).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Use &lt;code&gt;llamafactory-cli help&lt;/code&gt; to show help information.&lt;/p&gt; 
 &lt;p&gt;Read &lt;a href="https://github.com/hiyouga/LLaMA-Factory/issues/4614"&gt;FAQs&lt;/a&gt; first if you encounter any problems.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Fine-Tuning with LLaMA Board GUI (powered by &lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio&lt;/a&gt;)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;llamafactory-cli webui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build Docker&lt;/h3&gt; 
&lt;p&gt;For CUDA users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docker/docker-cuda/
docker compose up -d
docker compose exec llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Ascend NPU users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docker/docker-npu/
docker compose up -d
docker compose exec llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For AMD ROCm users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docker/docker-rocm/
docker compose up -d
docker compose exec llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt;
 &lt;summary&gt;Build without Docker Compose&lt;/summary&gt; 
 &lt;p&gt;For CUDA users:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -f ./docker/docker-cuda/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=metrics \
    -t llamafactory:latest .

docker run -dit --ipc=host --gpus=all \
    -p 7860:7860 \
    -p 8000:8000 \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Ascend NPU users:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -f ./docker/docker-npu/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=torch-npu,metrics \
    -t llamafactory:latest .

docker run -dit --ipc=host \
    -v /usr/local/dcmi:/usr/local/dcmi \
    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \
    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \
    -v /etc/ascend_install.info:/etc/ascend_install.info \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/davinci0 \
    --device /dev/davinci_manager \
    --device /dev/devmm_svm \
    --device /dev/hisi_hdc \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For AMD ROCm users:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -f ./docker/docker-rocm/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=metrics \
    -t llamafactory:latest .

docker run -dit --ipc=host \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/kfd \
    --device /dev/dri \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Use Docker volumes&lt;/summary&gt; 
 &lt;p&gt;You can uncomment &lt;code&gt;VOLUME [ "/root/.cache/huggingface", "/app/shared_data", "/app/output" ]&lt;/code&gt; in the Dockerfile to use data volumes.&lt;/p&gt; 
 &lt;p&gt;When building the Docker image, use &lt;code&gt;-v ./hf_cache:/root/.cache/huggingface&lt;/code&gt; argument to mount the local directory to the container. The following data volumes are available.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;hf_cache&lt;/code&gt;: Utilize Hugging Face cache on the host machine.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;shared_data&lt;/code&gt;: The directionary to store datasets on the host machine.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;output&lt;/code&gt;: Set export dir to this location so that the merged result can be accessed directly on the host machine.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Deploy with OpenAI-style API and vLLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;API_PORT=8000 llamafactory-cli api examples/inference/llama3.yaml infer_backend=vllm vllm_enforce_eager=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Visit &lt;a href="https://platform.openai.com/docs/api-reference/chat/create"&gt;this page&lt;/a&gt; for API document.&lt;/p&gt; 
 &lt;p&gt;Examples: &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/scripts/api_example/test_image.py"&gt;Image understanding&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/scripts/api_example/test_toolcall.py"&gt;Function calling&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Download from ModelScope Hub&lt;/h3&gt; 
&lt;p&gt;If you have trouble with downloading models and datasets from Hugging Face, you can use ModelScope.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export USE_MODELSCOPE_HUB=1 # `set USE_MODELSCOPE_HUB=1` for Windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Train the model by specifying a model ID of the ModelScope Hub as the &lt;code&gt;model_name_or_path&lt;/code&gt;. You can find a full list of model IDs at &lt;a href="https://modelscope.cn/models"&gt;ModelScope Hub&lt;/a&gt;, e.g., &lt;code&gt;LLM-Research/Meta-Llama-3-8B-Instruct&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Download from Modelers Hub&lt;/h3&gt; 
&lt;p&gt;You can also use Modelers Hub to download models and datasets.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export USE_OPENMIND_HUB=1 # `set USE_OPENMIND_HUB=1` for Windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Train the model by specifying a model ID of the Modelers Hub as the &lt;code&gt;model_name_or_path&lt;/code&gt;. You can find a full list of model IDs at &lt;a href="https://modelers.cn/models"&gt;Modelers Hub&lt;/a&gt;, e.g., &lt;code&gt;TeleAI/TeleChat-7B-pt&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Use W&amp;amp;B Logger&lt;/h3&gt; 
&lt;p&gt;To use &lt;a href="https://wandb.ai"&gt;Weights &amp;amp; Biases&lt;/a&gt; for logging experimental results, you need to add the following arguments to yaml files.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;report_to: wandb
run_name: test_run # optional
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set &lt;code&gt;WANDB_API_KEY&lt;/code&gt; to &lt;a href="https://wandb.ai/authorize"&gt;your key&lt;/a&gt; when launching training tasks to log in with your W&amp;amp;B account.&lt;/p&gt; 
&lt;h3&gt;Use SwanLab Logger&lt;/h3&gt; 
&lt;p&gt;To use &lt;a href="https://github.com/SwanHubX/SwanLab"&gt;SwanLab&lt;/a&gt; for logging experimental results, you need to add the following arguments to yaml files.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;use_swanlab: true
swanlab_run_name: test_run # optional
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When launching training tasks, you can log in to SwanLab in three ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Add &lt;code&gt;swanlab_api_key=&amp;lt;your_api_key&amp;gt;&lt;/code&gt; to the yaml file, and set it to your &lt;a href="https://swanlab.cn/settings"&gt;API key&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Set the environment variable &lt;code&gt;SWANLAB_API_KEY&lt;/code&gt; to your &lt;a href="https://swanlab.cn/settings"&gt;API key&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use the &lt;code&gt;swanlab login&lt;/code&gt; command to complete the login.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Projects using LLaMA Factory&lt;/h2&gt; 
&lt;p&gt;If you have a project that should be incorporated, please contact via email or create a pull request.&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Click to show&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. &lt;a href="https://arxiv.org/abs/2308.02223"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. &lt;a href="https://arxiv.org/abs/2308.10092"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. &lt;a href="https://arxiv.org/abs/2308.10526"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. &lt;a href="https://arxiv.org/abs/2311.07816"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. &lt;a href="https://arxiv.org/abs/2312.15710"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. &lt;a href="https://arxiv.org/abs/2401.04319"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. &lt;a href="https://arxiv.org/abs/2401.07286"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. &lt;a href="https://arxiv.org/abs/2402.05904"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. &lt;a href="https://arxiv.org/abs/2402.07625"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2402.11176"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. &lt;a href="https://arxiv.org/abs/2402.11187"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. &lt;a href="https://arxiv.org/abs/2402.11746"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. &lt;a href="https://arxiv.org/abs/2402.11801"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. &lt;a href="https://arxiv.org/abs/2402.11809"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2402.11819"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. &lt;a href="https://arxiv.org/abs/2402.12204"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2402.14714"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. &lt;a href="https://arxiv.org/abs/2402.15043"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. &lt;a href="https://arxiv.org/abs/2403.02333"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. &lt;a href="https://arxiv.org/abs/2403.03419"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. &lt;a href="https://arxiv.org/abs/2403.08228"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. &lt;a href="https://arxiv.org/abs/2403.09073"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling. 2024. &lt;a href="https://arxiv.org/abs/2403.14541"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. &lt;a href="https://arxiv.org/abs/2403.15246"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. &lt;a href="https://arxiv.org/abs/2403.16008"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. &lt;a href="https://arxiv.org/abs/2403.16443"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. &lt;a href="https://arxiv.org/abs/2404.00604"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2404.02827"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. &lt;a href="https://arxiv.org/abs/2404.04167"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. &lt;a href="https://arxiv.org/abs/2404.04316"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2404.07084"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2404.09836"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2404.11581"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. &lt;a href="https://arxiv.org/abs/2404.14215"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. &lt;a href="https://arxiv.org/abs/2404.16621"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. &lt;a href="https://arxiv.org/abs/2404.17140"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. &lt;a href="https://arxiv.org/abs/2404.18585"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. &lt;a href="https://arxiv.org/abs/2405.04760"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Dammu et al. "They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. &lt;a href="https://arxiv.org/abs/2405.05378"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. &lt;a href="https://arxiv.org/abs/2405.09055"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. &lt;a href="https://arxiv.org/abs/2405.12739"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. &lt;a href="https://arxiv.org/abs/2405.13816"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2405.20215"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. &lt;a href="https://aclanthology.org/2024.lt4hala-1.30"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. &lt;a href="https://arxiv.org/abs/2406.00380"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. &lt;a href="https://arxiv.org/abs/2406.02106"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. &lt;a href="https://arxiv.org/abs/2406.03136"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. &lt;a href="https://arxiv.org/abs/2406.04496"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. &lt;a href="https://arxiv.org/abs/2406.05688"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. &lt;a href="https://arxiv.org/abs/2406.05955"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. &lt;a href="https://arxiv.org/abs/2406.06973"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. &lt;a href="https://arxiv.org/abs/2406.07115"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhu et al. Are Large Language Models Good Statisticians?. 2024. &lt;a href="https://arxiv.org/abs/2406.07815"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. &lt;a href="https://arxiv.org/abs/2406.10099"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. &lt;a href="https://arxiv.org/abs/2406.10173"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. &lt;a href="https://arxiv.org/abs/2406.12074"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. &lt;a href="https://arxiv.org/abs/2406.14408"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. &lt;a href="https://arxiv.org/abs/2406.14546"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. &lt;a href="https://arxiv.org/abs/2406.15695"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. &lt;a href="https://arxiv.org/abs/2406.17233"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. &lt;a href="https://arxiv.org/abs/2406.18069"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh's Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. &lt;a href="https://aclanthology.org/2024.americasnlp-1.25"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. &lt;a href="https://arxiv.org/abs/2406.19949"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yang et al. Financial Knowledge Large Language Model. 2024. &lt;a href="https://arxiv.org/abs/2407.00365"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. &lt;a href="https://arxiv.org/abs/2407.01470"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. &lt;a href="https://arxiv.org/abs/2407.06129"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. &lt;a href="https://arxiv.org/abs/2407.08044"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. &lt;a href="https://arxiv.org/abs/2407.09756"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. &lt;a href="https://scholarcommons.scu.edu/cseng_senior/272/"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. &lt;a href="https://arxiv.org/abs/2407.13561"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. &lt;a href="https://arxiv.org/abs/2407.16637"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. &lt;a href="https://arxiv.org/abs/2407.17535"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. &lt;a href="https://arxiv.org/abs/2407.19705"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. &lt;a href="https://arxiv.org/abs/2408.00137"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. &lt;a href="https://www.asianlp.sg/conferences/ialp2024/proceedings/papers/IALP2024_P055.pdf"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. &lt;a href="https://link.springer.com/chapter/10.1007/978-981-97-5669-8_11"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. &lt;a href="https://link.springer.com/chapter/10.1007/978-981-97-5669-8_23"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. &lt;a href="https://arxiv.org/abs/2408.04693"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. &lt;a href="https://arxiv.org/abs/2408.04168"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. &lt;a href="https://aclanthology.org/2024.finnlp-2.1/"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. &lt;a href="https://arxiv.org/abs/2408.08072"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. &lt;a href="https://dl.acm.org/doi/10.1145/3627673.3679611"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling. ACL 2024. &lt;a href="https://aclanthology.org/2024.findings-acl.830.pdf"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/Yu-Yang-Li/StarWhisper"&gt;StarWhisper&lt;/a&gt;&lt;/strong&gt;: A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/FudanDISC/DISC-LawLLM"&gt;DISC-LawLLM&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/X-D-Lab/Sunsimiao"&gt;Sunsimiao&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/WangRongsheng/CareGPT"&gt;CareGPT&lt;/a&gt;&lt;/strong&gt;: A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/PKU-YuanGroup/Machine-Mindset/"&gt;MachineMindset&lt;/a&gt;&lt;/strong&gt;: A series of MBTI Personality large language models, capable of giving any LLM 16 different personality types based on different datasets and training methods.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://huggingface.co/Nekochu/Luminia-13B-v3"&gt;Luminia-13B-v3&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in generate metadata for stable diffusion. &lt;a href="https://huggingface.co/spaces/Nekochu/Luminia-13B_SD_Prompt"&gt;[demo]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/BUAADreamer/Chinese-LLaVA-Med"&gt;Chinese-LLaVA-Med&lt;/a&gt;&lt;/strong&gt;: A multimodal large language model specialized in Chinese medical domain, based on LLaVA-1.5-7B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/THUDM/AutoRE"&gt;AutoRE&lt;/a&gt;&lt;/strong&gt;: A document-level relation extraction system based on large language models.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/NVIDIA/RTX-AI-Toolkit"&gt;NVIDIA RTX AI Toolkit&lt;/a&gt;&lt;/strong&gt;: SDKs for fine-tuning LLMs on Windows PC for NVIDIA RTX.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/LazyAGI/LazyLLM"&gt;LazyLLM&lt;/a&gt;&lt;/strong&gt;: An easy and lazy way for building multi-agent LLMs applications and supports model fine-tuning via LLaMA Factory.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/NLPJCL/RAG-Retrieval"&gt;RAG-Retrieval&lt;/a&gt;&lt;/strong&gt;: A full pipeline for RAG retrieval model fine-tuning, inference, and distillation. &lt;a href="https://zhuanlan.zhihu.com/p/987727357"&gt;[blog]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/Qihoo360/360-LLaMA-Factory"&gt;360-LLaMA-Factory&lt;/a&gt;&lt;/strong&gt;: A modified library that supports long sequence SFT &amp;amp; DPO using ring attention.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://novasky-ai.github.io/posts/sky-t1/"&gt;Sky-T1&lt;/a&gt;&lt;/strong&gt;: An o1-like model fine-tuned by NovaSky AI with very small cost.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/xming521/WeClone"&gt;WeClone&lt;/a&gt;&lt;/strong&gt;: One-stop solution for creating your digital avatar from chat logs.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/SmartFlowAI/EmoLLM"&gt;EmoLLM&lt;/a&gt;&lt;/strong&gt;: A project about large language models (LLMs) and mental health.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please follow the model licenses to use the corresponding model weights: &lt;a href="https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Community%20License%20for%20Baichuan%202%20Model.pdf"&gt;Baichuan 2&lt;/a&gt; / &lt;a href="https://huggingface.co/spaces/bigscience/license"&gt;BLOOM&lt;/a&gt; / &lt;a href="https://github.com/THUDM/ChatGLM3/raw/main/MODEL_LICENSE"&gt;ChatGLM3&lt;/a&gt; / &lt;a href="https://cohere.com/c4ai-cc-by-nc-license"&gt;Command R&lt;/a&gt; / &lt;a href="https://github.com/deepseek-ai/DeepSeek-LLM/raw/main/LICENSE-MODEL"&gt;DeepSeek&lt;/a&gt; / &lt;a href="https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt"&gt;Falcon&lt;/a&gt; / &lt;a href="https://ai.google.dev/gemma/terms"&gt;Gemma&lt;/a&gt; / &lt;a href="https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE"&gt;GLM-4&lt;/a&gt; / &lt;a href="https://github.com/openai/gpt-2/raw/master/LICENSE"&gt;GPT-2&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;Granite&lt;/a&gt; / &lt;a href="https://huggingface.co/IndexTeam/Index-1.9B/blob/main/LICENSE"&gt;Index&lt;/a&gt; / &lt;a href="https://github.com/InternLM/InternLM#license"&gt;InternLM&lt;/a&gt; / &lt;a href="https://github.com/facebookresearch/llama/raw/main/MODEL_CARD.md"&gt;Llama&lt;/a&gt; / &lt;a href="https://ai.meta.com/llama/license/"&gt;Llama 2&lt;/a&gt; / &lt;a href="https://llama.meta.com/llama3/license/"&gt;Llama 3&lt;/a&gt; / &lt;a href="https://github.com/meta-llama/llama-models/raw/main/models/llama4/LICENSE"&gt;Llama 4&lt;/a&gt; / &lt;a href="https://github.com/OpenBMB/MiniCPM/raw/main/MiniCPM%20Model%20License.md"&gt;MiniCPM&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;Mistral/Mixtral/Pixtral&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;OLMo&lt;/a&gt; / &lt;a href="https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx"&gt;Phi-1.5/Phi-2&lt;/a&gt; / &lt;a href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE"&gt;Phi-3/Phi-4&lt;/a&gt; / &lt;a href="https://github.com/QwenLM/Qwen/raw/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT"&gt;Qwen&lt;/a&gt; / &lt;a href="https://huggingface.co/Skywork/Skywork-13B-base/blob/main/Skywork%20Community%20License.pdf"&gt;Skywork&lt;/a&gt; / &lt;a href="https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement"&gt;StarCoder 2&lt;/a&gt; / &lt;a href="https://huggingface.co/Tele-AI/telechat-7B/blob/main/TeleChat%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf"&gt;TeleChat2&lt;/a&gt; / &lt;a href="https://github.com/xverse-ai/XVERSE-13B/raw/main/MODEL_LICENSE.pdf"&gt;XVERSE&lt;/a&gt; / &lt;a href="https://huggingface.co/01-ai/Yi-6B/blob/main/LICENSE"&gt;Yi&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;Yi-1.5&lt;/a&gt; / &lt;a href="https://github.com/IEIT-Yuan/Yuan-2.0/raw/main/LICENSE-Yuan"&gt;Yuan 2&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If this work is helpful, please kindly cite as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{zheng2024llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
  url={http://arxiv.org/abs/2403.13372}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;This repo benefits from &lt;a href="https://github.com/huggingface/peft"&gt;PEFT&lt;/a&gt;, &lt;a href="https://github.com/huggingface/trl"&gt;TRL&lt;/a&gt;, &lt;a href="https://github.com/artidoro/qlora"&gt;QLoRA&lt;/a&gt; and &lt;a href="https://github.com/lm-sys/FastChat"&gt;FastChat&lt;/a&gt;. Thanks for their wonderful works.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ansible/ansible</title>
      <link>https://github.com/ansible/ansible</link>
      <description>&lt;p&gt;Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://pypi.org/project/ansible-core"&gt;&lt;img src="https://img.shields.io/pypi/v/ansible-core.svg?sanitize=true" alt="PyPI version"&gt;&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/latest/"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-brightgreen.svg?sanitize=true" alt="Docs badge"&gt;&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/devel/community/communication.html"&gt;&lt;img src="https://img.shields.io/badge/chat-IRC-brightgreen.svg?sanitize=true" alt="Chat badge"&gt;&lt;/a&gt; &lt;a href="https://dev.azure.com/ansible/ansible/_build/latest?definitionId=20&amp;amp;branchName=devel"&gt;&lt;img src="https://dev.azure.com/ansible/ansible/_apis/build/status/CI?branchName=devel" alt="Build Status"&gt;&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/devel/community/code_of_conduct.html"&gt;&lt;img src="https://img.shields.io/badge/code%20of%20conduct-Ansible-silver.svg?sanitize=true" alt="Ansible Code of Conduct"&gt;&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/devel/community/communication.html#mailing-list-information"&gt;&lt;img src="https://img.shields.io/badge/mailing%20lists-Ansible-orange.svg?sanitize=true" alt="Ansible mailing lists"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/ansible/ansible/devel/COPYING"&gt;&lt;img src="https://img.shields.io/badge/license-GPL%20v3.0-brightgreen.svg?sanitize=true" alt="Repository License"&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/2372"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/2372/badge" alt="Ansible CII Best Practices certification"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Ansible&lt;/h1&gt; 
&lt;p&gt;Ansible is a radically simple IT automation system. It handles configuration management, application deployment, cloud provisioning, ad-hoc task execution, network automation, and multi-node orchestration. Ansible makes complex changes like zero-downtime rolling updates with load balancers easy. More information on the Ansible &lt;a href="https://ansible.com/"&gt;website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Design Principles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have an extremely simple setup process with a minimal learning curve.&lt;/li&gt; 
 &lt;li&gt;Manage machines quickly and in parallel.&lt;/li&gt; 
 &lt;li&gt;Avoid custom-agents and additional open ports, be agentless by leveraging the existing SSH daemon.&lt;/li&gt; 
 &lt;li&gt;Describe infrastructure in a language that is both machine and human friendly.&lt;/li&gt; 
 &lt;li&gt;Focus on security and easy auditability/review/rewriting of content.&lt;/li&gt; 
 &lt;li&gt;Manage new remote machines instantly, without bootstrapping any software.&lt;/li&gt; 
 &lt;li&gt;Allow module development in any dynamic language, not just Python.&lt;/li&gt; 
 &lt;li&gt;Be usable as non-root.&lt;/li&gt; 
 &lt;li&gt;Be the easiest IT automation system to use, ever.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Use Ansible&lt;/h2&gt; 
&lt;p&gt;You can install a released version of Ansible with &lt;code&gt;pip&lt;/code&gt; or a package manager. See our &lt;a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html"&gt;installation guide&lt;/a&gt; for details on installing Ansible on a variety of platforms.&lt;/p&gt; 
&lt;p&gt;Power users and developers can run the &lt;code&gt;devel&lt;/code&gt; branch, which has the latest features and fixes, directly. Although it is reasonably stable, you are more likely to encounter breaking changes when running the &lt;code&gt;devel&lt;/code&gt; branch. We recommend getting involved in the Ansible community if you want to run the &lt;code&gt;devel&lt;/code&gt; branch.&lt;/p&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p&gt;Join the Ansible forum to ask questions, get help, and interact with the community.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://forum.ansible.com/c/help/6"&gt;Get Help&lt;/a&gt;: Find help or share your Ansible knowledge to help others. Use tags to filter and subscribe to posts, such as the following: 
  &lt;ul&gt; 
   &lt;li&gt;Posts tagged with &lt;a href="https://forum.ansible.com/tag/ansible"&gt;ansible&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Posts tagged with &lt;a href="https://forum.ansible.com/tag/ansible-core"&gt;ansible-core&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Posts tagged with &lt;a href="https://forum.ansible.com/tag/playbook"&gt;playbook&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://forum.ansible.com/c/chat/4"&gt;Social Spaces&lt;/a&gt;: Meet and interact with fellow enthusiasts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://forum.ansible.com/c/news/5"&gt;News &amp;amp; Announcements&lt;/a&gt;: Track project-wide announcements including social events.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn"&gt;Bullhorn newsletter&lt;/a&gt;: Get release announcements and important changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more ways to get in touch, see &lt;a href="https://docs.ansible.com/ansible/devel/community/communication.html"&gt;Communicating with the Ansible community&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contribute to Ansible&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/ansible/ansible/devel/.github/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Read &lt;a href="https://docs.ansible.com/ansible/devel/community"&gt;Community Information&lt;/a&gt; for all kinds of ways to contribute to and interact with the project, including how to submit bug reports and code to Ansible.&lt;/li&gt; 
 &lt;li&gt;Submit a proposed code update through a pull request to the &lt;code&gt;devel&lt;/code&gt; branch.&lt;/li&gt; 
 &lt;li&gt;Talk to us before making larger changes to avoid duplicate efforts. This not only helps everyone know what is going on, but it also helps save time and effort if we decide some changes are needed.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Coding Guidelines&lt;/h2&gt; 
&lt;p&gt;We document our Coding Guidelines in the &lt;a href="https://docs.ansible.com/ansible/devel/dev_guide/"&gt;Developer Guide&lt;/a&gt;. We particularly suggest you review:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_checklist.html"&gt;Contributing your module to Ansible&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_best_practices.html"&gt;Conventions, tips, and pitfalls&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Branch Info&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;devel&lt;/code&gt; branch corresponds to the release actively under development.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;stable-2.X&lt;/code&gt; branches correspond to stable releases.&lt;/li&gt; 
 &lt;li&gt;Create a branch based on &lt;code&gt;devel&lt;/code&gt; and set up a &lt;a href="https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_general.html#common-environment-setup"&gt;dev environment&lt;/a&gt; if you want to open a PR.&lt;/li&gt; 
 &lt;li&gt;See the &lt;a href="https://docs.ansible.com/ansible/devel/reference_appendices/release_and_maintenance.html"&gt;Ansible release and maintenance&lt;/a&gt; page for information about active branches.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Based on team and community feedback, an initial roadmap will be published for a major or minor version (ex: 2.7, 2.8). The &lt;a href="https://docs.ansible.com/ansible/devel/roadmap/"&gt;Ansible Roadmap page&lt;/a&gt; details what is planned and how to influence the roadmap.&lt;/p&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;p&gt;Ansible was created by &lt;a href="https://github.com/mpdehaan"&gt;Michael DeHaan&lt;/a&gt; and has contributions from over 5000 users (and growing). Thanks everyone!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.ansible.com"&gt;Ansible&lt;/a&gt; is sponsored by &lt;a href="https://www.redhat.com"&gt;Red Hat, Inc.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;GNU General Public License v3.0 or later&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/ansible/ansible/devel/COPYING"&gt;COPYING&lt;/a&gt; to see the full text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>getsentry/sentry</title>
      <link>https://github.com/getsentry/sentry</link>
      <description>&lt;p&gt;Developer-first error tracking and performance monitoring&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://sentry.io/?utm_source=github&amp;amp;utm_medium=logo" target="_blank"&gt; &lt;img src="https://sentry-brand.storage.googleapis.com/sentry-wordmark-dark-280x84.png" alt="Sentry" width="280" height="84"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Users and logs provide clues. Sentry provides answers. &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;What's Sentry?&lt;/h1&gt; 
&lt;p&gt;Sentry is the debugging platform that helps every developer detect, trace, and fix issues. Code breaks, fix it faster.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/issue-details.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/seer.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/traces.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/trace-explorer.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/replays.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/logs.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/uptime.png" width="270"&gt; &lt;/p&gt; 
&lt;h2&gt;Official Sentry SDKs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-javascript"&gt;JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-electron/"&gt;Electron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-react-native"&gt;React-Native&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-ruby"&gt;Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-php"&gt;PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-laravel"&gt;Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-rust"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-java"&gt;Java/Kotlin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-cocoa"&gt;Objective-C/Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-dotnet"&gt;C#/F#&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-native"&gt;C/C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-dart"&gt;Dart/Flutter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/perl-raven"&gt;Perl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-clj/"&gt;Clojure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-elixir"&gt;Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-unity"&gt;Unity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-unreal"&gt;Unreal Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-godot"&gt;Godot Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-powershell"&gt;PowerShell&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Resources&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.sentry.io/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry/discussions"&gt;Discussions&lt;/a&gt; (Bugs, feature requests, general questions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/PXa5Apfe7K"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.sentry.io/internal/contributing/"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry/issues"&gt;Bug Tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry"&gt;Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.transifex.com/getsentry/sentry/"&gt;Transifex&lt;/a&gt; (Translate Sentry!)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>9001/copyparty</title>
      <link>https://github.com/9001/copyparty</link>
      <description>&lt;p&gt;Portable file server with accelerated resumable uploads, dedup, WebDAV, FTP, TFTP, zeroconf, media indexer, thumbnails++ all in one file, no deps&lt;/p&gt;&lt;hr&gt;&lt;img src="https://github.com/9001/copyparty/raw/hovudstraum/docs/logo.svg?sanitize=true" width="250" align="right"&gt; 
&lt;h3&gt;üíæüéâ copyparty&lt;/h3&gt; 
&lt;p&gt;turn almost any device into a file server with resumable uploads/downloads using &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#browser-support"&gt;&lt;em&gt;any&lt;/em&gt;&lt;/a&gt; web browser&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;server only needs Python (2 or 3), all dependencies optional&lt;/li&gt; 
 &lt;li&gt;üîå protocols: &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#the-browser"&gt;http&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tftp-server"&gt;tftp&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb/cifs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üì± &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#android-app"&gt;android app&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ios-shortcuts"&gt;iPhone shortcuts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#quickstart"&gt;Get started&lt;/a&gt;!&lt;/strong&gt; or visit the &lt;strong&gt;&lt;a href="https://a.ocv.me/pub/demo/"&gt;read-only demo server&lt;/a&gt;&lt;/strong&gt; üëÄ running on a nuc in my basement&lt;/p&gt; 
&lt;p&gt;üì∑ &lt;strong&gt;screenshots:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#the-browser"&gt;browser&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;upload&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;search&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;fsearch&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zip-downloads"&gt;zip-DL&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-viewer"&gt;md-viewer&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üé¨ &lt;strong&gt;videos:&lt;/strong&gt; &lt;a href="https://a.ocv.me/pub/demo/pics-vids/up2k.webm"&gt;upload&lt;/a&gt; // &lt;a href="https://a.ocv.me/pub/demo/pics-vids/u2cli.webm"&gt;cli-upload&lt;/a&gt; // &lt;a href="https://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm"&gt;race-the-beam&lt;/a&gt; // üëâ &lt;strong&gt;&lt;a href="https://a.ocv.me/pub/demo/showcase-hq.webm"&gt;feature-showcase&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://www.youtube.com/watch?v=15_-hgsX2V0"&gt;youtube&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;made in Norway üá≥üá¥&lt;/p&gt; 
&lt;h2&gt;readme toc&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;top 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#quickstart"&gt;quickstart&lt;/a&gt; - just run &lt;strong&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt;&lt;/strong&gt; -- that's it! üéâ 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#at-home"&gt;at home&lt;/a&gt; - make it accessible over the internet&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#on-servers"&gt;on servers&lt;/a&gt; - you may also want these, especially on servers&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#features"&gt;features&lt;/a&gt; - also see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/versus.md"&gt;comparison to similar software&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#testimonials"&gt;testimonials&lt;/a&gt; - small collection of user feedback&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#motivations"&gt;motivations&lt;/a&gt; - project goals / philosophy 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#notes"&gt;notes&lt;/a&gt; - general notes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#bugs"&gt;bugs&lt;/a&gt; - roughly sorted by chance of encounter 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#not-my-bugs"&gt;not my bugs&lt;/a&gt; - same order here too&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#breaking-changes"&gt;breaking changes&lt;/a&gt; - upgrade notes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#FAQ"&gt;FAQ&lt;/a&gt; - "frequently" asked questions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt; - per-folder, per-user permissions 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#shadowing"&gt;shadowing&lt;/a&gt; - hiding specific subfolders&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dotfiles"&gt;dotfiles&lt;/a&gt; - unix-style hidden files/folders&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#the-browser"&gt;the browser&lt;/a&gt; - accessing a copyparty server using a web-browser 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tabs"&gt;tabs&lt;/a&gt; - the main tabs in the ui&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#hotkeys"&gt;hotkeys&lt;/a&gt; - the browser has the following hotkeys&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#navpane"&gt;navpane&lt;/a&gt; - switching between breadcrumbs or navpane&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; - press &lt;code&gt;g&lt;/code&gt; or &lt;code&gt;Áî∞&lt;/code&gt; to toggle grid-view instead of the file listing&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zip-downloads"&gt;zip downloads&lt;/a&gt; - download folders (or file selections) as &lt;code&gt;zip&lt;/code&gt; or &lt;code&gt;tar&lt;/code&gt; files&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;uploading&lt;/a&gt; - drag files/folders into the web-browser to upload 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt; - dropping files into the browser also lets you see if they exist on the server&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt; - undo/delete accidental uploads&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#self-destruct"&gt;self-destruct&lt;/a&gt; - uploads can be given a lifetime&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#race-the-beam"&gt;race the beam&lt;/a&gt; - download files while they're still uploading (&lt;a href="http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm"&gt;demo video&lt;/a&gt;)&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#incoming-files"&gt;incoming files&lt;/a&gt; - the control-panel shows the ETA for all incoming files&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-manager"&gt;file manager&lt;/a&gt; - cut/paste, rename, and delete files/folders (if you have permission)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#shares"&gt;shares&lt;/a&gt; - share a file or folder by creating a temporary link&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#batch-rename"&gt;batch rename&lt;/a&gt; - select some files and press &lt;code&gt;F2&lt;/code&gt; to bring up the rename UI&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#rss-feeds"&gt;rss feeds&lt;/a&gt; - monitor a folder with your RSS reader&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#recent-uploads"&gt;recent uploads&lt;/a&gt; - list all recent uploads&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#media-player"&gt;media player&lt;/a&gt; - plays almost every audio format there is 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#playlists"&gt;playlists&lt;/a&gt; - create and play &lt;a href="https://en.wikipedia.org/wiki/M3U"&gt;m3u8&lt;/a&gt; playlists&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#creating-a-playlist"&gt;creating a playlist&lt;/a&gt; - with a standalone mediaplayer or copyparty&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#audio-equalizer"&gt;audio equalizer&lt;/a&gt; - and &lt;a href="https://en.wikipedia.org/wiki/Dynamic_range_compression"&gt;dynamic range compressor&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#fix-unreliable-playback-on-android"&gt;fix unreliable playback on android&lt;/a&gt; - due to phone / app settings&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#textfile-viewer"&gt;textfile viewer&lt;/a&gt; - with realtime streaming of logfiles and such (&lt;a href="https://a.ocv.me/pub/demo/logtail/"&gt;demo&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-viewer"&gt;markdown viewer&lt;/a&gt; - and there are &lt;em&gt;two&lt;/em&gt; editors 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-vars"&gt;markdown vars&lt;/a&gt; - dynamic docs with serverside variable expansion&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#other-tricks"&gt;other tricks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;searching&lt;/a&gt; - search by size, date, path/name, mp3-tags, ...&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#server-config"&gt;server config&lt;/a&gt; - using arguments or config files, or a mix of both 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeroconf"&gt;zeroconf&lt;/a&gt; - announce enabled services on the LAN (&lt;a href="https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png"&gt;pic&lt;/a&gt;) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mdns"&gt;mdns&lt;/a&gt; - LAN domain-name and feature announcer&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ssdp"&gt;ssdp&lt;/a&gt; - windows-explorer announcer&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#qr-code"&gt;qr-code&lt;/a&gt; - print a qr-code &lt;a href="https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png"&gt;(screenshot)&lt;/a&gt; for quick access&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp server&lt;/a&gt; - an FTP server can be started using &lt;code&gt;--ftp 3921&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav server&lt;/a&gt; - with read-write support 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#connecting-to-webdav-from-windows"&gt;connecting to webdav from windows&lt;/a&gt; - using the GUI&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tftp-server"&gt;tftp server&lt;/a&gt; - a TFTP server (read/write) can be started using &lt;code&gt;--tftp 3969&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb server&lt;/a&gt; - unsafe, slow, not recommended for wan&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#browser-ux"&gt;browser ux&lt;/a&gt; - tweaking the ui&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#opengraph"&gt;opengraph&lt;/a&gt; - discord and social-media embeds&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-deduplication"&gt;file deduplication&lt;/a&gt; - enable symlink-based upload deduplication&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt; - enable music search, upload-undo, and better dedup 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#exclude-patterns"&gt;exclude-patterns&lt;/a&gt; - to save some time&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filesystem-guards"&gt;filesystem guards&lt;/a&gt; - avoid traversing into other filesystems&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#periodic-rescan"&gt;periodic rescan&lt;/a&gt; - filesystem monitoring&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#upload-rules"&gt;upload rules&lt;/a&gt; - set upload rules using volflags&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#compress-uploads"&gt;compress uploads&lt;/a&gt; - files can be autocompressed on upload&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#chmod-and-chown"&gt;chmod and chown&lt;/a&gt; - per-volume filesystem-permissions and ownership&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#other-flags"&gt;other flags&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#database-location"&gt;database location&lt;/a&gt; - in-volume (&lt;code&gt;.hist/up2k.db&lt;/code&gt;, default) or somewhere else&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#metadata-from-audio-files"&gt;metadata from audio files&lt;/a&gt; - set &lt;code&gt;-e2t&lt;/code&gt; to index tags on upload&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-parser-plugins"&gt;file parser plugins&lt;/a&gt; - provide custom parsers to index additional tags&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#event-hooks"&gt;event hooks&lt;/a&gt; - trigger a program on uploads, renames etc (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/hooks/"&gt;examples&lt;/a&gt;) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeromq"&gt;zeromq&lt;/a&gt; - event-hooks can send zeromq messages&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#upload-events"&gt;upload events&lt;/a&gt; - the older, more powerful approach (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/mtag/"&gt;examples&lt;/a&gt;)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#handlers"&gt;handlers&lt;/a&gt; - redefine behavior with plugins (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/handlers/"&gt;examples&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ip-auth"&gt;ip auth&lt;/a&gt; - autologin based on IP range (CIDR)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;identity providers&lt;/a&gt; - replace copyparty passwords with oauth and such&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#user-changeable-passwords"&gt;user-changeable passwords&lt;/a&gt; - if permitted, users can change their own passwords&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#using-the-cloud-as-storage"&gt;using the cloud as storage&lt;/a&gt; - connecting to an aws s3 bucket and similar&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#hiding-from-google"&gt;hiding from google&lt;/a&gt; - tell search engines you don't wanna be indexed&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#themes"&gt;themes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#complete-examples"&gt;complete examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#listen-on-port-80-and-443"&gt;listen on port 80 and 443&lt;/a&gt; - become a &lt;em&gt;real&lt;/em&gt; webserver&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; - running copyparty next to other websites 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; - teaching copyparty how to see client IPs&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy-performance"&gt;reverse-proxy performance&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#permanent-cloudflare-tunnel"&gt;permanent cloudflare tunnel&lt;/a&gt; - if you have a domain and want to get your copyparty online real quick&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#prometheus"&gt;prometheus&lt;/a&gt; - metrics/stats can be enabled&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#other-extremely-specific-features"&gt;other extremely specific features&lt;/a&gt; - you'll never find a use for these 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#custom-mimetypes"&gt;custom mimetypes&lt;/a&gt; - change the association of a file extension&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#GDPR-compliance"&gt;GDPR compliance&lt;/a&gt; - imagine using copyparty professionally...&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#feature-chickenbits"&gt;feature chickenbits&lt;/a&gt; - buggy feature? rip it out&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#feature-beefybits"&gt;feature beefybits&lt;/a&gt; - force-enable features with known issues on your OS/env&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#packages"&gt;packages&lt;/a&gt; - the party might be closer than you think 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#arch-package"&gt;arch package&lt;/a&gt; - &lt;code&gt;pacman -S copyparty&lt;/code&gt; (in &lt;a href="https://archlinux.org/packages/extra/any/copyparty/"&gt;arch linux extra&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#fedora-package"&gt;fedora package&lt;/a&gt; - does not exist yet&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nix-package"&gt;nix package&lt;/a&gt; - &lt;code&gt;nix profile install github:9001/copyparty&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nixos-module"&gt;nixos module&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#browser-support"&gt;browser support&lt;/a&gt; - TLDR: yes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-examples"&gt;client examples&lt;/a&gt; - interact with copyparty using non-browser clients 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#folder-sync"&gt;folder sync&lt;/a&gt; - sync folders to/from copyparty&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mount-as-drive"&gt;mount as drive&lt;/a&gt; - a remote copyparty server as a local filesystem&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#android-app"&gt;android app&lt;/a&gt; - upload to copyparty with one tap&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#iOS-shortcuts"&gt;iOS shortcuts&lt;/a&gt; - there is no iPhone app, but&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#performance"&gt;performance&lt;/a&gt; - defaults are usually fine - expect &lt;code&gt;8 GiB/s&lt;/code&gt; download, &lt;code&gt;1 GiB/s&lt;/code&gt; upload 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-side"&gt;client-side&lt;/a&gt; - when uploading files&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#security"&gt;security&lt;/a&gt; - there is a &lt;a href="https://discord.gg/25J8CdTT6G"&gt;discord server&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#gotchas"&gt;gotchas&lt;/a&gt; - behavior that might be unexpected&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#cors"&gt;cors&lt;/a&gt; - cross-site request config&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekeys&lt;/a&gt; - prevent filename bruteforcing 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dirkeys"&gt;dirkeys&lt;/a&gt; - share specific folders in a volume&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;password hashing&lt;/a&gt; - you can hash passwords&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#https"&gt;https&lt;/a&gt; - both HTTP and HTTPS are accepted&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#recovering-from-crashes"&gt;recovering from crashes&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-crashes"&gt;client crashes&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#firefox-wsod"&gt;firefox wsod&lt;/a&gt; - firefox 87 can crash during uploads&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#HTTP-API"&gt;HTTP API&lt;/a&gt; - see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#http-api"&gt;devnotes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dependencies"&gt;dependencies&lt;/a&gt; - mandatory deps 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;optional dependencies&lt;/a&gt; - install these to enable bonus features 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dependency-chickenbits"&gt;dependency chickenbits&lt;/a&gt; - prevent loading an optional dependency&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-gpl-stuff"&gt;optional gpl stuff&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#sfx"&gt;sfx&lt;/a&gt; - the self-contained "binary" (recommended!) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#copypartyexe"&gt;copyparty.exe&lt;/a&gt; - download &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.exe"&gt;copyparty.exe&lt;/a&gt; (win8+) or &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe"&gt;copyparty32.exe&lt;/a&gt; (win7+)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zipapp"&gt;zipapp&lt;/a&gt; - another emergency alternative, &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz"&gt;copyparty.pyz&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-android"&gt;install on android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reporting-bugs"&gt;reporting bugs&lt;/a&gt; - ideas for context to include, and where to submit them&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#devnotes"&gt;devnotes&lt;/a&gt; - for build instructions etc, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md"&gt;./docs/devnotes.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;quickstart&lt;/h2&gt; 
&lt;p&gt;just run &lt;strong&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt;&lt;/strong&gt; -- that's it! üéâ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;or install through &lt;a href="https://pypi.org/project/copyparty/"&gt;pypi&lt;/a&gt;: &lt;code&gt;python3 -m pip install --user -U copyparty&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;or if you cannot install python, you can use &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#copypartyexe"&gt;copyparty.exe&lt;/a&gt; instead&lt;/li&gt; 
 &lt;li&gt;or install &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#arch-package"&gt;on arch&lt;/a&gt; ‚ï± &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nixos-module"&gt;on NixOS&lt;/a&gt; ‚ï± &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nix-package"&gt;through nix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if you are on android, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-android"&gt;install copyparty in termux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or maybe you have a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/synology-dsm.md"&gt;synology nas / dsm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if you have &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; installed, run &lt;code&gt;uv tool run copyparty&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;or if your computer is messed up and nothing else works, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zipapp"&gt;try the pyz&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if your OS is dead, give the &lt;a href="https://a.ocv.me/pub/stuff/edcd001/enterprise-edition/"&gt;bootable flashdrive / cd-rom&lt;/a&gt; a spin&lt;/li&gt; 
 &lt;li&gt;or if you don't trust copyparty yet and want to isolate it a little, then... 
  &lt;ul&gt; 
   &lt;li&gt;...maybe &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/prisonparty.sh"&gt;prisonparty&lt;/a&gt; to create a tiny &lt;a href="https://wiki.archlinux.org/title/Chroot"&gt;chroot&lt;/a&gt; (very portable),&lt;/li&gt; 
   &lt;li&gt;...or &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/bubbleparty.sh"&gt;bubbleparty&lt;/a&gt; to wrap it in &lt;a href="https://github.com/containers/bubblewrap"&gt;bubblewrap&lt;/a&gt; (much better)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;or if you prefer to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/scripts/docker/"&gt;use docker&lt;/a&gt; üêã you can do that too 
  &lt;ul&gt; 
   &lt;li&gt;docker has all deps built-in, so skip this step:&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable thumbnails (images/audio/video), media indexing, and audio transcoding by installing some recommended deps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Alpine:&lt;/strong&gt; &lt;code&gt;apk add py3-pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debian:&lt;/strong&gt; &lt;code&gt;apt install --no-install-recommends python3-pil ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fedora:&lt;/strong&gt; rpmfusion + &lt;code&gt;dnf install python3-pillow ffmpeg --allowerasing&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FreeBSD:&lt;/strong&gt; &lt;code&gt;pkg install py39-sqlite3 py39-pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MacOS:&lt;/strong&gt; &lt;code&gt;port install py-Pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MacOS&lt;/strong&gt; (alternative): &lt;code&gt;brew install pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; &lt;code&gt;python -m pip install --user -U Pillow&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;install &lt;a href="https://www.python.org/downloads/windows/"&gt;python&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;ffmpeg&lt;/a&gt; manually; do not use &lt;code&gt;winget&lt;/code&gt; or &lt;code&gt;Microsoft Store&lt;/code&gt; (it breaks $PATH)&lt;/li&gt; 
   &lt;li&gt;copyparty.exe comes with &lt;code&gt;Pillow&lt;/code&gt; and only needs &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;ffmpeg&lt;/a&gt; for mediatags/videothumbs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;optional dependencies&lt;/a&gt; to enable even more features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;running copyparty without arguments (for example doubleclicking it on Windows) will give everyone read/write access to the current folder; you may want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;or see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#complete-examples"&gt;some usage examples&lt;/a&gt; for inspiration, or the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/windows.md"&gt;complete windows example&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;some recommended options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-e2dsa&lt;/code&gt; enables general &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2ts&lt;/code&gt; enables audio metadata indexing (needs either FFprobe or Mutagen)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v /mnt/music:/music:r:rw,foo -a foo:bar&lt;/code&gt; shares &lt;code&gt;/mnt/music&lt;/code&gt; as &lt;code&gt;/music&lt;/code&gt;, &lt;code&gt;r&lt;/code&gt;eadable by anyone, and read-write for user &lt;code&gt;foo&lt;/code&gt;, password &lt;code&gt;bar&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;replace &lt;code&gt;:r:rw,foo&lt;/code&gt; with &lt;code&gt;:r,foo&lt;/code&gt; to only make the folder readable by &lt;code&gt;foo&lt;/code&gt; and nobody else&lt;/li&gt; 
   &lt;li&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt; (or &lt;code&gt;--help-accounts&lt;/code&gt;) for the syntax and other permissions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;at home&lt;/h3&gt; 
&lt;p&gt;make it accessible over the internet by starting a &lt;a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/do-more-with-tunnels/trycloudflare/"&gt;cloudflare quicktunnel&lt;/a&gt; like so:&lt;/p&gt; 
&lt;p&gt;first download &lt;a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/downloads/"&gt;cloudflared&lt;/a&gt; and then start the tunnel with &lt;code&gt;cloudflared tunnel --url http://127.0.0.1:3923&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;as the tunnel starts, it will show a URL which you can share to let anyone browse your stash or upload files to you&lt;/p&gt; 
&lt;p&gt;but if you have a domain, then you probably want to skip the random autogenerated URL and instead make a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#permanent-cloudflare-tunnel"&gt;permanent cloudflare tunnel&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;since people will be connecting through cloudflare, run copyparty with &lt;code&gt;--xff-hdr cf-connecting-ip&lt;/code&gt; to detect client IPs correctly&lt;/p&gt; 
&lt;h3&gt;on servers&lt;/h3&gt; 
&lt;p&gt;you may also want these, especially on servers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/systemd/copyparty.service"&gt;contrib/systemd/copyparty.service&lt;/a&gt; to run copyparty as a systemd service (see guide inside)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/systemd/prisonparty.service"&gt;contrib/systemd/prisonparty.service&lt;/a&gt; to run it in a chroot (for extra security)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/openrc/copyparty"&gt;contrib/openrc/copyparty&lt;/a&gt; to run copyparty on Alpine / Gentoo&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/rc/copyparty"&gt;contrib/rc/copyparty&lt;/a&gt; to run copyparty on FreeBSD&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nixos-module"&gt;nixos module&lt;/a&gt; to run copyparty on NixOS hosts&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/nginx/copyparty.conf"&gt;contrib/nginx/copyparty.conf&lt;/a&gt; to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; behind nginx (for better https)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and remember to open the ports you want; here's a complete example including every feature copyparty has to offer:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;firewall-cmd --permanent --add-port={80,443,3921,3923,3945,3990}/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port=12000-12099/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port={69,1900,3969,5353}/udp  # --zone=libvirt
firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(69:tftp, 1900:ssdp, 3921:ftp, 3923:http/https, 3945:smb, 3969:tftp, 3990:ftps, 5353:mdns, 12000:passive-ftp)&lt;/p&gt; 
&lt;h2&gt;features&lt;/h2&gt; 
&lt;p&gt;also see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/versus.md"&gt;comparison to similar software&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;backend stuff 
  &lt;ul&gt; 
   &lt;li&gt;‚òë IPv6 + unix-sockets&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#performance"&gt;multiprocessing&lt;/a&gt; (actual multithreading)&lt;/li&gt; 
   &lt;li&gt;‚òë volumes (mountpoints)&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tftp-server"&gt;tftp server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb/cifs server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#qr-code"&gt;qr-code&lt;/a&gt; for quick access&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeroconf"&gt;upnp / zeroconf / mdns / ssdp&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#event-hooks"&gt;event hooks&lt;/a&gt; / script runner&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://github.com/9001/copyparty#reverse-proxy"&gt;reverse-proxy support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë cross-platform (Windows, Linux, Macos, Android, FreeBSD, arm32/arm64, ppc64le, s390x, risc-v/riscv64)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;upload 
  &lt;ul&gt; 
   &lt;li&gt;‚òë basic: plain multipart, ie6 support&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;up2k&lt;/a&gt;: js, resumable, multithreaded 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;no filesize limit!&lt;/strong&gt; even on Cloudflare&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;‚òë stash: simple PUT filedropper&lt;/li&gt; 
   &lt;li&gt;‚òë filename randomizer&lt;/li&gt; 
   &lt;li&gt;‚òë write-only folders&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt;: undo/delete accidental uploads&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#self-destruct"&gt;self-destruct&lt;/a&gt; (specified server-side or client-side)&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#race-the-beam"&gt;race the beam&lt;/a&gt; (almost like peer-to-peer)&lt;/li&gt; 
   &lt;li&gt;‚òë symlink/discard duplicates (content-matching)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;download 
  &lt;ul&gt; 
   &lt;li&gt;‚òë single files in browser&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zip-downloads"&gt;folders as zip / tar files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/bin#partyfusepy"&gt;FUSE client&lt;/a&gt; (read-only)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;browser 
  &lt;ul&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#navpane"&gt;navpane&lt;/a&gt; (directory tree sidebar)&lt;/li&gt; 
   &lt;li&gt;‚òë file manager (cut/paste, delete, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#batch-rename"&gt;batch-rename&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;‚òë audio player (with &lt;a href="https://user-images.githubusercontent.com/241032/215347492-b4250797-6c90-4e09-9a4c-721edf2fb15c.png"&gt;OS media controls&lt;/a&gt; and opus/mp3 transcoding) 
    &lt;ul&gt; 
     &lt;li&gt;‚òë play video files as audio (converted on server)&lt;/li&gt; 
     &lt;li&gt;‚òë create and play &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#playlists"&gt;m3u8 playlists&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;‚òë image gallery with webm player&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#textfile-viewer"&gt;textfile browser&lt;/a&gt; with syntax hilighting 
    &lt;ul&gt; 
     &lt;li&gt;‚òë realtime streaming of growing files (logfiles and such)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;‚òë ...of images using Pillow, pyvips, or FFmpeg&lt;/li&gt; 
     &lt;li&gt;‚òë ...of videos using FFmpeg&lt;/li&gt; 
     &lt;li&gt;‚òë ...of audio (spectrograms) using FFmpeg&lt;/li&gt; 
     &lt;li&gt;‚òë cache eviction (max-age; maybe max-size eventually)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;‚òë multilingual UI (english, norwegian, chinese, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rice/#translations"&gt;add your own&lt;/a&gt;))&lt;/li&gt; 
   &lt;li&gt;‚òë SPA (browse while uploading)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;server indexing 
  &lt;ul&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;locate files by contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë search by name/path/date/size&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;search by ID3-tags etc.&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;client support 
  &lt;ul&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#folder-sync"&gt;folder sync&lt;/a&gt; (one-way only; full sync will never be supported)&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://user-images.githubusercontent.com/241032/215322619-ea5fd606-3654-40ad-94ee-2bc058647bb2.png"&gt;curl-friendly&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#opengraph"&gt;opengraph&lt;/a&gt; (discord embeds)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;markdown 
  &lt;ul&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-viewer"&gt;viewer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;‚òë editor (sure why not)&lt;/li&gt; 
   &lt;li&gt;‚òë &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-vars"&gt;variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PS: something missing? post any crazy ideas you've got as a &lt;a href="https://github.com/9001/copyparty/issues/new?assignees=9001&amp;amp;labels=enhancement&amp;amp;template=feature_request.md"&gt;feature request&lt;/a&gt; or &lt;a href="https://github.com/9001/copyparty/discussions/new?category=ideas"&gt;discussion&lt;/a&gt; ü§ô&lt;/p&gt; 
&lt;h2&gt;testimonials&lt;/h2&gt; 
&lt;p&gt;small collection of user feedback&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;good enough&lt;/code&gt;, &lt;code&gt;surprisingly correct&lt;/code&gt;, &lt;code&gt;certified good software&lt;/code&gt;, &lt;code&gt;just works&lt;/code&gt;, &lt;code&gt;why&lt;/code&gt;, &lt;code&gt;wow this is better than nextcloud&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;UI –ø—Ä–æ—Å—Ç–æ —É–∂–∞—Å–Ω–æ. –ï—Å–ª–∏ –±—É–¥—É –æ–ø–∏—Å—ã–≤–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω–æ –Ω–µ —Å–º–æ–≥—É —É–¥–µ—Ä–∂–∞—Ç—å—Å—è –≤ —Ä–∞–º–∫–∞—Ö –ø—Ä–∏–ª–∏—á–∏–π&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;motivations&lt;/h1&gt; 
&lt;p&gt;project goals / philosophy&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;inverse linux philosophy -- do all the things, and do an &lt;em&gt;okay&lt;/em&gt; job 
  &lt;ul&gt; 
   &lt;li&gt;quick drop-in service to get a lot of features in a pinch&lt;/li&gt; 
   &lt;li&gt;some of &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/versus.md"&gt;the alternatives&lt;/a&gt; might be a better fit for you&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;run anywhere, support everything 
  &lt;ul&gt; 
   &lt;li&gt;as many web-browsers and python versions as possible 
    &lt;ul&gt; 
     &lt;li&gt;every browser should at least be able to browse, download, upload files&lt;/li&gt; 
     &lt;li&gt;be a good emergency solution for transferring stuff between ancient boxes&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;minimal dependencies 
    &lt;ul&gt; 
     &lt;li&gt;but optional dependencies adding bonus-features are ok&lt;/li&gt; 
     &lt;li&gt;everything being plaintext makes it possible to proofread for malicious code&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;no preparations / setup necessary, just run the sfx (which is also plaintext)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;adaptable, malleable, hackable 
  &lt;ul&gt; 
   &lt;li&gt;no build steps; modify the js/python without needing node.js or anything like that&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;becoming rich is specifically &lt;em&gt;not&lt;/em&gt; a motivation, but if you wanna donate then see my &lt;a href="https://github.com/9001"&gt;github profile&lt;/a&gt; regarding donations for my FOSS stuff in general (also THANKS!)&lt;/p&gt; 
&lt;h2&gt;notes&lt;/h2&gt; 
&lt;p&gt;general notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;paper-printing is affected by dark/light-mode! use lightmode for color, darkmode for grayscale 
  &lt;ul&gt; 
   &lt;li&gt;because no browsers currently implement the media-query to do this properly orz&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;browser-specific:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;iPhone/iPad: use Firefox to download files&lt;/li&gt; 
 &lt;li&gt;Android-Chrome: increase "parallel uploads" for higher speed (android bug)&lt;/li&gt; 
 &lt;li&gt;Android-Firefox: takes a while to select files (their fix for ‚òùÔ∏è)&lt;/li&gt; 
 &lt;li&gt;Desktop-Firefox: &lt;del&gt;may use gigabytes of RAM if your files are massive&lt;/del&gt; &lt;em&gt;seems to be OK now&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Desktop-Firefox: &lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1792598"&gt;may stop you from unplugging USB flashdrives&lt;/a&gt; until you visit &lt;code&gt;about:memory&lt;/code&gt; and click &lt;code&gt;Minimize memory usage&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;server-os-specific:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RHEL8 / Rocky8: you can run copyparty using &lt;code&gt;/usr/libexec/platform-python&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;server notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;pypy is supported but regular cpython is faster if you enable the database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;bugs&lt;/h1&gt; 
&lt;p&gt;roughly sorted by chance of encounter&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;general:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--th-ff-jpg&lt;/code&gt; may fix video thumbnails on some FFmpeg versions (macos, some linux)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--th-ff-swr&lt;/code&gt; may fix audio thumbnails on some FFmpeg versions&lt;/li&gt; 
   &lt;li&gt;if the &lt;code&gt;up2k.db&lt;/code&gt; (filesystem index) is on a samba-share or network disk, you'll get unpredictable behavior if the share is disconnected for a bit 
    &lt;ul&gt; 
     &lt;li&gt;use &lt;code&gt;--hist&lt;/code&gt; or the &lt;code&gt;hist&lt;/code&gt; volflag (&lt;code&gt;-v [...]:c,hist=/tmp/foo&lt;/code&gt;) to place the db and thumbnails on a local disk instead&lt;/li&gt; 
     &lt;li&gt;or, if you only want to move the db (and not the thumbnails), then use &lt;code&gt;--dbpath&lt;/code&gt; or the &lt;code&gt;dbpath&lt;/code&gt; volflag&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;all volumes must exist / be available on startup; up2k (mtp especially) gets funky otherwise&lt;/li&gt; 
   &lt;li&gt;probably more, pls let me know&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;python 3.4 and older (including 2.7):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;many rare and exciting edge-cases because &lt;a href="https://peps.python.org/pep-0475/"&gt;python didn't handle EINTR yet&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;downloads from copyparty may suddenly fail, but uploads &lt;em&gt;should&lt;/em&gt; be fine&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;python 2.7 on Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;cannot index non-ascii filenames with &lt;code&gt;-e2d&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;cannot handle filenames with mojibake&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you have a new exciting bug to share, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reporting-bugs"&gt;reporting bugs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;not my bugs&lt;/h2&gt; 
&lt;p&gt;same order here too&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1317069"&gt;Chrome issue 1317069&lt;/a&gt; -- if you try to upload a folder which contains symlinks by dragging it into the browser, the symlinked files will not get uploaded&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1352210"&gt;Chrome issue 1352210&lt;/a&gt; -- plaintext http may be faster at filehashing than https (but also extremely CPU-intensive)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://issues.chromium.org/issues/383568268"&gt;Chrome issue 383568268&lt;/a&gt; -- filereaders in webworkers can OOM / crash the browser-tab&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;copyparty has a workaround which seems to work well enough&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1790500"&gt;Firefox issue 1790500&lt;/a&gt; -- entire browser can crash after uploading ~4000 small files&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Android: music playback randomly stops due to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#fix-unreliable-playback-on-android"&gt;battery usage settings&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: the volume control doesn't work because &lt;a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/Using_HTML5_Audio_Video/Device-SpecificConsiderations/Device-SpecificConsiderations.html#//apple_ref/doc/uid/TP40009523-CH5-SW11"&gt;apple doesn't want it to&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;AudioContext&lt;/code&gt; will probably never be a viable workaround as apple introduces new issues faster than they fix current ones&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: music volume goes on a rollercoaster during song changes&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;nothing I can do about it because &lt;code&gt;AudioContext&lt;/code&gt; is still broken in safari&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: the preload feature (in the media-player-options tab) can cause a tiny audio glitch 20sec before the end of each song, but disabling it may cause worse iOS bugs to appear instead&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;just a hunch, but disabling preloading may cause playback to stop entirely, or possibly mess with bluetooth speakers&lt;/li&gt; 
   &lt;li&gt;tried to add a tooltip regarding this but looks like apple broke my tooltips&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: preloaded awo files make safari log MEDIA_ERR_NETWORK errors as playback starts, but the song plays just fine so eh whatever&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;awo, opus-weba, is apple's new take on opus support, replacing opus-caf which was technically limited to cbr opus&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: preloading another awo file may cause playback to stop&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;can be somewhat mitigated with &lt;code&gt;mp.au.play()&lt;/code&gt; in &lt;code&gt;mp.onpreload&lt;/code&gt; but that can hit a race condition in safari that starts playing the same audio object twice in parallel...&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Windows: folders cannot be accessed if the name ends with &lt;code&gt;.&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;python or windows bug&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Windows: msys2-python 3.8.6 occasionally throws &lt;code&gt;RuntimeError: release unlocked lock&lt;/code&gt; when leaving a scoped mutex in up2k&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;this is an msys2 bug, the regular windows edition of python is fine&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;VirtualBox: sqlite throws &lt;code&gt;Disk I/O Error&lt;/code&gt; when running in a VM and the up2k database is in a vboxsf&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;use &lt;code&gt;--hist&lt;/code&gt; or the &lt;code&gt;hist&lt;/code&gt; volflag (&lt;code&gt;-v [...]:c,hist=/tmp/foo&lt;/code&gt;) to place the db and thumbnails inside the vm instead 
    &lt;ul&gt; 
     &lt;li&gt;or, if you only want to move the db (and not the thumbnails), then use &lt;code&gt;--dbpath&lt;/code&gt; or the &lt;code&gt;dbpath&lt;/code&gt; volflag&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;also happens on mergerfs, so put the db elsewhere&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu: dragging files from certain folders into firefox or chrome is impossible&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;due to snap security policies -- see &lt;code&gt;snap connections firefox&lt;/code&gt; for the allowlist, &lt;code&gt;removable-media&lt;/code&gt; permits all of &lt;code&gt;/mnt&lt;/code&gt; and &lt;code&gt;/media&lt;/code&gt; apparently&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;breaking changes&lt;/h1&gt; 
&lt;p&gt;upgrade notes&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;1.9.16&lt;/code&gt; (2023-11-04): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--stats&lt;/code&gt;/prometheus: &lt;code&gt;cpp_bans&lt;/code&gt; renamed to &lt;code&gt;cpp_active_bans&lt;/code&gt;, and that + &lt;code&gt;cpp_uptime&lt;/code&gt; are gauges&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.6.0&lt;/code&gt; (2023-01-29): 
  &lt;ul&gt; 
   &lt;li&gt;http-api: delete/move is now &lt;code&gt;POST&lt;/code&gt; instead of &lt;code&gt;GET&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;everything other than &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;HEAD&lt;/code&gt; must pass &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#cors"&gt;cors validation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.5.0&lt;/code&gt; (2022-12-03): &lt;a href="https://github.com/9001/copyparty/commit/54e1c8d261df"&gt;new chunksize formula&lt;/a&gt; for files larger than 128 GiB 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;users:&lt;/strong&gt; upgrade to the latest &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/u2c.py"&gt;cli uploader&lt;/a&gt; if you use that&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;devs:&lt;/strong&gt; update third-party up2k clients (if those even exist)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;FAQ&lt;/h1&gt; 
&lt;p&gt;"frequently" asked questions&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;CopyParty?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;nope! the name is either copyparty (all-lowercase) or Copyparty -- it's &lt;a href="https://en.wiktionary.org/wiki/copyparty"&gt;one word&lt;/a&gt; after all :&amp;gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;can I change the üå≤ spinning pine-tree loading animation?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/docs/rice#boring-loader-spinner"&gt;yeah...&lt;/a&gt; :-(&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;is it possible to block read-access to folders unless you know the exact URL for a particular file inside?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;yes, using the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;&lt;code&gt;g&lt;/code&gt; permission&lt;/a&gt;, see the examples there&lt;/li&gt; 
   &lt;li&gt;you can also do this with linux filesystem permissions; &lt;code&gt;chmod 111 music&lt;/code&gt; will make it possible to access files and folders inside the &lt;code&gt;music&lt;/code&gt; folder but not list the immediate contents -- also works with other software, not just copyparty&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;can I link someone to a password-protected volume/file by including the password in the URL?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;yes, by adding &lt;code&gt;?pw=hunter2&lt;/code&gt; to the end; replace &lt;code&gt;?&lt;/code&gt; with &lt;code&gt;&amp;amp;&lt;/code&gt; if there are parameters in the URL already, meaning it contains a &lt;code&gt;?&lt;/code&gt; near the end&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;how do I stop &lt;code&gt;.hist&lt;/code&gt; folders from appearing everywhere on my HDD?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;by default, a &lt;code&gt;.hist&lt;/code&gt; folder is created inside each volume for the filesystem index, thumbnails, audio transcodes, and markdown document history. Use the &lt;code&gt;--hist&lt;/code&gt; global-option or the &lt;code&gt;hist&lt;/code&gt; volflag to move it somewhere else; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#database-location"&gt;database location&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;can I make copyparty download a file to my server if I give it a URL?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;yes, using &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/hooks/wget.py"&gt;hooks&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;firefox refuses to connect over https, saying "Secure Connection Failed" or "SEC_ERROR_BAD_SIGNATURE", but the usual button to "Accept the Risk and Continue" is not shown&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;firefox has corrupted its certstore; fix this by exiting firefox, then find and delete the file named &lt;code&gt;cert9.db&lt;/code&gt; somewhere in your firefox profile folder&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;the server keeps saying &lt;code&gt;thank you for playing&lt;/code&gt; when I try to access the website&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you've gotten banned for malicious traffic! if this happens by mistake, and you're running a reverse-proxy and/or something like cloudflare, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; on how to fix this&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;copyparty seems to think I am using http, even though the URL is https&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;your reverse-proxy is not sending the &lt;code&gt;X-Forwarded-Proto: https&lt;/code&gt; header; this could be because your reverse-proxy itself is confused. Ensure that none of the intermediates (such as cloudflare) are terminating https before the traffic hits your entrypoint&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;thumbnails are broken (you get a colorful square which says the filetype instead)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you need to install &lt;code&gt;FFmpeg&lt;/code&gt; or &lt;code&gt;Pillow&lt;/code&gt;; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;thumbnails are broken (some images appear, but other files just get a blank box, and/or the broken-image placeholder)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;probably due to a reverse-proxy messing with the request URLs and stripping the query parameters (&lt;code&gt;?th=w&lt;/code&gt;), so check your URL rewrite rules&lt;/li&gt; 
   &lt;li&gt;could also be due to incorrect caching settings in reverse-proxies and/or CDNs, so make sure that nothing is set to ignore the query string&lt;/li&gt; 
   &lt;li&gt;could also be due to misbehaving privacy-related browser extensions, so try to disable those&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;i want to learn python and/or programming and am considering looking at the copyparty source code in that occasion&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;pre&gt;&lt;code class="language-bash"&gt; _|  _      __   _  _|_
(_| (_)     | | (_)  |_
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;accounts and volumes&lt;/h1&gt; 
&lt;p&gt;per-folder, per-user permissions - if your setup is getting complex, consider making a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example.conf"&gt;config file&lt;/a&gt; instead of using arguments&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;much easier to manage, and you can modify the config at runtime with &lt;code&gt;systemctl reload copyparty&lt;/code&gt; or more conveniently using the &lt;code&gt;[reload cfg]&lt;/code&gt; button in the control-panel (if the user has &lt;code&gt;a&lt;/code&gt;/admin in any volume) 
  &lt;ul&gt; 
   &lt;li&gt;changes to the &lt;code&gt;[global]&lt;/code&gt; config section requires a restart to take effect&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;a quick summary can be seen using &lt;code&gt;--help-accounts&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;configuring accounts/volumes with arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-a usr:pwd&lt;/code&gt; adds account &lt;code&gt;usr&lt;/code&gt; with password &lt;code&gt;pwd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v .::r&lt;/code&gt; adds current-folder &lt;code&gt;.&lt;/code&gt; as the webroot, &lt;code&gt;r&lt;/code&gt;eadable by anyone 
  &lt;ul&gt; 
   &lt;li&gt;the syntax is &lt;code&gt;-v src:dst:perm:perm:...&lt;/code&gt; so local-path, url-path, and one or more permissions to set&lt;/li&gt; 
   &lt;li&gt;granting the same permissions to multiple accounts:&lt;br&gt; &lt;code&gt;-v .::r,usr1,usr2:rw,usr3,usr4&lt;/code&gt; = usr1/2 read-only, 3/4 read-write&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;permissions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;r&lt;/code&gt; (read): browse folder contents, download files, download as zip/tar, see filekeys/dirkeys&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt; (write): upload files, move/copy files &lt;em&gt;into&lt;/em&gt; this folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;m&lt;/code&gt; (move): move files/folders &lt;em&gt;from&lt;/em&gt; this folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;d&lt;/code&gt; (delete): delete files/folders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.&lt;/code&gt; (dots): user can ask to show dotfiles in directory listings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;g&lt;/code&gt; (get): only download files, cannot see folder contents or zip/tar&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;G&lt;/code&gt; (upget): same as &lt;code&gt;g&lt;/code&gt; except uploaders get to see their own &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekeys&lt;/a&gt; (see &lt;code&gt;fk&lt;/code&gt; in examples below)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;h&lt;/code&gt; (html): same as &lt;code&gt;g&lt;/code&gt; except folders return their index.html, and filekeys are not necessary for index.html&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;a&lt;/code&gt; (admin): can see upload time, uploader IPs, config-reload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;A&lt;/code&gt; ("all"): same as &lt;code&gt;rwmda.&lt;/code&gt; (read/write/move/delete/admin/dotfiles)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;add accounts named u1, u2, u3 with passwords p1, p2, p3: &lt;code&gt;-a u1:p1 -a u2:p2 -a u3:p3&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/srv&lt;/code&gt; the root of the filesystem, read-only by anyone: &lt;code&gt;-v /srv::r&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/mnt/music&lt;/code&gt; available at &lt;code&gt;/music&lt;/code&gt;, read-only for u1 and u2, read-write for u3: &lt;code&gt;-v /mnt/music:music:r,u1,u2:rw,u3&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;unauthorized users accessing the webroot can see that the &lt;code&gt;music&lt;/code&gt; folder exists, but cannot open it&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/mnt/incoming&lt;/code&gt; available at &lt;code&gt;/inc&lt;/code&gt;, write-only for u1, read-move for u2: &lt;code&gt;-v /mnt/incoming:inc:w,u1:rm,u2&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;unauthorized users accessing the webroot can see that the &lt;code&gt;inc&lt;/code&gt; folder exists, but cannot open it&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;u1&lt;/code&gt; can open the &lt;code&gt;inc&lt;/code&gt; folder, but cannot see the contents, only upload new files to it&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;u2&lt;/code&gt; can browse it and move files &lt;em&gt;from&lt;/em&gt; &lt;code&gt;/inc&lt;/code&gt; into any folder where &lt;code&gt;u2&lt;/code&gt; has write-access&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/mnt/ss&lt;/code&gt; available at &lt;code&gt;/i&lt;/code&gt;, read-write for u1, get-only for everyone else, and enable filekeys: &lt;code&gt;-v /mnt/ss:i:rw,u1:g:c,fk=4&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;c,fk=4&lt;/code&gt; sets the &lt;code&gt;fk&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekey&lt;/a&gt;) volflag to 4, meaning each file gets a 4-character accesskey&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;u1&lt;/code&gt; can upload files, browse the folder, and see the generated filekeys&lt;/li&gt; 
   &lt;li&gt;other users cannot browse the folder, but can access the files if they have the full file URL with the filekey&lt;/li&gt; 
   &lt;li&gt;replacing the &lt;code&gt;g&lt;/code&gt; permission with &lt;code&gt;wg&lt;/code&gt; would let anonymous users upload files, but not see the required filekey to access it&lt;/li&gt; 
   &lt;li&gt;replacing the &lt;code&gt;g&lt;/code&gt; permission with &lt;code&gt;wG&lt;/code&gt; would let anonymous users upload files, receiving a working direct link in return&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;anyone trying to bruteforce a password gets banned according to &lt;code&gt;--ban-pw&lt;/code&gt;; default is 24h ban for 9 failed attempts in 1 hour&lt;/p&gt; 
&lt;p&gt;and if you want to use config files instead of commandline args (good!) then here's the same examples as a configfile; save it as &lt;code&gt;foobar.conf&lt;/code&gt; and use it like this: &lt;code&gt;python copyparty-sfx.py -c foobar.conf&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[accounts]
  u1: p1  # create account "u1" with password "p1"
  u2: p2  #  (note that comments must have
  u3: p3  #   two spaces before the # sign)

[/]     # this URL will be mapped to...
  /srv  # ...this folder on the server filesystem
  accs:
    r: *  # read-only for everyone, no account necessary

[/music]       # create another volume at this URL,
  /mnt/music   # which is mapped to this folder
  accs:
    r: u1, u2  # only these accounts can read,
    rw: u3     # and only u3 can read-write

[/inc]
  /mnt/incoming
  accs:
    w: u1   # u1 can upload but not see/download any files,
    rm: u2  # u2 can browse + move files out of this volume

[/i]
  /mnt/ss
  accs:
    rw: u1  # u1 can read-write,
    g: *    # everyone can access files if they know the URL
  flags:
    fk: 4   # each file URL will have a 4-character password
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;shadowing&lt;/h2&gt; 
&lt;p&gt;hiding specific subfolders by mounting another volume on top of them&lt;/p&gt; 
&lt;p&gt;for example &lt;code&gt;-v /mnt::r -v /var/empty:web/certs:r&lt;/code&gt; mounts the server folder &lt;code&gt;/mnt&lt;/code&gt; as the webroot, but another volume is mounted at &lt;code&gt;/web/certs&lt;/code&gt; -- so visitors can only see the contents of &lt;code&gt;/mnt&lt;/code&gt; and &lt;code&gt;/mnt/web&lt;/code&gt; (at URLs &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;/web&lt;/code&gt;), but not &lt;code&gt;/mnt/web/certs&lt;/code&gt; because URL &lt;code&gt;/web/certs&lt;/code&gt; is mapped to &lt;code&gt;/var/empty&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;the example config file right above this section may explain this better; the first volume &lt;code&gt;/&lt;/code&gt; is mapped to &lt;code&gt;/srv&lt;/code&gt; which means &lt;a href="http://127.0.0.1:3923/music"&gt;http://127.0.0.1:3923/music&lt;/a&gt; would try to read &lt;code&gt;/srv/music&lt;/code&gt; on the server filesystem, but since there's another volume at &lt;code&gt;/music&lt;/code&gt; mapped to &lt;code&gt;/mnt/music&lt;/code&gt; then it'll go to &lt;code&gt;/mnt/music&lt;/code&gt; instead&lt;/p&gt; 
&lt;h2&gt;dotfiles&lt;/h2&gt; 
&lt;p&gt;unix-style hidden files/folders by starting the name with a dot&lt;/p&gt; 
&lt;p&gt;anyone can access these if they know the name, but they normally don't appear in directory listings&lt;/p&gt; 
&lt;p&gt;a client can request to see dotfiles in directory listings if global option &lt;code&gt;-ed&lt;/code&gt; is specified, or the volume has volflag &lt;code&gt;dots&lt;/code&gt;, or the user has permission &lt;code&gt;.&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;dotfiles do not appear in search results unless one of the above is true, &lt;strong&gt;and&lt;/strong&gt; the global option / volflag &lt;code&gt;dotsrch&lt;/code&gt; is set&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;even if user has permission to see dotfiles, they are default-hidden unless &lt;code&gt;--see-dots&lt;/code&gt; is set, and/or user has enabled the &lt;code&gt;dotfiles&lt;/code&gt; option in the settings tab&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;config file example, where the same permission to see dotfiles is given in two different ways just for reference:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/foo]
  /srv/foo
  accs:
    r.: ed   # user "ed" has read-access + dot-access in this volume;
             # dotfiles are visible in listings, but not in searches
  flags:
    dotsrch  # dotfiles will now appear in search results too
    dots     # another way to let everyone see dotfiles in this vol
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;the browser&lt;/h1&gt; 
&lt;p&gt;accessing a copyparty server using a web-browser&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/192042695-522b3ec7-6845-494a-abdb-d1c0d0e23801.png" alt="copyparty-browser-fs8"&gt;&lt;/p&gt; 
&lt;h2&gt;tabs&lt;/h2&gt; 
&lt;p&gt;the main tabs in the ui&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[üîé]&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;search&lt;/a&gt; by size, date, path/name, mp3-tags ...&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üßØ]&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt;: undo/delete accidental uploads&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üöÄ]&lt;/code&gt; and &lt;code&gt;[üéà]&lt;/code&gt; are the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;uploaders&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üìÇ]&lt;/code&gt; mkdir: create directories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üìù]&lt;/code&gt; new-md: create a new markdown document&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üìü]&lt;/code&gt; send-msg: either to server-log or into textfiles if &lt;code&gt;--urlform save&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üé∫]&lt;/code&gt; audio-player config options&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[‚öôÔ∏è]&lt;/code&gt; general client config options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;hotkeys&lt;/h2&gt; 
&lt;p&gt;the browser has the following hotkeys (always qwerty)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;?&lt;/code&gt; show hotkeys help&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;B&lt;/code&gt; toggle breadcrumbs / &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#navpane"&gt;navpane&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;I/K&lt;/code&gt; prev/next folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;M&lt;/code&gt; parent folder (or unexpand current)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;V&lt;/code&gt; toggle folders / textfiles in the navpane&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;G&lt;/code&gt; toggle list / &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;grid view&lt;/a&gt; -- same as &lt;code&gt;Áî∞&lt;/code&gt; bottom-right&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;T&lt;/code&gt; toggle thumbnails / icons&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ESC&lt;/code&gt; close various things&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-K&lt;/code&gt; delete selected files/folders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-X&lt;/code&gt; cut selected files/folders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-C&lt;/code&gt; copy selected files/folders to clipboard&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-V&lt;/code&gt; paste (move/copy)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Y&lt;/code&gt; download selected files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;F2&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#batch-rename"&gt;rename&lt;/a&gt; selected file/folder&lt;/li&gt; 
 &lt;li&gt;when a file/folder is selected (in not-grid-view): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;Up/Down&lt;/code&gt; move cursor&lt;/li&gt; 
   &lt;li&gt;shift+&lt;code&gt;Up/Down&lt;/code&gt; select and move cursor&lt;/li&gt; 
   &lt;li&gt;ctrl+&lt;code&gt;Up/Down&lt;/code&gt; move cursor and scroll viewport&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Space&lt;/code&gt; toggle file selection&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Ctrl-A&lt;/code&gt; toggle select all&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when a textfile is open: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;I/K&lt;/code&gt; prev/next textfile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;S&lt;/code&gt; toggle selection of open file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;M&lt;/code&gt; close textfile&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when playing audio: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;J/L&lt;/code&gt; prev/next song&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;U/O&lt;/code&gt; skip 10sec back/forward&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;0..9&lt;/code&gt; jump to 0%..90%&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;P&lt;/code&gt; play/pause (also starts playing the folder)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Y&lt;/code&gt; download file&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when viewing images / playing videos: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;J/L, Left/Right&lt;/code&gt; prev/next file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Home/End&lt;/code&gt; first/last file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;F&lt;/code&gt; toggle fullscreen&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;S&lt;/code&gt; toggle selection&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;R&lt;/code&gt; rotate clockwise (shift=ccw)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Y&lt;/code&gt; download file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Esc&lt;/code&gt; close viewer&lt;/li&gt; 
   &lt;li&gt;videos: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;U/O&lt;/code&gt; skip 10sec back/forward&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;0..9&lt;/code&gt; jump to 0%..90%&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;P/K/Space&lt;/code&gt; play/pause&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;M&lt;/code&gt; mute&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;C&lt;/code&gt; continue playing next video&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;V&lt;/code&gt; loop entire file&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;[&lt;/code&gt; loop range (start)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;]&lt;/code&gt; loop range (end)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when the navpane is open: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;A/D&lt;/code&gt; adjust tree width&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;in the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;grid view&lt;/a&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;S&lt;/code&gt; toggle multiselect&lt;/li&gt; 
   &lt;li&gt;shift+&lt;code&gt;A/D&lt;/code&gt; zoom&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;in the markdown editor: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;^s&lt;/code&gt; save&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^h&lt;/code&gt; header&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^k&lt;/code&gt; autoformat table&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^u&lt;/code&gt; jump to next unicode character&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^e&lt;/code&gt; toggle editor / preview&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^up, ^down&lt;/code&gt; jump paragraphs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;navpane&lt;/h2&gt; 
&lt;p&gt;switching between breadcrumbs or navpane&lt;/p&gt; 
&lt;p&gt;click the &lt;code&gt;üå≤&lt;/code&gt; or pressing the &lt;code&gt;B&lt;/code&gt; hotkey to toggle between breadcrumbs path (default), or a navpane (tree-browser sidebar thing)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[+]&lt;/code&gt; and &lt;code&gt;[-]&lt;/code&gt; (or hotkeys &lt;code&gt;A&lt;/code&gt;/&lt;code&gt;D&lt;/code&gt;) adjust the size&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üéØ]&lt;/code&gt; jumps to the currently open folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üìÉ]&lt;/code&gt; toggles between showing folders and textfiles&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üìå]&lt;/code&gt; shows the name of all parent folders in a docked panel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[a]&lt;/code&gt; toggles automatic widening as you go deeper&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[‚Üµ]&lt;/code&gt; toggles wordwrap&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üëÄ]&lt;/code&gt; show full name on hover (if wordwrap is off)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;thumbnails&lt;/h2&gt; 
&lt;p&gt;press &lt;code&gt;g&lt;/code&gt; or &lt;code&gt;Áî∞&lt;/code&gt; to toggle grid-view instead of the file listing and &lt;code&gt;t&lt;/code&gt; toggles icons / thumbnails&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;can be made default globally with &lt;code&gt;--grid&lt;/code&gt; or per-volume with volflag &lt;code&gt;grid&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;enable by adding &lt;code&gt;?imgs&lt;/code&gt; to a link, or disable with &lt;code&gt;?imgs=0&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129636211-abd20fa2-a953-4366-9423-1c88ebb96ba9.png" alt="copyparty-thumbs-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;it does static images with Pillow / pyvips / FFmpeg, and uses FFmpeg for video files, so you may want to &lt;code&gt;--no-thumb&lt;/code&gt; or maybe just &lt;code&gt;--no-vthumb&lt;/code&gt; depending on how dangerous your users are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;pyvips is 3x faster than Pillow, Pillow is 3x faster than FFmpeg&lt;/li&gt; 
 &lt;li&gt;disable thumbnails for specific volumes with volflag &lt;code&gt;dthumb&lt;/code&gt; for all, or &lt;code&gt;dvthumb&lt;/code&gt; / &lt;code&gt;dathumb&lt;/code&gt; / &lt;code&gt;dithumb&lt;/code&gt; for video/audio/images only&lt;/li&gt; 
 &lt;li&gt;for installing FFmpeg on windows, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;optional dependencies&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;audio files are converted into spectrograms using FFmpeg unless you &lt;code&gt;--no-athumb&lt;/code&gt; (and some FFmpeg builds may need &lt;code&gt;--th-ff-swr&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;images with the following names (see &lt;code&gt;--th-covers&lt;/code&gt;) become the thumbnail of the folder they're in: &lt;code&gt;folder.png&lt;/code&gt;, &lt;code&gt;folder.jpg&lt;/code&gt;, &lt;code&gt;cover.png&lt;/code&gt;, &lt;code&gt;cover.jpg&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the order is significant, so if both &lt;code&gt;cover.png&lt;/code&gt; and &lt;code&gt;folder.jpg&lt;/code&gt; exist in a folder, it will pick the first matching &lt;code&gt;--th-covers&lt;/code&gt; entry (&lt;code&gt;folder.jpg&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;and, if you enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt;, it will also try those names as dotfiles (&lt;code&gt;.folder.jpg&lt;/code&gt; and so), and then fallback on the first picture in the folder (if it has any pictures at all)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enabling &lt;code&gt;multiselect&lt;/code&gt; lets you click files to select them, and then shift-click another file for range-select&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;multiselect&lt;/code&gt; is mostly intended for phones/tablets, but the &lt;code&gt;sel&lt;/code&gt; option in the &lt;code&gt;[‚öôÔ∏è] settings&lt;/code&gt; tab is better suited for desktop use, allowing selection by CTRL-clicking and range-selection with SHIFT-click, all without affecting regular clicking 
  &lt;ul&gt; 
   &lt;li&gt;the &lt;code&gt;sel&lt;/code&gt; option can be made default globally with &lt;code&gt;--gsel&lt;/code&gt; or per-volume with volflag &lt;code&gt;gsel&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;to show &lt;code&gt;/icons/exe.png&lt;/code&gt; and &lt;code&gt;/icons/elf.gif&lt;/code&gt; as the thumbnail for all &lt;code&gt;.exe&lt;/code&gt; and &lt;code&gt;.elf&lt;/code&gt; files respectively, do this: &lt;code&gt;--ext-th=exe=/icons/exe.png --ext-th=elf=/icons/elf.gif&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;optionally as separate volflags for each mapping; see config file example below&lt;/li&gt; 
 &lt;li&gt;the supported image formats are &lt;a href="https://developer.mozilla.org/en-US/docs/Web/Media/Guides/Formats/Image_types"&gt;jpg, png, gif, webp, ico&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;be careful with svg; chrome will crash if you have too many unique svg files showing on the same page (the limit is 250 or so) -- showing the same handful of svg files thousands of times is ok however&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  no-thumb   # disable ALL thumbnails and audio transcoding
  no-vthumb  # only disable video thumbnails

[/music]
  /mnt/nas/music
  accs:
    r: *     # everyone can read
  flags:
    dthumb   # disable ALL thumbnails and audio transcoding
    dvthumb  # only disable video thumbnails
    ext-th:  exe=/ico/exe.png  # /ico/exe.png is the thumbnail of *.exe
    ext-th:  elf=/ico/elf.gif  # ...and /ico/elf.gif is used for *.elf
    th-covers:  folder.png,folder.jpg,cover.png,cover.jpg  # the default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;zip downloads&lt;/h2&gt; 
&lt;p&gt;download folders (or file selections) as &lt;code&gt;zip&lt;/code&gt; or &lt;code&gt;tar&lt;/code&gt; files&lt;/p&gt; 
&lt;p&gt;select which type of archive you want in the &lt;code&gt;[‚öôÔ∏è] config&lt;/code&gt; tab:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;name&lt;/th&gt; 
   &lt;th&gt;url-suffix&lt;/th&gt; 
   &lt;th&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tar&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;plain gnutar, works great with &lt;code&gt;curl | tar -xv&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pax&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar=pax&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;pax-format tar, futureproof, not as fast&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tgz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar=gz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;gzip compressed gnu-tar (slow), for &lt;code&gt;curl | tar -xvz&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;txz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar=xz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;gnu-tar with xz / lzma compression (v.slow)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;zip&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?zip&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;works everywhere, glitchy filenames on win7 and older&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;zip_dos&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?zip=dos&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;traditional cp437 (no unicode) to fix glitchy filenames&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;zip_crc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?zip=crc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;cp437 with crc32 computed early for truly ancient software&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;gzip default level is &lt;code&gt;3&lt;/code&gt; (0=fast, 9=best), change with &lt;code&gt;?tar=gz:9&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;xz default level is &lt;code&gt;1&lt;/code&gt; (0=fast, 9=best), change with &lt;code&gt;?tar=xz:9&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;bz2 default level is &lt;code&gt;2&lt;/code&gt; (1=fast, 9=best), change with &lt;code&gt;?tar=bz2:9&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;hidden files (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dotfiles"&gt;dotfiles&lt;/a&gt;) are excluded unless account is allowed to list them 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;up2k.db&lt;/code&gt; and &lt;code&gt;dir.txt&lt;/code&gt; is always excluded&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;bsdtar supports streaming unzipping: &lt;code&gt;curl foo?zip | bsdtar -xv&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;good, because copyparty's zip is faster than tar on small files 
    &lt;ul&gt; 
     &lt;li&gt;but &lt;code&gt;?tar&lt;/code&gt; is better for large files, especially if the total exceeds 4 GiB&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;zip_crc&lt;/code&gt; will take longer to download since the server has to read each file twice 
  &lt;ul&gt; 
   &lt;li&gt;this is only to support MS-DOS PKZIP v2.04g (october 1993) and older 
    &lt;ul&gt; 
     &lt;li&gt;how are you accessing copyparty actually&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;you can also zip a selection of files or folders by clicking them in the browser, that brings up a selection editor and zip button in the bottom right&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635374-e5136e01-470a-49b1-a762-848e8a4c9cdc.png" alt="copyparty-zipsel-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;cool trick: download a folder by appending url-params &lt;code&gt;?tar&amp;amp;opus&lt;/code&gt; or &lt;code&gt;?tar&amp;amp;mp3&lt;/code&gt; to transcode all audio files (except aac|m4a|mp3|ogg|opus|wma) to opus/mp3 before they're added to the archive&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;super useful if you're 5 minutes away from takeoff and realize you don't have any music on your phone but your server only has flac files and downloading those will burn through all your data + there wouldn't be enough time anyways&lt;/li&gt; 
 &lt;li&gt;and url-params &lt;code&gt;&amp;amp;j&lt;/code&gt; / &lt;code&gt;&amp;amp;w&lt;/code&gt; produce jpeg/webm thumbnails/spectrograms instead of the original audio/video/images (&lt;code&gt;&amp;amp;p&lt;/code&gt; for audio waveforms) 
  &lt;ul&gt; 
   &lt;li&gt;can also be used to pregenerate thumbnails; combine with &lt;code&gt;--th-maxage=9999999&lt;/code&gt; or &lt;code&gt;--th-clean=0&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;uploading&lt;/h2&gt; 
&lt;p&gt;drag files/folders into the web-browser to upload&lt;/p&gt; 
&lt;p&gt;dragdrop is the recommended way, but you may also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;select some files (not folders) in your file explorer and press CTRL-V inside the browser window&lt;/li&gt; 
 &lt;li&gt;use the &lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/bin#u2cpy"&gt;command-line uploader&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;upload using &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-examples"&gt;curl, sharex, ishare, ...&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;when uploading files through dragdrop or CTRL-V, this initiates an upload using &lt;code&gt;up2k&lt;/code&gt;; there are two browser-based uploaders available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[üéà] bup&lt;/code&gt;, the basic uploader, supports almost every browser since netscape 4.0&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üöÄ] up2k&lt;/code&gt;, the good / fancy one&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;NB: you can undo/delete your own uploads with &lt;code&gt;[üßØ]&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt; (and this is also where you abort unfinished uploads, but you have to refresh the page first)&lt;/p&gt; 
&lt;p&gt;up2k has several advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can drop folders into the browser (files are added recursively)&lt;/li&gt; 
 &lt;li&gt;files are processed in chunks, and each chunk is checksummed 
  &lt;ul&gt; 
   &lt;li&gt;uploads autoresume if they are interrupted by network issues&lt;/li&gt; 
   &lt;li&gt;uploads resume if you reboot your browser or pc, just upload the same files again&lt;/li&gt; 
   &lt;li&gt;server detects any corruption; the client reuploads affected chunks&lt;/li&gt; 
   &lt;li&gt;the client doesn't upload anything that already exists on the server&lt;/li&gt; 
   &lt;li&gt;no filesize limit, even when a proxy limits the request size (for example Cloudflare)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;much higher speeds than ftp/scp/tarpipe on some internet connections (mainly american ones) thanks to parallel connections&lt;/li&gt; 
 &lt;li&gt;the last-modified timestamp of the file is preserved&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;it is perfectly safe to restart / upgrade copyparty while someone is uploading to it!&lt;br&gt; all known up2k clients will resume just fine üí™&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#up2k"&gt;up2k&lt;/a&gt; for details on how it works, or watch a &lt;a href="https://a.ocv.me/pub/demo/pics-vids/#gf-0f6f5c0d"&gt;demo video&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635371-48fc54ca-fa91-48e3-9b1d-ba413e4b68cb.png" alt="copyparty-upload-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;protip:&lt;/strong&gt; you can avoid scaring away users with &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/plugins/minimal-up2k.js"&gt;contrib/plugins/minimal-up2k.js&lt;/a&gt; which makes it look &lt;a href="https://user-images.githubusercontent.com/241032/118311195-dd6ca380-b4ef-11eb-86f3-75a3ff2e1332.png"&gt;much simpler&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;protip:&lt;/strong&gt; if you enable &lt;code&gt;favicon&lt;/code&gt; in the &lt;code&gt;[‚öôÔ∏è] settings&lt;/code&gt; tab (by typing something into the textbox), the icon in the browser tab will indicate upload progress -- also, the &lt;code&gt;[üîî]&lt;/code&gt; and/or &lt;code&gt;[üîä]&lt;/code&gt; switches enable visible and/or audible notifications on upload completion&lt;/p&gt; 
&lt;p&gt;the up2k UI is the epitome of polished intuitive experiences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"parallel uploads" specifies how many chunks to upload at the same time&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üèÉ]&lt;/code&gt; analysis of other files should continue while one is uploading&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ü•î]&lt;/code&gt; shows a simpler UI for faster uploads from slow devices&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üõ°Ô∏è]&lt;/code&gt; decides when to overwrite existing files on the server 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;üõ°Ô∏è&lt;/code&gt; = never (generate a new filename instead)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;üïí&lt;/code&gt; = overwrite if the server-file is older&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;‚ôªÔ∏è&lt;/code&gt; = always overwrite if the files are different&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üé≤]&lt;/code&gt; generate random filenames during upload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[üîé]&lt;/code&gt; switch between upload and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt; mode 
  &lt;ul&gt; 
   &lt;li&gt;ignore &lt;code&gt;[üîé]&lt;/code&gt; if you add files by dragging them into the browser&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and then theres the tabs below it,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[ok]&lt;/code&gt; is the files which completed successfully&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ng]&lt;/code&gt; is the ones that failed / got rejected (already exists, ...)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[done]&lt;/code&gt; shows a combined list of &lt;code&gt;[ok]&lt;/code&gt; and &lt;code&gt;[ng]&lt;/code&gt;, chronological order&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[busy]&lt;/code&gt; files which are currently hashing, pending-upload, or uploading 
  &lt;ul&gt; 
   &lt;li&gt;plus up to 3 entries each from &lt;code&gt;[done]&lt;/code&gt; and &lt;code&gt;[que]&lt;/code&gt; for context&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[que]&lt;/code&gt; is all the files that are still queued&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note that since up2k has to read each file twice, &lt;code&gt;[üéà] bup&lt;/code&gt; can &lt;em&gt;theoretically&lt;/em&gt; be up to 2x faster in some extreme cases (files bigger than your ram, combined with an internet connection faster than the read-speed of your HDD, or if you're uploading from a cuo2duo)&lt;/p&gt; 
&lt;p&gt;if you are resuming a massive upload and want to skip hashing the files which already finished, you can enable &lt;code&gt;turbo&lt;/code&gt; in the &lt;code&gt;[‚öôÔ∏è] config&lt;/code&gt; tab, but please read the tooltip on that button&lt;/p&gt; 
&lt;p&gt;if the server is behind a proxy which imposes a request-size limit, you can configure up2k to sneak below the limit with server-option &lt;code&gt;--u2sz&lt;/code&gt; (the default is 96 MiB to support Cloudflare)&lt;/p&gt; 
&lt;p&gt;if you want to replace existing files on the server with new uploads by default, run with &lt;code&gt;--u2ow 2&lt;/code&gt; (only works if users have the delete-permission, and can still be disabled with &lt;code&gt;üõ°Ô∏è&lt;/code&gt; in the UI)&lt;/p&gt; 
&lt;h3&gt;file-search&lt;/h3&gt; 
&lt;p&gt;dropping files into the browser also lets you see if they exist on the server&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635361-c79286f0-b8f1-440e-aaf4-6e929428fac9.png" alt="copyparty-fsearch-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;when you drag/drop files into the browser, you will see two dropzones: &lt;code&gt;Upload&lt;/code&gt; and &lt;code&gt;Search&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;on a phone? toggle the &lt;code&gt;[üîé]&lt;/code&gt; switch green before tapping the big yellow Search button to select your files&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;the files will be hashed on the client-side, and each hash is sent to the server, which checks if that file exists somewhere&lt;/p&gt; 
&lt;p&gt;files go into &lt;code&gt;[ok]&lt;/code&gt; if they exist (and you get a link to where it is), otherwise they land in &lt;code&gt;[ng]&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the main reason filesearch is combined with the uploader is cause the code was too spaghetti to separate it out somewhere else, this is no longer the case but now i've warmed up to the idea too much&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;unpost&lt;/h3&gt; 
&lt;p&gt;undo/delete accidental uploads using the &lt;code&gt;[üßØ]&lt;/code&gt; tab in the UI&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635368-3afa6634-c20f-418c-90dc-ec411f3b3897.png" alt="copyparty-unpost-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;you can unpost even if you don't have regular move/delete access, however only for files uploaded within the past &lt;code&gt;--unpost&lt;/code&gt; seconds (default 12 hours) and the server must be running with &lt;code&gt;-e2d&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  e2d            # enable up2k database (remember uploads)
  unpost: 43200  # 12 hours (default)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;self-destruct&lt;/h3&gt; 
&lt;p&gt;uploads can be given a lifetime, after which they expire / self-destruct&lt;/p&gt; 
&lt;p&gt;the feature must be enabled per-volume with the &lt;code&gt;lifetime&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#upload-rules"&gt;upload rule&lt;/a&gt; which sets the upper limit for how long a file gets to stay on the server&lt;/p&gt; 
&lt;p&gt;clients can specify a shorter expiration time using the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;up2k ui&lt;/a&gt; -- the relevant options become visible upon navigating into a folder with &lt;code&gt;lifetimes&lt;/code&gt; enabled -- or by using the &lt;code&gt;life&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#write"&gt;upload modifier&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;specifying a custom expiration time client-side will affect the timespan in which unposts are permitted, so keep an eye on the estimates in the up2k ui&lt;/p&gt; 
&lt;h3&gt;race the beam&lt;/h3&gt; 
&lt;p&gt;download files while they're still uploading (&lt;a href="http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm"&gt;demo video&lt;/a&gt;) -- it's almost like peer-to-peer&lt;/p&gt; 
&lt;p&gt;requires the file to be uploaded using up2k (which is the default drag-and-drop uploader), alternatively the command-line program&lt;/p&gt; 
&lt;h3&gt;incoming files&lt;/h3&gt; 
&lt;p&gt;the control-panel shows the ETA for all incoming files , but only for files being uploaded into volumes where you have read-access&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/fd275ffa-698c-4fca-a307-4d2181269a6a" alt="copyparty-cpanel-upload-eta-or8"&gt;&lt;/p&gt; 
&lt;h2&gt;file manager&lt;/h2&gt; 
&lt;p&gt;cut/paste, rename, and delete files/folders (if you have permission)&lt;/p&gt; 
&lt;p&gt;file selection: click somewhere on the line (not the link itself), then:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;space&lt;/code&gt; to toggle&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;up/down&lt;/code&gt; to move&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;shift-up/down&lt;/code&gt; to move-and-select&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;ctrl-shift-up/down&lt;/code&gt; to also scroll&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;shift-click another line for range-select&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;cut: select some files and &lt;code&gt;ctrl-x&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;copy: select some files and &lt;code&gt;ctrl-c&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;paste: &lt;code&gt;ctrl-v&lt;/code&gt; in another folder&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;rename: &lt;code&gt;F2&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;you can copy/move files across browser tabs (cut/copy in one tab, paste in another)&lt;/p&gt; 
&lt;h2&gt;shares&lt;/h2&gt; 
&lt;p&gt;share a file or folder by creating a temporary link&lt;/p&gt; 
&lt;p&gt;when enabled in the server settings (&lt;code&gt;--shr&lt;/code&gt;), click the bottom-right &lt;code&gt;share&lt;/code&gt; button to share the folder you're currently in, or alternatively:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;select a folder first to share that folder instead&lt;/li&gt; 
 &lt;li&gt;select one or more files to share only those files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;this feature was made with &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;identity providers&lt;/a&gt; in mind -- configure your reverseproxy to skip the IdP's access-control for a given URL prefix and use that to safely share specific files/folders sans the usual auth checks&lt;/p&gt; 
&lt;p&gt;when creating a share, the creator can choose any of the following options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;password-protection&lt;/li&gt; 
 &lt;li&gt;expire after a certain time; &lt;code&gt;0&lt;/code&gt; or blank means infinite&lt;/li&gt; 
 &lt;li&gt;allow visitors to upload (if the user who creates the share has write-access)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;semi-intentional limitations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;cleanup of expired shares only works when global option &lt;code&gt;e2d&lt;/code&gt; is set, and/or at least one volume on the server has volflag &lt;code&gt;e2d&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;only folders from the same volume are shared; if you are sharing a folder which contains other volumes, then the contents of those volumes will not be available&lt;/li&gt; 
 &lt;li&gt;if you change &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;password hashing&lt;/a&gt; settings after creating a password-protected share, then that share will stop working&lt;/li&gt; 
 &lt;li&gt;related to &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/idp.md#idp-volumes-are-forgotten-on-shutdown"&gt;IdP volumes being forgotten on shutdown&lt;/a&gt;, any shares pointing into a user's IdP volume will be unavailable until that user makes their first request after a restart&lt;/li&gt; 
 &lt;li&gt;no option to "delete after first access" because tricky 
  &lt;ul&gt; 
   &lt;li&gt;when linking something to discord (for example) it'll get accessed by their scraper and that would count as a hit&lt;/li&gt; 
   &lt;li&gt;browsers wouldn't be able to resume a broken download unless the requester's IP gets allowlisted for X minutes (ref. tricky)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;specify &lt;code&gt;--shr /foobar&lt;/code&gt; to enable this feature; a toplevel virtual folder named &lt;code&gt;foobar&lt;/code&gt; is then created, and that's where all the shares will be served from&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can name it whatever, &lt;code&gt;foobar&lt;/code&gt; is just an example&lt;/li&gt; 
 &lt;li&gt;if you're using config files, put &lt;code&gt;shr: /foobar&lt;/code&gt; inside the &lt;code&gt;[global]&lt;/code&gt; section instead&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;users can delete their own shares in the controlpanel, and a list of privileged users (&lt;code&gt;--shr-adm&lt;/code&gt;) are allowed to see and/or delet any share on the server&lt;/p&gt; 
&lt;p&gt;after a share has expired, it remains visible in the controlpanel for &lt;code&gt;--shr-rt&lt;/code&gt; minutes (default is 1 day), and the owner can revive it by extending the expiration time there&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;security note:&lt;/strong&gt; using this feature does not mean that you can skip the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt; section -- you still need to restrict access to volumes that you do not intend to share with unauthenticated users! it is not sufficient to use rules in the reverseproxy to restrict access to just the &lt;code&gt;/share&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h2&gt;batch rename&lt;/h2&gt; 
&lt;p&gt;select some files and press &lt;code&gt;F2&lt;/code&gt; to bring up the rename UI&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/128434204-eb136680-3c07-4ec7-92e0-ae86af20c241.png" alt="batch-rename-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;quick explanation of the buttons,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[‚úÖ apply rename]&lt;/code&gt; confirms and begins renaming&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[‚ùå cancel]&lt;/code&gt; aborts and closes the rename window&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[‚Ü∫ reset]&lt;/code&gt; reverts any filename changes back to the original name&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[decode]&lt;/code&gt; does a URL-decode on the filename, fixing stuff like &lt;code&gt;&amp;amp;amp;&lt;/code&gt; and &lt;code&gt;%20&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[advanced]&lt;/code&gt; toggles advanced mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;advanced mode: rename files based on rules to decide the new names, based on the original name (regex), or based on the tags collected from the file (artist/title/...), or a mix of both&lt;/p&gt; 
&lt;p&gt;in advanced mode,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[case]&lt;/code&gt; toggles case-sensitive regex&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;regex&lt;/code&gt; is the regex pattern to apply to the original filename; any files which don't match will be skipped&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; is the new filename, taking values from regex capturing groups and/or from file tags 
  &lt;ul&gt; 
   &lt;li&gt;very loosely based on foobar2000 syntax&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;presets&lt;/code&gt; lets you save rename rules for later&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;available functions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;$lpad(text, length, pad_char)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$rpad(text, length, pad_char)&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;so,&lt;/p&gt; 
&lt;p&gt;say you have a file named &lt;a href="https://www.youtube.com/watch?v=-dtb0vDPruI"&gt;&lt;code&gt;meganeko - Eclipse - 07 Sirius A.mp3&lt;/code&gt;&lt;/a&gt; (absolutely fantastic album btw) and the tags are: &lt;code&gt;Album:Eclipse&lt;/code&gt;, &lt;code&gt;Artist:meganeko&lt;/code&gt;, &lt;code&gt;Title:Sirius A&lt;/code&gt;, &lt;code&gt;tn:7&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;you could use just regex to rename it:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;regex&lt;/code&gt; = &lt;code&gt;(.*) - (.*) - ([0-9]{2}) (.*)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; = &lt;code&gt;(3). (1) - (4)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;output&lt;/code&gt; = &lt;code&gt;07. meganeko - Sirius A.mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or you could use just tags:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; = &lt;code&gt;$lpad((tn),2,0). (artist) - (title).(ext)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;output&lt;/code&gt; = &lt;code&gt;7. meganeko - Sirius A.mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or a mix of both:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;regex&lt;/code&gt; = &lt;code&gt;- ([0-9]{2})&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; = &lt;code&gt;(1). (artist) - (title).(ext)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;output&lt;/code&gt; = &lt;code&gt;07. meganeko - Sirius A.mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the metadata keys you can use in the format field are the ones in the file-browser table header (whatever is collected with &lt;code&gt;-mte&lt;/code&gt; and &lt;code&gt;-mtp&lt;/code&gt;)&lt;/p&gt; 
&lt;h2&gt;rss feeds&lt;/h2&gt; 
&lt;p&gt;monitor a folder with your RSS reader , optionally recursive&lt;/p&gt; 
&lt;p&gt;must be enabled per-volume with volflag &lt;code&gt;rss&lt;/code&gt; or globally with &lt;code&gt;--rss&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;the feed includes itunes metadata for use with podcast readers such as &lt;a href="https://antennapod.org/"&gt;AntennaPod&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;a feed example: &lt;a href="https://cd.ocv.me/a/d2/d22/?rss&amp;amp;fext=mp3"&gt;https://cd.ocv.me/a/d2/d22/?rss&amp;amp;fext=mp3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;url parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;pw=hunter2&lt;/code&gt; for password auth&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;recursive&lt;/code&gt; to also include subfolders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title=foo&lt;/code&gt; changes the feed title (default: folder name)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fext=mp3,opus&lt;/code&gt; only include mp3 and opus files (default: all)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nf=30&lt;/code&gt; only show the first 30 results (default: 250)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;sort=m&lt;/code&gt; sort by mtime (file last-modified), newest first (default) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;u&lt;/code&gt; = upload-time; NOTE: non-uploaded files have upload-time &lt;code&gt;0&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;n&lt;/code&gt; = filename&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;a&lt;/code&gt; = filesize&lt;/li&gt; 
   &lt;li&gt;uppercase = reverse-sort; &lt;code&gt;M&lt;/code&gt; = oldest file first&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;recent uploads&lt;/h2&gt; 
&lt;p&gt;list all recent uploads by clicking "show recent uploads" in the controlpanel&lt;/p&gt; 
&lt;p&gt;will show uploader IP and upload-time if the visitor has the admin permission&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;global-option &lt;code&gt;--ups-when&lt;/code&gt; makes upload-time visible to all users, and not just admins&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;global-option &lt;code&gt;--ups-who&lt;/code&gt; (volflag &lt;code&gt;ups_who&lt;/code&gt;) specifies who gets access (0=nobody, 1=admins, 2=everyone), default=2&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note that the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;üßØ unpost&lt;/a&gt; feature is better suited for viewing &lt;em&gt;your own&lt;/em&gt; recent uploads, as it includes the option to undo/delete them&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  ups-when    # everyone can see upload times
  ups-who: 1  # but only admins can see the list,
              # so ups-when doesn't take effect
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;media player&lt;/h2&gt; 
&lt;p&gt;plays almost every audio format there is (if the server has FFmpeg installed for on-demand transcoding)&lt;/p&gt; 
&lt;p&gt;the following audio formats are usually always playable, even without FFmpeg: &lt;code&gt;aac|flac|m4a|mp3|ogg|opus|wav&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;some hilights:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OS integration; control playback from your phone's lockscreen (&lt;a href="https://user-images.githubusercontent.com/241032/233213022-298a98ba-721a-4cf1-a3d4-f62634bc53d5.png"&gt;windows&lt;/a&gt; // &lt;a href="https://user-images.githubusercontent.com/241032/142711926-0700be6c-3e31-47b3-9928-53722221f722.png"&gt;iOS&lt;/a&gt; // &lt;a href="https://user-images.githubusercontent.com/241032/233212311-a7368590-08c7-4f9f-a1af-48ccf3f36fad.png"&gt;android&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;shows the audio waveform in the seekbar&lt;/li&gt; 
 &lt;li&gt;not perfectly gapless but can get really close (see settings + eq below); good enough to enjoy gapless albums as intended&lt;/li&gt; 
 &lt;li&gt;videos can be played as audio, without wasting bandwidth on the video&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;click the &lt;code&gt;play&lt;/code&gt; link next to an audio file, or copy the link target to &lt;a href="https://a.ocv.me/pub/demo/music/Ubiktune%20-%20SOUNDSHOCK%202%20-%20FM%20FUNK%20TERRROR!!/#af-1fbfba61&amp;amp;t=18"&gt;share it&lt;/a&gt; (optionally with a timestamp to start playing from, like that example does)&lt;/p&gt; 
&lt;p&gt;open the &lt;code&gt;[üé∫]&lt;/code&gt; media-player-settings tab to configure it,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"switches": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[üîÅ]&lt;/code&gt; repeats one single song forever&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[üîÄ]&lt;/code&gt; shuffles the files inside each folder&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[preload]&lt;/code&gt; starts loading the next track when it's about to end, reduces the silence between songs&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[full]&lt;/code&gt; does a full preload by downloading the entire next file; good for unreliable connections, bad for slow connections&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[~s]&lt;/code&gt; toggles the seekbar waveform display&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[/np]&lt;/code&gt; enables buttons to copy the now-playing info as an irc message&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[üìª]&lt;/code&gt; enables buttons to create an &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#playlists"&gt;m3u playlist&lt;/a&gt; with the selected songs&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[os-ctl]&lt;/code&gt; makes it possible to control audio playback from the lockscreen of your device (enables &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaSession"&gt;mediasession&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[seek]&lt;/code&gt; allows seeking with lockscreen controls (buggy on some devices)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[art]&lt;/code&gt; shows album art on the lockscreen&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[üéØ]&lt;/code&gt; keeps the playing song scrolled into view (good when using the player as a taskbar dock)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[‚üé]&lt;/code&gt; shrinks the playback controls&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"buttons": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[uncache]&lt;/code&gt; may fix songs that won't play correctly due to bad files in browser cache&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"at end of folder": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[loop]&lt;/code&gt; keeps looping the folder&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[next]&lt;/code&gt; plays into the next folder&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"transcode": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[flac]&lt;/code&gt; converts &lt;code&gt;flac&lt;/code&gt; and &lt;code&gt;wav&lt;/code&gt; files into opus (if supported by browser) or mp3&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[aac]&lt;/code&gt; converts &lt;code&gt;aac&lt;/code&gt; and &lt;code&gt;m4a&lt;/code&gt; files into opus (if supported by browser) or mp3&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[oth]&lt;/code&gt; converts all other known formats into opus (if supported by browser) or mp3 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;aac|ac3|aif|aiff|alac|alaw|amr|ape|au|dfpwm|dts|flac|gsm|it|m4a|mo3|mod|mp2|mp3|mpc|mptm|mt2|mulaw|ogg|okt|opus|ra|s3m|tak|tta|ulaw|wav|wma|wv|xm|xpk&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"transcode to": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[opus]&lt;/code&gt; produces an &lt;code&gt;opus&lt;/code&gt; whenever transcoding is necessary (the best choice on Android and PCs)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[awo]&lt;/code&gt; is &lt;code&gt;opus&lt;/code&gt; in a &lt;code&gt;weba&lt;/code&gt; file, good for iPhones (iOS 17.5 and newer) but Apple is still fixing some state-confusion bugs as of iOS 18.2.1&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[caf]&lt;/code&gt; is &lt;code&gt;opus&lt;/code&gt; in a &lt;code&gt;caf&lt;/code&gt; file, good for iPhones (iOS 11 through 17), technically unsupported by Apple but works for the most part&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[mp3]&lt;/code&gt; -- the myth, the legend, the undying master of mediocre sound quality that definitely works everywhere&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"tint" reduces the contrast of the playback bar&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;playlists&lt;/h3&gt; 
&lt;p&gt;create and play &lt;a href="https://en.wikipedia.org/wiki/M3U"&gt;m3u8&lt;/a&gt; playlists -- see example &lt;a href="https://a.ocv.me/pub/demo/music/?doc=example-playlist.m3u"&gt;text&lt;/a&gt; and &lt;a href="https://a.ocv.me/pub/demo/music/#m3u=example-playlist.m3u"&gt;player&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;click a file with the extension &lt;code&gt;m3u&lt;/code&gt; or &lt;code&gt;m3u8&lt;/code&gt; (for example &lt;code&gt;mixtape.m3u&lt;/code&gt; or &lt;code&gt;touhou.m3u8&lt;/code&gt; ) and you get two choices: Play / Edit&lt;/p&gt; 
&lt;p&gt;playlists can include songs across folders anywhere on the server, but filekeys/dirkeys are NOT supported, so the listener must have read-access or get-access to the files&lt;/p&gt; 
&lt;h3&gt;creating a playlist&lt;/h3&gt; 
&lt;p&gt;with a standalone mediaplayer or copyparty&lt;/p&gt; 
&lt;p&gt;you can use foobar2000, deadbeef, just about any standalone player should work -- but you might need to edit the filepaths in the playlist so they fit with the server-URLs&lt;/p&gt; 
&lt;p&gt;alternatively, you can create the playlist using copyparty itself:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;open the &lt;code&gt;[üé∫]&lt;/code&gt; media-player-settings tab and enable the &lt;code&gt;[üìª]&lt;/code&gt; create-playlist feature -- this adds two new buttons in the bottom-right tray, &lt;code&gt;[üìªadd]&lt;/code&gt; and &lt;code&gt;[üìªcopy]&lt;/code&gt; which appear when you listen to music, or when you select a few audiofiles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;click the &lt;code&gt;üìªadd&lt;/code&gt; button while a song is playing (or when you've selected some songs) and they'll be added to "the list" (you can't see it yet)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;at any time, click &lt;code&gt;üìªcopy&lt;/code&gt; to send the playlist to your clipboard&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you can then continue adding more songs if you'd like&lt;/li&gt; 
   &lt;li&gt;if you want to wipe the playlist and start from scratch, just refresh the page&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;create a new textfile, name it &lt;code&gt;something.m3u&lt;/code&gt; and paste the playlist there&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;audio equalizer&lt;/h3&gt; 
&lt;p&gt;and &lt;a href="https://en.wikipedia.org/wiki/Dynamic_range_compression"&gt;dynamic range compressor&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;can also boost the volume in general, or increase/decrease stereo width (like &lt;a href="https://www.foobar2000.org/components/view/foo_dsp_meiercf"&gt;crossfeed&lt;/a&gt; just worse)&lt;/p&gt; 
&lt;p&gt;has the convenient side-effect of reducing the pause between songs, so gapless albums play better with the eq enabled (just make it flat)&lt;/p&gt; 
&lt;p&gt;not available on iPhones / iPads because AudioContext currently breaks background audio playback on iOS (15.7.8)&lt;/p&gt; 
&lt;h3&gt;fix unreliable playback on android&lt;/h3&gt; 
&lt;p&gt;due to phone / app settings, android phones may randomly stop playing music when the power saver kicks in, especially at the end of an album -- you can fix it by &lt;a href="https://user-images.githubusercontent.com/241032/235262123-c328cca9-3930-4948-bd18-3949b9fd3fcf.png"&gt;disabling power saving&lt;/a&gt; in the &lt;a href="https://user-images.githubusercontent.com/241032/235262121-2ffc51ae-7821-4310-a322-c3b7a507890c.png"&gt;app settings&lt;/a&gt; of the browser you use for music streaming (preferably a dedicated one)&lt;/p&gt; 
&lt;h2&gt;textfile viewer&lt;/h2&gt; 
&lt;p&gt;with realtime streaming of logfiles and such (&lt;a href="https://a.ocv.me/pub/demo/logtail/"&gt;demo&lt;/a&gt;) , and terminal colors work too&lt;/p&gt; 
&lt;p&gt;click &lt;code&gt;-txt-&lt;/code&gt; next to a textfile to open the viewer, which has the following toolbar buttons:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;‚úèÔ∏è edit&lt;/code&gt; opens the textfile editor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üì° follow&lt;/code&gt; starts monitoring the file for changes, streaming new lines in realtime 
  &lt;ul&gt; 
   &lt;li&gt;similar to &lt;code&gt;tail -f&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://a.ocv.me/pub/demo/logtail/?doc=lipsum.txt&amp;amp;tail"&gt;link directly&lt;/a&gt; to a file with tailing enabled by adding &lt;code&gt;&amp;amp;tail&lt;/code&gt; to the textviewer URL&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;markdown viewer&lt;/h2&gt; 
&lt;p&gt;and there are &lt;em&gt;two&lt;/em&gt; editors&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/115978057-66419080-a57d-11eb-8539-d2be843991aa.png" alt="copyparty-md-read-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;there is a built-in extension for inline clickable thumbnails;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;enable it by adding &lt;code&gt;&amp;lt;!-- th --&amp;gt;&lt;/code&gt; somewhere in the doc&lt;/li&gt; 
 &lt;li&gt;add thumbnails with &lt;code&gt;!th[l](your.jpg)&lt;/code&gt; where &lt;code&gt;l&lt;/code&gt; means left-align (&lt;code&gt;r&lt;/code&gt; = right-align)&lt;/li&gt; 
 &lt;li&gt;a single line with &lt;code&gt;---&lt;/code&gt; clears the float / inlining&lt;/li&gt; 
 &lt;li&gt;in the case of README.md being displayed below a file listing, thumbnails will open in the gallery viewer&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;other notes,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the document preview has a max-width which is the same as an A4 paper when printed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;markdown vars&lt;/h3&gt; 
&lt;p&gt;dynamic docs with serverside variable expansion to replace stuff like &lt;code&gt;{{self.ip}}&lt;/code&gt; with the client's IP, or &lt;code&gt;{{srv.htime}}&lt;/code&gt; with the current time on the server&lt;/p&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/srv/expand/"&gt;./srv/expand/&lt;/a&gt; for usage and examples&lt;/p&gt; 
&lt;h2&gt;other tricks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;you can link a particular timestamp in an audio file by adding it to the URL, such as &lt;code&gt;&amp;amp;20&lt;/code&gt; / &lt;code&gt;&amp;amp;20s&lt;/code&gt; / &lt;code&gt;&amp;amp;1m20&lt;/code&gt; / &lt;code&gt;&amp;amp;t=1:20&lt;/code&gt; after the &lt;code&gt;.../#af-c8960dab&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;enabling the audio equalizer can help make gapless albums fully gapless in some browsers (chrome), so consider leaving it on with all the values at zero&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;get a plaintext file listing by adding &lt;code&gt;?ls=t&lt;/code&gt; to a URL, or a compact colored one with &lt;code&gt;?ls=v&lt;/code&gt; (for unix terminals)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if you are using media hotkeys to switch songs and are getting tired of seeing the OSD popup which Windows doesn't let you disable, consider &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#media-osd-bgoneps1"&gt;./contrib/media-osd-bgone.ps1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;click the bottom-left &lt;code&gt;œÄ&lt;/code&gt; to open a javascript prompt for debugging&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;files named &lt;code&gt;.prologue.html&lt;/code&gt; / &lt;code&gt;.epilogue.html&lt;/code&gt; will be rendered before/after directory listings unless &lt;code&gt;--no-logues&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;files named &lt;code&gt;descript.ion&lt;/code&gt; / &lt;code&gt;DESCRIPT.ION&lt;/code&gt; are parsed and displayed in the file listing, or as the epilogue if nonstandard&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;files named &lt;code&gt;README.md&lt;/code&gt; / &lt;code&gt;readme.md&lt;/code&gt; will be rendered after directory listings unless &lt;code&gt;--no-readme&lt;/code&gt; (but &lt;code&gt;.epilogue.html&lt;/code&gt; takes precedence)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and &lt;code&gt;PREADME.md&lt;/code&gt; / &lt;code&gt;preadme.md&lt;/code&gt; is shown above directory listings unless &lt;code&gt;--no-readme&lt;/code&gt; or &lt;code&gt;.prologue.html&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;README.md&lt;/code&gt; and &lt;code&gt;*logue.html&lt;/code&gt; can contain placeholder values which are replaced server-side before embedding into directory listings; see &lt;code&gt;--help-exp&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;searching&lt;/h2&gt; 
&lt;p&gt;search by size, date, path/name, mp3-tags, ...&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635365-c0ff2a9f-0ee5-4fc3-8bb6-006033cf67b8.png" alt="copyparty-search-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;when started with &lt;code&gt;-e2dsa&lt;/code&gt; copyparty will scan/index all your files. This avoids duplicates on upload, and also makes the volumes searchable through the web-ui:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;make search queries by &lt;code&gt;size&lt;/code&gt;/&lt;code&gt;date&lt;/code&gt;/&lt;code&gt;directory-path&lt;/code&gt;/&lt;code&gt;filename&lt;/code&gt;, or...&lt;/li&gt; 
 &lt;li&gt;drag/drop a local file to see if the same contents exist somewhere on the server, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;path/name queries are space-separated, AND'ed together, and words are negated with a &lt;code&gt;-&lt;/code&gt; prefix, so for example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;path: &lt;code&gt;shibayan -bossa&lt;/code&gt; finds all files where one of the folders contain &lt;code&gt;shibayan&lt;/code&gt; but filters out any results where &lt;code&gt;bossa&lt;/code&gt; exists somewhere in the path&lt;/li&gt; 
 &lt;li&gt;name: &lt;code&gt;demetori styx&lt;/code&gt; gives you &lt;a href="https://www.youtube.com/watch?v=zGh0g14ZJ8I&amp;amp;list=PL3A147BD151EE5218&amp;amp;index=9"&gt;good stuff&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the &lt;code&gt;raw&lt;/code&gt; field allows for more complex stuff such as &lt;code&gt;( tags like *nhato* or tags like *taishi* ) and ( not tags like *nhato* or not tags like *taishi* )&lt;/code&gt; which finds all songs by either nhato or taishi, excluding collabs (terrible example, why would you do that)&lt;/p&gt; 
&lt;p&gt;for the above example to work, add the commandline argument &lt;code&gt;-e2ts&lt;/code&gt; to also scan/index tags from music files, which brings us over to:&lt;/p&gt; 
&lt;h1&gt;server config&lt;/h1&gt; 
&lt;p&gt;using arguments or config files, or a mix of both:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;config files (&lt;code&gt;-c some.conf&lt;/code&gt;) can set additional commandline arguments; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example.conf"&gt;./docs/example.conf&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example2.conf"&gt;./docs/example2.conf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;kill -s USR1&lt;/code&gt; (same as &lt;code&gt;systemctl reload copyparty&lt;/code&gt;) to reload accounts and volumes from config files without restarting 
  &lt;ul&gt; 
   &lt;li&gt;or click the &lt;code&gt;[reload cfg]&lt;/code&gt; button in the control-panel if the user has &lt;code&gt;a&lt;/code&gt;/admin in any volume&lt;/li&gt; 
   &lt;li&gt;changes to the &lt;code&gt;[global]&lt;/code&gt; config section requires a restart to take effect&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; as humongous as this readme is, there is also a lot of undocumented features. Run copyparty with &lt;code&gt;--help&lt;/code&gt; to see all available global options; all of those can be used in the &lt;code&gt;[global]&lt;/code&gt; section of config files, and everything listed in &lt;code&gt;--help-flags&lt;/code&gt; can be used in volumes as volflags.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if running in docker/podman, try this: &lt;code&gt;docker run --rm -it copyparty/ac --help&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;or see this (probably outdated): &lt;a href="https://ocv.me/copyparty/helptext.html"&gt;https://ocv.me/copyparty/helptext.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if you prefer plaintext, &lt;a href="https://ocv.me/copyparty/helptext.txt"&gt;https://ocv.me/copyparty/helptext.txt&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;zeroconf&lt;/h2&gt; 
&lt;p&gt;announce enabled services on the LAN (&lt;a href="https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png"&gt;pic&lt;/a&gt;) -- &lt;code&gt;-z&lt;/code&gt; enables both &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mdns"&gt;mdns&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ssdp"&gt;ssdp&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--z-on&lt;/code&gt; / &lt;code&gt;--z-off&lt;/code&gt; limits the feature to certain networks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  z      # enable all zeroconf features (mdns, ssdp)
  zm     # only enables mdns (does nothing since we already have z)
  z-on: 192.168.0.0/16, 10.1.2.0/24  # restrict to certain subnets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;mdns&lt;/h3&gt; 
&lt;p&gt;LAN domain-name and feature announcer&lt;/p&gt; 
&lt;p&gt;uses &lt;a href="https://en.wikipedia.org/wiki/Multicast_DNS"&gt;multicast dns&lt;/a&gt; to give copyparty a domain which any machine on the LAN can use to access it&lt;/p&gt; 
&lt;p&gt;all enabled services (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb&lt;/a&gt;) will appear in mDNS-aware file managers (KDE, gnome, macOS, ...)&lt;/p&gt; 
&lt;p&gt;the domain will be &lt;code&gt;partybox.local&lt;/code&gt; if the machine's hostname is &lt;code&gt;partybox&lt;/code&gt; unless &lt;code&gt;--name&lt;/code&gt; specifies something else&lt;/p&gt; 
&lt;p&gt;and the web-UI will be available at &lt;a href="http://partybox.local:3923/"&gt;http://partybox.local:3923/&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if you want to get rid of the &lt;code&gt;:3923&lt;/code&gt; so you can use &lt;a href="http://partybox.local/"&gt;http://partybox.local/&lt;/a&gt; instead then see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#listen-on-port-80-and-443"&gt;listen on port 80 and 443&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ssdp&lt;/h3&gt; 
&lt;p&gt;windows-explorer announcer&lt;/p&gt; 
&lt;p&gt;uses &lt;a href="https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol"&gt;ssdp&lt;/a&gt; to make copyparty appear in the windows file explorer on all machines on the LAN&lt;/p&gt; 
&lt;p&gt;doubleclicking the icon opens the "connect" page which explains how to mount copyparty as a local filesystem&lt;/p&gt; 
&lt;p&gt;if copyparty does not appear in windows explorer, use &lt;code&gt;--zsv&lt;/code&gt; to see why:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;maybe the discovery multicast was sent from an IP which does not intersect with the server subnets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;qr-code&lt;/h2&gt; 
&lt;p&gt;print a qr-code &lt;a href="https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png"&gt;(screenshot)&lt;/a&gt; for quick access, great between phones on android hotspots which keep changing the subnet&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--qr&lt;/code&gt; enables it&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qrs&lt;/code&gt; does https instead of http&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qrl lootbox/?pw=hunter2&lt;/code&gt; appends to the url, linking to the &lt;code&gt;lootbox&lt;/code&gt; folder with password &lt;code&gt;hunter2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qrz 1&lt;/code&gt; forces 1x zoom instead of autoscaling to fit the terminal size 
  &lt;ul&gt; 
   &lt;li&gt;1x may render incorrectly on some terminals/fonts, but 2x should always work&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;it uses the server hostname if &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mdns"&gt;mdns&lt;/a&gt; is enabled, otherwise it'll use your external ip (default route) unless &lt;code&gt;--qri&lt;/code&gt; specifies a specific ip-prefix or domain&lt;/p&gt; 
&lt;h2&gt;ftp server&lt;/h2&gt; 
&lt;p&gt;an FTP server can be started using &lt;code&gt;--ftp 3921&lt;/code&gt;, and/or &lt;code&gt;--ftps&lt;/code&gt; for explicit TLS (ftpes)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;based on &lt;a href="https://github.com/giampaolo/pyftpdlib"&gt;pyftpdlib&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;needs a dedicated port (cannot share with the HTTP/HTTPS API)&lt;/li&gt; 
 &lt;li&gt;uploads are not resumable -- delete and restart if necessary&lt;/li&gt; 
 &lt;li&gt;runs in active mode by default, you probably want &lt;code&gt;--ftp-pr 12000-13000&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;if you enable both &lt;code&gt;ftp&lt;/code&gt; and &lt;code&gt;ftps&lt;/code&gt;, the port-range will be divided in half&lt;/li&gt; 
   &lt;li&gt;some older software (filezilla on debian-stable) cannot passive-mode with TLS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;login with any username + your password, or put your password in the username field&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some recommended FTP / FTPS clients; &lt;code&gt;wark&lt;/code&gt; = example password:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://winscp.net/eng/download.php"&gt;https://winscp.net/eng/download.php&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://filezilla-project.org/"&gt;https://filezilla-project.org/&lt;/a&gt; struggles a bit with ftps in active-mode, but is fine otherwise&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/"&gt;https://rclone.org/&lt;/a&gt; does FTPS with &lt;code&gt;tls=false explicit_tls=true&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lftp -u k,wark -p 3921 127.0.0.1 -e ls&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lftp -u k,wark -p 3990 127.0.0.1 -e 'set ssl:verify-certificate no; ls'&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;webdav server&lt;/h2&gt; 
&lt;p&gt;with read-write support, supports winXP and later, macos, nautilus/gvfs ... a great way to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mount-as-drive"&gt;access copyparty straight from the file explorer in your OS&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;click the &lt;a href="http://127.0.0.1:3923/?hc"&gt;connect&lt;/a&gt; button in the control-panel to see connection instructions for windows, linux, macos&lt;/p&gt; 
&lt;p&gt;general usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;login with any username + your password, or put your password in the username field (password field can be empty/whatever)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;on macos, connect from finder:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[Go] -&amp;gt; [Connect to Server...] -&amp;gt; &lt;a href="http://192.168.123.1:3923/"&gt;http://192.168.123.1:3923/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;in order to grant full write-access to webdav clients, the volflag &lt;code&gt;daw&lt;/code&gt; must be set and the account must also have delete-access (otherwise the client won't be allowed to replace the contents of existing files, which is how webdav works)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;note: if you have enabled &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;IdP authentication&lt;/a&gt; then that may cause issues for some/most webdav clients; see &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/idp.md#connecting-webdav-clients"&gt;the webdav section in the IdP docs&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;connecting to webdav from windows&lt;/h3&gt; 
&lt;p&gt;using the GUI (winXP or later):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;rightclick [my computer] -&amp;gt; [map network drive] -&amp;gt; Folder: &lt;code&gt;http://192.168.123.1:3923/&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;on winXP only, click the &lt;code&gt;Sign up for online storage&lt;/code&gt; hyperlink instead and put the URL there&lt;/li&gt; 
   &lt;li&gt;providing your password as the username is recommended; the password field can be anything or empty&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the webdav client that's built into windows has the following list of bugs; you can avoid all of these by connecting with rclone instead:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;win7+ doesn't actually send the password to the server when reauthenticating after a reboot unless you first try to login with an incorrect password and then switch to the correct password 
  &lt;ul&gt; 
   &lt;li&gt;or just type your password into the username field instead to get around it entirely&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;connecting to a folder which allows anonymous read will make writing impossible, as windows has decided it doesn't need to login 
  &lt;ul&gt; 
   &lt;li&gt;workaround: connect twice; first to a folder which requires auth, then to the folder you actually want, and leave both of those mounted&lt;/li&gt; 
   &lt;li&gt;or set the server-option &lt;code&gt;--dav-auth&lt;/code&gt; to force password-auth for all webdav clients&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;win7+ may open a new tcp connection for every file and sometimes forgets to close them, eventually needing a reboot 
  &lt;ul&gt; 
   &lt;li&gt;maybe NIC-related (??), happens with win10-ltsc on e1000e but not virtio&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;windows cannot access folders which contain filenames with invalid unicode or forbidden characters (&lt;code&gt;&amp;lt;&amp;gt;:"/\|?*&lt;/code&gt;), or names ending with &lt;code&gt;.&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;winxp cannot show unicode characters outside of &lt;em&gt;some range&lt;/em&gt; 
  &lt;ul&gt; 
   &lt;li&gt;latin-1 is fine, hiragana is not (not even as shift-jis on japanese xp)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;tftp server&lt;/h2&gt; 
&lt;p&gt;a TFTP server (read/write) can be started using &lt;code&gt;--tftp 3969&lt;/code&gt; (you probably want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp&lt;/a&gt; instead unless you are &lt;em&gt;actually&lt;/em&gt; communicating with hardware from the 90s (in which case we should definitely hang some time))&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;that makes this the first RTX DECT Base that has been updated using copyparty üéâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;based on &lt;a href="https://github.com/9001/partftpy"&gt;partftpy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;no accounts; read from world-readable folders, write to world-writable, overwrite in world-deletable&lt;/li&gt; 
 &lt;li&gt;needs a dedicated port (cannot share with the HTTP/HTTPS API) 
  &lt;ul&gt; 
   &lt;li&gt;run as root (or see below) to use the spec-recommended port &lt;code&gt;69&lt;/code&gt; (nice)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;can reply from a predefined portrange (good for firewalls)&lt;/li&gt; 
 &lt;li&gt;only supports the binary/octet/image transfer mode (no netascii)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc7440"&gt;RFC 7440&lt;/a&gt; is &lt;strong&gt;not&lt;/strong&gt; supported, so will be extremely slow over WAN 
  &lt;ul&gt; 
   &lt;li&gt;assuming default blksize (512), expect 1100 KiB/s over 100BASE-T, 400-500 KiB/s over wifi, 200 on bad wifi&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;most clients expect to find TFTP on port 69, but on linux and macos you need to be root to listen on that. Alternatively, listen on 3969 and use NAT on the server to forward 69 to that port;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on linux: &lt;code&gt;iptables -t nat -A PREROUTING -i eth0 -p udp --dport 69 -j REDIRECT --to-port 3969&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some recommended TFTP clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;curl (cross-platform, read/write) 
  &lt;ul&gt; 
   &lt;li&gt;get: &lt;code&gt;curl --tftp-blksize 1428 tftp://127.0.0.1:3969/firmware.bin&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;put: &lt;code&gt;curl --tftp-blksize 1428 -T firmware.bin tftp://127.0.0.1:3969/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;windows: &lt;code&gt;tftp.exe&lt;/code&gt; (you probably already have it) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;tftp -i 127.0.0.1 put firmware.bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;linux: &lt;code&gt;tftp-hpa&lt;/code&gt;, &lt;code&gt;atftp&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;atftp --option "blksize 1428" 127.0.0.1 3969 -p -l firmware.bin -r firmware.bin&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;tftp -v -m binary 127.0.0.1 3969 -c put firmware.bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;smb server&lt;/h2&gt; 
&lt;p&gt;unsafe, slow, not recommended for wan, enable with &lt;code&gt;--smb&lt;/code&gt; for read-only or &lt;code&gt;--smbw&lt;/code&gt; for read-write&lt;/p&gt; 
&lt;p&gt;click the &lt;a href="http://127.0.0.1:3923/?hc"&gt;connect&lt;/a&gt; button in the control-panel to see connection instructions for windows, linux, macos&lt;/p&gt; 
&lt;p&gt;dependencies: &lt;code&gt;python3 -m pip install --user -U impacket==0.11.0&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;newer versions of impacket will hopefully work just fine but there is monkeypatching so maybe not&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some &lt;strong&gt;BIG WARNINGS&lt;/strong&gt; specific to SMB/CIFS, in decreasing importance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;not entirely confident that read-only is read-only&lt;/li&gt; 
 &lt;li&gt;the smb backend is not fully integrated with vfs, meaning there could be security issues (path traversal). Please use &lt;code&gt;--smb-port&lt;/code&gt; (see below) and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/prisonparty.sh"&gt;prisonparty&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/bubbleparty.sh"&gt;bubbleparty&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;account passwords work per-volume as expected, and so does account permissions (read/write/move/delete), but &lt;code&gt;--smbw&lt;/code&gt; must be given to allow write-access from smb&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#shadowing"&gt;shadowing&lt;/a&gt; probably works as expected but no guarantees&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and some minor issues,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;clients only see the first ~400 files in big folders; 
  &lt;ul&gt; 
   &lt;li&gt;this was originally due to &lt;a href="https://github.com/SecureAuthCorp/impacket/issues/1433"&gt;impacket#1433&lt;/a&gt; which was fixed in impacket-0.12, so you can disable the workaround with &lt;code&gt;--smb-nwa-1&lt;/code&gt; but then you get unacceptably poor performance instead&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;hot-reload of server config (&lt;code&gt;/?reload=cfg&lt;/code&gt;) does not include the &lt;code&gt;[global]&lt;/code&gt; section (commandline args)&lt;/li&gt; 
 &lt;li&gt;listens on the first IPv4 &lt;code&gt;-i&lt;/code&gt; interface only (default = :: = 0.0.0.0 = all)&lt;/li&gt; 
 &lt;li&gt;login doesn't work on winxp, but anonymous access is ok -- remove all accounts from copyparty config for that to work 
  &lt;ul&gt; 
   &lt;li&gt;win10 onwards does not allow connecting anonymously / without accounts&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;python3 only&lt;/li&gt; 
 &lt;li&gt;slow (the builtin webdav support in windows is 5x faster, and rclone-webdav is 30x faster)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;known client bugs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on win7 only, &lt;code&gt;--smb1&lt;/code&gt; is much faster than smb2 (default) because it keeps rescanning folders on smb2 
  &lt;ul&gt; 
   &lt;li&gt;however smb1 is buggy and is not enabled by default on win10 onwards&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;windows cannot access folders which contain filenames with invalid unicode or forbidden characters (&lt;code&gt;&amp;lt;&amp;gt;:"/\|?*&lt;/code&gt;), or names ending with &lt;code&gt;.&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the smb protocol listens on TCP port 445, which is a privileged port on linux and macos, which would require running copyparty as root. However, this can be avoided by listening on another port using &lt;code&gt;--smb-port 3945&lt;/code&gt; and then using NAT on the server to forward the traffic from 445 to there;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on linux: &lt;code&gt;iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 445 -j REDIRECT --to-port 3945&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;authenticate with one of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;username &lt;code&gt;$username&lt;/code&gt;, password &lt;code&gt;$password&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;username &lt;code&gt;$password&lt;/code&gt;, password &lt;code&gt;k&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;browser ux&lt;/h2&gt; 
&lt;p&gt;tweaking the ui&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;set default sort order globally with &lt;code&gt;--sort&lt;/code&gt; or per-volume with the &lt;code&gt;sort&lt;/code&gt; volflag; specify one or more comma-separated columns to sort by, and prefix the column name with &lt;code&gt;-&lt;/code&gt; for reverse sort 
  &lt;ul&gt; 
   &lt;li&gt;the column names you can use are visible as tooltips when hovering over the column headers in the directory listing, for example &lt;code&gt;href ext sz ts tags/.up_at tags/Circle tags/.tn tags/Artist tags/Title&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;to sort in music order (album, track, artist, title) with filename as fallback, you could &lt;code&gt;--sort tags/Circle,tags/.tn,tags/Artist,tags/Title,href&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;to sort by upload date, first enable showing the upload date in the listing with &lt;code&gt;-e2d -mte +.up_at&lt;/code&gt; and then &lt;code&gt;--sort tags/.up_at&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rice"&gt;./docs/rice&lt;/a&gt; for more, including how to add stuff (css/&lt;code&gt;&amp;lt;meta&amp;gt;&lt;/code&gt;/...) to the html &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt; tag, or to add your own translation&lt;/p&gt; 
&lt;h2&gt;opengraph&lt;/h2&gt; 
&lt;p&gt;discord and social-media embeds&lt;/p&gt; 
&lt;p&gt;can be enabled globally with &lt;code&gt;--og&lt;/code&gt; or per-volume with volflag &lt;code&gt;og&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;note that this disables hotlinking because the opengraph spec demands it; to sneak past this intentional limitation, you can enable opengraph selectively by user-agent, for example &lt;code&gt;--og-ua '(Discord|Twitter|Slack)bot'&lt;/code&gt; (or volflag &lt;code&gt;og_ua&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;you can also hotlink files regardless by appending &lt;code&gt;?raw&lt;/code&gt; to the url&lt;/p&gt; 
&lt;p&gt;if you want to entirely replace the copyparty response with your own jinja2 template, give the template filepath to &lt;code&gt;--og-tpl&lt;/code&gt; or volflag &lt;code&gt;og_tpl&lt;/code&gt; (all members of &lt;code&gt;HttpCli&lt;/code&gt; are available through the &lt;code&gt;this&lt;/code&gt; object)&lt;/p&gt; 
&lt;h2&gt;file deduplication&lt;/h2&gt; 
&lt;p&gt;enable symlink-based upload deduplication globally with &lt;code&gt;--dedup&lt;/code&gt; or per-volume with volflag &lt;code&gt;dedup&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;by default, when someone tries to upload a file that already exists on the server, the upload will be politely declined, and the server will copy the existing file over to where the upload would have gone&lt;/p&gt; 
&lt;p&gt;if you enable deduplication with &lt;code&gt;--dedup&lt;/code&gt; then it'll create a symlink instead of a full copy, thus reducing disk space usage&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on the contrary, if your server is hooked up to s3-glacier or similar storage where reading is expensive, and you cannot use &lt;code&gt;--safe-dedup=1&lt;/code&gt; because you have other software tampering with your files, so you want to entirely disable detection of duplicate data instead, then you can specify &lt;code&gt;--no-clone&lt;/code&gt; globally or &lt;code&gt;noclone&lt;/code&gt; as a volflag&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;warning:&lt;/strong&gt; when enabling dedup, you should also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;enable indexing with &lt;code&gt;-e2dsa&lt;/code&gt; or volflag &lt;code&gt;e2dsa&lt;/code&gt; (see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt; section below); strongly recommended&lt;/li&gt; 
 &lt;li&gt;...and/or &lt;code&gt;--hardlink-only&lt;/code&gt; to use hardlink-based deduplication instead of symlinks; see explanation below&lt;/li&gt; 
 &lt;li&gt;...and/or &lt;code&gt;--reflink&lt;/code&gt; to use CoW/reflink-based dedup (much safer than hardlink, but OS/FS-dependent)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;it will not be safe to rename/delete files if you only enable dedup and none of the above; if you enable indexing then it is not &lt;em&gt;necessary&lt;/em&gt; to also do hardlinks (but you may still want to)&lt;/p&gt; 
&lt;p&gt;by default, deduplication is done based on symlinks (symbolic links); these are tiny files which are pointers to the nearest full copy of the file&lt;/p&gt; 
&lt;p&gt;you can choose to use hardlinks instead of softlinks, globally with &lt;code&gt;--hardlink-only&lt;/code&gt; or volflag &lt;code&gt;hardlinkonly&lt;/code&gt;, and you can choose to use reflinks with &lt;code&gt;--reflink&lt;/code&gt; or volflag &lt;code&gt;reflink&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;advantages of using reflinks (CoW, copy-on-write):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;entirely safe (when your filesystem supports it correctly); either file can be edited or deleted without affecting other copies&lt;/li&gt; 
 &lt;li&gt;only linux 5.3 or newer, only python 3.14 or newer, only some filesystems (btrfs probably ok, maybe xfs too, but zfs had bugs)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;advantages of using hardlinks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;hardlinks are more compatible with other software; they behave entirely like regular files&lt;/li&gt; 
 &lt;li&gt;you can safely move and rename files using other file managers 
  &lt;ul&gt; 
   &lt;li&gt;symlinks need to be managed by copyparty to ensure the destinations remain correct&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;advantages of using symlinks (default):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;each symlink can have its own last-modified timestamp, but a single timestamp is shared by all hardlinks&lt;/li&gt; 
 &lt;li&gt;symlinks make it more obvious to other software that the file is not a regular file, so this can be less dangerous 
  &lt;ul&gt; 
   &lt;li&gt;hardlinks look like regular files, so other software may assume they are safe to edit without affecting the other copies&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;warning:&lt;/strong&gt; if you edit the contents of a deduplicated file, then you will also edit all other copies of that file! This is especially surprising with hardlinks, because they look like regular files, but that same file exists in multiple locations&lt;/p&gt; 
&lt;p&gt;global-option &lt;code&gt;--xlink&lt;/code&gt; / volflag &lt;code&gt;xlink&lt;/code&gt; additionally enables deduplication across volumes, but this is probably buggy and not recommended&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  e2dsa  # scan and index filesystem on startup
  dedup  # symlink-based deduplication for all volumes

[/media]
  /mnt/nas/media
  flags:
    hardlinkonly  # this vol does hardlinks instead of symlinks
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;file indexing&lt;/h2&gt; 
&lt;p&gt;enable music search, upload-undo, and better dedup&lt;/p&gt; 
&lt;p&gt;file indexing relies on two database tables, the up2k filetree (&lt;code&gt;-e2d&lt;/code&gt;) and the metadata tags (&lt;code&gt;-e2t&lt;/code&gt;), stored in &lt;code&gt;.hist/up2k.db&lt;/code&gt;. Configuration can be done through arguments, volflags, or a mix of both.&lt;/p&gt; 
&lt;p&gt;through arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-e2d&lt;/code&gt; enables file indexing on upload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2ds&lt;/code&gt; also scans writable folders for new files on startup&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2dsa&lt;/code&gt; also scans all mounted volumes (including readonly ones)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2t&lt;/code&gt; enables metadata indexing on upload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2ts&lt;/code&gt; also scans for tags in all files that don't have tags yet&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2tsr&lt;/code&gt; also deletes all existing tags, doing a full reindex&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2v&lt;/code&gt; verifies file integrity at startup, comparing hashes from the db&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2vu&lt;/code&gt; patches the database with the new hashes from the filesystem&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2vp&lt;/code&gt; panics and kills copyparty instead&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the same arguments can be set as volflags, in addition to &lt;code&gt;d2d&lt;/code&gt;, &lt;code&gt;d2ds&lt;/code&gt;, &lt;code&gt;d2t&lt;/code&gt;, &lt;code&gt;d2ts&lt;/code&gt;, &lt;code&gt;d2v&lt;/code&gt; for disabling:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,e2ds,e2tsr&lt;/code&gt; does a full reindex of everything on startup&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2d&lt;/code&gt; disables &lt;strong&gt;all&lt;/strong&gt; indexing, even if any &lt;code&gt;-e2*&lt;/code&gt; are on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2t&lt;/code&gt; disables all &lt;code&gt;-e2t*&lt;/code&gt; (tags), does not affect &lt;code&gt;-e2d*&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2ds&lt;/code&gt; disables on-boot scans; only index new uploads&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2ts&lt;/code&gt; same except only affecting tags&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;upload-times can be displayed in the file listing by enabling the &lt;code&gt;.up_at&lt;/code&gt; metadata key, either globally with &lt;code&gt;-e2d -mte +.up_at&lt;/code&gt; or per-volume with volflags &lt;code&gt;e2d,mte=+.up_at&lt;/code&gt; (will have a ~17% performance impact on directory listings)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;e2tsr&lt;/code&gt; is probably always overkill, since &lt;code&gt;e2ds&lt;/code&gt;/&lt;code&gt;e2dsa&lt;/code&gt; would pick up any file modifications and &lt;code&gt;e2ts&lt;/code&gt; would then reindex those, unless there is a new copyparty version with new parsers and the release note says otherwise&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example (these options are recommended btw):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  e2dsa  # scan and index all files in all volumes on startup
  e2ts   # check newly-discovered or uploaded files for media tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;exclude-patterns&lt;/h3&gt; 
&lt;p&gt;to save some time, you can provide a regex pattern for filepaths to only index by filename/path/size/last-modified (and not the hash of the file contents) by setting &lt;code&gt;--no-hash '\.iso$'&lt;/code&gt; or the volflag &lt;code&gt;:c,nohash=\.iso$&lt;/code&gt;, this has the following consequences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;initial indexing is way faster, especially when the volume is on a network disk&lt;/li&gt; 
 &lt;li&gt;makes it impossible to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;if someone uploads the same file contents, the upload will not be detected as a dupe, so it will not get symlinked or rejected&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;similarly, you can fully ignore files/folders using &lt;code&gt;--no-idx [...]&lt;/code&gt; and &lt;code&gt;:c,noidx=\.iso$&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;NOTE: &lt;code&gt;no-idx&lt;/code&gt; and/or &lt;code&gt;no-hash&lt;/code&gt; prevents deduplication of those files&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;when running on macos, all the usual apple metadata files are excluded by default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you set &lt;code&gt;--no-hash [...]&lt;/code&gt; globally, you can enable hashing for specific volumes using flag &lt;code&gt;:c,nohash=&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;to exclude certain filepaths from search-results, use &lt;code&gt;--srch-excl&lt;/code&gt; or volflag &lt;code&gt;srch_excl&lt;/code&gt; instead of &lt;code&gt;--no-idx&lt;/code&gt;, for example &lt;code&gt;--srch-excl 'password|logs/[0-9]'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/games]
  /mnt/nas/games
  flags:
    noidx: \.iso$  # skip indexing iso-files
    srch_excl: password|logs/[0-9]  # filter search results
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;filesystem guards&lt;/h3&gt; 
&lt;p&gt;avoid traversing into other filesystems using &lt;code&gt;--xdev&lt;/code&gt; / volflag &lt;code&gt;:c,xdev&lt;/code&gt;, skipping any symlinks or bind-mounts to another HDD for example&lt;/p&gt; 
&lt;p&gt;and/or you can &lt;code&gt;--xvol&lt;/code&gt; / &lt;code&gt;:c,xvol&lt;/code&gt; to ignore all symlinks leaving the volume's top directory, but still allow bind-mounts pointing elsewhere&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;symlinks are permitted with &lt;code&gt;xvol&lt;/code&gt; if they point into another volume where the user has the same level of access&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;these options will reduce performance; unlikely worst-case estimates are 14% reduction for directory listings, 35% for download-as-tar&lt;/p&gt; 
&lt;p&gt;as of copyparty v1.7.0 these options also prevent file access at runtime -- in previous versions it was just hints for the indexer&lt;/p&gt; 
&lt;h3&gt;periodic rescan&lt;/h3&gt; 
&lt;p&gt;filesystem monitoring; if copyparty is not the only software doing stuff on your filesystem, you may want to enable periodic rescans to keep the index up to date&lt;/p&gt; 
&lt;p&gt;argument &lt;code&gt;--re-maxage 60&lt;/code&gt; will rescan all volumes every 60 sec, same as volflag &lt;code&gt;:c,scan=60&lt;/code&gt; to specify it per-volume&lt;/p&gt; 
&lt;p&gt;uploads are disabled while a rescan is happening, so rescans will be delayed by &lt;code&gt;--db-act&lt;/code&gt; (default 10 sec) when there is write-activity going on (uploads, renames, ...)&lt;/p&gt; 
&lt;p&gt;note: folder-thumbnails are selected during filesystem indexing, so periodic rescans can be used to keep them accurate as images are uploaded/deleted (or manually do a rescan with the &lt;code&gt;reload&lt;/code&gt; button in the controlpanel)&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  re-maxage: 3600

[/pics]
  /mnt/nas/pics
  flags:
    scan: 900
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;upload rules&lt;/h2&gt; 
&lt;p&gt;set upload rules using volflags, some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;:c,sz=1k-3m&lt;/code&gt; sets allowed filesize between 1 KiB and 3 MiB inclusive (suffixes: &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;k&lt;/code&gt;, &lt;code&gt;m&lt;/code&gt;, &lt;code&gt;g&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,df=4g&lt;/code&gt; block uploads if there would be less than 4 GiB free disk space afterwards&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,vmaxb=1g&lt;/code&gt; block uploads if total volume size would exceed 1 GiB afterwards&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,vmaxn=4k&lt;/code&gt; block uploads if volume would contain more than 4096 files afterwards&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,nosub&lt;/code&gt; disallow uploading into subdirectories; goes well with &lt;code&gt;rotn&lt;/code&gt; and &lt;code&gt;rotf&lt;/code&gt;:&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,rotn=1000,2&lt;/code&gt; moves uploads into subfolders, up to 1000 files in each folder before making a new one, two levels deep (must be at least 1)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,rotf=%Y/%m/%d/%H&lt;/code&gt; enforces files to be uploaded into a structure of subfolders according to that date format 
  &lt;ul&gt; 
   &lt;li&gt;if someone uploads to &lt;code&gt;/foo/bar&lt;/code&gt; the path would be rewritten to &lt;code&gt;/foo/bar/2021/08/06/23&lt;/code&gt; for example&lt;/li&gt; 
   &lt;li&gt;but the actual value is not verified, just the structure, so the uploader can choose any values which conform to the format string 
    &lt;ul&gt; 
     &lt;li&gt;just to avoid additional complexity in up2k which is enough of a mess already&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,lifetime=300&lt;/code&gt; delete uploaded files when they become 5 minutes old&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;you can also set transaction limits which apply per-IP and per-volume, but these assume &lt;code&gt;-j 1&lt;/code&gt; (default) otherwise the limits will be off, for example &lt;code&gt;-j 4&lt;/code&gt; would allow anywhere between 1x and 4x the limits you set depending on which processing node the client gets routed to&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;:c,maxn=250,3600&lt;/code&gt; allows 250 files over 1 hour from each IP (tracked per-volume)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,maxb=1g,300&lt;/code&gt; allows 1 GiB total over 5 minutes from each IP (tracked per-volume)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;vmaxb&lt;/code&gt; and &lt;code&gt;vmaxn&lt;/code&gt; requires either the &lt;code&gt;e2ds&lt;/code&gt; volflag or &lt;code&gt;-e2dsa&lt;/code&gt; global-option&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/inc]
  /mnt/nas/uploads
  accs:
    w: *    # anyone can upload here
    rw: ed  # only user "ed" can read-write
  flags:
    e2ds       # filesystem indexing is required for many of these:
    sz: 1k-3m  # accept upload only if filesize in this range
    df: 4g     # free disk space cannot go lower than this
    vmaxb: 1g  # volume can never exceed 1 GiB
    vmaxn: 4k  # ...or 4000 files, whichever comes first
    nosub      # must upload to toplevel folder
    lifetime: 300   # uploads are deleted after 5min
    maxn: 250,3600  # each IP can upload 250 files in 1 hour
    maxb: 1g,300    # each IP can upload 1 GiB over 5 minutes
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;compress uploads&lt;/h2&gt; 
&lt;p&gt;files can be autocompressed on upload, either on user-request (if config allows) or forced by server-config&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;volflag &lt;code&gt;gz&lt;/code&gt; allows gz compression&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;xz&lt;/code&gt; allows lzma compression&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;pk&lt;/code&gt; &lt;strong&gt;forces&lt;/strong&gt; compression on all files&lt;/li&gt; 
 &lt;li&gt;url parameter &lt;code&gt;pk&lt;/code&gt; requests compression with server-default algorithm&lt;/li&gt; 
 &lt;li&gt;url parameter &lt;code&gt;gz&lt;/code&gt; or &lt;code&gt;xz&lt;/code&gt; requests compression with a specific algorithm&lt;/li&gt; 
 &lt;li&gt;url parameter &lt;code&gt;xz&lt;/code&gt; requests xz compression&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;things to note,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;code&gt;gz&lt;/code&gt; and &lt;code&gt;xz&lt;/code&gt; arguments take a single optional argument, the compression level (range 0 to 9)&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;pk&lt;/code&gt; volflag takes the optional argument &lt;code&gt;ALGORITHM,LEVEL&lt;/code&gt; which will then be forced for all uploads, for example &lt;code&gt;gz,9&lt;/code&gt; or &lt;code&gt;xz,0&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;default compression is gzip level 9&lt;/li&gt; 
 &lt;li&gt;all upload methods except up2k are supported&lt;/li&gt; 
 &lt;li&gt;the files will be indexed after compression, so dupe-detection and file-search will not work as expected&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some examples,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-v inc:inc:w:c,pk=xz,0&lt;/code&gt;&lt;br&gt; folder named inc, shared at inc, write-only for everyone, forces xz compression at level 0&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v inc:inc:w:c,pk&lt;/code&gt;&lt;br&gt; same write-only inc, but forces gz compression (default) instead of xz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v inc:inc:w:c,gz&lt;/code&gt;&lt;br&gt; allows (but does not force) gz compression if client uploads to &lt;code&gt;/inc?pk&lt;/code&gt; or &lt;code&gt;/inc?gz&lt;/code&gt; or &lt;code&gt;/inc?gz=4&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;chmod and chown&lt;/h2&gt; 
&lt;p&gt;per-volume filesystem-permissions and ownership&lt;/p&gt; 
&lt;p&gt;by default:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;all folders are chmod 755&lt;/li&gt; 
 &lt;li&gt;files are usually chmod 644 (umask-defined)&lt;/li&gt; 
 &lt;li&gt;user/group is whatever copyparty is running as&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;this can be configured per-volume:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;volflag &lt;code&gt;chmod_f&lt;/code&gt; sets file permissions; default=&lt;code&gt;644&lt;/code&gt; (usually)&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;chmod_d&lt;/code&gt; sets directory permissions; default=&lt;code&gt;755&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;uid&lt;/code&gt; sets the owner user-id&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;gid&lt;/code&gt; sets the owner group-id&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;gid&lt;/code&gt; can only be set to one of the groups which the copyparty process is a member of&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uid&lt;/code&gt; can only be set if copyparty is running as root (i appreciate your faith)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;other flags&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;:c,magic&lt;/code&gt; enables filetype detection for nameless uploads, same as &lt;code&gt;--magic&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;needs &lt;a href="https://pypi.org/project/python-magic/"&gt;https://pypi.org/project/python-magic/&lt;/a&gt; &lt;code&gt;python3 -m pip install --user -U python-magic&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;on windows grab this instead &lt;code&gt;python3 -m pip install --user -U python-magic-bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;database location&lt;/h2&gt; 
&lt;p&gt;in-volume (&lt;code&gt;.hist/up2k.db&lt;/code&gt;, default) or somewhere else&lt;/p&gt; 
&lt;p&gt;copyparty creates a subfolder named &lt;code&gt;.hist&lt;/code&gt; inside each volume where it stores the database, thumbnails, and some other stuff&lt;/p&gt; 
&lt;p&gt;this can instead be kept in a single place using the &lt;code&gt;--hist&lt;/code&gt; argument, or the &lt;code&gt;hist=&lt;/code&gt; volflag, or a mix of both:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--hist ~/.cache/copyparty -v ~/music::r:c,hist=-&lt;/code&gt; sets &lt;code&gt;~/.cache/copyparty&lt;/code&gt; as the default place to put volume info, but &lt;code&gt;~/music&lt;/code&gt; gets the regular &lt;code&gt;.hist&lt;/code&gt; subfolder (&lt;code&gt;-&lt;/code&gt; restores default behavior)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;by default, the per-volume &lt;code&gt;up2k.db&lt;/code&gt; sqlite3-database for &lt;code&gt;-e2d&lt;/code&gt; and &lt;code&gt;-e2t&lt;/code&gt; is stored next to the thumbnails according to the &lt;code&gt;--hist&lt;/code&gt; option, but the global-option &lt;code&gt;--dbpath&lt;/code&gt; and/or volflag &lt;code&gt;dbpath&lt;/code&gt; can be used to put the database somewhere else&lt;/p&gt; 
&lt;p&gt;if your storage backend is unreliable (NFS or bad HDDs), you can specify one or more "landmarks" to look for before doing anything database-related. A landmark is a file which is always expected to exist inside the volume. This avoids spurious filesystem rescans in the event of an outage. One line per landmark (see example below)&lt;/p&gt; 
&lt;p&gt;note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;putting the hist-folders on an SSD is strongly recommended for performance&lt;/li&gt; 
 &lt;li&gt;markdown edits are always stored in a local &lt;code&gt;.hist&lt;/code&gt; subdirectory&lt;/li&gt; 
 &lt;li&gt;on windows the volflag path is cyglike, so &lt;code&gt;/c/temp&lt;/code&gt; means &lt;code&gt;C:\temp&lt;/code&gt; but use regular paths for &lt;code&gt;--hist&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you can use cygpaths for volumes too, &lt;code&gt;-v C:\Users::r&lt;/code&gt; and &lt;code&gt;-v /c/users::r&lt;/code&gt; both work&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  hist: ~/.cache/copyparty  # put db/thumbs/etc. here by default

[/pics]
  /mnt/nas/pics
  flags:
    hist: -  # restore the default (/mnt/nas/pics/.hist/)
    hist: /mnt/nas/cache/pics/  # can be absolute path
    landmark: me.jpg  # /mnt/nas/pics/me.jpg must be readable to enable db
    landmark: info/a.txt^=ok  # and this textfile must start with "ok"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;metadata from audio files&lt;/h2&gt; 
&lt;p&gt;set &lt;code&gt;-e2t&lt;/code&gt; to index tags on upload&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;-mte&lt;/code&gt; decides which tags to index and display in the browser (and also the display order), this can be changed per-volume:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,mte=title,artist&lt;/code&gt; indexes and displays &lt;em&gt;title&lt;/em&gt; followed by &lt;em&gt;artist&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you add/remove a tag from &lt;code&gt;mte&lt;/code&gt; you will need to run with &lt;code&gt;-e2tsr&lt;/code&gt; once to rebuild the database, otherwise only new files will be affected&lt;/p&gt; 
&lt;p&gt;but instead of using &lt;code&gt;-mte&lt;/code&gt;, &lt;code&gt;-mth&lt;/code&gt; is a better way to hide tags in the browser: these tags will not be displayed by default, but they still get indexed and become searchable, and users can choose to unhide them in the &lt;code&gt;[‚öôÔ∏è] config&lt;/code&gt; pane&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;-mtm&lt;/code&gt; can be used to add or redefine a metadata mapping, say you have media files with &lt;code&gt;foo&lt;/code&gt; and &lt;code&gt;bar&lt;/code&gt; tags and you want them to display as &lt;code&gt;qux&lt;/code&gt; in the browser (preferring &lt;code&gt;foo&lt;/code&gt; if both are present), then do &lt;code&gt;-mtm qux=foo,bar&lt;/code&gt; and now you can &lt;code&gt;-mte artist,title,qux&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;tags that start with a &lt;code&gt;.&lt;/code&gt; such as &lt;code&gt;.bpm&lt;/code&gt; and &lt;code&gt;.dur&lt;/code&gt;(ation) indicate numeric value&lt;/p&gt; 
&lt;p&gt;see the beautiful mess of a dictionary in &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/copyparty/mtag.py"&gt;mtag.py&lt;/a&gt; for the default mappings (should cover mp3,opus,flac,m4a,wav,aif,)&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--no-mutagen&lt;/code&gt; disables Mutagen and uses FFprobe instead, which...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;is about 20x slower than Mutagen&lt;/li&gt; 
 &lt;li&gt;catches a few tags that Mutagen doesn't 
  &lt;ul&gt; 
   &lt;li&gt;melodic key, video resolution, framerate, pixfmt&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;avoids pulling any GPL code into copyparty&lt;/li&gt; 
 &lt;li&gt;more importantly runs FFprobe on incoming files which is bad if your FFmpeg has a cve&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;--mtag-to&lt;/code&gt; sets the tag-scan timeout; very high default (60 sec) to cater for zfs and other randomly-freezing filesystems. Lower values like 10 are usually safe, allowing for faster processing of tricky files&lt;/p&gt; 
&lt;h2&gt;file parser plugins&lt;/h2&gt; 
&lt;p&gt;provide custom parsers to index additional tags, also see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/mtag/README.md"&gt;./bin/mtag/README.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;copyparty can invoke external programs to collect additional metadata for files using &lt;code&gt;mtp&lt;/code&gt; (either as argument or volflag), there is a default timeout of 60sec, and only files which contain audio get analyzed by default (see ay/an/ad below)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-mtp .bpm=~/bin/audio-bpm.py&lt;/code&gt; will execute &lt;code&gt;~/bin/audio-bpm.py&lt;/code&gt; with the audio file as argument 1 to provide the &lt;code&gt;.bpm&lt;/code&gt; tag, if that does not exist in the audio metadata&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-mtp key=f,t5,~/bin/audio-key.py&lt;/code&gt; uses &lt;code&gt;~/bin/audio-key.py&lt;/code&gt; to get the &lt;code&gt;key&lt;/code&gt; tag, replacing any existing metadata tag (&lt;code&gt;f,&lt;/code&gt;), aborting if it takes longer than 5sec (&lt;code&gt;t5,&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,mtp=.bpm=~/bin/audio-bpm.py:c,mtp=key=f,t5,~/bin/audio-key.py&lt;/code&gt; both as a per-volume config wow this is getting ugly&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;but wait, there's more!&lt;/em&gt; &lt;code&gt;-mtp&lt;/code&gt; can be used for non-audio files as well using the &lt;code&gt;a&lt;/code&gt; flag: &lt;code&gt;ay&lt;/code&gt; only do audio files (default), &lt;code&gt;an&lt;/code&gt; only do non-audio files, or &lt;code&gt;ad&lt;/code&gt; do all files (d as in dontcare)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"audio file" also means videos btw, as long as there is an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-mtp ext=an,~/bin/file-ext.py&lt;/code&gt; runs &lt;code&gt;~/bin/file-ext.py&lt;/code&gt; to get the &lt;code&gt;ext&lt;/code&gt; tag only if file is not audio (&lt;code&gt;an&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-mtp arch,built,ver,orig=an,eexe,edll,~/bin/exe.py&lt;/code&gt; runs &lt;code&gt;~/bin/exe.py&lt;/code&gt; to get properties about windows-binaries only if file is not audio (&lt;code&gt;an&lt;/code&gt;) and file extension is exe or dll&lt;/li&gt; 
 &lt;li&gt;if you want to daisychain parsers, use the &lt;code&gt;p&lt;/code&gt; flag to set processing order 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;-mtp foo=p1,~/a.py&lt;/code&gt; runs before &lt;code&gt;-mtp foo=p2,~/b.py&lt;/code&gt; and will forward all the tags detected so far as json to the stdin of b.py&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;option &lt;code&gt;c0&lt;/code&gt; disables capturing of stdout/stderr, so copyparty will not receive any tags from the process at all -- instead the invoked program is free to print whatever to the console, just using copyparty as a launcher 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;c1&lt;/code&gt; captures stdout only, &lt;code&gt;c2&lt;/code&gt; only stderr, and &lt;code&gt;c3&lt;/code&gt; (default) captures both&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;you can control how the parser is killed if it times out with option &lt;code&gt;kt&lt;/code&gt; killing the entire process tree (default), &lt;code&gt;km&lt;/code&gt; just the main process, or &lt;code&gt;kn&lt;/code&gt; let it continue running until copyparty is terminated&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if something doesn't work, try &lt;code&gt;--mtag-v&lt;/code&gt; for verbose error messages&lt;/p&gt; 
&lt;p&gt;config file example; note that &lt;code&gt;mtp&lt;/code&gt; is an additive option so all of the mtp options will take effect:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/music]
  /mnt/nas/music
  flags:
    mtp: .bpm=~/bin/audio-bpm.py  # assign ".bpm" (numeric) with script
    mtp: key=f,t5,~/bin/audio-key.py  # force/overwrite, 5sec timeout
    mtp: ext=an,~/bin/file-ext.py  # will only run on non-audio files
    mtp: arch,built,ver,orig=an,eexe,edll,~/bin/exe.py  # only exe/dll
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;event hooks&lt;/h2&gt; 
&lt;p&gt;trigger a program on uploads, renames etc (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/hooks/"&gt;examples&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;you can set hooks before and/or after an event happens, and currently you can hook uploads, moves/renames, and deletes&lt;/p&gt; 
&lt;p&gt;there's a bunch of flags and stuff, see &lt;code&gt;--help-hooks&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;if you want to write your own hooks, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#event-hooks"&gt;devnotes&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;zeromq&lt;/h3&gt; 
&lt;p&gt;event-hooks can send zeromq messages instead of running programs&lt;/p&gt; 
&lt;p&gt;to send a 0mq message every time a file is uploaded,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--xau zmq:pub:tcp://*:5556&lt;/code&gt; sends a PUB to any/all connected SUB clients&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--xau t3,zmq:push:tcp://*:5557&lt;/code&gt; sends a PUSH to exactly one connected PULL client&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--xau t3,j,zmq:req:tcp://localhost:5555&lt;/code&gt; sends a REQ to the connected REP client&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the PUSH and REQ examples have &lt;code&gt;t3&lt;/code&gt; (timeout after 3 seconds) because they block if there's no clients to talk to&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the REQ example does &lt;code&gt;t3,j&lt;/code&gt; to send extended upload-info as json instead of just the filesystem-path&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;see &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/zmq-recv.py"&gt;zmq-recv.py&lt;/a&gt; if you need something to receive the messages with&lt;/p&gt; 
&lt;p&gt;config file example; note that the hooks are additive options, so all of the xau options will take effect:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  xau: zmq:pub:tcp://*:5556`  # send a PUB to any/all connected SUB clients
  xau: t3,zmq:push:tcp://*:5557`  # send PUSH to exactly one connected PULL cli
  xau: t3,j,zmq:req:tcp://localhost:5555`  # send REQ to the connected REP cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;upload events&lt;/h3&gt; 
&lt;p&gt;the older, more powerful approach (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/mtag/"&gt;examples&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-v /mnt/inc:inc:w:c,e2d,e2t,mte=+x1:c,mtp=x1=ad,kn,/usr/bin/notify-send
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;that was the commandline example; here's the config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/inc]
  /mnt/inc
  accs:
    w: *
  flags:
    e2d, e2t  # enable indexing of uploaded files and their tags
    mte: +x1
    mtp: x1=ad,kn,/usr/bin/notify-send
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;so filesystem location &lt;code&gt;/mnt/inc&lt;/code&gt; shared at &lt;code&gt;/inc&lt;/code&gt;, write-only for everyone, appending &lt;code&gt;x1&lt;/code&gt; to the list of tags to index (&lt;code&gt;mte&lt;/code&gt;), and using &lt;code&gt;/usr/bin/notify-send&lt;/code&gt; to "provide" tag &lt;code&gt;x1&lt;/code&gt; for any filetype (&lt;code&gt;ad&lt;/code&gt;) with kill-on-timeout disabled (&lt;code&gt;kn&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;that'll run the command &lt;code&gt;notify-send&lt;/code&gt; with the path to the uploaded file as the first and only argument (so on linux it'll show a notification on-screen)&lt;/p&gt; 
&lt;p&gt;note that this is way more complicated than the new &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#event-hooks"&gt;event hooks&lt;/a&gt; but this approach has the following advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;non-blocking and multithreaded; doesn't hold other uploads back&lt;/li&gt; 
 &lt;li&gt;you get access to tags from FFmpeg and other mtp parsers&lt;/li&gt; 
 &lt;li&gt;only trigger on new unique files, not dupes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note that it will occupy the parsing threads, so fork anything expensive (or set &lt;code&gt;kn&lt;/code&gt; to have copyparty fork it for you) -- otoh if you want to intentionally queue/singlethread you can combine it with &lt;code&gt;--mtag-mt 1&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;for reference, if you were to do this using event hooks instead, it would be like this: &lt;code&gt;-e2d --xau notify-send,hello,--&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;handlers&lt;/h2&gt; 
&lt;p&gt;redefine behavior with plugins (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/handlers/"&gt;examples&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;replace 404 and 403 errors with something completely different (that's it for now)&lt;/p&gt; 
&lt;p&gt;as for client-side stuff, there is &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/plugins/"&gt;plugins for modifying UI/UX&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ip auth&lt;/h2&gt; 
&lt;p&gt;autologin based on IP range (CIDR) , using the global-option &lt;code&gt;--ipu&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;for example, if everyone with an IP that starts with &lt;code&gt;192.168.123&lt;/code&gt; should automatically log in as the user &lt;code&gt;spartacus&lt;/code&gt;, then you can either specify &lt;code&gt;--ipu=192.168.123.0/24=spartacus&lt;/code&gt; as a commandline option, or put this in a config file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  ipu: 192.168.123.0/24=spartacus
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;repeat the option to map additional subnets&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;be careful with this one!&lt;/strong&gt; if you have a reverseproxy, then you definitely want to make sure you have &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; configured correctly, and it's probably a good idea to nullmap the reverseproxy's IP just in case; so if your reverseproxy is sending requests from &lt;code&gt;172.24.27.9&lt;/code&gt; then that would be &lt;code&gt;--ipu=172.24.27.9/32=&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;identity providers&lt;/h2&gt; 
&lt;p&gt;replace copyparty passwords with oauth and such&lt;/p&gt; 
&lt;p&gt;you can disable the built-in password-based login system, and instead replace it with a separate piece of software (an identity provider) which will then handle authenticating / authorizing of users; this makes it possible to login with passkeys / fido2 / webauthn / yubikey / ldap / active directory / oauth / many other single-sign-on contraptions&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the regular config-defined users will be used as a fallback for requests which don't include a valid (trusted) IdP username header&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some popular identity providers are &lt;a href="https://www.authelia.com/"&gt;Authelia&lt;/a&gt; (config-file based) and &lt;a href="https://goauthentik.io/"&gt;authentik&lt;/a&gt; (GUI-based, more complex)&lt;/p&gt; 
&lt;p&gt;there is a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/docker/idp-authelia-traefik"&gt;docker-compose example&lt;/a&gt; which is hopefully a good starting point (alternatively see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/idp.md"&gt;./docs/idp.md&lt;/a&gt; if you're the DIY type)&lt;/p&gt; 
&lt;p&gt;a more complete example of the copyparty configuration options &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/docker/idp/copyparty.conf"&gt;look like this&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;but if you just want to let users change their own passwords, then you probably want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#user-changeable-passwords"&gt;user-changeable passwords&lt;/a&gt; instead&lt;/p&gt; 
&lt;h2&gt;user-changeable passwords&lt;/h2&gt; 
&lt;p&gt;if permitted, users can change their own passwords in the control-panel&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;not compatible with &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;identity providers&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;must be enabled with &lt;code&gt;--chpw&lt;/code&gt; because account-sharing is a popular usecase&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;if you want to enable the feature but deny password-changing for a specific list of accounts, you can do that with &lt;code&gt;--chpw-no name1,name2,name3,...&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;to perform a password reset, edit the server config and give the user another password there, then do a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#server-config"&gt;config reload&lt;/a&gt; or server restart&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;the custom passwords are kept in a textfile at filesystem-path &lt;code&gt;--chpw-db&lt;/code&gt;, by default &lt;code&gt;chpw.json&lt;/code&gt; in the copyparty config folder&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;if you run multiple copyparty instances with different users you &lt;em&gt;almost definitely&lt;/em&gt; want to specify separate DBs for each instance&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;if &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;password hashing&lt;/a&gt; is enabled, the passwords in the db are also hashed&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;...which means that all user-defined passwords will be forgotten if you change password-hashing settings&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;using the cloud as storage&lt;/h2&gt; 
&lt;p&gt;connecting to an aws s3 bucket and similar&lt;/p&gt; 
&lt;p&gt;there is no built-in support for this, but you can use FUSE-software such as &lt;a href="https://rclone.org/"&gt;rclone&lt;/a&gt; / &lt;a href="https://github.com/yandex-cloud/geesefs"&gt;geesefs&lt;/a&gt; / &lt;a href="https://juicefs.com/en/"&gt;JuiceFS&lt;/a&gt; to first mount your cloud storage as a local disk, and then let copyparty use (a folder in) that disk as a volume&lt;/p&gt; 
&lt;p&gt;if copyparty is unable to access the local folder that rclone/geesefs/JuiceFS provides (for example if it looks invisible) then you may need to run rclone with &lt;code&gt;--allow-other&lt;/code&gt; and/or enable &lt;code&gt;user_allow_other&lt;/code&gt; in &lt;code&gt;/etc/fuse.conf&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;you will probably get decent speeds with the default config, however most likely restricted to using one TCP connection per file, so the upload-client won't be able to send multiple chunks in parallel&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;before &lt;a href="https://github.com/9001/copyparty/releases/tag/v1.13.5"&gt;v1.13.5&lt;/a&gt; it was recommended to use the volflag &lt;code&gt;sparse&lt;/code&gt; to force-allow multiple chunks in parallel; this would improve the upload-speed from &lt;code&gt;1.5 MiB/s&lt;/code&gt; to over &lt;code&gt;80 MiB/s&lt;/code&gt; at the risk of provoking latent bugs in S3 or JuiceFS. But v1.13.5 added chunk-stitching, so this is now probably much less important. On the contrary, &lt;code&gt;nosparse&lt;/code&gt; &lt;em&gt;may&lt;/em&gt; now increase performance in some cases. Please try all three options (default, &lt;code&gt;sparse&lt;/code&gt;, &lt;code&gt;nosparse&lt;/code&gt;) as the optimal choice depends on your network conditions and software stack (both the FUSE-driver and cloud-server)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;someone has also tested geesefs in combination with &lt;a href="https://nuetzlich.net/gocryptfs/"&gt;gocryptfs&lt;/a&gt; with surprisingly good results, getting 60 MiB/s upload speeds on a gbit line, but JuiceFS won with 80 MiB/s using its built-in encryption&lt;/p&gt; 
&lt;p&gt;you may improve performance by specifying larger values for &lt;code&gt;--iobuf&lt;/code&gt; / &lt;code&gt;--s-rd-sz&lt;/code&gt; / &lt;code&gt;--s-wr-sz&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;if you've experimented with this and made interesting observations, please share your findings so we can add a section with specific recommendations :-)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;hiding from google&lt;/h2&gt; 
&lt;p&gt;tell search engines you don't wanna be indexed, either using the good old &lt;a href="https://www.robotstxt.org/robotstxt.html"&gt;robots.txt&lt;/a&gt; or through copyparty settings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--no-robots&lt;/code&gt; adds HTTP (&lt;code&gt;X-Robots-Tag&lt;/code&gt;) and HTML (&lt;code&gt;&amp;lt;meta&amp;gt;&lt;/code&gt;) headers with &lt;code&gt;noindex, nofollow&lt;/code&gt; globally&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;[...]:c,norobots&lt;/code&gt; does the same thing for that single volume&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;[...]:c,robots&lt;/code&gt; ALLOWS search-engine crawling for that volume, even if &lt;code&gt;--no-robots&lt;/code&gt; is set globally&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;also, &lt;code&gt;--force-js&lt;/code&gt; disables the plain HTML folder listing, making things harder to parse for &lt;em&gt;some&lt;/em&gt; search engines -- note that crawlers which understand javascript (such as google) will not be affected&lt;/p&gt; 
&lt;h2&gt;themes&lt;/h2&gt; 
&lt;p&gt;you can change the default theme with &lt;code&gt;--theme 2&lt;/code&gt;, and add your own themes by modifying &lt;code&gt;browser.css&lt;/code&gt; or providing your own css to &lt;code&gt;--css-browser&lt;/code&gt;, then telling copyparty they exist by increasing &lt;code&gt;--themes&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt;
 &lt;tbody&gt;
  &lt;tr&gt;
   &lt;td width="33%" align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864907-17e2ac7d-319d-4f25-8718-2f376f614b51.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867551-fceb35dd-38f0-42bb-bef3-25ba651ca69b.png"&gt;&lt;/a&gt; 0. classic dark&lt;/td&gt;
   &lt;td width="33%" align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/168644399-68938de5-da9b-445f-8d92-b51c74b5f345.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/168644404-8e1a2fdc-6e59-4c41-905e-ba5399ed686f.png"&gt;&lt;/a&gt; 2. flat pm-monokai&lt;/td&gt;
   &lt;td width="33%" align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864901-db13a429-a5da-496d-8bc6-ce838547f69d.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867560-aa834aef-58dc-4abe-baef-7e562b647945.png"&gt;&lt;/a&gt; 4. vice&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864905-692682eb-6fb4-4d40-b6fe-27d2c7d3e2a7.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867555-080b73b6-6d85-41bb-a7c6-ad277c608365.png"&gt;&lt;/a&gt; 1. classic light&lt;/td&gt;
   &lt;td align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/168645276-fb02fd19-190a-407a-b8d3-d58fee277e02.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/168645280-f0662b3c-9764-4875-a2e2-d91cc8199b23.png"&gt;&lt;/a&gt; 3. flat light &lt;/td&gt;
   &lt;td align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864898-10ce7052-a117-4fcf-845b-b56c91687908.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867562-f3003d45-dd2a-4564-8aae-fed44c1ae064.png"&gt;&lt;/a&gt; 5. &lt;a href="https://blog.codinghorror.com/a-tribute-to-the-windows-31-hot-dog-stand-color-scheme/"&gt;hotdog stand&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;the classname of the HTML tag is set according to the selected theme, which is used to set colors as css variables ++&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;each theme &lt;em&gt;generally&lt;/em&gt; has a dark theme (even numbers) and a light theme (odd numbers), showing in pairs&lt;/li&gt; 
 &lt;li&gt;the first theme (theme 0 and 1) is &lt;code&gt;html.a&lt;/code&gt;, second theme (2 and 3) is &lt;code&gt;html.b&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;if a light theme is selected, &lt;code&gt;html.y&lt;/code&gt; is set, otherwise &lt;code&gt;html.z&lt;/code&gt; is&lt;/li&gt; 
 &lt;li&gt;so if the dark edition of the 2nd theme is selected, you use any of &lt;code&gt;html.b&lt;/code&gt;, &lt;code&gt;html.z&lt;/code&gt;, &lt;code&gt;html.bz&lt;/code&gt; to specify rules&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;see the top of &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/copyparty/web/browser.css"&gt;./copyparty/web/browser.css&lt;/a&gt; where the color variables are set, and there's layout-specific stuff near the bottom&lt;/p&gt; 
&lt;p&gt;if you want to change the fonts, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rice/"&gt;./docs/rice/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;complete examples&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/windows.md"&gt;running on windows&lt;/a&gt; for a fancy windows setup&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;or use any of the examples below, just replace &lt;code&gt;python copyparty-sfx.py&lt;/code&gt; with &lt;code&gt;copyparty.exe&lt;/code&gt; if you're using the exe edition&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;allow anyone to download or upload files into the current folder:&lt;br&gt; &lt;code&gt;python copyparty-sfx.py&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;enable searching and music indexing with &lt;code&gt;-e2dsa -e2ts&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;start an FTP server on port 3921 with &lt;code&gt;--ftp 3921&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;announce it on your LAN with &lt;code&gt;-z&lt;/code&gt; so it appears in windows/Linux file managers&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;anyone can upload, but nobody can see any files (even the uploader):&lt;br&gt; &lt;code&gt;python copyparty-sfx.py -e2dsa -v .::w&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;block uploads if there's less than 4 GiB free disk space with &lt;code&gt;--df 4&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;show a popup on new uploads with &lt;code&gt;--xau bin/hooks/notify.py&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;anyone can upload, and receive "secret" links for each upload they do:&lt;br&gt; &lt;code&gt;python copyparty-sfx.py -e2dsa -v .::wG:c,fk=8&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;anyone can browse (&lt;code&gt;r&lt;/code&gt;), only &lt;code&gt;kevin&lt;/code&gt; (password &lt;code&gt;okgo&lt;/code&gt;) can upload/move/delete (&lt;code&gt;A&lt;/code&gt;) files:&lt;br&gt; &lt;code&gt;python copyparty-sfx.py -e2dsa -a kevin:okgo -v .::r:A,kevin&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;read-only music server:&lt;br&gt; &lt;code&gt;python copyparty-sfx.py -v /mnt/nas/music:/music:r -e2dsa -e2ts --no-robots --force-js --theme 2&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;...with bpm and key scanning&lt;br&gt; &lt;code&gt;-mtp .bpm=f,audio-bpm.py -mtp key=f,audio-key.py&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;...with a read-write folder for &lt;code&gt;kevin&lt;/code&gt; whose password is &lt;code&gt;okgo&lt;/code&gt;&lt;br&gt; &lt;code&gt;-a kevin:okgo -v /mnt/nas/inc:/inc:rw,kevin&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;...with logging to disk&lt;br&gt; &lt;code&gt;-lo log/cpp-%Y-%m%d-%H%M%S.txt.xz&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;listen on port 80 and 443&lt;/h2&gt; 
&lt;p&gt;become a &lt;em&gt;real&lt;/em&gt; webserver which people can access by just going to your IP or domain without specifying a port&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;if you're on windows,&lt;/strong&gt; then you just need to add the commandline argument &lt;code&gt;-p 80,443&lt;/code&gt; and you're done! nice&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;if you're on macos,&lt;/strong&gt; sorry, I don't know&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;if you're on Linux,&lt;/strong&gt; you have the following 4 options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 1:&lt;/strong&gt; set up a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; -- this one makes a lot of sense if you're running on a proper headless server, because that way you get real HTTPS too&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 2:&lt;/strong&gt; NAT to port 3923 -- this is cumbersome since you'll need to do it every time you reboot, and the exact command may depend on your linux distribution:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3923
iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port 3923
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 3:&lt;/strong&gt; disable the &lt;a href="https://www.w3.org/Daemon/User/Installation/PrivilegedPorts.html"&gt;security policy&lt;/a&gt; which prevents the use of 80 and 443; this is &lt;em&gt;probably&lt;/em&gt; fine:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;setcap CAP_NET_BIND_SERVICE=+eip $(realpath $(which python))
python copyparty-sfx.py -p 80,443
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 4:&lt;/strong&gt; run copyparty as root (please don't)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;reverse-proxy&lt;/h2&gt; 
&lt;p&gt;running copyparty next to other websites hosted on an existing webserver such as nginx, caddy, or apache&lt;/p&gt; 
&lt;p&gt;you can either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;give copyparty its own domain or subdomain (recommended)&lt;/li&gt; 
 &lt;li&gt;or do location-based proxying, using &lt;code&gt;--rp-loc=/stuff&lt;/code&gt; to tell copyparty where it is mounted -- has a slight performance cost and higher chance of bugs 
  &lt;ul&gt; 
   &lt;li&gt;if copyparty says &lt;code&gt;incorrect --rp-loc or webserver config; expected vpath starting with [...]&lt;/code&gt; it's likely because the webserver is stripping away the proxy location from the request URLs -- see the &lt;code&gt;ProxyPass&lt;/code&gt; in the apache example below&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;when running behind a reverse-proxy (this includes services like cloudflare), it is important to configure real-ip correctly, as many features rely on knowing the client's IP. Look out for red and yellow log messages which explain how to do this. But basically, set &lt;code&gt;--xff-hdr&lt;/code&gt; to the name of the http header to read the IP from (usually &lt;code&gt;x-forwarded-for&lt;/code&gt;, but cloudflare uses &lt;code&gt;cf-connecting-ip&lt;/code&gt;), and then &lt;code&gt;--xff-src&lt;/code&gt; to the IP of the reverse-proxy so copyparty will trust the xff-hdr. Note that &lt;code&gt;--rp-loc&lt;/code&gt; in particular will not work at all unless you do this&lt;/p&gt; 
&lt;p&gt;some reverse proxies (such as &lt;a href="https://caddyserver.com/"&gt;Caddy&lt;/a&gt;) can automatically obtain a valid https/tls certificate for you, and some support HTTP/2 and QUIC which &lt;em&gt;could&lt;/em&gt; be a nice speed boost, depending on a lot of factors&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;warning:&lt;/strong&gt; nginx-QUIC (HTTP/3) is still experimental and can make uploads much slower, so HTTP/1.1 is recommended for now&lt;/li&gt; 
 &lt;li&gt;depending on server/client, HTTP/1.1 can also be 5x faster than HTTP/2&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;for improved security (and a 10% performance boost) consider listening on a unix-socket with &lt;code&gt;-i unix:770:www:/dev/shm/party.sock&lt;/code&gt; (permission &lt;code&gt;770&lt;/code&gt; means only members of group &lt;code&gt;www&lt;/code&gt; can access it)&lt;/p&gt; 
&lt;p&gt;example webserver / reverse-proxy configs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/apache/copyparty.conf"&gt;apache config&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;caddy uds: &lt;code&gt;caddy reverse-proxy --from :8080 --to unix///dev/shm/party.sock&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;caddy tcp: &lt;code&gt;caddy reverse-proxy --from :8081 --to http://127.0.0.1:3923&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/haproxy/copyparty.conf"&gt;haproxy config&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/lighttpd/subdomain.conf"&gt;lighttpd subdomain&lt;/a&gt; -- entire domain/subdomain&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/lighttpd/subpath.conf"&gt;lighttpd subpath&lt;/a&gt; -- location-based (not optimal, but in case you need it)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/nginx/copyparty.conf"&gt;nginx config&lt;/a&gt; -- recommended&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/traefik/copyparty.yaml"&gt;traefik config&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;real-ip&lt;/h3&gt; 
&lt;p&gt;teaching copyparty how to see client IPs when running behind a reverse-proxy, or a WAF, or another protection service such as cloudflare&lt;/p&gt; 
&lt;p&gt;if you (and maybe everybody else) keep getting a message that says &lt;code&gt;thank you for playing&lt;/code&gt;, then you've gotten banned for malicious traffic. This ban applies to the IP address that copyparty &lt;em&gt;thinks&lt;/em&gt; identifies the shady client -- so, depending on your setup, you might have to tell copyparty where to find the correct IP&lt;/p&gt; 
&lt;p&gt;for most common setups, there should be a helpful message in the server-log explaining what to do, but see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/xff.md"&gt;docs/xff.md&lt;/a&gt; if you want to learn more, including a quick hack to &lt;strong&gt;just make it work&lt;/strong&gt; (which is &lt;strong&gt;not&lt;/strong&gt; recommended, but hey...)&lt;/p&gt; 
&lt;h3&gt;reverse-proxy performance&lt;/h3&gt; 
&lt;p&gt;most reverse-proxies support connecting to copyparty either using uds/unix-sockets (&lt;code&gt;/dev/shm/party.sock&lt;/code&gt;, faster/recommended) or using tcp (&lt;code&gt;127.0.0.1&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;with copyparty listening on a uds / unix-socket / unix-domain-socket and the reverse-proxy connecting to that:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;index.html&lt;/th&gt; 
   &lt;th&gt;upload&lt;/th&gt; 
   &lt;th&gt;download&lt;/th&gt; 
   &lt;th&gt;software&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;28'900 req/s&lt;/td&gt; 
   &lt;td&gt;6'900 MiB/s&lt;/td&gt; 
   &lt;td&gt;7'400 MiB/s&lt;/td&gt; 
   &lt;td&gt;no-proxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18'750 req/s&lt;/td&gt; 
   &lt;td&gt;3'500 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'370 MiB/s&lt;/td&gt; 
   &lt;td&gt;haproxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9'900 req/s&lt;/td&gt; 
   &lt;td&gt;3'750 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'200 MiB/s&lt;/td&gt; 
   &lt;td&gt;caddy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18'700 req/s&lt;/td&gt; 
   &lt;td&gt;2'200 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'570 MiB/s&lt;/td&gt; 
   &lt;td&gt;nginx&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9'700 req/s&lt;/td&gt; 
   &lt;td&gt;1'750 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'830 MiB/s&lt;/td&gt; 
   &lt;td&gt;apache&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9'900 req/s&lt;/td&gt; 
   &lt;td&gt;1'300 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'470 MiB/s&lt;/td&gt; 
   &lt;td&gt;lighttpd&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;when connecting the reverse-proxy to &lt;code&gt;127.0.0.1&lt;/code&gt; instead (the basic and/or old-fasioned way), speeds are a bit worse:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;index.html&lt;/th&gt; 
   &lt;th&gt;upload&lt;/th&gt; 
   &lt;th&gt;download&lt;/th&gt; 
   &lt;th&gt;software&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21'200 req/s&lt;/td&gt; 
   &lt;td&gt;5'700 MiB/s&lt;/td&gt; 
   &lt;td&gt;6'700 MiB/s&lt;/td&gt; 
   &lt;td&gt;no-proxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14'500 req/s&lt;/td&gt; 
   &lt;td&gt;1'700 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'170 MiB/s&lt;/td&gt; 
   &lt;td&gt;haproxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11'100 req/s&lt;/td&gt; 
   &lt;td&gt;2'750 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'000 MiB/s&lt;/td&gt; 
   &lt;td&gt;traefik&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8'400 req/s&lt;/td&gt; 
   &lt;td&gt;2'300 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'950 MiB/s&lt;/td&gt; 
   &lt;td&gt;caddy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13'400 req/s&lt;/td&gt; 
   &lt;td&gt;1'100 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'480 MiB/s&lt;/td&gt; 
   &lt;td&gt;nginx&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8'400 req/s&lt;/td&gt; 
   &lt;td&gt;1'000 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'000 MiB/s&lt;/td&gt; 
   &lt;td&gt;apache&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6'500 req/s&lt;/td&gt; 
   &lt;td&gt;1'270 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'500 MiB/s&lt;/td&gt; 
   &lt;td&gt;lighttpd&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;in summary, &lt;code&gt;haproxy &amp;gt; caddy &amp;gt; traefik &amp;gt; nginx &amp;gt; apache &amp;gt; lighttpd&lt;/code&gt;, and use uds when possible (traefik does not support it yet)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if these results are bullshit because my config exampels are bad, please submit corrections!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;permanent cloudflare tunnel&lt;/h2&gt; 
&lt;p&gt;if you have a domain and want to get your copyparty online real quick, either from your home-PC behind a CGNAT or from a server without an existing &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; setup, one approach is to create a &lt;a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/get-started/"&gt;Cloudflare Tunnel&lt;/a&gt; (formerly "Argo Tunnel")&lt;/p&gt; 
&lt;p&gt;I'd recommend making a &lt;code&gt;Locally-managed tunnel&lt;/code&gt; for more control, but if you prefer to make a &lt;code&gt;Remotely-managed tunnel&lt;/code&gt; then this is currently how:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;cloudflare dashboard&lt;/code&gt; ¬ª &lt;code&gt;zero trust&lt;/code&gt; ¬ª &lt;code&gt;networks&lt;/code&gt; ¬ª &lt;code&gt;tunnels&lt;/code&gt; ¬ª &lt;code&gt;create a tunnel&lt;/code&gt; ¬ª &lt;code&gt;cloudflared&lt;/code&gt; ¬ª choose a cool &lt;code&gt;subdomain&lt;/code&gt; and leave the &lt;code&gt;path&lt;/code&gt; blank, and use &lt;code&gt;service type&lt;/code&gt; = &lt;code&gt;http&lt;/code&gt; and &lt;code&gt;URL&lt;/code&gt; = &lt;code&gt;127.0.0.1:3923&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;and if you want to just run the tunnel without installing it, skip the &lt;code&gt;cloudflared service install BASE64&lt;/code&gt; step and instead do &lt;code&gt;cloudflared --no-autoupdate tunnel run --token BASE64&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;NOTE: since people will be connecting through cloudflare, as mentioned in &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; you should run copyparty with &lt;code&gt;--xff-hdr cf-connecting-ip&lt;/code&gt; to detect client IPs correctly&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  xff-hdr: cf-connecting-ip
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;prometheus&lt;/h2&gt; 
&lt;p&gt;metrics/stats can be enabled at URL &lt;code&gt;/.cpr/metrics&lt;/code&gt; for grafana / prometheus / etc (openmetrics 1.0.0)&lt;/p&gt; 
&lt;p&gt;must be enabled with &lt;code&gt;--stats&lt;/code&gt; since it reduces startup time a tiny bit, and you probably want &lt;code&gt;-e2dsa&lt;/code&gt; too&lt;/p&gt; 
&lt;p&gt;the endpoint is only accessible by &lt;code&gt;admin&lt;/code&gt; accounts, meaning the &lt;code&gt;a&lt;/code&gt; in &lt;code&gt;rwmda&lt;/code&gt; in the following example commandline: &lt;code&gt;python3 -m copyparty -a ed:wark -v /mnt/nas::rwmda,ed --stats -e2dsa&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;follow a guide for setting up &lt;code&gt;node_exporter&lt;/code&gt; except have it read from copyparty instead; example &lt;code&gt;/etc/prometheus/prometheus.yml&lt;/code&gt; below&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;scrape_configs:
  - job_name: copyparty
    metrics_path: /.cpr/metrics
    basic_auth:
      password: wark
    static_configs:
      - targets: ['192.168.123.1:3923']
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;currently the following metrics are available,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_uptime_seconds&lt;/code&gt; time since last copyparty restart&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_boot_unixtime_seconds&lt;/code&gt; same but as an absolute timestamp&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_active_dl&lt;/code&gt; number of active downloads&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_http_conns&lt;/code&gt; number of open http(s) connections&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_http_reqs&lt;/code&gt; number of http(s) requests handled&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_sus_reqs&lt;/code&gt; number of 403/422/malicious requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_active_bans&lt;/code&gt; number of currently banned IPs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_total_bans&lt;/code&gt; number of IPs banned since last restart&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;these are available unless &lt;code&gt;--nos-vst&lt;/code&gt; is specified:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_db_idle_seconds&lt;/code&gt; time since last database activity (upload/rename/delete)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_db_act_seconds&lt;/code&gt; same but as an absolute timestamp&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_idle_vols&lt;/code&gt; number of volumes which are idle / ready&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_busy_vols&lt;/code&gt; number of volumes which are busy / indexing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_offline_vols&lt;/code&gt; number of volumes which are offline / unavailable&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_hashing_files&lt;/code&gt; number of files queued for hashing / indexing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_tagq_files&lt;/code&gt; number of files queued for metadata scanning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_mtpq_files&lt;/code&gt; number of files queued for plugin-based analysis&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and these are available per-volume only:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_disk_size_bytes&lt;/code&gt; total HDD size&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_disk_free_bytes&lt;/code&gt; free HDD space&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and these are per-volume and &lt;code&gt;total&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_vol_bytes&lt;/code&gt; size of all files in volume&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_vol_files&lt;/code&gt; number of files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_dupe_bytes&lt;/code&gt; disk space presumably saved by deduplication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_dupe_files&lt;/code&gt; number of dupe files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_unf_bytes&lt;/code&gt; currently unfinished / incoming uploads&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some of the metrics have additional requirements to function correctly,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_vol_*&lt;/code&gt; requires either the &lt;code&gt;e2ds&lt;/code&gt; volflag or &lt;code&gt;-e2dsa&lt;/code&gt; global-option&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the following options are available to disable some of the metrics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--nos-hdd&lt;/code&gt; disables &lt;code&gt;cpp_disk_*&lt;/code&gt; which can prevent spinning up HDDs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-vol&lt;/code&gt; disables &lt;code&gt;cpp_vol_*&lt;/code&gt; which reduces server startup time&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-vst&lt;/code&gt; disables volume state, reducing the worst-case prometheus query time by 0.5 sec&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-dup&lt;/code&gt; disables &lt;code&gt;cpp_dupe_*&lt;/code&gt; which reduces the server load caused by prometheus queries&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-unf&lt;/code&gt; disables &lt;code&gt;cpp_unf_*&lt;/code&gt; for no particular purpose&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note: the following metrics are counted incorrectly if multiprocessing is enabled with &lt;code&gt;-j&lt;/code&gt;: &lt;code&gt;cpp_http_conns&lt;/code&gt;, &lt;code&gt;cpp_http_reqs&lt;/code&gt;, &lt;code&gt;cpp_sus_reqs&lt;/code&gt;, &lt;code&gt;cpp_active_bans&lt;/code&gt;, &lt;code&gt;cpp_total_bans&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;other extremely specific features&lt;/h2&gt; 
&lt;p&gt;you'll never find a use for these:&lt;/p&gt; 
&lt;h3&gt;custom mimetypes&lt;/h3&gt; 
&lt;p&gt;change the association of a file extension&lt;/p&gt; 
&lt;p&gt;using commandline args, you can do something like &lt;code&gt;--mime gif=image/jif&lt;/code&gt; and &lt;code&gt;--mime ts=text/x.typescript&lt;/code&gt; (can be specified multiple times)&lt;/p&gt; 
&lt;p&gt;in a config file, this is the same as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  mime: gif=image/jif
  mime: ts=text/x.typescript
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;run copyparty with &lt;code&gt;--mimes&lt;/code&gt; to list all the default mappings&lt;/p&gt; 
&lt;h3&gt;GDPR compliance&lt;/h3&gt; 
&lt;p&gt;imagine using copyparty professionally... &lt;strong&gt;TINLA/IANAL; EU laws are hella confusing&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;remember to disable logging, or configure logrotation to an acceptable timeframe with &lt;code&gt;-lo cpp-%Y-%m%d.txt.xz&lt;/code&gt; or similar&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if running with the database enabled (recommended), then have it forget uploader-IPs after some time using &lt;code&gt;--forget-ip 43200&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;don't set it too low; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unposting&lt;/a&gt; a file is no longer possible after this takes effect&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if you actually &lt;em&gt;are&lt;/em&gt; a lawyer then I'm open for feedback, would be fun&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;feature chickenbits&lt;/h3&gt; 
&lt;p&gt;buggy feature? rip it out by setting any of the following environment variables to disable its associated bell or whistle,&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;env-var&lt;/th&gt; 
   &lt;th&gt;what it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_DB_LOCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not lock session/shares-databases for exclusive access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_IFADDR&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable ip/nic discovery by poking into your OS with ctypes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_IMPRESO&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not try to load js/css files using &lt;code&gt;importlib.resources&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_IPV6&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable some ipv6 support (should not be necessary since windows 2000)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_LZMA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable streaming xz compression of incoming uploads&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_MP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all use of the python &lt;code&gt;multiprocessing&lt;/code&gt; module (actual multithreading, cpu-count for parsers/thumbnailers)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_SQLITE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all database-related functionality (file indexing, metadata indexing, most file deduplication logic)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_TLS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable native HTTPS support; if you still want to accept HTTPS connections then TLS must now be terminated by a reverse-proxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_TPOKE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable systemd-tmpfilesd avoider&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;example: &lt;code&gt;PRTY_NO_IFADDR=1 python3 copyparty-sfx.py&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;feature beefybits&lt;/h3&gt; 
&lt;p&gt;force-enable features with known issues on your OS/env by setting any of the following environment variables, also affectionately known as &lt;code&gt;fuckitbits&lt;/code&gt; or &lt;code&gt;hail-mary-bits&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;env-var&lt;/th&gt; 
   &lt;th&gt;what it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_FORCE_MP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;force-enable multiprocessing (real multithreading) on MacOS and other broken platforms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_FORCE_MAGIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;use &lt;a href="https://pypi.org/project/python-magic/"&gt;magic&lt;/a&gt; on Windows (you will segfault)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;packages&lt;/h1&gt; 
&lt;p&gt;the party might be closer than you think&lt;/p&gt; 
&lt;p&gt;if your distro/OS is not mentioned below, there might be some hints in the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#on-servers"&gt;¬´on servers¬ª&lt;/a&gt; section&lt;/p&gt; 
&lt;h2&gt;arch package&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;pacman -S copyparty&lt;/code&gt; (in &lt;a href="https://archlinux.org/packages/extra/any/copyparty/"&gt;arch linux extra&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;it comes with a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/package/arch/copyparty.service"&gt;systemd service&lt;/a&gt; and expects to find one or more &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example.conf"&gt;config files&lt;/a&gt; in &lt;code&gt;/etc/copyparty.d/&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;after installing it, you may want to &lt;code&gt;cp /usr/lib/systemd/system/copyparty.service /etc/systemd/system/&lt;/code&gt; and then &lt;code&gt;vim /etc/systemd/system/copyparty.service&lt;/code&gt; to change what user/group it is running as (you only need to do this once)&lt;/p&gt; 
&lt;p&gt;NOTE: there used to be an aur package; this evaporated when copyparty was adopted by the official archlinux repos. If you're still using the aur package, please move&lt;/p&gt; 
&lt;h2&gt;fedora package&lt;/h2&gt; 
&lt;p&gt;does not exist yet; there are rumours that it is being packaged! keep an eye on this space...&lt;/p&gt; 
&lt;h2&gt;nix package&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;nix profile install github:9001/copyparty&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;requires a &lt;a href="https://nixos.wiki/wiki/Flakes"&gt;flake-enabled&lt;/a&gt; installation of nix&lt;/p&gt; 
&lt;p&gt;some recommended dependencies are enabled by default; &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/contrib/package/nix/copyparty/default.nix#L3-L22"&gt;override the package&lt;/a&gt; if you want to add/remove some features/deps&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ffmpeg-full&lt;/code&gt; was chosen over &lt;code&gt;ffmpeg-headless&lt;/code&gt; mainly because we need &lt;code&gt;withWebp&lt;/code&gt; (and &lt;code&gt;withOpenmpt&lt;/code&gt; is also nice) and being able to use a cached build felt more important than optimizing for size at the time -- PRs welcome if you disagree üëç&lt;/p&gt; 
&lt;h2&gt;nixos module&lt;/h2&gt; 
&lt;p&gt;for this setup, you will need a &lt;a href="https://nixos.wiki/wiki/Flakes"&gt;flake-enabled&lt;/a&gt; installation of NixOS.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;{
  # add copyparty flake to your inputs
  inputs.copyparty.url = "github:9001/copyparty";

  # ensure that copyparty is an allowed argument to the outputs function
  outputs = { self, nixpkgs, copyparty }: {
    nixosConfigurations.yourHostName = nixpkgs.lib.nixosSystem {
      modules = [
        # load the copyparty NixOS module
        copyparty.nixosModules.default
        ({ pkgs, ... }: {
          # add the copyparty overlay to expose the package to the module
          nixpkgs.overlays = [ copyparty.overlays.default ];
          # (optional) install the package globally
          environment.systemPackages = [ pkgs.copyparty ];
          # configure the copyparty module
          services.copyparty.enable = true;
        })
      ];
    };
  };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;copyparty on NixOS is configured via &lt;code&gt;services.copyparty&lt;/code&gt; options, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;services.copyparty = {
  enable = true;
  # directly maps to values in the [global] section of the copyparty config.
  # see `copyparty --help` for available options
  settings = {
    i = "0.0.0.0";
    # use lists to set multiple values
    p = [ 3210 3211 ];
    # use booleans to set binary flags
    no-reload = true;
    # using 'false' will do nothing and omit the value when generating a config
    ignored-flag = false;
  };

  # create users
  accounts = {
    # specify the account name as the key
    ed = {
      # provide the path to a file containing the password, keeping it out of /nix/store
      # must be readable by the copyparty service user
      passwordFile = "/run/keys/copyparty/ed_password";
    };
    # or do both in one go
    k.passwordFile = "/run/keys/copyparty/k_password";
  };

  # create a volume
  volumes = {
    # create a volume at "/" (the webroot), which will
    "/" = {
      # share the contents of "/srv/copyparty"
      path = "/srv/copyparty";
      # see `copyparty --help-accounts` for available options
      access = {
        # everyone gets read-access, but
        r = "*";
        # users "ed" and "k" get read-write
        rw = [ "ed" "k" ];
      };
      # see `copyparty --help-flags` for available options
      flags = {
        # "fk" enables filekeys (necessary for upget permission) (4 chars long)
        fk = 4;
        # scan for new files every 60sec
        scan = 60;
        # volflag "e2d" enables the uploads database
        e2d = true;
        # "d2t" disables multimedia parsers (in case the uploads are malicious)
        d2t = true;
        # skips hashing file contents if path matches *.iso
        nohash = "\.iso$";
      };
    };
  };
  # you may increase the open file limit for the process
  openFilesLimit = 8192;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;the passwordFile at /run/keys/copyparty/ could for example be generated by &lt;a href="https://github.com/ryantm/agenix"&gt;agenix&lt;/a&gt;, or you could just dump it in the nix store instead if that's acceptable&lt;/p&gt; 
&lt;h1&gt;browser support&lt;/h1&gt; 
&lt;p&gt;TLDR: yes&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/118192791-fb31fe00-b446-11eb-9647-898ea8efc1f7.png" alt="copyparty-ie4-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ie&lt;/code&gt; = internet-explorer, &lt;code&gt;ff&lt;/code&gt; = firefox, &lt;code&gt;c&lt;/code&gt; = chrome, &lt;code&gt;iOS&lt;/code&gt; = iPhone/iPad, &lt;code&gt;Andr&lt;/code&gt; = Android&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;feature&lt;/th&gt; 
   &lt;th&gt;ie6&lt;/th&gt; 
   &lt;th&gt;ie9&lt;/th&gt; 
   &lt;th&gt;ie10&lt;/th&gt; 
   &lt;th&gt;ie11&lt;/th&gt; 
   &lt;th&gt;ff 52&lt;/th&gt; 
   &lt;th&gt;c 49&lt;/th&gt; 
   &lt;th&gt;iOS&lt;/th&gt; 
   &lt;th&gt;Andr&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;browse files&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;thumbnail view&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;basic uploader&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;up2k&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;make directory&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;send message&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;set sort order&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;zip selection&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file search&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file rename&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file cut/paste&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;unpost uploads&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;navpane&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;image viewer&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;video player&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;markdown editor&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;markdown viewer&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;play mp3/m4a&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;play ogg/opus&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*3&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;= feature =&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;ie6&lt;/td&gt; 
   &lt;td&gt;ie9&lt;/td&gt; 
   &lt;td&gt;ie10&lt;/td&gt; 
   &lt;td&gt;ie11&lt;/td&gt; 
   &lt;td&gt;ff 52&lt;/td&gt; 
   &lt;td&gt;c 49&lt;/td&gt; 
   &lt;td&gt;iOS&lt;/td&gt; 
   &lt;td&gt;Andr&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;internet explorer 6 through 8 behave the same&lt;/li&gt; 
 &lt;li&gt;firefox 52 and chrome 49 are the final winxp versions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*1&lt;/code&gt; yes, but extremely slow (ie10: &lt;code&gt;1 MiB/s&lt;/code&gt;, ie11: &lt;code&gt;270 KiB/s&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*2&lt;/code&gt; only able to do plaintext documents (no markdown rendering)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*3&lt;/code&gt; iOS 11 and newer, opus only, and requires FFmpeg on the server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;quick summary of more eccentric web-browsers trying to view a directory index:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;browser&lt;/th&gt; 
   &lt;th&gt;will it blend&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;links&lt;/strong&gt; (2.21/macports)&lt;/td&gt; 
   &lt;td&gt;can browse, login, upload/mkdir/msg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;lynx&lt;/strong&gt; (2.8.9/macports)&lt;/td&gt; 
   &lt;td&gt;can browse, login, upload/mkdir/msg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;w3m&lt;/strong&gt; (0.5.3/macports)&lt;/td&gt; 
   &lt;td&gt;can browse, login, upload at 100kB/s, mkdir/msg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;netsurf&lt;/strong&gt; (3.10/arch)&lt;/td&gt; 
   &lt;td&gt;is basically ie6 with much better css (javascript has almost no effect)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;opera&lt;/strong&gt; (11.60/winxp)&lt;/td&gt; 
   &lt;td&gt;OK: thumbnails, image-viewer, zip-selection, rename/cut/paste. NG: up2k, navpane, markdown, audio&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ie4&lt;/strong&gt; and &lt;strong&gt;netscape&lt;/strong&gt; 4.0&lt;/td&gt; 
   &lt;td&gt;can browse, upload with &lt;code&gt;?b=u&lt;/code&gt;, auth with &lt;code&gt;&amp;amp;pw=wark&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ncsa mosaic&lt;/strong&gt; 2.7&lt;/td&gt; 
   &lt;td&gt;does not get a pass, &lt;a href="https://user-images.githubusercontent.com/241032/174189227-ae816026-cf6f-4be5-a26e-1b3b072c1b2f.png"&gt;pic1&lt;/a&gt; - &lt;a href="https://user-images.githubusercontent.com/241032/174189225-5651c059-5152-46e9-ac26-7e98e497901b.png"&gt;pic2&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;SerenityOS&lt;/strong&gt; (7e98457)&lt;/td&gt; 
   &lt;td&gt;hits a page fault, works with &lt;code&gt;?b=u&lt;/code&gt;, file upload not-impl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;sony psp&lt;/strong&gt; 5.50&lt;/td&gt; 
   &lt;td&gt;can browse, upload/mkdir/msg (thx dwarf) &lt;a href="https://github.com/user-attachments/assets/9d21f020-1110-4652-abeb-6fc09c533d4f"&gt;screenshot&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;nintendo 3ds&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;can browse, upload, view thumbnails (thx bnjmn)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p align="center"&gt;&lt;img src="https://github.com/user-attachments/assets/88deab3d-6cad-4017-8841-2f041472b853"&gt;&lt;/p&gt; 
&lt;h1&gt;client examples&lt;/h1&gt; 
&lt;p&gt;interact with copyparty using non-browser clients&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;javascript: dump some state into a file (two separate examples)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;await fetch('//127.0.0.1:3923/', {method:"PUT", body: JSON.stringify(foo)});&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;var xhr = new XMLHttpRequest(); xhr.open('POST', '//127.0.0.1:3923/msgs?raw'); xhr.send('foo');&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;curl/wget: upload some files (post=file, chunk=stdin)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;post(){ curl -F f=@"$1" http://127.0.0.1:3923/?pw=wark;}&lt;/code&gt;&lt;br&gt; &lt;code&gt;post movie.mkv&lt;/code&gt; (gives HTML in return)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post(){ curl -F f=@"$1" 'http://127.0.0.1:3923/?want=url&amp;amp;pw=wark';}&lt;/code&gt;&lt;br&gt; &lt;code&gt;post movie.mkv&lt;/code&gt; (gives hotlink in return)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post(){ curl -H pw:wark -H rand:8 -T "$1" http://127.0.0.1:3923/;}&lt;/code&gt;&lt;br&gt; &lt;code&gt;post movie.mkv&lt;/code&gt; (randomized filename)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post(){ wget --header='pw: wark' --post-file="$1" -O- http://127.0.0.1:3923/?raw;}&lt;/code&gt;&lt;br&gt; &lt;code&gt;post movie.mkv&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;chunk(){ curl -H pw:wark -T- http://127.0.0.1:3923/;}&lt;/code&gt;&lt;br&gt; &lt;code&gt;chunk &amp;lt;movie.mkv&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;bash: when curl and wget is not available or too boring&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;(printf 'PUT /junk?pw=wark HTTP/1.1\r\n\r\n'; cat movie.mkv) | nc 127.0.0.1 3923&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;(printf 'PUT / HTTP/1.1\r\n\r\n'; cat movie.mkv) &amp;gt;/dev/tcp/127.0.0.1/3923&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;python: &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/u2c.py"&gt;u2c.py&lt;/a&gt; is a command-line up2k client &lt;a href="https://ocv.me/stuff/u2cli.webm"&gt;(webm)&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;file uploads, file-search, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#folder-sync"&gt;folder sync&lt;/a&gt;, autoresume of aborted/broken uploads&lt;/li&gt; 
   &lt;li&gt;can be downloaded from copyparty: controlpanel -&amp;gt; connect -&amp;gt; &lt;a href="http://127.0.0.1:3923/.cpr/a/u2c.py"&gt;u2c.py&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/README.md#u2cpy"&gt;./bin/README.md#u2cpy&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;FUSE: mount a copyparty server as a local filesystem&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;cross-platform python client available in &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/"&gt;./bin/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;able to mount nginx and iis directory listings too, not just copyparty&lt;/li&gt; 
   &lt;li&gt;can be downloaded from copyparty: controlpanel -&amp;gt; connect -&amp;gt; &lt;a href="http://127.0.0.1:3923/.cpr/a/partyfuse.py"&gt;partyfuse.py&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://rclone.org/"&gt;rclone&lt;/a&gt; as client can give ~5x performance, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;./docs/rclone.md&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;sharex (screenshot utility): see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#sharexsxcu"&gt;./contrib/sharex.sxcu&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and for screenshots on macos, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#ishareiscu"&gt;./contrib/ishare.iscu&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;and for screenshots on linux, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/flameshot.sh"&gt;./contrib/flameshot.sh&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://f-droid.org/en/packages/com.nyx.custom_uploader/"&gt;Custom Uploader&lt;/a&gt; (an Android app) as an alternative to copyparty's own &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#android-app"&gt;PartyUP!&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;works if you set UploadURL to &lt;code&gt;https://your.com/foo/?want=url&amp;amp;pw=hunter2&lt;/code&gt; and FormDataName &lt;code&gt;f&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;contextlet (web browser integration); see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#send-to-cppcontextletjson"&gt;contrib contextlet&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://iglooirc.com/"&gt;igloo irc&lt;/a&gt;: Method: &lt;code&gt;post&lt;/code&gt; Host: &lt;code&gt;https://you.com/up/?want=url&amp;amp;pw=hunter2&lt;/code&gt; Multipart: &lt;code&gt;yes&lt;/code&gt; File parameter: &lt;code&gt;f&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;copyparty returns a truncated sha512sum of your PUT/POST as base64; you can generate the same checksum locally to verify uploads:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;b512(){ printf "$((sha512sum||shasum -a512)|sed -E 's/ .*//;s/(..)/\\x\1/g')"|base64|tr '+/' '-_'|head -c44;}
b512 &amp;lt;movie.mkv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;you can provide passwords using header &lt;code&gt;PW: hunter2&lt;/code&gt;, cookie &lt;code&gt;cppwd=hunter2&lt;/code&gt;, url-param &lt;code&gt;?pw=hunter2&lt;/code&gt;, or with basic-authentication (either as the username or password)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;for basic-authentication, all of the following are accepted: &lt;code&gt;password&lt;/code&gt; / &lt;code&gt;whatever:password&lt;/code&gt; / &lt;code&gt;password:whatever&lt;/code&gt; (the username is ignored)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NOTE: curl will not send the original filename if you use &lt;code&gt;-T&lt;/code&gt; combined with url-params! Also, make sure to always leave a trailing slash in URLs unless you want to override the filename&lt;/p&gt; 
&lt;h2&gt;folder sync&lt;/h2&gt; 
&lt;p&gt;sync folders to/from copyparty&lt;/p&gt; 
&lt;p&gt;NOTE: full bidirectional sync, like what &lt;a href="https://docs.nextcloud.com/server/latest/user_manual/sv/files/desktop_mobile_sync.html"&gt;nextcloud&lt;/a&gt; and &lt;a href="https://syncthing.net/"&gt;syncthing&lt;/a&gt; does, will never be supported! Only single-direction sync (server-to-client, or client-to-server) is possible with copyparty&lt;/p&gt; 
&lt;p&gt;the commandline uploader &lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/bin#u2cpy"&gt;u2c.py&lt;/a&gt; with &lt;code&gt;--dr&lt;/code&gt; is the best way to sync a folder to copyparty; verifies checksums and does files in parallel, and deletes unexpected files on the server after upload has finished which makes file-renames really cheap (it'll rename serverside and skip uploading)&lt;/p&gt; 
&lt;p&gt;alternatively there is &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone&lt;/a&gt; which allows for bidirectional sync and is &lt;em&gt;way&lt;/em&gt; more flexible (stream files straight from sftp/s3/gcs to copyparty, ...), although there is no integrity check and it won't work with files over 100 MiB if copyparty is behind cloudflare&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;starting from rclone v1.63, rclone is faster than u2c.py on low-latency connections&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;mount as drive&lt;/h2&gt; 
&lt;p&gt;a remote copyparty server as a local filesystem; go to the control-panel and click &lt;code&gt;connect&lt;/code&gt; to see a list of commands to do that&lt;/p&gt; 
&lt;p&gt;alternatively, some alternatives roughly sorted by speed (unreproducible benchmark), best first:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone-webdav&lt;/a&gt; (25s), read/WRITE (rclone v1.63 or later)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone-http&lt;/a&gt; (26s), read-only&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/#partyfusepy"&gt;partyfuse.py&lt;/a&gt; (26s), read-only&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone-ftp&lt;/a&gt; (47s), read/WRITE&lt;/li&gt; 
 &lt;li&gt;davfs2 (103s), read/WRITE&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;win10-webdav&lt;/a&gt; (138s), read/WRITE&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;win10-smb2&lt;/a&gt; (387s), read/WRITE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;most clients will fail to mount the root of a copyparty server unless there is a root volume (so you get the admin-panel instead of a browser when accessing it) -- in that case, mount a specific volume instead&lt;/p&gt; 
&lt;p&gt;if you have volumes that are accessible without a password, then some webdav clients (such as davfs2) require the global-option &lt;code&gt;--dav-auth&lt;/code&gt; to access any password-protected areas&lt;/p&gt; 
&lt;h1&gt;android app&lt;/h1&gt; 
&lt;p&gt;upload to copyparty with one tap&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://f-droid.org/packages/me.ocv.partyup/"&gt;&lt;img src="https://ocv.me/fdroid.png" alt="Get it on F-Droid" height="50"&gt; '' &lt;img src="https://img.shields.io/f-droid/v/me.ocv.partyup.svg?sanitize=true" alt="f-droid version info"&gt;&lt;/a&gt; '' &lt;a href="https://github.com/9001/party-up"&gt;&lt;img src="https://img.shields.io/github/release/9001/party-up.svg?logo=github" alt="github version info"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;the app is &lt;strong&gt;NOT&lt;/strong&gt; the full copyparty server! just a basic upload client, nothing fancy yet&lt;/p&gt; 
&lt;p&gt;if you want to run the copyparty server on your android device, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-android"&gt;install on android&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;iOS shortcuts&lt;/h1&gt; 
&lt;p&gt;there is no iPhone app, but the following shortcuts are almost as good:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.icloud.com/shortcuts/41e98dd985cb4d3bb433222bc1e9e770"&gt;upload to copyparty&lt;/a&gt; (&lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/contrib/ios/upload-to-copyparty.shortcut"&gt;offline&lt;/a&gt;) (&lt;a href="https://user-images.githubusercontent.com/241032/226118053-78623554-b0ed-482e-98e4-6d57ada58ea4.png"&gt;png&lt;/a&gt;) based on the &lt;a href="https://www.icloud.com/shortcuts/ab415d5b4de3467b9ce6f151b439a5d7"&gt;original&lt;/a&gt; by &lt;a href="https://github.com/Daedren"&gt;Daedren&lt;/a&gt; (thx!) 
  &lt;ul&gt; 
   &lt;li&gt;can strip exif, upload files, pics, vids, links, clipboard&lt;/li&gt; 
   &lt;li&gt;can download links and rehost the target file on copyparty (see first comment inside the shortcut)&lt;/li&gt; 
   &lt;li&gt;pics become lowres if you share from gallery to shortcut, so better to launch the shortcut and pick stuff from there&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;performance&lt;/h1&gt; 
&lt;p&gt;defaults are usually fine - expect &lt;code&gt;8 GiB/s&lt;/code&gt; download, &lt;code&gt;1 GiB/s&lt;/code&gt; upload&lt;/p&gt; 
&lt;p&gt;below are some tweaks roughly ordered by usefulness:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;disabling HTTP/2 and HTTP/3 can make uploads 5x faster, depending on server/client software&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;-q&lt;/code&gt; disables logging and can help a bunch, even when combined with &lt;code&gt;-lo&lt;/code&gt; to redirect logs to file&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--hist&lt;/code&gt; pointing to a fast location (ssd) will make directory listings and searches faster when &lt;code&gt;-e2d&lt;/code&gt; or &lt;code&gt;-e2t&lt;/code&gt; is set&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and also makes thumbnails load faster, regardless of e2d/e2t&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--dedup&lt;/code&gt; enables deduplication and thus avoids writing to the HDD if someone uploads a dupe&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--safe-dedup 1&lt;/code&gt; makes deduplication much faster during upload by skipping verification of file contents; safe if there is no other software editing/moving the files in the volumes&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--no-dirsz&lt;/code&gt; shows the size of folder inodes instead of the total size of the contents, giving about 30% faster folder listings&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--no-hash .&lt;/code&gt; when indexing a network-disk if you don't care about the actual filehashes and only want the names/tags searchable&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if your volumes are on a network-disk such as NFS / SMB / s3, specifying larger values for &lt;code&gt;--iobuf&lt;/code&gt; and/or &lt;code&gt;--s-rd-sz&lt;/code&gt; and/or &lt;code&gt;--s-wr-sz&lt;/code&gt; may help; try setting all of them to &lt;code&gt;524288&lt;/code&gt; or &lt;code&gt;1048576&lt;/code&gt; or &lt;code&gt;4194304&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--no-htp --hash-mt=0 --mtag-mt=1 --th-mt=1&lt;/code&gt; minimizes the number of threads; can help in some eccentric environments (like the vscode debugger)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;when running on AlpineLinux or other musl-based distro, try mimalloc for higher performance (and twice as much RAM usage); &lt;code&gt;apk add mimalloc2&lt;/code&gt; and run copyparty with env-var &lt;code&gt;LD_PRELOAD=/usr/lib/libmimalloc-secure.so.2&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;note that mimalloc requires special care when combined with prisonparty and/or bubbleparty/bubblewrap; you must give it access to &lt;code&gt;/proc&lt;/code&gt; and &lt;code&gt;/sys&lt;/code&gt; otherwise you'll encounter issues with FFmpeg (audio transcoding, thumbnails)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;-j0&lt;/code&gt; enables multiprocessing (actual multithreading), can reduce latency to &lt;code&gt;20+80/numCores&lt;/code&gt; percent and generally improve performance in cpu-intensive workloads, for example:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;lots of connections (many users or heavy clients)&lt;/li&gt; 
   &lt;li&gt;simultaneous downloads and uploads saturating a 20gbps connection&lt;/li&gt; 
   &lt;li&gt;if &lt;code&gt;-e2d&lt;/code&gt; is enabled, &lt;code&gt;-j2&lt;/code&gt; gives 4x performance for directory listings; &lt;code&gt;-j4&lt;/code&gt; gives 16x&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;...however it also increases the server/filesystem/HDD load during uploads, and adds an overhead to internal communication, so it is usually a better idea to don't&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;using &lt;a href="https://www.pypy.org/"&gt;pypy&lt;/a&gt; instead of &lt;a href="https://www.python.org/"&gt;cpython&lt;/a&gt; &lt;em&gt;can&lt;/em&gt; be 70% faster for some workloads, but slower for many others&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and pypy can sometimes crash on startup with &lt;code&gt;-j0&lt;/code&gt; (TODO make issue)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;client-side&lt;/h2&gt; 
&lt;p&gt;when uploading files,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;when uploading from very fast storage (NVMe SSD) with chrome/firefox, enable &lt;code&gt;[wasm]&lt;/code&gt; in the &lt;code&gt;[‚öôÔ∏è] settings&lt;/code&gt; tab to more effectively use all CPU-cores for hashing&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;don't do this on Safari (runs faster without)&lt;/li&gt; 
   &lt;li&gt;don't do this on older browsers; likely to provoke browser-bugs (browser eats all RAM and crashes)&lt;/li&gt; 
   &lt;li&gt;can be made default-enabled serverside with &lt;code&gt;--nosubtle 137&lt;/code&gt; (chrome v137+) or &lt;code&gt;--nosubtle 2&lt;/code&gt; (chrome+firefox)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;chrome is recommended (unfortunately), at least compared to firefox:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;up to 90% faster when hashing, especially on SSDs&lt;/li&gt; 
   &lt;li&gt;up to 40% faster when uploading over extremely fast internets&lt;/li&gt; 
   &lt;li&gt;but &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/u2c.py"&gt;u2c.py&lt;/a&gt; can be 40% faster than chrome again&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if you're cpu-bottlenecked, or the browser is maxing a cpu core:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;up to 30% faster uploads if you hide the upload status list by switching away from the &lt;code&gt;[üöÄ]&lt;/code&gt; up2k ui-tab (or closing it) 
    &lt;ul&gt; 
     &lt;li&gt;optionally you can switch to the lightweight potato ui by clicking the &lt;code&gt;[ü•î]&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;switching to another browser-tab also works, the favicon will update every 10 seconds in that case&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;unlikely to be a problem, but can happen when uploading many small files, or your internet is too fast, or PC too slow&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;security&lt;/h1&gt; 
&lt;p&gt;there is a &lt;a href="https://discord.gg/25J8CdTT6G"&gt;discord server&lt;/a&gt; with an &lt;code&gt;@everyone&lt;/code&gt; for all important updates (at the lack of better ideas)&lt;/p&gt; 
&lt;p&gt;some notes on hardening&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;set &lt;code&gt;--rproxy 0&lt;/code&gt; if your copyparty is directly facing the internet (not through a reverse-proxy) 
  &lt;ul&gt; 
   &lt;li&gt;cors doesn't work right otherwise&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;if you allow anonymous uploads or otherwise don't trust the contents of a volume, you can prevent XSS with volflag &lt;code&gt;nohtml&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;this returns html documents as plaintext, and also disables markdown rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when running behind a reverse-proxy, listen on a unix-socket for tighter access control (and more performance); see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; or &lt;code&gt;--help-bind&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;safety profiles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;option &lt;code&gt;-s&lt;/code&gt; is a shortcut to set the following options:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--no-thumb&lt;/code&gt; disables thumbnails and audio transcoding to stop copyparty from running &lt;code&gt;FFmpeg&lt;/code&gt;/&lt;code&gt;Pillow&lt;/code&gt;/&lt;code&gt;VIPS&lt;/code&gt; on uploaded files, which is a &lt;a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=3611"&gt;good idea&lt;/a&gt; if anonymous upload is enabled&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--no-mtag-ff&lt;/code&gt; uses &lt;code&gt;mutagen&lt;/code&gt; to grab music tags instead of &lt;code&gt;FFmpeg&lt;/code&gt;, which is safer and faster but less accurate&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--dotpart&lt;/code&gt; hides uploads from directory listings while they're still incoming&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--no-robots&lt;/code&gt; and &lt;code&gt;--force-js&lt;/code&gt; makes life harder for crawlers, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#hiding-from-google"&gt;hiding from google&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;option &lt;code&gt;-ss&lt;/code&gt; is a shortcut for the above plus:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--unpost 0&lt;/code&gt;, &lt;code&gt;--no-del&lt;/code&gt;, &lt;code&gt;--no-mv&lt;/code&gt; disables all move/delete support&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--hardlink&lt;/code&gt; creates hardlinks instead of symlinks when deduplicating uploads, which is less maintenance 
    &lt;ul&gt; 
     &lt;li&gt;however note if you edit one file it will also affect the other copies&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--vague-403&lt;/code&gt; returns a "404 not found" instead of "401 unauthorized" which is a common enterprise meme&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-nih&lt;/code&gt; removes the server hostname from directory listings&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;option &lt;code&gt;-sss&lt;/code&gt; is a shortcut for the above plus:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--no-dav&lt;/code&gt; disables webdav support&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--no-logues&lt;/code&gt; and &lt;code&gt;--no-readme&lt;/code&gt; disables support for readme's and prologues / epilogues in directory listings, which otherwise lets people upload arbitrary (but sandboxed) &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-lo cpp-%Y-%m%d-%H%M%S.txt.xz&lt;/code&gt; enables logging to disk&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-ls **,*,ln,p,r&lt;/code&gt; does a scan on startup for any dangerous symlinks&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;other misc notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can disable directory listings by giving permission &lt;code&gt;g&lt;/code&gt; instead of &lt;code&gt;r&lt;/code&gt;, only accepting direct URLs to files 
  &lt;ul&gt; 
   &lt;li&gt;you may want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekeys&lt;/a&gt; to prevent filename bruteforcing&lt;/li&gt; 
   &lt;li&gt;permission &lt;code&gt;h&lt;/code&gt; instead of &lt;code&gt;r&lt;/code&gt; makes copyparty behave like a traditional webserver with directory listing/index disabled, returning index.html instead 
    &lt;ul&gt; 
     &lt;li&gt;compatibility with filekeys: index.html itself can be retrieved without the correct filekey, but all other files are protected&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;gotchas&lt;/h2&gt; 
&lt;p&gt;behavior that might be unexpected&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;users without read-access to a folder can still see the &lt;code&gt;.prologue.html&lt;/code&gt; / &lt;code&gt;.epilogue.html&lt;/code&gt; / &lt;code&gt;PREADME.md&lt;/code&gt; / &lt;code&gt;README.md&lt;/code&gt; contents, for the purpose of showing a description on how to use the uploader for example&lt;/li&gt; 
 &lt;li&gt;users can submit &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;s which autorun (in a sandbox) for other visitors in a few ways; 
  &lt;ul&gt; 
   &lt;li&gt;uploading a &lt;code&gt;README.md&lt;/code&gt; -- avoid with &lt;code&gt;--no-readme&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;renaming &lt;code&gt;some.html&lt;/code&gt; to &lt;code&gt;.epilogue.html&lt;/code&gt; -- avoid with either &lt;code&gt;--no-logues&lt;/code&gt; or &lt;code&gt;--no-dot-ren&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;the directory-listing embed is sandboxed (so any malicious scripts can't do any damage) but the markdown editor is not 100% safe, see below&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;markdown documents can contain html and &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;s; attempts are made to prevent scripts from executing (unless &lt;code&gt;-emp&lt;/code&gt; is specified) but this is not 100% bulletproof, so setting the &lt;code&gt;nohtml&lt;/code&gt; volflag is still the safest choice 
  &lt;ul&gt; 
   &lt;li&gt;or eliminate the problem entirely by only giving write-access to trustworthy people :^)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;cors&lt;/h2&gt; 
&lt;p&gt;cross-site request config&lt;/p&gt; 
&lt;p&gt;by default, except for &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;HEAD&lt;/code&gt; operations, all requests must either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;not contain an &lt;code&gt;Origin&lt;/code&gt; header at all&lt;/li&gt; 
 &lt;li&gt;or have an &lt;code&gt;Origin&lt;/code&gt; matching the server domain&lt;/li&gt; 
 &lt;li&gt;or the header &lt;code&gt;PW&lt;/code&gt; with your password as value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;cors can be configured with &lt;code&gt;--acao&lt;/code&gt; and &lt;code&gt;--acam&lt;/code&gt;, or the protections entirely disabled with &lt;code&gt;--allow-csrf&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;filekeys&lt;/h2&gt; 
&lt;p&gt;prevent filename bruteforcing&lt;/p&gt; 
&lt;p&gt;volflag &lt;code&gt;fk&lt;/code&gt; generates filekeys (per-file accesskeys) for all files; users which have full read-access (permission &lt;code&gt;r&lt;/code&gt;) will then see URLs with the correct filekey &lt;code&gt;?k=...&lt;/code&gt; appended to the end, and &lt;code&gt;g&lt;/code&gt; users must provide that URL including the correct key to avoid a 404&lt;/p&gt; 
&lt;p&gt;by default, filekeys are generated based on salt (&lt;code&gt;--fk-salt&lt;/code&gt;) + filesystem-path + file-size + inode (if not windows); add volflag &lt;code&gt;fka&lt;/code&gt; to generate slightly weaker filekeys which will not be invalidated if the file is edited (only salt + path)&lt;/p&gt; 
&lt;p&gt;permissions &lt;code&gt;wG&lt;/code&gt; (write + upget) lets users upload files and receive their own filekeys, still without being able to see other uploads&lt;/p&gt; 
&lt;h3&gt;dirkeys&lt;/h3&gt; 
&lt;p&gt;share specific folders in a volume without giving away full read-access to the rest -- the visitor only needs the &lt;code&gt;g&lt;/code&gt; (get) permission to view the link&lt;/p&gt; 
&lt;p&gt;volflag &lt;code&gt;dk&lt;/code&gt; generates dirkeys (per-directory accesskeys) for all folders, granting read-access to that folder; by default only that folder itself, no subfolders&lt;/p&gt; 
&lt;p&gt;volflag &lt;code&gt;dky&lt;/code&gt; disables the actual key-check, meaning anyone can see the contents of a folder where they have &lt;code&gt;g&lt;/code&gt; access, but not its subdirectories&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;dk&lt;/code&gt; + &lt;code&gt;dky&lt;/code&gt; gives the same behavior as if all users with &lt;code&gt;g&lt;/code&gt; access have full read-access, but subfolders are hidden files (as if their names start with a dot), so &lt;code&gt;dky&lt;/code&gt; is an alternative to renaming all the folders for that purpose, maybe just for some users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;volflag &lt;code&gt;dks&lt;/code&gt; lets people enter subfolders as well, and also enables download-as-zip/tar&lt;/p&gt; 
&lt;p&gt;if you enable dirkeys, it is probably a good idea to enable filekeys too, otherwise it will be impossible to hotlink files from a folder which was accessed using a dirkey&lt;/p&gt; 
&lt;p&gt;dirkeys are generated based on another salt (&lt;code&gt;--dk-salt&lt;/code&gt;) + filesystem-path and have a few limitations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the key does not change if the contents of the folder is modified 
  &lt;ul&gt; 
   &lt;li&gt;if you need a new dirkey, either change the salt or rename the folder&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;linking to a textfile (so it opens in the textfile viewer) is not possible if recipient doesn't have read-access&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;password hashing&lt;/h2&gt; 
&lt;p&gt;you can hash passwords before putting them into config files / providing them as arguments; see &lt;code&gt;--help-pwhash&lt;/code&gt; for all the details&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--ah-alg argon2&lt;/code&gt; enables it, and if you have any plaintext passwords then it'll print the hashed versions on startup so you can replace them&lt;/p&gt; 
&lt;p&gt;optionally also specify &lt;code&gt;--ah-cli&lt;/code&gt; to enter an interactive mode where it will hash passwords without ever writing the plaintext ones to disk&lt;/p&gt; 
&lt;p&gt;the default configs take about 0.4 sec and 256 MiB RAM to process a new password on a decent laptop&lt;/p&gt; 
&lt;h2&gt;https&lt;/h2&gt; 
&lt;p&gt;both HTTP and HTTPS are accepted by default, but letting a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse proxy&lt;/a&gt; handle the https/tls/ssl would be better (probably more secure by default)&lt;/p&gt; 
&lt;p&gt;copyparty doesn't speak HTTP/2 or QUIC, so using a reverse proxy would solve that as well -- but note that HTTP/1 is usually faster than both HTTP/2 and HTTP/3&lt;/p&gt; 
&lt;p&gt;if &lt;a href="https://github.com/cloudflare/cfssl/releases/latest"&gt;cfssl&lt;/a&gt; is installed, copyparty will automatically create a CA and server-cert on startup&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the certs are written to &lt;code&gt;--crt-dir&lt;/code&gt; for distribution, see &lt;code&gt;--help&lt;/code&gt; for the other &lt;code&gt;--crt&lt;/code&gt; options&lt;/li&gt; 
 &lt;li&gt;this will be a self-signed certificate so you must install your &lt;code&gt;ca.pem&lt;/code&gt; into all your browsers/devices&lt;/li&gt; 
 &lt;li&gt;if you want to avoid the hassle of distributing certs manually, please consider using a reverse proxy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;recovering from crashes&lt;/h1&gt; 
&lt;h2&gt;client crashes&lt;/h2&gt; 
&lt;h3&gt;firefox wsod&lt;/h3&gt; 
&lt;p&gt;firefox 87 can crash during uploads -- the entire browser goes, including all other browser tabs, everything turns white&lt;/p&gt; 
&lt;p&gt;however you can hit &lt;code&gt;F12&lt;/code&gt; in the up2k tab and use the devtools to see how far you got in the uploads:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;get a complete list of all uploads, organized by status (ok / no-good / busy / queued):&lt;br&gt; &lt;code&gt;var tabs = { ok:[], ng:[], bz:[], q:[] }; for (var a of up2k.ui.tab) tabs[a.in].push(a); tabs&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;list of filenames which failed:&lt;br&gt; &lt;code&gt;‚Äãvar ng = []; for (var a of up2k.ui.tab) if (a.in != 'ok') ng.push(a.hn.split('&amp;lt;a href=\"').slice(-1)[0].split('\"&amp;gt;')[0]); ng&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;send the list of filenames to copyparty for safekeeping:&lt;br&gt; &lt;code&gt;await fetch('/inc', {method:'PUT', body:JSON.stringify(ng,null,1)})&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;HTTP API&lt;/h1&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#http-api"&gt;devnotes&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;dependencies&lt;/h1&gt; 
&lt;p&gt;mandatory deps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;jinja2&lt;/code&gt; (is built into the SFX)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;optional dependencies&lt;/h2&gt; 
&lt;p&gt;install these to enable bonus features&lt;/p&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;hashed passwords&lt;/a&gt; in config: &lt;code&gt;argon2-cffi&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp-server&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;for just plaintext FTP, &lt;code&gt;pyftpdlib&lt;/code&gt; (is built into the SFX)&lt;/li&gt; 
 &lt;li&gt;with TLS encryption, &lt;code&gt;pyftpdlib pyopenssl&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#metadata-from-audio-files"&gt;music tags&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;either &lt;code&gt;mutagen&lt;/code&gt; (fast, pure-python, skips a few tags, makes copyparty GPL? idk)&lt;/li&gt; 
 &lt;li&gt;or &lt;code&gt;ffprobe&lt;/code&gt; (20x slower, more accurate, possibly dangerous depending on your distro and users)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; of...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;images:&lt;/strong&gt; &lt;code&gt;Pillow&lt;/code&gt; and/or &lt;code&gt;pyvips&lt;/code&gt; and/or &lt;code&gt;ffmpeg&lt;/code&gt; (requires py2.7 or py3.5+)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;videos/audio:&lt;/strong&gt; &lt;code&gt;ffmpeg&lt;/code&gt; and &lt;code&gt;ffprobe&lt;/code&gt; somewhere in &lt;code&gt;$PATH&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HEIF pictures:&lt;/strong&gt; &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt; or &lt;code&gt;pyheif-pillow-opener&lt;/code&gt; (requires Linux or a C compiler)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AVIF pictures:&lt;/strong&gt; &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt; or &lt;code&gt;pillow-avif-plugin&lt;/code&gt; or pillow v11.3+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JPEG XL pictures:&lt;/strong&gt; &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable sending &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeromq"&gt;zeromq messages&lt;/a&gt; from event-hooks: &lt;code&gt;pyzmq&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb&lt;/a&gt; support (&lt;strong&gt;not&lt;/strong&gt; recommended): &lt;code&gt;impacket==0.12.0&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pyvips&lt;/code&gt; gives higher quality thumbnails than &lt;code&gt;Pillow&lt;/code&gt; and is 320% faster, using 270% more ram: &lt;code&gt;sudo apt install libvips42 &amp;amp;&amp;amp; python3 -m pip install --user -U pyvips&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;to install FFmpeg on Windows, grab &lt;a href="https://www.gyan.dev/ffmpeg/builds/ffmpeg-git-full.7z"&gt;a recent build&lt;/a&gt; -- you need &lt;code&gt;ffmpeg.exe&lt;/code&gt; and &lt;code&gt;ffprobe.exe&lt;/code&gt; from inside the &lt;code&gt;bin&lt;/code&gt; folder; copy them into &lt;code&gt;C:\Windows\System32&lt;/code&gt; or any other folder that's in your &lt;code&gt;%PATH%&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;dependency chickenbits&lt;/h3&gt; 
&lt;p&gt;prevent loading an optional dependency , for example if:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you have an incompatible version installed and it causes problems&lt;/li&gt; 
 &lt;li&gt;you just don't want copyparty to use it, maybe to save ram&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;set any of the following environment variables to disable its associated optional feature,&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;env-var&lt;/th&gt; 
   &lt;th&gt;what it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_ARGON2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable argon2-cffi password hashing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_CFSSL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;never attempt to generate self-signed certificates using &lt;a href="https://github.com/cloudflare/cfssl"&gt;cfssl&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_FFMPEG&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;audio transcoding&lt;/strong&gt; goes byebye, &lt;strong&gt;thumbnailing&lt;/strong&gt; must be handled by Pillow/libvips&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_FFPROBE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;audio transcoding&lt;/strong&gt; goes byebye, &lt;strong&gt;thumbnailing&lt;/strong&gt; must be handled by Pillow/libvips, &lt;strong&gt;metadata-scanning&lt;/strong&gt; must be handled by mutagen&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_MAGIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not use &lt;a href="https://pypi.org/project/python-magic/"&gt;magic&lt;/a&gt; for filetype detection&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_MUTAGEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not use &lt;a href="https://pypi.org/project/mutagen/"&gt;mutagen&lt;/a&gt; for reading metadata from media files; will fallback to ffprobe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all &lt;a href="https://pypi.org/project/pillow/"&gt;Pillow&lt;/a&gt;-based thumbnail support; will fallback to libvips or ffmpeg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PILF&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable Pillow &lt;code&gt;ImageFont&lt;/code&gt; text rendering, used for folder thumbnails&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL_AVIF&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable Pillow avif support (internal and/or &lt;a href="https://pypi.org/project/pillow-avif-plugin/"&gt;plugin&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL_HEIF&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable 3rd-party Pillow plugin for &lt;a href="https://pypi.org/project/pyheif-pillow-opener/"&gt;HEIF support&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL_WEBP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable use of native webp support in Pillow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PSUTIL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not use &lt;a href="https://pypi.org/project/psutil/"&gt;psutil&lt;/a&gt; for reaping stuck hooks and plugins on Windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_VIPS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all &lt;a href="https://pypi.org/project/pyvips/"&gt;libvips&lt;/a&gt;-based thumbnail support; will fallback to Pillow or ffmpeg&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;example: &lt;code&gt;PRTY_NO_PIL=1 python3 copyparty-sfx.py&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;PRTY_NO_PIL&lt;/code&gt; saves ram&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;PRTY_NO_VIPS&lt;/code&gt; saves ram and startup time&lt;/li&gt; 
 &lt;li&gt;python2.7 on windows: &lt;code&gt;PRTY_NO_FFMPEG&lt;/code&gt; + &lt;code&gt;PRTY_NO_FFPROBE&lt;/code&gt; saves startup time&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;optional gpl stuff&lt;/h2&gt; 
&lt;p&gt;some bundled tools have copyleft dependencies, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/#mtag"&gt;./bin/#mtag&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;these are standalone programs and will never be imported / evaluated by copyparty, and must be enabled through &lt;code&gt;-mtp&lt;/code&gt; configs&lt;/p&gt; 
&lt;h1&gt;sfx&lt;/h1&gt; 
&lt;p&gt;the self-contained "binary" (recommended!) &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt; will unpack itself and run copyparty, assuming you have python installed of course&lt;/p&gt; 
&lt;p&gt;you can reduce the sfx size by repacking it; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#sfx-repack"&gt;./docs/devnotes.md#sfx-repack&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;copyparty.exe&lt;/h2&gt; 
&lt;p&gt;download &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.exe"&gt;copyparty.exe&lt;/a&gt; (win8+) or &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe"&gt;copyparty32.exe&lt;/a&gt; (win7+)&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/221445946-1e328e56-8c5b-44a9-8b9f-dee84d942535.png" alt="copyparty-exe-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;can be convenient on machines where installing python is problematic, however is &lt;strong&gt;not recommended&lt;/strong&gt; -- if possible, please use &lt;strong&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt;&lt;/strong&gt; instead&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.exe"&gt;copyparty.exe&lt;/a&gt; runs on win8 or newer, was compiled on win10, does thumbnails + media tags, and is &lt;em&gt;currently&lt;/em&gt; safe to use, but any future python/expat/pillow CVEs can only be remedied by downloading a newer version of the exe&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;on win8 it needs &lt;a href="https://www.microsoft.com/en-us/download/details.aspx?id=48145"&gt;vc redist 2015&lt;/a&gt;, on win10 it just works&lt;/li&gt; 
   &lt;li&gt;some antivirus may freak out (false-positive), possibly &lt;a href="https://www.virustotal.com/gui/file/52391a1e9842cf70ad243ef83844d46d29c0044d101ee0138fcdd3c8de2237d6/detection"&gt;Avast, AVG, and McAfee&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dangerous: &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe"&gt;copyparty32.exe&lt;/a&gt; is compatible with &lt;a href="https://user-images.githubusercontent.com/241032/221445944-ae85d1f4-d351-4837-b130-82cab57d6cca.png"&gt;windows7&lt;/a&gt;, which means it uses an ancient copy of python (3.7.9) which cannot be upgraded and should never be exposed to the internet (LAN is fine)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dangerous and deprecated: &lt;a href="https://github.com/9001/copyparty/releases/download/v1.8.7/copyparty-winpe64.exe"&gt;copyparty-winpe64.exe&lt;/a&gt; lets you &lt;a href="https://user-images.githubusercontent.com/241032/205454984-e6b550df-3c49-486d-9267-1614078dd0dd.png"&gt;run copyparty in WinPE&lt;/a&gt; and is otherwise completely useless&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;meanwhile &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt; instead relies on your system python which gives better performance and will stay safe as long as you keep your python install up-to-date&lt;/p&gt; 
&lt;p&gt;then again, if you are already into downloading shady binaries from the internet, you may also want my &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/scripts/pyinstaller#ffmpeg"&gt;minimal builds&lt;/a&gt; of &lt;a href="https://ocv.me/stuff/bin/ffmpeg.exe"&gt;ffmpeg&lt;/a&gt; and &lt;a href="https://ocv.me/stuff/bin/ffprobe.exe"&gt;ffprobe&lt;/a&gt; which enables copyparty to extract multimedia-info, do audio-transcoding, and thumbnails/spectrograms/waveforms, however it's much better to instead grab a &lt;a href="https://www.gyan.dev/ffmpeg/builds/ffmpeg-git-full.7z"&gt;recent official build&lt;/a&gt; every once ina while if you can afford the size&lt;/p&gt; 
&lt;h2&gt;zipapp&lt;/h2&gt; 
&lt;p&gt;another emergency alternative, &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz"&gt;copyparty.pyz&lt;/a&gt; has less features, is slow, requires python 3.7 or newer, worse compression, and more importantly is unable to benefit from more recent versions of jinja2 and such (which makes it less secure)... lots of drawbacks with this one really -- but it does not unpack any temporary files to disk, so it &lt;em&gt;may&lt;/em&gt; just work if the regular sfx fails to start because the computer is messed up in certain funky ways, so it's worth a shot if all else fails&lt;/p&gt; 
&lt;p&gt;run it by doubleclicking it, or try typing &lt;code&gt;python copyparty.pyz&lt;/code&gt; in your terminal/console/commandline/telex if that fails&lt;/p&gt; 
&lt;p&gt;it is a python &lt;a href="https://docs.python.org/3/library/zipapp.html"&gt;zipapp&lt;/a&gt; meaning it doesn't have to unpack its own python code anywhere to run, so if the filesystem is busted it has a better chance of getting somewhere&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;but note that it currently still needs to extract the web-resources somewhere (they'll land in the default TEMP-folder of your OS)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;install on android&lt;/h1&gt; 
&lt;p&gt;install &lt;a href="https://termux.com/"&gt;Termux&lt;/a&gt; + its companion app &lt;code&gt;Termux:API&lt;/code&gt; (see &lt;a href="https://ocv.me/termux/"&gt;ocv.me/termux&lt;/a&gt;) and then copy-paste this into Termux (long-tap) all at once:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;yes | pkg upgrade &amp;amp;&amp;amp; termux-setup-storage &amp;amp;&amp;amp; yes | pkg install python termux-api &amp;amp;&amp;amp; python -m ensurepip &amp;amp;&amp;amp; python -m pip install --user -U copyparty &amp;amp;&amp;amp; { grep -qE 'PATH=.*\.local/bin' ~/.bashrc 2&amp;gt;/dev/null || { echo 'PATH="$HOME/.local/bin:$PATH"' &amp;gt;&amp;gt; ~/.bashrc &amp;amp;&amp;amp; . ~/.bashrc; }; }
echo $?
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;after the initial setup, you can launch copyparty at any time by running &lt;code&gt;copyparty&lt;/code&gt; anywhere in Termux -- and if you run it with &lt;code&gt;--qr&lt;/code&gt; you'll get a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#qr-code"&gt;neat qr-code&lt;/a&gt; pointing to your external ip&lt;/p&gt; 
&lt;p&gt;if you want thumbnails (photos+videos) and you're okay with spending another 132 MiB of storage, &lt;code&gt;pkg install ffmpeg &amp;amp;&amp;amp; python3 -m pip install --user -U pillow&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;or if you want to use &lt;code&gt;vips&lt;/code&gt; for photo-thumbs instead, &lt;code&gt;pkg install libvips &amp;amp;&amp;amp; python -m pip install --user -U wheel &amp;amp;&amp;amp; python -m pip install --user -U pyvips &amp;amp;&amp;amp; (cd /data/data/com.termux/files/usr/lib/; ln -s libgobject-2.0.so{,.0}; ln -s libvips.so{,.42})&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;reporting bugs&lt;/h1&gt; 
&lt;p&gt;ideas for context to include, and where to submit them&lt;/p&gt; 
&lt;p&gt;please get in touch using any of the following URLs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/9001/copyparty/"&gt;https://github.com/9001/copyparty/&lt;/a&gt; &lt;strong&gt;(primary)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/9001/copyparty/"&gt;https://gitlab.com/9001/copyparty/&lt;/a&gt; &lt;em&gt;(mirror)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeberg.org/9001/copyparty"&gt;https://codeberg.org/9001/copyparty&lt;/a&gt; &lt;em&gt;(mirror)&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;in general, commandline arguments (and config file if any)&lt;/p&gt; 
&lt;p&gt;if something broke during an upload (replacing FILENAME with a part of the filename that broke):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;journalctl -aS '48 hour ago' -u copyparty | grep -C10 FILENAME | tee bug.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;if there's a wall of base64 in the log (thread stacks) then please include that, especially if you run into something freezing up or getting stuck, for example &lt;code&gt;OperationalError('database is locked')&lt;/code&gt; -- alternatively you can visit &lt;code&gt;/?stack&lt;/code&gt; to see the stacks live, so &lt;a href="http://127.0.0.1:3923/?stack"&gt;http://127.0.0.1:3923/?stack&lt;/a&gt; for example&lt;/p&gt; 
&lt;h1&gt;devnotes&lt;/h1&gt; 
&lt;p&gt;for build instructions etc, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md"&gt;./docs/devnotes.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;specifically you may want to &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/devnotes.md#just-the-sfx"&gt;build the sfx&lt;/a&gt; or &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/devnotes.md#build-from-scratch"&gt;build from scratch&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/TODO.md"&gt;./docs/TODO.md&lt;/a&gt; for planned features / fixes / changes&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>