<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Sun, 24 Aug 2025 01:31:55 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>plait-board/drawnix</title>
      <link>https://github.com/plait-board/drawnix</link>
      <description>&lt;p&gt;开源白板工具（SaaS），一体化白板，包含思维导图、流程图、自由画等。All in one open-source whiteboard tool with mind, flowchart, freehand and etc.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture style="width: 320px"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/plait-board/drawnix/blob/develop/apps/web/public/logo/logo_drawnix_h.svg?raw=true" /&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/plait-board/drawnix/blob/develop/apps/web/public/logo/logo_drawnix_h_dark.svg?raw=true" /&gt; 
  &lt;img src="https://github.com/plait-board/drawnix/raw/develop/apps/web/public/logo/logo_drawnix_h.svg?raw=true" width="360" alt="Drawnix logo and name" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt; 开源白板工具（SaaS），一体化白板，包含思维导图、流程图、自由画等 &lt;br /&gt; &lt;/h2&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;figure&gt; 
  &lt;a target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/plait-board/drawnix/raw/develop/apps/web/public/product_showcase/case-2.png" alt="Product showcase" width="80%" /&gt; &lt;/a&gt; 
  &lt;figcaption&gt; 
   &lt;p align="center"&gt; All in one 白板，思维导图、流程图、自由画等 &lt;/p&gt; 
  &lt;/figcaption&gt; 
 &lt;/figure&gt; 
 &lt;a href="https://hellogithub.com/repository/plait-board/drawnix" target="_blank"&gt; 
  &lt;picture style="width: 250"&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=4dcea807fab7468a962c153b07ae4e4e&amp;amp;claim_uid=zmFSY5k8EuZri43&amp;amp;theme=neutral" /&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=4dcea807fab7468a962c153b07ae4e4e&amp;amp;claim_uid=zmFSY5k8EuZri43&amp;amp;theme=dark" /&gt; 
   &lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=4dcea807fab7468a962c153b07ae4e4e&amp;amp;claim_uid=zmFSY5k8EuZri43&amp;amp;theme=neutral" alt="Featured｜HelloGitHub" style="width: 250px; height: 54px;" width="250" height="54" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://github.com/plait-board/drawnix/raw/develop/README_en.md"&gt;&lt;em&gt;English README&lt;/em&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;特性&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;💯&amp;nbsp;免费 + 开源&lt;/li&gt; 
 &lt;li&gt;⚒️&amp;nbsp;思维导图、流程图&lt;/li&gt; 
 &lt;li&gt;🖌 画笔&lt;/li&gt; 
 &lt;li&gt;😀 插入图片&lt;/li&gt; 
 &lt;li&gt;🚀 基于插件机制&lt;/li&gt; 
 &lt;li&gt;🖼️ 📃 导出为 PNG, JSON(&lt;code&gt;.drawnix&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;💾 自动保存（浏览器缓存）&lt;/li&gt; 
 &lt;li&gt;⚡ 编辑特性：撤销、重做、复制、粘贴等&lt;/li&gt; 
 &lt;li&gt;🌌 无限画布：缩放、滚动&lt;/li&gt; 
 &lt;li&gt;🎨 主题模式&lt;/li&gt; 
 &lt;li&gt;📱 移动设备适配&lt;/li&gt; 
 &lt;li&gt;📈 支持 mermaid 语法转流程图&lt;/li&gt; 
 &lt;li&gt;✨ 支持 markdown 文本转思维导图（新支持 🔥🔥🔥）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;关于名称&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Drawnix&lt;/strong&gt;&lt;/em&gt; ，源于绘画( &lt;em&gt;&lt;strong&gt;Draw&lt;/strong&gt;&lt;/em&gt; )与凤凰( &lt;em&gt;&lt;strong&gt;Phoenix&lt;/strong&gt;&lt;/em&gt; )的灵感交织。&lt;/p&gt; 
&lt;p&gt;凤凰象征着生生不息的创造力，而 &lt;em&gt;Draw&lt;/em&gt; 代表着人类最原始的表达方式。在这里，每一次创作都是一次艺术的涅槃，每一笔绘画都是灵感的重生。&lt;/p&gt; 
&lt;p&gt;创意如同凤凰，浴火方能重生，而 &lt;em&gt;&lt;strong&gt;Drawnix&lt;/strong&gt;&lt;/em&gt; 要做技术与创意之火的守护者。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Draw Beyond, Rise Above.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;与 Plait 画图框架&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Drawnix&lt;/em&gt; 的定位是一个开箱即用、开源、免费的工具产品，它的底层是 &lt;em&gt;Plait&lt;/em&gt; 框架，&lt;em&gt;Plait&lt;/em&gt; 是我司开源的一款画图框架，代表着公司在知识库产品上的重要技术沉淀。&lt;/p&gt; 
&lt;p&gt;Drawnix 是插件架构，与前面说到开源工具比技术架构更复杂一些，但是插件架构也有优势，比如能够支持多种 UI 框架（&lt;em&gt;Angular、React&lt;/em&gt;），能够集成不同富文本框架（当前仅支持 &lt;em&gt;Slate&lt;/em&gt; 框架），在开发上可以很好的实现业务的分层，开发各种细粒度的可复用插件，可以扩展更多的画板的应用场景。&lt;/p&gt; 
&lt;h2&gt;仓储结构&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;drawnix/
├── apps/
│   ├── web                   # drawnix.com
│   │    └── index.html       # HTML
├── dist/                     # 构建产物
├── packages/
│   └── drawnix/              # 白板应用
│   └── react-board/          # 白板 React 视图层
│   └── react-text/           # 文本渲染模块
├── package.json
├── ...
└── README.md
└── README_en.md

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;应用&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://drawnix.com"&gt;&lt;em&gt;https://drawnix.com&lt;/em&gt;&lt;/a&gt; 是 &lt;em&gt;drawnix&lt;/em&gt; 的最小化应用。&lt;/p&gt; 
&lt;p&gt;近期会高频迭代 drawnix.com，直到发布 &lt;em&gt;Dawn（破晓）&lt;/em&gt; 版本。&lt;/p&gt; 
&lt;h2&gt;开发&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;npm install

npm run start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;docker pull pubuzhixing/drawnix:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;依赖&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/worktile/plait"&gt;plait&lt;/a&gt; - 画图框架&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ianstormtaylor/slate"&gt;slate&lt;/a&gt; - 富文本编辑器框架&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/floating-ui/floating-ui"&gt;floating-ui&lt;/a&gt; - 一个超级好用的创建弹出层基础库&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;贡献&lt;/h2&gt; 
&lt;p&gt;欢迎任何形式的贡献：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提 Bug&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;贡献代码&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;支持&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;欢迎大家 star ⭐️⭐️⭐️ 支持。&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/plait-board/drawnix/raw/master/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>moeru-ai/airi</title>
      <link>https://github.com/moeru-ai/airi</link>
      <description>&lt;p&gt;💖🧸 Self hosted, you owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source width="100%" srcset="./docs/content/public/banner-dark-1280x640.avif" media="(prefers-color-scheme: dark)" /&gt; 
 &lt;source width="100%" srcset="./docs/content/public/banner-light-1280x640.avif" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)" /&gt; 
 &lt;img width="250" src="https://raw.githubusercontent.com/moeru-ai/airi/main/docs/content/public/banner-light-1280x640.avif" /&gt; 
&lt;/picture&gt; 
&lt;h1 align="center"&gt;Project AIRI&lt;/h1&gt; 
&lt;p align="center"&gt;Re-creating Neuro-sama, a container of souls of AI waifu / virtual characters to bring them into our worlds.&lt;/p&gt; 
&lt;p align="center"&gt; [&lt;a href="https://discord.gg/TgQ3Cu2F7A"&gt;Join Discord Server&lt;/a&gt;] [&lt;a href="https:///airi.moeru.ai"&gt;Try it&lt;/a&gt;] [&lt;a href="https://github.com/moeru-ai/airi/raw/main/docs/README.zh-CN.md"&gt;简体中文&lt;/a&gt;] [&lt;a href="https://github.com/moeru-ai/airi/raw/main/docs/README.ja-JP.md"&gt;日本語&lt;/a&gt;] &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://deepwiki.com/moeru-ai/airi"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/moeru-ai/airi/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/moeru-ai/airi.svg?style=flat&amp;amp;colorA=080f12&amp;amp;colorB=1fa669" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/TgQ3Cu2F7A"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2FTgQ3Cu2F7A%3Fwith_counts%3Dtrue&amp;amp;query=%24.approximate_member_count&amp;amp;suffix=%20members&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;label=%20&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" /&gt;&lt;/a&gt; &lt;a href="https://x.com/proj_airi"&gt;&lt;img src="https://img.shields.io/badge/%40proj__airi-black?style=flat&amp;amp;logo=x&amp;amp;labelColor=%23101419&amp;amp;color=%232d2e30" /&gt;&lt;/a&gt; &lt;a href="https://t.me/+7M_ZKO3zUHFlOThh"&gt;&lt;img src="https://img.shields.io/badge/Telegram-%235AA9E6?logo=telegram&amp;amp;labelColor=FFFFFF" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.producthunt.com/products/airi?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-airi" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=993524&amp;amp;theme=neutral&amp;amp;t=1752696535380" alt="AIRI - A container of cyber living souls, re-creation of Neuro-sama | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;a href="https://trendshift.io/repositories/14636" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14636" alt="moeru-ai%2Fairi | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Heavily inspired by &lt;a href="https://www.youtube.com/@Neurosama"&gt;Neuro-sama&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;Attention:&lt;/strong&gt; We &lt;strong&gt;do not&lt;/strong&gt; have any officially minted cryptocurrency or token associated with this project. Please check the information and proceed with caution.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;We got a whole dedicated organization &lt;a href="https://github.com/proj-airi"&gt;@proj-airi&lt;/a&gt; for all the sub-project that born from Project AIRI, check it out!&lt;/p&gt; 
 &lt;p&gt;RAG, memory system, embedded database, icons, Live2D utilities, and more!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Have you dreamed about having a cyber living being (cyber waifu / husbando, digital pet), or digital companion that could play with and talk to you?&lt;/p&gt; 
&lt;p&gt;With the power of modern large language models like &lt;a href="https://chatgpt.com"&gt;ChatGPT&lt;/a&gt;, and famous &lt;a href="https://claude.ai"&gt;Claude&lt;/a&gt;, asking a virtual being able to have role playing and chat with us is already easy enough for everyone. Platforms like &lt;a href="https://character.ai"&gt;Character.ai (a.k.a. c.ai)&lt;/a&gt; and &lt;a href="https://janitorai.com/"&gt;JanitorAI&lt;/a&gt;, and local playgrounds like &lt;a href="https://github.com/SillyTavern/SillyTavern"&gt;SillyTavern&lt;/a&gt; is already a well-enough solution for chat based, or visual adventure game like experience.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;But, what about the abilities to play games? And see what you are coding at? Chatting while playing games, watching videos, and capable of doing many other things.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Perhaps you know &lt;a href="https://www.youtube.com/@Neurosama"&gt;Neuro-sama&lt;/a&gt; already, she is currently the best companion capable of playing games, chatting, and interacting with you and the participants (in VTuber community), some call this kind of being, "digital human" too. &lt;strong&gt;Sadly, it's not open sourced, you cannot interact with her after she went offline from live stream&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Therefore, this project, AIRI, offers another possibility here: &lt;strong&gt;let you own your digital life, cyber living, easily, anywhere, anytime&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;DevLogs we posted &amp;amp; Recent updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://airi.moeru.ai/docs/blog/DevLog-2025.07.18/"&gt;DevLog @ 2025.07.18&lt;/a&gt; on July 18, 2025&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://airi.moeru.ai/docs/blog/dreamlog-0x1/"&gt;DreamLog 0x1&lt;/a&gt; on June 16, 2025&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://airi.moeru.ai/docs/blog/DevLog-2025.06.08/"&gt;DevLog @ 2025.06.08&lt;/a&gt; on June 8, 2025&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://airi.moeru.ai/docs/blog/DevLog-2025.05.16/"&gt;DevLog @ 2025.05.16&lt;/a&gt; on May 16, 2025&lt;/li&gt; 
 &lt;li&gt;...more on &lt;a href="https://airi.moeru.ai/docs"&gt;documentation site&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What's so special for this project?&lt;/h2&gt; 
&lt;p&gt;Unlike the other AI driven VTuber open source projects, アイリ VTuber was built with many support of Web technologies such as &lt;a href="https://www.w3.org/TR/webgpu/"&gt;WebGPU&lt;/a&gt;, &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API"&gt;WebAudio&lt;/a&gt;, &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers"&gt;Web Workers&lt;/a&gt;, &lt;a href="https://webassembly.org/"&gt;WebAssembly&lt;/a&gt;, &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/WebSocket"&gt;WebSocket&lt;/a&gt;, etc. from the first day.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Worry about the performance drop since we are using Web related technologies?&lt;/p&gt; 
 &lt;p&gt;Don't worry, while Web browser version meant to give a insight about how much we can push and do inside browsers, and webviews, we will never fully rely on this, the desktop version of AIRI is capable of using native &lt;a href="https://developer.nvidia.com/cuda-toolkit"&gt;NVIDIA CUDA&lt;/a&gt; and &lt;a href="https://developer.apple.com/metal/"&gt;Apple Metal&lt;/a&gt; by default (thanks to HuggingFace &amp;amp; beloved &lt;a href="https://github.com/huggingface/candle"&gt;candle&lt;/a&gt; project), without any complex dependency managements, considering the tradeoff, it was partially powered by Web technologies for graphics, layouts, animations, and the WIP plugin systems for everyone to integrate things.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This means that &lt;strong&gt;アイリ VTuber is capable to run on modern browsers and devices&lt;/strong&gt;, and even on mobile devices (already done with PWA support), this brought a lot of possibilities for us (the developers) to build and extend the power of アイリ VTuber to the next level, while still left the flexibilities for users to enable features that requires TCP connections or other non-Web technologies such as connect to voice channel to Discord, or playing Minecraft, Factorio with you and your friends.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;We are still in the early stage of development where we are seeking out talented developers to join us and help us to make アイリ VTuber a reality.&lt;/p&gt; 
 &lt;p&gt;It's ok if you are not familiar with Vue.js, TypeScript, and devtools that required for this project, you can join us as an artist, designer, or even help us to launch our first live stream.&lt;/p&gt; 
 &lt;p&gt;Even you are a big fan of React or Svelte, even Solid, we welcome you, you can open a sub-directory to add features that you want to see in アイリ VTuber, or would like to experiment with.&lt;/p&gt; 
 &lt;p&gt;Fields (and related projects) that we are looking for:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Live2D modeller&lt;/li&gt; 
  &lt;li&gt;VRM modeller&lt;/li&gt; 
  &lt;li&gt;VRChat avatar designer&lt;/li&gt; 
  &lt;li&gt;Computer Vision&lt;/li&gt; 
  &lt;li&gt;Reinforcement Learning&lt;/li&gt; 
  &lt;li&gt;Speech Recognition&lt;/li&gt; 
  &lt;li&gt;Speech Synthesis&lt;/li&gt; 
  &lt;li&gt;ONNX Runtime&lt;/li&gt; 
  &lt;li&gt;Transformers.js&lt;/li&gt; 
  &lt;li&gt;vLLM&lt;/li&gt; 
  &lt;li&gt;WebGPU&lt;/li&gt; 
  &lt;li&gt;Three.js&lt;/li&gt; 
  &lt;li&gt;WebXR (&lt;a href="https://github.com/moeru-ai/chat"&gt;checkout the another project&lt;/a&gt; we have under @moeru-ai organization)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;If you are interested in, why not introduce yourself here? &lt;a href="https://github.com/moeru-ai/airi/discussions/33"&gt;Would like to join part of us to build AIRI?&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Current progress&lt;/h2&gt; 
&lt;img src="https://raw.githubusercontent.com/moeru-ai/airi/main/docs/content/public/readme-image-pc-preview.avif" /&gt; 
&lt;p&gt;Capable of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Brain 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Play &lt;a href="https://www.minecraft.net"&gt;Minecraft&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Play &lt;a href="https://www.factorio.com"&gt;Factorio&lt;/a&gt; (WIP, but &lt;a href="https://github.com/moeru-ai/airi-factorio"&gt;PoC and demo available&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Chat in &lt;a href="https://telegram.org"&gt;Telegram&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Chat in &lt;a href="https://discord.com"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Memory 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Pure in-browser database support (DuckDB WASM | &lt;code&gt;pglite&lt;/code&gt;)&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Memory Alaya (WIP)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Pure in-browser local (WebGPU) inference&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Ears 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Audio input from browser&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Audio input from &lt;a href="https://discord.com"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Client side speech recognition&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Client side talking detection&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Mouth 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://elevenlabs.io/"&gt;ElevenLabs&lt;/a&gt; voice synthesis&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Body 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; VRM support 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Control VRM model&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; VRM model animations 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Auto blink&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Auto look at&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Idle eye movement&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Live2D support 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Control Live2D model&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Live2D model animations 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Auto blink&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Auto look at&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Idle eye movement&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For detailed instructions to develop this project, follow the &lt;a href="https://raw.githubusercontent.com/moeru-ai/airi/main/.github/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] By default, &lt;code&gt;pnpm dev&lt;/code&gt; will start the development server for the Stage Web (browser version), if you would like to try developing the desktop version, please make sure you read &lt;a href="https://raw.githubusercontent.com/moeru-ai/airi/main/.github/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; to setup the environment correctly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm i
pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Stage Web (Browser version for &lt;a href="https://airi.moeru.ai"&gt;airi.moeru.ai&lt;/a&gt;)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Stage Tamagotchi (Desktop version)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm dev:tamagotchi
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Documentation site&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm dev:docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Publish&lt;/h3&gt; 
&lt;p&gt;Please update the version in &lt;code&gt;Cargo.toml&lt;/code&gt; after running the &lt;code&gt;bumpp&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npx bumpp --no-commit --no-tag
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported the following LLM API Providers (powered by &lt;a href="https://github.com/moeru-ai/xsai"&gt;xsai&lt;/a&gt;)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://developers.generativeai.google"&gt;Google Gemini&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/guides/gpt/chat-completions-api"&gt;OpenAI&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/reference"&gt;Azure OpenAI API&lt;/a&gt; (PR welcome)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://anthropic.com"&gt;Anthropic Claude&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://docs.anthropic.com/en/api/claude-on-amazon-bedrock"&gt;AWS Claude&lt;/a&gt; (PR welcome)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.deepseek.com/"&gt;DeepSeek&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://help.aliyun.com/document_detail/2400395.html"&gt;Qwen&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://x.ai/"&gt;xAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://wow.groq.com/"&gt;Groq&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://mistral.ai/"&gt;Mistral&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://developers.cloudflare.com/workers-ai/"&gt;Cloudflare Workers AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.together.ai/"&gt;Together.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.together.ai/"&gt;Fireworks.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://www.novita.ai/"&gt;Novita&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://bigmodel.cn"&gt;Zhipu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://cloud.siliconflow.cn/i/rKXmRobW"&gt;SiliconFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.stepfun.com/"&gt;Stepfun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.baichuan-ai.com"&gt;Baichuan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://api.minimax.chat/"&gt;Minimax&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.moonshot.cn/"&gt;Moonshot AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://player2.game/"&gt;Player2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://cloud.tencent.com/document/product/1729"&gt;Tencent Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.xfyun.cn/doc/spark/Web.html"&gt;Sparks&lt;/a&gt; (PR welcome)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;amp;ac=DSASUQY5&amp;amp;rc=2QXCA1VI"&gt;Volcano Engine&lt;/a&gt; (PR welcome)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sub-projects born from this project&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/proj-airi/awesome-ai-vtuber"&gt;Awesome AI VTuber&lt;/a&gt;: A curated list of AI VTubers and related projects&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/unspeech"&gt;&lt;code&gt;unspeech&lt;/code&gt;&lt;/a&gt;: Universal endpoint proxy server for &lt;code&gt;/audio/transcriptions&lt;/code&gt; and &lt;code&gt;/audio/speech&lt;/code&gt;, like LiteLLM but for any ASR and TTS&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/hfup"&gt;&lt;code&gt;hfup&lt;/code&gt;&lt;/a&gt;: tools to help on deploying, bundling to HuggingFace Spaces&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/xsai-transformers"&gt;&lt;code&gt;xsai-transformers&lt;/code&gt;&lt;/a&gt;: Experimental &lt;a href="https://github.com/huggingface/transformers.js"&gt;🤗 Transformers.js&lt;/a&gt; provider for &lt;a href="https://github.com/moeru-ai/xsai"&gt;xsAI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/proj-airi/webai-realtime-voice-chat"&gt;WebAI: Realtime Voice Chat&lt;/a&gt;: Full example of implementing ChatGPT's realtime voice from scratch with VAD + STT + LLM + TTS.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi/tree/main/packages/drizzle-duckdb-wasm/README.md"&gt;&lt;code&gt;@proj-airi/drizzle-duckdb-wasm&lt;/code&gt;&lt;/a&gt;: Drizzle ORM driver for DuckDB WASM&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi/tree/main/packages/duckdb-wasm/README.md"&gt;&lt;code&gt;@proj-airi/duckdb-wasm&lt;/code&gt;&lt;/a&gt;: Easy to use wrapper for &lt;code&gt;@duckdb/duckdb-wasm&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi/raw/main/crates/tauri-plugin-mcp/README.md"&gt;&lt;code&gt;tauri-plugin-mcp&lt;/code&gt;&lt;/a&gt;: A Tauri plugin for interacting with MCP servers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi-factorio"&gt;AIRI Factorio&lt;/a&gt;: Allow AIRI to play Factorio&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nekomeowww/factorio-rcon-api"&gt;Factorio RCON API&lt;/a&gt;: RESTful API wrapper for Factorio headless server console&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi-factorio/tree/main/packages/autorio"&gt;&lt;code&gt;autorio&lt;/code&gt;&lt;/a&gt;: Factorio automation library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/airi-factorio/tree/main/packages/tstl-plugin-reload-factorio-mod"&gt;&lt;code&gt;tstl-plugin-reload-factorio-mod&lt;/code&gt;&lt;/a&gt;: Reload Factorio mod when developing&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/luoling8192/velin"&gt;Velin&lt;/a&gt;: Use Vue SFC and Markdown to write easy to manage stateful prompts for LLM&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/demodel"&gt;&lt;code&gt;demodel&lt;/code&gt;&lt;/a&gt;: Easily boost the speed of pulling your models and datasets from various of inference runtimes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/inventory"&gt;&lt;code&gt;inventory&lt;/code&gt;&lt;/a&gt;: Centralized model catalog and default provider configurations backend service&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/mcp-launcher"&gt;MCP Launcher&lt;/a&gt;: Easy to use MCP builder &amp;amp; launcher for all possible MCP servers, just like Ollama for models!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/sad"&gt;🥺 SAD&lt;/a&gt;: Documentation and notes for self-host and browser running LLMs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;%%{ init: { 'flowchart': { 'curve': 'catmullRom' } } }%%

flowchart TD
  Core("Core")
  Unspeech("unspeech")
  DBDriver("@proj-airi/drizzle-duckdb-wasm")
  MemoryDriver("[WIP] Memory Alaya")
  DB1("@proj-airi/duckdb-wasm")
  SVRT("@proj-airi/server-runtime")
  Memory("Memory")
  STT("STT")
  Stage("Stage")
  StageUI("@proj-airi/stage-ui")
  UI("@proj-airi/ui")

  subgraph AIRI
    DB1 --&amp;gt; DBDriver --&amp;gt; MemoryDriver --&amp;gt; Memory --&amp;gt; Core
    UI --&amp;gt; StageUI --&amp;gt; Stage --&amp;gt; Core
    Core --&amp;gt; STT
    Core --&amp;gt; SVRT
  end

  subgraph UI_Components
    UI --&amp;gt; StageUI
    UITransitions("@proj-airi/ui-transitions") --&amp;gt; StageUI
    UILoadingScreens("@proj-airi/ui-loading-screens") --&amp;gt; StageUI
    FontCJK("@proj-airi/font-cjkfonts-allseto") --&amp;gt; StageUI
    FontXiaolai("@proj-airi/font-xiaolai") --&amp;gt; StageUI
  end

  subgraph Apps
    Stage --&amp;gt; StageWeb("@proj-airi/stage-web")
    Stage --&amp;gt; StageTamagotchi("@proj-airi/stage-tamagotchi")
    Core --&amp;gt; RealtimeAudio("@proj-airi/realtime-audio")
    Core --&amp;gt; PromptEngineering("@proj-airi/playground-prompt-engineering")
  end

  subgraph Server_Components
    Core --&amp;gt; ServerSDK("@proj-airi/server-sdk")
    ServerShared("@proj-airi/server-shared") --&amp;gt; SVRT
    ServerShared --&amp;gt; ServerSDK
  end

  STT --&amp;gt;|Speaking| Unspeech
  SVRT --&amp;gt;|Playing Factorio| F_AGENT
  SVRT --&amp;gt;|Playing Minecraft| MC_AGENT

  subgraph Factorio_Agent
    F_AGENT("Factorio Agent")
    F_API("Factorio RCON API")
    factorio-server("factorio-server")
    F_MOD1("autorio")

    F_AGENT --&amp;gt; F_API -.-&amp;gt; factorio-server
    F_MOD1 -.-&amp;gt; factorio-server
  end

  subgraph Minecraft_Agent
    MC_AGENT("Minecraft Agent")
    Mineflayer("Mineflayer")
    minecraft-server("minecraft-server")

    MC_AGENT --&amp;gt; Mineflayer -.-&amp;gt; minecraft-server
  end

  XSAI("xsAI") --&amp;gt; Core
  XSAI --&amp;gt; F_AGENT
  XSAI --&amp;gt; MC_AGENT

  Core --&amp;gt; TauriMCP("@proj-airi/tauri-plugin-mcp")
  Memory_PGVector("@proj-airi/memory-pgvector") --&amp;gt; Memory

  style Core fill:#f9d4d4,stroke:#333,stroke-width:1px
  style AIRI fill:#fcf7f7,stroke:#333,stroke-width:1px
  style UI fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Stage fill:#d4f9d4,stroke:#333,stroke-width:1px
  style UI_Components fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Server_Components fill:#d4e6f9,stroke:#333,stroke-width:1px
  style Apps fill:#d4d4f9,stroke:#333,stroke-width:1px
  style Factorio_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px
  style Minecraft_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px

  style DBDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style MemoryDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style DB1 fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory_PGVector fill:#f9f9d4,stroke:#333,stroke-width:1px
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Similar Projects&lt;/h2&gt; 
&lt;h3&gt;Open sourced ones&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kimjammer/Neuro"&gt;kimjammer/Neuro: A recreation of Neuro-Sama originally created in 7 days.&lt;/a&gt;: very well completed implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SugarcaneDefender/z-waif"&gt;SugarcaneDefender/z-waif&lt;/a&gt;: Great at gaming, autonomous, and prompt engineering&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/semperai/amica/"&gt;semperai/amica&lt;/a&gt;: Great at VRM, WebXR&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/elizaOS/eliza"&gt;elizaOS/eliza&lt;/a&gt;: Great examples and software engineering on how to integrate agent into various of systems and APIs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ardha27/AI-Waifu-Vtuber"&gt;ardha27/AI-Waifu-Vtuber&lt;/a&gt;: Great about Twitch API integrations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InsanityLabs/AIVTuber"&gt;InsanityLabs/AIVTuber&lt;/a&gt;: Nice UI and UX&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/IRedDragonICY/vixevia"&gt;IRedDragonICY/vixevia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/t41372/Open-LLM-VTuber"&gt;t41372/Open-LLM-VTuber&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PeterH0323/Streamer-Sales"&gt;PeterH0323/Streamer-Sales&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Non-open-sourced ones&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://clips.twitch.tv/WanderingCaringDeerDxCat-Qt55xtiGDSoNmDDr"&gt;https://clips.twitch.tv/WanderingCaringDeerDxCat-Qt55xtiGDSoNmDDr&lt;/a&gt; &lt;a href="https://www.youtube.com/watch?v=8Giv5mupJNE"&gt;https://www.youtube.com/watch?v=8Giv5mupJNE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://clips.twitch.tv/TriangularAthleticBunnySoonerLater-SXpBk1dFso21VcWD"&gt;https://clips.twitch.tv/TriangularAthleticBunnySoonerLater-SXpBk1dFso21VcWD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@NOWA_Mirai"&gt;https://www.youtube.com/@NOWA_Mirai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Project Status&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/a1d6fe2c13ea2bb53a5154435a71e2431f70c2ee.svg?sanitize=true" alt="Repobeats analytics image" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unovue/reka-ui"&gt;Reka UI&lt;/a&gt;: for designing the documentation site, new landing page is based on this, as well as implementing massive amount of UI components. (shadcn-vue is using Reka UI as the headless, do checkout!)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pixiv/ChatVRM"&gt;pixiv/ChatVRM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josephrocca/ChatVRM-js"&gt;josephrocca/ChatVRM-js: A JS conversion/adaptation of parts of the ChatVRM (TypeScript) code for standalone use in OpenCharacters and elsewhere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Design of UI and style was inspired by &lt;a href="https://store.steampowered.com/app/2919650/Cookard/"&gt;Cookard&lt;/a&gt;, &lt;a href="https://store.steampowered.com/app/2240620/UNBEATABLE/"&gt;UNBEATABLE&lt;/a&gt;, and &lt;a href="https://store.steampowered.com/app/2957700/_/"&gt;Sensei! I like you so much!&lt;/a&gt;, and artworks of &lt;a href="https://dribbble.com/shots/22157656-Ayame"&gt;Ayame by Mercedes Bazan&lt;/a&gt; with &lt;a href="https://dribbble.com/shots/24501019-Wish"&gt;Wish by Mercedes Bazan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mallorbc/whisper_mic"&gt;mallorbc/whisper_mic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moeru-ai/xsai"&gt;&lt;code&gt;xsai&lt;/code&gt;&lt;/a&gt;: Implemented a decent amount of packages to interact with LLMs and models, like &lt;a href="https://sdk.vercel.ai/"&gt;Vercel AI SDK&lt;/a&gt; but way small.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#moeru-ai/airi&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=moeru-ai/airi&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Leantime/leantime</title>
      <link>https://github.com/Leantime/leantime</link>
      <description>&lt;p&gt;Leantime is a goals focused project management system for non-project managers. Building with ADHD, Autism, and dyslexia in mind.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://leantime.io"&gt;&lt;img src="https://leantime.io/wp-content/uploads/2023/03/leantime_logo.png" alt="Leantime Logo" width="300" /&gt;&lt;/a&gt; 
 &lt;h1&gt;Leantime®&lt;/h1&gt; 
 &lt;p&gt;⭐ If you find Leantime useful, please star us on GitHub! ⭐&lt;/p&gt; 
 &lt;p&gt;Leantime is an open source project management system for non-project managers.&lt;br /&gt; We combine strategy, planning and execution while making it easy for everyone on the team to use.&lt;br /&gt; Built with ADHD, dyslexia and autism in mind. 🧠&lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;💪 As simple as Trello but as feature-rich as Jira&lt;br /&gt; 🔄 A perfect alternative to ClickUp, Monday, or Asana&lt;br /&gt; 🌐 &lt;a href="https://leantime.io"&gt;https://leantime.io&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/2264" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/2264" alt="A screenshot of Leantime's my work dashboard showing a few boxes with large metrics represnting todos complete, goals contributing to, scheduled todos. Also shows a day calendar with one task on it and a list of tasks grouped by Overdue, Due this week and Due Later" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.gnu.org/licenses/agpl-3.0.en.html"&gt;&lt;img src="https://img.shields.io/github/license/leantime/leantime?style=flat-square" alt="License Badge" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/leantime/leantime"&gt;&lt;img src="https://img.shields.io/docker/pulls/leantime/leantime?style=flat-square" alt="Docker Hub Badge" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/leantime/leantime/total" alt="Github Downloads" /&gt; &lt;a href="https://discord.gg/4zMzJtAq9z"&gt;&lt;img src="https://img.shields.io/discord/990001288026677318?label=Discord&amp;amp;style=flat-square" alt="Discord Badge" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/leantime"&gt;&lt;img src="https://badges.crowdin.net/leantime/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/sponsors/leantime" alt="GitHub Sponsors" /&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/mywork-v3.5.png" alt="alt text" title="Home Screen" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;h2&gt;🚀 Features*&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Task Management&lt;/th&gt; 
   &lt;th&gt;Project Planning&lt;/th&gt; 
   &lt;th&gt;Information/Knowledge Management&lt;/th&gt; 
   &lt;th&gt;Administration&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task management via&lt;br /&gt;kanban boards, gantt, table, list and calendar views&lt;/td&gt; 
   &lt;td&gt;Project Dashboards, reports &amp;amp; status updates&lt;/td&gt; 
   &lt;td&gt;Wikis / Docs&lt;/td&gt; 
   &lt;td&gt;Easy installation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Unlimited subtasks and dependencies&lt;/td&gt; 
   &lt;td&gt;Goal &amp;amp; metrics tracking&lt;/td&gt; 
   &lt;td&gt;Idea Boards&lt;/td&gt; 
   &lt;td&gt;Multiple user roles and per project permissions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Milestone management&lt;/td&gt; 
   &lt;td&gt;Lean &amp;amp; Business Model Canvas&lt;/td&gt; 
   &lt;td&gt;Retrospectives&lt;/td&gt; 
   &lt;td&gt;Two factor authentication&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sprint Management&lt;/td&gt; 
   &lt;td&gt;SWOT Analysis canvas&lt;/td&gt; 
   &lt;td&gt;File Storage via S3 or local filesystem&lt;/td&gt; 
   &lt;td&gt;LDAP, OIDC integration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Timetracking &amp;amp; timesheets&lt;/td&gt; 
   &lt;td&gt;Risk Analysis&lt;/td&gt; 
   &lt;td&gt;Screen &amp;amp; webcam recording&lt;/td&gt; 
   &lt;td&gt;Extendable via plugins and API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;... and more&lt;/td&gt; 
   &lt;td&gt;Comments/discussions on everything&lt;/td&gt; 
   &lt;td&gt;Integrates with Slack, Mattermost, Discord&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;... and more&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Available in over 20 languages&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;*yes, all of these features are included in the OSS version&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;📸 Screenshots&lt;/h3&gt; 
&lt;table width="100%"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%"&gt;&lt;img alt="Screenshot of Leantime's my work dashboard but with a dark color scheme. All colors are darkened or reverted" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/dark.png" title="My Work" /&gt;&lt;/td&gt; 
   &lt;td width="33%"&gt;&lt;img alt="Screenshot of Leantime's project dashboard showing a project checklist that has the first box checked, the latest tasks (1 right now), a progress donut chart at 0%" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/projectDashboard.png" title="Project Dashboard" /&gt;&lt;/td&gt; 
   &lt;td width="33%"&gt;&lt;img alt="Screenshot of Leantime's todo screen in table format. Tasks are grouped by status where each Status has a different color" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/table.png" title="Grouped To-Dos" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt="alt text" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/kanban.png" title="Kanban Board" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Screenshot of Leantime's timeline or gantt feature showing a timeline with various milestone boxes different in length representing how long these take. Each milestone has a different color and they are connected with an arrow" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/timeline.png" title="Tasks on timeline" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Screenshot of Leantime's personal calendar screen showing a month overview with a few tasks" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/calendar.png" title="Project Calendar" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt="alt text" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/goals.png" title="Goals" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Screenshot of Leantime's wiki page showing one template article of a product requirements document formatted with lists and tables" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/docs.png" title="Documents &amp;amp; Wikis" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Screenshot of Leantime's timesheet feature with a table a one week overview and input boxes for each day. Tasks are organized in rows" src="https://raw.githubusercontent.com/Leantime/leantime/master/public/assets/images/Screenshots/timesheet.png" title="Timesheets" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;❗System Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;PHP 8.2+&lt;/li&gt; 
 &lt;li&gt;MySQL 8.0+ or MariaDB 10.6+&lt;/li&gt; 
 &lt;li&gt;Apache or Nginx (IIS works with some modifications)&lt;/li&gt; 
 &lt;li&gt;PHP Extensions:&lt;/li&gt; 
 &lt;li&gt;BC Math (bcmath)&lt;/li&gt; 
 &lt;li&gt;Ctype&lt;/li&gt; 
 &lt;li&gt;cURL&lt;/li&gt; 
 &lt;li&gt;DOM&lt;/li&gt; 
 &lt;li&gt;Exif&lt;/li&gt; 
 &lt;li&gt;Fileinfo&lt;/li&gt; 
 &lt;li&gt;Filter&lt;/li&gt; 
 &lt;li&gt;GD&lt;/li&gt; 
 &lt;li&gt;Hash&lt;/li&gt; 
 &lt;li&gt;LDAP&lt;/li&gt; 
 &lt;li&gt;Multibyte String (mbstring)&lt;/li&gt; 
 &lt;li&gt;MySQL&lt;/li&gt; 
 &lt;li&gt;OPcache&lt;/li&gt; 
 &lt;li&gt;OpenSSL&lt;/li&gt; 
 &lt;li&gt;PCNTL&lt;/li&gt; 
 &lt;li&gt;PCRE&lt;/li&gt; 
 &lt;li&gt;PDO&lt;/li&gt; 
 &lt;li&gt;Phar&lt;/li&gt; 
 &lt;li&gt;Session&lt;/li&gt; 
 &lt;li&gt;Tokenizer&lt;/li&gt; 
 &lt;li&gt;Zip&lt;/li&gt; 
 &lt;li&gt;SimpleXML &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Ctype PHP Extension cURL PHP Extension DOM PHP Extension Fileinfo PHP Extension Filter PHP Extension Hash PHP Extension Mbstring PHP Extension OpenSSL PHP Extension PCRE PHP Extension PDO PHP Extension Session PHP Extension Tokenizer PHP Extension XML PHP Extension&lt;/p&gt; 
&lt;h3&gt;️⚡️ Installation (Production)&lt;/h3&gt; 
&lt;p&gt;There are two main ways to install LeanTime for production. The first of which is to install all needed pieces of the system locally. The second is to use the officially supported Docker image.&lt;/p&gt; 
&lt;h4&gt;Local Production Installation&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download latest release package (file is called: Leantime-vx.x.x.zip) from the &lt;a href="https://github.com/Leantime/leantime/releases"&gt;release page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Create an empty MySQL database&lt;/li&gt; 
 &lt;li&gt;Upload the entire directory to your server&lt;/li&gt; 
 &lt;li&gt;Point your domain root to the &lt;code&gt;public/&lt;/code&gt; directory&lt;/li&gt; 
 &lt;li&gt;Rename &lt;code&gt;config/sample.env&lt;/code&gt; to &lt;code&gt;config/.env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Fill in your database credentials (username, password, host, dbname) in &lt;code&gt;config/.env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;&amp;lt;yourdomain.com&amp;gt;/install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Follow instructions to install database and set up first user account&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;IIS Installation Notes&lt;/h5&gt; 
&lt;p&gt;Whilst the steps above are applicable to Internet Information Services (IIS), there is an additional configuration change that may be required in IIS to ensure full functionality - you need to allow the PATCH method:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open IIS&lt;/li&gt; 
 &lt;li&gt;Expand the server and sites on the left and select the LeanTime site&lt;/li&gt; 
 &lt;li&gt;Double click on &lt;code&gt;Handler Mappings&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Double click on the PHP handler mapping that is used by the site&lt;/li&gt; 
 &lt;li&gt;Click &lt;code&gt;Request Restrictions…&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Click the &lt;code&gt;Verbs&lt;/code&gt; tab&lt;/li&gt; 
 &lt;li&gt;In the &lt;code&gt;One of the following verbs&lt;/code&gt; text box, add &lt;code&gt;PATCH&lt;/code&gt; - for example: &lt;code&gt;GET,HEAD,POST,PATCH&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;In the &lt;code&gt;Executable (optional)&lt;/code&gt; text box, put a double quote character (&lt;code&gt;“&lt;/code&gt;) at the start and at the end of the path to the &lt;code&gt;php-cgi.exe&lt;/code&gt; file (&lt;em&gt;this isn't needed if the path doesn't have a space in it&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;Click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;A popup will appear asking if you want to create a FastCGI application - click &lt;code&gt;Yes&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: You may need to repeat this when you upgrade PHP.&lt;/p&gt; 
&lt;h4&gt;Production Installation via Docker&lt;/h4&gt; 
&lt;p&gt;We maintain an official &lt;a href="https://hub.docker.com/r/leantime/leantime"&gt;Docker image on dockerhub&lt;/a&gt;. To run the image enter your MySQL credentials and execute. You can pass in all the configuration variables from .env&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -d --restart unless-stopped -p 8080:8080 --network leantime-net \
-e LEAN_DB_HOST=mysql_leantime \
-e LEAN_DB_USER=admin \
-e LEAN_DB_PASSWORD=321.qwerty \
-e LEAN_DB_DATABASE=leantime \
-e LEAN_EMAIL_RETURN=changeme@local.local \
--name leantime leantime/leantime:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless you have a database defined somewhere else you should use our &lt;a href="https://github.com/Leantime/docker-leantime/raw/master/docker-compose.yml"&gt;docker-compose file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Once started you can go to &lt;code&gt;&amp;lt;yourdomain.com&amp;gt;/install&lt;/code&gt; and run the installation script.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important: If you are planning to use plugins you need to mount the plugin folder &lt;code&gt;plugins:/var/www/html/app/Plugins&lt;/code&gt; and ensure the www-data user has access to it. Otherwise installation may fail or plugins will be removed after a restart&lt;/strong&gt;&lt;/p&gt; 
&lt;h5&gt;Docker Installation Notes&lt;/h5&gt; 
&lt;p&gt;If you intend to place Leantime behind a reverse proxy (nginx, etc.) to handle custom domain name resolution and SSL offloading, you will need to set the following environment variable in docker&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-e LEAN_APP_URL=https://yourdomain.com \
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Update yourdomain.com to your custom domain name. &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🤓 Installation (Development)&lt;/h3&gt; 
&lt;p&gt;There are two ways to install a development setup of LeanTime. The first (but most technical) is to install all pieces of the system locally. The second (and preferred method) is to use a docker containerized development environment.&lt;/p&gt; 
&lt;h4&gt;Local Development Installation&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Clone repository to your local server&lt;/li&gt; 
 &lt;li&gt;Create MySQL database&lt;/li&gt; 
 &lt;li&gt;Run webpack builder via &lt;code&gt;make build-dev&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Point your local domain to the &lt;code&gt;public/&lt;/code&gt; directory&lt;/li&gt; 
 &lt;li&gt;Rename &lt;code&gt;config/sample.env&lt;/code&gt; to &lt;code&gt;config/.env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Fill in your database credentials (username, password, host, dbname) in &lt;code&gt;config/.env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;&amp;lt;localdomain&amp;gt;/install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Follow instructions to install database and user account&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Development Installation via Docker&lt;/h4&gt; 
&lt;p&gt;For development, we use a dockerized development environment. You will need to have &lt;code&gt;docker&lt;/code&gt;, &lt;code&gt;docker compose&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt;, &lt;code&gt;composer&lt;/code&gt;, &lt;code&gt;git&lt;/code&gt; and &lt;code&gt;npm&lt;/code&gt; installed.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Notes for Windows Environments: 
  &lt;ul&gt; 
   &lt;li&gt;Run all commands within the git bash terminal in order to utilize unix specific commands&lt;/li&gt; 
   &lt;li&gt;If installing php from a zip file, make sure to configure php.ini It does not exist initially, so copy C:\php\php.ini-development to C:\php\php.ini. You will also need to edit php.ini in a text editor and enable all needed extensions for the build process. You can find these by running the make commands and looking for any extensions that error out as missing. You can enable them by searching php.ini for the extension that will look like: &lt;code&gt;;extension=gd&lt;/code&gt; and removing the semicolon.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In order to build the development docker image, in the root of this repository, run a primer with&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;make clean build&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;afterwards, run&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;make run-dev&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;this will start the development server on port 8090.&lt;/p&gt; 
&lt;p&gt;The dev environment provides a MySQL server, mail server, s3 server, and should be good to go for your needs out of the box. The configuration of the development environment is found in &lt;code&gt;.dev/.env&lt;/code&gt;, and is already seeded with the appropriate values. &lt;strong&gt;You should probably not be modifying this unless you plan to work on a feature for a specific integration&lt;/strong&gt;. the applications you get are as follows&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8090"&gt;http://localhost:8090&lt;/a&gt; : leantime&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8081"&gt;http://localhost:8081&lt;/a&gt; : maildev - to check emails sent&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8082"&gt;http://localhost:8082&lt;/a&gt; : phpMyAdmin(authentication &lt;code&gt;leantime:leantime&lt;/code&gt;) to check the DB schema and data&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://localhost:8083"&gt;http://localhost:8083&lt;/a&gt; : s3ninja - to check s3 uploads. You need to enable this in the &lt;code&gt;.dev/.env&lt;/code&gt; file by enabling s3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, Xdebug is enabled, but you will have to modify your IDE key in the &lt;code&gt;.dev/xdebug.ini&lt;/code&gt; file(or alternatively, on your IDE). You also need to have port 9003 temporarily open on your firewall so you can utilize it effectively. This is because connections from docker to the host will count as external inbound connections &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Run Tests&lt;/h3&gt; 
&lt;p&gt;Static Analysis &lt;code&gt;make phpstan&lt;/code&gt;&lt;br /&gt; Code Style &lt;code&gt;make test-code-style&lt;/code&gt; (to fix code style automatically use &lt;code&gt;make fix-code-style&lt;/code&gt;)&lt;br /&gt; Unit Tests &lt;code&gt;make unit-test&lt;/code&gt;&lt;br /&gt; Acceptance Tests &lt;code&gt;make acceptance-test&lt;/code&gt;&lt;br /&gt; (requires docker)&lt;/p&gt; 
&lt;p&gt;You can test individual acceptance test groups directly using:&lt;br /&gt; For api: &lt;br /&gt; &lt;code&gt;docker compose --file .dev/docker-compose.yaml --file .dev/docker-compose.tests.yaml exec leantime-dev php vendor/bin/codecept run -g api --steps&lt;/code&gt;&lt;br /&gt; For timesheets: &lt;br /&gt; &lt;code&gt;docker compose --file .dev/docker-compose.yaml --file .dev/docker-compose.tests.yaml exec leantime-dev php vendor/bin/codecept run -g timesheet --steps&lt;/code&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;🏗 Update&lt;/h3&gt; 
&lt;h4&gt;Manual&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Make sure to take a backup of your database and files&lt;/li&gt; 
 &lt;li&gt;Replace all files in your directory with the updated version&lt;/li&gt; 
 &lt;li&gt;If there were any database changes, the system will redirect you to &lt;code&gt;&amp;lt;yourdomain.com&amp;gt;/update&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;CLI&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run &lt;code&gt;php bin/leantime system:update&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Before updating, make sure your mysql container was started using a mounted volume, otherwise your content will be deleted&lt;/li&gt; 
 &lt;li&gt;Delete/Stop existing container&lt;/li&gt; 
 &lt;li&gt;Pull the latest docker image and rebuild using your compose file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Common Issues&lt;/h3&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://docs.leantime.io/installation/common-issues"&gt;documentation&lt;/a&gt; about common issues found when installing or updating Leantime&lt;/p&gt; 
&lt;h2&gt;🔌 Extend Leantime&lt;/h2&gt; 
&lt;h4&gt;You can extend Leantime by:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;building your own plugin: &lt;a href="https://docs.leantime.io/development/plugin-development"&gt;Plugin Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;using our json-rpc API: &lt;a href="https://docs.leantime.io/api/usage"&gt;API Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or by purchasing a plugin from our &lt;a href="https://marketplace.leantime.io"&gt;marketplace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🛟 Let us install it for you.&lt;/h2&gt; 
&lt;p&gt;Hassle free installation service in your environments. We can do full installations, updates, configurations or plugin installations. See our &lt;a href="https://marketplace.leantime.io/product-category/services/technical/"&gt;Marketplace&lt;/a&gt; for details.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;☁️ Not interested in hosting yourself? Let us do it for you&lt;/h2&gt; 
&lt;p&gt;We offer &lt;a href="https://leantime.io/managed-hosting/"&gt;managed hosting plans&lt;/a&gt; as well as a &lt;a href="https://leantime.io/pricing/"&gt;SaaS product&lt;/a&gt; so you can get all the benefits of Leantime without the hassle. Head to &lt;a href="https://leantime.io/"&gt;leantime.io&lt;/a&gt; for more information. &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;🤙 Need technical support?&lt;/h2&gt; 
&lt;p&gt;We can help you set up Leantime in your environment and customize it to your needs. Our support plans are &lt;a href="https://leantime.io/priority-support/"&gt;outlined on our website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please note: We currently only support the official Leantime docker compose and standard installations. We only offer support for the most recent version.&lt;/p&gt; 
&lt;p&gt;We do not offer support for Cloudron, Elestio, Turnkey, or other external distribution platforms sharing unofficial versions of Leantime.&lt;/p&gt; 
&lt;h2&gt;🫴 Contributing&lt;/h2&gt; 
&lt;p&gt;We're excited you are interested in contributing to Leantime. We want to make sure you have a great experience contributing to Leantime and that the new features you build will make it into core. &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;🪲 Bugs&lt;/h3&gt; 
&lt;p&gt;Find an issue on Github (or create a new one) add your name to it or comment that you will be working on it. Once fixed, create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;New Features in Core&lt;/h3&gt; 
&lt;p&gt;If you have an idea about new features please reach out to us on Discord. This is where we coordinate feature development and discuss whether core is the right place to add your new features (Plugins is the alternative).&lt;/p&gt; 
&lt;h3&gt;🌏 Translations&lt;/h3&gt; 
&lt;p&gt;Language files and translations are stored in &lt;code&gt;app/Language/* &lt;/code&gt;. Once updates please create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;👥 Community Support&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Documentation &lt;a href="https://docs.leantime.io"&gt;https://docs.leantime.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community Chat &lt;a href="https://discord.gg/4zMzJtAq9z"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;File a bug report &lt;a href="https://github.com/Leantime/leantime/issues/new"&gt;https://github.com/Leantime/leantime/issues/new&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Translations &lt;a href="https://crowdin.com/project/leantime"&gt;https://crowdin.com/project/leantime&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;⚖️ LICENSE Exceptions&lt;/h2&gt; 
&lt;p&gt;Leantime is licensed under AGPLv3. This file forms part of the Leantime Software for which the following exception is added: Plugins within the &lt;code&gt;/app/Plugins&lt;/code&gt; directory which may contain plugins licensed under other licenses including our enterprise license.&lt;/p&gt; 
&lt;img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=856e290f-a6e9-4fbd-9b95-a835e39a0492" /&gt;</description>
    </item>
    
    <item>
      <title>zigtools/zls</title>
      <link>https://github.com/zigtools/zls</link>
      <description>&lt;p&gt;A language server for Zig supporting developers with features like autocomplete and goto definition&lt;/p&gt;&lt;hr&gt;&lt;img src="https://raw.githubusercontent.com/zigtools/zls/master/.github/assets/zls-opt.svg?sanitize=true" alt="ZLS Logo" width="200" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/zigtools/zls/actions/workflows/main.yml"&gt;&lt;img src="https://github.com/zigtools/zls/actions/workflows/main.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/github/zigtools/zls"&gt;&lt;img src="https://codecov.io/github/zigtools/zls/graph/badge.svg?token=WE18MPF00W" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Need support? Wanna help out? Join our &lt;a href="https://discord.gg/5m5U3qpUhk"&gt;Discord server&lt;/a&gt;!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;ZLS is a non-official implementation of the &lt;a href="https://microsoft.github.io/language-server-protocol/"&gt;Language Server Protocol&lt;/a&gt; for &lt;a href="https://ziglang.org/"&gt;Zig&lt;/a&gt; in Zig. It provides developers with IDE &lt;a href="https://raw.githubusercontent.com/zigtools/zls/master/#features"&gt;features&lt;/a&gt; in their editor.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;See the &lt;a href="https://zigtools.org/zls/install/"&gt;Installation Guide&lt;/a&gt; for editor and binary installation instructions.&lt;/h3&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;p&gt;Building ZLS requires &lt;a href="https://ziglang.org/download/"&gt;a build of Zig master&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/zigtools/zls
cd zls
zig build -Doptimize=ReleaseSafe
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;ZLS supports most language features, including simple type function support, using namespace, payload capture type resolution, custom packages, cImport and others. Support for comptime and semantic analysis is Work-in-Progress.&lt;/p&gt; 
&lt;p&gt;The following LSP features are supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Completions&lt;/li&gt; 
 &lt;li&gt;Hover&lt;/li&gt; 
 &lt;li&gt;Goto definition/declaration&lt;/li&gt; 
 &lt;li&gt;Document symbols&lt;/li&gt; 
 &lt;li&gt;Find references&lt;/li&gt; 
 &lt;li&gt;Rename symbol&lt;/li&gt; 
 &lt;li&gt;Formatting using &lt;code&gt;zig fmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Semantic token highlighting&lt;/li&gt; 
 &lt;li&gt;Inlay hints&lt;/li&gt; 
 &lt;li&gt;Code actions&lt;/li&gt; 
 &lt;li&gt;Selection ranges&lt;/li&gt; 
 &lt;li&gt;Folding regions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/prime31/sublime-zig-language"&gt;&lt;code&gt;sublime-zig-language&lt;/code&gt; by @prime31&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports basic language features&lt;/li&gt; 
   &lt;li&gt;Uses data provided by &lt;code&gt;src/data&lt;/code&gt; to perform builtin autocompletion&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xackus/zig-lsp"&gt;&lt;code&gt;zig-lsp&lt;/code&gt; by @xackus&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Inspiration for ZLS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ziglibs/known-folders"&gt;&lt;code&gt;known-folders&lt;/code&gt; by @ziglibs&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Provides API to access known folders on Linux, Windows and Mac OS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zigtools/zls"&gt;&lt;code&gt;zls&lt;/code&gt; by @zigtools&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Used by many ZLS developers to more efficiently work on ZLS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Thanks :)&lt;/h2&gt; 
&lt;p&gt;We'd like to take a second to thank all our awesome &lt;a href="https://github.com/zigtools/zls/graphs/contributors"&gt;contributors&lt;/a&gt; and donators/backers/sponsors; if you have time or money to spare, consider partaking in either of these options - they help keep ZLS awesome for everyone!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/zigtools#category-CONTRIBUTE"&gt;&lt;img src="https://opencollective.com/zigtools/backers.svg?width=890&amp;amp;limit=1000" alt="OpenCollective Backers" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HunxByts/GhostTrack</title>
      <link>https://github.com/HunxByts/GhostTrack</link>
      <description>&lt;p&gt;Useful tool to track location or mobile number&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GhostTrack&lt;/h1&gt; 
&lt;p&gt;Useful tool to track location or mobile number, so this tool can be called osint or also information gathering&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/bn.png" /&gt; 
&lt;p&gt;New update : &lt;code&gt;Version 2.2&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Instalation on Linux (deb)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt-get install git
sudo apt-get install python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instalation on Termux&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;pkg install git
pkg install python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage Tool&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/HunxByts/GhostTrack.git
cd GhostTrack
pip3 install -r requirements.txt
python3 GhostTR.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;IP Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/blob/main/asset/ip.png " /&gt; 
&lt;p&gt;on the IP Track menu, you can combo with the seeker tool to get the target IP&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;span&gt;⚡&lt;/span&gt; Install Seeker :&lt;/summary&gt; - 
 &lt;strong&gt;&lt;a href="https://github.com/thewhiteh4t/seeker"&gt;Get Seeker&lt;/a&gt;&lt;/strong&gt; 
&lt;/details&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;Phone Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/phone.png" /&gt; 
&lt;p&gt;on this menu you can search for information from the target phone number&lt;/p&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;Username Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/User.png" /&gt; on this menu you can search for information from the target username on social media 
&lt;details&gt; 
 &lt;summary&gt;&lt;span&gt;⚡&lt;/span&gt; Author :&lt;/summary&gt; - 
 &lt;strong&gt;&lt;a href="https://github.com/HunxByts"&gt;HunxByts&lt;/a&gt;&lt;/strong&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Budibase/budibase</title>
      <link>https://github.com/Budibase/budibase</link>
      <description>&lt;p&gt;Create business apps and automate workflows in minutes. Supports PostgreSQL, MySQL, MariaDB, MSSQL, MongoDB, Rest API, Docker, K8s, and more 🚀 No code / Low code platform..&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.budibase.com"&gt; &lt;img alt="Budibase" src="https://res.cloudinary.com/daog6scxm/image/upload/v1696515725/Branding/Assets/Symbol/RGB/Full%20Colour/Budibase_Symbol_RGB_FullColour_cbqvha_1_z5cwq2.svg?sanitize=true" width="60" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Budibase &lt;/h1&gt; 
&lt;h3 align="center"&gt; The low code platform you'll enjoy using &lt;/h3&gt; 
&lt;p align="center"&gt; Budibase is an open-source low-code platform that saves engineers 100s of hours building forms, portals, and approval apps, securely. &lt;/p&gt; 
&lt;h3 align="center"&gt; 🤖 🎨 🚀 &lt;/h3&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img alt="Budibase design ui" src="https://res.cloudinary.com/daog6scxm/image/upload/v1680181644/ui/homepage-design-ui_sizp7b.png" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/Budibase/budibase/releases"&gt; &lt;img alt="GitHub all releases" src="https://img.shields.io/github/downloads/Budibase/budibase/total" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Budibase/budibase/releases"&gt; &lt;img alt="GitHub release (latest by date)" src="https://img.shields.io/github/v/release/Budibase/budibase" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=budibase"&gt; &lt;img src="https://img.shields.io/twitter/follow/budibase?style=social" alt="Follow @budibase" /&gt; &lt;/a&gt; &lt;img src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg?sanitize=true" alt="Code of conduct" /&gt; &lt;a href="https://codecov.io/gh/Budibase/budibase"&gt; &lt;img src="https://codecov.io/gh/Budibase/budibase/graph/badge.svg?token=E8W2ZFXQOH" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; &lt;a href="https://account.budibase.app/register"&gt;Get started - we host (Budibase Cloud)&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://docs.budibase.com/docs/hosting-methods"&gt;Get started - you host (Docker, K8s, DO)&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://docs.budibase.com/docs"&gt;Docs&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas"&gt;Feature request&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://github.com/Budibase/budibase/issues"&gt;Report a bug&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; Support: &lt;a href="https://github.com/Budibase/budibase/discussions"&gt;Discussions&lt;/a&gt; &lt;/h3&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;h3&gt;Build and ship real software&lt;/h3&gt; 
&lt;p&gt;Unlike other platforms, with Budibase you build and ship single page applications. Budibase applications have performance baked in and can be designed responsively, providing users with a great experience. &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Open source and extensible&lt;/h3&gt; 
&lt;p&gt;Budibase is open-source - licensed as GPL v3. This should fill you with confidence that Budibase will always be around. You can also code against Budibase or fork it and make changes as you please, providing a developer-friendly experience. &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Load data or start from scratch&lt;/h3&gt; 
&lt;p&gt;Budibase pulls data from multiple sources, including MongoDB, CouchDB, PostgreSQL, MariaDB, MySQL, Airtable, S3, DynamoDB, or a REST API. And unlike other platforms, with Budibase you can start from scratch and create business apps with no data sources. &lt;a href="https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas"&gt;Request new datasources&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="Budibase data" src="https://res.cloudinary.com/daog6scxm/image/upload/v1680281798/ui/data_klbuna.png" /&gt; &lt;/p&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;h3&gt;Design and build apps with powerful pre-made components&lt;/h3&gt; 
&lt;p&gt;Budibase comes out of the box with beautifully designed, powerful components which you can use like building blocks to build your UI. We also expose many of your favourite CSS styling options so you can go that extra creative mile. &lt;a href="https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas"&gt;Request new component&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="Budibase design" src="https://res.cloudinary.com/daog6scxm/image/upload/v1675437167/ui/form_2x_mbli8y.png" /&gt; &lt;/p&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;h3&gt;Automate processes, integrate with other tools and connect to webhooks&lt;/h3&gt; 
&lt;p&gt;Save time by automating manual processes and workflows. From connecting to webhooks to automating emails, simply tell Budibase what to do and let it work for you. You can easily &lt;a href="https://github.com/Budibase/automations"&gt;create new automations for Budibase here&lt;/a&gt; or &lt;a href="https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas"&gt;Request new automation&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Integrate with your favorite tools&lt;/h3&gt; 
&lt;p&gt;Budibase integrates with a number of popular tools allowing you to build apps that perfectly fit your stack.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="Budibase integrations" src="https://res.cloudinary.com/daog6scxm/image/upload/v1680195228/ui/automate_fg9z07.png" /&gt; &lt;/p&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;h3&gt;Deploy with confidence and security&lt;/h3&gt; 
&lt;p&gt;Budibase is made to scale. With Budibase, you can self-host on your own infrastructure and globally manage users, onboarding, SMTP, apps, groups, theming and more. You can also provide users/groups with an app portal and disseminate user management to the group manager.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Checkout the promo video: &lt;a href="https://youtu.be/xoljVpty_Kw"&gt;https://youtu.be/xoljVpty_Kw&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;hr /&gt; 
&lt;br /&gt; 
&lt;h2&gt;Budibase Public API&lt;/h2&gt; 
&lt;p&gt;As with anything that we build in Budibase, our new public API is simple to use, flexible, and introduces new extensibility. To summarize, the Budibase API enables:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Budibase as a backend&lt;/li&gt; 
 &lt;li&gt;Interoperability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docs&lt;/h4&gt; 
&lt;p&gt;You can learn more about the Budibase API at the following places:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.budibase.com/docs/public-api"&gt;General documentation&lt;/a&gt;: Learn how to get your API key, how to use spec, and how to use Postman&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.budibase.com/reference/appcreate"&gt;Interactive API documentation&lt;/a&gt; : Learn how to interact with the API&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;🏁 Get started&lt;/h2&gt; 
&lt;p&gt;Deploy Budibase using Docker, Kubernetes, and Digital Ocean on your existing infrastructure. Or use Budibase Cloud if you don't need to self-host and would like to get started quickly.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://docs.budibase.com/docs/hosting-methods"&gt;Get started with self-hosting Budibase&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.budibase.com/docs/docker"&gt;Docker - single ARM compatible image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.budibase.com/docs/docker-compose"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.budibase.com/docs/kubernetes-k8s"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.budibase.com/docs/digitalocean"&gt;Digital Ocean&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.budibase.com/docs/portainer"&gt;Portainer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://budibase.com"&gt;Get started with Budibase Cloud&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;🎓 Learning Budibase&lt;/h2&gt; 
&lt;p&gt;The Budibase documentation &lt;a href="https://docs.budibase.com/docs"&gt;lives here&lt;/a&gt;. &lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;💬 Community&lt;/h2&gt; 
&lt;p&gt;If you have a question or would like to talk with other Budibase users and join our community, please hop over to &lt;a href="https://github.com/Budibase/budibase/discussions"&gt;Github discussions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;❗ Code of conduct&lt;/h2&gt; 
&lt;p&gt;Budibase is dedicated to providing everyone a welcoming, diverse, and harassment-free experience. We expect everyone in the Budibase community to abide by our &lt;a href="https://github.com/Budibase/budibase/raw/HEAD/docs/CODE_OF_CONDUCT.md"&gt;&lt;strong&gt;Code of Conduct&lt;/strong&gt;&lt;/a&gt;. Please read it. &lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;🙌 Contributing to Budibase&lt;/h2&gt; 
&lt;p&gt;From opening a bug report to creating a pull request: every contribution is appreciated and welcomed. If you're planning to implement a new feature or change the API, please create an issue first. This way, we can ensure your work is not in vain. Environment setup instructions are available &lt;a href="https://github.com/Budibase/budibase/tree/HEAD/docs/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Not Sure Where to Start?&lt;/h3&gt; 
&lt;p&gt;A good place to start contributing is by looking for the &lt;a href="https://github.com/Budibase/budibase/labels/good%20first%20issue"&gt;good first issue&lt;/a&gt; tag.&lt;/p&gt; 
&lt;h3&gt;How the repository is organized&lt;/h3&gt; 
&lt;p&gt;Budibase is a monorepo managed by lerna. Lerna manages the building and publishing of the budibase packages. At a high level, here are the packages that make up Budibase.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Budibase/budibase/tree/HEAD/packages/builder"&gt;packages/builder&lt;/a&gt; - contains code for the budibase builder client-side svelte application.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Budibase/budibase/tree/HEAD/packages/client"&gt;packages/client&lt;/a&gt; - A module that runs in the browser responsible for reading JSON definition and creating living, breathing web apps from it.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Budibase/budibase/tree/HEAD/packages/server"&gt;packages/server&lt;/a&gt; - The budibase server. This Koa app is responsible for serving the JS for the builder and budibase apps, as well as providing the API for interaction with the database and file system.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information, see &lt;a href="https://github.com/Budibase/budibase/raw/HEAD/docs/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;📝 License&lt;/h2&gt; 
&lt;p&gt;Budibase is open-source, licensed as &lt;a href="https://www.gnu.org/licenses/gpl-3.0.en.html"&gt;GPL v3&lt;/a&gt;. The client and component libraries are licensed as &lt;a href="https://directory.fsf.org/wiki/License:MPL-2.0"&gt;MPL&lt;/a&gt; - so the apps you build can be licensed however you like.&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;⭐ Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/Budibase/budibase"&gt;&lt;img src="https://starchart.cc/Budibase/budibase.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you are having issues between updates of the builder, please use the guide &lt;a href="https://github.com/Budibase/budibase/raw/HEAD/docs/CONTRIBUTING.md#troubleshooting"&gt;here&lt;/a&gt; to clear down your environment.&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors ✨&lt;/h2&gt; 
&lt;p&gt;Thanks goes to these wonderful people (&lt;a href="https://allcontributors.org/docs/en/emoji-key"&gt;emoji key&lt;/a&gt;):&lt;/p&gt; 
&lt;a href="https://github.com/Budibase/budibase/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=Budibase/budibase" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google/googletest</title>
      <link>https://github.com/google/googletest</link>
      <description>&lt;p&gt;GoogleTest - Google Testing and Mocking Framework&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GoogleTest&lt;/h1&gt; 
&lt;h3&gt;Announcements&lt;/h3&gt; 
&lt;h4&gt;Documentation Updates&lt;/h4&gt; 
&lt;p&gt;Our documentation is now live on GitHub Pages at &lt;a href="https://google.github.io/googletest/"&gt;https://google.github.io/googletest/&lt;/a&gt;. We recommend browsing the documentation on GitHub Pages rather than directly in the repository.&lt;/p&gt; 
&lt;h4&gt;Release 1.17.0&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/google/googletest/releases/tag/v1.17.0"&gt;Release 1.17.0&lt;/a&gt; is now available.&lt;/p&gt; 
&lt;p&gt;The 1.17.x branch &lt;a href="https://opensource.google/documentation/policies/cplusplus-support#c_language_standard"&gt;requires at least C++17&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Continuous Integration&lt;/h4&gt; 
&lt;p&gt;We use Google's internal systems for continuous integration.&lt;/p&gt; 
&lt;h4&gt;Coming Soon&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;We are planning to take a dependency on &lt;a href="https://github.com/abseil/abseil-cpp"&gt;Abseil&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Welcome to &lt;strong&gt;GoogleTest&lt;/strong&gt;, Google's C++ test framework!&lt;/h2&gt; 
&lt;p&gt;This repository is a merger of the formerly separate GoogleTest and GoogleMock projects. These were so closely related that it makes sense to maintain and release them together.&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://google.github.io/googletest/"&gt;GoogleTest User's Guide&lt;/a&gt; for documentation. We recommend starting with the &lt;a href="https://google.github.io/googletest/primer.html"&gt;GoogleTest Primer&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;More information about building GoogleTest can be found at &lt;a href="https://raw.githubusercontent.com/google/googletest/main/googletest/README.md"&gt;googletest/README.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;xUnit test framework: &lt;br /&gt; Googletest is based on the &lt;a href="https://en.wikipedia.org/wiki/XUnit"&gt;xUnit&lt;/a&gt; testing framework, a popular architecture for unit testing&lt;/li&gt; 
 &lt;li&gt;Test discovery: &lt;br /&gt; Googletest automatically discovers and runs your tests, eliminating the need to manually register your tests&lt;/li&gt; 
 &lt;li&gt;Rich set of assertions: &lt;br /&gt; Googletest provides a variety of assertions, such as equality, inequality, exceptions, and more, making it easy to test your code&lt;/li&gt; 
 &lt;li&gt;User-defined assertions: &lt;br /&gt; You can define your own assertions with Googletest, making it simple to write tests that are specific to your code&lt;/li&gt; 
 &lt;li&gt;Death tests: &lt;br /&gt; Googletest supports death tests, which verify that your code exits in a certain way, making it useful for testing error-handling code&lt;/li&gt; 
 &lt;li&gt;Fatal and non-fatal failures: &lt;br /&gt; You can specify whether a test failure should be treated as fatal or non-fatal with Googletest, allowing tests to continue running even if a failure occurs&lt;/li&gt; 
 &lt;li&gt;Value-parameterized tests: &lt;br /&gt; Googletest supports value-parameterized tests, which run multiple times with different input values, making it useful for testing functions that take different inputs&lt;/li&gt; 
 &lt;li&gt;Type-parameterized tests: &lt;br /&gt; Googletest also supports type-parameterized tests, which run with different data types, making it useful for testing functions that work with different data types&lt;/li&gt; 
 &lt;li&gt;Various options for running tests: &lt;br /&gt; Googletest provides many options for running tests including running individual tests, running tests in a specific order and running tests in parallel&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Platforms&lt;/h2&gt; 
&lt;p&gt;GoogleTest follows Google's &lt;a href="https://opensource.google/documentation/policies/cplusplus-support"&gt;Foundational C++ Support Policy&lt;/a&gt;. See &lt;a href="https://github.com/google/oss-policies-info/raw/main/foundational-cxx-support-matrix.md"&gt;this table&lt;/a&gt; for a list of currently supported versions of compilers, platforms, and build tools.&lt;/p&gt; 
&lt;h2&gt;Who Is Using GoogleTest?&lt;/h2&gt; 
&lt;p&gt;In addition to many internal projects at Google, GoogleTest is also used by the following notable projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://www.chromium.org/"&gt;Chromium projects&lt;/a&gt; (behind the Chrome browser and Chrome OS).&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://llvm.org/"&gt;LLVM&lt;/a&gt; compiler.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/protobuf"&gt;Protocol Buffers&lt;/a&gt;, Google's data interchange format.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://opencv.org/"&gt;OpenCV&lt;/a&gt; computer vision library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related Open Source Projects&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/nholthaus/gtest-runner"&gt;GTest Runner&lt;/a&gt; is a Qt5 based automated test-runner and Graphical User Interface with powerful features for Windows and Linux platforms.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ospector/gtest-gbar"&gt;GoogleTest UI&lt;/a&gt; is a test runner that runs your test binary, allows you to track its progress via a progress bar, and displays a list of test failures. Clicking on one shows failure text. GoogleTest UI is written in C#.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kinow/gtest-tap-listener"&gt;GTest TAP Listener&lt;/a&gt; is an event listener for GoogleTest that implements the &lt;a href="https://en.wikipedia.org/wiki/Test_Anything_Protocol"&gt;TAP protocol&lt;/a&gt; for test result output. If your test runner understands TAP, you may find it useful.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/google/gtest-parallel"&gt;gtest-parallel&lt;/a&gt; is a test runner that runs tests from your binary in parallel to provide significant speed-up.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=DavidSchuldenfrei.gtest-adapter"&gt;GoogleTest Adapter&lt;/a&gt; is a VS Code extension allowing to view GoogleTest in a tree view and run/debug your tests.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/matepek/vscode-catch2-test-adapter"&gt;C++ TestMate&lt;/a&gt; is a VS Code extension allowing to view GoogleTest in a tree view and run/debug your tests.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/cornichon/"&gt;Cornichon&lt;/a&gt; is a small Gherkin DSL parser that generates stub code for GoogleTest.&lt;/p&gt; 
&lt;h2&gt;Contributing Changes&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href="https://github.com/google/googletest/raw/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for details on how to contribute to this project.&lt;/p&gt; 
&lt;p&gt;Happy testing!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dataease/SQLBot</title>
      <link>https://github.com/dataease/SQLBot</link>
      <description>&lt;p&gt;基于大模型和 RAG 的智能问数系统。Text-to-SQL Generation via LLMs using RAG.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png" alt="SQLBot" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;基于大模型和 RAG 的智能问数系统&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/dataease/SQLBot/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dataease/SQLBot" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dataease/SQLBot"&gt;&lt;img src="https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dataease/SQLbot"&gt;&lt;img src="https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;SQLBot 是一款基于大模型和 RAG 的智能问数系统。SQLBot 的优势包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;开箱即用&lt;/strong&gt;: 只需配置大模型和数据源即可开启问数之旅，通过大模型和 RAG 的结合来实现高质量的 text2sql；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;易于集成&lt;/strong&gt;: 支持快速嵌入到第三方业务系统，也支持被 n8n、MaxKB、Dify、Coze 等 AI 应用开发平台集成调用，让各类应用快速拥有智能问数能力；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安全可控&lt;/strong&gt;: 提供基于工作空间的资源隔离机制，能够实现细粒度的数据权限控制。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速开始&lt;/h2&gt; 
&lt;h3&gt;安装部署&lt;/h3&gt; 
&lt;p&gt;准备一台 Linux 服务器，执行以下一键安装脚本。&lt;br /&gt; 在运行 SQLBot 前，请确保已安装好 &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt; 和 &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt;。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 创建目录
mkdir -p /opt/sqlbot
cd /opt/sqlbot

# 下载 docker-compose.yaml
curl -o docker-compose.yaml https://raw.githubusercontent.com/dataease/SQLBot/main/docker-compose.yaml

# 启动服务
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;你也可以通过 &lt;a href="https://apps.fit2cloud.com/1panel"&gt;1Panel 应用商店&lt;/a&gt; 快速部署 SQLBot；&lt;/p&gt; 
&lt;h3&gt;访问方式&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;在浏览器中打开: http://&amp;lt;你的服务器IP&amp;gt;:8000/&lt;/li&gt; 
 &lt;li&gt;用户名: admin&lt;/li&gt; 
 &lt;li&gt;密码: SQLBot@123456&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;联系我们&lt;/h3&gt; 
&lt;p&gt;如你有更多问题，可以加入我们的技术交流群与我们交流。&lt;/p&gt; 
&lt;img width="396" height="396" alt="contact_me_qr" src="https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030" /&gt; 
&lt;h2&gt;UI 展示&lt;/h2&gt;  
&lt;img alt="q&amp;amp;a" src="https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280" /&gt;  
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#dataease/sqlbot&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=dataease/sqlbot&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;飞致云旗下的其他明星项目&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dataease/dataease/"&gt;DataEase&lt;/a&gt; - 人人可用的开源 BI 工具&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/1panel/"&gt;1Panel&lt;/a&gt; - 现代化、开源的 Linux 服务器运维管理面板&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; - 强大易用的企业级智能体平台&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jumpserver/jumpserver/"&gt;JumpServer&lt;/a&gt; - 广受欢迎的开源堡垒机&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/halo-dev/halo/"&gt;Halo&lt;/a&gt; - 强大易用的开源建站工具&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metersphere/metersphere/"&gt;MeterSphere&lt;/a&gt; - 新一代的开源持续测试工具&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;本仓库遵循 &lt;a href="https://raw.githubusercontent.com/dataease/SQLBot/main/LICENSE"&gt;FIT2CLOUD Open Source License&lt;/a&gt; 开源协议，该许可证本质上是 GPLv3，但有一些额外的限制。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>scottpetrovic/mesh2motion-app</title>
      <link>https://github.com/scottpetrovic/mesh2motion-app</link>
      <description>&lt;p&gt;Import a 3D Model and automatically assign and export animations&lt;/p&gt;&lt;hr&gt;&lt;img src="https://raw.githubusercontent.com/scottpetrovic/mesh2motion-app/main/mesh2motion.svg?sanitize=true" alt="Mesh2Motion Logo" width="400" /&gt; 
&lt;p&gt;Import a 3D Model and automatically assign and export animations with Mesh2Motion. This is kind of similar to a web application like Mixamo, but I would like it to be more flexible so it can support other model and skeleton types. Hopefully the open source nature means it can be expanded on and evolve more than than the closed tools have.&lt;/p&gt; 
&lt;p&gt;The marketing site that explains features and release notes: &lt;a href="https://mesh2motion.org/"&gt;https://mesh2motion.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try it live: &lt;a href="https://app.mesh2motion.org/"&gt;https://app.mesh2motion.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/scottpetrovic/mesh2motion-app/main/readme.png" alt="Screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;There are instructions built into the web application, but this is the general flow of how to use it:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Import a 3d model of your choosing (currently only supports GLB/GLTF format)&lt;/li&gt; 
 &lt;li&gt;Pick what type of skeleton that the 3d model will use&lt;/li&gt; 
 &lt;li&gt;Modify the skeleton to fit inside of the model (optionally test the results)&lt;/li&gt; 
 &lt;li&gt;Test out various animations to see the results.&lt;/li&gt; 
 &lt;li&gt;Select which animations you want to use, then export (currently only GLB/GLTF supported format)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Building and running locally&lt;/h2&gt; 
&lt;p&gt;The main dependency you need is Node.js. I am using 18.15, but other versions probably work fine too. Open you command line tool to the directory this readme is in. Run ths following commands to start the web server.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npm install
npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Creating a production build for the web&lt;/h2&gt; 
&lt;p&gt;We mostly just have typescript for this project, which web browsers cannot just read, so we need to do a build step to get everything ready for deploying. This project uses Vite for the web server and builder. See the vite.config.js for more info. This command will create a "dist" folder with all the files to serve to the web:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npm run build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running in Docker&lt;/h2&gt; 
&lt;p&gt;If you don't want to modify your local file system, you can alternitvely build and run the project from Docker. Make sure you have Docker and Docker Compose installed. Navigate your command line tool to this directory where your Dockerfile is at. Make sure Docker is actually started and running before you run this command.&lt;/p&gt; 
&lt;p&gt;Execute the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To try it out, visit &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Running and creating video previews&lt;/h2&gt; 
&lt;p&gt;There is separate tool in the web app where you can generate video previews for each animation. It isn't too hard to run, but it has a separate README file that explains how that works. It is more of an internal tool, so I didn't want to muddy up this page too much.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/scottpetrovic/mesh2motion-app/main/src/preview-generator/README.md"&gt;Preview Generator Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Animator Guide&lt;/h2&gt; 
&lt;p&gt;Are you an animator who wants to help build out animations for this tool? This is by far my weakest skill, which is why I have been avoiding it. In the &lt;strong&gt;static &amp;gt; blender&lt;/strong&gt; folder, you can see all the source Blender files where I have been working. There are a couple of model files where I just have the model, and other files that actually contain the animations. These are the files we can build animations into.&lt;/p&gt; 
&lt;p&gt;🦊 fox.blend (animations for the quadruped character)&lt;/p&gt; 
&lt;p&gt;🫡 human.blend (animations for the humanoid character)&lt;/p&gt; 
&lt;p&gt;🐦‍⬛ bird.blend (animations for the bird character)&lt;/p&gt; 
&lt;p&gt;When new animations are added, I export everything to GLB and save the file in the &lt;strong&gt;static &amp;gt; animation&lt;/strong&gt; folder. Just overwrite the file that correlates. For the human animations, use the "addon" GLB file since these are being appended to the Quaternius ones. The Mixamo one is unused right now. Just a reference if I were to later add some type of support.&lt;/p&gt; 
&lt;p&gt;If you come up with anything, just get me the source .blend file and let me know what you changed. I can export it out to GLB and rebuild the animation previews.&lt;/p&gt; 
&lt;h2&gt;Contribute to the animation fund&lt;/h2&gt; 
&lt;p&gt;I don't expect to be receiving money for working on this, but I am also not the best animator. If people want to see better, and more, animations made, add to the fund. I can pay for an animator to help build out the animation library better. Or, if you know an animator that wants to help with this, send them my way! I am just a dude working on this during nights and weekends.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/scottpetrovic/mesh2motion-app/main/venmo.png" alt="Venmo Animator Fund" width="400" /&gt;</description>
    </item>
    
    <item>
      <title>dream-num/univer</title>
      <link>https://github.com/dream-num/univer</link>
      <description>&lt;p&gt;Build truly AI-native spreadsheets. Univer is a full-stack framework for creating and editing spreadsheets, documents, and slides on both web and server. With Univer MCP, Univer Sheet is driven directly through natural language.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="./docs/img/banner-light.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/banner-dark.png" alt="Univer" width="400" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;An Isomorphic Full-Stack Framework for Creating and Editing Spreadsheets, Docs, and Slides Across Web and Server.&lt;br /&gt; &lt;strong&gt;Extensible. High-performance. Embedded to your application.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;English&lt;/strong&gt; | &lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/README-zh.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/README-ja.md"&gt;日本語&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/README-es.md"&gt;Español&lt;/a&gt; &lt;br /&gt; &lt;a href="https://univer.ai"&gt;Official Site&lt;/a&gt; | &lt;a href="https://docs.univer.ai/en-US"&gt;Documentation&lt;/a&gt; | &lt;a href="https://docs.univer.ai/en-US/showcase"&gt;Online Playground&lt;/a&gt; | &lt;a href="https://docs.univer.ai/en-US/blog"&gt;Blog&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/dream-num/univer?style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dream-num/univer/actions/workflows/build.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/dream-num/univer/build.yml?style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dream-num/univer/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/dream-num/univer?style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dream-num/univer/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/dream-num/univer?style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/dream-num/univer/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/dream-num/univer?style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dream-num/univer/issues"&gt;&lt;img src="https://img.shields.io/github/issues/dream-num/univer?style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/dream-num/univer"&gt;&lt;img src="https://img.shields.io/codecov/c/gh/dream-num/univer?token=aPfyW2pIMN&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://www.codefactor.io/repository/github/dream-num/univer/overview/dev"&gt;&lt;img src="https://www.codefactor.io/repository/github/dream-num/univer/badge/dev?style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/z3NKNT6D2f"&gt;&lt;img src="https://img.shields.io/discord/1136129819961217077?logo=discord&amp;amp;logoColor=FFFFFF&amp;amp;label=discord&amp;amp;color=5865F2&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/4376"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4376" alt="Trendshift" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Use Univer MCP to drive Univer Sheet with natural language and build truly AI-native spreadsheets.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fb439d4d-ef91-4747-ad43-aa8c731ba60b"&gt;https://github.com/user-attachments/assets/fb439d4d-ef91-4747-ad43-aa8c731ba60b&lt;/a&gt;&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt; &lt;strong&gt;Table of contents&lt;/strong&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#-highlights"&gt;🌈 Highlights&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#-features"&gt;✨ Features&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#-univer-sheet"&gt;📊 Univer Sheet&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#-univer-doc-under-development"&gt;📝 Univer Doc&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#%EF%B8%8F-univer-slide-under-development"&gt;📽️ Univer Slide&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#-internationalization"&gt;🌐 Internationalization&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#-showcase"&gt;👾 Showcase&lt;/a&gt;
   &lt;!-- - [📦 Ecosystem](#-ecosystem) --&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#-community"&gt;💬 Community&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#-contribution"&gt;🤝 Contribution&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#%EF%B8%8F-sponsors"&gt;❤️ Sponsor&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/#-license"&gt;📄 License&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;🌈 Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;📈 Univer is designed to support &lt;strong&gt;spreadsheets&lt;/strong&gt;, &lt;strong&gt;documents&lt;/strong&gt; and &lt;strong&gt;presentation&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;🧙‍♀️ Univer is &lt;strong&gt;isomorphic&lt;/strong&gt;. It can run both on browsers and Node.js (in the future, mobile devices as well), with the same API.&lt;/li&gt; 
 &lt;li&gt;⚙️ Univer is easily &lt;strong&gt;embeddable&lt;/strong&gt;, allowing seamless integration into your applications.&lt;/li&gt; 
 &lt;li&gt;🎇 Univer is &lt;strong&gt;powerful&lt;/strong&gt;, offering a wide range of features including &lt;strong&gt;formulas&lt;/strong&gt;, &lt;strong&gt;conditional formatting&lt;/strong&gt;, &lt;strong&gt;data validation&lt;/strong&gt;, &lt;strong&gt;filtering&lt;/strong&gt;, &lt;strong&gt;collaborative editing&lt;/strong&gt;, &lt;strong&gt;printing&lt;/strong&gt;, &lt;strong&gt;import &amp;amp; export&lt;/strong&gt; and more features on the horizon.&lt;/li&gt; 
 &lt;li&gt;🔌 Univer is &lt;strong&gt;highly extensible&lt;/strong&gt;, thanks to its &lt;em&gt;plug-in architecture&lt;/em&gt; that makes it a delight for developers to implement their unique requirements on the top of Univer.&lt;/li&gt; 
 &lt;li&gt;💄 Univer is &lt;strong&gt;highly customizable&lt;/strong&gt;, allowing you to personalize its appearance using &lt;em&gt;themes&lt;/em&gt;. It also provides support for internationalization (i18n).&lt;/li&gt; 
 &lt;li&gt;🥤 Univer is &lt;strong&gt;easy to work with&lt;/strong&gt;. The &lt;em&gt;Presets&lt;/em&gt; &amp;amp; &lt;em&gt;Facade API&lt;/em&gt; make it easy to hands on.&lt;/li&gt; 
 &lt;li&gt;⚡ Univer in &lt;strong&gt;performant&lt;/strong&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;✏️ Univer boasts an efficient &lt;em&gt;rendering engine&lt;/em&gt; based on canvas, capable of rendering various document types flawlessly. The rendering engines supports advanced typesetting features such as &lt;em&gt;punctuation squeezing&lt;/em&gt;, &lt;em&gt;text and image layout&lt;/em&gt; and &lt;em&gt;scroll buffering&lt;/em&gt;.&lt;/li&gt; 
   &lt;li&gt;🧮 Univer incorporates a lightning-fast &lt;em&gt;formula engine&lt;/em&gt; that can operate in Web Workers or even on the server side.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;🌌 Univer is a &lt;strong&gt;highly integrated&lt;/strong&gt; system. Documents, spreadsheets and slides can interoperate with each others and even rendered on the same canvas, allowing information and data flow within Univer.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;p&gt;Univer provides a wide range of features for spreadsheets, documents and presentations. Here are some of the key features:&lt;/p&gt; 
&lt;h3&gt;📊 Univer Sheets&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Features&lt;/strong&gt;: Univer supports core spreadsheet functionality, including cells, rows, columns, worksheets, and workbooks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Formulas&lt;/strong&gt;: Extensive support for various formulas, including mathematical, statistical, logical, text, date and time, lookup and reference, engineering, financial, and information formulas.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Permissions&lt;/strong&gt;: Allows restricting access to specific elements.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Number Formatting&lt;/strong&gt;: Supports formatting numbers based on specific criteria.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hyperlinks&lt;/strong&gt;: Enables linking to external websites, email addresses, and other locations within a spreadsheet.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Floating Images&lt;/strong&gt;: Allows inserting images into a spreadsheet and positioning them anywhere on the sheet.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Find &amp;amp; Replace&lt;/strong&gt;: Provides the ability to search for specific text within a spreadsheet and replace it with other text.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Filtering&lt;/strong&gt;: Allows filtering data based on specific criteria.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sorting&lt;/strong&gt;: Allows sorting data based on specific criteria.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Validation&lt;/strong&gt;: Supports restricting the type of data that can be entered into a cell.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conditional Formatting&lt;/strong&gt;: Supports applying formatting to cells based on specific criteria.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comments&lt;/strong&gt;: Enables adding comments to cells to provide additional information.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-highlighting&lt;/strong&gt;: Supports displaying cross-highlighting in spreadsheets to help users quickly locate selected cells.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zen Editor&lt;/strong&gt;: Provides a distraction-free editing experience with a clean interface and minimal distractions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pivot Tables&lt;/strong&gt;[^1]: Supports pivot tables, allowing users to summarize and analyze data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sparklines&lt;/strong&gt;[^1]: Supports sparklines, which are small charts that fit within a cell to provide a visual representation of data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Printing&lt;/strong&gt;[^1]: Allows printing a spreadsheet or exporting it to PDF.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import &amp;amp; Export&lt;/strong&gt;[^1]: Support for importing and exporting data in XLSX.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Charts&lt;/strong&gt;[^1]: Supports various types of charts, including bar charts, line charts, pie charts, scatter plots, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Collaborative Editing&lt;/strong&gt;[^1]: Supports multiple users editing a spreadsheet simultaneously. File history and recovering are also provided.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Editing History&lt;/strong&gt;[^1]: Allows users to view and restore previous versions of a spreadsheet.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📝 Univer Docs (rc)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Features&lt;/strong&gt;: Univer supports core document features, including paragraphs, headings, lists, superscript, subscript, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lists&lt;/strong&gt;: Supports ordered lists, unordered lists, and task lists.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hyperlinks&lt;/strong&gt;: Supports inserting links to external websites, email addresses, and other locations within a document.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Floating Images&lt;/strong&gt;: Allows inserting images into a document and supporting text and image layout.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Headers &amp;amp; Footers&lt;/strong&gt;: Allows adding headers and footers to a document.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comments&lt;/strong&gt;: Enables adding comments to a document to provide additional information.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Printing&lt;/strong&gt;[^1]: Allows printing a document or exporting it to PDF.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import &amp;amp; Export&lt;/strong&gt;[^1]: Supports importing and exporting data in DOCX format.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Collaborative Editing&lt;/strong&gt;[^1]: Supports multiple users editing a document simultaneously.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📽️ Univer Slides (Under Development)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Features&lt;/strong&gt;: Univer will support core presentation features, including slides, shapes, text, images, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🌐 Internationalization&lt;/h2&gt; 
&lt;p&gt;Univer supports multiple languages, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;zh-CN&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;zh-TW&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;en-US&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ru-RU&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vi-VN&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fa-IR&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ko-KR&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;es-ES&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ca-ES&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;zh-CN&lt;/code&gt; and &lt;code&gt;en-US&lt;/code&gt; are officially supported, while the others are contributed and maintained by the community.&lt;/p&gt; 
&lt;p&gt;You can add the language you want by &lt;a href="https://univer.ai/guides/sheet/getting-started/i18n#using-custom-locales"&gt;Using Custom Locales&lt;/a&gt;. You can also help us add new language support by referring to the &lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;👾 Showcase&lt;/h2&gt; 
&lt;p&gt;Embed Univer in AI products as a data presentation tool.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://capalyze.ai/"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-sheets-capalyze.gif" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can find all the examples in the &lt;a href="https://univer.ai/examples"&gt;Univer Examples&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;📊 Spreadsheets&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;📊 Multi-instance&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;📊 Uniscript&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-sheets.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-sheets-multi.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-sheets-uniscript.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📊 Big data&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📊 Collaboration&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📊 Collaboration Playground&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-sheets-big-data.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/pro-examples-sheets-collaboration.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/pro-examples-sheets-collaboration-playground.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📊 Import &amp;amp; Export&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📊 Printing&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📝 Documents&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/pro-examples-sheets-exchange.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/pro-examples-sheets-print.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-docs.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📝 Multi-instance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📝 Uniscript&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📝 Big data&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-docs-multi.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-docs-uniscript.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-docs-big-data.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📝 Collaboration&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📝 Collaboration Playground&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📽️ Presentations&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/pro-examples-docs-collaboration.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/pro-examples-docs-collaboration-playground.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.univer.ai/showcase"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/examples-slides.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;📊 Zen Editor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Univer Workspace (SaaS version)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&amp;nbsp;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://univer.ai/guides/sheet/features/zen-editor"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/zen-mode.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://youtu.be/kpV0MvQuFZA"&gt;&lt;img src="https://raw.githubusercontent.com/dream-num/univer/dev/docs/img/univer-workspace-drag-chart.gif" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&amp;nbsp;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!-- ## 📦 Ecosystem

Univer has a rich ecosystem that includes a wide range of tools and resources to help you get started with Univer: --&gt; 
&lt;h2&gt;🔗 Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://univer-preview.vercel.app/"&gt;Latest Preview of the &lt;code&gt;dev&lt;/code&gt; Branch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://univer.ai"&gt;Official Site&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dream-num/univer-presets"&gt;Presets Repository&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔒 Security&lt;/h2&gt; 
&lt;p&gt;Univer is committed to maintaining a secure codebase. We follow best practices for security and regularly update our dependencies. For more information, please refer to our &lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/SECURITY.md"&gt;Security Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;💬 Community&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/dream-num/univer/discussions"&gt;&lt;img src="https://img.shields.io/badge/github-univer-24292e?labelColor=black&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/z3NKNT6D2f"&gt;&lt;img src="https://img.shields.io/discord/1136129819961217077?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/univer"&gt;&lt;img src="https://img.shields.io/badge/stackoverflow-univer-ef8236?labelColor=black&amp;amp;logo=stackoverflow&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Univer is an inclusive and welcoming project. Please read our &lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; before participating in the community.&lt;/p&gt; 
&lt;p&gt;Join the Univer community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chat with us and other developers on &lt;a href="https://discord.gg/z3NKNT6D2f"&gt;Discord&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Start a discussion on &lt;a href="https://github.com/dream-num/univer/discussions"&gt;GitHub Discussions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Open a topic on &lt;a href="https://stackoverflow.com/questions/tagged/univer"&gt;Stack Overflow&lt;/a&gt; and tag it with &lt;code&gt;univer&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can also find Univer on:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/univerhq"&gt;Twitter&lt;/a&gt; | &lt;a href="https://www.youtube.com/@dreamNum"&gt;YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🤝 Contribution&lt;/h2&gt; 
&lt;p&gt;We appreciate any kinds of contributing. You can submit &lt;a href="https://github.com/dream-num/univer/issues"&gt;issues or feature requests&lt;/a&gt; to us. Please read our &lt;a href="https://raw.githubusercontent.com/dream-num/univer/dev/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; first.&lt;/p&gt; 
&lt;p&gt;If you would like to contribute code to Univer, please refer to the contributing guide as well. It would guide you through the process of setting up the development environment and submitting a pull request.&lt;/p&gt; 
&lt;h2&gt;❤️ Sponsors&lt;/h2&gt; 
&lt;p&gt;The growth and development of the Univer project rely on the support of its backers and sponsors. If you are interested in supporting our project, we kindly invite you to consider becoming a sponsor. You can sponsor us through &lt;a href="https://opencollective.com/univer"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thanks to our sponsors, just part of them are listed here because of the space limit, ranking is no particular order:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/univer/sponsor/0/website"&gt;&lt;img src="https://opencollective.com/univer/sponsor/0/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/sponsor/1/website"&gt;&lt;img src="https://opencollective.com/univer/sponsor/1/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/sponsor/2/website"&gt;&lt;img src="https://opencollective.com/univer/sponsor/2/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/sponsor/3/website"&gt;&lt;img src="https://opencollective.com/univer/sponsor/3/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/sponsor/4/website"&gt;&lt;img src="https://opencollective.com/univer/sponsor/4/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/sponsor/5/website"&gt;&lt;img src="https://opencollective.com/univer/sponsor/5/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/sponsor/6/website"&gt;&lt;img src="https://opencollective.com/univer/sponsor/6/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/univer/backer/0/website"&gt;&lt;img src="https://opencollective.com/univer/backer/0/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/backer/1/website"&gt;&lt;img src="https://opencollective.com/univer/backer/1/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/backer/2/website"&gt;&lt;img src="https://opencollective.com/univer/backer/2/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/backer/3/website"&gt;&lt;img src="https://opencollective.com/univer/backer/3/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/backer/4/website"&gt;&lt;img src="https://opencollective.com/univer/backer/4/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/backer/5/website"&gt;&lt;img src="https://opencollective.com/univer/backer/5/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/univer/backer/6/website"&gt;&lt;img src="https://opencollective.com/univer/backer/6/avatar.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;Copyright © 2021-2025 DreamNum Co,Ltd. All Rights Reserved.&lt;/p&gt; 
&lt;p&gt;Licensed under the &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;Apache-2.0&lt;/a&gt; license.&lt;/p&gt; 
&lt;!-- Footnotes --&gt; 
&lt;p&gt;[^1]: These features are provided by the non-OSS version of Univer, which is free for commercial use and also includes paid upgrade plans.&lt;/p&gt; 
&lt;!-- Links --&gt;</description>
    </item>
    
    <item>
      <title>chartdb/chartdb</title>
      <link>https://github.com/chartdb/chartdb</link>
      <description>&lt;p&gt;Database diagrams editor that allows you to visualize and design your DB with a single query.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://chartdb.io#gh-light-mode-only"&gt; &lt;img src="https://github.com/chartdb/chartdb/raw/main/src/assets/logo-light.png" width="400" height="70" alt="ChartDB" /&gt; &lt;/a&gt; &lt;a href="https://chartdb.io##gh-dark-mode-only"&gt; &lt;img src="https://github.com/chartdb/chartdb/raw/main/src/assets/logo-dark.png" width="400" height="70" alt="ChartDB" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;b&gt;Open-source database diagrams editor&lt;/b&gt; &lt;br /&gt; &lt;b&gt;No installations • No Database password required.&lt;/b&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; &lt;a href="https://discord.gg/QeFwyWSKwC"&gt;Community&lt;/a&gt; • &lt;a href="https://www.chartdb.io?ref=github_readme"&gt;Website&lt;/a&gt; • &lt;a href="https://chartdb.io/templates?ref=github_readme"&gt;Examples&lt;/a&gt; • &lt;a href="https://app.chartdb.io?ref=github_readme"&gt;Demo&lt;/a&gt; &lt;/h3&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://github.com/chartdb/chartdb?tab=AGPL-3.0-1-ov-file#readme"&gt; &lt;img src="https://img.shields.io/github/license/chartdb/chartdb?color=blue" alt="ChartDB is released under the AGPL license." /&gt; &lt;/a&gt; &lt;a href="https://github.com/chartdb/chartdb/raw/main/CONTRIBUTING.md"&gt; &lt;img src="https://img.shields.io/badge/PRs-Welcome-brightgreen" alt="PRs welcome!" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/QeFwyWSKwC"&gt; &lt;img src="https://img.shields.io/discord/1277047413705670678?color=5865F2&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord community channel" /&gt; &lt;/a&gt; &lt;a href="https://x.com/intent/follow?screen_name=jonathanfishner"&gt; &lt;img src="https://img.shields.io/twitter/follow/jonathanfishner?style=social" /&gt; &lt;/a&gt; &lt;/h4&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;img width="700px" src="https://raw.githubusercontent.com/chartdb/chartdb/main/public/chartdb.png" /&gt; &lt;/p&gt; 
&lt;h3&gt;🎉 ChartDB&lt;/h3&gt; 
&lt;p&gt;ChartDB is a powerful, web-based database diagramming editor. Instantly visualize your database schema with a single &lt;strong&gt;"Smart Query."&lt;/strong&gt; Customize diagrams, export SQL scripts, and access all features—no account required. Experience seamless database design here.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;What it does&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Instant Schema Import&lt;/strong&gt; Run a single query to instantly retrieve your database schema as JSON. This makes it incredibly fast to visualize your database schema, whether for documentation, team discussions, or simply understanding your data better.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Export for Easy Migration&lt;/strong&gt; Our AI-driven export feature allows you to generate the DDL script in the dialect of your choice. Whether you're migrating from MySQL to PostgreSQL or from SQLite to MariaDB, ChartDB simplifies the process by providing the necessary scripts tailored to your target database.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Interactive Editing&lt;/strong&gt; Fine-tune your database schema using our intuitive editor. Easily make adjustments or annotations to better visualize complex structures.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Status&lt;/h3&gt; 
&lt;p&gt;ChartDB is currently in Public Beta. Star and watch this repository to get notified of updates.&lt;/p&gt; 
&lt;h3&gt;Supported Databases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ PostgreSQL (&lt;img src="https://raw.githubusercontent.com/chartdb/chartdb/main/src/assets/postgresql_logo_2.png" width="15" /&gt; + &lt;img src="https://raw.githubusercontent.com/chartdb/chartdb/main/src/assets/supabase.png" alt="Supabase" width="15" /&gt; + &lt;img src="https://raw.githubusercontent.com/chartdb/chartdb/main/src/assets/timescale.png" alt="Timescale" width="15" /&gt; )&lt;/li&gt; 
 &lt;li&gt;✅ MySQL&lt;/li&gt; 
 &lt;li&gt;✅ SQL Server&lt;/li&gt; 
 &lt;li&gt;✅ MariaDB&lt;/li&gt; 
 &lt;li&gt;✅ SQLite (&lt;img src="https://raw.githubusercontent.com/chartdb/chartdb/main/src/assets/sqlite_logo_2.png" width="15" /&gt; + &lt;img src="https://raw.githubusercontent.com/chartdb/chartdb/main/src/assets/cloudflare_d1.png" alt="Cloudflare D1" width="15" /&gt; Cloudflare D1)&lt;/li&gt; 
 &lt;li&gt;✅ CockroachDB&lt;/li&gt; 
 &lt;li&gt;✅ ClickHouse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Use the &lt;a href="https://app.chartdb.io?ref=github_readme_2"&gt;cloud version&lt;/a&gt; or deploy locally:&lt;/p&gt; 
&lt;h3&gt;How To Use&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install
npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install
npm run build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or like this if you want to have AI capabilities:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install
VITE_OPENAI_API_KEY=&amp;lt;YOUR_OPEN_AI_KEY&amp;gt; npm run build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run the Docker Container&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -e OPENAI_API_KEY=&amp;lt;YOUR_OPEN_AI_KEY&amp;gt; -p 8080:80 ghcr.io/chartdb/chartdb:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Build and Run locally&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t chartdb .
docker run -e OPENAI_API_KEY=&amp;lt;YOUR_OPEN_AI_KEY&amp;gt; -p 8080:80 chartdb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Custom Inference Server&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build
docker build \
  --build-arg VITE_OPENAI_API_ENDPOINT=&amp;lt;YOUR_ENDPOINT&amp;gt; \
  --build-arg VITE_LLM_MODEL_NAME=&amp;lt;YOUR_MODEL_NAME&amp;gt; \
  -t chartdb .

# Run
docker run \
  -e OPENAI_API_ENDPOINT=&amp;lt;YOUR_ENDPOINT&amp;gt; \
  -e LLM_MODEL_NAME=&amp;lt;YOUR_MODEL_NAME&amp;gt; \
  -p 8080:80 chartdb
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Privacy Note:&lt;/strong&gt; ChartDB includes privacy-focused analytics via Fathom Analytics. You can disable this by adding &lt;code&gt;-e DISABLE_ANALYTICS=true&lt;/code&gt; to the run command or &lt;code&gt;--build-arg VITE_DISABLE_ANALYTICS=true&lt;/code&gt; when building.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You must configure either Option 1 (OpenAI API key) OR Option 2 (Custom endpoint and model name) for AI capabilities to work. Do not mix the two options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Open your browser and navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Example configuration for a local vLLM server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;VITE_OPENAI_API_ENDPOINT=http://localhost:8000/v1
VITE_LLM_MODEL_NAME=Qwen/Qwen2.5-32B-Instruct-AWQ
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Try it on our website&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to &lt;a href="https://chartdb.io?ref=github_readme_2"&gt;ChartDB.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click "Go to app"&lt;/li&gt; 
 &lt;li&gt;Choose the database that you are using.&lt;/li&gt; 
 &lt;li&gt;Take the magic query and run it in your database.&lt;/li&gt; 
 &lt;li&gt;Copy and paste the resulting JSON set into ChartDB.&lt;/li&gt; 
 &lt;li&gt;Enjoy Viewing &amp;amp; Editing!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;💚 Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/QeFwyWSKwC"&gt;Discord&lt;/a&gt; (For live discussion with the community and the ChartDB team)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chartdb/chartdb/issues"&gt;GitHub Issues&lt;/a&gt; (For any bugs and errors you encounter using ChartDB)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/intent/follow?screen_name=jonathanfishner"&gt;Twitter&lt;/a&gt; (Get news fast)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions, big or small, and are here to guide you along the way. Message us in the &lt;a href="https://discord.gg/QeFwyWSKwC"&gt;ChartDB Community Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more information on how to contribute, please see our &lt;a href="https://raw.githubusercontent.com/chartdb/chartdb/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is released with a &lt;a href="https://raw.githubusercontent.com/chartdb/chartdb/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project, you agree to follow its terms.&lt;/p&gt; 
&lt;p&gt;Thank you for helping us make ChartDB better for everyone &lt;span&gt;❤️&lt;/span&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;ChartDB is licensed under the &lt;a href="https://raw.githubusercontent.com/chartdb/chartdb/main/LICENSE"&gt;GNU Affero General Public License v3.0&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google/highway</title>
      <link>https://github.com/google/highway</link>
      <description>&lt;p&gt;Performance-portable, length-agnostic SIMD with runtime dispatch&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Efficient and performance-portable vector software&lt;/h1&gt; 
&lt;p&gt;Highway is a C++ library that provides portable SIMD/vector intrinsics.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://google.github.io/highway/en/master/"&gt;Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Previously licensed under Apache 2, now dual-licensed as Apache 2 / BSD-3.&lt;/p&gt; 
&lt;h2&gt;Why&lt;/h2&gt; 
&lt;p&gt;We are passionate about high-performance software. We see major untapped potential in CPUs (servers, mobile, desktops). Highway is for engineers who want to reliably and economically push the boundaries of what is possible in software.&lt;/p&gt; 
&lt;h2&gt;How&lt;/h2&gt; 
&lt;p&gt;CPUs provide SIMD/vector instructions that apply the same operation to multiple data items. This can reduce energy usage e.g. &lt;em&gt;fivefold&lt;/em&gt; because fewer instructions are executed. We also often see &lt;em&gt;5-10x&lt;/em&gt; speedups.&lt;/p&gt; 
&lt;p&gt;Highway makes SIMD/vector programming practical and workable according to these guiding principles:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Does what you expect&lt;/strong&gt;: Highway is a C++ library with carefully-chosen functions that map well to CPU instructions without extensive compiler transformations. The resulting code is more predictable and robust to code changes/compiler updates than autovectorization.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Works on widely-used platforms&lt;/strong&gt;: Highway supports five architectures; the same application code can target various instruction sets, including those with 'scalable' vectors (size unknown at compile time). Highway only requires C++11 and supports four families of compilers. If you would like to use Highway on other platforms, please raise an issue.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Flexible to deploy&lt;/strong&gt;: Applications using Highway can run on heterogeneous clouds or client devices, choosing the best available instruction set at runtime. Alternatively, developers may choose to target a single instruction set without any runtime overhead. In both cases, the application code is the same except for swapping &lt;code&gt;HWY_STATIC_DISPATCH&lt;/code&gt; with &lt;code&gt;HWY_DYNAMIC_DISPATCH&lt;/code&gt; plus one line of code. See also @kfjahnke's &lt;a href="https://github.com/kfjahnke/zimt/raw/multi_isa/examples/multi_isa_example/multi_simd_isa.md"&gt;introduction to dispatching&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Suitable for a variety of domains&lt;/strong&gt;: Highway provides an extensive set of operations, used for image processing (floating-point), compression, video analysis, linear algebra, cryptography, sorting and random generation. We recognise that new use-cases may require additional ops and are happy to add them where it makes sense (e.g. no performance cliffs on some architectures). If you would like to discuss, please file an issue.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Rewards data-parallel design&lt;/strong&gt;: Highway provides tools such as Gather, MaskedLoad, and FixedTag to enable speedups for legacy data structures. However, the biggest gains are unlocked by designing algorithms and data structures for scalable vectors. Helpful techniques include batching, structure-of-array layouts, and aligned/padded allocations.&lt;/p&gt; 
&lt;p&gt;We recommend these resources for getting started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=R57biOOhnJM"&gt;SIMD programming with Highway talk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://const.me/articles/simd/simd.pdf"&gt;SIMD for C++ Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.algorithmica.org/hpc/"&gt;Algorithms for Modern Hardware&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://agner.org/optimize/optimizing_cpp.pdf"&gt;Optimizing software in C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stackoverflow.blog/2020/07/08/improving-performance-with-simd-intrinsics-in-three-use-cases/"&gt;Improving performance with SIMD intrinsics in three use cases&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Online demos using Compiler Explorer:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gcc.godbolt.org/z/KM3ben7ET"&gt;multiple targets with dynamic dispatch&lt;/a&gt; (more complicated, but flexible and uses best available SIMD)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gcc.godbolt.org/z/rGnjMevKG"&gt;single target using -m flags&lt;/a&gt; (simpler, but requires/only uses the instruction set enabled by compiler flags)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We observe that Highway is referenced in the following open source projects, found via sourcegraph.com. Most are GitHub repositories. If you would like to add your project or link to it directly, feel free to raise an issue or contact us via the below email.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Audio: &lt;a href="https://github.com/google/zimtohrli"&gt;Zimtohrli perceptual metric&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Browsers: Chromium (+Vivaldi), Firefox (+floorp / foxhound / librewolf / Waterfox)&lt;/li&gt; 
 &lt;li&gt;Computational biology: &lt;a href="https://github.com/bnprks/BPCells"&gt;RNA analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Computer graphics: &lt;a href="https://github.com/rools/voxl"&gt;Sparse voxel renderer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Cryptography: google/distributed_point_functions, google/shell-encryption&lt;/li&gt; 
 &lt;li&gt;Data structures: bkille/BitLib&lt;/li&gt; 
 &lt;li&gt;Image codecs: eustas/2im, &lt;a href="https://github.com/GrokImageCompression/grok"&gt;Grok JPEG 2000&lt;/a&gt;, &lt;a href="https://github.com/libjxl/libjxl"&gt;JPEG XL&lt;/a&gt;, &lt;a href="https://github.com/osamu620/JPEGenc"&gt;JPEGenc&lt;/a&gt;, &lt;a href="https://github.com/google/jpegli"&gt;Jpegli&lt;/a&gt;, OpenHTJ2K&lt;/li&gt; 
 &lt;li&gt;Image processing: cloudinary/ssimulacra2, m-ab-s/media-autobuild_suite, &lt;a href="https://github.com/libvips/libvips"&gt;libvips&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Image viewers: AlienCowEatCake/ImageViewer, diffractor/diffractor, mirillis/jpegxl-wic, &lt;a href="https://bitbucket.org/kfj/pv/"&gt;Lux panorama/image viewer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Information retrieval: &lt;a href="https://github.com/iresearch-toolkit/iresearch"&gt;iresearch database index&lt;/a&gt;, michaeljclark/zvec, &lt;a href="https://github.com/varchar-io/nebula"&gt;nebula interactive analytics / OLAP&lt;/a&gt;, &lt;a href="https://github.com/google-research/google-research/tree/7a269cb2ce0ae1db591fe11b62cbc0be7d72532a/scann"&gt;ScaNN Scalable Nearest Neighbors&lt;/a&gt;, &lt;a href="https://github.com/1yefuwang1/vectorlite/"&gt;vectorlite vector search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Machine learning: &lt;a href="https://github.com/google/gemma.cpp"&gt;gemma.cpp&lt;/a&gt;, Tensorflow, Numpy, zpye/SimpleInfer&lt;/li&gt; 
 &lt;li&gt;Robotics: &lt;a href="https://github.com/RobotLocomotion/drake"&gt;MIT Model-Based Design and Verification&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.mnm-team.org/pub/Fopras/rock23/"&gt;Evaluation of C++ SIMD Libraries&lt;/a&gt;: "Highway excelled with a strong performance across multiple SIMD extensions [..]. Thus, Highway may currently be the most suitable SIMD library for many software projects."&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kfjahnke/zimt"&gt;zimt&lt;/a&gt;: C++11 template library to process n-dimensional arrays with multi-threaded SIMD code&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/highway/tree/master/hwy/contrib/sort"&gt;vectorized Quicksort&lt;/a&gt; (&lt;a href="https://arxiv.org/abs/2205.05982"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you'd like to get Highway, in addition to cloning from this GitHub repository or using it as a Git submodule, you can also find it in the following package managers or repositories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;alpinelinux&lt;/li&gt; 
 &lt;li&gt;conan-io&lt;/li&gt; 
 &lt;li&gt;conda-forge&lt;/li&gt; 
 &lt;li&gt;DragonFlyBSD,&lt;/li&gt; 
 &lt;li&gt;fd00/yacp&lt;/li&gt; 
 &lt;li&gt;freebsd&lt;/li&gt; 
 &lt;li&gt;getsolus/packages&lt;/li&gt; 
 &lt;li&gt;ghostbsd&lt;/li&gt; 
 &lt;li&gt;microsoft/vcpkg&lt;/li&gt; 
 &lt;li&gt;MidnightBSD&lt;/li&gt; 
 &lt;li&gt;MSYS2&lt;/li&gt; 
 &lt;li&gt;NetBSD&lt;/li&gt; 
 &lt;li&gt;openSUSE&lt;/li&gt; 
 &lt;li&gt;opnsense&lt;/li&gt; 
 &lt;li&gt;Xilinx/Vitis_Libraries&lt;/li&gt; 
 &lt;li&gt;xmake-io/xmake-repo&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See also the list at &lt;a href="https://repology.org/project/highway-simd-library/versions"&gt;https://repology.org/project/highway-simd-library/versions&lt;/a&gt; .&lt;/p&gt; 
&lt;h2&gt;Current status&lt;/h2&gt; 
&lt;h3&gt;Targets&lt;/h3&gt; 
&lt;p&gt;Highway supports 24 targets, listed in alphabetical order of platform:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Any: &lt;code&gt;EMU128&lt;/code&gt;, &lt;code&gt;SCALAR&lt;/code&gt;;&lt;/li&gt; 
 &lt;li&gt;Armv7+: &lt;code&gt;NEON_WITHOUT_AES&lt;/code&gt;, &lt;code&gt;NEON&lt;/code&gt;, &lt;code&gt;NEON_BF16&lt;/code&gt;, &lt;code&gt;SVE&lt;/code&gt;, &lt;code&gt;SVE2&lt;/code&gt;, &lt;code&gt;SVE_256&lt;/code&gt;, &lt;code&gt;SVE2_128&lt;/code&gt;;&lt;/li&gt; 
 &lt;li&gt;IBM Z: &lt;code&gt;Z14&lt;/code&gt;, &lt;code&gt;Z15&lt;/code&gt;;&lt;/li&gt; 
 &lt;li&gt;POWER: &lt;code&gt;PPC8&lt;/code&gt; (v2.07), &lt;code&gt;PPC9&lt;/code&gt; (v3.0), &lt;code&gt;PPC10&lt;/code&gt; (v3.1B, not yet supported due to compiler bugs, see #1207; also requires QEMU 7.2);&lt;/li&gt; 
 &lt;li&gt;RISC-V: &lt;code&gt;RVV&lt;/code&gt; (1.0);&lt;/li&gt; 
 &lt;li&gt;WebAssembly: &lt;code&gt;WASM&lt;/code&gt;, &lt;code&gt;WASM_EMU256&lt;/code&gt; (a 2x unrolled version of wasm128, enabled if &lt;code&gt;HWY_WANT_WASM2&lt;/code&gt; is defined. This will remain supported until it is potentially superseded by a future version of WASM.);&lt;/li&gt; 
 &lt;li&gt;x86: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;SSE2&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;SSSE3&lt;/code&gt; (~Intel Core)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;SSE4&lt;/code&gt; (~Nehalem, also includes AES + CLMUL).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;AVX2&lt;/code&gt; (~Haswell, also includes BMI2 + F16 + FMA)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;AVX3&lt;/code&gt; (~Skylake, AVX-512F/BW/CD/DQ/VL)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;AVX3_DL&lt;/code&gt; (~Icelake, includes &lt;code&gt;BitAlg&lt;/code&gt; + &lt;code&gt;CLMUL&lt;/code&gt; + &lt;code&gt;GFNI&lt;/code&gt; + &lt;code&gt;VAES&lt;/code&gt; + &lt;code&gt;VBMI&lt;/code&gt; + &lt;code&gt;VBMI2&lt;/code&gt; + &lt;code&gt;VNNI&lt;/code&gt; + &lt;code&gt;VPOPCNT&lt;/code&gt;),&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;AVX3_ZEN4&lt;/code&gt; (AVX3_DL plus BF16, optimized for AMD Zen4; requires opt-in by defining &lt;code&gt;HWY_WANT_AVX3_ZEN4&lt;/code&gt; if compiling for static dispatch, but enabled by default for runtime dispatch),&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;AVX3_SPR&lt;/code&gt; (~Sapphire Rapids, includes AVX-512FP16)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Our policy is that unless otherwise specified, targets will remain supported as long as they can be (cross-)compiled with currently supported Clang or GCC, and tested using QEMU. If the target can be compiled with LLVM trunk and tested using our version of QEMU without extra flags, then it is eligible for inclusion in our continuous testing infrastructure. Otherwise, the target will be manually tested before releases with selected versions/configurations of Clang and GCC.&lt;/p&gt; 
&lt;p&gt;SVE was initially tested using farm_sve (see acknowledgments).&lt;/p&gt; 
&lt;h3&gt;Versioning&lt;/h3&gt; 
&lt;p&gt;Highway releases aim to follow the semver.org system (MAJOR.MINOR.PATCH), incrementing MINOR after backward-compatible additions and PATCH after backward-compatible fixes. We recommend using releases (rather than the Git tip) because they are tested more extensively, see below.&lt;/p&gt; 
&lt;p&gt;The current version 1.0 signals an increased focus on backwards compatibility. Applications using documented functionality will remain compatible with future updates that have the same major version number.&lt;/p&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;p&gt;Continuous integration tests build with a recent version of Clang (running on native x86, or QEMU for RISC-V and Arm) and MSVC 2019 (v19.28, running on native x86).&lt;/p&gt; 
&lt;p&gt;Before releases, we also test on x86 with Clang and GCC, and Armv7/8 via GCC cross-compile. See the &lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/release_testing_process.md"&gt;testing process&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Related modules&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;contrib&lt;/code&gt; directory contains SIMD-related utilities: an image class with aligned rows, a math library (16 functions already implemented, mostly trigonometry), and functions for computing dot products and sorting.&lt;/p&gt; 
&lt;h3&gt;Other libraries&lt;/h3&gt; 
&lt;p&gt;If you only require x86 support, you may also use Agner Fog's &lt;a href="https://github.com/vectorclass"&gt;VCL vector class library&lt;/a&gt;. It includes many functions including a complete math library.&lt;/p&gt; 
&lt;p&gt;If you have existing code using x86/NEON intrinsics, you may be interested in &lt;a href="https://github.com/simd-everywhere/simde"&gt;SIMDe&lt;/a&gt;, which emulates those intrinsics using other platforms' intrinsics or autovectorization.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;This project uses CMake to generate and build. In a Debian-based system you can install it via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt install cmake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Highway's unit tests use &lt;a href="https://github.com/google/googletest"&gt;googletest&lt;/a&gt;. By default, Highway's CMake downloads this dependency at configuration time. You can avoid this by setting the &lt;code&gt;HWY_SYSTEM_GTEST&lt;/code&gt; CMake variable to ON and installing gtest separately:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt install libgtest-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can define &lt;code&gt;HWY_TEST_STANDALONE=1&lt;/code&gt; and remove all occurrences of &lt;code&gt;gtest_main&lt;/code&gt; in each BUILD file, then tests avoid the dependency on GUnit.&lt;/p&gt; 
&lt;p&gt;Running cross-compiled tests requires support from the OS, which on Debian is provided by the &lt;code&gt;qemu-user-binfmt&lt;/code&gt; package.&lt;/p&gt; 
&lt;p&gt;To build Highway as a shared or static library (depending on BUILD_SHARED_LIBS), the standard CMake workflow can be used:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p build &amp;amp;&amp;amp; cd build
cmake ..
make -j &amp;amp;&amp;amp; make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or you can run &lt;code&gt;run_tests.sh&lt;/code&gt; (&lt;code&gt;run_tests.bat&lt;/code&gt; on Windows).&lt;/p&gt; 
&lt;p&gt;Bazel is also supported for building, but it is not as widely used/tested.&lt;/p&gt; 
&lt;p&gt;When building for Armv7, a limitation of current compilers requires you to add &lt;code&gt;-DHWY_CMAKE_ARM7:BOOL=ON&lt;/code&gt; to the CMake command line; see #834 and #1032. We understand that work is underway to remove this limitation.&lt;/p&gt; 
&lt;p&gt;Building on 32-bit x86 is not officially supported, and AVX2/3 are disabled by default there. Note that johnplatts has successfully built and run the Highway tests on 32-bit x86, including AVX2/3, on GCC 7/8 and Clang 8/11/12. On Ubuntu 22.04, Clang 11 and 12, but not later versions, require extra compiler flags &lt;code&gt;-m32 -isystem /usr/i686-linux-gnu/include&lt;/code&gt;. Clang 10 and earlier require the above plus &lt;code&gt;-isystem /usr/i686-linux-gnu/include/c++/12/i686-linux-gnu&lt;/code&gt;. See #1279.&lt;/p&gt; 
&lt;h2&gt;Building highway - Using vcpkg&lt;/h2&gt; 
&lt;p&gt;highway is now available in &lt;a href="https://github.com/Microsoft/vcpkg"&gt;vcpkg&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vcpkg install highway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The highway port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please &lt;a href="https://github.com/Microsoft/vcpkg"&gt;create an issue or pull request&lt;/a&gt; on the vcpkg repository.&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;benchmark&lt;/code&gt; inside examples/ as a starting point.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/quick_reference.md"&gt;quick-reference page&lt;/a&gt; briefly lists all operations and their parameters, and the &lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/instruction_matrix.pdf"&gt;instruction_matrix&lt;/a&gt; indicates the number of instructions per operation.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/faq.md"&gt;FAQ&lt;/a&gt; answers questions about portability, API design and where to find more information.&lt;/p&gt; 
&lt;p&gt;We recommend using full SIMD vectors whenever possible for maximum performance portability. To obtain them, pass a &lt;code&gt;ScalableTag&amp;lt;float&amp;gt;&lt;/code&gt; (or equivalently &lt;code&gt;HWY_FULL(float)&lt;/code&gt;) tag to functions such as &lt;code&gt;Zero/Set/Load&lt;/code&gt;. There are two alternatives for use-cases requiring an upper bound on the lanes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;For up to &lt;code&gt;N&lt;/code&gt; lanes, specify &lt;code&gt;CappedTag&amp;lt;T, N&amp;gt;&lt;/code&gt; or the equivalent &lt;code&gt;HWY_CAPPED(T, N)&lt;/code&gt;. The actual number of lanes will be &lt;code&gt;N&lt;/code&gt; rounded down to the nearest power of two, such as 4 if &lt;code&gt;N&lt;/code&gt; is 5, or 8 if &lt;code&gt;N&lt;/code&gt; is 8. This is useful for data structures such as a narrow matrix. A loop is still required because vectors may actually have fewer than &lt;code&gt;N&lt;/code&gt; lanes.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For exactly a power of two &lt;code&gt;N&lt;/code&gt; lanes, specify &lt;code&gt;FixedTag&amp;lt;T, N&amp;gt;&lt;/code&gt;. The largest supported &lt;code&gt;N&lt;/code&gt; depends on the target, but is guaranteed to be at least &lt;code&gt;16/sizeof(T)&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Due to ADL restrictions, user code calling Highway ops must either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reside inside &lt;code&gt;namespace hwy { namespace HWY_NAMESPACE {&lt;/code&gt;; or&lt;/li&gt; 
 &lt;li&gt;prefix each op with an alias such as &lt;code&gt;namespace hn = hwy::HWY_NAMESPACE; hn::Add()&lt;/code&gt;; or&lt;/li&gt; 
 &lt;li&gt;add using-declarations for each op used: &lt;code&gt;using hwy::HWY_NAMESPACE::Add;&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, each function that calls Highway ops (such as &lt;code&gt;Load&lt;/code&gt;) must either be prefixed with &lt;code&gt;HWY_ATTR&lt;/code&gt;, OR reside between &lt;code&gt;HWY_BEFORE_NAMESPACE()&lt;/code&gt; and &lt;code&gt;HWY_AFTER_NAMESPACE()&lt;/code&gt;. Lambda functions currently require &lt;code&gt;HWY_ATTR&lt;/code&gt; before their opening brace.&lt;/p&gt; 
&lt;p&gt;Do not use namespace-scope nor &lt;code&gt;static&lt;/code&gt; initializers for SIMD vectors because this can cause SIGILL when using runtime dispatch and the compiler chooses an initializer compiled for a target not supported by the current CPU. Instead, constants initialized via &lt;code&gt;Set&lt;/code&gt; should generally be local (const) variables.&lt;/p&gt; 
&lt;p&gt;The entry points into code using Highway differ slightly depending on whether they use static or dynamic dispatch. In both cases, we recommend that the top-level function receives one or more pointers to arrays, rather than target-specific vector types.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;For static dispatch, &lt;code&gt;HWY_TARGET&lt;/code&gt; will be the best available target among &lt;code&gt;HWY_BASELINE_TARGETS&lt;/code&gt;, i.e. those allowed for use by the compiler (see &lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/quick_reference.md"&gt;quick-reference&lt;/a&gt;). Functions inside &lt;code&gt;HWY_NAMESPACE&lt;/code&gt; can be called using &lt;code&gt;HWY_STATIC_DISPATCH(func)(args)&lt;/code&gt; within the same module they are defined in. You can call the function from other modules by wrapping it in a regular function and declaring the regular function in a header.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For dynamic dispatch, a table of function pointers is generated via the &lt;code&gt;HWY_EXPORT&lt;/code&gt; macro that is used by &lt;code&gt;HWY_DYNAMIC_DISPATCH(func)(args)&lt;/code&gt; to call the best function pointer for the current CPU's supported targets. A module is automatically compiled for each target in &lt;code&gt;HWY_TARGETS&lt;/code&gt; (see &lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/quick_reference.md"&gt;quick-reference&lt;/a&gt;) if &lt;code&gt;HWY_TARGET_INCLUDE&lt;/code&gt; is defined and &lt;code&gt;foreach_target.h&lt;/code&gt; is included. Note that the first invocation of &lt;code&gt;HWY_DYNAMIC_DISPATCH&lt;/code&gt;, or each call to the pointer returned by the first invocation of &lt;code&gt;HWY_DYNAMIC_POINTER&lt;/code&gt;, involves some CPU detection overhead. You can prevent this by calling the following before any invocation of &lt;code&gt;HWY_DYNAMIC_*&lt;/code&gt;: &lt;code&gt;hwy::GetChosenTarget().Update(hwy::SupportedTargets());&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See also a separate &lt;a href="https://github.com/kfjahnke/zimt/raw/multi_isa/examples/multi_isa_example/multi_simd_isa.md"&gt;introduction to dynamic dispatch&lt;/a&gt; by @kfjahnke.&lt;/p&gt; 
&lt;p&gt;When using dynamic dispatch, &lt;code&gt;foreach_target.h&lt;/code&gt; is included from translation units (.cc files), not headers. Headers containing vector code shared between several translation units require a special include guard, for example the following taken from &lt;code&gt;examples/skeleton-inl.h&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#if defined(HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_) == defined(HWY_TARGET_TOGGLE)
#ifdef HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_
#undef HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_
#else
#define HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_
#endif

#include "hwy/highway.h"
// Your vector code
#endif
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By convention, we name such headers &lt;code&gt;-inl.h&lt;/code&gt; because their contents (often function templates) are usually inlined.&lt;/p&gt; 
&lt;h2&gt;Compiler flags&lt;/h2&gt; 
&lt;p&gt;Applications should be compiled with optimizations enabled. Without inlining SIMD code may slow down by factors of 10 to 100. For clang and GCC, &lt;code&gt;-O2&lt;/code&gt; is generally sufficient.&lt;/p&gt; 
&lt;p&gt;For MSVC, we recommend compiling with &lt;code&gt;/Gv&lt;/code&gt; to allow non-inlined functions to pass vector arguments in registers. If intending to use the AVX2 target together with half-width vectors (e.g. for &lt;code&gt;PromoteTo&lt;/code&gt;), it is also important to compile with &lt;code&gt;/arch:AVX2&lt;/code&gt;. This seems to be the only way to reliably generate VEX-encoded SSE instructions on MSVC. Sometimes MSVC generates VEX-encoded SSE instructions, if they are mixed with AVX, but not always, see &lt;a href="https://developercommunity.visualstudio.com/t/10618264"&gt;DevCom-10618264&lt;/a&gt;. Otherwise, mixing VEX-encoded AVX2 instructions and non-VEX SSE may cause severe performance degradation. Unfortunately, with &lt;code&gt;/arch:AVX2&lt;/code&gt; option, the resulting binary will then require AVX2. Note that no such flag is needed for clang and GCC because they support target-specific attributes, which we use to ensure proper VEX code generation for AVX2 targets.&lt;/p&gt; 
&lt;h2&gt;Strip-mining loops&lt;/h2&gt; 
&lt;p&gt;When vectorizing a loop, an important question is whether and how to deal with a number of iterations ('trip count', denoted &lt;code&gt;count&lt;/code&gt;) that does not evenly divide the vector size &lt;code&gt;N = Lanes(d)&lt;/code&gt;. For example, it may be necessary to avoid writing past the end of an array.&lt;/p&gt; 
&lt;p&gt;In this section, let &lt;code&gt;T&lt;/code&gt; denote the element type and &lt;code&gt;d = ScalableTag&amp;lt;T&amp;gt;&lt;/code&gt;. Assume the loop body is given as a function &lt;code&gt;template&amp;lt;bool partial, class D&amp;gt; void LoopBody(D d, size_t index, size_t max_n)&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;"Strip-mining" is a technique for vectorizing a loop by transforming it into an outer loop and inner loop, such that the number of iterations in the inner loop matches the vector width. Then, the inner loop is replaced with vector operations.&lt;/p&gt; 
&lt;p&gt;Highway offers several strategies for loop vectorization:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ensure all inputs/outputs are padded. Then the (outer) loop is simply&lt;/p&gt; &lt;pre&gt;&lt;code&gt;for (size_t i = 0; i &amp;lt; count; i += N) LoopBody&amp;lt;false&amp;gt;(d, i, 0);
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here, the template parameter and second function argument are not needed.&lt;/p&gt; &lt;p&gt;This is the preferred option, unless &lt;code&gt;N&lt;/code&gt; is in the thousands and vector operations are pipelined with long latencies. This was the case for supercomputers in the 90s, but nowadays ALUs are cheap and we see most implementations split vectors into 1, 2 or 4 parts, so there is little cost to processing entire vectors even if we do not need all their lanes. Indeed this avoids the (potentially large) cost of predication or partial loads/stores on older targets, and does not duplicate code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Process whole vectors and include previously processed elements in the last vector:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;for (size_t i = 0; i &amp;lt; count; i += N) LoopBody&amp;lt;false&amp;gt;(d, HWY_MIN(i, count - N), 0);
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is the second preferred option provided that &lt;code&gt;count &amp;gt;= N&lt;/code&gt; and &lt;code&gt;LoopBody&lt;/code&gt; is idempotent. Some elements might be processed twice, but a single code path and full vectorization is usually worth it. Even if &lt;code&gt;count &amp;lt; N&lt;/code&gt;, it usually makes sense to pad inputs/outputs up to &lt;code&gt;N&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use the &lt;code&gt;Transform*&lt;/code&gt; functions in hwy/contrib/algo/transform-inl.h. This takes care of the loop and remainder handling and you simply define a generic lambda function (C++14) or functor which receives the current vector from the input/output array, plus optionally vectors from up to two extra input arrays, and returns the value to write to the input/output array.&lt;/p&gt; &lt;p&gt;Here is an example implementing the BLAS function SAXPY (&lt;code&gt;alpha * x + y&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Transform1(d, x, n, y, [](auto d, const auto v, const auto v1) HWY_ATTR {
  return MulAdd(Set(d, alpha), v, v1);
});
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Process whole vectors as above, followed by a scalar loop:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;size_t i = 0;
for (; i + N &amp;lt;= count; i += N) LoopBody&amp;lt;false&amp;gt;(d, i, 0);
for (; i &amp;lt; count; ++i) LoopBody&amp;lt;false&amp;gt;(CappedTag&amp;lt;T, 1&amp;gt;(), i, 0);
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The template parameter and second function arguments are again not needed.&lt;/p&gt; &lt;p&gt;This avoids duplicating code, and is reasonable if &lt;code&gt;count&lt;/code&gt; is large. If &lt;code&gt;count&lt;/code&gt; is small, the second loop may be slower than the next option.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Process whole vectors as above, followed by a single call to a modified &lt;code&gt;LoopBody&lt;/code&gt; with masking:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;size_t i = 0;
for (; i + N &amp;lt;= count; i += N) {
  LoopBody&amp;lt;false&amp;gt;(d, i, 0);
}
if (i &amp;lt; count) {
  LoopBody&amp;lt;true&amp;gt;(d, i, count - i);
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now the template parameter and third function argument can be used inside &lt;code&gt;LoopBody&lt;/code&gt; to non-atomically 'blend' the first &lt;code&gt;num_remaining&lt;/code&gt; lanes of &lt;code&gt;v&lt;/code&gt; with the previous contents of memory at subsequent locations: &lt;code&gt;BlendedStore(v, FirstN(d, num_remaining), d, pointer);&lt;/code&gt;. Similarly, &lt;code&gt;MaskedLoad(FirstN(d, num_remaining), d, pointer)&lt;/code&gt; loads the first &lt;code&gt;num_remaining&lt;/code&gt; elements and returns zero in other lanes.&lt;/p&gt; &lt;p&gt;This is a good default when it is infeasible to ensure vectors are padded, but is only safe &lt;code&gt;#if !HWY_MEM_OPS_MIGHT_FAULT&lt;/code&gt;! In contrast to the scalar loop, only a single final iteration is needed. The increased code size from two loop bodies is expected to be worthwhile because it avoids the cost of masking in all but the final iteration.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Additional resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/highway_intro.pdf"&gt;Highway introduction (slides)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/instruction_matrix.pdf"&gt;Overview of instructions per operation on different architectures&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/design_philosophy.md"&gt;Design philosophy and comparison&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/google/highway/master/g3doc/impl_details.md"&gt;Implementation details&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;We have used &lt;a href="https://gitlab.inria.fr/bramas/farm-sve"&gt;farm-sve&lt;/a&gt; by Berenger Bramas; it has proved useful for checking the SVE port on an x86 development machine.&lt;/p&gt; 
&lt;p&gt;This is not an officially supported Google product. Contact: &lt;a href="mailto:janwas@google.com"&gt;janwas@google.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA-NeMo/RL</title>
      <link>https://github.com/NVIDIA-NeMo/RL</link>
      <description>&lt;p&gt;Scalable toolkit for efficient model reinforcement&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Nemo RL: A Scalable and Efficient Post-Training Library&lt;/h1&gt; 
&lt;h2&gt;📣 News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[7/25/2025] &lt;a href="https://github.com/NVIDIA-NeMo/RL/releases/tag/v0.3.0"&gt;Release v0.3.0!&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;📝 &lt;a href="https://nvidia-nemo.github.io/blog/2025/07/21/nemo-rl-v0.3/"&gt;v0.3.0 Blog Post&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;📊 View the release run metrics on &lt;a href="https://colab.research.google.com/drive/15kpesCV1m_C5UQFStssTEjaN2RsBMeZ0?usp=sharing"&gt;Google Colab&lt;/a&gt; to get a head start on your experimentation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;[5/14/2025] &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/guides/grpo-deepscaler.md"&gt;Reproduce DeepscaleR with NeMo RL!&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[5/14/2025] &lt;a href="https://github.com/NVIDIA-NeMo/RL/releases/tag/v0.2.1"&gt;Release v0.2.1!&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;📊 View the release run metrics on &lt;a href="https://colab.research.google.com/drive/1o14sO0gj_Tl_ZXGsoYip3C0r5ofkU1Ey?usp=sharing"&gt;Google Colab&lt;/a&gt; to get a head start on your experimentation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- markdown all in one --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#nemo-rl-a-scalable-and-efficient-post-training-library"&gt;Nemo RL: A Scalable and Efficient Post-Training Library&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#-news"&gt;📣 News&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#training-backends"&gt;Training Backends&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#grpo"&gt;GRPO&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#grpo-single-node"&gt;GRPO Single Node&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#grpo-multi-node"&gt;GRPO Multi-node&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#grpo-qwen25-32b"&gt;GRPO Qwen2.5-32B&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#grpo-multi-turn"&gt;GRPO Multi-Turn&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#supervised-fine-tuning-sft"&gt;Supervised Fine-Tuning (SFT)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#sft-single-node"&gt;SFT Single Node&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#sft-multi-node"&gt;SFT Multi-node&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#dpo"&gt;DPO&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#dpo-single-node"&gt;DPO Single Node&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#dpo-multi-node"&gt;DPO Multi-node&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#rm"&gt;RM&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#rm-single-node"&gt;RM Single Node&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#rm-multi-node"&gt;RM Multi-node&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#evaluation"&gt;Evaluation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#convert-model-format-optional"&gt;Convert Model Format (Optional)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#run-evaluation"&gt;Run Evaluation&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#set-up-clusters"&gt;Set Up Clusters&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#tips-and-tricks"&gt;Tips and Tricks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/#licenses"&gt;Licenses&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Nemo RL&lt;/strong&gt; is a scalable and efficient post-training library designed for models ranging from 1 GPU to thousands, and from tiny to over 100 billion parameters.&lt;/p&gt; 
&lt;p&gt;What you can expect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless integration with Hugging Face&lt;/strong&gt; for ease of use, allowing users to leverage a wide range of pre-trained models and tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High-performance implementation with Megatron Core&lt;/strong&gt;, supporting various parallelism techniques for large models (&amp;gt;100B) and large context lengths.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient resource management using Ray&lt;/strong&gt;, enabling scalable and flexible deployment across different hardware configurations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexibility&lt;/strong&gt; with a modular design that allows easy integration and customization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive documentation&lt;/strong&gt; that is both detailed and user-friendly, with practical examples.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;✅ &lt;em&gt;Available now&lt;/em&gt; | 🔜 &lt;em&gt;Coming in v0.4&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Fast Generation&lt;/strong&gt; - vLLM backend for optimized inference.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;HuggingFace Integration&lt;/strong&gt; - Works with 1-70B models (Qwen, Llama).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Distributed Training&lt;/strong&gt; - Fully Sharded Data Parallel (FSDP2) support and Ray-based infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Environment Support&lt;/strong&gt; - Support for multi-environment training.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Learning Algorithms&lt;/strong&gt; - GRPO (Group Relative Policy Optimization), SFT (Supervised Fine-Tuning), and DPO (Direct Preference Optimization).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Multi-Turn RL&lt;/strong&gt; - Multi-turn generation and training for RL with tool use, games, etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Large Model Support&lt;/strong&gt; - Native PyTorch support for models up to 70B parameters.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Advanced Parallelism&lt;/strong&gt; - PyTorch native FSDP2, TP, CP, and SP for efficient training.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;(even) Larger Model Support with Long(er) Sequences&lt;/strong&gt; - Advanced parallelisms with Megatron Core (TP/PP/CP/SP/EP).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Worker Isolation&lt;/strong&gt; - Process isolation between RL Actors (no worries about global state).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Environment Isolation&lt;/strong&gt; - Dependency isolation between components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Megatron Inference&lt;/strong&gt; - (static) Megatron Inference for day-0 support for new megatron models.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;MoE Models&lt;/strong&gt; - Support for DeepseekV3 and Qwen-3 MoE models&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ &lt;strong&gt;Sequence Packing&lt;/strong&gt; - Sequence packing in both DTensor and MCore for huge training perf gains&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🔜 &lt;strong&gt;Improved Native Performance&lt;/strong&gt; - Improve training time for Native Pytorch Models.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🔜 &lt;strong&gt;Megatron Inference&lt;/strong&gt; - (dynamic) Megatron Inference for fast day-0 support for new megatron models.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;Clone &lt;strong&gt;NeMo RL&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone git@github.com:NVIDIA-NeMo/RL.git nemo-rl
cd nemo-rl

# If you are using the Megatron backend, download the pinned versions of Megatron-LM and NeMo submodules 
# by running (This is not necessary if you are using the pure Pytorch/DTensor path):
git submodule update --init --recursive

# Different branches of the repo can have different pinned versions of these third-party submodules. Ensure
# submodules are automatically updated after switching branches or pulling updates by configuring git with:
# git config submodule.recurse true

# **NOTE**: this setting will not download **new** or remove **old** submodules with the branch's changes.
# You will have to run the full `git submodule update --init --recursive` command in these situations.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using the Megatron backend on bare-metal (outside of a container), you may need to install the cudnn headers as well. Here is how you can check as well as install them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Check if you have libcudnn installed
dpkg -l | grep cudnn.*cuda

# Find the version you need here: https://developer.nvidia.com/cudnn-downloads?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;Distribution=Ubuntu&amp;amp;target_version=20.04&amp;amp;target_type=deb_network
# As an example, these are the "Linux Ubuntu 20.04 x86_64" instructions
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get install cudnn-cuda-12
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For faster setup and environment isolation, we use &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;. Follow &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;these instructions&lt;/a&gt; to install uv.&lt;/p&gt; 
&lt;p&gt;Then, initialize NeMo RL project virtual environment via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv venv
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Please do not use &lt;code&gt;-p/--python&lt;/code&gt; and instead allow &lt;code&gt;uv venv&lt;/code&gt; to read it from &lt;code&gt;.python-version&lt;/code&gt;. This ensures that the version of python used is always what we prescribe.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If working outside a container, it can help to build &lt;a href="https://github.com/Dao-AILab/flash-attention"&gt;flash-attn&lt;/a&gt; and warm the uv cache before your first run.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;bash tools/build-flash-attn-in-uv-cache.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] On the first install, &lt;code&gt;flash-attn&lt;/code&gt; can take a while to install (~45min with 48 CPU hyperthreads). After it is built once, it is cached in your uv's cache dir making subsequent installs much quicker.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The NeMo RL Dockerfile will warm the uv cache with flash-attn. See &lt;a href="https://docs.nvidia.com/nemo/rl/latest/docker.html"&gt;https://docs.nvidia.com/nemo/rl/latest/docker.html&lt;/a&gt; for instructions if you are looking for the NeMo RL container.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If sucessful, you should see &lt;code&gt;✅ flash-attn successfully added to uv cache&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Use &lt;code&gt;uv run&lt;/code&gt; to launch all commands. It handles pip installing implicitly and ensures your environment is up to date with our lock file.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;It is not recommended to activate the &lt;code&gt;venv&lt;/code&gt;, and you should use &lt;code&gt;uv run &amp;lt;command&amp;gt;&lt;/code&gt; instead to execute scripts within the managed environment. This ensures consistent environment usage across different shells and sessions. Example: &lt;code&gt;uv run python examples/run_grpo_math.py&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Ensure you have the necessary CUDA drivers and PyTorch installed compatible with your hardware.&lt;/li&gt; 
  &lt;li&gt;If you update your environment in &lt;code&gt;pyproject.toml&lt;/code&gt;, it is necessary to force a rebuild of the virtual environments by setting &lt;code&gt;NRL_FORCE_REBUILD_VENVS=true&lt;/code&gt; next time you launch a run.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Reminder&lt;/strong&gt;: Don't forget to set your &lt;code&gt;HF_HOME&lt;/code&gt;, &lt;code&gt;WANDB_API_KEY&lt;/code&gt;, and &lt;code&gt;HF_DATASETS_CACHE&lt;/code&gt; (if needed). You'll need to do a &lt;code&gt;huggingface-cli login&lt;/code&gt; as well for Llama models.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Training Backends&lt;/h2&gt; 
&lt;p&gt;NeMo RL supports multiple training backends to accommodate different model sizes and hardware configurations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;DTensor (FSDP2)&lt;/strong&gt; - PyTorch's next-generation distributed training with improved memory efficiency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Megatron&lt;/strong&gt; - NVIDIA's high-performance training framework for scaling to large models (&amp;gt;100B parameters)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The training backend is automatically determined based on your YAML configuration settings. For detailed information on backend selection, configuration, and examples, see the &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/design-docs/training-backends.md"&gt;Training Backends documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;GRPO&lt;/h2&gt; 
&lt;p&gt;We have a reference GRPO experiment config set up trained for math benchmarks using the &lt;a href="https://huggingface.co/datasets/nvidia/OpenMathInstruct-2"&gt;OpenInstructMath2&lt;/a&gt; dataset.&lt;/p&gt; 
&lt;p&gt;You can read about the details of the GRPO implementation &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/guides/grpo.md"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;GRPO Single Node&lt;/h3&gt; 
&lt;p&gt;To run GRPO on a single GPU for &lt;code&gt;Qwen/Qwen2.5-1.5B&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run the GRPO math example using a 1B parameter model
uv run python examples/run_grpo_math.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, this uses the configuration in &lt;code&gt;examples/configs/grpo_math_1B.yaml&lt;/code&gt;. You can customize parameters with command-line overrides. For example, to run on 8 GPUs,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run the GRPO math example using a 1B parameter model using 8 GPUs
uv run python examples/run_grpo_math.py \
  cluster.gpus_per_node=8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can override any of the parameters listed in the yaml configuration file. For example,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_grpo_math.py \
  policy.model_name="meta-llama/Llama-3.2-1B-Instruct" \
  checkpointing.checkpoint_dir="results/llama1b_math" \
  logger.wandb_enabled=True \
  logger.wandb.name="grpo-llama1b_math" \
  logger.num_val_samples_to_print=10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The default configuration uses the DTensor training backend. We also provide a config &lt;code&gt;examples/configs/grpo_math_1B_megatron.yaml&lt;/code&gt; which is set up to use the Megatron backend out of the box.&lt;/p&gt; 
&lt;p&gt;To train using this config on a single GPU:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run a GRPO math example on 1 GPU using the Megatron backend
uv run python examples/run_grpo_math.py \
  --config examples/configs/grpo_math_1B_megatron.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For additional details on supported backends and how to configure the training backend to suit your setup, refer to the &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/design-docs/training-backends.md"&gt;Training Backends documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;GRPO Multi-node&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run from the root of NeMo RL repo
NUM_ACTOR_NODES=2

# grpo_math_8b uses Llama-3.1-8B-Instruct model
COMMAND="uv run ./examples/run_grpo_math.py --config examples/configs/grpo_math_8B.yaml cluster.num_nodes=2 checkpointing.checkpoint_dir='results/llama8b_2nodes' logger.wandb_enabled=True logger.wandb.name='grpo-llama8b_math'" \
CONTAINER=YOUR_CONTAINER \
MOUNTS="$PWD:$PWD" \
sbatch \
    --nodes=${NUM_ACTOR_NODES} \
    --account=YOUR_ACCOUNT \
    --job-name=YOUR_JOBNAME \
    --partition=YOUR_PARTITION \
    --time=4:0:0 \
    --gres=gpu:8 \
    ray.sub
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The required &lt;code&gt;CONTAINER&lt;/code&gt; can be built by following the instructions in the &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/docker.md"&gt;Docker documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;GRPO Qwen2.5-32B&lt;/h4&gt; 
&lt;p&gt;This section outlines how to run GRPO for Qwen2.5-32B with a 16k sequence length.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run from the root of NeMo RL repo
NUM_ACTOR_NODES=32

# Download Qwen before the job starts to avoid spending time downloading during the training loop
HF_HOME=/path/to/hf_home huggingface-cli download Qwen/Qwen2.5-32B

# Ensure HF_HOME is included in your MOUNTS
HF_HOME=/path/to/hf_home \
COMMAND="uv run ./examples/run_grpo_math.py --config examples/configs/grpo_math_8B.yaml policy.model_name='Qwen/Qwen2.5-32B' policy.generation.vllm_cfg.tensor_parallel_size=4 policy.max_total_sequence_length=16384 cluster.num_nodes=${NUM_ACTOR_NODES} policy.dtensor_cfg.enabled=True policy.dtensor_cfg.tensor_parallel_size=8 policy.dtensor_cfg.sequence_parallel=True policy.dtensor_cfg.activation_checkpointing=True checkpointing.checkpoint_dir='results/qwen2.5-32b' logger.wandb_enabled=True logger.wandb.name='qwen2.5-32b'" \
CONTAINER=YOUR_CONTAINER \
MOUNTS="$PWD:$PWD" \
sbatch \
    --nodes=${NUM_ACTOR_NODES} \
    --account=YOUR_ACCOUNT \
    --job-name=YOUR_JOBNAME \
    --partition=YOUR_PARTITION \
    --time=4:0:0 \
    --gres=gpu:8 \
    ray.sub
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;GRPO Multi-Turn&lt;/h4&gt; 
&lt;p&gt;We also support multi-turn generation and training (tool use, games, etc.). Reference example for training to play a Sliding Puzzle Game:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_grpo_sliding_puzzle.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supervised Fine-Tuning (SFT)&lt;/h2&gt; 
&lt;p&gt;We provide an example SFT experiment using the &lt;a href="https://rajpurkar.github.io/SQuAD-explorer/"&gt;SQuAD dataset&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SFT Single Node&lt;/h3&gt; 
&lt;p&gt;The default SFT configuration is set to run on a single GPU. To start the experiment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This fine-tunes the &lt;code&gt;Llama3.2-1B&lt;/code&gt; model on the SQuAD dataset using a 1 GPU.&lt;/p&gt; 
&lt;p&gt;To use multiple GPUs on a single node, you can modify the cluster configuration. This adjustment will also let you potentially increase the model and batch size:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_sft.py \
  policy.model_name="meta-llama/Meta-Llama-3-8B" \
  policy.train_global_batch_size=128 \
  sft.val_global_batch_size=128 \
  cluster.gpus_per_node=8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to &lt;code&gt;examples/configs/sft.yaml&lt;/code&gt; for a full list of parameters that can be overridden.&lt;/p&gt; 
&lt;h3&gt;SFT Multi-node&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run from the root of NeMo RL repo
NUM_ACTOR_NODES=2

COMMAND="uv run ./examples/run_sft.py --config examples/configs/sft.yaml cluster.num_nodes=2 cluster.gpus_per_node=8 checkpointing.checkpoint_dir='results/sft_llama8b_2nodes' logger.wandb_enabled=True logger.wandb.name='sft-llama8b'" \
CONTAINER=YOUR_CONTAINER \
MOUNTS="$PWD:$PWD" \
sbatch \
    --nodes=${NUM_ACTOR_NODES} \
    --account=YOUR_ACCOUNT \
    --job-name=YOUR_JOBNAME \
    --partition=YOUR_PARTITION \
    --time=4:0:0 \
    --gres=gpu:8 \
    ray.sub
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;DPO&lt;/h2&gt; 
&lt;p&gt;We provide a sample DPO experiment that uses the &lt;a href="https://huggingface.co/datasets/nvidia/HelpSteer3"&gt;HelpSteer3 dataset&lt;/a&gt; for preference-based training.&lt;/p&gt; 
&lt;h3&gt;DPO Single Node&lt;/h3&gt; 
&lt;p&gt;The default DPO experiment is configured to run on a single GPU. To launch the experiment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_dpo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This trains &lt;code&gt;Llama3.2-1B-Instruct&lt;/code&gt; on one GPU.&lt;/p&gt; 
&lt;p&gt;If you have access to more GPUs, you can update the experiment accordingly. To run on 8 GPUs, we update the cluster configuration and switch to an 8B Llama3.1 Instruct model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_dpo.py \
  policy.model_name="meta-llama/Llama-3.1-8B-Instruct" \
  policy.train_global_batch_size=256 \
  cluster.gpus_per_node=8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Any of the DPO parameters can be customized from the command line. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_dpo.py \
  dpo.sft_loss_weight=0.1 \
  dpo.preference_average_log_probs=True \
  checkpointing.checkpoint_dir="results/llama_dpo_sft" \
  logger.wandb_enabled=True \
  logger.wandb.name="llama-dpo-sft"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to &lt;code&gt;examples/configs/dpo.yaml&lt;/code&gt; for a full list of parameters that can be overridden. For an in-depth explanation of how to add your own DPO dataset, refer to the &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/guides/dpo.md"&gt;DPO documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;DPO Multi-node&lt;/h3&gt; 
&lt;p&gt;For distributed DPO training across multiple nodes, modify the following script for your use case:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run from the root of NeMo RL repo
## number of nodes to use for your job
NUM_ACTOR_NODES=2

COMMAND="uv run ./examples/run_dpo.py --config examples/configs/dpo.yaml cluster.num_nodes=2 cluster.gpus_per_node=8 dpo.val_global_batch_size=32 checkpointing.checkpoint_dir='results/dpo_llama81_2nodes' logger.wandb_enabled=True logger.wandb.name='dpo-llama1b'" \
CONTAINER=YOUR_CONTAINER \
MOUNTS="$PWD:$PWD" \
sbatch \
    --nodes=${NUM_ACTOR_NODES} \
    --account=YOUR_ACCOUNT \
    --job-name=YOUR_JOBNAME \
    --partition=YOUR_PARTITION \
    --time=4:0:0 \
    --gres=gpu:8 \
    ray.sub
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;RM&lt;/h2&gt; 
&lt;p&gt;We provide a sample RM experiment that uses the &lt;a href="https://huggingface.co/datasets/nvidia/HelpSteer3"&gt;HelpSteer3 dataset&lt;/a&gt; for preference-based training.&lt;/p&gt; 
&lt;h3&gt;RM Single Node&lt;/h3&gt; 
&lt;p&gt;The default RM experiment is configured to run on a single GPU. To launch the experiment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_rm.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This trains a RM based on &lt;code&gt;meta-llama/Llama-3.2-1B-Instruct&lt;/code&gt; on one GPU.&lt;/p&gt; 
&lt;p&gt;If you have access to more GPUs, you can update the experiment accordingly. To run on 8 GPUs, we update the cluster configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_rm.py cluster.gpus_per_node=8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to the &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/guides/rm.md"&gt;RM documentation&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;RM Multi-node&lt;/h3&gt; 
&lt;p&gt;For distributed RM training across multiple nodes, modify the following script for your use case:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run from the root of NeMo RL repo
## number of nodes to use for your job
NUM_ACTOR_NODES=2

COMMAND="uv run ./examples/run_rm.py --config examples/configs/rm.yaml cluster.num_nodes=2 cluster.gpus_per_node=8 checkpointing.checkpoint_dir='results/rm_llama1b_2nodes' logger.wandb_enabled=True logger.wandb.name='rm-llama1b-2nodes'" \
CONTAINER=YOUR_CONTAINER \
MOUNTS="$PWD:$PWD" \
sbatch \
    --nodes=${NUM_ACTOR_NODES} \
    --account=YOUR_ACCOUNT \
    --job-name=YOUR_JOBNAME \
    --partition=YOUR_PARTITION \
    --time=4:0:0 \
    --gres=gpu:8 \
    ray.sub
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Evaluation&lt;/h2&gt; 
&lt;p&gt;We provide evaluation tools to assess model capabilities.&lt;/p&gt; 
&lt;h3&gt;Convert Model Format (Optional)&lt;/h3&gt; 
&lt;p&gt;If you have trained a model and saved the checkpoint in the Pytorch DCP format, you first need to convert it to the Hugging Face format before running evaluation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Example for a GRPO checkpoint at step 170
uv run python examples/converters/convert_dcp_to_hf.py \
    --config results/grpo/step_170/config.yaml \
    --dcp-ckpt-path results/grpo/step_170/policy/weights/ \
    --hf-ckpt-path results/grpo/hf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you have a model saved in Megatron format, you can use the following command to convert it to Hugging Face format prior to running evaluation. This script requires mcore, so make sure to launch with the mcore extra:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Example for a GRPO checkpoint at step 170
uv run --extra mcore python examples/converters/convert_megatron_to_hf.py \
    --config results/grpo/step_170/config.yaml \
    --megatron-ckpt-path results/grpo/step_170/policy/weights/iter_0000000 \
    --hf-ckpt-path results/grpo/hf
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Adjust the paths according to your training output directory structure.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For an in-depth explanation of checkpointing, refer to the &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/design-docs/checkpointing.md"&gt;Checkpointing documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Run Evaluation&lt;/h3&gt; 
&lt;p&gt;Run evaluation script with converted model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run python examples/run_eval.py generation.model_name=$PWD/results/grpo/hf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run evaluation script with custom settings:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Example: Evaluation of DeepScaleR-1.5B-Preview on MATH-500 using 8 GPUs
#          Pass@1 accuracy averaged over 16 samples for each problem
uv run python examples/run_eval.py \
    --config examples/configs/evals/math_eval.yaml \
    generation.model_name=agentica-org/DeepScaleR-1.5B-Preview \
    generation.temperature=0.6 \
    generation.top_p=0.95 \
    generation.vllm_cfg.max_model_len=32768 \
    data.dataset_name=math500 \
    eval.num_tests_per_prompt=16 \
    cluster.gpus_per_node=8
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Evaluation results may vary slightly due to various factors, such as sampling parameters, random seed, inference engine version, and inference engine settings.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Refer to &lt;code&gt;examples/configs/evals/eval.yaml&lt;/code&gt; for a full list of parameters that can be overridden. For an in-depth explanation of evaluation, refer to the &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/guides/eval.md"&gt;Evaluation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Set Up Clusters&lt;/h2&gt; 
&lt;p&gt;For detailed instructions on how to set up and launch NeMo RL on Slurm or Kubernetes clusters, please refer to the dedicated &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/RL/main/docs/cluster.md"&gt;Cluster Start&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;Tips and Tricks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;If you forget to initialize the NeMo and Megatron submodules when cloning the NeMo-RL repository, you may run into an error like this:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;ModuleNotFoundError: No module named 'megatron'
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you see this error, there is likely an issue with your virtual environments. To fix this, first intialize the submodules:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and then force a rebuild of the virtual environments by setting &lt;code&gt;NRL_FORCE_REBUILD_VENVS=true&lt;/code&gt; next time you launch a run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;NRL_FORCE_REBUILD_VENVS=true uv run examples/run_grpo.py ...
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use NeMo RL in your research, please cite it using the following BibTeX entry:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{nemo-rl,
title = {NeMo RL: A Scalable and Efficient Post-Training Library},
howpublished = {\url{https://github.com/NVIDIA-NeMo/RL}},
year = {2025},
note = {GitHub repository},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to NeMo RL! Please see our &lt;a href="https://github.com/NVIDIA-NeMo/RL/raw/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt; for more information on how to get involved.&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;NVIDIA NeMo RL is licensed under the &lt;a href="https://github.com/NVIDIA-NeMo/RL/raw/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>puckeditor/puck</title>
      <link>https://github.com/puckeditor/puck</link>
      <description>&lt;p&gt;The visual editor for React&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://puckeditor.com?utm_source=readme&amp;amp;utm_medium=code&amp;amp;utm_campaign=repo&amp;amp;utm_contents=logo"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://res.cloudinary.com/die3nptcg/image/upload/Puck_Logo_White_RGB_j2rwgg.svg" height="100px" aria-label="Puck logo" /&gt; 
   &lt;img src="https://res.cloudinary.com/die3nptcg/image/upload/Puck_Logo_Black_RGB_dqsjag.svg?sanitize=true" height="100px" aria-label="Puck logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;em&gt;The visual editor for React&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://puckeditor.com/docs?utm_source=readme&amp;amp;utm_medium=code&amp;amp;utm_campaign=repo&amp;amp;utm_contents=docs_link"&gt;Documentation&lt;/a&gt; • &lt;a href="https://demo.puckeditor.com/edit?utm_source=readme&amp;amp;utm_medium=code&amp;amp;utm_campaign=repo&amp;amp;utm_contents=demo_link"&gt;Demo&lt;/a&gt; • &lt;a href="https://discord.gg/V9mDAhuxyZ"&gt;Discord&lt;/a&gt; • &lt;a href="https://github.com/puckeditor/puck/raw/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;⭐️ Enjoying Puck? Please &lt;a href="https://github.com/puckeditor/puck"&gt;leave a star&lt;/a&gt;!&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://demo.puckeditor.com/edit"&gt;&lt;img src="https://github.com/user-attachments/assets/25e1ae25-ca5e-450f-afa0-01816830b731" alt="GIF showing a page being created in the Puck Editor, with components being added, arranged, and customized in real time" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is Puck?&lt;/h2&gt; 
&lt;p&gt;Puck is a modular, open-source visual editor for React.js. You can use Puck to build custom drag-and-drop experiences with your own application and React components.&lt;/p&gt; 
&lt;p&gt;Because Puck is just a React component, it plays well with all React.js environments, including Next.js. You own your data and there’s no vendor lock-in.&lt;/p&gt; 
&lt;p&gt;Puck is also &lt;a href="https://github.com/puckeditor/puck?tab=MIT-1-ov-file#readme"&gt;licensed under MIT&lt;/a&gt;, making it suitable for both internal systems and commercial applications.&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;Install the package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm i @measured/puck --save # or npx create-puck-app my-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Render the editor:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsx"&gt;// Editor.jsx
import { Puck } from "@measured/puck";
import "@measured/puck/puck.css";

// Create Puck component config
const config = {
  components: {
    HeadingBlock: {
      fields: {
        children: {
          type: "text",
        },
      },
      render: ({ children }) =&amp;gt; {
        return &amp;lt;h1&amp;gt;{children}&amp;lt;/h1&amp;gt;;
      },
    },
  },
};

// Describe the initial data
const initialData = {};

// Save the data to your database
const save = (data) =&amp;gt; {};

// Render Puck editor
export function Editor() {
  return &amp;lt;Puck config={config} data={initialData} onPublish={save} /&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Render the page:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsx"&gt;// Page.jsx
import { Render } from "@measured/puck";
import "@measured/puck/puck.css";

export function Page() {
  return &amp;lt;Render config={config} data={data} /&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Recipes&lt;/h2&gt; 
&lt;p&gt;Use &lt;code&gt;create-puck-app&lt;/code&gt; to quickly spin up a a pre-configured app based on our provided &lt;a href="https://github.com/puckeditor/puck/tree/main/recipes"&gt;recipes&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npx create-puck-app my-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Available recipes include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/puckeditor/puck/tree/main/recipes/next"&gt;&lt;strong&gt;next&lt;/strong&gt;&lt;/a&gt;: Next.js example, using App Router and static page generation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/puckeditor/puck/tree/main/recipes/remix"&gt;&lt;strong&gt;remix&lt;/strong&gt;&lt;/a&gt;: Remix Run v2 example, using dynamic routes at root-level&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/puckeditor/puck/tree/main/recipes/react-router"&gt;&lt;strong&gt;react-router&lt;/strong&gt;&lt;/a&gt;: React Router v7 app example, using dynamic routes to create pages at any level&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/D9e4E3MQVZ"&gt;Discord server&lt;/a&gt; for discussions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/puckeditor/awesome-puck"&gt;awesome-puck&lt;/a&gt; community repo for plugins, custom fields &amp;amp; more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get support&lt;/h2&gt; 
&lt;p&gt;If you have any questions about Puck, please open a &lt;a href="https://github.com/puckeditor/puck/issues"&gt;GitHub issue&lt;/a&gt; or join us on &lt;a href="https://discord.gg/D9e4E3MQVZ"&gt;Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Or &lt;a href="https://app.cal.com/chrisvxd/puck-enquiry/"&gt;book a discovery call&lt;/a&gt; for hands-on support and consultancy.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT © &lt;a href="https://github.com/puckeditor/puck/graphs/contributors"&gt;The Puck Contributors&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pestphp/pest</title>
      <link>https://github.com/pestphp/pest</link>
      <description>&lt;p&gt;Pest is an elegant PHP testing Framework with a focus on simplicity, meticulously designed to bring back the joy of testing in PHP.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/pestphp/art/master/v4/social.png" width="600" alt="PEST" /&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://github.com/pestphp/pest/actions"&gt;&lt;img alt="GitHub Workflow Status (master)" src="https://img.shields.io/github/actions/workflow/status/pestphp/pest/tests.yml?branch=4.x&amp;amp;label=Tests%204.x" /&gt;&lt;/a&gt; &lt;a href="https://packagist.org/packages/pestphp/pest"&gt;&lt;img alt="Total Downloads" src="https://img.shields.io/packagist/dt/pestphp/pest" /&gt;&lt;/a&gt; &lt;a href="https://packagist.org/packages/pestphp/pest"&gt;&lt;img alt="Latest Version" src="https://img.shields.io/packagist/v/pestphp/pest" /&gt;&lt;/a&gt; &lt;a href="https://packagist.org/packages/pestphp/pest"&gt;&lt;img alt="License" src="https://img.shields.io/packagist/l/pestphp/pest" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Pest v4 Now Available: &lt;strong&gt;&lt;a href="https://pestphp.com/docs/pest-v4-is-here-now-with-browser-testing"&gt;Read the announcement »&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Pest&lt;/strong&gt; is an elegant PHP testing Framework with a focus on simplicity, meticulously designed to bring back the joy of testing in PHP.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Explore our docs at &lt;strong&gt;&lt;a href="https://pestphp.com"&gt;pestphp.com »&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Follow the creator Nuno Maduro: 
  &lt;ul&gt; 
   &lt;li&gt;YouTube: &lt;strong&gt;&lt;a href="https://www.youtube.com/@nunomaduro"&gt;youtube.com/@nunomaduro&lt;/a&gt;&lt;/strong&gt; — Videos every weekday&lt;/li&gt; 
   &lt;li&gt;Twitch: &lt;strong&gt;&lt;a href="https://www.twitch.tv/enunomaduro"&gt;twitch.tv/enunomaduro&lt;/a&gt;&lt;/strong&gt; — Streams (almost) every weekday&lt;/li&gt; 
   &lt;li&gt;Twitter / X: &lt;strong&gt;&lt;a href="https://x.com/enunomaduro"&gt;x.com/enunomaduro&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;LinkedIn: &lt;strong&gt;&lt;a href="https://www.linkedin.com/in/nunomaduro"&gt;linkedin.com/in/nunomaduro&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Instagram: &lt;strong&gt;&lt;a href="https://www.instagram.com/enunomaduro"&gt;instagram.com/enunomaduro&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Tiktok: &lt;strong&gt;&lt;a href="https://www.tiktok.com/@enunomaduro"&gt;tiktok.com/@enunomaduro&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;We cannot thank our sponsors enough for their incredible support in funding Pest's development. Their contributions have been instrumental in making Pest the best it can be. For those who are interested in becoming a sponsor, please visit Nuno Maduro's Sponsor page at &lt;strong&gt;&lt;a href="https://github.com/sponsors/nunomaduro"&gt;github.com/sponsors/nunomaduro&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Platinum Sponsors&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://laracasts.com/?ref=pestphp"&gt;Laracasts&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://coderabbit.ai/?ref=pestphp"&gt;CodeRabbit&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://nativephp.com/mobile?ref=pestphp.com"&gt;NativePHP&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://cmsmax.com/?ref=pestphp"&gt;CMS Max&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Premium Sponsors&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://akaunting.com/?ref=pestphp"&gt;Akaunting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.docuwriter.ai/?ref=pestphp"&gt;DocuWriter.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localazy.com/?ref=pestphp"&gt;Localazy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://forge.laravel.com/?ref=pestphp"&gt;Forge&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.route4me.com/?ref=pestphp"&gt;Route4Me&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spatie.be/?ref=pestphp"&gt;Spatie&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.worksome.com/?ref=pestphp"&gt;Worksome&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zapiet.com/?ref=pestphp"&gt;Zapiet&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Pest is an open-sourced software licensed under the &lt;strong&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;MIT license&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    ██████╗ ███████╗███████╗██████╗  ██████╗ ██████╗ ██████╗ ███████╗
    ██╔══██╗██╔════╝██╔════╝██╔══██╗██╔════╝██╔═══██╗██╔══██╗██╔════╝
    ██║  ██║█████╗  █████╗  ██████╔╝██║     ██║   ██║██║  ██║█████╗
    ██║  ██║██╔══╝  ██╔══╝  ██╔═══╝ ██║     ██║   ██║██║  ██║██╔══╝
    ██████╔╝███████╗███████╗██║     ╚██████╗╚██████╔╝██████╔╝███████╗
    ╚═════╝ ╚══════╝╚══════╝╚═╝      ╚═════╝ ╚═════╝ ╚═════╝ ╚══════╝&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/🐍Python-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/💬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/💬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;🖥️ &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;🖥️ &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;🚀 Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;⚡ Fast command-line workflow&lt;br /&gt;🔧 Developer-friendly interface&lt;br /&gt;📊 Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;🌐 &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;🎨 Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;🖱️ Intuitive drag-and-drop&lt;br /&gt;📱 Responsive design&lt;br /&gt;🎯 Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;🎬 &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;🎯 &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/▶️_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📑 Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;🚀 Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;🏗️ Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;🚀 Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;💡 Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;🎬 Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;⭐ Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;📄 License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;🚀 &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;🎨 &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;⚙️ &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h3&gt;🎯 &lt;strong&gt;Autonomous Multi-Agent Workflow&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;📄 &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🔬 &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;⏱️ &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🔄 &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["📄 Research Papers&amp;lt;br/&amp;gt;💬 Text Prompts&amp;lt;br/&amp;gt;🌐 URLs &amp;amp; Document&amp;lt;br/&amp;gt;📎 Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["🧠 DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["🚀 Algorithm Implementation &amp;lt;br/&amp;gt;🎨 Frontend Development &amp;lt;br/&amp;gt;⚙️ Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏗️ Architecture&lt;/h2&gt; 
&lt;h3&gt;📊 &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;🎯 &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;🧬 &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;🪄 &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;⚡ &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;💎 &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;🔮 &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🔧 &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;🧠 &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;💾 &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🔍 &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🤖 &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🎯 Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;📝 Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;📄 Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🏗️ Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔍 Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;📚 Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🧬 Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;🛠️ &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;🔧 Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;📡 &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;🛠️ &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;🔧 &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;💡 &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🔍 brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🌐 bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📂 filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🌐 fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📥 github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📋 file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;⚡ command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🧬 code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📚 code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📄 document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;🔧 &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;🛠️ &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;🎯 &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📄 read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;✍️ write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🐍 execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📁 get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;⚙️ set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📊 get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;🎛️ &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🚀 Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;🌟 &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; 💡 &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; 📄 Research Papers • 💬 Natural Language • 🌐 URLs • 📋 Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; 🎯 &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making • Workflow Coordination • Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; 📝 &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; 📄 &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; 📋 &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis • Code Requirements Parsing • Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; 🔍 &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; 📚 &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; 🧬 &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation • Testing • Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ⚡ &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; 📦 Complete Codebase • 🧪 Test Suite • 📚 Documentation • 🚀 Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;🔄 &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;🎯 Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;🧠 Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;🔍 Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;⚡ Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;h3&gt;📦 &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;⚡ &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 🚀 Install DeepCode package directly
pip install deepcode-hku

# 🔑 Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# 🔑 Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# 🔑 Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# 📄 Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;🔧 &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📂 Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;🔥 &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 🔽 Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# 📦 Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# 🔧 Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# 🔑 Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# 🔑 Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# 📄 Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;🐍 &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 🔽 Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# 📦 Install dependencies
pip install -r requirements.txt

# 🔑 Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# 🔑 Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# 📄 Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;🪟 &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;🔍 &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔍 Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🌐 Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;💡 Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;⚡ &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;🚀 &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 🌐 Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;🛠️ &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;🌐 &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;🖥️ &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;🎯 &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;📄 Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🤖 Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;⚡ Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;💡 Examples&lt;/h2&gt; 
&lt;h3&gt;🎬 &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;📄 &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;▶️ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;🖼️ &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;▶️ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;🌐 &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;▶️ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;🆕 &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;📄 &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🚀 &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;🔧 &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📊 &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;⚡ &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;⭐ Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🚀 &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/🚀_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/🏛️_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/⭐_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;📄 &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
 &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>winapps-org/winapps</title>
      <link>https://github.com/winapps-org/winapps</link>
      <description>&lt;p&gt;Run Windows apps such as Microsoft Office/Adobe in Linux (Ubuntu/Fedora) and GNOME/KDE as if they were a part of the native OS, including Nautilus integration. Hard fork of https://github.com/Fmstrat/winapps/&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img align="center" width="700" src="https://raw.githubusercontent.com/winapps-org/winapps/main/icons/banner_dark.svg#gh-dark-mode-only" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img align="center" width="700" src="https://raw.githubusercontent.com/winapps-org/winapps/main/icons/banner_light.svg#gh-light-mode-only" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Run Windows applications (including &lt;a href="https://www.microsoft365.com/"&gt;Microsoft 365&lt;/a&gt; and &lt;a href="https://www.adobe.com/creativecloud.html"&gt;Adobe Creative Cloud&lt;/a&gt;) on GNU/Linux with &lt;code&gt;KDE Plasma&lt;/code&gt;, &lt;code&gt;GNOME&lt;/code&gt; or &lt;code&gt;XFCE&lt;/code&gt;, integrated seamlessly as if they were native to the OS.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/demo/demo.png" width="1000" alt="WinApps Demonstration." /&gt;&lt;/p&gt; 
&lt;h2&gt;Underlying Mechanism&lt;/h2&gt; 
&lt;p&gt;WinApps works by:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Running Windows in a &lt;code&gt;Docker&lt;/code&gt;, &lt;code&gt;Podman&lt;/code&gt; or &lt;code&gt;libvirt&lt;/code&gt; virtual machine.&lt;/li&gt; 
 &lt;li&gt;Querying Windows for all installed applications.&lt;/li&gt; 
 &lt;li&gt;Creating shortcuts to selected Windows applications on the host GNU/Linux OS.&lt;/li&gt; 
 &lt;li&gt;Using &lt;a href="https://www.freerdp.com/"&gt;&lt;code&gt;FreeRDP&lt;/code&gt;&lt;/a&gt; as a backend to seamlessly render Windows applications alongside GNU/Linux applications.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The GNU/Linux &lt;code&gt;/home&lt;/code&gt; directory is accessible within Windows via the &lt;code&gt;\\tsclient\home&lt;/code&gt; mount.&lt;/li&gt; 
 &lt;li&gt;Integration with &lt;code&gt;Nautilus&lt;/code&gt;, allowing you to right-click files to open them with specific Windows applications based on the file MIME type.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://github.com/winapps-org/WinApps-Launcher"&gt;official taskbar widget&lt;/a&gt; enables seamless administration of the Windows subsystem and offers an easy way to launch Windows applications.&lt;/li&gt; 
 &lt;li&gt;Microsoft Office links (e.g. ms-word://) from the host system are automatically opened in the Windows subsystem. (Note: You may need to use a &lt;a href="https://github.com/ray-lothian/UserAgent-Switcher/"&gt;User Agent Switcher&lt;/a&gt; browser extension and set the User-Agent to Windows, as the Office webapps typically hide the "Open in Desktop App" option for Linux users.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Applications&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;WinApps supports &lt;u&gt;&lt;em&gt;ALL&lt;/em&gt;&lt;/u&gt; Windows applications.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Universal application support is achieved by:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Scanning Windows for any officially supported applications (list below).&lt;/li&gt; 
 &lt;li&gt;Scanning Windows for any other &lt;code&gt;.exe&lt;/code&gt; files listed within the Windows Registry.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Officially supported applications benefit from high-resolution icons and pre-populated MIME types. This enables file managers to determine which Windows applications should open files based on file extensions. Icons for other detected applications are pulled from &lt;code&gt;.exe&lt;/code&gt; files.&lt;/p&gt; 
&lt;p&gt;Contributing to the list of supported applications is encouraged through submission of pull requests! Please help us grow the WinApps community.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Please note that the provided list of officially supported applications is community-driven. As such, some applications may not be tested and verified by the WinApps team.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Officially Supported Applications&lt;/h3&gt; 
&lt;table cellpadding="10" cellspacing="0" border="0"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;!-- Adobe Acrobat Pro --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/acrobat-x-pro/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Adobe Acrobat Pro&lt;/b&gt;&lt;br /&gt; (X)&lt;br /&gt; &lt;i&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Adobe_Acrobat_DC_logo_2020.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Adobe After Effects --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/aftereffects-cc/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Adobe After Effects&lt;/b&gt;&lt;br /&gt; (CC)&lt;br /&gt; &lt;i&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Adobe_After_Effects_CC_icon.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Adobe Audition --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/audition-cc/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Adobe Audition&lt;/b&gt;&lt;br /&gt; (CC)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Adobe_Audition_CC_icon_%282020%29.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Adobe Bridge --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/bridge-cs6/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Adobe Bridge&lt;/b&gt;&lt;br /&gt; (CS6, CC)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Adobe_Bridge_CC_icon.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Adobe Creative Cloud --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/adobe-cc/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Adobe Creative Cloud&lt;/b&gt;&lt;br /&gt; (CC)&lt;br /&gt; &lt;i&gt;&lt;a href="https://iconduck.com/icons/240218/adobe-creative-cloud"&gt;Icon&lt;/a&gt; under &lt;a href="https://iconduck.com/licenses/mit"&gt;MIT license&lt;/a&gt;.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Adobe Illustrator --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/illustrator-cc/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Adobe Illustrator&lt;/b&gt;&lt;br /&gt; (CC)&lt;br /&gt; &lt;i&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Adobe_Illustrator_CC_icon.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Adobe InDesign --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/indesign-cc/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Adobe InDesign&lt;/b&gt;&lt;br /&gt; (CC)&lt;br /&gt; &lt;i&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Adobe_InDesign_CC_icon.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Adobe Lightroom --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/lightroom-cc/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Adobe Lightroom&lt;/b&gt;&lt;br /&gt; (CC)&lt;br /&gt; &lt;i&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Adobe_Photoshop_Lightroom_CC_logo.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Adobe Photoshop --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/photoshop-cc/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Adobe Photoshop&lt;/b&gt;&lt;br /&gt; (CS6, CC, 2022)&lt;br /&gt; &lt;i&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Adobe_Photoshop_CC_icon.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Command Prompt --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/cmd/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Command Prompt&lt;/b&gt;&lt;br /&gt; (cmd.exe)&lt;br /&gt; &lt;i&gt;&lt;a href="https://github.com/microsoft/terminal/raw/main/res/terminal/Terminal.svg"&gt;Icon&lt;/a&gt; under &lt;a href="https://github.com/microsoft/terminal/raw/main/LICENSE"&gt;MIT license&lt;/a&gt;.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- File Explorer --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/explorer/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;File Explorer&lt;/b&gt;&lt;br /&gt; (Windows Explorer)&lt;br /&gt; &lt;i&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Windows_Explorer.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Internet Explorer --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/iexplorer/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Internet Explorer&lt;/b&gt;&lt;br /&gt; (11)&lt;br /&gt; &lt;i&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Internet_Explorer_10%2B11_logo.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Microsoft Access --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/access/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft Access&lt;/b&gt;&lt;br /&gt; (2016, 2019, o365)&lt;br /&gt; &lt;i&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Microsoft_Office_Access_(2019-present).svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Microsoft Excel --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/excel/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft Excel&lt;/b&gt;&lt;br /&gt; (2016, 2019, o365)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Microsoft_Office_Excel_(2019%E2%80%93present).svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Microsoft Word --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/word/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft Word&lt;/b&gt;&lt;br /&gt; (2016, 2019, o365)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Microsoft_Office_Word_(2019%E2%80%93present).svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Microsoft OneNote --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/onenote/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft OneNote&lt;/b&gt;&lt;br /&gt; (2016, 2019, o365)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Microsoft_Office_OneNote_(2019%E2%80%93present).svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Microsoft Outlook --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/outlook/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft Outlook&lt;/b&gt;&lt;br /&gt; (2016, 2019, o365)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Microsoft_Office_Outlook_(2018%E2%80%93present).svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Microsoft PowerPoint --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/powerpoint/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft PowerPoint&lt;/b&gt;&lt;br /&gt; (2016, 2019, o365)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Microsoft_Office_PowerPoint_(2019%E2%80%93present).svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Microsoft Publisher --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/publisher/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft Publisher&lt;/b&gt;&lt;br /&gt; (2016, 2019, o365)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Microsoft_Office_Publisher_(2019-present).svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Microsoft Visio --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/visio/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft Visio&lt;/b&gt;&lt;br /&gt; (Standard/Pro. 2021, Plan 2)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Microsoft_Office_Visio_(2019).svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Microsoft Project --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/project/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft Project&lt;/b&gt;&lt;br /&gt; (Standard/Pro. 2021, Plan 3/5)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Microsoft_Project_(2019–present).svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- Microsoft Visual Studio --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/visual-studio-pro/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Microsoft Visual Studio&lt;/b&gt;&lt;br /&gt; (Comm./Pro./Ent. 2022)&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.m.wikipedia.org/wiki/File:Visual_Studio_Icon_2022.svg"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- mIRC --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/mirc/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;mIRC&lt;/b&gt;&lt;br /&gt; &lt;i&gt;&lt;a href="https://en.wikipedia.org/wiki/MIRC#/media/File:Mircnewlogo.png"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
   &lt;!-- PowerShell --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/apps/powershell/icon.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;PowerShell&lt;/b&gt;&lt;br /&gt; &lt;i&gt;&lt;a href="https://iconduck.com/icons/102322/file-type-powershell"&gt;Icon&lt;/a&gt; under &lt;a href="https://iconduck.com/licenses/mit"&gt;MIT license&lt;/a&gt;.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;!-- Windows --&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/icons/windows.svg?sanitize=true" width="100" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;b&gt;Windows&lt;/b&gt;&lt;br /&gt; (Full RDP Session)&lt;br /&gt; &lt;i&gt;&lt;a href="https://raw.githubusercontent.com/winapps-org/winapps/main/url"&gt;Icon&lt;/a&gt; in the Public Domain.&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Step 1: Configure a Windows VM&lt;/h3&gt; 
&lt;p&gt;Both &lt;code&gt;Docker&lt;/code&gt; and &lt;code&gt;Podman&lt;/code&gt; are recommended backends for running the Windows virtual machine, as they facilitate an automated Windows installation process. WinApps is also compatible with &lt;code&gt;libvirt&lt;/code&gt;. While this method requires considerably more manual configuration, it also provides greater virtual machine customisation options. All three methods leverage the &lt;code&gt;KVM&lt;/code&gt; hypervisor, ensuring excellent virtual machine performance. Ultimately, the choice of backend depends on your specific use case.&lt;/p&gt; 
&lt;p&gt;The following guides are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/winapps-org/winapps/main/docs/docker.md"&gt;Creating a Windows VM with &lt;code&gt;Docker&lt;/code&gt; or &lt;code&gt;Podman&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/winapps-org/winapps/main/docs/libvirt.md"&gt;Creating a Windows VM with &lt;code&gt;libvirt&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you already have a Windows VM or server you wish to use with WinApps, you will still have to follow the &lt;a href="https://raw.githubusercontent.com/winapps-org/winapps/main/docs/libvirt.md#final-configuration-steps"&gt;final steps described in the &lt;code&gt;libvirt&lt;/code&gt; documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Step 2: Install Dependencies&lt;/h3&gt; 
&lt;p&gt;Install the required dependencies.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Debian/Ubuntu: &lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt install -y curl dialog freerdp3-x11 git iproute2 libnotify-bin netcat-openbsd
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] On Debian 12 (&lt;em&gt;"bookworm"&lt;/em&gt;), you need to enable the &lt;code&gt;backports&lt;/code&gt; repository for the &lt;code&gt;freerdp3-x11&lt;/code&gt; package to become available. For instructions, see &lt;a href="https://backports.debian.org/Instructions"&gt;https://backports.debian.org/Instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fedora/RHEL: &lt;pre&gt;&lt;code class="language-bash"&gt;sudo dnf install -y curl dialog freerdp git iproute libnotify nmap-ncat
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Arch Linux: &lt;pre&gt;&lt;code class="language-bash"&gt;sudo pacman -Syu --needed -y curl dialog freerdp git iproute2 libnotify openbsd-netcat
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;OpenSUSE: &lt;pre&gt;&lt;code class="language-bash"&gt;sudo zypper install -y curl dialog freerdp git iproute2 libnotify-tools netcat-openbsd
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Gentoo Linux: &lt;pre&gt;&lt;code class="language-bash"&gt;sudo emerge --ask=n net-misc/curl dev-util/dialog net-misc/freerdp:3 dev-vcs/git sys-apps/iproute2 x11-libs/libnotify net-analyzer/openbsd-netcat
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] WinApps requires &lt;code&gt;FreeRDP&lt;/code&gt; version 3 or later. If not available for your distribution through your package manager, you can install the &lt;a href="https://flathub.org/apps/com.freerdp.FreeRDP"&gt;Flatpak&lt;/a&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;flatpak install flathub com.freerdp.FreeRDP
sudo flatpak override --filesystem=home com.freerdp.FreeRDP # To use `+home-drive`
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;However, if you have weird issues like &lt;a href="https://github.com/winapps-org/winapps/issues/233"&gt;#233&lt;/a&gt; when running Flatpak, please compile FreeRDP from source according to &lt;a href="https://github.com/FreeRDP/FreeRDP/wiki/Compilation"&gt;this guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Step 3: Create a WinApps Configuration File&lt;/h3&gt; 
&lt;p&gt;Create a configuration file at &lt;code&gt;~/.config/winapps/winapps.conf&lt;/code&gt; containing the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;##################################
#   WINAPPS CONFIGURATION FILE   #
##################################

# INSTRUCTIONS
# - Leading and trailing whitespace are ignored.
# - Empty lines are ignored.
# - Lines starting with '#' are ignored.
# - All characters following a '#' are ignored.

# [WINDOWS USERNAME]
RDP_USER="MyWindowsUser"

# [WINDOWS PASSWORD]
# NOTES:
# - If using FreeRDP v3.9.0 or greater, you *have* to set a password
RDP_PASS="MyWindowsPassword"

# [WINDOWS DOMAIN]
# DEFAULT VALUE: '' (BLANK)
RDP_DOMAIN=""

# [WINDOWS IPV4 ADDRESS]
# NOTES:
# - If using 'libvirt', 'RDP_IP' will be determined by WinApps at runtime if left unspecified.
# DEFAULT VALUE:
# - 'docker': '127.0.0.1'
# - 'podman': '127.0.0.1'
# - 'libvirt': '' (BLANK)
RDP_IP="127.0.0.1"

# [VM NAME]
# NOTES:
# - Only applicable when using 'libvirt'
# - The libvirt VM name must match so that WinApps can determine VM IP, start the VM, etc.
# DEFAULT VALUE: 'RDPWindows'
VM_NAME="RDPWindows"

# [WINAPPS BACKEND]
# DEFAULT VALUE: 'docker'
# VALID VALUES:
# - 'docker'
# - 'podman'
# - 'libvirt'
# - 'manual'
WAFLAVOR="docker"

# [DISPLAY SCALING FACTOR]
# NOTES:
# - If an unsupported value is specified, a warning will be displayed.
# - If an unsupported value is specified, WinApps will use the closest supported value.
# DEFAULT VALUE: '100'
# VALID VALUES:
# - '100'
# - '140'
# - '180'
RDP_SCALE="100"

# [MOUNTING REMOVABLE PATHS FOR FILES]
# NOTES:
# - By default, `udisks` (which you most likely have installed) uses /run/media for mounting removable devices.
#   This improves compatibility with most desktop environments (DEs).
# ATTENTION: The Filesystem Hierarchy Standard (FHS) recommends /media instead. Verify your system's configuration.
# - To manually mount devices, you may optionally use /mnt.
# REFERENCE: https://wiki.archlinux.org/title/Udisks#Mount_to_/media
REMOVABLE_MEDIA="/run/media"

# [ADDITIONAL FREERDP FLAGS &amp;amp; ARGUMENTS]
# NOTES:
# - You can try adding /network:lan to these flags in order to increase performance, however, some users have faced issues with this.
# DEFAULT VALUE: '/cert:tofu /sound /microphone +home-drive'
# VALID VALUES: See https://github.com/awakecoding/FreeRDP-Manuals/blob/master/User/FreeRDP-User-Manual.markdown
RDP_FLAGS="/cert:tofu /sound /microphone +home-drive"

# [DEBUG WINAPPS]
# NOTES:
# - Creates and appends to ~/.local/share/winapps/winapps.log when running WinApps.
# DEFAULT VALUE: 'true'
# VALID VALUES:
# - 'true'
# - 'false'
DEBUG="true"

# [AUTOMATICALLY PAUSE WINDOWS]
# NOTES:
# - This is currently INCOMPATIBLE with 'docker' and 'manual'.
# - See https://github.com/dockur/windows/issues/674
# DEFAULT VALUE: 'off'
# VALID VALUES:
# - 'on'
# - 'off'
AUTOPAUSE="off"

# [AUTOMATICALLY PAUSE WINDOWS TIMEOUT]
# NOTES:
# - This setting determines the duration of inactivity to tolerate before Windows is automatically paused.
# - This setting is ignored if 'AUTOPAUSE' is set to 'off'.
# - The value must be specified in seconds (to the nearest 10 seconds e.g., '30', '40', '50', etc.).
# - For RemoteApp RDP sessions, there is a mandatory 20-second delay, so the minimum value that can be specified here is '20'.
# - Source: https://techcommunity.microsoft.com/t5/security-compliance-and-identity/terminal-services-remoteapp-8482-session-termination-logic/ba-p/246566
# DEFAULT VALUE: '300'
# VALID VALUES: &amp;gt;=20
AUTOPAUSE_TIME="300"

# [FREERDP COMMAND]
# NOTES:
# - WinApps will attempt to automatically detect the correct command to use for your system.
# DEFAULT VALUE: '' (BLANK)
# VALID VALUES: The command required to run FreeRDPv3 on your system (e.g., 'xfreerdp', 'xfreerdp3', etc.).
FREERDP_COMMAND=""

# [TIMEOUTS]
# NOTES:
# - These settings control various timeout durations within the WinApps setup.
# - Increasing the timeouts is only necessary if the corresponding errors occur.
# - Ensure you have followed all the Troubleshooting Tips in the error message first.

# PORT CHECK
# - The maximum time (in seconds) to wait when checking if the RDP port on Windows is open.
# - Corresponding error: "NETWORK CONFIGURATION ERROR" (exit status 13).
# DEFAULT VALUE: '5'
PORT_TIMEOUT="5"

# RDP CONNECTION TEST
# - The maximum time (in seconds) to wait when testing the initial RDP connection to Windows.
# - Corresponding error: "REMOTE DESKTOP PROTOCOL FAILURE" (exit status 14).
# DEFAULT VALUE: '30'
RDP_TIMEOUT="30"

# APPLICATION SCAN
# - The maximum time (in seconds) to wait for the script that scans for installed applications on Windows to complete.
# - Corresponding error: "APPLICATION QUERY FAILURE" (exit status 15).
# DEFAULT VALUE: '60'
APP_SCAN_TIMEOUT="60"

# WINDOWS BOOT
# - The maximum time (in seconds) to wait for the Windows VM to boot if it is not running, before attempting to launch an application.
# DEFAULT VALUE: '120'
BOOT_TIMEOUT="120"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] To safeguard your Windows password, ensure &lt;code&gt;~/.config/winapps/winapps.conf&lt;/code&gt; is accessible only by your user account.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;chown $(whoami):$(whoami) ~/.config/winapps/winapps.conf
chmod 600 ~/.config/winapps/winapps.conf
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;code&gt;RDP_USER&lt;/code&gt; and &lt;code&gt;RDP_PASS&lt;/code&gt; must correspond to a complete Windows user account and password, such as those created during Windows setup or for a domain user. User/PIN combinations are not valid for RDP access.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you wish to use an alternative WinApps backend (other than &lt;code&gt;Docker&lt;/code&gt;), uncomment and change &lt;code&gt;WAFLAVOR="docker"&lt;/code&gt; to &lt;code&gt;WAFLAVOR="podman"&lt;/code&gt; or &lt;code&gt;WAFLAVOR="libvirt"&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Configuration Options Explained&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;If using a pre-existing Windows RDP server on your LAN, you must use &lt;code&gt;RDP_IP&lt;/code&gt; to specify the location of the Windows server. You may also wish to configure a static IP address for this server.&lt;/li&gt; 
 &lt;li&gt;If running a Windows VM using &lt;code&gt;libvirt&lt;/code&gt; with NAT enabled, leave &lt;code&gt;RDP_IP&lt;/code&gt; commented out and WinApps will auto-detect the local IP address for the VM.&lt;/li&gt; 
 &lt;li&gt;For domain users, you can uncomment and change &lt;code&gt;RDP_DOMAIN&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;On high-resolution (UHD) displays, you can set &lt;code&gt;RDP_SCALE&lt;/code&gt; to the scale you would like to use (100, 140 or 180).&lt;/li&gt; 
 &lt;li&gt;To add additional flags to the FreeRDP call (e.g. &lt;code&gt;/prevent-session-lock 120&lt;/code&gt;), uncomment and use the &lt;code&gt;RDP_FLAGS&lt;/code&gt; configuration option.&lt;/li&gt; 
 &lt;li&gt;For multi-monitor setups, you can try adding &lt;code&gt;/multimon&lt;/code&gt; to &lt;code&gt;RDP_FLAGS&lt;/code&gt;. A FreeRDP bug may result in a black screen however, in which case you should revert this change.&lt;/li&gt; 
 &lt;li&gt;To enable non-English input and seamless language switching, you can try adding &lt;code&gt;/kbd:unicode&lt;/code&gt; to &lt;code&gt;RDP_FLAGS&lt;/code&gt;. This ensures client inputs are sent as Unicode sequences.&lt;/li&gt; 
 &lt;li&gt;If you enable &lt;code&gt;DEBUG&lt;/code&gt;, a log will be created on each application start in &lt;code&gt;~/.local/share/winapps/winapps.log&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;If using a system on which the FreeRDP command is not &lt;code&gt;xfreerdp&lt;/code&gt; or &lt;code&gt;xfreerdp3&lt;/code&gt;, the correct command can be specified using &lt;code&gt;FREERDP_COMMAND&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 4: Test FreeRDP&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Test establishing an RDP session by running the following command, replacing the &lt;code&gt;/u:&lt;/code&gt;, &lt;code&gt;/p:&lt;/code&gt;, and &lt;code&gt;/v:&lt;/code&gt; values with the correct values specified in &lt;code&gt;~/.config/winapps/winapps.conf&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;xfreerdp3 /u:"Your Windows Username" /p:"Your Windows Password" /v:192.168.122.2 /cert:tofu

# Or, if you installed FreeRDP using Flatpak
flatpak run --command=xfreerdp com.freerdp.FreeRDP /u:"Your Windows Username" /p:"Your Windows Password" /v:192.168.122.2 /cert:tofu
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Please note that the correct &lt;code&gt;FreeRDP&lt;/code&gt; command may vary depending on your system (e.g. &lt;code&gt;xfreerdp&lt;/code&gt;, &lt;code&gt;xfreerdp3&lt;/code&gt;, etc.).&lt;/li&gt; 
   &lt;li&gt;Ensure you use the correct IP address for your Windows instance in the above command.&lt;/li&gt; 
   &lt;li&gt;If prompted within the terminal window, choose to accept the certificate permanently.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;If the Windows desktop appears in a &lt;code&gt;FreeRDP&lt;/code&gt; window, the configuration was successful and the correct RDP TLS certificate was enrolled on the Linux host. Disconnect from the RDP session and skip the following debugging step.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[DEBUGGING STEP] If an outdated or expired certificate is detected, the &lt;code&gt;FreeRDP&lt;/code&gt; command will display output resembling the following. In this case, the old certificate will need to be removed and a new RDP TLS certificate installed.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@           WARNING: CERTIFICATE NAME MISMATCH!           @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

The hostname used for this connection (192.168.122.2:3389)
does not match the name given in the certificate:
Common Name (CN):
        RDPWindows
A valid certificate for the wrong name should NOT be trusted!

The host key for 192.168.122.2:3389 has changed

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle attack)!
It is also possible that a host key has just been changed.
The fingerprint for the host key sent by the remote host is 8e:b4:d2:8e:4e:14:e7:4e:82:9b:07:5b:e1:68:40:18:bc:db:5f:bc:29:0d:91:83:f9:17:f9:13:e6:51:dc:36
Please contact your system administrator.
Add correct host key in /home/rohanbarar/.config/freerdp/server/192.168.122.2_3389.pem to get rid of this message.
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you experience the above error, delete any old or outdated RDP TLS certificates associated with Windows, as they can prevent &lt;code&gt;FreeRDP&lt;/code&gt; from establishing a connection.&lt;/p&gt; &lt;p&gt;These certificates are located within &lt;code&gt;~/.config/freerdp/server/&lt;/code&gt; and follow the naming format &lt;code&gt;&amp;lt;Windows-VM-IPv4-Address&amp;gt;_&amp;lt;RDP-Port&amp;gt;.pem&lt;/code&gt; (e.g., &lt;code&gt;192.168.122.2_3389.pem&lt;/code&gt;, &lt;code&gt;127.0.0.1_3389.pem&lt;/code&gt;, etc.).&lt;/p&gt; &lt;p&gt;If you use FreeRDP for purposes other than WinApps, ensure you only remove certificates related to the relevant Windows VM. If no relevant certificates are found, no action is needed.&lt;/p&gt; &lt;p&gt;Following deletion, re-attempt establishing an RDP session.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Step 5: Run the WinApps Installer&lt;/h3&gt; 
&lt;p&gt;With Windows still powered on, run the WinApps installer.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash &amp;lt;(curl https://raw.githubusercontent.com/winapps-org/winapps/main/setup.sh)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once WinApps is installed, a list of additional arguments can be accessed by running &lt;code&gt;winapps-setup --help&lt;/code&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/demo/installer.gif" width="1000" alt="WinApps Installer Animation." /&gt; 
&lt;h2&gt;Adding Additional Pre-defined Applications&lt;/h2&gt; 
&lt;p&gt;Adding your own applications with custom icons and MIME types to the installer is easy. Simply copy one of the application configurations in the &lt;code&gt;apps&lt;/code&gt; folder located within the WinApps repository, and:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify the name and variables to reflect the appropriate/desired values for your application.&lt;/li&gt; 
 &lt;li&gt;Replace &lt;code&gt;icon.svg&lt;/code&gt; with an SVG for your application (ensuring the icon is appropriately licensed).&lt;/li&gt; 
 &lt;li&gt;Remove and reinstall WinApps.&lt;/li&gt; 
 &lt;li&gt;Submit a pull request to add your application to WinApps as an officially supported application once you have tested and verified your configuration (optional, but encouraged).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Running Applications Manually&lt;/h2&gt; 
&lt;p&gt;WinApps offers a manual mode for running applications that were not configured by the WinApps installer. This is completed with the &lt;code&gt;manual&lt;/code&gt; flag. Executables that are in the Windows PATH do not require full path definition.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;winapps manual "C:\my\directory\executableNotInPath.exe"
winapps manual executableInPath.exe
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Updating WinApps&lt;/h2&gt; 
&lt;p&gt;The installer can be run multiple times. To update your installation of WinApps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run the WinApps installer to remove WinApps from your system.&lt;/li&gt; 
 &lt;li&gt;Pull the latest changes from the WinApps GitHub repository.&lt;/li&gt; 
 &lt;li&gt;Re-install WinApps using the WinApps installer by running &lt;code&gt;winapps-setup&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;WinApps Launcher (Optional)&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://github.com/winapps-org/winapps-launcher"&gt;WinApps Launcher&lt;/a&gt; provides a simple system tray menu that makes it easy to launch your installed Windows applications, open a full desktop RDP session, and control your Windows VM or container. You can start, stop, pause, reboot or hibernate Windows, as well as access your installed applications from a convenient list. This lightweight, optional tool helps streamline your overall WinApps experience.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/winapps-org/winapps/main/demo/launcher.gif" width="1000" alt="WinApps Launcher Animation." /&gt; 
&lt;h2&gt;Installation using Nix&lt;/h2&gt; 
&lt;p&gt;First, follow Step 1 of the normal installation guide to create your VM. Then, install WinApps according to the following instructions.&lt;/p&gt; 
&lt;p&gt;After installation, it will be available under &lt;code&gt;winapps&lt;/code&gt;, with the installer being available under &lt;code&gt;winapps-setup&lt;/code&gt; and the optional launcher being available under &lt;code&gt;winapps-launcher.&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Using standalone Nix&lt;/h3&gt; 
&lt;p&gt;First, make sure Flakes and the &lt;code&gt;nix&lt;/code&gt; command are enabled. In your &lt;code&gt;~/.config/nix/nix.conf&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;experimental-features = nix-command flakes
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nix profile install github:winapps-org/winapps#winapps
nix profile install github:winapps-org/winapps#winapps-launcher # optional
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On NixOS using Flakes&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;# flake.nix
{
  description = "My configuration";

  inputs = {
    nixpkgs.url = "github:NixOS/nixpkgs/nixos-unstable";

    winapps = {
      url = "github:winapps-org/winapps";
      inputs.nixpkgs.follows = "nixpkgs";
    };
  };

  outputs =
    inputs@{
      nixpkgs,
      winapps,
      ...
    }:
    {
      nixosConfigurations.hostname = nixpkgs.lib.nixosSystem rec {
        system = "x86_64-linux";

        specialArgs = {
          inherit inputs system;
        };

        modules = [
          ./configuration.nix
          (
            {
              pkgs,
              system ? pkgs.system,
              ...
            }:
            {
              environment.systemPackages = [
                winapps.packages."${system}".winapps
                winapps.packages."${system}".winapps-launcher # optional
              ];
            }
          )
        ];
      };
    };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On NixOS without Flakes&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://jade.fyi/blog/flakes-arent-real/"&gt;Flakes aren't real and they can't hurt you.&lt;/a&gt;. However, if you still don't want to use flakes, you can use WinApps with flake-compat like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;# configuration.nix
{
  pkgs,
  system ? pkgs.system,
  ...
}:
{
  # set up binary cache (optional)
  nix.settings = {
    substituters = [ "https://winapps.cachix.org/" ];
    trusted-public-keys = [ "winapps.cachix.org-1:HI82jWrXZsQRar/PChgIx1unmuEsiQMQq+zt05CD36g=" ];
    trusted-users = [ "&amp;lt;your username&amp;gt;" ]; # replace with your username
  };

  environment.systemPackages =
    let
      winapps =
        (import (builtins.fetchTarball "https://github.com/winapps-org/winapps/archive/main.tar.gz"))
        .packages."${system}";
    in
    [
      winapps.winapps
      winapps.winapps-launcher # optional
    ];
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#winapps-org/winapps&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=winapps-org/winapps&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=winapps-org/winapps&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=winapps-org/winapps&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>clash-verge-rev/clash-verge-rev</title>
      <link>https://github.com/clash-verge-rev/clash-verge-rev</link>
      <description>&lt;p&gt;A modern GUI client based on Tauri, designed to run in Windows, macOS and Linux for tailored proxy experience&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/src-tauri/icons/icon.png" alt="Clash" width="128" /&gt; &lt;br /&gt; Continuation of &lt;a href="https://github.com/zzzgydi/clash-verge"&gt;Clash Verge&lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h3 align="center"&gt; A Clash Meta GUI based on &lt;a href="https://github.com/tauri-apps/tauri"&gt;Tauri&lt;/a&gt;. &lt;/h3&gt; 
&lt;h2&gt;Preview&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dark&lt;/th&gt; 
   &lt;th&gt;Light&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/docs/preview_dark.png" alt="预览" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/docs/preview_light.png" alt="预览" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;请到发布页面下载对应的安装包：&lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases"&gt;Release page&lt;/a&gt;&lt;br /&gt; Go to the &lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases"&gt;Release page&lt;/a&gt; to download the corresponding installation package&lt;br /&gt; Supports Windows (x64/x86), Linux (x64/arm64) and macOS 10.15+ (intel/apple).&lt;/p&gt; 
&lt;h4&gt;我应当怎样选择发行版&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;版本&lt;/th&gt; 
   &lt;th align="left"&gt;特征&lt;/th&gt; 
   &lt;th align="left"&gt;链接&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Stable&lt;/td&gt; 
   &lt;td align="left"&gt;正式版，高可靠性，适合日常使用。&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases"&gt;Release&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Alpha&lt;/td&gt; 
   &lt;td align="left"&gt;早期测试版，功能未完善，可能存在缺陷。&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases/tag/alpha"&gt;Alpha&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AutoBuild&lt;/td&gt; 
   &lt;td align="left"&gt;滚动更新版，持续集成更新，适合开发测试。&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases/tag/autobuild"&gt;AutoBuild&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;安装说明和常见问题，请到 &lt;a href="https://clash-verge-rev.github.io/"&gt;文档页&lt;/a&gt; 查看&lt;/h4&gt; 
&lt;hr /&gt; 
&lt;h3&gt;TG 频道: &lt;a href="https://t.me/clash_verge_re"&gt;@clash_verge_rev&lt;/a&gt;&lt;/h3&gt; 
&lt;h2&gt;Promotion&lt;/h2&gt; 
&lt;h4&gt;&lt;a href="https://verge.dginv.click/#/register?code=oaxsAGo6"&gt;狗狗加速 —— 技术流机场 Doggygo VPN&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;高性能海外机场，免费试用，优惠套餐，解锁流媒体，全球首家支持 Hysteria 协议。&lt;/li&gt; 
 &lt;li&gt;使用 Clash Verge 专属邀请链接注册送 3 天，每天 1G 流量免费试用：&lt;a href="https://verge.dginv.click/#/register?code=oaxsAGo6"&gt;点此注册&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Clash Verge 专属 8 折优惠码: verge20 (仅有 500 份)&lt;/li&gt; 
 &lt;li&gt;优惠套餐每月仅需 15.8 元，160G 流量，年付 8 折&lt;/li&gt; 
 &lt;li&gt;海外团队，无跑路风险，高达 50% 返佣&lt;/li&gt; 
 &lt;li&gt;集群负载均衡设计，高速专线(兼容老客户端)，极低延迟，无视晚高峰，4K 秒开&lt;/li&gt; 
 &lt;li&gt;全球首家 Hysteria 协议机场，现已上线更快的 &lt;code&gt;Hysteria2&lt;/code&gt; 协议(Clash Verge 客户端最佳搭配)&lt;/li&gt; 
 &lt;li&gt;解锁流媒体及 ChatGPT&lt;/li&gt; 
 &lt;li&gt;官网：&lt;a href="https://verge.dginv.click/#/register?code=oaxsAGo6"&gt;https://狗狗加速.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;本项目的构建与发布环境由 &lt;a href="https://yxvm.com/aff.php?aff=827"&gt;YXVM&lt;/a&gt; 独立服务器全力支持，&lt;/h4&gt; 
&lt;p&gt;感谢提供 独享资源、高性能、高速网络 的强大后端环境。如果你觉得下载够快、使用够爽，那是因为我们用了好服务器！&lt;/p&gt; 
&lt;p&gt;🧩 YXVM 独立服务器优势：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🌎 优质网络，回程优化，下载快到飞起&lt;/li&gt; 
 &lt;li&gt;🔧 物理机独享资源，非VPS可比，性能拉满&lt;/li&gt; 
 &lt;li&gt;🧠 适合跑代理、搭建 WEB 站 CDN 站 、搞 CI/CD 或任何高负载应用&lt;/li&gt; 
 &lt;li&gt;💡 支持即开即用，多机房选择，CN2 / IEPL 可选&lt;/li&gt; 
 &lt;li&gt;📦 本项目使用配置已在售，欢迎同款入手！&lt;/li&gt; 
 &lt;li&gt;🎯 想要同款构建体验？&lt;a href="https://yxvm.com/aff.php?aff=827"&gt;立即下单 YXVM 独立服务器！&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;基于性能强劲的 Rust 和 Tauri 2 框架&lt;/li&gt; 
 &lt;li&gt;内置&lt;a href="https://github.com/MetaCubeX/mihomo"&gt;Clash.Meta(mihomo)&lt;/a&gt;内核，并支持切换 &lt;code&gt;Alpha&lt;/code&gt; 版本内核。&lt;/li&gt; 
 &lt;li&gt;简洁美观的用户界面，支持自定义主题颜色、代理组/托盘图标以及 &lt;code&gt;CSS Injection&lt;/code&gt;。&lt;/li&gt; 
 &lt;li&gt;配置文件管理和增强（Merge 和 Script），配置文件语法提示。&lt;/li&gt; 
 &lt;li&gt;系统代理和守卫、&lt;code&gt;TUN(虚拟网卡)&lt;/code&gt; 模式。&lt;/li&gt; 
 &lt;li&gt;可视化节点和规则编辑&lt;/li&gt; 
 &lt;li&gt;WebDav 配置备份和同步&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;p&gt;Refer to &lt;a href="https://clash-verge-rev.github.io/faq/windows.html"&gt;Doc FAQ Page&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Donation&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/clash-verge-rev"&gt;捐助Clash Verge Rev的开发&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;To run the development server, execute the following commands after all prerequisites for &lt;strong&gt;Tauri&lt;/strong&gt; are installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm i
pnpm run prebuild
pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Issue and PR welcome!&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;Clash Verge rev was based on or inspired by these projects and so on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zzzgydi/clash-verge"&gt;zzzgydi/clash-verge&lt;/a&gt;: A Clash GUI based on tauri. Supports Windows, macOS and Linux.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tauri-apps/tauri"&gt;tauri-apps/tauri&lt;/a&gt;: Build smaller, faster, and more secure desktop applications with a web frontend.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Dreamacro/clash"&gt;Dreamacro/clash&lt;/a&gt;: A rule-based tunnel in Go.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MetaCubeX/mihomo"&gt;MetaCubeX/mihomo&lt;/a&gt;: A rule-based tunnel in Go.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Fndroid/clash_for_windows_pkg"&gt;Fndroid/clash_for_windows_pkg&lt;/a&gt;: A Windows/macOS GUI based on Clash.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vitejs/vite"&gt;vitejs/vite&lt;/a&gt;: Next generation frontend tooling. It's fast!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;GPL-3.0 License. See &lt;a href="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/LICENSE"&gt;License here&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>deepseek-ai/awesome-deepseek-integration</title>
      <link>https://github.com/deepseek-ai/awesome-deepseek-integration</link>
      <description>&lt;p&gt;Integrate the DeepSeek API into popular softwares&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img width="1000px" alt="Awesome DeepSeek Integrations" src="docs/Awesome DeepSeek Integrations.png" /&gt; &lt;/p&gt; 
 &lt;h1&gt;Awesome DeepSeek Integrations &lt;img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" alt="Awesome" /&gt;&lt;/h1&gt; 
 &lt;p&gt;Integrate the DeepSeek API into popular softwares. Access &lt;a href="https://platform.deepseek.com/"&gt;DeepSeek Open Platform&lt;/a&gt; to get an API key.&lt;/p&gt; 
 &lt;p&gt;English/&lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/README_cn.md"&gt;简体中文&lt;/a&gt;/&lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/README_zh_tw.md"&gt;繁體中文&lt;/a&gt;/&lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/README_ja.md"&gt;日本語&lt;/a&gt;/&lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/README_es.md"&gt;Español&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12798" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12798" alt="deepseek-ai%2Fawesome-deepseek-integration | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#awesome-deepseek-integrations-"&gt;Awesome DeepSeek Integrations &lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#project-list"&gt;Project List&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#applications"&gt;Applications&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#ai-agent-frameworks"&gt;AI Agent frameworks&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#data-ai-applications-frameworks"&gt;Data AI Applications frameworks&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#rag-frameworks"&gt;RAG frameworks&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#fhe-fully-homomorphic-encryption-frameworks"&gt;FHE (Fully Homomorphic Encryption) frameworks&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#solana-frameworks"&gt;Solana frameworks&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#synthetic-data-curation"&gt;Synthetic data curation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#im-application-plugins"&gt;IM Application Plugins&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#office-addin"&gt;Office Addin&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#browser-extensions"&gt;Browser Extensions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#vs-code-extensions"&gt;VS Code Extensions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#visual-studio-extensions"&gt;Visual Studio Extensions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#neovim-extensions"&gt;neovim Extensions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#jetbrains-extensions"&gt;JetBrains Extensions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#discord-bots"&gt;Discord Bots&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#native-ai-code-editor"&gt;Native AI Code Editor&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#emacs"&gt;Emacs&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#security"&gt;Security&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#providers"&gt;Providers&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#others"&gt;Others&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Project List&lt;/h2&gt; 
&lt;h3&gt;&lt;span id="applications"&gt;Applications&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;/p&gt;
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/OpenXLab/migo/logo.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://migo.intern-ai.org.cn/education"&gt;Migo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A free AI innovation accelerator offering intelligent Q&amp;amp;A, in-depth paper comprehension, cutting-edge AI tools, and a personal academic knowledge base. As your exploration partner, Migo helps you discover and realize outstanding ideas!&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/eechat/assets/logo.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lucassssss/eechat"&gt;eechat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A simple and user-friendly tool for local deployment of large language models, supporting local private deployment of open-source models such as DeepSeek-R1, DLlama 3, Phi-4, Mistral, Gemma 3, etc., while also supporting remote LLM API calls.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/aingdesk/assets/logo.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/aingdesk/AingDesk"&gt;AingDesk&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;One-click deployment of AI models on your computer with a visual interface, featuring an elegant chat UI. It allows online sharing for collaborative use, supports various models like DeepSeek, and enables web search and third-party API integration.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/dingtalk/assets/dingtalk_icon.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.dingtalk.com/"&gt;DingTalk&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DingTalk AI Assistant integrates multiple AI product features from the DingTalk platform to intelligently support enterprises in their daily workflows. It possesses various intelligent capabilities, including but not limited to smart communication, smart collaboration, and smart management. &lt;p&gt;With these functionalities, the AI assistant can summarize key points within an organization, generate meeting minutes, and provide users with relevant task notifications and schedule reminders. Additionally, DingTalk AI Assistant leverages its knowledge base to intelligently answer common employee inquiries regarding company administrative processes, HR policies, and other related topics.&lt;/p&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://chatdoc.com/chatdoc/chatdoc.webp" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://chatdoc.com"&gt;ChatDOC&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ChatDOC is an AI-powered document reading tool equipped with robust traceability features, ensuring that the source of every piece of information is clear and verifiable, helping you efficiently and accurately grasp the core of your documents.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/SwiftChat/assets/favicon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/SwiftChat/README.md"&gt;SwiftChat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; is a lightning-fast, cross-platform AI chat application built with React Native. It delivers native performance on Android, iOS, and macOS. Features include real-time streaming chat, rich Markdown support, AI image generation, customizable system prompts, quick model selection and multimodal capabilities. Supports multiple AI providers including DeepSeek, Amazon Bedrock, Ollama and OpenAI Compatible Modles with clean UI and high performance.&lt;/td&gt; 
  &lt;/tr&gt;  
  &lt;tr&gt;
   &lt;td&gt;&lt;img src="https://4everlogo.4everland.store/logo/logo.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/4EVERChat/README.md"&gt;4EVERChat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://chat.4everland.org/"&gt;4EVERChat&lt;/a&gt; is an intelligent model selection platform integrating hundreds of LLMs, enabling real-time comparison of model performance. Leveraging &lt;a href="https://www.4everland.org/"&gt;4EVERLAND&lt;/a&gt; AI RPC's unified API endpoint, it achieves cost-free model switching and automatically selects combinations with fast responses and low costs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/xhai_browser/assets/logo_512.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/xhai_browser/README.md"&gt;xhai Browser&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;xhai Browser is an Android desktop management &amp;amp; AI browser, DeepSeek is the default AI dialog engine.It has the ultimate performance (0.2 seconds to start), slim size (apk 3M), no ads, ultra-fast ad blocking, multi-screen classification, screen navigation, multi-search box, a box multiple search!&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://i.imgur.com/FkbmMVG.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://intellibar.app/"&gt;IntelliBar&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;IntelliBar is a beautiful assistant for the Mac that lets you use advanced models like DeepSeek R1 with any app on your Mac — ex: edit emails in your mail app or summarize articles in your browser.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/gptbots/gptbots.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gptbots.ai/docs"&gt;GPTBots&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gptbots.ai/"&gt;GPTBots&lt;/a&gt; is a no-code AI agent building platform that integrates major international LLMs, including Deepseek. It offers modules for RAG-based knowledge storage/retrieval, tool customization/calling, and workflow orchestration. Additionally, it allows agents to be integrated into multiple mainstream platforms (such as WhatsApp, Telegram, etc.), providing end-to-end AI solutions for businesses and helping them stand out in the AI era.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/ThinkInAIXYZ/deepchat/raw/main/build/icon.png?raw=true" alt="Icon" width="64" height="auto" style="border-radius: 10px" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ThinkInAIXYZ/deepchat/raw/main/README.md"&gt;DeepChat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DeepChat is a fully free desktop smart assistant, with a powerful DeepSeek large model, supporting multi-round conversations, internet search, file uploads, knowledge bases, and more.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://avatars.githubusercontent.com/u/171659527?s=400&amp;amp;u=39906ab3b6e2066f83046096a66a77fb3f8bb836&amp;amp;v=4" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/quantalogic/quantalogic"&gt;Quantalogic&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; QuantaLogic is a ReAct (Reasoning &amp;amp; Action) framework for building advanced AI agents. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/13600976/224d547a-6fbc-47c8-859f-aa14813e2b0f" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/chatbox/README.md"&gt;Chatbox&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Chatbox is a desktop client for multiple cutting-edge LLM models, available on Windows, Mac and Linux. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/bb65404c-f867-42d8-ae2b-281fe953ab54" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/chatgpt_next_web/README.md"&gt; ChatGPT-Next-Web &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; ChatGPT Next Web is a cross-platform ChatGPT web UI, with GPT3, GPT4 &amp;amp; Gemini Pro support. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/Casibase/assets/casibase.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://casibase.org/docs/category/beginner-guide/"&gt;Casibase&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://casibase.org"&gt;Casibase&lt;/a&gt; is an open source AI knowledge base and dialogue system that combines the latest RAG technology, SSO functionality, and support for a wide range of mainstream AI models. Casibase is designed to provide enterprises and developers with a powerful, flexible, and easy-to-use knowledge management and intelligent dialogue platform. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="./docs/Coco AI/assets/favicon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="docs/Coco AI/README.md"&gt;Coco AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://coco.rs"&gt;Coco AI&lt;/a&gt; is a fully open-source, cross-platform unified search and productivity tool that connects and searches across various data sources, including applications, files, Google Drive, Notion, Yuque, Hugo, and more, both local and cloud-based. By integrating with large models like DeepSeek, Coco AI enables intelligent personal knowledge management, emphasizing privacy and supporting private deployment, helping users quickly and intelligently access their information. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/liubai/assets/liubai-logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/liubai/README.md"&gt;Liubai&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Liubai allows DeepSeek to have arms and legs to manipulate your notes, tasks, calendars, and to-do lists just on WeChat! &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/1ac9791b-87f7-41d9-9282-a70698344e1d" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/pal/README.md"&gt; Pal - AI Chat Client&lt;br /&gt;(iOS, ipadOS) &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Pal is a customized chat playground on iOS. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.librechat.ai/librechat.svg?sanitize=true" alt="LibreChat" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.librechat.ai/docs/configuration/librechat_yaml/ai_endpoints/deepseek"&gt;LibreChat&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; LibreChat is a customizable open-source app that seamlessly integrates DeepSeek for enhanced AI interactions. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/longevity-genie/chat-ui/11c6647c83f9d2de21180b552474ac5ffcf53980/static/geneticsgenie/icon-128x128.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/longevity-genie/just-chat"&gt;Just-Chat&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Make your LLM agent and chat with it simple and fast!&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.papersgpt.com/images/logo/favicon.ico" alt="PapersGPT" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/papersgpt/papersgpt-for-zotero"&gt;PapersGPT&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; PapersGPT is a Zotero plugin that seamlessly with DeepSeek and other multiple AI models for quickly reading papers in Zotero. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/rss-translator/RSS-Translator/main/core/static/favicon.ico" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/rss_translator/README.md"&gt; RSS Translator &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Translate RSS feeds into your language! &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://relingo.net/assets/images/relingo-logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://relingo.net"&gt; Relingo &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Build and master vocabulary while you browse website and watch youtube! &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ysnows/enconvo_media/main/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/enconvo/README.md"&gt; Enconvo &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Enconvo is the Launcher of the AI era, the entry point for all AI functions, and a thoughtful intelligent assistant.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/kangfenmao/cherry-studio/raw/main/src/renderer/src/assets/images/logo.png?raw=true" alt="Icon" width="64" height="auto" style="border-radius: 10px" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/cherrystudio/README.md"&gt;Cherry Studio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A powerful desktop AI assistant for producer&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://tomemo.top/images/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/tomemo/README.md"&gt; ToMemo (iOS, ipadOS) &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; A phrasebook + clipboard history + keyboard iOS app with integrated AI macromodeling for quick output use in the keyboard.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/buxuku/video-subtitle-master/refs/heads/main/resources/icon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/buxuku/video-subtitle-master"&gt;Video Subtitle Master&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; Batch generate subtitles for videos, with the ability to translate subtitles into other languages. This is a client-side tool that supports both Mac and Windows platforms and integrates with multiple translation services such as Baidu, Volcengine, DeepLx, OpenAI, DeepSeek, and Ollama.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/UnknownEnergy/chatgpt-api/raw/master/dist/assets/chatworm-72x72.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/UnknownEnergy/chatgpt-api/raw/master/README.md"&gt;Chatworm&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Chatworm is a webapp for multiple cutting-edge LLM models, open-source and also available on Android. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/icon_512x512@2x.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/tisfeng/Easydict"&gt;Easydict&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; Easydict is a concise and easy-to-use translation dictionary macOS App that allows you to easily and elegantly look up words or translate text. Supports calling large language model APIs for translation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.raycast.com/favicon-production.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/raycast/README.md"&gt;Raycast&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raycast.com/?via=ViGeng"&gt;Raycast&lt;/a&gt; is a productivity tool for macOS that lets you control your tools with a few keystrokes. It supports various extensions including DeepSeek AI.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/chatpdflocal/assets/chatpdflocal-icon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.chatpdflocal.com"&gt;ChatPDFLocal&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; ChatPDFLocal is an AI powered Mac OS App for helping to chat PDF, it works seamlessly with DeepSeek and other multiple AI models to improve your reading efficiency. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://niceprompt.app/favicon.ico" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://niceprompt.app"&gt;Nice Prompt&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://niceprompt.app"&gt;Nice Prompt&lt;/a&gt; Organize, share and use your prompts in your code editor, with Cursor and VSCode。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://avatars.githubusercontent.com/u/193405629?s=200&amp;amp;v=4" alt="PHP Client" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-php/deepseek-php-client/raw/master/README.md"&gt;PHP Client&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Deepseek PHP Client is a robust and community-driven PHP client library for seamless integration with the Deepseek API. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/tornikegomareli/DeepSwiftSeek/raw/main/logo.webp" alt="DeepSwiftSeek Logo" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/tornikegomareli/DeepSwiftSeek/raw/main/README.md"&gt;DeepSwiftSeek&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; DeepSwiftSeek is a lightweight yet powerful Swift client library, pretty good integration with the DeepSeek API. It provides easy-to-use Swift concurrency for chat, streaming, FIM (Fill-in-the-Middle) completions, and more. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt; &lt;img src="https://avatars.githubusercontent.com/u/958072?s=200&amp;amp;v=4" alt="Laravel Integration" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-php/deepseek-laravel/raw/master/README.md"&gt;Laravel Integration&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Laravel wrapper for Deepseek PHP client, to seamless deepseek API integration with laravel applications.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/cohesion-org/deepseek-go/refs/heads/main/internal/images/deepseek-go.png" alt="Go Client" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/cohesion-org/deepseek-go/raw/main/README.md"&gt;Deepseek Go&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; A Deepseek client written for Go supporting Chat and Reasoning Models. Also supports external providers like Azure, OpenRouter and others. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/zotero/assets/zotero-icon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/zotero/README_cn.md"&gt;Zotero&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.zotero.org"&gt;Zotero&lt;/a&gt; is a free, easy-to-use tool to help you collect, organize, annotate, cite, and share research. It can use deepseek as translation service.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://b3log.org/images/brand/siyuan-128.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/SiYuan/README.md"&gt;SiYuan&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; SiYuan is a privacy-first personal knowledge management system that supports complete offline usage, as well as end-to-end encrypted data sync.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/ArvinLovegood/go-stock/raw/master/build/appicon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/ArvinLovegood/go-stock/raw/master/README.md"&gt;go-stock&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;go-stock is a Chinese stock data viewer built by Wails with NativeUI and powered by LLM.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://avatars.githubusercontent.com/u/102771702?s=200&amp;amp;v=4" alt="Wordware" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/wordware/README.md"&gt;Wordware&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.wordware.ai/"&gt;Wordware&lt;/a&gt; is a toolkit that enables anyone to build, iterate, and deploy their AI stack with just natural language.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://framerusercontent.com/images/xRJ6vNo9mUYeVNxt0KITXCXEuSk.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/langgenius/dify/"&gt;Dify&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://dify.ai/"&gt;Dify&lt;/a&gt; is an LLM application development platform that supports DeepSeek models for creating assistants, workflows, text generators, and more. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/enricoros/big-AGI/refs/heads/v2-dev/public/favicon.ico" alt="Big-AGI" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/enricoros/big-AGI/raw/v2-dev/README.md"&gt;Big-AGI&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://big-agi.com/"&gt;Big-AGI&lt;/a&gt; is a groundbreaking AI suite designed to democratize access to advanced artificial intelligence for everyone.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/LiberSonora/LiberSonora/raw/main/assets/avatar.jpeg?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/LiberSonora/LiberSonora/raw/main/README_en.md"&gt;LiberSonora&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; LiberSonora, meaning "Voice of Freedom", is an AI-powered, robust, open-source audiobook toolkit that includes features like intelligent subtitle extraction, AI title generation, multilingual translation, with support for GPU acceleration and batch offline processing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ripperhe/Bob/master/docs/_media/icon_128.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://bobtranslate.com/"&gt;Bob&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://bobtranslate.com/"&gt;Bob&lt;/a&gt; is a macOS translation &amp;amp; OCR tool ready to use in any app — right out of the box!&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://agenticflow.ai/favicon.ico" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://agenticflow.ai/"&gt;AgenticFlow&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://agenticflow.ai/"&gt;AgenticFlow&lt;/a&gt; is a no-code platform where marketers build agentic AI workflows for go-to-market automation, powered by hundreds of everyday apps as tools for your AI agents.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/ZGGSONG/STranslate/raw/main/img/favicon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://stranslate.zggsong.com/en/"&gt;STranslate&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://stranslate.zggsong.com/en/"&gt;STranslate&lt;/a&gt;（Windows） is a ready-to-go translation ocr tool developed by WPF &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://devinci.onicai.com/favicon.ico" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://devinci.onicai.com/"&gt;DeVinci&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://devinci.onicai.com/"&gt;DeVinci&lt;/a&gt; is the end-to-end decentralized AI chat app to privately chat with open-source LLMs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/user-attachments/assets/5e16beb0-993e-47bf-807e-7c8804b313a2" alt="Asp Client" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/Anwar-alhitar/Deepseek.Asp.Client/raw/master/README.md"&gt;ASP Client&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Anwar-alhitar/Deepseek.Asp.Client/raw/master/README.md"&gt;Deepseek.ASPClient&lt;/a&gt; is a lightweight ASP.NET wrapper for the Deepseek AI API, designed to simplify AI-driven text processing in .NET applications.. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.gptaiflow.tech/logo.png" alt="gpt-ai-flow-logo" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.gptaiflow.tech/docs/product/api-keys-setup#setup-deepseek-api-keys"&gt;GPT AI Flow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; The ultimate productivity weapon built by engineers for efficiency enthusiasts (themselves): &lt;a href="https://www.gptaiflow.tech/"&gt;GPT AI Flow&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;`Shift+Alt+Space` Wake up desktop intelligent hub&lt;/li&gt; 
     &lt;li&gt;Local encrypted storage&lt;/li&gt; 
     &lt;li&gt;Custom instruction engine&lt;/li&gt; 
     &lt;li&gt;On-demand calling without subscription bundling&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/user-attachments/assets/b09f17a8-936d-4dac-8b24-1682d52c9a3c" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/alecm20/story-flicks"&gt;Story-Flicks&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;With just one sentence, you can quickly generate high-definition story short videos, supporting models such as DeepSeek.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://prompt.16x.engineer/favicon.ico" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/16x_prompt/README.md"&gt;16x Prompt&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://prompt.16x.engineer/"&gt;16x Prompt&lt;/a&gt; is an AI coding tool with context management. It helps developers manage source code context and craft prompts for complex coding tasks on existing codebases.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/blob/main/docs/Alpha派/assets/favicon1.png?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/blob/main/docs/Alpha派/README.md"&gt; Alpha Pai &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; AI Research Assistant / The Next-Generation Financial Information Portal Driven by AI.&lt;br /&gt;Proxy for investors to attend meetings and take notes, as well as providing search and Q&amp;amp;A services for financial information and quantitative analysis for investment research.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt; &lt;img src="https://docs.xark-argo.com/img/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.xark-argo.com"&gt;argo&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Locally download and run Ollama and Huggingface models with RAG on Mac/Windows/Linux. Support LLM API too.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.petercat.ai/images/favicon.ico" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.petercat.ai"&gt;PeterCat&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; A conversational Q&amp;amp;A agent configuration system, self-hosted deployment solutions, and a convenient all-in-one application SDK, allowing you to create intelligent Q&amp;amp;A bots for your GitHub repositories.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/labring/FastGPT/refs/heads/main/.github/imgs/logo.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://fastgpt.cn/en"&gt;FastGPT&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; FastGPT is an open-source AI knowledge base platform built on large language models (LLMs), supporting various models including DeepSeek and OpenAI. We provide out-of-the-box capabilities for data processing, model invocation, RAG retrieval, and visual AI workflow orchestration, enabling you to effortlessly build sophisticated AI applications. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/ruzhiai_note/assets/play_store_512.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/ruzhiai_note/README.md"&gt;RuZhi AI Notes&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;RuZhi AI Notes is an intelligent knowledge management tool powered by AI, providing one-stop knowledge management and application services including AI search &amp;amp; exploration, AI results to notes conversion, note management &amp;amp; organization, knowledge presentation &amp;amp; sharing. Integrated with DeepSeek model to provide more stable and higher quality outputs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://cdn.link-ai.tech/doc/CoW%20logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat"&gt;Chatgpt-on-Wechat&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Chatgpt-on-Wechat(CoW) is a flexible chatbot framework that supports seamless integration of multiple LLMs, including DeepSeek, OpenAI, Claude, Qwen, and others, into commonly used platforms or office software such as WeChat Official Accounts, WeCom, Feishu, DingTalk, and websites. It also supports a wide range of custom plugins. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://athenalab.ai/assets/favicon/favicon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://athenalab.ai/"&gt;Athena&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;The world's first autonomous general AI with advanced cognitive architecture and human-like reasoning capabilities, designed to tackle complex real-world challenges.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://maxkb.cn/images/favicon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/1Panel-dev/MaxKB"&gt;MaxKB&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://maxkb.cn/"&gt;MaxKB&lt;/a&gt; is a ready-to-use, flexible RAG Chatbot. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/TigerGPT/assets/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://ttm.financial/gpt"&gt;TigerGPT&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;TigerGPT is the first financial AI investment assistant of its kind based on OpenAI, developed by Tiger Group. TigerGPT aims to provide intelligent investment decision-making support for investors. On February 18, 2025, TigerGPT officially integrated the DeepSeek-R1 model to provide users with online Q&amp;amp;A services that support deep reasoning. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/HIX.AI/assets/logo.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://hix.ai"&gt;HIX.AI&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Try DeepSeek for free and enjoy unlimited AI chat on HIX.AI. Use DeepSeek R1 for AI chat, writing, coding &amp;amp; more. Experience next-gen AI chat now!&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/sharmt1411/askanywhere/raw/main/icon/Depth_8,_Frame_0explore-%E8%A7%92%E6%A0%87.png?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/sharmt1411/askanywhere"&gt;Askanywhere&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Select text anywhere and start a conversation with Deepseek&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/OJZen/1chat/raw/refs/heads/main/doc/assets/icon.ico?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/OJZen/1chat"&gt;1chat&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;An iOS app that lets you chat with the DeepSeek-R1 model locally.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://chatlabsai.com/assets/logo/logo.png" alt="iOS AI Chatbot" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://chatlabsai.com"&gt;Access 250+ text, image LLMs in one app&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; 1AI iOS Chatbot integrates with 250+ text, image, voice models allowing users chat with any model in the world including Deepseek R1 and Deepseek V3 models.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/PopAi/assets/logo.svg?sanitize=true" alt="PopAi" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://popai.pro"&gt;PopAi&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;PopAi launches DeepSeek R1! Enjoy lag-free, lightning-fast performance with PopAi. Seamlessly toggle online search on/off.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://pot-app.com/logo/icon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://pot-app.com/"&gt;Pot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://pot-app.com/"&gt;Pot&lt;/a&gt; 🌈 A cross-platform software for text translation and recognition. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/images/banner.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate"&gt;PDFMathTranslate&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;PDF Math Translate is an AI-based full-text bilingual translation tool that fully preserves the layout of PDF documents.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/Richasy/Bili.Copilot/raw/master/assets/StoreLogo.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Richasy/Bili.Copilot"&gt;Bili.Copilot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Bilibili third-party Windows desktop client, a native application built with the Windows App SDK.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://www.tensorbounce.com/logo.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.tensorbounce.com/"&gt;LawAgent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LawAgent is a legal AI product developed by the Tensorbounce team, integrating a knowledge base with AI Agent capabilities. It boasts a vast repository of tens of millions of official legal-related data points and also allows for custom knowledge base configurations. The professional mode leverages the reasoning abilities of DeepSeek-R1 to assist users in legal analysis, contract review, document generation, file translation, and other legal scenarios.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/AlphaBot/assets/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://alphabot.x-pai.com/"&gt;AlphaBot&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; AlphaBot is an intelligent stock analysis assistant that integrates multi-source data with AI analysis technology to provide technical analysis, predictions, and risk assessment, helping investors make data-driven trading decisions. It supports one-click deployment, easy operation，Support Windows/Linux/MacOS and other platforms&lt;/td&gt; 
  &lt;/tr&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://h1.appinn.me/file/1741929316827_21.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jiqi136/DS-AI"&gt;Multi-platform connected DeepSeek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Leveraging the three-channel AI engine powered by DeepSeek Official, Alibaba Cloud, and Douyin Volcano, it continuously evolves its intelligence. Additionally, it employs a hybrid mode combining "online search + deep thinking".&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/remio/assets/remio_icon.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.remio.ai/"&gt;remio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;remio is an AI-powered personal knowledge hub that builds personalized knowledge bases by automatically capturing browsed web content, parsing local files, and integrating personal notes. It enables search and natural language Q&amp;amp;A within your personal knowledge base for instant insights while offering smart writing assistance—adapting to your style to streamline drafting, refining, and completing content with ease. Designed with local-first storage, remio prioritizes data privacy while centralizing fragmented information for maximum productivity.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/DocKit/assets/dockit.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://dockit.geekfun.club/"&gt;DocKit&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DocKit is an AI powered desktop GUI client designed for NoSQL database, support Elasticsearch and OpenSearch across Mac, windows and Linux. By integrating with large models like DeepSeek, DocKit can help developers to write complex DSL queries, and provide a better experience for data management and analysis. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/zenfeed/assets/icon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/glidea/zenfeed"&gt;zenfeed&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Empower RSS with AI, automatically filter, summarize, and push important information to overcome information overload. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="agent"&gt;AI Agent frameworks&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/smolagents/mascot_smol.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/huggingface/smolagents/tree/main"&gt; smolagents &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; The simplest way to build great agents. Agents write python code to call tools and orchestrate other agents. Priority support for open models like DeepSeek-R1! &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://yomo.run/yomo-logo.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/yomo/README.md"&gt;YoMo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Stateful Serverless LLM Function Calling Framework with Strongly-typed Language Support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/superagentxai/superagentX/refs/heads/master/docs/logo/icononly_transparent_nobuffer.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/superagentx/README.md"&gt;SuperAgentX&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;SuperAgentX: A Lightweight Open Source AI Framework Built for Autonomous Multi-Agent Applications with Artificial General Intelligence (AGI) Capabilities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://panda.fans/_assets/favicons/apple-touch-icon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/anda/README.md"&gt;Anda&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;A Rust framework for AI agent development, designed to build a highly composable, autonomous, and perpetually memorizing network of AI agents.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://rig.rs/assets/favicon.png" alt="Rig (Rust)" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://rig.rs"&gt;RIG&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Build modular and scalable LLM Applications in Rust.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/longevity-genie/chat-ui/11c6647c83f9d2de21180b552474ac5ffcf53980/static/geneticsgenie/icon-128x128.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/longevity-genie/just-agents"&gt;Just-Agents&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;A lightweight, straightforward library for LLM agents - no over-engineering, just simplicity!&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://alice.fun/alice-logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/bob-robert-ai/bob/raw/main/alice/readme.md"&gt;Alice&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;An autonomous AI agent on ICP, leveraging LLMs like DeepSeek for on-chain decision-making. Alice combines real-time data analysis with a playful personality to manage tokens, mine BOB, and govern ecosystems.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/Upsonic/Upsonic/raw/9d2e6d43b44defc6744817330625661ca3a2184e/Upsonic%20pp.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/Upsonic/Upsonic"&gt;Upsonic&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Upsonic offers a cutting-edge enterprise-ready agent framework where you can orchestrate LLM calls, agents, and computer use to complete tasks cost-effectively.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://avatars.githubusercontent.com/u/173022229" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/APRO-com"&gt;ATTPs&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;A foundational protocol framework for trusted communication between agents. Any agents based on DeepSeek, By integrating with the &lt;a href="https://docs.apro.com/attps"&gt;ATTPs&lt;/a&gt; SDK, can access features such as agent registration, sending verifiable data, and retrieving verifiable data. So that it can make trusted communication with agents from other platforms. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/translate.js/assets/icon.png" alt="图标" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/translate.js/README.md"&gt;translate.js&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; AI i18n for front-end developers. It can achieve fully automatic HTML translation with just two lines of JavaScript. You can switch among dozens of languages with a single click. There is no need to modify the page, no language configuration files are required, and it supports dozens of fine-tuning extension instructions. It is SEO-friendly. Moreover, it opens up a standard text translation API interface. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/agentUniverse/assets/agentUniverse_logo_s.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/antgroup/agentUniverse"&gt; agentUniverse &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; agentUniverse is a multi-agent collaboration framework designed for complex business scenarios. It offers rapid and user-friendly development capabilities for LLM agent applications, with a focus on mechanisms such as agent collaborative scheduling, autonomous decision-making, and dynamic feedback. The framework originates from Ant Group's real-world business practices in the financial industry. In June 2024, agentUniverse achieved full integration support for the DeepSeek series of models. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/BotSharp/assets/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/SciSharp/BotSharp"&gt; BotSharp &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; BotSharp is an open-source multi-agent application development framework. From simple chatbots to multi-agent collaboration and complex tasks like the Text To SQL framework, it provides out-of-the-box solutions to quickly integrate large model capabilities into existing business systems. It also includes built-in knowledge base and session management features. The framework has been thoroughly tested with DeepSeek V3 models, and thanks to the performance of DeepSeek V3, the framework's performance is on par with other proprietary models. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/eino/assets/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/cloudwego/eino"&gt; Eino &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Eino (pronounced like "I know") aims to be the best LLM application development framework in the Go language. It draws on the design concept of excellent LLM frameworks in open source communities such as LangChain and LlamaIndex, while absorbing cutting-edge research results and practical application experience, providing a LLM application development framework that is more in line with Go programming conventions, emphasizing simplicity, scalability, reliability and efficiency. &lt;/td&gt; 
  &lt;/tr&gt;  
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="data"&gt;Data AI Applications frameworks&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://github.com/user-attachments/assets/a327d72f-755f-4256-8a37-32a518a55df3" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td width="120"&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/dbgpt/README.md"&gt; DB-GPT &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; 🤖 DB-GPT is an open source AI native data app development framework with AWEL(Agentic Workflow Expression Language) and agents. The purpose is to build infrastructure in the field of large models, through the development of multiple technical capabilities such as multi-model management (SMMF), Text2SQL effect optimization, RAG framework and optimization, Multi-Agents framework collaboration, AWEL (agent workflow orchestration), etc. Which makes large model applications with data simpler and more convenient. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="rag"&gt;RAG frameworks&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/33142505/77093e84-9f7c-4716-9168-bac962fa1372" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/ragflow/README.md"&gt; RAGFlow &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; An open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models) to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted data. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://raw.githubusercontent.com/pingcap/tidb.ai/main/frontend/app/public/nextra/icon-dark.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/autoflow/README.md"&gt; Autoflow &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/pingcap/autoflow"&gt;AutoFlow&lt;/a&gt; is an open-source knowledge base tool based on GraphRAG (Graph-based Retrieval-Augmented Generation), built on &lt;a href="https://www.pingcap.com/ai?utm_source=tidb.ai&amp;amp;utm_medium=community"&gt;TiDB&lt;/a&gt; Vector, LlamaIndex, and DSPy. It provides a Perplexity-like search interface and allows easy integration of AutoFlow's conversational search window into your website by embedding a simple JavaScript snippet. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://assets.zilliz.com/Zilliz_Logo_Mark_White_20230223_041013_86057436cc.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/zilliztech/deep-searcher"&gt; DeepSearcher &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; DeepSearcher combines powerful LLMs (DeepSeek, OpenAI, etc.) and Vector Databases (Milvus, etc.) to perform search, evaluation, and reasoning based on private data, providing highly accurate answer and comprehensive report. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="80"&gt; &lt;img src="https://raw.githubusercontent.com/OpenSPG/openspg/089188f3e7b0392221f5a8e8f1a3629b6352a6f9/LOGO.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/OpenSPG/KAG/raw/master/README.md"&gt; KAG &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; KAG is a logical reasoning and Q&amp;amp;A framework based on the &lt;a href="https://github.com/OpenSPG/openspg"&gt;OpenSPG&lt;/a&gt; engine and large language models, which is used to build logical reasoning and Q&amp;amp;A solutions for vertical domain knowledge bases. KAG can effectively overcome the ambiguity of traditional RAG vector similarity calculation and the noise problem of GraphRAG introduced by OpenIE. KAG supports logical reasoning and multi-hop fact Q&amp;amp;A, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="fhe"&gt;FHE (Fully Homomorphic Encryption) frameworks&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/fhe.mind-network/mind-network-log.png" alt="Icon" width="200" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/mind-network/mind-sdk-deepseek-rust"&gt; Mind FHE Rust SDK &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;An open-source SDK for encrypting AI with Fully Homomorphic Encryption (FHE) and integrating with Mind Network for agent consensus. FHE is considered the &lt;b&gt;holy grail of cryptography&lt;/b&gt;, enabling computations directly on encrypted data without the need for decryption. With FHE, agents can safeguard their privacy while using Deepseek, ensuring both model integrity and result consensus -&lt;b&gt; all without exposing their data &lt;/b&gt;- by connecting to Mind Network. The SDK &lt;a href="https://github.com/mind-network/mind-sdk-deepseek-rust"&gt; source code &lt;/a&gt; is implemented in pure &lt;b&gt;Rust&lt;/b&gt;&amp;gt; and the package also available on &lt;a href="https://crates.io/crates/mind_sdk_deepseek"&gt; crates.io &lt;/a&gt;. &lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="solana"&gt;Solana frameworks&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/solana-agent-kit/assets/sendai-logo.png" alt="Icon" width="128" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/solana-agent-kit/README.md"&gt; Solana Agent Kit &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;An open-source toolkit for connecting AI agents to Solana protocols. Now, any agent, using any Deepseek LLM, can autonomously perform 60+ Solana actions: &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="sythetic"&gt;Synthetic data curation&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/bespokelabsai/curator/main/docs/Bespoke-Labs-Logomark-Red-crop.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/curator/README.md"&gt; Curator &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; An open-source tool to curate large scale datasets for post-training LLMs. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/user-attachments/assets/8455694b-c52e-40ec-847e-adf6a5ac064f" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/Kiln-AI/Kiln"&gt; Kiln &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Generate synthetic datasets and distill R1 models into custom fine-tunes. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://avatars.githubusercontent.com/u/192579850?s=200&amp;amp;v=4" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/DataEval/dingo"&gt; Dingo &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Dingo: A Comprehensive Data Quality Evaluation Tool. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="im"&gt;IM Application Plugins&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/InternLM/HuixiangDou/releases/download/v0.1.0rc1/huixiangdou.jpg" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/huixiangdou/README_cn.md"&gt;HuixiangDou&lt;br /&gt;(wechat,lark)&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Domain knowledge assistant in personal WeChat and Feishu, focusing on answering questions.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/RockChinQ/LangBot/raw/master/res/logo.png?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/RockChinQ/LangBot"&gt;LangBot&lt;br /&gt;（QQ, Lark, WeCom）&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; LLM-based IM bots framework, supports QQ, Lark, WeCom, and more platforms.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://nonebot.dev/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/KomoriDev/nonebot-plugin-deepseek"&gt;NoneBot&lt;br /&gt;（QQ, Lark, Discord, TG, etc.）&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Based on NoneBot framework, provide intelligent chat and deep thinking functions, supports QQ, Lark, Discord, TG, and more platforms.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/Soulter/AstrBot/raw/refs/heads/master/dashboard/src/assets/images/logo-normal.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/Soulter/AstrBot/"&gt;AstrBot&lt;br /&gt;（QQ, WeChat, WeCom, Lark, TG, etc.）&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; User-friendly LLM-based multi-platform chatbot with a WebUI, supporting long-term-memory, RAG, LLM agents, and plugins integration.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="office"&gt;Office Addin&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.44886.com/view/img/bukeng.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.bukenghezi.com/"&gt;BKOffice&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;An Office plugin that supports the Word, Excel, and PPT suite (also supports the WPS suite), adding more than 300 functions to Office.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.aippt.cn/_nuxt/logo_cn.eYEokZzA.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.aippt.cn/"&gt;AiPPT&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;AiPPT.com，chosen by over 20 million users，One sentence, one minute, one click to generate PPT。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/office-sec/OfficeAI/raw/main/logo/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/office-sec/OfficeAI"&gt;OfficeAI Assistant&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;OfficeAI Assistant is a free office plugin that provides functions such as AI Q&amp;amp;A, AI proofreading, AI typesetting, AI creation, and AI data processing within Office. It can improve office efficiency and is compatible with both Microsoft Office and WPS Office.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="browser"&gt;Browser Extensions&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/deepshare/assets/logo_200.png" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/deepshare/README.md"&gt;Tiny AI Bee&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; Tiny AI Bee is a free login-free one-click grease monkey plugin for sharing AI chats, Specialized in solving the problem of sending thousands of words of AI Q&amp;amp;A to friends, causing their phones to be brushed, or long screenshots to be compressed and opened blurred, not easy to read. Satisfy users' need to share their crystallized wisdom with AI to others &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/OpenXLab/migo/logo.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://chromewebstore.google.com/detail/cjapgnecnkblehipjghhegiccobeloka?utm_source=item-share-cb"&gt;Migo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; Migo offers comprehensive text processing, information search, and knowledge Q&amp;amp;A functions, adapting to various online work and research scenarios (such as Feishu, arXiv, Overleaf, etc.).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/9d3f42b8-fcd0-47ab-8b06-1dd0554dd80e" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/immersive_translate/README.md"&gt; Immersive Translate &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Immersive Translate is a bilingual webpage translation plugin. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://lh3.googleusercontent.com/K9i0qJb8phasC5wWf5tU68rhnfvX4swsE0hrhJP-WB3WV7MwE5KpMUIJvHKNHHRE6GKNIvIdTNSWoDMl_NggrmUsaw=s120" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/immersive_reading_guide/README.md"&gt; Immersive Reading Guide &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; NO Sidebar!!! Immersive AI web summarization, ask questions... &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/8a301619-a3de-489b-81fd-69aaa7c1c561" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/chatgpt_box/README.md"&gt; ChatGPT Box &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; ChatGPT Box is a ChatGPT integration in browser, completely for free. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/c3d9d100-247a-41cc-97c1-10b01ed25e70" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/hcfy/README.md"&gt; hcfy (划词翻译) &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; hcfy (划词翻译) is a web browser extension to integrate multiple translation services. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://static.eudic.net/web/trans/en_trans.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="docs/Lulu Translate/README.md"&gt; Lulu Translate &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; The plugin provides mouse selection translation, paragraph-by-paragraph comparison translation, and PDF document translation functionalities. It can utilize various translation engines, such as DeepSeek AI, Bing, GPT, Google, etc. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/Bistutu/FluentRead/raw/refs/heads/main/public/icon/192.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://fluent.thinkstu.com/"&gt; FluentRead &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; A revolutionary open-source browser translation plugin that enables everyone to have a native-like reading experience &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.ncurator.com/_next/image?url=%2Ffavicon.ico&amp;amp;w=96&amp;amp;q=75" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.ncurator.com/"&gt; Ncurator &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Knowledge Base AI Q&amp;amp;A Assistant - Let AI help you organize and analyze knowledge&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/oinzen/RSSFlow-doc/raw/main/docs/images/en/icon64.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://rssflow.oinchain.com"&gt; RssFlow &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;An intelligent RSS reader browser extension with AI-powered RSS summarization and multi-dimensional feed views. Supports DeepSeek model configuration for enhanced content understanding. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/refinereader/assets/refinereader-128.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://refinereader.cuihuaer.com"&gt; Refine Reader &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; A Chrome extension that uses AI (DeepSeek, OpenAI, etc.) to help you quickly understand and summarize articles. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/Hedwi/deepchat/refs/heads/main/images/logo.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://chromewebstore.google.com/detail/deepchat-power-of-deepsee/femhcibnncinlabdboehojdhfcihpkpl?hl=en"&gt; DeepChat &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;A Chrome extension that enables users to chat with DeepSeek by opening a sidebar on any website. In addition, it provides a floating menu underneath any selected text on any website that allows users to generate text summaries, check grammar issues, and translate content.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.typral.com/_next/image?url=%2Ffavicon.ico&amp;amp;w=96&amp;amp;q=75" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.typral.com/"&gt; Typral &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Fast AI writer assistant - Let AI help you quickly improve article, paper, text...&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://static.trancy.org/assets/trancy_logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.trancy.org/"&gt; Trancy &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Immersive bilingual translation, video bilingual subtitles, sentence/word selection translation extension&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://ziziyi.com/svg/anything_copilot.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/baotlake/anything-copilot"&gt; Anything Copilot &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Anything Copilot is a browser extension that enables seamless access to mainstream AI tools directly from your sidebar. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://cliprun.com/apple-touch-icon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://cliprun.com/"&gt; Cliprun &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Python code runner &amp;amp; playground. Right-click Python code on DeepSeek to run it instantly in your browser. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="http://cdn.docky.ai/assets/logo.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/docky-ai/README.md"&gt; Docky AI &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Docky AI is a powerful browser extension that allows you to have real-time conversations with multiple AI models through a sidebar. It supports simultaneous communication with multiple models and can assist you in reading web pages, writing, translating, and creating images&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="vscode"&gt;VS Code Extensions&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/continuedev/continue/raw/main/docs/static/img/logo.png?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/continue/README.md"&gt; Continue &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Continue is an open-source autopilot in IDE. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/cline/assets/favicon.png?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/cline/README.md"&gt; Cline &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Meet Cline, an AI assistant that can use your CLI aNd Editor. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/Sitoi/ai-commit/refs/heads/main/images/logo.png?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/Sitoi/ai-commit/raw/main/README.md"&gt; AI Commit &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Use AI to generate git commit messages in VS Code. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/titusTong/seekCodeCopilot/raw/main/assets/SeekCodeCopilotLogo.png?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/titusTong/seekCodeCopilot/raw/main/README.md"&gt; SeekCode Copilot &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; vscode intelligent coding assistant supports configuring locally deployed DeepSeek models &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/intellism/vscode-comment-translate/raw/master/doc/image/icon.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/intellism/vscode-comment-translate/raw/master/README.md"&gt; Comment Translation &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; This extension helps developers translate comments, strings, code hints, error messages, and variable names in their code. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="vs"&gt;Visual Studio Extensions&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://merryyellow.gallerycdn.vsassets.io/extensions/merryyellow/comment2gpt/2.0.5/1739475434185/Microsoft.VisualStudio.Services.Icons.Default" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://marketplace.visualstudio.com/items?itemName=MerryYellow.Comment2GPT"&gt; Comment2GPT &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Use OpenAI ChatGPT, Google Gemini, Anthropic Claude, DeepSeek and Ollama through your comments &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://merryyellow.gallerycdn.vsassets.io/extensions/merryyellow/codelens2gpt/2.0.5/1739475875714/Microsoft.VisualStudio.Services.Icons.Default" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://marketplace.visualstudio.com/items?itemName=MerryYellow.CodeLens2GPT"&gt; CodeLens2GPT &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Use OpenAI ChatGPT, Google Gemini, Anthropic Claude, DeepSeek and Ollama through the CodeLens &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://merryyellow.gallerycdn.vsassets.io/extensions/merryyellow/uca-lite/1.4.2/1739392928984/Microsoft.VisualStudio.Services.Icons.Default" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://marketplace.visualstudio.com/items?itemName=MerryYellow.UCA-Lite"&gt; Unity Code Assist Lite &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Code assistance for Unity scripts &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="neovim"&gt;neovim Extensions&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/user-attachments/assets/c316f70a-0a3c-4a32-b148-4df15e609acc" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/avante.nvim/README.md"&gt; avante.nvim &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; avante.nvim is an open-source autopilot in IDE. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/user-attachments/assets/d66dfc62-8e69-4b00-8549-d0158e48e2e0" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/llm.nvim/README.md"&gt; llm.nvim &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; A free large language model (LLM) plugin that allows you to interact with LLM in Neovim. Supports any LLM, such as Deepseek, GPT, GLM, Kimi or local LLMs (such as ollama). &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/user-attachments/assets/d66dfc62-8e69-4b00-8549-d0158e48e2e0" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/codecompanion.nvim/README.md"&gt; codecompanion.nvim &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; AI-powered coding, seamlessly in Neovim. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/user-attachments/assets/d66dfc62-8e69-4b00-8549-d0158e48e2e0" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/minuet-ai.nvim/README.md"&gt; minuet-ai.nvim &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Minuet offers code completion as-you-type from popular LLMs including Deepseek, OpenAI, Gemini, Claude, Ollama, Codestral, and more. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="jetbrains"&gt;JetBrains Extensions&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://plugins.jetbrains.com/files/21520/412905/icon/pluginIcon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://ide.unitmesh.cc/quick-start"&gt; AutoDev &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;‍AutoDev is an open-source AI coding assistant in JetBrain's IDE. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://plugins.jetbrains.com/files/21410/561595/icon/pluginIcon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://plugins.jetbrains.com/plugin/21410-onegai-copilot"&gt; Onegai Copilot &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Onegai Copilot is an AI coding assistant in JetBrain's IDE. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/continuedev/continue/raw/main/docs/static/img/logo.png?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/continue/README.md"&gt; Continue &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Continue is an open-source autopilot in IDE. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/a18792721831/studyplugin/535b9cab69da0f97b42dcaebb00bb0d4ed15c8a6/translate/src/main/resources/META-INF/pluginIcon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://plugins.jetbrains.com/plugin/18336-chinese-english-translate"&gt;Chinese-English Translate&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Chinese-English Translate is a multiple translation services in JetBrain's IDE. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://plugins.jetbrains.com/files/24851/659002/icon/pluginIcon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://plugins.jetbrains.com/plugin/24851-ai-git-commit"&gt;AI Git Commit&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; This plugin uses AI to automatically generate commit messages based on the changes in your code. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/YiiGuxing/TranslationPlugin/raw/master/pluginIcon.svg?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://intellij-translation.yiiguxing.top/#/en/"&gt;IntelliJ Translation Plugin&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; A translation plugin for IntelliJ-based IDEs that integrates multiple translation services, including OpenAI Translator (compatible with DeepSeek, Doubao, Ollama, etc.), allowing direct translation of code texts like comments and documentation within the IDE at any time. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="discord"&gt;Discord Bots&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://geneplore.com/img/geneplore_color_logo_circular.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="docs/Geneplore AI/README.md"&gt; Geneplore AI &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Geneplore AI runs one of the largest AI Discord bots, now with Deepseek v3 and R1. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="codeeditor"&gt;Native AI Code Editor&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://global.discourse-cdn.com/flex020/uploads/cursor1/original/2X/a/a4f78589d63edd61a2843306f8e11bad9590f0ca.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.cursor.com/"&gt; Cursor &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;‍The AI Code Editor based on VS Code&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://exafunction.github.io/public/images/windsurf/windsurf-app-icon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://codeium.com/windsurf"&gt; WindSurf &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Another AI Code Editor based on VS Code by Codeium&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="emacs"&gt;Emacs&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://upload.wikimedia.org/wikipedia/commons/0/08/EmacsIcon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/karthink/gptel"&gt; gptel &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;A simple LLM client for Emacs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://upload.wikimedia.org/wikipedia/commons/0/08/EmacsIcon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/milanglacier/minuet-ai.el"&gt; Minuet AI &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Dance with Intelligence in Your Code 💃&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="security"&gt;Security&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/lukehinds/awesome-deepseek-integration/raw/codegate/docs/codegate/assets/codegate.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/stacklok/codegate/"&gt; CodeGate &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; CodeGate: secure AI code generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/tencent/hunyuan.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/tencent/AI-Infra-Guard"&gt; AI-Infra-Guard &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Tencent's Hunyuan Security Team - AI infrastructure security assessment tool designed to discover and detect potential security risks in AI systems.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="providers"&gt;Providers&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/aimlapi/aimlapi_logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://docs.aimlapi.com/api-references/text-models-llm?utm_source=awesome-deepseek-integrations&amp;amp;utm_medium=github&amp;amp;utm_campaign=integration"&gt; AI/ML API &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; AI/ML API gives users enterprise-grade access to 200+ models with just one API. This includes Deepseek R1 and V3, alongside closed and open-source models. All at 99% uptime and with 24/7 human support.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span id="others"&gt;Others&lt;/span&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/icon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://mlflow.org/docs/latest/tracing/integrations/deepseek"&gt; MLflow &lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; Open-source MLOps / LLMOps platform for build, test, deploy, and monitor AI applications with DeepSeek. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="font-size: 64px"&gt;🤖&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/wangrongding/wechat-bot/raw/main/README.md"&gt; Wechat-Bot &lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; A wechat robot based on WeChaty combined with DeepSeek and other Ai services. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="font-size: 64px"&gt;🐠&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/lunary-ai/abso/raw/main/README.md"&gt; Abso &lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt; TypeScript SDK to interact with any LLM provider using the OpenAI format. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://i.imgur.com/IsQYInJ.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/djcopley/ShellOracle/"&gt; ShellOracle &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; A terminal utility for intelligent shell command generation. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://avatars.githubusercontent.com/u/178783630?s=200&amp;amp;v=4" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/bolna-ai/bolna/"&gt; Bolna &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Use DeepSeek as the LLM for conversational voice AI agents&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://pics.fatwang2.com/56912e614b35093426c515860f9f2234.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/fatwang2/siri-ultra"&gt; Siri Ultra &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; A GitHub project with 1000 stars, supporting internet connectivity, multi-turn conversations, and DeepSeek series models &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/c1e47b01-1766-4f7e-bfe6-ab3cb3991c30" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main/docs/siri_deepseek_shortcut"&gt; siri_deepseek_shortcut &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Siri equiped with the DeepSeek API &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/n8n-io/n8n/raw/master/assets/n8n-logo.png?raw=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/rubickecho/n8n-deepseek"&gt; n8n-nodes-deepseek &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; An N8N community node that supports direct integration with the DeepSeek API into workflows. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://framerusercontent.com/images/TSKshn2UFdTyvUi85EDMIXrXgs.png?scale-down-to=512" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/Portkey-AI/gateway"&gt; Portkey AI &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Portkey is a unified API for interacting with over 1600+ LLM models, offering advanced tools for control, visibility, and security in your DeepSeek apps. Python &amp;amp; Node SDK available. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://framerusercontent.com/images/8rF2JOaZ8l9AvM4H6ezliw44aI.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/BerriAI/litellm"&gt; LiteLLM &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format. Supports DeepSeek AI with cost tracking as well. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://i.postimg.cc/k5Z4YWjt/Screenshot-2025-01-23-at-6-08-01-PM.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/mem0ai/mem0"&gt; Mem0 &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Mem0 enhances AI assistants with an intelligent memory layer, enabling personalized interactions and continuous learning over time. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://simplismart-public-assets.s3.ap-south-1.amazonaws.com/logos/Logo+Icon+Light.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://simplismart.ai/"&gt; Simplismart AI &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Simplismart enables seamless GenAI deployments with the fastest inference for LLMs, Diffusion, and Speech models. Deploy Deepseek effortlessly on the Simplismart Cloud or with your own Cloud. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://www.promptfoo.dev/img/logo-panda.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/promptfoo/README.md"&gt; promptfoo &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Test and evaluate LLM prompts, including DeepSeek models. Compare different LLM providers, catch regressions, and evaluate responses. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/AndersonBY/deepseek-tokenizer"&gt; deepseek-tokenizer &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; An efficient and lightweight tokenization library for DeepSeek models, relying solely on the `tokenizers` library without heavy dependencies like `transformers`. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://langfuse.com/icon.svg?sanitize=true" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://langfuse.com/docs/integrations/deepseek"&gt; Langfuse &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Open-source LLM observability platform that helps teams collaboratively debug, analyze, and iterate on their DeepSeek applications. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; CR &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/hustcer/deepseek-review"&gt; deepseek-review &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; 🚀 Sharpen Your Code, Ship with Confidence – Elevate Your Workflow with Deepseek Code Review 🚀 &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="http://gptlocalhost.com/wp-content/uploads/2025/01/icon_1024.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://youtu.be/T1my2gqi-7Q"&gt; GPTLocalost &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Use DeepSeek-R1 in Microsoft Word Locally. No inference costs. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/suqicloud/wp-ai-chat/raw/main/ic_logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/suqicloud/wp-ai-chat"&gt; WordPress ai助手 &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Docking Deepseek api for WordPress site ai conversation assistant, post generation, post summary plugin. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="docs/ComfyUI-Copilot/assets/logo 2.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/AIDC-AI/ComfyUI-Copilot"&gt; ComfyUI-Copilot &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; An intelligent assistant built on the Comfy-UI framework that simplifies and enhances the AI algorithm debugging and deployment process through natural language interactions. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/Optima-CityU/llm4ad/raw/main/assets/figs/logo_short.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/Optima-CityU/llm4ad"&gt;LLM4AD&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/Optima-CityU/llm4ad"&gt;LLM4AD&lt;/a&gt; is a unified open-source Python-based Platform using Large Language Models (LLMs) for Automatic Algorithm Design (AD).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/JiauZhang/chatchat"&gt; chatchat &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Large Language Models Python API. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://serpapi.com/android-chrome-512x512.png" alt="Icon" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://serpapi.com/blog/connect-deepseek-api-with-the-internet-google-search-and-more/#connect-deepseek-with-google-search-result"&gt; SerpApi &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; Connect DeepSeek API with search results like Google. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;img src="https://github.com/yincongcyincong/telegram-deepseek-bot/raw/main/static/logo.png" alt="Icon" width="64" height="auto" /&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/yincongcyincong/telegram-deepseek-bot"&gt;telegram-deepseek-bot&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/yincongcyincong/telegram-deepseek-bot"&gt;telegram-deepseek-bot&lt;/a&gt; is a Telegram bot integrated with DeepSeek AI capabilities. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/eqld/nlsh"&gt;nlsh&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/eqld/nlsh"&gt;nlsh&lt;/a&gt; is an AI-powered CLI tool to generate context-aware shell commands with multi-backend LLM support. Supports shell-specific syntax, read-only system tools, and custom inference endpoints.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p style="text-align: right;"&gt;&lt;a href="https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/#table-of-contents"&gt;^ Back to Contents ^&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Star History&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#deepseek-ai/awesome-deepseek-integration&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=deepseek-ai/awesome-deepseek-integration&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>simstudioai/sim</title>
      <link>https://github.com/simstudioai/sim</link>
      <description>&lt;p&gt;Sim is an open-source AI agent workflow builder. Sim's interface is a lightweight, intuitive way to rapidly build and deploy LLMs that connect with your favorite tools.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/logo/reverse/text/large.png" alt="Sim Logo" width="500" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Build and deploy AI agent workflows in minutes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA" alt="Sim.ai" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Hr4UWYEcTT" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/simdotai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/simstudioai?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://docs.sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Docs-6F3DFA.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/demo.gif" alt="Sim Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Cloud-hosted: &lt;a href="https://sim.ai"&gt;sim.ai&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&amp;amp;logoColor=white" alt="Sim.ai" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Self-hosted: NPM Package&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx simstudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;→ &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Note&lt;/h4&gt; 
&lt;p&gt;Docker must be installed and running on your machine.&lt;/p&gt; 
&lt;h4&gt;Options&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-p, --port &amp;lt;port&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port to run Sim on (default &lt;code&gt;3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-pull&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Skip pulling latest Docker images&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Self-hosted: Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the application at &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Local Models with Ollama&lt;/h4&gt; 
&lt;p&gt;Run Sim with local AI models using &lt;a href="https://ollama.ai"&gt;Ollama&lt;/a&gt; - no external APIs required:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the model to download, then visit &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;. Add more models with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Self-hosted: Dev Containers&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open VS Code with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers"&gt;Remote - Containers extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open the project and click "Reopen in Container" when prompted&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;bun run dev:full&lt;/code&gt; in the terminal or use the &lt;code&gt;sim-start&lt;/code&gt; alias 
  &lt;ul&gt; 
   &lt;li&gt;This starts both the main application and the realtime socket server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Self-hosted: Manual Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt; runtime&lt;/li&gt; 
 &lt;li&gt;PostgreSQL 12+ with &lt;a href="https://github.com/pgvector/pgvector"&gt;pgvector extension&lt;/a&gt; (required for AI embeddings)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the &lt;code&gt;pgvector&lt;/code&gt; PostgreSQL extension.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/simstudioai/sim.git
cd sim
bun install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Set up PostgreSQL with pgvector:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You need PostgreSQL with the &lt;code&gt;vector&lt;/code&gt; extension for embedding support. Choose one option:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Using Docker (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Manual Installation&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install PostgreSQL 12+ and the pgvector extension&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/pgvector/pgvector#installation"&gt;pgvector installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Set up the database:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bunx drizzle-kit migrate 
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Start the development servers:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Recommended approach - run both servers together (from project root):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev:full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts both the main Next.js application and the realtime socket server required for full functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Alternative - run servers separately:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Next.js app (from project root):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Realtime socket server (from &lt;code&gt;apps/sim&lt;/code&gt; directory in a separate terminal):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
bun run dev:sockets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Copilot API Keys&lt;/h2&gt; 
&lt;p&gt;Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href="https://sim.ai"&gt;https://sim.ai&lt;/a&gt; → Settings → Copilot and generate a Copilot API key&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;COPILOT_API_KEY&lt;/code&gt; in your self-hosted environment to that value&lt;/li&gt; 
 &lt;li&gt;Host Sim on a publicly available DNS and set NEXT_PUBLIC_APP_URL and BETTER_AUTH_URL to that value (&lt;a href="https://ngrok.com/"&gt;ngrok&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: &lt;a href="https://nextjs.org/"&gt;Next.js&lt;/a&gt; (App Router)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: PostgreSQL with &lt;a href="https://orm.drizzle.team"&gt;Drizzle ORM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: &lt;a href="https://better-auth.com"&gt;Better Auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: &lt;a href="https://ui.shadcn.com/"&gt;Shadcn&lt;/a&gt;, &lt;a href="https://tailwindcss.com"&gt;Tailwind CSS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;State Management&lt;/strong&gt;: &lt;a href="https://zustand-demo.pmnd.rs/"&gt;Zustand&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flow Editor&lt;/strong&gt;: &lt;a href="https://reactflow.dev/"&gt;ReactFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://fumadocs.vercel.app/"&gt;Fumadocs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monorepo&lt;/strong&gt;: &lt;a href="https://turborepo.org/"&gt;Turborepo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Realtime&lt;/strong&gt;: &lt;a href="https://socket.io/"&gt;Socket.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Jobs&lt;/strong&gt;: &lt;a href="https://trigger.dev/"&gt;Trigger.dev&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p align="center"&gt;Made with ❤️ by the Sim Team&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>