<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Sun, 11 Jan 2026 01:31:43 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>xpipe-io/xpipe</title>
      <link>https://github.com/xpipe-io/xpipe</link>
      <description>&lt;p&gt;Access your entire server infrastructure from your local desktop&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://xpipe.io" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/img/banner.png" alt="XPipe Banner" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;&lt;/h1&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;XPipe is a connection hub that allows you to access your entire server infrastructure from your local desktop. It works on top of your installed command-line programs like SSH, docker, or others, and does not require any setup on your remote systems. It integrates with your favourite text editors, terminals, shells, VNC/RDP clients, password managers, and command-line tools. The platform is designed to be extensible, allowing anyone to add easily support for more tools or to implement custom functionality through a modular extension system.&lt;/p&gt; 
&lt;p&gt;It currently supports:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.xpipe.io/guide/ssh"&gt;SSH&lt;/a&gt; connections, config files, and tunnels&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.xpipe.io/guide/docker"&gt;Docker&lt;/a&gt; + compose, &lt;a href="https://docs.xpipe.io/guide/podman"&gt;Podman&lt;/a&gt;, &lt;a href="https://docs.xpipe.io/guide/lxc"&gt;LXD&lt;/a&gt;, and &lt;a href="https://docs.xpipe.io/guide/lxc"&gt;incus&lt;/a&gt; containers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.xpipe.io/guide/proxmox"&gt;Proxmox PVE&lt;/a&gt;, &lt;a href="https://docs.xpipe.io/guide/hyperv"&gt;Hyper-V&lt;/a&gt;, &lt;a href="https://docs.xpipe.io/guide/kvm"&gt;KVM&lt;/a&gt;, and &lt;a href="https://docs.xpipe.io/guide/vmware"&gt;VMware Player/Workstation/Fusion&lt;/a&gt; virtual machines&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.xpipe.io/guide/tailscale"&gt;Tailscale&lt;/a&gt;, &lt;a href="https://docs.xpipe.io/guide/netbird"&gt;Netbird&lt;/a&gt;, and &lt;a href="https://docs.xpipe.io/guide/teleport"&gt;Teleport&lt;/a&gt; connections&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.xpipe.io/guide/aws"&gt;AWS&lt;/a&gt; and &lt;a href="https://docs.xpipe.io/guide/hcloud"&gt;Hetzner Cloud&lt;/a&gt; servers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.xpipe.io/guide/rdp"&gt;RDP&lt;/a&gt; and &lt;a href="https://docs.xpipe.io/guide/vnc"&gt;VNC&lt;/a&gt; connections&lt;/li&gt; 
 &lt;li&gt;Windows Subsystem for Linux, Cygwin, and MSYS2 environments&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.xpipe.io/guide/kubernetes"&gt;Kubernetes&lt;/a&gt; clusters, pods, and containers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.xpipe.io/guide/pssession"&gt;Powershell Remote Sessions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://docs.xpipe.io/guide/ssh" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/ssh.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/docker" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/docker.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/docker#compose" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/compose.png" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/lxc" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/lxd.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/podman" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/podman.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/aws" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/aws.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/kubernetes" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/k8s.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/proxmox" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/proxmox.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/vmware" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/vmware.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/kvm" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/virsh.png" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/tailscale" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/tailscale.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/netbird" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/netbird.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/hcloud" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/hetzner.svg?sanitize=true" width="40" height="40" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/#"&gt;&lt;img width="10" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.xpipe.io/guide/teleport" target="_blank" rel="noopener"&gt; &lt;img src="https://github.com/xpipe-io/.github/raw/main/icons/teleport.png" width="40" height="40" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Connection hub&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easily establish and manage connections to remote systems from a central hub interface&lt;/li&gt; 
 &lt;li&gt;Organize all your connections in hierarchical categories to maintain an overview over hundreds of connections.&lt;/li&gt; 
 &lt;li&gt;Create custom shell login environments to instantly jump into a properly set up shell for every use case&lt;/li&gt; 
 &lt;li&gt;Quickly perform various commonly used actions like starting/stopping systems, establishing tunnels, and more&lt;/li&gt; 
 &lt;li&gt;Create desktop shortcuts and macros that automatically open remote connections in your terminal without having to open any GUI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/xpipe-io/.github/raw/main/img/hub_shadow.png" alt="Connection hub" /&gt;&lt;/p&gt; 
&lt;h2&gt;File browser&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interact with the file system of any remote system using a workflow optimized for professionals&lt;/li&gt; 
 &lt;li&gt;Utilize your entire arsenal of locally installed programs to open and edit remote files&lt;/li&gt; 
 &lt;li&gt;Dynamically elevate sessions with sudo when required without having to restart the session&lt;/li&gt; 
 &lt;li&gt;Seamlessly transfer files from and to your system desktop environment&lt;/li&gt; 
 &lt;li&gt;Work and perform transfers on multiple systems at the same time with the built-in tabbed multitasking&lt;/li&gt; 
 &lt;li&gt;Quickly open a terminal session into any directory in your favourite terminal emulator&lt;/li&gt; 
 &lt;li&gt;Customize every action through the scripting system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/xpipe-io/.github/raw/main/img/browser_shadow.png" alt="Browser" /&gt;&lt;/p&gt; 
&lt;h2&gt;Terminal launcher&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Launches you into a shell session in your favourite terminal with one click. Automatically fills password prompts and more&lt;/li&gt; 
 &lt;li&gt;Comes with support for all commonly used terminal emulators across all operating systems&lt;/li&gt; 
 &lt;li&gt;Supports opening custom terminal emulators as well via a custom command-line spec&lt;/li&gt; 
 &lt;li&gt;Works with all command shells such as bash, zsh, fish, cmd, PowerShell, and more, locally and remote&lt;/li&gt; 
 &lt;li&gt;Integrates with multiplexers like tmux and zellij, plus prompts like starship and oh-my-zsh&lt;/li&gt; 
 &lt;li&gt;Supports opening multiple sessions in split terminal pane views&lt;/li&gt; 
 &lt;li&gt;Connects to a system while the terminal is still starting up, allowing for faster connections than otherwise possible&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/xpipe-io/.github/raw/main/img/terminal_shadow.png" alt="Terminal" /&gt;&lt;/p&gt; 
&lt;h2&gt;Versatile scripting system&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create reusable simple shell scripts, templates, and groups to run on connected remote systems&lt;/li&gt; 
 &lt;li&gt;Automatically make your scripts available in the PATH on any remote system without any setup&lt;/li&gt; 
 &lt;li&gt;Setup shell init environments for connections to fully customize your work environment for every purpose&lt;/li&gt; 
 &lt;li&gt;Open custom shells and custom remote connections by providing your own commands&lt;/li&gt; 
 &lt;li&gt;Use custom scripts in the file browser&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/xpipe-io/.github/raw/main/img/scripts_shadow.png" alt="scripts" /&gt;&lt;/p&gt; 
&lt;h2&gt;And much more&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can synchronize your vault across multiple systems and share it with other team members via your own self-hosted git repository&lt;/li&gt; 
 &lt;li&gt;All data is stored exclusively on your systems in a cryptographically secure vault. You can also choose to increase security by using a custom master passphrase for further encryption&lt;/li&gt; 
 &lt;li&gt;XPipe is able to retrieve secrets automatically from your installed password manager and doesn't have store secrets itself&lt;/li&gt; 
 &lt;li&gt;There are no servers involved, all your information stays on your systems. The XPipe application does not send any personal or sensitive information to outside services&lt;/li&gt; 
 &lt;li&gt;XPipe has an integrated MCP server that you can enable. This allows you to easily use all of XPipe's features from an AI agent&lt;/li&gt; 
 &lt;li&gt;Run coherent desktop applications remotely via the uniform desktop application system in XPipe for RDP, VNC, and X11 forwards&lt;/li&gt; 
 &lt;li&gt;Securely tunnel and automatically open remote services with one click with the services integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Downloads&lt;/h1&gt; 
&lt;p&gt;Note that this is a desktop application that should be run on your local desktop workstation, not on any server or containers. It will be able to connect to your server infrastructure from there.&lt;/p&gt; 
&lt;p&gt;For a full reference and instructions, see the &lt;a href="https://docs.xpipe.io/guide/installation"&gt;installation docs&lt;/a&gt; and &lt;a href="https://docs.xpipe.io/guide/managed-installation"&gt;managed installation docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Windows&lt;/h2&gt; 
&lt;p&gt;Installers are the easiest way to get started and come with an optional automatic update functionality:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-windows-x86_64.msi"&gt;Windows .msi Installer (x86-64)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-windows-arm64.msi"&gt;Windows .msi Installer (ARM 64)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you don't like installers, you can also use a portable version that is packaged as an archive:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-windows-x86_64.zip"&gt;Windows .zip Portable (x86-64)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-windows-arm64.zip"&gt;Windows .zip Portable (ARM 64)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Alternatively, you can also use the following package managers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://community.chocolatey.org/packages/xpipe"&gt;choco&lt;/a&gt; to install it with &lt;code&gt;choco install xpipe&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/winget-cli"&gt;winget&lt;/a&gt; to install it with &lt;code&gt;winget install xpipe-io.xpipe --source winget&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/winget-cli"&gt;scoop&lt;/a&gt; to install it with &lt;code&gt;scoop install extras/xpipe&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;macOS&lt;/h2&gt; 
&lt;p&gt;Installers are the easiest way to get started and come with an optional automatic update functionality:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-macos-x86_64.pkg"&gt;MacOS .pkg Installer (x86-64)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-macos-arm64.pkg"&gt;MacOS .pkg Installer (ARM 64)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you don't like installers, you can also use a portable version that is packaged as an archive:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-macos-x86_64.dmg"&gt;MacOS .dmg Portable (x86-64)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-macos-arm64.dmg"&gt;MacOS .dmg Portable (ARM 64)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Alternatively, you can also use &lt;a href="https://github.com/xpipe-io/homebrew-tap"&gt;Homebrew&lt;/a&gt; to install XPipe with &lt;code&gt;brew install --cask xpipe-io/tap/xpipe&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Linux&lt;/h2&gt; 
&lt;p&gt;You can install XPipe the fastest by pasting the installation command into your terminal. This will perform the setup automatically. The script supports installation via &lt;code&gt;apt&lt;/code&gt;, &lt;code&gt;dnf&lt;/code&gt;, &lt;code&gt;yum&lt;/code&gt;, &lt;code&gt;zypper&lt;/code&gt;, &lt;code&gt;rpm&lt;/code&gt;, and &lt;code&gt;pacman&lt;/code&gt; on Linux:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bash &amp;lt;(curl -sL https://github.com/xpipe-io/xpipe/raw/master/get-xpipe.sh)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Of course, there are also other installation methods available.&lt;/p&gt; 
&lt;h3&gt;Debian-based distros&lt;/h3&gt; 
&lt;p&gt;The following debian installers are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-x86_64.deb"&gt;Linux .deb Installer (x86-64)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-arm64.deb"&gt;Linux .deb Installer (ARM 64)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that you should use apt to install the package with &lt;code&gt;sudo apt install &amp;lt;file&amp;gt;&lt;/code&gt; as other package managers, for example dpkg, are not able to resolve and install any dependency packages.&lt;/p&gt; 
&lt;h3&gt;RHEL-based distros&lt;/h3&gt; 
&lt;p&gt;The rpm releases are signed with the GPG key &lt;a href="https://xpipe.io/signatures/crschnick.asc"&gt;https://xpipe.io/signatures/crschnick.asc&lt;/a&gt;. You can import it via &lt;code&gt;rpm --import https://xpipe.io/signatures/crschnick.asc&lt;/code&gt; to allow your rpm-based package manager to verify the release signature.&lt;/p&gt; 
&lt;p&gt;The following rpm installers are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-x86_64.rpm"&gt;Linux .rpm Installer (x86-64)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-arm64.rpm"&gt;Linux .rpm Installer (ARM 64)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Arch&lt;/h3&gt; 
&lt;p&gt;There is an official &lt;a href="https://aur.archlinux.org/packages/xpipe"&gt;AUR package&lt;/a&gt; available that you can either install manually or via an AUR helper such as with &lt;code&gt;yay -S xpipe&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;AppImages&lt;/h3&gt; 
&lt;p&gt;Alternatively, there are also AppImages available. These can be useful if you are using an immutable distro.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-x86_64.AppImage"&gt;Linux .AppImage Portable (x86-64)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-arm64.AppImage"&gt;Linux .AppImage Portable (ARM 64)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;NixOS&lt;/h3&gt; 
&lt;p&gt;There's an official &lt;a href="https://search.nixos.org/packages?channel=unstable&amp;amp;show=xpipe&amp;amp;from=0&amp;amp;size=50&amp;amp;sort=relevance&amp;amp;type=packages&amp;amp;query=xpipe"&gt;xpipe nixpkg&lt;/a&gt; available that you can install with &lt;code&gt;nix-env -iA nixos.xpipe&lt;/code&gt; on x86_64 Linux systems. This package is however usually not up to date.&lt;/p&gt; 
&lt;p&gt;There is also a custom repository that contains the latest up-to-date release flakes for Linux and macOS systems: &lt;a href="https://github.com/xpipe-io/nixpkg"&gt;https://github.com/xpipe-io/nixpkg&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Tarball&lt;/h3&gt; 
&lt;p&gt;In case you prefer to use an archive version that you can extract anywhere, you can use these:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-x86_64.tar.gz"&gt;Linux .tar.gz Portable (x86-64)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-arm64.tar.gz"&gt;Linux .tar.gz Portable (ARM 64)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Docker container&lt;/h3&gt; 
&lt;p&gt;XPipe is a desktop application first and foremost. It requires a full desktop environment to function with various installed applications such as terminals, editors, shells, CLI tools, and more. So there is no true web-based interface for XPipe.&lt;/p&gt; 
&lt;p&gt;Since it might make sense however to access your XPipe environment from the web, there is also a so-called webtop docker container image for XPipe. &lt;a href="https://github.com/xpipe-io/xpipe-webtop"&gt;XPipe Webtop&lt;/a&gt; is a web-based desktop environment that can be run in a container and accessed from a browser via KasmVNC. The desktop environment comes with XPipe and various terminals and editors preinstalled and configured. This image is also available for Kasm Workspaces in the &lt;a href="https://github.com/xpipe-io/kasm-registry"&gt;XPipe Kasm Registry&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Further information&lt;/h1&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for details.&lt;/p&gt; 
&lt;img src="https://contrib.rocks/image?repo=xpipe-io/xpipe" alt="contrib.rocks image" /&gt; 
&lt;h2&gt;Open source model&lt;/h2&gt; 
&lt;p&gt;XPipe follows an open core model, which essentially means that the main application is open source while certain other components are not. This mainly concerns the features only available in the homelab/professional plan and the shell handling library implementation. Furthermore, some CI pipelines and tests that run on private servers are also not included in the open repository.&lt;/p&gt; 
&lt;p&gt;The distributed XPipe application consists out of two parts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The open-source core that you can find this repository. It is licensed under the &lt;a href="https://raw.githubusercontent.com/xpipe-io/xpipe/master/LICENSE.md"&gt;Apache License 2.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The closed-source extensions, mostly for homelab/professional plan features, which are not included in this repository&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additional features are available in the homelab/professional plan. For more details see &lt;a href="https://xpipe.io/pricing"&gt;https://xpipe.io/pricing&lt;/a&gt;. If your enterprise puts great emphasis on having access to the full source code, there are also full source-available enterprise options available.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;You can find the documentation at &lt;a href="https://docs.xpipe.io"&gt;https://docs.xpipe.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Discord&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/8y89vS8cRb"&gt;&lt;img src="https://discordapp.com/api/guilds/979695018782646285/widget.png?style=banner2" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MiroMindAI/MiroThinker</title>
      <link>https://github.com/MiroMindAI/MiroThinker</link>
      <description>&lt;p&gt;MiroThinker is an open-source search agent model, built for tool-augmented reasoning and real-world information seeking, aiming to match the deep research experience of OpenAI Deep Research and Gemini Deep Research.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/assets/miro_thinker.png" width="55%" alt="MiroThinker" /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://dr.miromind.ai/"&gt;&lt;img src="https://img.shields.io/badge/Demo-FFB300?style=for-the-badge&amp;amp;logo=airplayvideo&amp;amp;logoColor=white" alt="DEMO" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v15"&gt;&lt;img src="https://img.shields.io/badge/Models-5EDDD2?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="MODELS" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2511.11793"&gt;&lt;img src="https://img.shields.io/badge/Paper-B31B1B?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white" alt="Paper" /&gt;&lt;/a&gt; &lt;a href="https://miromind.ai/#blog"&gt;&lt;img src="https://img.shields.io/badge/Blog-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="Blog" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"&gt;&lt;img src="https://img.shields.io/badge/Data-0040A1?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="DATA" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/MiroMindAI"&gt;&lt;img src="https://img.shields.io/badge/Github-24292F?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GITHUB" /&gt;&lt;/a&gt; &lt;a href="https://miromind.ai/"&gt;&lt;img src="https://img.shields.io/badge/Website-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="WEBSITE" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/GPqEnkzQZd"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="DISCORD" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/refs/heads/main/assets/miromind_wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white" alt="WeChat" /&gt;&lt;/a&gt; &lt;a href="https://www.xiaohongshu.com/user/profile/5e353bd80000000001000239"&gt;&lt;img src="https://img.shields.io/badge/RedNote-FF2442?style=for-the-badge&amp;amp;logo=revoltdotchat&amp;amp;logoColor=white" alt="RedNote" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üöÄ &lt;a href="https://dr.miromind.ai/"&gt;Try our Demo!&lt;/a&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;MiroThinker&lt;/strong&gt; is MiroMind's Flagship Research Agent Model. It is an open-source search model designed to advance tool-augmented reasoning and information-seeking capabilities, enabling complex real-world research workflows across diverse challenges.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The project currently comprises four key components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí° &lt;strong&gt;MiroThinker&lt;/strong&gt;: An open-source search &lt;strong&gt;model&lt;/strong&gt; that natively supports tool-assisted reasoning, achieving leading performance across multiple benchmarks (e.g., HLE, HLE-Text-2158, HLE-Text-500, BrowseComp, BrowseComp-ZH, GAIA, XBench-DeepSearch, FutureX, and Frames). See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-quick-start"&gt;Quick Start&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;MiroFlow&lt;/strong&gt;: An open-source research agent framework that offers reproducible state-of-the-art performance across multiple benchmarks. See &lt;a href="https://github.com/MiroMindAI/MiroFlow"&gt;MiroFlow&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;MiroVerse&lt;/strong&gt;: A premium open-source training dataset with 147k samples supporting research agent training. See &lt;a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"&gt;MiroVerse&lt;/a&gt; on HuggingFace.&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;MiroTrain / MiroRL&lt;/strong&gt;: Training infrastructure that supports stable and efficient training for research agent models. See &lt;a href="https://github.com/MiroMindAI/MiroTrain"&gt;MiroTrain&lt;/a&gt; and &lt;a href="https://github.com/MiroMindAI/MiroRL"&gt;MiroRL&lt;/a&gt; for details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìã Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üì∞ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-news--updates"&gt;News &amp;amp; Updates&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìù &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-performance-on-benchmarks"&gt;Performance on Benchmarks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìä &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-benchmark-evaluation"&gt;Benchmark Evaluation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî¨ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-trace-collection"&gt;Trace Collection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ùì &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-faq--troubleshooting"&gt;FAQ &amp;amp; Troubleshooting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìÑ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üôè &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì∞ News &amp;amp; Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;[2026-01-05]&lt;/strong&gt; üéâüéâ We release &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v15"&gt;MiroThinker-v1.5&lt;/a&gt;, a world-leading open-source search agent. &lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-30B"&gt;MiroThinker-v1.5-30B&lt;/a&gt; surpasses Kimi-K2-Thinking on BrowseComp-ZH at much lower cost, using only 1/30 of the parameters. &lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-235B"&gt;MiroThinker-v1.5-235B&lt;/a&gt; scores 39.2% on HLE-Text, 69.8% on BrowseComp, 71.5% on BrowseComp-ZH, and 80.8% on GAIA-Val-165, setting a new state-of-the-art among search agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-11-13]&lt;/strong&gt; üéâ &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v10"&gt;MiroThinker-v1.0&lt;/a&gt; is now released! Introducing &lt;strong&gt;interactive scaling&lt;/strong&gt; as a third dimension of performance improvement, MiroThinker v1.0 supports 256K context window and up to 600 tool calls per task. Available in 8B, 30B, and 72B parameter scales, achieving 37.7%, 47.1%, 55.6%, and 81.9% on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Text-103, respectively. See &lt;a href="https://arxiv.org/abs/2511.11793"&gt;Technical Report&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-09-11]&lt;/strong&gt; MiroThinker-72B-Preview ranked 4th in this week's FutureX benchmark. See &lt;a href="https://futurex-ai.github.io/"&gt;FutureX&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìú Click to expand older updates&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-09-08]&lt;/strong&gt; &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v02"&gt;MiroThinker-v0.2&lt;/a&gt; is now released, achieving open-source SOTA performance across multiple benchmarks, including HLE (17.8%), HLE-Text-Only (19.1%), BrowseComp-EN (17.2%), BrowseComp-ZH (29.4%), XBench-DeepSearch (56.0%), and Frames (74.8%).&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-09-07]&lt;/strong&gt; We supported more benchmarks, including &lt;a href="https://arxiv.org/abs/2504.19314"&gt;BrowseComp-ZH&lt;/a&gt;, &lt;a href="https://xbench.org/agi/aisearch"&gt;XBench-DeepSearch&lt;/a&gt;, and &lt;a href="https://futurex-ai.github.io/"&gt;FutureX&lt;/a&gt;. We plan to add more benchmarks in the future.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-08-22]&lt;/strong&gt; Introducing streamlined deployment options for MiroThinker models with optimized resource usage and faster startup times. Experience the interactive demo: &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/apps/gradio-demo"&gt;üöÄ Try Gradio Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-08-08]&lt;/strong&gt; &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v01-689301b6d0563321862d44a1"&gt;MiroThinker-v0.1&lt;/a&gt; released. Models, framework, and data are now fully open-sourced!&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üìù Introduction&lt;/h2&gt; 
&lt;h3&gt;MiroThinker-v1.5&lt;/h3&gt; 
&lt;p&gt;MiroThinker v1.5 is the world-leading open-source search agent that advances tool-augmented reasoning through &lt;strong&gt;interactive scaling&lt;/strong&gt; ‚Äî training the model to handle deeper and more frequent agent-environment interactions as a third dimension of performance improvement, beyond model size and context length.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/mirothinker_v1.5_framework.png" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ MiroThinker v1.5 supports a 256K context window, long-horizon reasoning, and deep multi-step analysis.&lt;/li&gt; 
 &lt;li&gt;üîß Handles up to 400 tool calls per task ‚Äî a substantial improvement over previous open-source research agents.&lt;/li&gt; 
 &lt;li&gt;üì¶ Released in 30B and 235B parameter scales, accompanied by a comprehensive suite of tools and workflows to flexibly support diverse research settings and compute budgets.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;Model Name&lt;/th&gt; 
    &lt;th align="center"&gt;Base Model&lt;/th&gt; 
    &lt;th align="center"&gt;Max Context&lt;/th&gt; 
    &lt;th align="center"&gt;Max Tool Calls&lt;/th&gt; 
    &lt;th align="center"&gt;HF Link&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;MiroThinker-v1.5-30B&lt;/td&gt; 
    &lt;td align="center"&gt;Qwen3-30B-A3B-Thinking-2507&lt;/td&gt; 
    &lt;td align="center"&gt;256K&lt;/td&gt; 
    &lt;td align="center"&gt;400&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-30B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;MiroThinker-v1.5-235B&lt;/td&gt; 
    &lt;td align="center"&gt;Qwen3-235B-A22B-Thinking-2507&lt;/td&gt; 
    &lt;td align="center"&gt;256K&lt;/td&gt; 
    &lt;td align="center"&gt;400&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-235B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;MiroThinker v1.5 demonstrates strong general-research performance across a broad range of benchmarks, achieving&amp;nbsp;39.2%,&amp;nbsp;69.8%, 71.5%, and&amp;nbsp;80.8%&amp;nbsp;on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Val-165, respectively. These results surpass previous open-source agents and set the new world-leading BrowseComp performance.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/mirothinker_v1.5_browsecomp.png" alt="image" /&gt;&lt;/p&gt; 
&lt;h3&gt;MiroThinker-v1.0&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v1.0 details&lt;/summary&gt; 
 &lt;p&gt;Unlike previous agents that scale only model size or context length, MiroThinker v1.0 introduces &lt;strong&gt;interactive scaling&lt;/strong&gt; at the model level, systematically training the model to handle deeper and more frequent agent‚Äìenvironment interactions as a third dimension of performance improvement. Interactive scaling leverages environment feedback and external information acquisition to correct errors and refine trajectories.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v1.0_Overall.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;‚ú® Key Features&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üöÄ &lt;strong&gt;256K Context Window&lt;/strong&gt;: Supports long-horizon reasoning and deep multi-step analysis&lt;/li&gt; 
  &lt;li&gt;üîß &lt;strong&gt;600 Tool Calls&lt;/strong&gt;: Handles up to 600 tool calls per task ‚Äî a substantial improvement over previous open-source research agents&lt;/li&gt; 
  &lt;li&gt;üì¶ &lt;strong&gt;Multiple Scales&lt;/strong&gt;: Released in 8B, 30B, and 72B parameter scales, accompanied by a comprehensive suite of tools and workflows to flexibly support diverse research settings and compute budgets&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="center"&gt;Model Name&lt;/th&gt; 
     &lt;th align="center"&gt;Base Model&lt;/th&gt; 
     &lt;th align="center"&gt;Max Context&lt;/th&gt; 
     &lt;th align="center"&gt;Max Tool Calls&lt;/th&gt; 
     &lt;th align="center"&gt;HF Link&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-v1.0-8B&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;256K&lt;/td&gt; 
     &lt;td align="center"&gt;600&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-8B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-v1.0-30B&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-30B-A3B-Thinking-2507&lt;/td&gt; 
     &lt;td align="center"&gt;256K&lt;/td&gt; 
     &lt;td align="center"&gt;600&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-30B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-v1.0-72B&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen2.5-72B-Instruct&lt;/td&gt; 
     &lt;td align="center"&gt;256K&lt;/td&gt; 
     &lt;td align="center"&gt;600&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-72B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;p&gt;MiroThinker v1.0 demonstrates strong general-research performance across a broad range of benchmarks, achieving &lt;strong&gt;37.7%&lt;/strong&gt;, &lt;strong&gt;47.1%&lt;/strong&gt;, &lt;strong&gt;55.6%&lt;/strong&gt;, and &lt;strong&gt;81.9%&lt;/strong&gt; on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Text-103, respectively. These results surpass previous open-source agents and narrow the gap with commercial counterparts such as &lt;strong&gt;GPT-5-high&lt;/strong&gt;.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v1.0_Performance_1.png" width="100%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.2&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.2 details&lt;/summary&gt; 
 &lt;p&gt;In this new version, we introduced three key improvements:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üìö &lt;strong&gt;Richer training data&lt;/strong&gt; from both English and Chinese sources, yielding significant gains in benchmark performance and generalization&lt;/li&gt; 
  &lt;li&gt;üéØ &lt;strong&gt;Unified DPO training&lt;/strong&gt; with a single preference dataset across all models&lt;/li&gt; 
  &lt;li&gt;üìè &lt;strong&gt;Extended context length&lt;/strong&gt; from 40k to 64k for more challenging multi-turn tool-use tasks&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Compared to v0.1, MiroThinker v0.2 delivers consistent gains across benchmarks. For example, scores improved from &lt;strong&gt;57.3 ‚Üí 64.1&lt;/strong&gt; on &lt;strong&gt;GAIA-Text-103&lt;/strong&gt; and from &lt;strong&gt;17.0 ‚Üí 29.4&lt;/strong&gt; on &lt;strong&gt;BrowseComp-ZH&lt;/strong&gt;, reflecting substantial advancements in the model‚Äôs general research agent capabilities.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="center"&gt;Model Name&lt;/th&gt; 
     &lt;th align="center"&gt;Base Model&lt;/th&gt; 
     &lt;th align="center"&gt;Max Context&lt;/th&gt; 
     &lt;th align="center"&gt;HF Link&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-4B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-4B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-4B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-4B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-4B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-4B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.1&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.1 details&lt;/summary&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/assets/gaia_text_103.png" width="98%" alt="MiroFlow Performance on GAIA-Validation" /&gt; 
  &lt;p&gt;&lt;strong&gt;Performance of Open-Source Models on GAIA-Validation Benchmark.&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;We have released the &lt;strong&gt;MiroThinker v0.1&lt;/strong&gt; series, including both SFT and DPO variants at parameter scales of &lt;strong&gt;8B&lt;/strong&gt;, &lt;strong&gt;14B&lt;/strong&gt;, and &lt;strong&gt;32B&lt;/strong&gt;. Notably, MiroThinker v0.1 achieves &lt;strong&gt;state-of-the-art performance&lt;/strong&gt; among open-source models on the &lt;a href="https://huggingface.co/datasets/gaia-benchmark/GAIA"&gt;GAIA benchmark&lt;/a&gt;, a rigorous evaluation suite for advanced agentic capabilities, demonstrating its strength in long-context, decision-intensive, and real-world task scenarios.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="center"&gt;Model Name&lt;/th&gt; 
     &lt;th align="center"&gt;Base Model&lt;/th&gt; 
     &lt;th align="center"&gt;Max Context&lt;/th&gt; 
     &lt;th align="center"&gt;HF Link&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-SFT-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-SFT-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-DPO-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-DPO-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-SFT-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-SFT-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-DPO-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-DPO-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-SFT-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-SFT-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-DPO-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-DPO-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ú® Key Features&lt;/h2&gt; 
&lt;h3&gt;ü§ñ &lt;strong&gt;MiroThinker-Optimized Framework&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîì &lt;strong&gt;Fully Open-Source Agent Framework&lt;/strong&gt;: Complete transparency with open framework and open models&lt;/li&gt; 
 &lt;li&gt;üîó &lt;strong&gt;Tool Integration&lt;/strong&gt;: Seamless integration with external tools and APIs&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;Trace Collection&lt;/strong&gt;: Comprehensive logging and analysis of agent interactions with elapsed time and estimated completion time displayed in minutes. Ready for SFT and DPO&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Benchmark Evaluation&lt;/strong&gt;: Extensive testing across multiple benchmark datasets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìä &lt;strong&gt;Comprehensive Benchmark Suite&lt;/strong&gt;&lt;/h3&gt; 
&lt;details open&gt; 
 &lt;summary&gt;üìã Click to expand benchmark list&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;GAIA Validation&lt;/strong&gt;: A benchmark for General AI Assistants. (&lt;a href="https://arxiv.org/abs/2311.12983"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GAIA-Text-103&lt;/strong&gt;: A subset of GAIA Validation for text-only tasks. (&lt;a href="https://arxiv.org/abs/2505.22648"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HLE&lt;/strong&gt;: Humanity's Last Exam. (&lt;a href="https://arxiv.org/abs/2501.14249"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HLE-Text-2158&lt;/strong&gt;: A subset of HLE for text-only tasks. (&lt;a href="https://arxiv.org/abs/2501.14249"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HLE-Text-500&lt;/strong&gt;: A subset of HLE for text-only tasks, created by &lt;a href="https://arxiv.org/pdf/2504.21776"&gt;WebThinker&lt;/a&gt;. (&lt;a href="https://arxiv.org/pdf/2504.21776"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;BrowseComp-EN&lt;/strong&gt;: Web browsing and comprehension tasks. (&lt;a href="https://arxiv.org/abs/2504.12516"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;BrowseComp-ZH&lt;/strong&gt;: A Chinese version of BrowseComp. (&lt;a href="https://arxiv.org/abs/2504.19314"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;WebWalkerQA&lt;/strong&gt;: Web navigation and question answering. (&lt;a href="https://arxiv.org/abs/2501.07572"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Frames&lt;/strong&gt;: Factuality, Retrieval, And reasoning MEasurement Set. (&lt;a href="https://arxiv.org/abs/2409.12941"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;XBench-DeepSearch&lt;/strong&gt;: A benchmark for deep research agents. (&lt;a href="https://xbench.org/agi/aisearch"&gt;website&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;FutureX&lt;/strong&gt;: A live benchmark designed for predicting unknown future. (&lt;a href="https://futurex-ai.github.io/"&gt;website&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;SEAL-0&lt;/strong&gt;: A benchmark for evaluating LLMs on conflicting-evidence web questions. (&lt;a href="https://arxiv.org/abs/2506.01062"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;AIME2025&lt;/strong&gt;: American Invitational Mathematics Examination 2025. (&lt;a href="https://artificialanalysis.ai/evaluations/aime-2025"&gt;website&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;DeepSearchQA&lt;/strong&gt;: Google's Deep Search Question Answering benchmark. (&lt;a href="https://arxiv.org/abs/2505.20827"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üìà Performance on Benchmarks&lt;/h2&gt; 
&lt;h3&gt;MiroThinker-v1.5&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To prevent potential information leakage (e.g., searching benchmark answers from HuggingFace), access to HuggingFace has been explicitly disabled in these tools.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We further perform canary string testing on the tool outputs of all trajectories and disregard any trajectory found to be contaminated, treating it as an incorrect answer.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div&gt; 
 &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/mirothinker_v1.5_performance.png" width="100%" alt="MiroThinker" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;MiroThinker-v1.0&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v1.0 details&lt;/summary&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://github.com/user-attachments/assets/108a2105-4e1d-499e-a001-4713a03fd8ac" width="100%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.2&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.2 details&lt;/summary&gt; 
 &lt;h4&gt;Comparison with SOTA Research Agents&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v0.2_Performance_2.png" width="90%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;GAIA Benchmark&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v0.2_Performance_1.png" width="80%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.1&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.1 details&lt;/summary&gt; 
 &lt;h4&gt;GAIA Benchmark&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;&lt;strong&gt;Method&lt;/strong&gt;&lt;/th&gt; 
     &lt;th align="center"&gt;Text-103&lt;br /&gt;Best Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;Text-103&lt;br /&gt;Pass@1 (Avg@8)&lt;/th&gt; 
     &lt;th align="center"&gt;Val-165&lt;br /&gt;Best Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;Val-165&lt;br /&gt;Pass@1 (Avg@8)&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;üîπ‚Äî‚Äî 7B/8B Models ‚Äî‚Äî&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Search-o1-7B&lt;/td&gt; 
     &lt;td align="center"&gt;17.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;R1-Searcher-7B&lt;/td&gt; 
     &lt;td align="center"&gt;20.4&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-7B&lt;/td&gt; 
     &lt;td align="center"&gt;31.0&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-7B&lt;/td&gt; 
     &lt;td align="center"&gt;37.9&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;CK-Pro-8B&lt;/td&gt; 
     &lt;td align="center"&gt;40.3&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;32.7&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;44.7&lt;/td&gt; 
     &lt;td align="center"&gt;40.1&lt;/td&gt; 
     &lt;td align="center"&gt;34.6&lt;/td&gt; 
     &lt;td align="center"&gt;31.8&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;46.6&lt;/td&gt; 
     &lt;td align="center"&gt;42.1&lt;/td&gt; 
     &lt;td align="center"&gt;37.6&lt;/td&gt; 
     &lt;td align="center"&gt;33.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;46.6&lt;/td&gt; 
     &lt;td align="center"&gt;44.8&lt;/td&gt; 
     &lt;td align="center"&gt;37.0&lt;/td&gt; 
     &lt;td align="center"&gt;35.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;50.5&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;46.7&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;38.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;35.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;üîπ‚Äî‚Äî 14B Models ‚Äî‚Äî&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-14B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;47.6&lt;/td&gt; 
     &lt;td align="center"&gt;44.4&lt;/td&gt; 
     &lt;td align="center"&gt;37.0&lt;/td&gt; 
     &lt;td align="center"&gt;34.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;49.5&lt;/td&gt; 
     &lt;td align="center"&gt;47.5&lt;/td&gt; 
     &lt;td align="center"&gt;41.8&lt;/td&gt; 
     &lt;td align="center"&gt;39.8&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-14B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;46.6&lt;/td&gt; 
     &lt;td align="center"&gt;42.4&lt;/td&gt; 
     &lt;td align="center"&gt;39.2&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;52.4&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;48.5&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;45.5&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;42.0&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;üîπ‚Äî‚Äî 32B Models ‚Äî‚Äî&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;31.1&lt;/td&gt; 
     &lt;td align="center"&gt;26.7&lt;/td&gt; 
     &lt;td align="center"&gt;29.7&lt;/td&gt; 
     &lt;td align="center"&gt;26.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Search-o1-32B&lt;/td&gt; 
     &lt;td align="center"&gt;28.2&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebThinker-32B-RL&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-QwQ-32B&lt;/td&gt; 
     &lt;td align="center"&gt;51.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-32B&lt;/td&gt; 
     &lt;td align="center"&gt;53.2&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebShaper-QwQ-32B&lt;/td&gt; 
     &lt;td align="center"&gt;53.3&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;55.3&lt;/td&gt; 
     &lt;td align="center"&gt;51.3&lt;/td&gt; 
     &lt;td align="center"&gt;44.9&lt;/td&gt; 
     &lt;td align="center"&gt;42.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;58.3&lt;/td&gt; 
     &lt;td align="center"&gt;54.2&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;45.8&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;57.3&lt;/td&gt; 
     &lt;td align="center"&gt;54.1&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;45.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;60.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;57.9&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;50.9&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;48.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Following the practices of WebThinker, WebAgents, and CognitiveKernel, we report the Best Pass@1, the highest score across three runs, which often reflects stronger performance, though it may exhibit some variability. To provide a more stable measure, we additionally report Pass@1 (Avg@8), which offers greater consistency at the cost of slightly lower scores.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;For consistency with prior open-source works, we evaluate GAIA-Text-103 using the WebAgents LLM-as-a-Judge template, and report results on GAIA-Val-165 using the official GAIA scorer script.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;By default, we use open-source tools wherever possible, except for the code tool &lt;a href="https://github.com/e2b-dev/E2B"&gt;E2B&lt;/a&gt; and the Google search tool &lt;a href="https://serper.dev/"&gt;Serper&lt;/a&gt;. We use &lt;a href="https://huggingface.co/openai/whisper-large-v3-turbo"&gt;Whisper&lt;/a&gt;, &lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct"&gt;Qwen2.5-VL-72B-Instruct&lt;/a&gt;, and &lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507"&gt;Qwen3-235B-A22B-Thinking-2507&lt;/a&gt; in our implementation. The framework can be easily extended to other open-source tools of your choice.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Replacing these open-source tools with commercial alternatives can yield performance gains. Commercial tools were mainly used for multimodal capabilities and certain complex reasoning subtasks. The majority of tasks, including planning, browsing, refinement, navigation, and more, were handled by our models.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;More Benchmarks&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;Method&lt;/th&gt; 
     &lt;th align="center"&gt;HLE&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;Frames&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;BrowseComp&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;BrowseComp-ZH&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;WebWalkerQA&lt;br /&gt;Pass@1&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;OpenAI Deep Research&lt;/td&gt; 
     &lt;td align="center"&gt;26.6&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;51.5&lt;/td&gt; 
     &lt;td align="center"&gt;42.9&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Gemini Deep Research&lt;/td&gt; 
     &lt;td align="center"&gt;26.9&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Kimi-Researcher&lt;/td&gt; 
     &lt;td align="center"&gt;26.9&lt;/td&gt; 
     &lt;td align="center"&gt;78.8&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-7B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;36.0&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-7B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;6.7&lt;/td&gt; 
     &lt;td align="center"&gt;14.2&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;58.0&lt;/td&gt; 
     &lt;td align="center"&gt;5.5&lt;/td&gt; 
     &lt;td align="center"&gt;9.3&lt;/td&gt; 
     &lt;td align="center"&gt;41.3&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;64.4&lt;/td&gt; 
     &lt;td align="center"&gt;8.7&lt;/td&gt; 
     &lt;td align="center"&gt;13.6&lt;/td&gt; 
     &lt;td align="center"&gt;45.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebThinker-32B-RL&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;46.5&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-QwQ-32B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;3.8&lt;/td&gt; 
     &lt;td align="center"&gt;18.0&lt;/td&gt; 
     &lt;td align="center"&gt;47.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-32B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;10.5&lt;/td&gt; 
     &lt;td align="center"&gt;25.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebShaper-32B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;51.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;10.2&lt;/td&gt; 
     &lt;td align="center"&gt;70.4&lt;/td&gt; 
     &lt;td align="center"&gt;10.6&lt;/td&gt; 
     &lt;td align="center"&gt;13.8&lt;/td&gt; 
     &lt;td align="center"&gt;45.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;11.8&lt;/td&gt; 
     &lt;td align="center"&gt;71.7&lt;/td&gt; 
     &lt;td align="center"&gt;13.0&lt;/td&gt; 
     &lt;td align="center"&gt;17.0&lt;/td&gt; 
     &lt;td align="center"&gt;49.3&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;MiroThinker‚Äôs performance was tested with this repository and open-source tools; other models‚Äô results are from their papers and official sites.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;As &lt;a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"&gt;MiroVerse-v0.1&lt;/a&gt; mainly contains English data, the model‚Äôs Chinese capability is limited. We plan to add more Chinese data to improve performance in the next version.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêç &lt;strong&gt;Python 3.10+&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;üì¶ &lt;strong&gt;uv package manager&lt;/strong&gt; (&lt;a href="https://github.com/astral-sh/uv"&gt;Installation guide&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üîë &lt;strong&gt;Required API keys&lt;/strong&gt; (see configuration section below)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/MiroMindAI/MiroThinker
cd MiroThinker

# Setup environment
cd apps/miroflow-agent
uv sync

# Configure API keys
cp .env.example .env
# Edit .env with your API keys (SERPER_API_KEY, JINA_API_KEY, E2B_API_KEY, etc.)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìù Environment Variables&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#tool-configuration"&gt;Tool Configuration&lt;/a&gt; section for required API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Tool Configuration&lt;/h3&gt; 
&lt;h4&gt;Minimal Configuration for MiroThinker v1.5 and v1.0&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Server&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Tools Provided&lt;/th&gt; 
   &lt;th align="left"&gt;Required Environment Variables&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;tool-python&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Execution environment and file management (E2B sandbox)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;create_sandbox&lt;/code&gt;, &lt;code&gt;run_command&lt;/code&gt;, &lt;code&gt;run_python_code&lt;/code&gt;, &lt;code&gt;upload_file_from_local_to_sandbox&lt;/code&gt;, &lt;code&gt;download_file_from_sandbox_to_local&lt;/code&gt;, &lt;code&gt;download_file_from_internet_to_sandbox&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;E2B_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;search_and_scrape_webpage&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Google search via Serper API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;google_search&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;jina_scrape_llm_summary&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Web scraping with LLM-based information extraction&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;scrape_and_extract_info&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_BASE_URL&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_MODEL_NAME&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Minimal &lt;code&gt;.env&lt;/code&gt; configuration example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Required for MiroThinker v1.5 and v1.0 (minimal setup)
SERPER_API_KEY=your_serper_key
SERPER_BASE_URL="https://google.serper.dev"
JINA_API_KEY=your_jina_key
JINA_BASE_URL="https://r.jina.ai"
E2B_API_KEY=your_e2b_key

# Required for jina_scrape_llm_summary
# Note: Summary LLM can be a small model (e.g., Qwen3-14B or GPT-5-Nano)
# The choice has minimal impact on performance, use what's most convenient
SUMMARY_LLM_BASE_URL="https://your_summary_llm_base_url/v1/chat/completions"
SUMMARY_LLM_MODEL_NAME=your_llm_model_name  # e.g., "Qwen/Qwen3-14B" or "gpt-5-nano"
SUMMARY_LLM_API_KEY=your_llm_api_key  # Optional, depends on LLM provider

# Required for benchmark evaluation (LLM-as-a-Judge)
OPENAI_API_KEY=your_openai_key  # Required for running benchmark evaluations
OPENAI_BASE_URL="https://api.openai.com/v1"  # Optional, defaults to OpenAI's API
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Why this is minimal&lt;/strong&gt;: These 3 MCP servers cover the core capabilities needed for research tasks: web search, content extraction, and code execution. All other servers are optional enhancements.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ü§ñ Summary LLM&lt;/strong&gt;: The &lt;code&gt;SUMMARY_LLM&lt;/code&gt; can be a small model like Qwen3-14B or GPT-5-Nano. The choice has minimal impact on overall performance, use whichever is most convenient for your setup.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üìä For Benchmark Evaluation&lt;/strong&gt;: If you plan to run benchmark evaluations, you also need &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; (and optionally &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt;) for LLM-as-a-Judge functionality used in evaluation scripts.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üñºÔ∏è For GAIA Multimodal Tasks&lt;/strong&gt;: GAIA-Val-165 includes tasks with image/audio/video files. Since MiroThinker is a text-only LLM, GPT-4o is used to pre-process these files into text descriptions. The same &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is used for both this preprocessing and LLM-as-a-Judge.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üìñ For more details&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/libs/miroflow-tools/README.md"&gt;MiroFlow Tools README&lt;/a&gt; for complete documentation of all available tools.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Click to expand additional available tools&lt;/summary&gt; 
 &lt;p&gt;The following optional tools are available but were not used in MiroThinker v1.5 and v1.0 evaluation:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Server Name&lt;/th&gt; 
    &lt;th align="left"&gt;Type&lt;/th&gt; 
    &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-vqa&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Vision processing using Claude&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-vqa-os&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Vision processing (open-source alternative)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-transcribe&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Audio transcription using OpenAI&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-transcribe-os&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Audio transcription using Whisper&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-reasoning&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Reasoning engine using Claude&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-reasoning-os&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Reasoning engine (open-source alternative)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-reading&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Document reading using MarkItDown&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-google-search&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Web search using Google + scraping&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-sogou-search&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Web search using Sogou (Chinese)&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;üìñ Local Deployment&lt;/strong&gt;: For instructions on deploying open-source tools (&lt;code&gt;tool-vqa-os&lt;/code&gt;, &lt;code&gt;tool-transcribe-os&lt;/code&gt;, &lt;code&gt;tool-reasoning-os&lt;/code&gt;) locally, see &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/assets/LOCAL-TOOL-DEPLOYMENT.md"&gt;Local Tool Deployment Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/libs/miroflow-tools/README.md"&gt;MiroFlow Tools README&lt;/a&gt; for complete documentation of all available tools.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h4&gt;Pre-configured Agent Settings&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;apps/miroflow-agent/conf/agent/&lt;/code&gt; directory contains several pre-configured agent settings. Each configuration uses different tools and requires corresponding environment variables in your &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Recommended&lt;/strong&gt;: For MiroThinker v1.5, use &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; (with context management, recommended for most tasks) or &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (only used for BrowseComp and BrowseComp-ZH). For v1.0, use &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt; (with context management). All use minimal configuration with only 3 MCP servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Configuration&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Max Turns&lt;/th&gt; 
   &lt;th align="left"&gt;Context Retention&lt;/th&gt; 
   &lt;th align="left"&gt;Required Environment Variables&lt;/th&gt; 
   &lt;th align="left"&gt;Recommended For&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt;&lt;/strong&gt; ‚≠ê&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent with context management&lt;/td&gt; 
   &lt;td align="left"&gt;200&lt;/td&gt; 
   &lt;td align="left"&gt;Keep 5 most recent&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;, &lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;, &lt;code&gt;E2B_API_KEY&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_BASE_URL&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_MODEL_NAME&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.5 (recommended for most tasks)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt;&lt;/strong&gt; ‚≠ê&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent with context management&lt;/td&gt; 
   &lt;td align="left"&gt;400&lt;/td&gt; 
   &lt;td align="left"&gt;Keep 5 most recent&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.5 (for BrowseComp &amp;amp; BrowseComp-ZH)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.5&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent for MiroThinker v1.5&lt;/td&gt; 
   &lt;td align="left"&gt;600&lt;/td&gt; 
   &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.5&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent with context management&lt;/td&gt; 
   &lt;td align="left"&gt;600&lt;/td&gt; 
   &lt;td align="left"&gt;Keep 5 most recent&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.0&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.0&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent for MiroThinker v1.0&lt;/td&gt; 
   &lt;td align="left"&gt;600&lt;/td&gt; 
   &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.0&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand legacy configurations (v0.1/v0.2)&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Configuration&lt;/th&gt; 
    &lt;th align="left"&gt;Description&lt;/th&gt; 
    &lt;th align="left"&gt;Max Turns&lt;/th&gt; 
    &lt;th align="left"&gt;Context Retention&lt;/th&gt; 
    &lt;th align="left"&gt;Required Environment Variables&lt;/th&gt; 
    &lt;th align="left"&gt;Recommended For&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;multi_agent&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Multi-agent with commercial tools (v0.1/v0.2)&lt;/td&gt; 
    &lt;td align="left"&gt;50&lt;/td&gt; 
    &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;E2B_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_BASE_URL&lt;/code&gt;, &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt;, &lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;, &lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;v0.1/v0.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;multi_agent_os&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Multi-agent with open-source tools (v0.1/v0.2)&lt;/td&gt; 
    &lt;td align="left"&gt;50&lt;/td&gt; 
    &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;E2B_API_KEY&lt;/code&gt;, &lt;code&gt;VISION_API_KEY&lt;/code&gt;, &lt;code&gt;VISION_BASE_URL&lt;/code&gt;, &lt;code&gt;VISION_MODEL_NAME&lt;/code&gt;, &lt;code&gt;WHISPER_API_KEY&lt;/code&gt;, &lt;code&gt;WHISPER_BASE_URL&lt;/code&gt;, &lt;code&gt;WHISPER_MODEL_NAME&lt;/code&gt;, &lt;code&gt;REASONING_API_KEY&lt;/code&gt;, &lt;code&gt;REASONING_BASE_URL&lt;/code&gt;, &lt;code&gt;REASONING_MODEL_NAME&lt;/code&gt;, &lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;, &lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;v0.1/v0.2&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Note&lt;/strong&gt;: All environment variables are listed in &lt;code&gt;apps/miroflow-agent/.env.example&lt;/code&gt;. Copy it to &lt;code&gt;.env&lt;/code&gt; and fill in the values for the tools you plan to use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Creating Custom Tool Configurations&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Click to expand custom tool configuration guide&lt;/summary&gt; 
 &lt;p&gt;You can create your own YAML configuration file to freely combine MCP servers. Here's how:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Create a new YAML file&lt;/strong&gt; in &lt;code&gt;apps/miroflow-agent/conf/agent/&lt;/code&gt;:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# conf/agent/my_custom_config.yaml
defaults:
  - default
  - _self_

main_agent:
  tools:
    - tool-python                    # Execution environment
    - search_and_scrape_webpage      # Google search
    - jina_scrape_llm_summary        # Web scraping with LLM
    - tool-vqa                       # Vision processing (optional)
    - tool-transcribe                # Audio processing (optional)
    - tool-reasoning                 # Reasoning engine (optional)
    - tool-reading                   # Document reading (optional)
  max_turns: 400  # Maximum number of turns

sub_agents:
  agent-browsing:  # Optional sub-agent
    tools:
      - tool-google-search
      - tool-vqa
      - tool-reading
      - tool-python
    max_turns: 50

keep_tool_result: -1  # Context retention budget: -1 keeps all tool results, or specify K to keep only the K most recent tool responses
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;üí° Context Retention Strategy&lt;/strong&gt;: The &lt;code&gt;keep_tool_result&lt;/code&gt; parameter implements a &lt;strong&gt;recency-based context retention&lt;/strong&gt; strategy. In the standard ReAct paradigm, all tool outputs are retained in the message history, which can lead to inefficient context utilization. Empirically, we observe that the model's subsequent actions depend primarily on recent observations rather than distant ones. This strategy retains only the most recent K tool responses (where K is the &lt;code&gt;keep_tool_result&lt;/code&gt; value) while preserving the complete sequence of thoughts and actions.&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;Benefits:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‚úÖ Preserves the reasoning and action trace&lt;/li&gt; 
   &lt;li&gt;‚úÖ Focuses the model's attention on the most contextually relevant observations&lt;/li&gt; 
   &lt;li&gt;‚úÖ Frees additional context space for extended reasoning and deeper tool-use trajectories&lt;/li&gt; 
   &lt;li&gt;‚úÖ Does not lead to performance degradation while allowing more context space for interactive scaling&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Set &lt;code&gt;keep_tool_result: -1&lt;/code&gt; to keep all tool results, or specify a positive integer K (e.g., &lt;code&gt;keep_tool_result: 5&lt;/code&gt;) to keep only the K most recent tool responses.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;&lt;strong&gt;Use your custom configuration&lt;/strong&gt; when running evaluations:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent
uv run main.py llm=qwen-3 agent=my_custom_config llm.base_url=https://your_base_url/v1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure environment variables&lt;/strong&gt; in &lt;code&gt;.env&lt;/code&gt; based on the tools you use.&lt;/p&gt; &lt;p&gt;All available environment variables are listed in &lt;code&gt;apps/miroflow-agent/.env.example&lt;/code&gt;. Copy it to &lt;code&gt;.env&lt;/code&gt; and configure the variables according to your chosen configuration:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent
cp .env.example .env
# Edit .env with your actual API keys
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;For MiroThinker v1.5&lt;/strong&gt; (&lt;code&gt;mirothinker_v1.5_keep5_max200.yaml&lt;/code&gt;, &lt;code&gt;mirothinker_v1.5_keep5_max400.yaml&lt;/code&gt;, or &lt;code&gt;mirothinker_v1.5.yaml&lt;/code&gt;) and &lt;strong&gt;v1.0&lt;/strong&gt; (&lt;code&gt;mirothinker_v1.0_keep5.yaml&lt;/code&gt; or &lt;code&gt;mirothinker_v1.0.yaml&lt;/code&gt;), see the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#minimal-configuration-for-mirothinker-v15-and-v10"&gt;Minimal Configuration&lt;/a&gt; section above for the complete configuration example.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;For other configurations&lt;/strong&gt;, refer to the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#pre-configured-agent-settings"&gt;Pre-configured Agent Settings&lt;/a&gt; table above to see which environment variables are required.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîë Click to expand optional API keys&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# API for LLM-as-a-Judge (for benchmark testing, required for benchmark evaluation)
OPENAI_API_KEY=your_openai_key
OPENAI_BASE_URL="https://api.openai.com/v1"  # Optional, defaults to OpenAI's API

# API for Open-Source Audio Transcription Tool (for benchmark testing, optional)
WHISPER_MODEL_NAME="openai/whisper-large-v3-turbo"
WHISPER_API_KEY=your_whisper_key
WHISPER_BASE_URL="https://your_whisper_base_url/v1"

# API for Open-Source VQA Tool (for benchmark testing, optional)
VISION_MODEL_NAME="Qwen/Qwen2.5-VL-72B-Instruct"
VISION_API_KEY=your_vision_key
VISION_BASE_URL="https://your_vision_base_url/v1/chat/completions"

# API for Open-Source Reasoning Tool (for benchmark testing, optional)
REASONING_MODEL_NAME="Qwen/Qwen3-235B-A22B-Thinking-2507"
REASONING_API_KEY=your_reasoning_key
REASONING_BASE_URL="https://your_reasoning_base_url/v1/chat/completions"

# API for Claude Sonnet 3.7 as Commercial Tools (optional)
ANTHROPIC_API_KEY=your_anthropic_key

# API for Sogou Search (optional)
TENCENTCLOUD_SECRET_ID=your_tencent_cloud_secret_id
TENCENTCLOUD_SECRET_KEY=your_tencent_cloud_secret_key

# API for Summary LLM (can use small models like Qwen3-14B or GPT-5-Nano)
SUMMARY_LLM_BASE_URL="https://your_summary_llm_base_url/v1/chat/completions"
SUMMARY_LLM_MODEL_NAME=your_summary_llm_model_name  # e.g., "Qwen/Qwen3-14B" or "gpt-5-nano"
SUMMARY_LLM_API_KEY=your_summary_llm_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Serve the MiroThinker Model&lt;/h3&gt; 
&lt;h4&gt;Option 1 (Recommended): Serve with SGLang or vLLM&lt;/h4&gt; 
&lt;p&gt;Use SGLang to serve MiroThinker models at port 61002:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;NUM_GPUS=4
PORT=61002

# Downloading model from HF (v1.5 recommended)
MODEL_PATH=miromind-ai/MiroThinker-v1.5-30B

# Or use v1.0
# MODEL_PATH=miromind-ai/MiroThinker-v1.0-30B

python3 -m sglang.launch_server \
    --model-path $MODEL_PATH \
    --tp $NUM_GPUS \
    --dp 1 \
    --host 0.0.0.0 \
    --port $PORT \
    --trust-remote-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìç Server URL&lt;/strong&gt;: This will start a server at &lt;code&gt;http://0.0.0.0:$PORT&lt;/code&gt;. Use this as your server base URL (e.g., &lt;code&gt;http://0.0.0.0:61002/v1&lt;/code&gt;).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Option 2: Quantized Light-Weight Options&lt;/h4&gt; 
&lt;p&gt;We also provide comprehensive guidance for serving MiroThinker models using CPU-optimized and GPU-accelerated quantization techniques, along with detailed analysis and guidelines for deployment with llama.cpp, Ollama, SGLang, and other inference frameworks.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìñ Complete Guide&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/apps/gradio-demo/"&gt;Deployment Documentation&lt;/a&gt; for detailed deployment instructions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Run Your First Task&lt;/h3&gt; 
&lt;p&gt;After setting up the environment and starting your model server, run &lt;code&gt;main.py&lt;/code&gt; to test with a default question: &lt;em&gt;"What is the title of today's arxiv paper in computer science?"&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent

# Using MiroThinker models (requires your own model server)
uv run python main.py llm=qwen-3 agent=mirothinker_v1.5_keep5_max200 llm.base_url=http://localhost:61002/v1

# Or using Claude (requires ANTHROPIC_API_KEY in .env)
uv run python main.py llm=claude-3-7 agent=single_agent_keep5

# Or using GPT-5 (requires OPENAI_API_KEY in .env)
uv run python main.py llm=gpt-5 agent=single_agent_keep5
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To customize your question&lt;/strong&gt;, edit &lt;code&gt;main.py&lt;/code&gt; line 32:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;task_description = "Your custom question here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The agent will search the web, execute code if needed, and provide an answer with sources.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìñ More details&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/apps/miroflow-agent/README.md"&gt;apps/miroflow-agent/README.md&lt;/a&gt; for available configurations and troubleshooting.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìä Benchmark Evaluation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For researchers who want to reproduce our benchmark results or evaluate on standard benchmarks.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Download Benchmark Data&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd MiroThinker  # Back to project root
wget https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/data_20251115_password_protected.zip
unzip data_20251115_password_protected.zip
# Password: pf4*
rm data_20251115_password_protected.zip
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run Benchmark Evaluation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For MiroThinker v1.5, use &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; (with context management), &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (with context management), or &lt;code&gt;mirothinker_v1.5&lt;/code&gt; configurations. For v1.0, use &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt; (with context management) or &lt;code&gt;mirothinker_v1.0&lt;/code&gt; configurations.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Available Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can customize the evaluation by setting the following environment variables before running the script:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Parameter&lt;/th&gt; 
   &lt;th align="left"&gt;Default&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;LLM_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"MiroThinker-Models"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Model name identifier&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"https://your-api.com/v1"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Base URL of your model server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;NUM_RUNS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Varies by benchmark&lt;/td&gt; 
   &lt;td align="left"&gt;Number of evaluation runs (3 for most benchmarks, 8 for GAIA/XBench/FutureX/SEAL-0, 32 for AIME2025)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;LLM_PROVIDER&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"qwen"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;LLM provider (e.g., &lt;code&gt;qwen&lt;/code&gt;, &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;anthropic&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;AGENT_SET&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"mirothinker_v1.5_keep5_max200"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Agent configuration (e.g., &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt;, &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt;, &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;MAX_CONTEXT_LENGTH&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;262144&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Maximum context length (256K)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;MAX_CONCURRENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Maximum concurrent tasks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;PASS_AT_K&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Pass@K evaluation metric&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TEMPERATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sampling temperature&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"xxx"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API key for the model server&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Example Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# Basic usage with v1.5 (recommended)
NUM_RUNS=8 LLM_MODEL="MiroThinker-v1.5-30B" BASE_URL="https://your-api.com/v1" bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# Or with v1.0
# NUM_RUNS=8 LLM_MODEL="MiroThinker-v1.0-30B" BASE_URL="https://your-api.com/v1" bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# Customize number of runs and agent configuration (v1.5 with context management)
LLM_MODEL="MiroThinker-v1.5-30B" \
BASE_URL="https://your-api.com/v1" \
NUM_RUNS=8 \
AGENT_SET="mirothinker_v1.5_keep5_max200" \
bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# Or with v1.0 configuration (with context management)
# LLM_MODEL="MiroThinker-v1.0-30B" \
# BASE_URL="https://your-api.com/v1" \
# NUM_RUNS=8 \
# AGENT_SET="mirothinker_v1.0_keep5" \
# bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;details open&gt; 
 &lt;summary&gt;üìã Click to expand all benchmark commands&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Important for MiroThinker v1.5&lt;/strong&gt;: To reproduce our reported results, you must set the correct &lt;code&gt;AGENT_SET&lt;/code&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;BrowseComp &amp;amp; BrowseComp-ZH&lt;/strong&gt;: Use &lt;code&gt;AGENT_SET="mirothinker_v1.5_keep5_max400"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;All other benchmarks&lt;/strong&gt;: Use &lt;code&gt;AGENT_SET="mirothinker_v1.5_keep5_max200"&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# HLE
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_hle.sh

# HLE-Text-2158
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_hle-text-2158.sh

# HLE-Text-500
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_hle-text-500.sh

# GAIA-Text-103
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# GAIA-Validation (GAIA-Val-165)
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_gaia-validation.sh

# BrowseComp-EN (‚ö†Ô∏è use max400)
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max400" bash scripts/run_evaluate_multiple_runs_browsecomp.sh

# BrowseComp-ZH (‚ö†Ô∏è use max400)
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max400" bash scripts/run_evaluate_multiple_runs_browsecomp_zh.sh

# WebWalkerQA
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_webwalkerqa.sh

# XBench-DeepSearch
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_xbench_deepsearch.sh

# FRAMES
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_frames.sh

# SEAL-0
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_seal-0.sh

# FutureX
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_futurex.sh

# AIME2025
NUM_RUNS=32 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_aime2025.sh

# DeepSearchQA
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_deepsearchqa.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;3. &lt;strong&gt;Monitor evaluation progress&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìä Click to expand progress monitoring commands&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# For HLE
python benchmarks/check_progress/check_progress_hle.py /path/to/evaluation/logs

# For HLE-Text-2158
python benchmarks/check_progress/check_progress_hle-text-2158.py /path/to/evaluation/logs

# For HLE-Text-500
python benchmarks/check_progress/check_progress_hle-text-500.py /path/to/evaluation/logs

# For BrowseComp-EN
python benchmarks/check_progress/check_progress_browsecomp.py /path/to/evaluation/logs

# For BrowseComp-ZH
python benchmarks/check_progress/check_progress_browsecomp_zh.py /path/to/evaluation/logs

# For GAIA-Validation
python benchmarks/check_progress/check_progress_gaia-validation.py /path/to/evaluation/logs

# For GAIA-Text-103
python benchmarks/check_progress/check_progress_gaia-validation-text-103.py /path/to/evaluation/logs

# For WebWalkerQA
python benchmarks/check_progress/check_progress_webwalkerqa.py /path/to/evaluation/logs

# For Frames
python benchmarks/check_progress/check_progress_frames.py /path/to/evaluation/logs

# For XBench-DeepSearch
python benchmarks/check_progress/check_progress_xbench_deepsearch.py /path/to/evaluation/logs

# For SEAL-0
python benchmarks/check_progress/check_progress_seal-0.py /path/to/evaluation/logs

# For AIME2025
python benchmarks/check_progress/check_progress_aime2025.py /path/to/evaluation/logs

# For DeepSearchQA
python benchmarks/check_progress/check_progress_deepsearchqa.py /path/to/evaluation/logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;üî¨ Trace Collection&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìã Click to expand trace collection commands&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/collect-trace

# Collect Traces for SFT
bash scripts/collect_trace_claude37.sh
bash scripts/collect_trace_gpt5.sh

# Collect Traces for DPO
bash scripts/collect_trace_qwen3.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ùì FAQ &amp;amp; Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Common Issues&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Click to expand troubleshooting guide&lt;/summary&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Which version should I use?&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; We recommend &lt;strong&gt;MiroThinker v1.5&lt;/strong&gt; ‚≠ê with the minimal configuration:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;v1.5&lt;/strong&gt; ‚≠ê: Latest version with 256K context, world-leading performance. Use config (with context management): 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; (up to 200 turns, recommended for most tasks)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (up to 400 turns, only used for BrowseComp and BrowseComp-ZH)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: How do I get API keys?&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; You need these keys for minimal setup:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;SERPER_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://serper.dev/"&gt;Serper.dev&lt;/a&gt; (Google search API)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;JINA_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://jina.ai/"&gt;Jina.ai&lt;/a&gt; (Web scraping)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;E2B_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://e2b.dev/"&gt;E2B.dev&lt;/a&gt; (Code execution sandbox)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;SUMMARY_LLM_API_KEY&lt;/strong&gt;: Your LLM API credentials (for content summarization). Can be a small model like Qwen3-14B or GPT-5-Nano‚Äîthe choice has minimal impact on performance.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;OPENAI_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://platform.openai.com/"&gt;OpenAI&lt;/a&gt; (Required for benchmark evaluation, used for LLM-as-a-Judge)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;OPENAI_BASE_URL&lt;/strong&gt;: Optional, defaults to &lt;code&gt;https://api.openai.com/v1&lt;/code&gt;. Can be changed to use OpenAI-compatible APIs.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Model server connection errors&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Common issues:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Check base URL format&lt;/strong&gt;: Should end with &lt;code&gt;/v1&lt;/code&gt; (e.g., &lt;code&gt;https://your-api.com/v1&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Verify API key&lt;/strong&gt;: Ensure &lt;code&gt;API_KEY&lt;/code&gt; is set correctly in environment or script&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Check server status&lt;/strong&gt;: Make sure your model server is running and accessible&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Network issues&lt;/strong&gt;: Verify firewall/network settings allow connections&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Evaluation script fails to run&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Troubleshooting steps:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Check working directory&lt;/strong&gt;: Make sure you're in &lt;code&gt;apps/miroflow-agent&lt;/code&gt; directory&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Verify environment&lt;/strong&gt;: Run &lt;code&gt;uv sync&lt;/code&gt; to ensure dependencies are installed&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Check .env file&lt;/strong&gt;: Ensure all required environment variables are set&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Review logs&lt;/strong&gt;: Check &lt;code&gt;logs/&lt;/code&gt; directory for detailed error messages&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Verify data path&lt;/strong&gt;: Ensure benchmark data is downloaded and in correct location&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Out of memory errors&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Solutions:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Reduce context length&lt;/strong&gt;: Set &lt;code&gt;MAX_CONTEXT_LENGTH&lt;/code&gt; to a smaller value (e.g., 131072 for 128K)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Use context management with fewer turns&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;For v1.5: Use &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; or &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (with context management)&lt;/li&gt; 
    &lt;li&gt;For v1.0: Use &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt; (with context management)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Reduce concurrent tasks&lt;/strong&gt;: Set &lt;code&gt;MAX_CONCURRENT&lt;/code&gt; to a smaller number (e.g., 5)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Use smaller model&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;For v1.5: Try 30B instead of 235B&lt;/li&gt; 
    &lt;li&gt;For v1.0: Try 8B or 30B instead of 72B&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Tool execution errors&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Common fixes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;E2B errors&lt;/strong&gt;: Verify &lt;code&gt;E2B_API_KEY&lt;/code&gt; is valid and account has credits&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Serper errors&lt;/strong&gt;: Check &lt;code&gt;SERPER_API_KEY&lt;/code&gt; and rate limits&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Jina errors&lt;/strong&gt;: Verify &lt;code&gt;JINA_API_KEY&lt;/code&gt; and &lt;code&gt;JINA_BASE_URL&lt;/code&gt; are correct&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;LLM summarization errors&lt;/strong&gt;: Check &lt;code&gt;SUMMARY_LLM_*&lt;/code&gt; variables and model availability&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: How to monitor long-running evaluations?&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Use the progress monitoring scripts:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent
python benchmarks/check_progress/check_progress_&amp;lt;benchmark_name&amp;gt;.py /path/to/logs
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The scripts show completion status, elapsed time, and estimated remaining time.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Getting Help&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Documentation&lt;/strong&gt;: Check &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/libs/miroflow-tools/README.md"&gt;MiroFlow Tools README&lt;/a&gt; for tool details&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;Discord&lt;/strong&gt;: Join our &lt;a href="https://discord.com/invite/GPqEnkzQZd"&gt;Discord community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Issues&lt;/strong&gt;: Report bugs on &lt;a href="https://github.com/MiroMindAI/MiroThinker/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìß &lt;strong&gt;Contact&lt;/strong&gt;: Visit &lt;a href="https://miromind.ai/"&gt;our website&lt;/a&gt; for more information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;p&gt;We extend our sincere gratitude to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üèÜ &lt;strong&gt;Benchmark Contributors&lt;/strong&gt; for the comprehensive evaluation datasets&lt;/li&gt; 
 &lt;li&gt;üåç &lt;strong&gt;Open Source Community&lt;/strong&gt; for the tools and libraries that make this possible&lt;/li&gt; 
 &lt;li&gt;üë• &lt;strong&gt;All Contributors&lt;/strong&gt; who have helped make MiroThinker better&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/MiroMindAI/MiroThinker/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=MiroMindAI/MiroThinker" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Join our community and help us build the future of AI agents!&lt;/p&gt; 
&lt;h3&gt;References&lt;/h3&gt; 
&lt;p&gt;If you find this project useful in your research, please consider citing:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@article{miromind2025mirothinker,
  title={MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling},
  author={MiroMind Team and Bai, Song and Bing, Lidong and Chen, Carson and Chen, Guanzheng and Chen, Yuntao and Chen, Zhe and Chen, Ziyi and Dai, Jifeng and Dong, Xuan and others},
  journal={arXiv preprint arXiv:2511.11793},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#MiroMindAI/MiroThinker&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=MiroMindAI/MiroThinker&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>opf/openproject</title>
      <link>https://github.com/opf/openproject</link>
      <description>&lt;p&gt;OpenProject is the leading open source project management software.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenProject&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/v/release/opf/openproject" alt="GitHub release (latest by date)" /&gt; &lt;img src="https://img.shields.io/github/commit-activity/m/opf/openproject" alt="GitHub commit activity" /&gt; &lt;img src="https://img.shields.io/github/checks-status/opf/openproject/dev" alt="GitHub branch checks state" /&gt; &lt;a href="https://github.com/opf/openproject/actions/workflows/test-core.yml"&gt;&lt;img src="https://github.com/opf/openproject/actions/workflows/test-core.yml/badge.svg?branch=dev" alt="Github Tests" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We empower teams to achieve great things together for the good of society.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OpenProject is a web-based project management software. Use OpenProject to manage your projects, tasks and goals. Collaborate via work packages and link them to your pull requests on Github. &lt;a href="https://www.openproject.org/docs/system-admin-guide/integrations/github-integration/"&gt;Read more about the OpenProject GitHub integration&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/opf/openproject/dev/GitHub-tab-new.png" alt="Screenshot of OpenProject, showing the GitHub tab on a work package" /&gt;&lt;/p&gt; 
&lt;p&gt;OpenProject's key features are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/collaboration-software-features/#project-planning"&gt;Project planning and scheduling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/collaboration-software-features/#product-management"&gt;Product roadmap and release planning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/collaboration-software-features/#task-management"&gt;Task management and team collaboration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/collaboration-software-features/#agile-scrum"&gt;Agile and Scrum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/collaboration-software-features/#time-tracking"&gt;Time tracking, cost reporting, and budgeting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/collaboration-software-features/#bug-tracking"&gt;Bug tracking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/docs/user-guide/wysiwyg/"&gt;Wikis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/docs/user-guide/forums/"&gt;Forums&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/docs/user-guide/meetings/"&gt;Meeting agendas and meeting minutes&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More information and screenshots can be found on our &lt;a href="https://www.openproject.org"&gt;website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Start now with OpenProject&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Free Trial&lt;/strong&gt;: &lt;a href="https://start.openproject.com/"&gt;Start a 14-days free trial of OpenProject&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Edition&lt;/strong&gt;, free of charge: Download OpenProject and get started with the self-hosted Community edition. If you want to run an instance of OpenProject in production (or for evaluation), refer to our in-depth &lt;a href="https://www.openproject.org/download-and-installation/"&gt;installation guides&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Edition&lt;/strong&gt;: Sign up for the Enterprise version, choose between cloud or on-premises and benefit from comprehensive support and Enterprise add-ons.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Explore our &lt;a href="https://www.openproject.org/docs/"&gt;comprehensive documentation&lt;/a&gt; to help you get up and running quickly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Training&lt;/strong&gt;: &lt;a href="https://www.openproject.org/training-and-consulting/#training-signup"&gt;Book one of our training or consulting offers&lt;/a&gt; to get your team on board in no time.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Report bugs&lt;/h2&gt; 
&lt;p&gt;You found a bug? Please &lt;a href="https://www.openproject.org/docs/development/report-a-bug/"&gt;report it&lt;/a&gt; to our &lt;a href="https://community.openproject.org/projects/openproject"&gt;OpenProject Community&lt;/a&gt;. Thank you!&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;OpenProject is supported by its Community members, both companies and individuals.&lt;/p&gt; 
&lt;p&gt;We are always looking for new members to our Community, so if you are interested in improving OpenProject we would be glad to welcome and support you getting into the code. There are guides as well, e.g. a &lt;a href="https://www.openproject.org/docs/development/development-environment/"&gt;Quick Start for Developers&lt;/a&gt;, but don't hesitate to simply &lt;a href="https://www.openproject.org/contact"&gt;contact us&lt;/a&gt; if you have questions.&lt;/p&gt; 
&lt;p&gt;Working on OpenProject comes with the satisfaction of working on a widely used open source application.&lt;/p&gt; 
&lt;p&gt;Also, if you do not want to be limited to working on open source in your free time, OpenProject GmbH, the company contributing to the OpenProject development, &lt;a href="https://www.openproject.org/career/"&gt;is hiring&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Stay in contact&lt;/h2&gt; 
&lt;p&gt;Here you can find our &lt;a href="https://www.openproject.org/contact/"&gt;contact information&lt;/a&gt;. As we regularly update OpenProject, we recommend staying in touch ‚Äì here is where you can find us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.openproject.org/blog/community-instance/"&gt;OpenProject Community&lt;/a&gt; with &lt;a href="https://community.openproject.org/projects/openproject/forums"&gt;forum discussions&lt;/a&gt;: The open instance where we develop our features ‚Äì transparent and open for discussions, bug reports or feature requests.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/company/18706985"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/openproject/"&gt;Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fosstodon.org/@openproject"&gt;Fosstodon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/openproject"&gt;Twitter/X&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security / responsible disclosure&lt;/h2&gt; 
&lt;p&gt;We take security very seriously at OpenProject. We value any kind of feedback that will keep our Community secure. If you happen to come across a security issue we urge you to disclose it to us privately to allow our users and Community enough time to upgrade. Security issues will always take precedence over anything else in the pipeline.&lt;/p&gt; 
&lt;p&gt;For more information on how to disclose a security vulnerability, &lt;a href="https://raw.githubusercontent.com/opf/openproject/dev/docs/security-and-privacy/statement-on-security/README.md"&gt;please see this page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OpenProject is licensed under the terms of the GNU General Public License version 3. See &lt;a href="https://raw.githubusercontent.com/opf/openproject/dev/COPYRIGHT"&gt;COPYRIGHT&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/opf/openproject/dev/LICENSE"&gt;LICENSE&lt;/a&gt; files for details.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;h3&gt;Icons&lt;/h3&gt; 
&lt;p&gt;Thanks to Vincent Le Moign and his fabulous Minicons icons on &lt;a href="http://www.webalys.com/minicons/icons-free-pack.php"&gt;webalys.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenProject icon font&lt;/h3&gt; 
&lt;p&gt;Published and created by the OpenProject Foundation (OPF) under &lt;a href="http://creativecommons.org/licenses/by/3.0/"&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt; with icons from the following sources &lt;a href="http://www.webalys.com/minicons"&gt;Minicons Free Vector Icons Pack&lt;/a&gt; and &lt;a href="http://www.webalys.com/design-interface-application-framework.php"&gt;User Interface Design framework&lt;/a&gt; both by webalys&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Creative Commons License&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OpenProject Icon Font by the OpenProject Foundation (OPF) is licensed under Creative Commons Attribution 3.0 Unported License and Free for both personal and commercial use. You can copy, adapt, remix, distribute or transmit it.&lt;/p&gt; 
&lt;p&gt;Under this condition: provide a mention of the "OpenProject Foundation" and a link back to OpenProject &lt;a href="http://www.openproject.org"&gt;www.openproject.org&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-code</title>
      <link>https://github.com/anthropics/claude-code</link>
      <description>&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square" alt="" /&gt; &lt;a href="https://www.npmjs.com/package/@anthropic-ai/claude-code"&gt;&lt;img src="https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square" alt="npm" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn more in the &lt;a href="https://code.claude.com/docs/en/overview"&gt;official documentation&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/anthropics/claude-code/main/demo.gif" /&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Claude Code:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;MacOS/Linux:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://claude.ai/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Homebrew (MacOS):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install --cask claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://claude.ai/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NPM:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g @anthropic-ai/claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: If installing with NPM, you also need to install &lt;a href="https://nodejs.org/en/download/"&gt;Node.js 18+&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Navigate to your project directory and run &lt;code&gt;claude&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;This repository includes several Claude Code plugins that extend functionality with custom commands and agents. See the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-code/main/plugins/README.md"&gt;plugins directory&lt;/a&gt; for detailed documentation on available plugins.&lt;/p&gt; 
&lt;h2&gt;Reporting Bugs&lt;/h2&gt; 
&lt;p&gt;We welcome your feedback. Use the &lt;code&gt;/bug&lt;/code&gt; command to report issues directly within Claude Code, or file a &lt;a href="https://github.com/anthropics/claude-code/issues"&gt;GitHub issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Connect on Discord&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://anthropic.com/discord"&gt;Claude Developers Discord&lt;/a&gt; to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.&lt;/p&gt; 
&lt;h2&gt;Data collection, usage, and retention&lt;/h2&gt; 
&lt;p&gt;When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the &lt;code&gt;/bug&lt;/code&gt; command.&lt;/p&gt; 
&lt;h3&gt;How we use your data&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://code.claude.com/docs/en/data-usage"&gt;data usage policies&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Privacy safeguards&lt;/h3&gt; 
&lt;p&gt;We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.&lt;/p&gt; 
&lt;p&gt;For full details, please review our &lt;a href="https://www.anthropic.com/legal/commercial-terms"&gt;Commercial Terms of Service&lt;/a&gt; and &lt;a href="https://www.anthropic.com/legal/privacy"&gt;Privacy Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>obra/superpowers</title>
      <link>https://github.com/obra/superpowers</link>
      <description>&lt;p&gt;Claude Code superpowers: core skills library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Superpowers&lt;/h1&gt; 
&lt;p&gt;Superpowers is a complete software development workflow for your coding agents, built on top of a set of composable "skills" and some initial instructions that make sure your agent uses them.&lt;/p&gt; 
&lt;h2&gt;How it works&lt;/h2&gt; 
&lt;p&gt;It starts from the moment you fire up your coding agent. As soon as it sees that you're building something, it &lt;em&gt;doesn't&lt;/em&gt; just jump into trying to write code. Instead, it steps back and asks you what you're really trying to do.&lt;/p&gt; 
&lt;p&gt;Once it's teased a spec out of the conversation, it shows it to you in chunks short enough to actually read and digest.&lt;/p&gt; 
&lt;p&gt;After you've signed off on the design, your agent puts together an implementation plan that's clear enough for an enthusiastic junior engineer with poor taste, no judgement, no project context, and an aversion to testing to follow. It emphasizes true red/green TDD, YAGNI (You Aren't Gonna Need It), and DRY.&lt;/p&gt; 
&lt;p&gt;Next up, once you say "go", it launches a &lt;em&gt;subagent-driven-development&lt;/em&gt; process, having agents work through each engineering task, inspecting and reviewing their work, and continuing forward. It's not uncommon for Claude to be able to work autonomously for a couple hours at a time without deviating from the plan you put together.&lt;/p&gt; 
&lt;p&gt;There's a bunch more to it, but that's the core of the system. And because the skills trigger automatically, you don't need to do anything special. Your coding agent just has Superpowers.&lt;/p&gt; 
&lt;h2&gt;Sponsorship&lt;/h2&gt; 
&lt;p&gt;If Superpowers has helped you do stuff that makes money and you are so inclined, I'd greatly appreciate it if you'd consider &lt;a href="https://github.com/sponsors/obra"&gt;sponsoring my opensource work&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thanks!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jesse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Installation differs by platform. Claude Code has a built-in plugin system. Codex and OpenCode require manual setup.&lt;/p&gt; 
&lt;h3&gt;Claude Code (via Plugin Marketplace)&lt;/h3&gt; 
&lt;p&gt;In Claude Code, register the marketplace first:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin marketplace add obra/superpowers-marketplace
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install the plugin from this marketplace:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin install superpowers@superpowers-marketplace
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Verify Installation&lt;/h3&gt; 
&lt;p&gt;Check that commands appear:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/help
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# Should see:
# /superpowers:brainstorm - Interactive design refinement
# /superpowers:write-plan - Create implementation plan
# /superpowers:execute-plan - Execute plan in batches
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Codex&lt;/h3&gt; 
&lt;p&gt;Tell Codex:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.codex/INSTALL.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Detailed docs:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/obra/superpowers/main/docs/README.codex.md"&gt;docs/README.codex.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;OpenCode&lt;/h3&gt; 
&lt;p&gt;Tell OpenCode:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.opencode/INSTALL.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Detailed docs:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/obra/superpowers/main/docs/README.opencode.md"&gt;docs/README.opencode.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;The Basic Workflow&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;brainstorming&lt;/strong&gt; - Activates before writing code. Refines rough ideas through questions, explores alternatives, presents design in sections for validation. Saves design document.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;using-git-worktrees&lt;/strong&gt; - Activates after design approval. Creates isolated workspace on new branch, runs project setup, verifies clean test baseline.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;writing-plans&lt;/strong&gt; - Activates with approved design. Breaks work into bite-sized tasks (2-5 minutes each). Every task has exact file paths, complete code, verification steps.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;subagent-driven-development&lt;/strong&gt; or &lt;strong&gt;executing-plans&lt;/strong&gt; - Activates with plan. Dispatches fresh subagent per task with two-stage review (spec compliance, then code quality), or executes in batches with human checkpoints.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;test-driven-development&lt;/strong&gt; - Activates during implementation. Enforces RED-GREEN-REFACTOR: write failing test, watch it fail, write minimal code, watch it pass, commit. Deletes code written before tests.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;requesting-code-review&lt;/strong&gt; - Activates between tasks. Reviews against plan, reports issues by severity. Critical issues block progress.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;finishing-a-development-branch&lt;/strong&gt; - Activates when tasks complete. Verifies tests, presents options (merge/PR/keep/discard), cleans up worktree.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;The agent checks for relevant skills before any task.&lt;/strong&gt; Mandatory workflows, not suggestions.&lt;/p&gt; 
&lt;h2&gt;What's Inside&lt;/h2&gt; 
&lt;h3&gt;Skills Library&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;test-driven-development&lt;/strong&gt; - RED-GREEN-REFACTOR cycle (includes testing anti-patterns reference)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Debugging&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;systematic-debugging&lt;/strong&gt; - 4-phase root cause process (includes root-cause-tracing, defense-in-depth, condition-based-waiting techniques)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;verification-before-completion&lt;/strong&gt; - Ensure it's actually fixed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Collaboration&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;brainstorming&lt;/strong&gt; - Socratic design refinement&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;writing-plans&lt;/strong&gt; - Detailed implementation plans&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;executing-plans&lt;/strong&gt; - Batch execution with checkpoints&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;dispatching-parallel-agents&lt;/strong&gt; - Concurrent subagent workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;requesting-code-review&lt;/strong&gt; - Pre-review checklist&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;receiving-code-review&lt;/strong&gt; - Responding to feedback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;using-git-worktrees&lt;/strong&gt; - Parallel development branches&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;finishing-a-development-branch&lt;/strong&gt; - Merge/PR decision workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;subagent-driven-development&lt;/strong&gt; - Fast iteration with two-stage review (spec compliance, then code quality)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Meta&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;writing-skills&lt;/strong&gt; - Create new skills following best practices (includes testing methodology)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;using-superpowers&lt;/strong&gt; - Introduction to the skills system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Test-Driven Development&lt;/strong&gt; - Write tests first, always&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Systematic over ad-hoc&lt;/strong&gt; - Process over guessing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complexity reduction&lt;/strong&gt; - Simplicity as primary goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evidence over claims&lt;/strong&gt; - Verify before declaring success&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more: &lt;a href="https://blog.fsck.com/2025/10/09/superpowers/"&gt;Superpowers for Claude Code&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Skills live directly in this repository. To contribute:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a branch for your skill&lt;/li&gt; 
 &lt;li&gt;Follow the &lt;code&gt;writing-skills&lt;/code&gt; skill for creating and testing new skills&lt;/li&gt; 
 &lt;li&gt;Submit a PR&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;code&gt;skills/writing-skills/SKILL.md&lt;/code&gt; for the complete guide.&lt;/p&gt; 
&lt;h2&gt;Updating&lt;/h2&gt; 
&lt;p&gt;Skills update automatically when you update the plugin:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin update superpowers
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License - see LICENSE file for details&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/obra/superpowers/issues"&gt;https://github.com/obra/superpowers/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Marketplace&lt;/strong&gt;: &lt;a href="https://github.com/obra/superpowers-marketplace"&gt;https://github.com/obra/superpowers-marketplace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>google/googletest</title>
      <link>https://github.com/google/googletest</link>
      <description>&lt;p&gt;GoogleTest - Google Testing and Mocking Framework&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GoogleTest&lt;/h1&gt; 
&lt;h3&gt;Announcements&lt;/h3&gt; 
&lt;h4&gt;Documentation Updates&lt;/h4&gt; 
&lt;p&gt;Our documentation is now live on GitHub Pages at &lt;a href="https://google.github.io/googletest/"&gt;https://google.github.io/googletest/&lt;/a&gt;. We recommend browsing the documentation on GitHub Pages rather than directly in the repository.&lt;/p&gt; 
&lt;h4&gt;Release 1.17.0&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/google/googletest/releases/tag/v1.17.0"&gt;Release 1.17.0&lt;/a&gt; is now available.&lt;/p&gt; 
&lt;p&gt;The 1.17.x branch &lt;a href="https://opensource.google/documentation/policies/cplusplus-support#c_language_standard"&gt;requires at least C++17&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Continuous Integration&lt;/h4&gt; 
&lt;p&gt;We use Google's internal systems for continuous integration.&lt;/p&gt; 
&lt;h4&gt;Coming Soon&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;We are planning to take a dependency on &lt;a href="https://github.com/abseil/abseil-cpp"&gt;Abseil&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Welcome to &lt;strong&gt;GoogleTest&lt;/strong&gt;, Google's C++ test framework!&lt;/h2&gt; 
&lt;p&gt;This repository is a merger of the formerly separate GoogleTest and GoogleMock projects. These were so closely related that it makes sense to maintain and release them together.&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://google.github.io/googletest/"&gt;GoogleTest User's Guide&lt;/a&gt; for documentation. We recommend starting with the &lt;a href="https://google.github.io/googletest/primer.html"&gt;GoogleTest Primer&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;More information about building GoogleTest can be found at &lt;a href="https://raw.githubusercontent.com/google/googletest/main/googletest/README.md"&gt;googletest/README.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;xUnit test framework: &lt;br /&gt; Googletest is based on the &lt;a href="https://en.wikipedia.org/wiki/XUnit"&gt;xUnit&lt;/a&gt; testing framework, a popular architecture for unit testing&lt;/li&gt; 
 &lt;li&gt;Test discovery: &lt;br /&gt; Googletest automatically discovers and runs your tests, eliminating the need to manually register your tests&lt;/li&gt; 
 &lt;li&gt;Rich set of assertions: &lt;br /&gt; Googletest provides a variety of assertions, such as equality, inequality, exceptions, and more, making it easy to test your code&lt;/li&gt; 
 &lt;li&gt;User-defined assertions: &lt;br /&gt; You can define your own assertions with Googletest, making it simple to write tests that are specific to your code&lt;/li&gt; 
 &lt;li&gt;Death tests: &lt;br /&gt; Googletest supports death tests, which verify that your code exits in a certain way, making it useful for testing error-handling code&lt;/li&gt; 
 &lt;li&gt;Fatal and non-fatal failures: &lt;br /&gt; You can specify whether a test failure should be treated as fatal or non-fatal with Googletest, allowing tests to continue running even if a failure occurs&lt;/li&gt; 
 &lt;li&gt;Value-parameterized tests: &lt;br /&gt; Googletest supports value-parameterized tests, which run multiple times with different input values, making it useful for testing functions that take different inputs&lt;/li&gt; 
 &lt;li&gt;Type-parameterized tests: &lt;br /&gt; Googletest also supports type-parameterized tests, which run with different data types, making it useful for testing functions that work with different data types&lt;/li&gt; 
 &lt;li&gt;Various options for running tests: &lt;br /&gt; Googletest provides many options for running tests including running individual tests, running tests in a specific order and running tests in parallel&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Platforms&lt;/h2&gt; 
&lt;p&gt;GoogleTest follows Google's &lt;a href="https://opensource.google/documentation/policies/cplusplus-support"&gt;Foundational C++ Support Policy&lt;/a&gt;. See &lt;a href="https://github.com/google/oss-policies-info/raw/main/foundational-cxx-support-matrix.md"&gt;this table&lt;/a&gt; for a list of currently supported versions of compilers, platforms, and build tools.&lt;/p&gt; 
&lt;h2&gt;Who Is Using GoogleTest?&lt;/h2&gt; 
&lt;p&gt;In addition to many internal projects at Google, GoogleTest is also used by the following notable projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://www.chromium.org/"&gt;Chromium projects&lt;/a&gt; (behind the Chrome browser and Chrome OS).&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://llvm.org/"&gt;LLVM&lt;/a&gt; compiler.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/protobuf"&gt;Protocol Buffers&lt;/a&gt;, Google's data interchange format.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://opencv.org/"&gt;OpenCV&lt;/a&gt; computer vision library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related Open Source Projects&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/nholthaus/gtest-runner"&gt;GTest Runner&lt;/a&gt; is a Qt5 based automated test-runner and Graphical User Interface with powerful features for Windows and Linux platforms.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ospector/gtest-gbar"&gt;GoogleTest UI&lt;/a&gt; is a test runner that runs your test binary, allows you to track its progress via a progress bar, and displays a list of test failures. Clicking on one shows failure text. GoogleTest UI is written in C#.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kinow/gtest-tap-listener"&gt;GTest TAP Listener&lt;/a&gt; is an event listener for GoogleTest that implements the &lt;a href="https://en.wikipedia.org/wiki/Test_Anything_Protocol"&gt;TAP protocol&lt;/a&gt; for test result output. If your test runner understands TAP, you may find it useful.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/google/gtest-parallel"&gt;gtest-parallel&lt;/a&gt; is a test runner that runs tests from your binary in parallel to provide significant speed-up.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=DavidSchuldenfrei.gtest-adapter"&gt;GoogleTest Adapter&lt;/a&gt; is a VS Code extension allowing to view GoogleTest in a tree view and run/debug your tests.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/matepek/vscode-catch2-test-adapter"&gt;C++ TestMate&lt;/a&gt; is a VS Code extension allowing to view GoogleTest in a tree view and run/debug your tests.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/cornichon/"&gt;Cornichon&lt;/a&gt; is a small Gherkin DSL parser that generates stub code for GoogleTest.&lt;/p&gt; 
&lt;h2&gt;Contributing Changes&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href="https://github.com/google/googletest/raw/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for details on how to contribute to this project.&lt;/p&gt; 
&lt;p&gt;Happy testing!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NevaMind-AI/memU</title>
      <link>https://github.com/NevaMind-AI/memU</link>
      <description>&lt;p&gt;Memory infrastructure for LLMs and AI agents&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/banner.png" alt="MemU Banner" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;MemU&lt;/h1&gt; 
 &lt;h3&gt;A Future-Oriented Agentic Memory System&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/memu-py"&gt;&lt;img src="https://badge.fury.io/py/memu-py.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.13+-blue.svg?sanitize=true" alt="Python 3.13+" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/memu"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Chat-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/memU_ai"&gt;&lt;img src="https://img.shields.io/badge/Twitter-Follow-1DA1F2?logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/17374" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/17374" alt="NevaMind-AI%2FmemU | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;MemU is an agentic memory framework for LLM and AI agent backends. It receives &lt;strong&gt;multimodal inputs&lt;/strong&gt; (conversations, documents, images), extracts them into structured memory, and organizes them into a &lt;strong&gt;hierarchical file system&lt;/strong&gt; that supports both &lt;strong&gt;embedding-based (RAG)&lt;/strong&gt; and &lt;strong&gt;non-embedding (LLM)&lt;/strong&gt; retrieval.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠êÔ∏è Star the repository&lt;/h2&gt; 
&lt;img width="100%" src="https://github.com/NevaMind-AI/memU/raw/main/assets/star.gif" /&gt; If you find memU useful or interesting, a GitHub Star ‚≠êÔ∏è would be greatly appreciated. 
&lt;hr /&gt; 
&lt;p&gt;MemU is collaborating with four open-source projects to launch the 2026 New Year Challenge. üéâBetween January 8‚Äì18, contributors can submit PRs to memU and earn cash rewards, community recognition, and platform credits. üéÅ&lt;a href="https://discord.gg/KaWy6SBAsx"&gt;Learn more &amp;amp; get involved&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Core Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üóÇÔ∏è &lt;strong&gt;Hierarchical File System&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Three-layer architecture: Resource ‚Üí Item ‚Üí Category with full traceability&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîç &lt;strong&gt;Dual Retrieval Methods&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RAG (embedding-based) for speed, LLM (non-embedding) for deep semantic understanding&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üé® &lt;strong&gt;Multimodal Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process conversations, documents, images, audio, and video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîÑ &lt;strong&gt;Self-Evolving Memory&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Memory structure adapts and improves based on usage patterns&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üóÇÔ∏è Hierarchical File System&lt;/h2&gt; 
&lt;p&gt;MemU organizes memory using a &lt;strong&gt;three-layer architecture&lt;/strong&gt; inspired by hierarchical storage systems:&lt;/p&gt; 
&lt;img width="100%" alt="structure" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/structure.png" /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Layer&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Resource&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Raw multimodal data warehouse&lt;/td&gt; 
   &lt;td&gt;JSON conversations, text documents, images, videos&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Item&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Discrete extracted memory units&lt;/td&gt; 
   &lt;td&gt;Individual preferences, skills, opinions, habits&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Category&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Aggregated textual memory with summaries&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;preferences.md&lt;/code&gt;, &lt;code&gt;work_life.md&lt;/code&gt;, &lt;code&gt;relationships.md&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Key Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full Traceability&lt;/strong&gt;: Track from raw data ‚Üí items ‚Üí categories and back&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Progressive Summarization&lt;/strong&gt;: Each layer provides increasingly abstracted views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Organization&lt;/strong&gt;: Categories evolve based on content patterns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üé® Multimodal Support&lt;/h2&gt; 
&lt;p&gt;MemU processes diverse content types into unified memory:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Modality&lt;/th&gt; 
   &lt;th&gt;Input&lt;/th&gt; 
   &lt;th&gt;Processing&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;conversation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;JSON chat logs&lt;/td&gt; 
   &lt;td&gt;Extract preferences, opinions, habits, relationships&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;document&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Text files (.txt, .md)&lt;/td&gt; 
   &lt;td&gt;Extract knowledge, skills, facts&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;image&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;PNG, JPG, etc.&lt;/td&gt; 
   &lt;td&gt;Vision model extracts visual concepts and descriptions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;video&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Video files&lt;/td&gt; 
   &lt;td&gt;Frame extraction + vision analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;audio&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Audio files&lt;/td&gt; 
   &lt;td&gt;Transcription + text processing&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;All modalities are unified into the same three-layer hierarchy, enabling cross-modal retrieval.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Option 1: Cloud Version&lt;/h3&gt; 
&lt;p&gt;Try MemU instantly without any setup:&lt;/p&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://memu.so"&gt;memu.so&lt;/a&gt;&lt;/strong&gt; - Hosted cloud service with full API access&lt;/p&gt; 
&lt;p&gt;For enterprise deployment and custom solutions, contact &lt;strong&gt;&lt;a href="mailto:info@nevamind.ai"&gt;info@nevamind.ai&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Cloud API (v3)&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Base URL&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;https://api.memu.so&lt;/code&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Auth&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Authorization: Bearer YOUR_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Endpoint&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/memorize&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register a memorization task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GET&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/memorize/status/{task_id}&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Get task status&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/categories&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;List memory categories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/retrieve&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Retrieve memories (semantic search)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;üìö &lt;strong&gt;&lt;a href="https://memu.pro/docs#cloud-version"&gt;Full API Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Option 2: Self-Hosted&lt;/h3&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Basic Example&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Requirements&lt;/strong&gt;: Python 3.13+ and an OpenAI API key&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Test with In-Memory Storage&lt;/strong&gt; (no database required):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
cd tests
python test_inmemory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Test with PostgreSQL Storage&lt;/strong&gt; (requires pgvector):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector
docker run -d \
  --name memu-postgres \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=memu \
  -p 5432:5432 \
  pgvector/pgvector:pg16

# Run the test
export OPENAI_API_KEY=your_api_key
cd tests
python test_postgres.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Both examples demonstrate the complete workflow:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Memorize&lt;/strong&gt;: Process a conversation file and extract structured memory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Retrieve (RAG)&lt;/strong&gt;: Fast embedding-based search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Retrieve (LLM)&lt;/strong&gt;: Deep semantic understanding search&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/tests/test_inmemory.py"&gt;&lt;code&gt;tests/test_inmemory.py&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/tests/test_postgres.py"&gt;&lt;code&gt;tests/test_postgres.py&lt;/code&gt;&lt;/a&gt; for the full source code.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Custom LLM and Embedding Providers&lt;/h3&gt; 
&lt;p&gt;MemU supports custom LLM and embedding providers beyond OpenAI. Configure them via &lt;code&gt;llm_profiles&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memu import MemUService

service = MemUService(
    llm_profiles={
        # Default profile for LLM operations
        "default": {
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": "your_api_key",
            "chat_model": "qwen3-max",
            "client_backend": "sdk"  # "sdk" or "http"
        },
        # Separate profile for embeddings
        "embedding": {
            "base_url": "https://api.voyageai.com/v1",
            "api_key": "your_voyage_api_key",
            "embed_model": "voyage-3.5-lite"
        }
    },
    # ... other configuration
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìñ Core APIs&lt;/h2&gt; 
&lt;h3&gt;&lt;code&gt;memorize()&lt;/code&gt; - Extract and Store Memory&lt;/h3&gt; 
&lt;p&gt;Processes input resources and extracts structured memory:&lt;/p&gt; 
&lt;img width="100%" alt="memorize" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/memorize.png" /&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result = await service.memorize(
    resource_url="path/to/file.json",  # File path or URL
    modality="conversation",            # conversation | document | image | video | audio
    user={"user_id": "123"}             # Optional: scope to a user
)

# Returns:
{
    "resource": {...},      # Stored resource metadata
    "items": [...],         # Extracted memory items
    "categories": [...]     # Updated category summaries
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;retrieve()&lt;/code&gt; - Query Memory&lt;/h3&gt; 
&lt;p&gt;Retrieves relevant memory based on queries. MemU supports &lt;strong&gt;two retrieval strategies&lt;/strong&gt;:&lt;/p&gt; 
&lt;img width="100%" alt="retrieve" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/retrieve.png" /&gt; 
&lt;h4&gt;RAG-based Retrieval (&lt;code&gt;method="rag"&lt;/code&gt;)&lt;/h4&gt; 
&lt;p&gt;Fast &lt;strong&gt;embedding vector search&lt;/strong&gt; using cosine similarity:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Fast&lt;/strong&gt;: Pure vector computation&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Scalable&lt;/strong&gt;: Efficient for large memory stores&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Returns scores&lt;/strong&gt;: Each result includes similarity score&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;LLM-based Retrieval (&lt;code&gt;method="llm"&lt;/code&gt;)&lt;/h4&gt; 
&lt;p&gt;Deep &lt;strong&gt;semantic understanding&lt;/strong&gt; through direct LLM reasoning:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Deep understanding&lt;/strong&gt;: LLM comprehends context and nuance&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Query rewriting&lt;/strong&gt;: Automatically refines query at each tier&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Adaptive&lt;/strong&gt;: Stops early when sufficient information is found&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Comparison&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;RAG&lt;/th&gt; 
   &lt;th&gt;LLM&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Speed&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚ö° Fast&lt;/td&gt; 
   &lt;td&gt;üê¢ Slower&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üí∞ Low&lt;/td&gt; 
   &lt;td&gt;üí∞üí∞ Higher&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Semantic depth&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medium&lt;/td&gt; 
   &lt;td&gt;Deep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Tier 2 scope&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All items&lt;/td&gt; 
   &lt;td&gt;Only items in relevant categories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;With similarity scores&lt;/td&gt; 
   &lt;td&gt;Ranked by LLM reasoning&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Both methods support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Context-aware rewriting&lt;/strong&gt;: Resolves pronouns using conversation history&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Progressive search&lt;/strong&gt;: Categories ‚Üí Items ‚Üí Resources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sufficiency checking&lt;/strong&gt;: Stops when enough information is retrieved&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result = await service.retrieve(
    queries=[
        {"role": "user", "content": {"text": "What are their preferences?"}},
        {"role": "user", "content": {"text": "Tell me about work habits"}}
    ],
    where={"user_id": "123"}  # Optional: scope filter
)

# Returns:
{
    "categories": [...],     # Relevant categories (with scores for RAG)
    "items": [...],          # Relevant memory items
    "resources": [...],      # Related raw resources
    "next_step_query": "..." # Rewritten query for follow-up (if applicable)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Scope Filtering&lt;/strong&gt;: Use &lt;code&gt;where&lt;/code&gt; to filter by user model fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;where={"user_id": "123"}&lt;/code&gt; - exact match&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;where={"agent_id__in": ["1", "2"]}&lt;/code&gt; - match any in list&lt;/li&gt; 
 &lt;li&gt;Omit &lt;code&gt;where&lt;/code&gt; to retrieve across all scopes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìö &lt;strong&gt;For complete API documentation&lt;/strong&gt;, see &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/docs/SERVICE_API.md"&gt;SERVICE_API.md&lt;/a&gt; - includes all methods, CRUD operations, pipeline configuration, and configuration types.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° Use Cases&lt;/h2&gt; 
&lt;h3&gt;Example 1: Conversation Memory&lt;/h3&gt; 
&lt;p&gt;Extract and organize memory from multi-turn conversations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_1_conversation_memory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Processes multiple conversation JSON files&lt;/li&gt; 
 &lt;li&gt;Extracts memory items (preferences, habits, opinions, relationships)&lt;/li&gt; 
 &lt;li&gt;Generates category markdown files (&lt;code&gt;preferences.md&lt;/code&gt;, &lt;code&gt;work_life.md&lt;/code&gt;, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Personal AI assistants, customer support bots, social chatbots&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Example 2: Skill Extraction from Logs&lt;/h3&gt; 
&lt;p&gt;Extract skills and lessons learned from agent execution logs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_2_skill_extraction.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Processes agent logs sequentially&lt;/li&gt; 
 &lt;li&gt;Extracts actions, outcomes, and lessons learned&lt;/li&gt; 
 &lt;li&gt;Demonstrates &lt;strong&gt;incremental learning&lt;/strong&gt; - memory evolves with each file&lt;/li&gt; 
 &lt;li&gt;Generates evolving skill guides (&lt;code&gt;log_1.md&lt;/code&gt; ‚Üí &lt;code&gt;log_2.md&lt;/code&gt; ‚Üí &lt;code&gt;skill.md&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; DevOps teams, agent self-improvement, knowledge management&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Example 3: Multimodal Memory&lt;/h3&gt; 
&lt;p&gt;Process diverse content types into unified memory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_3_multimodal_memory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Processes documents and images together&lt;/li&gt; 
 &lt;li&gt;Extracts memory from different content types&lt;/li&gt; 
 &lt;li&gt;Unifies into cross-modal categories (&lt;code&gt;technical_documentation&lt;/code&gt;, &lt;code&gt;visual_diagrams&lt;/code&gt;, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Documentation systems, learning platforms, research tools&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìä Performance&lt;/h2&gt; 
&lt;p&gt;MemU achieves &lt;strong&gt;92.09% average accuracy&lt;/strong&gt; on the Locomo benchmark across all reasoning tasks.&lt;/p&gt; 
&lt;img width="100%" alt="benchmark" src="https://github.com/user-attachments/assets/6fec4884-94e5-4058-ad5c-baac3d7e76d9" /&gt; 
&lt;p&gt;View detailed experimental data: &lt;a href="https://github.com/NevaMind-AI/memU-experiment"&gt;memU-experiment&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üß© Ecosystem&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Repository&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU"&gt;memU&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Core algorithm engine&lt;/td&gt; 
   &lt;td&gt;Embed AI memory into your product&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU-server"&gt;memU-server&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Backend service with CRUD, user system, RBAC&lt;/td&gt; 
   &lt;td&gt;Self-host a memory backend&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU-ui"&gt;memU-ui&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Visual dashboard&lt;/td&gt; 
   &lt;td&gt;Ready-to-use memory console&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Links:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;a href="https://app.memu.so/quick-start"&gt;Try MemU Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìö &lt;a href="https://memu.pro/docs"&gt;API Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://discord.gg/memu"&gt;Discord Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Partners&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework"&gt;&lt;img src="https://avatars.githubusercontent.com/u/113095513?s=200&amp;amp;v=4" alt="Ten" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://openagents.org"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/openagents.png" alt="OpenAgents" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/milvus-io/milvus"&gt;&lt;img src="https://miro.medium.com/v2/resize:fit:2400/1*-VEGyAgcIBD62XtZWavy8w.png" alt="Milvus" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://xroute.ai/"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/xroute.png" alt="xRoute" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://jaaz.app/"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/jazz.png" alt="Jazz" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Buddie-AI/Buddie"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/buddie.png" alt="Buddie" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/bytebase/bytebase"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/bytebase.png" alt="Bytebase" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/LazyAGI/LazyLLM"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/LazyLLM.png" alt="LazyLLM" height="40" style="margin: 10px;" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù How to Contribute&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding features, or improving documentation, your help is appreciated.&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;p&gt;To start contributing to MemU, you'll need to set up your development environment:&lt;/p&gt; 
&lt;h4&gt;Prerequisites&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.13+&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (Python package manager)&lt;/li&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Setup Development Environment&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Fork and clone the repository
git clone https://github.com/YOUR_USERNAME/memU.git
cd memU

# 2. Install development dependencies
make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;make install&lt;/code&gt; command will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment using &lt;code&gt;uv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install all project dependencies&lt;/li&gt; 
 &lt;li&gt;Set up pre-commit hooks for code quality checks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Running Quality Checks&lt;/h4&gt; 
&lt;p&gt;Before submitting your contribution, ensure your code passes all quality checks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make check
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;make check&lt;/code&gt; command runs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lock file verification&lt;/strong&gt;: Ensures &lt;code&gt;pyproject.toml&lt;/code&gt; consistency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-commit hooks&lt;/strong&gt;: Lints code with Ruff, formats with Black&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type checking&lt;/strong&gt;: Runs &lt;code&gt;mypy&lt;/code&gt; for static type analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependency analysis&lt;/strong&gt;: Uses &lt;code&gt;deptry&lt;/code&gt; to find obsolete dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing Guidelines&lt;/h3&gt; 
&lt;p&gt;For detailed contribution guidelines, code standards, and development practices, please see &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick tips:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a new branch for each feature or bug fix&lt;/li&gt; 
 &lt;li&gt;Write clear commit messages&lt;/li&gt; 
 &lt;li&gt;Add tests for new functionality&lt;/li&gt; 
 &lt;li&gt;Update documentation as needed&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;make check&lt;/code&gt; before pushing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/LICENSE.txt"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåç Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/NevaMind-AI/memU/issues"&gt;Report bugs &amp;amp; request features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;a href="https://discord.com/invite/hQZntfGsbJ"&gt;Join the community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;X (Twitter)&lt;/strong&gt;: &lt;a href="https://x.com/memU_ai"&gt;Follow @memU_ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contact&lt;/strong&gt;: &lt;a href="mailto:info@nevamind.ai"&gt;info@nevamind.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Star us on GitHub&lt;/strong&gt; to get notified about new releases!&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>github/awesome-copilot</title>
      <link>https://github.com/github/awesome-copilot</link>
      <description>&lt;p&gt;Community-contributed instructions, prompts, and configurations to help you make the most of GitHub Copilot.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ü§ñ Awesome GitHub Copilot Customizations&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://aka.ms/awesome-github-copilot"&gt;&lt;img src="https://img.shields.io/badge/Powered_by-Awesome_Copilot-blue?logo=githubcopilot" alt="Powered by Awesome Copilot" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/#contributors-"&gt;&lt;img src="https://img.shields.io/badge/all_contributors-93-orange.svg?style=flat-square" alt="All Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-BADGE:END --&gt; 
&lt;p&gt;A community created collection of custom agents, prompts, and instructions to supercharge your GitHub Copilot experience across different domains, languages, and use cases.&lt;/p&gt; 
&lt;h2&gt;üöÄ What is Awesome GitHub Copilot?&lt;/h2&gt; 
&lt;p&gt;This repository provides a comprehensive toolkit for enhancing GitHub Copilot with specialized:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üëâ &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/docs/README.agents.md"&gt;Awesome Agents&lt;/a&gt;&lt;/strong&gt; - Specialized GitHub Copilot agents that integrate with MCP servers to provide enhanced capabilities for specific workflows and tools&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üëâ &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/docs/README.prompts.md"&gt;Awesome Prompts&lt;/a&gt;&lt;/strong&gt; - Focused, task-specific prompts for generating code, documentation, and solving specific problems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üëâ &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/docs/README.instructions.md"&gt;Awesome Instructions&lt;/a&gt;&lt;/strong&gt; - Comprehensive coding standards and best practices that apply to specific file patterns or entire projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üëâ &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/docs/README.skills.md"&gt;Awesome Skills&lt;/a&gt;&lt;/strong&gt; - Self-contained folders with instructions and bundled resources that enhance AI capabilities for specialized tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üëâ &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/docs/README.collections.md"&gt;Awesome Collections&lt;/a&gt;&lt;/strong&gt; - Curated collections of related prompts, instructions, and chat modes organized around specific themes and workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåü Featured Collections&lt;/h2&gt; 
&lt;p&gt;Discover our curated collections of prompts, instructions, and agents organized around specific themes and workflows.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Items&lt;/th&gt; 
   &lt;th&gt;Tags&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/collections/awesome-copilot.md"&gt;Awesome Copilot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Meta prompts that help you discover and generate curated GitHub Copilot chat modes, collections, instructions, prompts, and agents.&lt;/td&gt; 
   &lt;td&gt;6 items&lt;/td&gt; 
   &lt;td&gt;github-copilot, discovery, meta, prompt-engineering, agents&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/collections/partners.md"&gt;Partners&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Custom agents that have been created by GitHub partners&lt;/td&gt; 
   &lt;td&gt;20 items&lt;/td&gt; 
   &lt;td&gt;devops, security, database, cloud, infrastructure, observability, feature-flags, cicd, migration, performance&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;MCP Server&lt;/h2&gt; 
&lt;p&gt;To make it easy to add these customizations to your editor, we have created a &lt;a href="https://developer.microsoft.com/blog/announcing-awesome-copilot-mcp-server"&gt;MCP Server&lt;/a&gt; that provides a prompt for searching and installing prompts, instructions, and chat modes directly from this repository. You'll need to have Docker installed and running to run the server.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aka.ms/awesome-copilot/mcp/vscode"&gt;&lt;img src="https://img.shields.io/badge/VS_Code-Install-0098FF?logo=visualstudiocode&amp;amp;logoColor=white" alt="Install in VS Code" /&gt;&lt;/a&gt; &lt;a href="https://aka.ms/awesome-copilot/mcp/vscode-insiders"&gt;&lt;img src="https://img.shields.io/badge/VS_Code_Insiders-Install-24bfa5?logo=visualstudiocode&amp;amp;logoColor=white" alt="Install in VS Code Insiders" /&gt;&lt;/a&gt; &lt;a href="https://aka.ms/awesome-copilot/mcp/vs"&gt;&lt;img src="https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&amp;amp;logoColor=white" alt="Install in Visual Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Show MCP Server JSON configuration&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "servers": {
    "awesome-copilot": {
      "type": "stdio",
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "ghcr.io/microsoft/mcp-dotnet-samples/awesome-copilot:latest"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;üîß How to Use&lt;/h2&gt; 
&lt;h3&gt;ü§ñ Custom Agents&lt;/h3&gt; 
&lt;p&gt;Custom agents can be used in Copilot coding agent (CCA), VS Code, and Copilot CLI (coming soon). For CCA, when assigning an issue to Copilot, select the custom agent from the provided list. In VS Code, you can activate the custom agent in the agents session, alongside built-in agents like Plan and Agent.&lt;/p&gt; 
&lt;h3&gt;üéØ Prompts&lt;/h3&gt; 
&lt;p&gt;Use the &lt;code&gt;/&lt;/code&gt; command in GitHub Copilot Chat to access prompts:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-plaintext"&gt;/awesome-copilot create-readme
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üìã Instructions&lt;/h3&gt; 
&lt;p&gt;Instructions automatically apply to files based on their patterns and provide contextual guidance for coding standards, frameworks, and best practices.&lt;/p&gt; 
&lt;h2&gt;üéØ Why Use Awesome GitHub Copilot?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Productivity&lt;/strong&gt;: Pre-built agents, prompts and instructions save time and provide consistent results.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Best Practices&lt;/strong&gt;: Benefit from community-curated coding standards and patterns.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Specialized Assistance&lt;/strong&gt;: Access expert-level guidance through specialized custom agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Continuous Learning&lt;/strong&gt;: Stay updated with the latest patterns and practices across technologies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt; for details on how to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add new prompts, instructions, or chat modes&lt;/li&gt; 
 &lt;li&gt;Improve existing content&lt;/li&gt; 
 &lt;li&gt;Report issues or suggest enhancements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For AI coding agents working with this project, refer to &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/AGENTS.md"&gt;AGENTS.md&lt;/a&gt; for detailed technical guidance on development workflows, setup commands, and contribution standards.&lt;/p&gt; 
&lt;h3&gt;Quick Contribution Guide&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Follow our file naming conventions and frontmatter requirements&lt;/li&gt; 
 &lt;li&gt;Test your contributions thoroughly&lt;/li&gt; 
 &lt;li&gt;Update the appropriate README tables&lt;/li&gt; 
 &lt;li&gt;Submit a pull request with a clear description&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìñ Repository Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-plaintext"&gt;‚îú‚îÄ‚îÄ prompts/          # Task-specific prompts (.prompt.md)
‚îú‚îÄ‚îÄ instructions/     # Coding standards and best practices (.instructions.md)
‚îú‚îÄ‚îÄ agents/           # AI personas and specialized modes (.agent.md)
‚îú‚îÄ‚îÄ collections/      # Curated collections of related items (.collection.yml)
‚îî‚îÄ‚îÄ scripts/          # Utility scripts for maintenance
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üõ°Ô∏è Security &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Security Issues&lt;/strong&gt;: Please see our &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/SECURITY.md"&gt;Security Policy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support&lt;/strong&gt;: Check our &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/SUPPORT.md"&gt;Support Guide&lt;/a&gt; for getting help&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code of Conduct&lt;/strong&gt;: We follow the &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/CODE_OF_CONDUCT.md"&gt;Contributor Covenant&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ÑπÔ∏è Disclaimer&lt;/h2&gt; 
&lt;p&gt;The customizations in this repository are sourced from and created by third-party developers. GitHub does not verify, endorse, or guarantee the functionality or security of these agents. Please carefully inspect any agent and its documentation before installing to understand permissions it may require and actions it may perform.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Ready to supercharge your coding experience?&lt;/strong&gt; Start exploring our &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/docs/README.prompts.md"&gt;prompts&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/docs/README.instructions.md"&gt;instructions&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/docs/README.agents.md"&gt;custom agents&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Contributors ‚ú®&lt;/h2&gt; 
&lt;p&gt;Thanks goes to these wonderful people (&lt;a href="https://allcontributors.org/docs/en/emoji-key"&gt;emoji key&lt;/a&gt;):&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.aaron-powell.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/434140?v=4?s=100" width="100px;" alt="Aaron Powell" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aaron Powell&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=aaronpowell" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/#maintenance-aaronpowell" title="Maintenance"&gt;üöß&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/#projectManagement-aaronpowell" title="Project Management"&gt;üìÜ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/#promotion-aaronpowell" title="Promotion"&gt;üì£&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://mubaidr.js.org/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2222702?v=4?s=100" width="100px;" alt="Muhammad Ubaid Raza" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Muhammad Ubaid Raza&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mubaidr" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://digitarald.de/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/8599?v=4?s=100" width="100px;" alt="Harald Kirschner" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Harald Kirschner&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=digitarald" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/mbianchidev"&gt;&lt;img src="https://avatars.githubusercontent.com/u/37507190?v=4?s=100" width="100px;" alt="Matteo Bianchi" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matteo Bianchi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mbianchidev" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/AungMyoKyaw"&gt;&lt;img src="https://avatars.githubusercontent.com/u/9404824?v=4?s=100" width="100px;" alt="Aung Myo Kyaw" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aung Myo Kyaw&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=AungMyoKyaw" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://danielscottraynsford.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/7589164?v=4?s=100" width="100px;" alt="Daniel Scott-Raynsford" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Daniel Scott-Raynsford&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=PlagueHO" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/burkeholland"&gt;&lt;img src="https://avatars.githubusercontent.com/u/686963?v=4?s=100" width="100px;" alt="Burke Holland" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Burke Holland&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=burkeholland" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://calva.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/30010?v=4?s=100" width="100px;" alt="Peter Str√∂mberg" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Peter Str√∂mberg&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=PEZ" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.devprodlogs.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/51440732?v=4?s=100" width="100px;" alt="Daniel Meppiel" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Daniel Meppiel&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=danielmeppiel" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://montemagno.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1676321?v=4?s=100" width="100px;" alt="James Montemagno" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;James Montemagno&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=jamesmontemagno" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/VamshiVerma"&gt;&lt;img src="https://avatars.githubusercontent.com/u/21999324?v=4?s=100" width="100px;" alt="Vamshi Verma" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vamshi Verma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=VamshiVerma" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/sinedied"&gt;&lt;img src="https://avatars.githubusercontent.com/u/593151?v=4?s=100" width="100px;" alt="Yohan Lasorsa" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yohan Lasorsa&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=sinedied" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/OrenMe"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5461862?v=4?s=100" width="100px;" alt="Oren Me" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Oren Me&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=OrenMe" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/mjrousos"&gt;&lt;img src="https://avatars.githubusercontent.com/u/10077254?v=4?s=100" width="100px;" alt="Mike Rousos" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mike Rousos&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mjrousos" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/guiopen"&gt;&lt;img src="https://avatars.githubusercontent.com/u/94094527?v=4?s=100" width="100px;" alt="Guilherme do Amaral Alves " /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Guilherme do Amaral Alves &lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=guiopen" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.buymeacoffee.com/troystaylor"&gt;&lt;img src="https://avatars.githubusercontent.com/u/44444967?v=4?s=100" width="100px;" alt="Troy Simeon Taylor" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Troy Simeon Taylor&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=troystaylor" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.linkedin.com/in/ambilykk/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/10282550?v=4?s=100" width="100px;" alt="Ambily" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ambily&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=ambilykk" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://tgrall.github.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/541250?v=4?s=100" width="100px;" alt="Tugdual Grall" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tugdual Grall&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=tgrall" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/TianqiZhang"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5326582?v=4?s=100" width="100px;" alt="Tianqi Zhang" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tianqi Zhang&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=TianqiZhang" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/shubham070"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5480589?v=4?s=100" width="100px;" alt="Shubham Gaikwad" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Shubham Gaikwad&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=shubham070" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/sdolgin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/576449?v=4?s=100" width="100px;" alt="Saul Dolgin" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Saul Dolgin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=sdolgin" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/nullchimp"&gt;&lt;img src="https://avatars.githubusercontent.com/u/58362593?v=4?s=100" width="100px;" alt="NULLchimp" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;NULLchimp&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=nullchimp" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/MattVevang"&gt;&lt;img src="https://avatars.githubusercontent.com/u/20714898?v=4?s=100" width="100px;" alt="Matt Vevang" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matt Vevang&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=MattVevang" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://devkimchi.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1538528?v=4?s=100" width="100px;" alt="Justin Yoo" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Justin Yoo&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=justinyoo" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://hachyderm.io/@0gis0"&gt;&lt;img src="https://avatars.githubusercontent.com/u/175379?v=4?s=100" width="100px;" alt="Gisela Torres" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Gisela Torres&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=0GiS0" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://debbie.codes/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/13063165?v=4?s=100" width="100px;" alt="Debbie O'Brien" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Debbie O'Brien&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=debs-obrien" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/agreaves-ms"&gt;&lt;img src="https://avatars.githubusercontent.com/u/111466195?v=4?s=100" width="100px;" alt="Allen Greaves" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Allen Greaves&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=agreaves-ms" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/AmeliaRose802"&gt;&lt;img src="https://avatars.githubusercontent.com/u/26167931?v=4?s=100" width="100px;" alt="Amelia Payne" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Amelia Payne&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=AmeliaRose802" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/SebastienDegodez"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2349146?v=4?s=100" width="100px;" alt="Sebastien DEGODEZ" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sebastien DEGODEZ&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=SebastienDegodez" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://graef.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/19261257?v=4?s=100" width="100px;" alt="Sebastian Gr√§f" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sebastian Gr√§f&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=segraef" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://9ssi7.dev/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/76786120?v=4?s=100" width="100px;" alt="Salih ƒ∞brahimba≈ü" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Salih ƒ∞brahimba≈ü&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=9ssi7" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/inquinity"&gt;&lt;img src="https://avatars.githubusercontent.com/u/406234?v=4?s=100" width="100px;" alt="Robert Altman" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Robert Altman&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=inquinity" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/pertrai1"&gt;&lt;img src="https://avatars.githubusercontent.com/u/442374?v=4?s=100" width="100px;" alt="Rob Simpson" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rob Simpson&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=pertrai1" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://ricksm.it/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/7207783?v=4?s=100" width="100px;" alt="Rick Smit" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rick Smit&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=ricksmit3000" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://dotneteers.net/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/28162552?v=4?s=100" width="100px;" alt="Peter Smulovics" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Peter Smulovics&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=psmulovics" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/pelikhan"&gt;&lt;img src="https://avatars.githubusercontent.com/u/4175913?v=4?s=100" width="100px;" alt="Peli de Halleux" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Peli de Halleux&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=pelikhan" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.paulomorgado.net/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/470455?v=4?s=100" width="100px;" alt="Paulo Morgado" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Paulo Morgado&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=paulomorgado" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://nickyt.co/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/833231?v=4?s=100" width="100px;" alt="Nick Taylor" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Nick Taylor&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=nickytonline" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/mikeparker104"&gt;&lt;img src="https://avatars.githubusercontent.com/u/12763221?v=4?s=100" width="100px;" alt="Mike Parker" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mike Parker&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mikeparker104" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/mikekistler"&gt;&lt;img src="https://avatars.githubusercontent.com/u/85643503?v=4?s=100" width="100px;" alt="Mike Kistler" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mike Kistler&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mikekistler" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://a11ysupport.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/498678?v=4?s=100" width="100px;" alt="Michael Fairchild" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Michael Fairchild&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mfairchild365" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.linkedin.com/in/michael-volz/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/129928?v=4?s=100" width="100px;" alt="Michael A. Volz (Flynn)" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Michael A. Volz (Flynn)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=michaelvolz" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/4regab"&gt;&lt;img src="https://avatars.githubusercontent.com/u/178603515?v=4?s=100" width="100px;" alt="4regab" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;4regab&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=4regab" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/TheovanKraay"&gt;&lt;img src="https://avatars.githubusercontent.com/u/24420698?v=4?s=100" width="100px;" alt="Theo van Kraay" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Theo van Kraay&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=TheovanKraay" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://glsauto.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/132710946?v=4?s=100" width="100px;" alt="Troy Witthoeft (glsauto)" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Troy Witthoeft (glsauto)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=twitthoeft-gls" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/iletai"&gt;&lt;img src="https://avatars.githubusercontent.com/u/26614687?v=4?s=100" width="100px;" alt="T√†i L√™" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;T√†i L√™&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=iletai" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://tinyurl.com/3p5j9mwe"&gt;&lt;img src="https://avatars.githubusercontent.com/u/9591887?v=4?s=100" width="100px;" alt="Udaya Veeramreddygari" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Udaya Veeramreddygari&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=udayakumarreddyv" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://bio.warengonzaga.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/15052701?v=4?s=100" width="100px;" alt="Waren Gonzaga" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Waren Gonzaga&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=warengonzaga" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://blog.miniasp.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/88981?v=4?s=100" width="100px;" alt="Will ‰øùÂì•" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Will ‰øùÂì•&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=doggy8088" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/yukiomoto"&gt;&lt;img src="https://avatars.githubusercontent.com/u/38450410?v=4?s=100" width="100px;" alt="Yuki Omoto" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yuki Omoto&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=yukiomoto" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/hueanmy"&gt;&lt;img src="https://avatars.githubusercontent.com/u/20430626?v=4?s=100" width="100px;" alt="Meii" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Meii&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=hueanmy" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/samqbush"&gt;&lt;img src="https://avatars.githubusercontent.com/u/74389839?v=4?s=100" width="100px;" alt="samqbush" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;samqbush&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=samqbush" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/sdanzo-hrb"&gt;&lt;img src="https://avatars.githubusercontent.com/u/136493100?v=4?s=100" width="100px;" alt="sdanzo-hrb" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;sdanzo-hrb&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=sdanzo-hrb" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/voidfnc"&gt;&lt;img src="https://avatars.githubusercontent.com/u/194750710?v=4?s=100" width="100px;" alt="voidfnc" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;voidfnc&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=voidfnc" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/webreidi"&gt;&lt;img src="https://avatars.githubusercontent.com/u/55603905?v=4?s=100" width="100px;" alt="Wendy Breiding" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Wendy Breiding&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=webreidi" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/zooav"&gt;&lt;img src="https://avatars.githubusercontent.com/u/12625412?v=4?s=100" width="100px;" alt="Ankur Sharma" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ankur Sharma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=zooav" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://jianminhuang.cc/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/6296280?v=4?s=100" width="100px;" alt="ÈªÉÂÅ•Êóª Vincent Huang" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;ÈªÉÂÅ•Êóª Vincent Huang&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=Jian-Min-Huang" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/dgh06175"&gt;&lt;img src="https://avatars.githubusercontent.com/u/77305722?v=4?s=100" width="100px;" alt="Ïù¥ÏÉÅÌòÑ" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ïù¥ÏÉÅÌòÑ&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=dgh06175" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/abdidaudpropel"&gt;&lt;img src="https://avatars.githubusercontent.com/u/51310019?v=4?s=100" width="100px;" alt="Abdi Daud" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abdi Daud&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=abdidaudpropel" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://www.senseof.tech/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/50712277?v=4?s=100" width="100px;" alt="Adrien Clerbois" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Adrien Clerbois&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=AClerbois" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://www.qreate.it/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1868590?v=4?s=100" width="100px;" alt="Alan Sprecacenere" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alan Sprecacenere&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=tegola" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://asilva.dev/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2493377?v=4?s=100" width="100px;" alt="Andr√© Silva" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Andr√© Silva&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=askpt" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://javaetmoi.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/838318?v=4?s=100" width="100px;" alt="Antoine Rey" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Antoine Rey&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=arey" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/artemsaveliev"&gt;&lt;img src="https://avatars.githubusercontent.com/u/15679218?v=4?s=100" width="100px;" alt="Artem Saveliev" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Artem Saveliev&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=artemsaveliev" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://brunoborges.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/129743?v=4?s=100" width="100px;" alt="Bruno Borges" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bruno Borges&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=brunoborges" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.peug.net/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/3845786?v=4?s=100" width="100px;" alt="Christophe Peugnet" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Christophe Peugnet&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=tossnet" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.movinglive.ca/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/14792628?v=4?s=100" width="100px;" alt="Chtive" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Chtive&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=MovingLive" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/craigbekker"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1115912?v=4?s=100" width="100px;" alt="Craig Bekker" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Craig Bekker&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=craigbekker" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/breakid"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1446918?v=4?s=100" width="100px;" alt="Dan" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=breakid" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/ewega"&gt;&lt;img src="https://avatars.githubusercontent.com/u/26189114?v=4?s=100" width="100px;" alt="Eldrick Wega" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Eldrick Wega&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=ewega" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.felixarjuna.dev/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/79026094?v=4?s=100" width="100px;" alt="Felix Arjuna" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Felix Arjuna&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=felixarjuna" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/feapaydin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/19946639?v=4?s=100" width="100px;" alt="Furkan Enes" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Furkan Enes&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=feapaydin" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://learn.microsoft.com/dotnet"&gt;&lt;img src="https://avatars.githubusercontent.com/u/24882762?v=4?s=100" width="100px;" alt="Genevieve Warren" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Genevieve Warren&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=gewarren" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/geoder101"&gt;&lt;img src="https://avatars.githubusercontent.com/u/145904?v=4?s=100" width="100px;" alt="George Dernikos" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;George Dernikos&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=geoder101" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/giomartinsdev"&gt;&lt;img src="https://avatars.githubusercontent.com/u/125399281?v=4?s=100" width="100px;" alt="Giovanni de Almeida Martins" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Giovanni de Almeida Martins&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=giomartinsdev" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/Ioana37"&gt;&lt;img src="https://avatars.githubusercontent.com/u/69301842?v=4?s=100" width="100px;" alt="Ioana A" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ioana A&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=Ioana37" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/nohwnd"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5735905?v=4?s=100" width="100px;" alt="Jakub Jare≈°" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jakub Jare≈°&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=nohwnd" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://joe-watkins.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/3695795?v=4?s=100" width="100px;" alt="Joe Watkins" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Joe Watkins&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=joe-watkins" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://johnpapa.net/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1202528?v=4?s=100" width="100px;" alt="John Papa" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;John Papa&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=johnpapa" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://www.sugbo4j.co.nz/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/15100839?v=4?s=100" width="100px;" alt="Joseph Gonzales" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Joseph Gonzales&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=josephgonzales01" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://digio.es/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/173672918?v=4?s=100" width="100px;" alt="Jos√© Antonio Garrido" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jos√© Antonio Garrido&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=josegarridodigio" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/Ranrar"&gt;&lt;img src="https://avatars.githubusercontent.com/u/95967772?v=4?s=100" width="100px;" alt="Kim Skov Rasmussen" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kim Skov Rasmussen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=Ranrar" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/whiteken"&gt;&lt;img src="https://avatars.githubusercontent.com/u/20211937?v=4?s=100" width="100px;" alt="Kenny White" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kenny White&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=whiteken" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/LouellaCreemers"&gt;&lt;img src="https://avatars.githubusercontent.com/u/46204894?v=4?s=100" width="100px;" alt="Louella Creemers" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Louella Creemers&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=LouellaCreemers" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://linktr.ee/lukemurray"&gt;&lt;img src="https://avatars.githubusercontent.com/u/24467442?v=4?s=100" width="100px;" alt="Luke Murray" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Luke Murray&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=lukemurraynz" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://marknoble.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/3819700?v=4?s=100" width="100px;" alt="Mark Noble" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mark Noble&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=marknoble" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://soderlind.no"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1649452?v=4?s=100" width="100px;" alt="Per S√∏derlind" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Per S√∏derlind&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=soderlind" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/riqueufmg"&gt;&lt;img src="https://avatars.githubusercontent.com/u/108551585?v=4?s=100" width="100px;" alt="Henrique Nunes" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Henrique Nunes&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=riqueufmg" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/jeremiah-snee-openx"&gt;&lt;img src="https://avatars.githubusercontent.com/u/113928685?v=4?s=100" width="100px;" alt="Jeremiah Snee" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jeremiah Snee&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=jeremiah-snee-openx" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/spectatora"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1385755?v=4?s=100" width="100px;" alt="spectatora" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;spectatora&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=spectatora" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/Mike-Hanna"&gt;&lt;img src="https://avatars.githubusercontent.com/u/50142889?v=4?s=100" width="100px;" alt="Michael" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Michael&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=Mike-Hanna" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/lechnerc77"&gt;&lt;img src="https://avatars.githubusercontent.com/u/22294087?v=4?s=100" width="100px;" alt="Christian Lechner" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Christian Lechner&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=lechnerc77" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://jan-v.nl"&gt;&lt;img src="https://avatars.githubusercontent.com/u/462356?v=4?s=100" width="100px;" alt="Jan de Vries" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jan de Vries&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=Jandev" title="Code"&gt;üíª&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tfoot&gt; 
  &lt;tr&gt; 
   &lt;td align="center" size="13px" colspan="7"&gt; &lt;img src="https://raw.githubusercontent.com/all-contributors/all-contributors-cli/1b8533af435da9854653492b1327a23a4dbd0a10/assets/logo-small.svg?sanitize=true" /&gt; &lt;a href="https://all-contributors.js.org/docs/en/bot/usage"&gt;Add your contributions&lt;/a&gt;  &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tfoot&gt; 
&lt;/table&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;p&gt;This project follows the &lt;a href="https://github.com/all-contributors/all-contributors"&gt;all-contributors&lt;/a&gt; specification. Contributions of any kind welcome!&lt;/p&gt; 
&lt;h2&gt;üìö Additional Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/docs/copilot/copilot-customization"&gt;VS Code Copilot Customization Documentation&lt;/a&gt; - Official Microsoft documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/docs/copilot/chat/copilot-chat"&gt;GitHub Copilot Chat Documentation&lt;/a&gt; - Complete chat feature guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/docs/copilot/chat/chat-modes"&gt;Custom Chat Modes&lt;/a&gt; - Advanced chat configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/docs/getstarted/settings"&gt;VS Code Settings&lt;/a&gt; - General VS Code configuration guide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚Ñ¢Ô∏è Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ChromeDevTools/chrome-devtools-mcp</title>
      <link>https://github.com/ChromeDevTools/chrome-devtools-mcp</link>
      <description>&lt;p&gt;Chrome DevTools for coding agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Chrome DevTools MCP&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://npmjs.org/package/chrome-devtools-mcp"&gt;&lt;img src="https://img.shields.io/npm/v/chrome-devtools-mcp.svg?sanitize=true" alt="npm chrome-devtools-mcp package" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;chrome-devtools-mcp&lt;/code&gt; lets your coding agent (such as Gemini, Claude, Cursor or Copilot) control and inspect a live Chrome browser. It acts as a Model-Context-Protocol (MCP) server, giving your AI coding assistant access to the full power of Chrome DevTools for reliable automation, in-depth debugging, and performance analysis.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md"&gt;Tool reference&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/CHANGELOG.md"&gt;Changelog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/troubleshooting.md"&gt;Troubleshooting&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/design-principles.md"&gt;Design Principles&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Key features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Get performance insights&lt;/strong&gt;: Uses &lt;a href="https://github.com/ChromeDevTools/devtools-frontend"&gt;Chrome DevTools&lt;/a&gt; to record traces and extract actionable performance insights.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced browser debugging&lt;/strong&gt;: Analyze network requests, take screenshots and check the browser console.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable automation&lt;/strong&gt;. Uses &lt;a href="https://github.com/puppeteer/puppeteer"&gt;puppeteer&lt;/a&gt; to automate actions in Chrome and automatically wait for action results.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimers&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;chrome-devtools-mcp&lt;/code&gt; exposes content of the browser instance to the MCP clients allowing them to inspect, debug, and modify any data in the browser or DevTools. Avoid sharing sensitive or personal information that you don't want to share with MCP clients.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; v20.19 or a newer &lt;a href="https://github.com/nodejs/Release#release-schedule"&gt;latest maintenance LTS&lt;/a&gt; version.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.google.com/chrome/"&gt;Chrome&lt;/a&gt; current stable version or newer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/"&gt;npm&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Add the following config to your MCP client:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": ["-y", "chrome-devtools-mcp@latest"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; Using &lt;code&gt;chrome-devtools-mcp@latest&lt;/code&gt; ensures that your MCP client will always use the latest version of the Chrome DevTools MCP server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;MCP Client configuration&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Amp&lt;/summary&gt; Follow https://ampcode.com/manual#mcp and use the config provided above. You can also install the Chrome DevTools MCP server using the CLI: 
 &lt;pre&gt;&lt;code class="language-bash"&gt;amp mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Antigravity&lt;/summary&gt; 
 &lt;p&gt;To use the Chrome DevTools MCP server follow the instructions from &lt;a href="https://antigravity.google/docs/mcp"&gt;Antigravity's docs&lt;/a&gt;&lt;a&gt;&lt;/a&gt; to install a custom MCP server. Add the following config to the MCP servers config:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--browser-url=http://127.0.0.1:9222",
        "-y"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This will make the Chrome DevTools MCP server automatically connect to the browser that Antigravity is using. If you are not using port 9222, make sure to adjust accordingly.&lt;/p&gt; 
 &lt;p&gt;Chrome DevTools MCP will not start the browser instance automatically using this approach as as the Chrome DevTools MCP server runs in Antigravity's built-in browser. If the browser is not already running, you have to start it first by clicking the Chrome icon at the top right corner.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Claude Code&lt;/summary&gt; Use the Claude Code CLI to add the Chrome DevTools MCP server (
 &lt;a href="https://docs.anthropic.com/en/docs/claude-code/mcp"&gt;guide&lt;/a&gt;): 
 &lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add chrome-devtools npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Cline&lt;/summary&gt; Follow https://docs.cline.bot/mcp/configuring-mcp-servers and use the config provided above. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Codex&lt;/summary&gt; Follow the 
 &lt;a href="https://github.com/openai/codex/raw/main/docs/advanced.md#model-context-protocol-mcp"&gt;configure MCP guide&lt;/a&gt; using the standard config from above. You can also install the Chrome DevTools MCP server using the Codex CLI: 
 &lt;pre&gt;&lt;code class="language-bash"&gt;codex mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;On Windows 11&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Configure the Chrome install location and increase the startup timeout by updating &lt;code&gt;.codex/config.toml&lt;/code&gt; and adding the following &lt;code&gt;env&lt;/code&gt; and &lt;code&gt;startup_timeout_ms&lt;/code&gt; parameters:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;[mcp_servers.chrome-devtools]
command = "cmd"
args = [
    "/c",
    "npx",
    "-y",
    "chrome-devtools-mcp@latest",
]
env = { SystemRoot="C:\\Windows", PROGRAMFILES="C:\\Program Files" }
startup_timeout_ms = 20_000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Copilot CLI&lt;/summary&gt; 
 &lt;p&gt;Start Copilot CLI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;copilot
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Start the dialog to add a new MCP server by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;/mcp add
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Configure the following fields and press &lt;code&gt;CTRL+S&lt;/code&gt; to save the configuration:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Server name:&lt;/strong&gt; &lt;code&gt;chrome-devtools&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Server Type:&lt;/strong&gt; &lt;code&gt;[1] Local&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Command:&lt;/strong&gt; &lt;code&gt;npx -y chrome-devtools-mcp@latest&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Copilot / VS Code&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Click the button to install:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://vscode.dev/redirect/mcp/install?name=io.github.ChromeDevTools%2Fchrome-devtools-mcp&amp;amp;config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22chrome-devtools-mcp%22%5D%2C%22env%22%3A%7B%7D%7D"&gt;&lt;img src="https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&amp;amp;label=Install%20Server&amp;amp;color=0098FF" alt="Install in VS Code" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522io.github.ChromeDevTools%252Fchrome-devtools-mcp%2522%252C%2522config%2522%253A%257B%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522chrome-devtools-mcp%2522%255D%252C%2522env%2522%253A%257B%257D%257D%257D"&gt;&lt;img src="https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&amp;amp;label=Install%20Server&amp;amp;color=24bfa5" alt="Install in VS Code Insiders" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Or install manually:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Follow the MCP install &lt;a href="https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server"&gt;guide&lt;/a&gt;, with the standard config from above. You can also install the Chrome DevTools MCP server using the VS Code CLI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;code --add-mcp '{"name":"io.github.ChromeDevTools/chrome-devtools-mcp","command":"npx","args":["-y","chrome-devtools-mcp"],"env":{}}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Cursor&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Click the button to install:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://cursor.com/en/install-mcp?name=chrome-devtools&amp;amp;config=eyJjb21tYW5kIjoibnB4IC15IGNocm9tZS1kZXZ0b29scy1tY3BAbGF0ZXN0In0%3D"&gt;&lt;img src="https://cursor.com/deeplink/mcp-install-dark.svg?sanitize=true" alt="Install in Cursor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Or install manually:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Go to &lt;code&gt;Cursor Settings&lt;/code&gt; -&amp;gt; &lt;code&gt;MCP&lt;/code&gt; -&amp;gt; &lt;code&gt;New MCP Server&lt;/code&gt;. Use the config provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Factory CLI&lt;/summary&gt; Use the Factory CLI to add the Chrome DevTools MCP server (
 &lt;a href="https://docs.factory.ai/cli/configuration/mcp"&gt;guide&lt;/a&gt;): 
 &lt;pre&gt;&lt;code class="language-bash"&gt;droid mcp add chrome-devtools "npx -y chrome-devtools-mcp@latest"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini CLI&lt;/summary&gt; Install the Chrome DevTools MCP server using the Gemini CLI. 
 &lt;p&gt;&lt;strong&gt;Project wide:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;gemini mcp add chrome-devtools npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Globally:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;gemini mcp add -s user chrome-devtools npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Alternatively, follow the &lt;a href="https://github.com/google-gemini/gemini-cli/raw/main/docs/tools/mcp-server.md#how-to-set-up-your-mcp-server"&gt;MCP guide&lt;/a&gt; and use the standard config from above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini Code Assist&lt;/summary&gt; Follow the 
 &lt;a href="https://cloud.google.com/gemini/docs/codeassist/use-agentic-chat-pair-programmer#configure-mcp-servers"&gt;configure MCP guide&lt;/a&gt; using the standard config from above. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;JetBrains AI Assistant &amp;amp; Junie&lt;/summary&gt; 
 &lt;p&gt;Go to &lt;code&gt;Settings | Tools | AI Assistant | Model Context Protocol (MCP)&lt;/code&gt; -&amp;gt; &lt;code&gt;Add&lt;/code&gt;. Use the config provided above. The same way chrome-devtools-mcp can be configured for JetBrains Junie in &lt;code&gt;Settings | Tools | Junie | MCP Settings&lt;/code&gt; -&amp;gt; &lt;code&gt;Add&lt;/code&gt;. Use the config provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Kiro&lt;/summary&gt; 
 &lt;p&gt;In &lt;strong&gt;Kiro Settings&lt;/strong&gt;, go to &lt;code&gt;Configure MCP&lt;/code&gt; &amp;gt; &lt;code&gt;Open Workspace or User MCP Config&lt;/code&gt; &amp;gt; Use the configuration snippet provided above.&lt;/p&gt; 
 &lt;p&gt;Or, from the IDE &lt;strong&gt;Activity Bar&lt;/strong&gt; &amp;gt; &lt;code&gt;Kiro&lt;/code&gt; &amp;gt; &lt;code&gt;MCP Servers&lt;/code&gt; &amp;gt; &lt;code&gt;Click Open MCP Config&lt;/code&gt;. Use the configuration snippet provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenCode&lt;/summary&gt; 
 &lt;p&gt;Add the following configuration to your &lt;code&gt;opencode.json&lt;/code&gt; file. If you don't have one, create it at &lt;code&gt;~/.config/opencode/opencode.json&lt;/code&gt; (&lt;a href="https://opencode.ai/docs/mcp-servers"&gt;guide&lt;/a&gt;):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://opencode.ai/config.json",
  "mcp": {
    "chrome-devtools": {
      "type": "local",
      "command": ["npx", "-y", "chrome-devtools-mcp@latest"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qoder&lt;/summary&gt; 
 &lt;p&gt;In &lt;strong&gt;Qoder Settings&lt;/strong&gt;, go to &lt;code&gt;MCP Server&lt;/code&gt; &amp;gt; &lt;code&gt;+ Add&lt;/code&gt; &amp;gt; Use the configuration snippet provided above.&lt;/p&gt; 
 &lt;p&gt;Alternatively, follow the &lt;a href="https://docs.qoder.com/user-guide/chat/model-context-protocol"&gt;MCP guide&lt;/a&gt; and use the standard config from above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qoder CLI&lt;/summary&gt; 
 &lt;p&gt;Install the Chrome DevTools MCP server using the Qoder CLI (&lt;a href="https://docs.qoder.com/cli/using-cli#mcp-servsers"&gt;guide&lt;/a&gt;):&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Project wide:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;qodercli mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Globally:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;qodercli mcp add -s user chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Visual Studio&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Click the button to install:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://vs-open.link/mcp-install?%7B%22name%22%3A%22chrome-devtools%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22chrome-devtools-mcp%40latest%22%5D%7D"&gt;&lt;img src="https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&amp;amp;logoColor=white" alt="Install in Visual Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Warp&lt;/summary&gt; 
 &lt;p&gt;Go to &lt;code&gt;Settings | AI | Manage MCP Servers&lt;/code&gt; -&amp;gt; &lt;code&gt;+ Add&lt;/code&gt; to &lt;a href="https://docs.warp.dev/knowledge-and-collaboration/mcp#adding-an-mcp-server"&gt;add an MCP Server&lt;/a&gt;. Use the config provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Windsurf&lt;/summary&gt; Follow the 
 &lt;a href="https://docs.windsurf.com/windsurf/cascade/mcp#mcp-config-json"&gt;configure MCP guide&lt;/a&gt; using the standard config from above. 
&lt;/details&gt; 
&lt;h3&gt;Your first prompt&lt;/h3&gt; 
&lt;p&gt;Enter the following prompt in your MCP Client to check if everything is working:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Check the performance of https://developers.chrome.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Your MCP client should open the browser and record a performance trace.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; The MCP server will start the browser automatically once the MCP client uses a tool that requires a running browser instance. Connecting to the Chrome DevTools MCP server on its own will not automatically start the browser.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Tools&lt;/h2&gt; 
&lt;p&gt;If you run into any issues, checkout our &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/troubleshooting.md"&gt;troubleshooting guide&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- BEGIN AUTO GENERATED TOOLS --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Input automation&lt;/strong&gt; (8 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#click"&gt;&lt;code&gt;click&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#drag"&gt;&lt;code&gt;drag&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#fill"&gt;&lt;code&gt;fill&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#fill_form"&gt;&lt;code&gt;fill_form&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#handle_dialog"&gt;&lt;code&gt;handle_dialog&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#hover"&gt;&lt;code&gt;hover&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#press_key"&gt;&lt;code&gt;press_key&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#upload_file"&gt;&lt;code&gt;upload_file&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Navigation automation&lt;/strong&gt; (6 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#close_page"&gt;&lt;code&gt;close_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#list_pages"&gt;&lt;code&gt;list_pages&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#navigate_page"&gt;&lt;code&gt;navigate_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#new_page"&gt;&lt;code&gt;new_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#select_page"&gt;&lt;code&gt;select_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#wait_for"&gt;&lt;code&gt;wait_for&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Emulation&lt;/strong&gt; (2 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#emulate"&gt;&lt;code&gt;emulate&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#resize_page"&gt;&lt;code&gt;resize_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; (3 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#performance_analyze_insight"&gt;&lt;code&gt;performance_analyze_insight&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#performance_start_trace"&gt;&lt;code&gt;performance_start_trace&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#performance_stop_trace"&gt;&lt;code&gt;performance_stop_trace&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network&lt;/strong&gt; (2 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#get_network_request"&gt;&lt;code&gt;get_network_request&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#list_network_requests"&gt;&lt;code&gt;list_network_requests&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debugging&lt;/strong&gt; (5 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#evaluate_script"&gt;&lt;code&gt;evaluate_script&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#get_console_message"&gt;&lt;code&gt;get_console_message&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#list_console_messages"&gt;&lt;code&gt;list_console_messages&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#take_screenshot"&gt;&lt;code&gt;take_screenshot&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#take_snapshot"&gt;&lt;code&gt;take_snapshot&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END AUTO GENERATED TOOLS --&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;The Chrome DevTools MCP server supports the following configuration option:&lt;/p&gt; 
&lt;!-- BEGIN AUTO GENERATED OPTIONS --&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--autoConnect&lt;/code&gt;/ &lt;code&gt;--auto-connect&lt;/code&gt;&lt;/strong&gt; If specified, automatically connects to a browser (Chrome 145+) running in the user data directory identified by the channel param. Requires remote debugging being enabled in Chrome here: chrome://inspect/#remote-debugging.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--browserUrl&lt;/code&gt;/ &lt;code&gt;--browser-url&lt;/code&gt;, &lt;code&gt;-u&lt;/code&gt;&lt;/strong&gt; Connect to a running, debuggable Chrome instance (e.g. &lt;code&gt;http://127.0.0.1:9222&lt;/code&gt;). For more details see: &lt;a href="https://github.com/ChromeDevTools/chrome-devtools-mcp#connecting-to-a-running-chrome-instance"&gt;https://github.com/ChromeDevTools/chrome-devtools-mcp#connecting-to-a-running-chrome-instance&lt;/a&gt;.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--wsEndpoint&lt;/code&gt;/ &lt;code&gt;--ws-endpoint&lt;/code&gt;, &lt;code&gt;-w&lt;/code&gt;&lt;/strong&gt; WebSocket endpoint to connect to a running Chrome instance (e.g., ws://127.0.0.1:9222/devtools/browser/
   &lt;id&gt;
    ). Alternative to --browserUrl.
   &lt;/id&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--wsHeaders&lt;/code&gt;/ &lt;code&gt;--ws-headers&lt;/code&gt;&lt;/strong&gt; Custom headers for WebSocket connection in JSON format (e.g., '{"Authorization":"Bearer token"}'). Only works with --wsEndpoint.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--headless&lt;/code&gt;&lt;/strong&gt; Whether to run in headless (no UI) mode.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--executablePath&lt;/code&gt;/ &lt;code&gt;--executable-path&lt;/code&gt;, &lt;code&gt;-e&lt;/code&gt;&lt;/strong&gt; Path to custom Chrome executable.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--isolated&lt;/code&gt;&lt;/strong&gt; If specified, creates a temporary user-data-dir that is automatically cleaned up after the browser is closed. Defaults to false.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--userDataDir&lt;/code&gt;/ &lt;code&gt;--user-data-dir&lt;/code&gt;&lt;/strong&gt; Path to the user data directory for Chrome. Default is $HOME/.cache/chrome-devtools-mcp/chrome-profile$CHANNEL_SUFFIX_IF_NON_STABLE&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--channel&lt;/code&gt;&lt;/strong&gt; Specify a different Chrome channel that should be used. The default is the stable channel version.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Choices:&lt;/strong&gt; &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;canary&lt;/code&gt;, &lt;code&gt;beta&lt;/code&gt;, &lt;code&gt;dev&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--logFile&lt;/code&gt;/ &lt;code&gt;--log-file&lt;/code&gt;&lt;/strong&gt; Path to a file to write debug logs to. Set the env variable &lt;code&gt;DEBUG&lt;/code&gt; to &lt;code&gt;*&lt;/code&gt; to enable verbose logs. Useful for submitting bug reports.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--viewport&lt;/code&gt;&lt;/strong&gt; Initial viewport size for the Chrome instances started by the server. For example, &lt;code&gt;1280x720&lt;/code&gt;. In headless mode, max size is 3840x2160px.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--proxyServer&lt;/code&gt;/ &lt;code&gt;--proxy-server&lt;/code&gt;&lt;/strong&gt; Proxy server configuration for Chrome passed as --proxy-server when launching the browser. See &lt;a href="https://www.chromium.org/developers/design-documents/network-settings/"&gt;https://www.chromium.org/developers/design-documents/network-settings/&lt;/a&gt; for details.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--acceptInsecureCerts&lt;/code&gt;/ &lt;code&gt;--accept-insecure-certs&lt;/code&gt;&lt;/strong&gt; If enabled, ignores errors relative to self-signed and expired certificates. Use with caution.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--chromeArg&lt;/code&gt;/ &lt;code&gt;--chrome-arg&lt;/code&gt;&lt;/strong&gt; Additional arguments for Chrome. Only applies when Chrome is launched by chrome-devtools-mcp.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; array&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--categoryEmulation&lt;/code&gt;/ &lt;code&gt;--category-emulation&lt;/code&gt;&lt;/strong&gt; Set to false to exclude tools related to emulation.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--categoryPerformance&lt;/code&gt;/ &lt;code&gt;--category-performance&lt;/code&gt;&lt;/strong&gt; Set to false to exclude tools related to performance.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--categoryNetwork&lt;/code&gt;/ &lt;code&gt;--category-network&lt;/code&gt;&lt;/strong&gt; Set to false to exclude tools related to network.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END AUTO GENERATED OPTIONS --&gt; 
&lt;p&gt;Pass them via the &lt;code&gt;args&lt;/code&gt; property in the JSON configuration. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--channel=canary",
        "--headless=true",
        "--isolated=true"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting via WebSocket with custom headers&lt;/h3&gt; 
&lt;p&gt;You can connect directly to a Chrome WebSocket endpoint and include custom headers (e.g., for authentication):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--wsEndpoint=ws://127.0.0.1:9222/devtools/browser/&amp;lt;id&amp;gt;",
        "--wsHeaders={\"Authorization\":\"Bearer YOUR_TOKEN\"}"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To get the WebSocket endpoint from a running Chrome instance, visit &lt;code&gt;http://127.0.0.1:9222/json/version&lt;/code&gt; and look for the &lt;code&gt;webSocketDebuggerUrl&lt;/code&gt; field.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;npx chrome-devtools-mcp@latest --help&lt;/code&gt; to see all available configuration options.&lt;/p&gt; 
&lt;h2&gt;Concepts&lt;/h2&gt; 
&lt;h3&gt;User data directory&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;chrome-devtools-mcp&lt;/code&gt; starts a Chrome's stable channel instance using the following user data directory:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Linux / macOS: &lt;code&gt;$HOME/.cache/chrome-devtools-mcp/chrome-profile-$CHANNEL&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Windows: &lt;code&gt;%HOMEPATH%/.cache/chrome-devtools-mcp/chrome-profile-$CHANNEL&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The user data directory is not cleared between runs and shared across all instances of &lt;code&gt;chrome-devtools-mcp&lt;/code&gt;. Set the &lt;code&gt;isolated&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt; to use a temporary user data dir instead which will be cleared automatically after the browser is closed.&lt;/p&gt; 
&lt;h3&gt;Connecting to a running Chrome instance&lt;/h3&gt; 
&lt;p&gt;By default, the Chrome DevTools MCP server will start a new Chrome instance with a dedicated profile. This might not be ideal in all situations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you would like to maintain the same application state when alternating between manual site testing and agent-driven testing.&lt;/li&gt; 
 &lt;li&gt;When the MCP needs to sign into a website. Some accounts may prevent sign-in when the browser is controlled via WebDriver (the default launch mechanism for the Chrome DevTools MCP server).&lt;/li&gt; 
 &lt;li&gt;If you're running your LLM inside a sandboxed environment, but you would like to connect to a Chrome instance that runs outside the sandbox.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In these cases, start Chrome first and let the Chrome DevTools MCP server connect to it. There are two ways to do so:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic connection (available in Chrome 144)&lt;/strong&gt;: best for sharing state between manual and agent-driven testing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manual connection via remote debugging port&lt;/strong&gt;: best when running inside a sandboxed environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Automatically connecting to a running Chrome instance&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Set up remote debugging in Chrome&lt;/p&gt; 
&lt;p&gt;In Chrome (&amp;gt;= M144), do the following to set up remote debugging:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;chrome://inspect/#remote-debugging&lt;/code&gt; to enable remote debugging.&lt;/li&gt; 
 &lt;li&gt;Follow the dialog UI to allow or disallow incoming debugging connections.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Configure Chrome DevTools MCP server to automatically connect to a running Chrome Instance&lt;/p&gt; 
&lt;p&gt;To connect the &lt;code&gt;chrome-devtools-mcp&lt;/code&gt; server to the running Chrome instance, use &lt;code&gt;--autoConnect&lt;/code&gt; command line argument for the MCP server.&lt;/p&gt; 
&lt;p&gt;The following code snippet is an example configuration for gemini-cli:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": ["chrome-devtools-mcp@latest", "--autoConnect", "--channel=beta"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: you have to specify &lt;code&gt;--channel=beta&lt;/code&gt; until Chrome M144 has reached the stable channel.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Test your setup&lt;/p&gt; 
&lt;p&gt;Make sure your browser is running. Open gemini-cli and run the following prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-none"&gt;Check the performance of https://developers.chrome.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; The &lt;code&gt;autoConnect&lt;/code&gt; option requires the user to start Chrome. If the user has multiple active profiles, the MCP server will connect to the default profile (as determined by Chrome). The MCP server has access to all open windows for the selected profile.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The Chrome DevTools MCP server will try to connect to your running Chrome instance. It shows a dialog asking for user permission.&lt;/p&gt; 
&lt;p&gt;Clicking &lt;strong&gt;Allow&lt;/strong&gt; results in the Chrome DevTools MCP server opening &lt;a href="http://developers.chrome.com"&gt;developers.chrome.com&lt;/a&gt; and taking a performance trace.&lt;/p&gt; 
&lt;h4&gt;Manual connection using port forwarding&lt;/h4&gt; 
&lt;p&gt;You can connect to a running Chrome instance by using the &lt;code&gt;--browser-url&lt;/code&gt; option. This is useful if you are running the MCP server in a sandboxed environment that does not allow starting a new Chrome instance.&lt;/p&gt; 
&lt;p&gt;Here is a step-by-step guide on how to connect to a running Chrome instance:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 1: Configure the MCP client&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Add the &lt;code&gt;--browser-url&lt;/code&gt; option to your MCP client configuration. The value of this option should be the URL of the running Chrome instance. &lt;code&gt;http://127.0.0.1:9222&lt;/code&gt; is a common default.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--browser-url=http://127.0.0.1:9222"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 2: Start the Chrome browser&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;br /&gt; Enabling the remote debugging port opens up a debugging port on the running browser instance. Any application on your machine can connect to this port and control the browser. Make sure that you are not browsing any sensitive websites while the debugging port is open.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Start the Chrome browser with the remote debugging port enabled. Make sure to close any running Chrome instances before starting a new one with the debugging port enabled. The port number you choose must be the same as the one you specified in the &lt;code&gt;--browser-url&lt;/code&gt; option in your MCP client configuration.&lt;/p&gt; 
&lt;p&gt;For security reasons, &lt;a href="https://developer.chrome.com/blog/remote-debugging-port"&gt;Chrome requires you to use a non-default user data directory&lt;/a&gt; when enabling the remote debugging port. You can specify a custom directory using the &lt;code&gt;--user-data-dir&lt;/code&gt; flag. This ensures that your regular browsing profile and data are not exposed to the debugging session.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --remote-debugging-port=9222 --user-data-dir=/tmp/chrome-profile-stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Linux&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/usr/bin/google-chrome --remote-debugging-port=9222 --user-data-dir=/tmp/chrome-profile-stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;"C:\Program Files\Google\Chrome\Application\chrome.exe" --remote-debugging-port=9222 --user-data-dir="%TEMP%\chrome-profile-stable"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 3: Test your setup&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;After configuring the MCP client and starting the Chrome browser, you can test your setup by running a simple prompt in your MCP client:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Check the performance of https://developers.chrome.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Your MCP client should connect to the running Chrome instance and receive a performance report.&lt;/p&gt; 
&lt;p&gt;If you hit VM-to-host port forwarding issues, see the ‚ÄúRemote debugging between virtual machine (VM) and host fails‚Äù section in &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/troubleshooting.md#remote-debugging-between-virtual-machine-vm-and-host-fails"&gt;&lt;code&gt;docs/troubleshooting.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more details on remote debugging, see the &lt;a href="https://developer.chrome.com/docs/devtools/remote-debugging/"&gt;Chrome DevTools documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Known limitations&lt;/h2&gt; 
&lt;h3&gt;Operating system sandboxes&lt;/h3&gt; 
&lt;p&gt;Some MCP clients allow sandboxing the MCP server using macOS Seatbelt or Linux containers. If sandboxes are enabled, &lt;code&gt;chrome-devtools-mcp&lt;/code&gt; is not able to start Chrome that requires permissions to create its own sandboxes. As a workaround, either disable sandboxing for &lt;code&gt;chrome-devtools-mcp&lt;/code&gt; in your MCP client or use &lt;code&gt;--browser-url&lt;/code&gt; to connect to a Chrome instance that you start manually outside of the MCP client sandbox.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>twentyhq/twenty</title>
      <link>https://github.com/twentyhq/twenty</link>
      <description>&lt;p&gt;Building a modern alternative to Salesforce, powered by the community.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.twenty.com"&gt; &lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/core/logo.svg?sanitize=true" width="100px" alt="Twenty logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2 align="center"&gt;The #1 Open-Source CRM &lt;/h2&gt; 
&lt;p align="center"&gt;&lt;a href="https://twenty.com"&gt;üåê Website&lt;/a&gt; ¬∑ &lt;a href="https://docs.twenty.com"&gt;üìö Documentation&lt;/a&gt; ¬∑ &lt;a href="https://github.com/orgs/twentyhq/projects/1"&gt;&lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/planner-icon.svg?sanitize=true" width="12" height="12" /&gt; Roadmap &lt;/a&gt; ¬∑ &lt;a href="https://discord.gg/cx5n4Jzs57"&gt;&lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/discord-icon.svg?sanitize=true" width="12" height="12" /&gt; Discord&lt;/a&gt; ¬∑ &lt;a href="https://www.figma.com/file/xt8O9mFeLl46C5InWwoMrN/Twenty"&gt;&lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/figma-icon.png" width="12" height="12" /&gt; Figma&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.twenty.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/github-cover-dark.png" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/github-cover-light.png" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/github-cover-light.png" alt="Cover" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;See: üöÄ &lt;a href="https://docs.twenty.com/developers/self-hosting/docker-compose"&gt;Self-hosting&lt;/a&gt; üñ•Ô∏è &lt;a href="https://docs.twenty.com/developers/local-setup"&gt;Local Setup&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Does the world need another CRM?&lt;/h1&gt; 
&lt;p&gt;We built Twenty for three reasons:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CRMs are too expensive, and users are trapped.&lt;/strong&gt; Companies use locked-in customer data to hike prices. It shouldn't be that way.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A fresh start is required to build a better experience.&lt;/strong&gt; We can learn from past mistakes and craft a cohesive experience inspired by new UX patterns from tools like Notion, Airtable or Linear.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We believe in Open-source and community.&lt;/strong&gt; Hundreds of developers are already building Twenty together. Once we have plugin capabilities, a whole ecosystem will grow around it.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h1&gt;What You Can Do With Twenty&lt;/h1&gt; 
&lt;p&gt;Please feel free to flag any specific needs you have by creating an issue.&lt;/p&gt; 
&lt;p&gt;Below are a few features we have implemented to date:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/twentyhq/twenty/main/#personalize-layouts-with-filters-sort-group-by-kanban-and-table-views"&gt;Personalize layouts with filters, sort, group by, kanban and table views&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/twentyhq/twenty/main/#customize-your-objects-and-fields"&gt;Customize your objects and fields&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/twentyhq/twenty/main/#create-and-manage-permissions-with-custom-roles"&gt;Create and manage permissions with custom roles&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/twentyhq/twenty/main/#automate-workflow-with-triggers-and-actions"&gt;Automate workflow with triggers and actions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/twentyhq/twenty/main/#emails-calendar-events-files-and-more"&gt;Emails, calendar events, files, and more&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Personalize layouts with filters, sort, group by, kanban and table views&lt;/h2&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/views-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/views-light.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/views-light.png" alt="Companies Kanban Views" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h2&gt;Customize your objects and fields&lt;/h2&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/data-model-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/data-model-light.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/data-model-light.png" alt="Setting Custom Objects" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h2&gt;Create and manage permissions with custom roles&lt;/h2&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/permissions-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/permissions-light.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/permissions-light.png" alt="Permissions" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h2&gt;Automate workflow with triggers and actions&lt;/h2&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/workflows-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/workflows-light.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/workflows-light.png" alt="Workflows" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h2&gt;Emails, calendar events, files, and more&lt;/h2&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/plus-other-features-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/plus-other-features-light.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/plus-other-features-light.png" alt="Other Features" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;h1&gt;Stack&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.typescriptlang.org/"&gt;TypeScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nx.dev/"&gt;Nx&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nestjs.com/"&gt;NestJS&lt;/a&gt;, with &lt;a href="https://bullmq.io/"&gt;BullMQ&lt;/a&gt;, &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt;, &lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://reactjs.org/"&gt;React&lt;/a&gt;, with &lt;a href="https://recoiljs.org/"&gt;Recoil&lt;/a&gt;, &lt;a href="https://emotion.sh/"&gt;Emotion&lt;/a&gt; and &lt;a href="https://lingui.dev/"&gt;Lingui&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Thanks&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.chromatic.com/"&gt;&lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/chromatic.png" height="30" alt="Chromatic" /&gt;&lt;/a&gt; &lt;a href="https://greptile.com"&gt;&lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/greptile.png" height="30" alt="Greptile" /&gt;&lt;/a&gt; &lt;a href="https://sentry.io/"&gt;&lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/sentry.png" height="30" alt="Sentry" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/"&gt;&lt;img src="https://raw.githubusercontent.com/twentyhq/twenty/main/packages/twenty-website/public/images/readme/crowdin.png" height="30" alt="Crowdin" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Thanks to these amazing services that we use and recommend for UI testing (Chromatic), code review (Greptile), catching bugs (Sentry) and translating (Crowdin).&lt;/p&gt; 
&lt;h1&gt;Join the Community&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Star the repo&lt;/li&gt; 
 &lt;li&gt;Subscribe to releases (watch -&amp;gt; custom -&amp;gt; releases)&lt;/li&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://twitter.com/twentycrm"&gt;Twitter&lt;/a&gt; or &lt;a href="https://www.linkedin.com/company/twenty/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://discord.gg/cx5n4Jzs57"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Improve translations on &lt;a href="https://twenty.crowdin.com/twenty"&gt;Crowdin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/twentyhq/twenty/contribute"&gt;Contributions&lt;/a&gt; are, of course, most welcome!&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>C4illin/ConvertX</title>
      <link>https://github.com/C4illin/ConvertX</link>
      <description>&lt;p&gt;üíæ Self-hosted online file converter. Supports 1000+ formats ‚öôÔ∏è&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/C4illin/ConvertX/main/images/logo.png" alt="ConvertX" /&gt;&lt;/p&gt; 
&lt;h1&gt;ConvertX&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/C4illin/ConvertX/actions/workflows/docker-publish.yml"&gt;&lt;img src="https://github.com/C4illin/ConvertX/actions/workflows/docker-publish.yml/badge.svg?branch=main" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://github.com/C4illin/ConvertX/pkgs/container/ConvertX"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?logo=github&amp;amp;url=https%3A%2F%2Fipitio.github.io%2Fbackage%2FC4illin%2FConvertX%2Fconvertx.json&amp;amp;query=%24.downloads&amp;amp;label=ghcr.io%20pulls&amp;amp;cacheSeconds=14400" alt="ghcr.io Pulls" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/c4illin/convertx"&gt;&lt;img src="https://img.shields.io/docker/pulls/c4illin/convertx?style=flat&amp;amp;logo=docker&amp;amp;label=dockerhub%20pulls&amp;amp;link=https%3A%2F%2Fhub.docker.com%2Frepository%2Fdocker%2Fc4illin%2Fconvertx%2Fgeneral" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/C4illin/ConvertX/pkgs/container/convertx"&gt;&lt;img src="https://img.shields.io/github/v/release/C4illin/ConvertX" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/commits-since/C4illin/ConvertX/latest" alt="GitHub commits since latest release" /&gt; &lt;img src="https://img.shields.io/github/repo-size/C4illin/ConvertX" alt="GitHub repo size" /&gt; &lt;img src="https://ghcr-badge.egpl.dev/c4illin/convertx/size?color=%230375b6&amp;amp;tag=latest&amp;amp;label=image+size&amp;amp;trim=" alt="Docker container size" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/13818" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13818" alt="C4illin%2FConvertX | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- ![Dev image size](https://ghcr-badge.egpl.dev/c4illin/convertx/size?color=%230375b6&amp;tag=main&amp;label=dev+image&amp;trim=) --&gt; 
&lt;p&gt;A self-hosted online file converter. Supports over a thousand different formats. Written with TypeScript, Bun and Elysia.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert files to different formats&lt;/li&gt; 
 &lt;li&gt;Process multiple files at once&lt;/li&gt; 
 &lt;li&gt;Password protection&lt;/li&gt; 
 &lt;li&gt;Multiple accounts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Converters supported&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Converter&lt;/th&gt; 
   &lt;th&gt;Use case&lt;/th&gt; 
   &lt;th&gt;Converts from&lt;/th&gt; 
   &lt;th&gt;Converts to&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://inkscape.org/"&gt;Inkscape&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Vector images&lt;/td&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/libjxl/libjxl"&gt;libjxl&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;JPEG XL&lt;/td&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;11&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/RazrFalcon/resvg"&gt;resvg&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;SVG&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/libvips/libvips"&gt;Vips&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Images&lt;/td&gt; 
   &lt;td&gt;45&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/strukturag/libheif"&gt;libheif&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;HEIF&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://tug.org/xetex/"&gt;XeLaTeX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LaTeX&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://calibre-ebook.com/"&gt;Calibre&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;E-books&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;19&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.libreoffice.org/"&gt;LibreOffice&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Documents&lt;/td&gt; 
   &lt;td&gt;41&lt;/td&gt; 
   &lt;td&gt;22&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TomWright/dasel"&gt;Dasel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Data Files&lt;/td&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://pandoc.org/"&gt;Pandoc&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Documents&lt;/td&gt; 
   &lt;td&gt;43&lt;/td&gt; 
   &lt;td&gt;65&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mvz/email-outlook-message-perl"&gt;msgconvert&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Outlook&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://dvisvgm.de/"&gt;dvisvgm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Vector images&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://imagemagick.org/"&gt;ImageMagick&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Images&lt;/td&gt; 
   &lt;td&gt;245&lt;/td&gt; 
   &lt;td&gt;183&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="http://www.graphicsmagick.org/"&gt;GraphicsMagick&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Images&lt;/td&gt; 
   &lt;td&gt;167&lt;/td&gt; 
   &lt;td&gt;130&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/assimp/assimp"&gt;Assimp&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3D Assets&lt;/td&gt; 
   &lt;td&gt;77&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://ffmpeg.org/"&gt;FFmpeg&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Video&lt;/td&gt; 
   &lt;td&gt;~472&lt;/td&gt; 
   &lt;td&gt;~199&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://potrace.sourceforge.net/"&gt;Potrace&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Raster to vector&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;11&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/visioncortex/vtracer"&gt;VTracer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Raster to vector&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown"&gt;Markitdown&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Documents&lt;/td&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!-- many ffmpeg fileformats are duplicates --&gt; 
&lt;p&gt;Any missing converter? Open an issue or pull request!&lt;/p&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] If you can't login, make sure you are accessing the service over localhost or https otherwise set HTTP_ALLOWED=true&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;# docker-compose.yml
services:
  convertx:
    image: ghcr.io/c4illin/convertx
    container_name: convertx
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - JWT_SECRET=aLongAndSecretStringUsedToSignTheJSONWebToken1234 # will use randomUUID() if unset
      # - HTTP_ALLOWED=true # uncomment this if accessing it over a non-https connection
    volumes:
      - ./data:/app/data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 3000:3000 -v ./data:/app/data ghcr.io/c4illin/convertx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://localhost:3000&lt;/code&gt; in your browser and create your account. Don't leave it unconfigured and open, as anyone can register the first account.&lt;/p&gt; 
&lt;p&gt;If you get unable to open database file run &lt;code&gt;chown -R $USER:$USER path&lt;/code&gt; on the path you choose.&lt;/p&gt; 
&lt;h3&gt;Environment variables&lt;/h3&gt; 
&lt;p&gt;All are optional, JWT_SECRET is recommended to be set.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JWT_SECRET&lt;/td&gt; 
   &lt;td&gt;when unset it will use the value from randomUUID()&lt;/td&gt; 
   &lt;td&gt;A long and secret string used to sign the JSON Web Token&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ACCOUNT_REGISTRATION&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Allow users to register accounts&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HTTP_ALLOWED&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Allow HTTP connections, only set this to true locally&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ALLOW_UNAUTHENTICATED&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Allow unauthenticated users to use the service, only set this to true locally&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AUTO_DELETE_EVERY_N_HOURS&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;Checks every n hours for files older then n hours and deletes them, set to 0 to disable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WEBROOT&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;The address to the root path setting this to "/convert" will serve the website on "example.com/convert/"&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FFMPEG_ARGS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Arguments to pass to the input file of ffmpeg, e.g. &lt;code&gt;-hwaccel vaapi&lt;/code&gt;. See &lt;a href="https://github.com/C4illin/ConvertX/issues/190"&gt;https://github.com/C4illin/ConvertX/issues/190&lt;/a&gt; for more info about hw-acceleration.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FFMPEG_OUTPUT_ARGS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Arguments to pass to the output of ffmpeg, e.g. &lt;code&gt;-preset veryfast&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HIDE_HISTORY&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Hide the history page&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LANGUAGE&lt;/td&gt; 
   &lt;td&gt;en&lt;/td&gt; 
   &lt;td&gt;Language to format date strings in, specified as a &lt;a href="https://en.wikipedia.org/wiki/IETF_language_tag"&gt;BCP 47 language tag&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;UNAUTHENTICATED_USER_SHARING&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Shares conversion history between all unauthenticated users&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MAX_CONVERT_PROCESS&lt;/td&gt; 
   &lt;td&gt;0&lt;/td&gt; 
   &lt;td&gt;Maximum number of concurrent conversion processes allowed. Set to 0 for unlimited.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Docker images&lt;/h3&gt; 
&lt;p&gt;There is a &lt;code&gt;:latest&lt;/code&gt; tag that is updated with every release and a &lt;code&gt;:main&lt;/code&gt; tag that is updated with every push to the main branch. &lt;code&gt;:latest&lt;/code&gt; is recommended for normal use.&lt;/p&gt; 
&lt;p&gt;The image is available on &lt;a href="https://github.com/C4illin/ConvertX/pkgs/container/ConvertX"&gt;GitHub Container Registry&lt;/a&gt; and &lt;a href="https://hub.docker.com/r/c4illin/convertx"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Image&lt;/th&gt; 
   &lt;th&gt;What it is&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;image: ghcr.io/c4illin/convertx&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The latest release on ghcr&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;image: ghcr.io/c4illin/convertx:main&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The latest commit on ghcr&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;image: c4illin/convertx&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The latest release on docker hub&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;image: c4illin/convertx:main&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The latest commit on docker hub&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;img src="https://ghcr-badge.egpl.dev/c4illin/convertx/size?color=%230375b6&amp;amp;tag=latest&amp;amp;label=release+image&amp;amp;trim=" alt="Release image size" /&gt; &lt;img src="https://ghcr-badge.egpl.dev/c4illin/convertx/size?color=%230375b6&amp;amp;tag=main&amp;amp;label=dev+image&amp;amp;trim=" alt="Dev image size" /&gt;&lt;/p&gt; 
&lt;!-- Dockerhub was introduced in 0.9.0 and older releases --&gt; 
&lt;h3&gt;Tutorial&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] These are written by other people, and may be outdated, incorrect or wrong.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Tutorial in french: &lt;a href="https://belginux.com/installer-convertx-avec-docker/"&gt;https://belginux.com/installer-convertx-avec-docker/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Tutorial in chinese: &lt;a href="https://xzllll.com/24092901/"&gt;https://xzllll.com/24092901/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Tutorial in polish: &lt;a href="https://www.kreatywnyprogramista.pl/convertx-lokalny-konwerter-plikow"&gt;https://www.kreatywnyprogramista.pl/convertx-lokalny-konwerter-plikow&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/C4illin/ConvertX/main/images/preview.png" alt="ConvertX Preview" /&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt;Install &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt; and Git&lt;/li&gt; 
 &lt;li&gt;Clone the repository&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bun install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bun run dev&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Pull requests are welcome! See open issues for the list of todos. The ones tagged with "converter request" are quite easy. Help with docs and cleaning up in issues are also very welcome!&lt;/p&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/en/v1.0.0/#summary"&gt;conventional commits&lt;/a&gt; for commit messages.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/C4illin/ConvertX/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=C4illin/ConvertX" alt="Image with all contributors" /&gt; &lt;/a&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/dcdabd0564fcdcccbf5680c1bdc2efad54a3d4d9.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://github.com/C4illin/ConvertX/stargazers"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=C4illin/ConvertX&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=C4illin/ConvertX&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=C4illin/ConvertX&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>bytedance/UI-TARS-desktop</title>
      <link>https://github.com/bytedance/UI-TARS-desktop</link>
      <description>&lt;p&gt;The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;img alt="Agent TARS Banner" src="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/images/tars.png" /&gt; 
&lt;/picture&gt; 
&lt;br /&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/README.zh-CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/13584"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13584" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;b&gt;TARS&lt;sup&gt;*&lt;/sup&gt;&lt;/b&gt; is a Multimodal AI Agent stack, currently shipping two projects: &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS-desktop&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="50%" align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt;&lt;/th&gt; 
   &lt;th width="50%" align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS-desktop&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br /&gt; &lt;br /&gt; It primarily ships with a &lt;a href="https://agent-tars.com/guide/basic/cli.html" target="_blank"&gt;CLI&lt;/a&gt; and &lt;a href="https://agent-tars.com/guide/basic/web-ui.html" target="_blank"&gt;Web UI&lt;/a&gt; for usage. It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href="https://agent-tars.com/guide/basic/mcp.html" target="_blank"&gt;MCP&lt;/a&gt; tools. &lt;/td&gt; 
   &lt;td align="left"&gt; &lt;b&gt;UI-TARS Desktop&lt;/b&gt; is a desktop application that provides a native GUI Agent based on the &lt;a href="https://github.com/bytedance/UI-TARS" target="_blank"&gt;UI-TARS&lt;/a&gt; model. &lt;br /&gt; &lt;br /&gt; It primarily ships a &lt;a href="https://github.com/bytedance/UI-TARS-desktop/raw/main/docs/quick-start.md#get-model-and-run-local-operator" target="_blank"&gt;local&lt;/a&gt; and &lt;a href="https://github.com/bytedance/UI-TARS-desktop/raw/main/docs/quick-start.md#run-remote-operator" target="_blank"&gt;remote&lt;/a&gt; computer as well as browser operators. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt; 
&lt;!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#news"&gt;News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#showcase"&gt;Showcase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#core-features"&gt;Core Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS Desktop&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#showcase-1"&gt;Showcase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#quick-start-1"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-11-05]&lt;/strong&gt; üéâ We're excited to announce the release of &lt;a href="https://github.com/bytedance/UI-TARS-desktop/releases/tag/v0.3.0"&gt;Agent TARS CLI v0.3.0&lt;/a&gt;! This version brings streaming support for multiple tools (shell commands, multi-file structured display), runtime settings with timing statistics for tool calls and deep thinking, Event Stream Viewer for data flow tracking and debugging. Additionally, it features exclusive support for &lt;a href="https://github.com/agent-infra/sandbox"&gt;AIO agent Sandbox&lt;/a&gt; as isolated all-in-one tools execution environment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-06-25]&lt;/strong&gt; We released a Agent TARS Beta and Agent TARS CLI - &lt;a href="https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html"&gt;Introducing Agent TARS Beta&lt;/a&gt;, a multimodal AI agent that aims to explore a work form that is closer to human-like task completion through rich multimodal capabilities (such as GUI Agent, Vision) and seamless integration with various real-world tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-06-12]&lt;/strong&gt; - üéÅ We are thrilled to announce the release of UI-TARS Desktop v0.2.0! This update introduces two powerful new features: &lt;strong&gt;Remote Computer Operator&lt;/strong&gt; and &lt;strong&gt;Remote Browser Operator&lt;/strong&gt;‚Äîboth completely free. No configuration required: simply click to remotely control any computer or browser, and experience a new level of convenience and intelligence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-04-17]&lt;/strong&gt; - üéâ We're thrilled to announce the release of new UI-TARS Desktop application v0.1.0, featuring a redesigned Agent UI. The application enhances the computer using experience, introduces new browser operation features, and supports &lt;a href="https://seed-tars.com/1.5"&gt;the advanced UI-TARS-1.5 model&lt;/a&gt; for improved performance and precise control.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-02-20]&lt;/strong&gt; - üì¶ Introduced &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/sdk.md"&gt;UI TARS SDK&lt;/a&gt;, is a powerful cross-platform toolkit for building GUI automation agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-01-23]&lt;/strong&gt; - üöÄ We updated the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/deployment.md#cloud-deployment"&gt;Cloud Deployment&lt;/a&gt;&lt;/strong&gt; section in the ‰∏≠ÊñáÁâà: &lt;a href="https://bytedance.sg.larkoffice.com/docx/TCcudYwyIox5vyxiSDLlgIsTgWf#U94rdCxzBoJMLex38NPlHL21gNb"&gt;GUIÊ®°ÂûãÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/a&gt; with new information related to the ModelScope platform. You can now use the ModelScope platform for deployment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Agent TARS&lt;/h2&gt; 
&lt;p&gt; &lt;a href="https://npmjs.com/package/@agent-tars/cli?activeTab=readme"&gt;&lt;img src="https://img.shields.io/npm/v/@agent-tars/cli?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=3B82F6&amp;amp;logo=npm&amp;amp;logoColor=white" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://npmcharts.com/compare/@agent-tars/cli?minimal=true"&gt;&lt;img src="https://img.shields.io/npm/dm/@agent-tars/cli.svg?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=0EA5E9&amp;amp;logo=npm&amp;amp;logoColor=white" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://nodejs.org/en/about/previous-releases"&gt;&lt;img src="https://img.shields.io/node/v/@agent-tars/cli.svg?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=06B6D4&amp;amp;logo=node.js&amp;amp;logoColor=white" alt="node version" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/HnKcSBgTVx"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord Community" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/agent_tars"&gt;&lt;img src="https://img.shields.io/badge/Twitter-Follow%20%40agent__tars-1DA1F2?style=for-the-badge&amp;amp;logo=twitter&amp;amp;logoColor=white" alt="Official Twitter" /&gt;&lt;/a&gt; &lt;a href="https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=deen76f4-ea3c-4964-93a3-78f126f39651"&gt;&lt;img src="https://img.shields.io/badge/È£û‰π¶Áæ§-Âä†ÂÖ•‰∫§ÊµÅÁæ§-00D4AA?style=for-the-badge&amp;amp;logo=lark&amp;amp;logoColor=white" alt="È£û‰π¶‰∫§ÊµÅÁæ§" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/bytedance/UI-TARS-desktop"&gt;&lt;img src="https://img.shields.io/badge/DeepWiki-Ask%20AI-8B5CF6?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br /&gt; &lt;br /&gt; It primarily ships with a &lt;a href="https://agent-tars.com/guide/basic/cli.html" target="_blank"&gt;CLI&lt;/a&gt; and &lt;a href="https://agent-tars.com/guide/basic/web-ui.html" target="_blank"&gt;Web UI&lt;/a&gt; for usage. It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href="https://agent-tars.com/guide/basic/mcp.html" target="_blank"&gt;MCP&lt;/a&gt; tools.&lt;/p&gt; 
&lt;h3&gt;Showcase&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Please help me book the earliest flight from San Jose to New York on September 1st and the last return flight on September 6th on Priceline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8"&gt;https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="50%" align="center"&gt;Booking Hotel&lt;/th&gt; 
   &lt;th width="50%" align="center"&gt;Generate Chart with extra MCP Servers&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/a9fd72d0-01bb-4233-aa27-ca95194bbce9" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;I am in Los Angeles from September 1st to September 6th, with a budget of $5,000. Please help me book a Ritz-Carlton hotel closest to the airport on booking.com and compile a transportation guide for me&lt;/i&gt; &lt;/td&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;Draw me a chart of Hangzhou's weather for one month&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For more use cases, please check out &lt;a href="https://github.com/bytedance/UI-TARS-desktop/issues/842"&gt;#842&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Core Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üñ±Ô∏è &lt;strong&gt;One-Click Out-of-the-box CLI&lt;/strong&gt; - Supports both &lt;strong&gt;headful&lt;/strong&gt; &lt;a href="https://agent-tars.com/guide/basic/web-ui.html"&gt;Web UI&lt;/a&gt; and &lt;strong&gt;headless&lt;/strong&gt; &lt;a href="https://agent-tars.com/guide/advanced/server.html"&gt;server&lt;/a&gt;) &lt;a href="https://agent-tars.com/guide/basic/cli.html"&gt;execution&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Hybrid Browser Agent&lt;/strong&gt; - Control browsers using &lt;a href="https://agent-tars.com/guide/basic/browser.html#visual-grounding"&gt;GUI Agent&lt;/a&gt;, &lt;a href="https://agent-tars.com/guide/basic/browser.html#dom"&gt;DOM&lt;/a&gt;, or a hybrid strategy.&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Event Stream&lt;/strong&gt; - Protocol-driven Event Stream drives &lt;a href="https://agent-tars.com/beta#context-engineering"&gt;Context Engineering&lt;/a&gt; and &lt;a href="https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html#easy-to-build-applications"&gt;Agent UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üß∞ &lt;strong&gt;MCP Integration&lt;/strong&gt; - The kernel is built on MCP and also supports mounting &lt;a href="https://agent-tars.com/guide/basic/mcp.html"&gt;MCP Servers&lt;/a&gt; to connect to real-world tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;img alt="Agent TARS CLI" src="https://agent-tars.com/agent-tars-cli.png" /&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch with `npx`.
npx @agent-tars/cli@latest

# Install globally, required Node.js &amp;gt;= 22
npm install @agent-tars/cli@latest -g

# Run with your preferred model provider
agent-tars --provider volcengine --model doubao-1-5-thinking-vision-pro-250428 --apiKey your-api-key
agent-tars --provider anthropic --model claude-3-7-sonnet-latest --apiKey your-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit the comprehensive &lt;a href="https://agent-tars.com/guide/get-started/quick-start.html"&gt;Quick Start&lt;/a&gt; guide for detailed setup instructions.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üåü &lt;strong&gt;Explore Agent TARS Universe&lt;/strong&gt; üåü&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="20%" align="center"&gt;Category&lt;/th&gt; 
   &lt;th width="30%" align="center"&gt;Resource Link&lt;/th&gt; 
   &lt;th width="50%" align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üè† &lt;strong&gt;Central Hub&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com"&gt; &lt;img src="https://img.shields.io/badge/Visit-Website-4F46E5?style=for-the-badge&amp;amp;logo=globe&amp;amp;logoColor=white" alt="Website" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Your gateway to Agent TARS ecosystem&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üìö &lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/guide/get-started/quick-start.html"&gt; &lt;img src="https://img.shields.io/badge/Get-Started-06B6D4?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Quick Start" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Zero to hero in 5 minutes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üöÄ &lt;strong&gt;What's New&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/beta"&gt; &lt;img src="https://img.shields.io/badge/Read-Blog-F59E0B?style=for-the-badge&amp;amp;logo=rss&amp;amp;logoColor=white" alt="Blog" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Discover cutting-edge features &amp;amp; vision&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üõ†Ô∏è &lt;strong&gt;Developer Zone&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/guide/get-started/introduction.html"&gt; &lt;img src="https://img.shields.io/badge/View-Docs-10B981?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Docs" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Master every command &amp;amp; features&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üéØ &lt;strong&gt;Showcase&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/bytedance/UI-TARS-desktop/issues/842"&gt; &lt;img src="https://img.shields.io/badge/View-Examples-8B5CF6?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="Examples" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;View use cases built by the official and community&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üîß &lt;strong&gt;Reference&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/api/"&gt; &lt;img src="https://img.shields.io/badge/API-Reference-EF4444?style=for-the-badge&amp;amp;logo=book&amp;amp;logoColor=white" alt="API" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Complete technical reference&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;h2&gt;UI-TARS Desktop&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img alt="UI-TARS" width="260" src="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/apps/ui-tars/resources/icon.png" /&gt; &lt;/p&gt; 
&lt;p&gt;UI-TARS Desktop is a native GUI agent for your local computer, driven by &lt;a href="https://github.com/bytedance/UI-TARS"&gt;UI-TARS&lt;/a&gt; and Seed-1.5-VL/1.6 series models.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &amp;nbsp;&amp;nbsp; üìë &lt;a href="https://arxiv.org/abs/2501.12326"&gt;Paper&lt;/a&gt; &amp;nbsp;&amp;nbsp; | ü§ó &lt;a href="https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B"&gt;Hugging Face Models&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü´® &lt;a href="https://discord.gg/pTXwYVjfcs"&gt;Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü§ñ &lt;a href="https://www.modelscope.cn/collections/UI-TARS-bccb56fa1ef640"&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;br /&gt; üñ•Ô∏è Desktop Application &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; üëì &lt;a href="https://github.com/web-infra-dev/midscene"&gt;Midscene (use in browser)&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;Showcase&lt;/h3&gt; 
&lt;!-- // FIXME: Choose only two demo, one local computer and one remote computer showcase. --&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Instruction&lt;/th&gt; 
   &lt;th align="center"&gt;Local Operator&lt;/th&gt; 
   &lt;th align="center"&gt;Remote Operator&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Please help me open the autosave feature of VS Code and delay AutoSave operations for 500 milliseconds in the VS Code setting.&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/01e49b69-7070-46c8-b3e3-2aaaaec71800" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Could you help me check the latest open issue of the UI-TARS-Desktop project on GitHub?&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/3d159f54-d24a-4268-96c0-e149607e9199" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/072fb72d-7394-4bfa-95f5-4736e29f7e58" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ Natural language control powered by Vision-Language Model&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Screenshot and visual recognition support&lt;/li&gt; 
 &lt;li&gt;üéØ Precise mouse and keyboard control&lt;/li&gt; 
 &lt;li&gt;üíª Cross-platform support (Windows/MacOS/Browser)&lt;/li&gt; 
 &lt;li&gt;üîÑ Real-time feedback and status display&lt;/li&gt; 
 &lt;li&gt;üîê Private and secure - fully local processing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/quick-start.md"&gt;Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our paper and code useful in your research, please consider giving a star &lt;span&gt;‚≠ê&lt;/span&gt; and citation &lt;span&gt;üìù&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@article{qin2025ui,
  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},
  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},
  journal={arXiv preprint arXiv:2501.12326},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>hacksider/Deep-Live-Cam</title>
      <link>https://github.com/hacksider/Deep-Live-Cam</link>
      <description>&lt;p&gt;real time face swap and one-click video deepfake with only a single image&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Deep-Live-Cam 2.0.1c&lt;/h1&gt; 
&lt;p align="center"&gt; Real-time face swap and video deepfake with a single click and only a single image. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/11395" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11395" alt="hacksider%2FDeep-Live-Cam | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif" alt="Demo GIF" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.&lt;/p&gt; 
&lt;p&gt;We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ethical Use: Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.&lt;/p&gt; 
&lt;p&gt;Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.&lt;/p&gt; 
&lt;h2&gt;Exclusive v2.4 Quick Start - Pre-built (Windows/Mac Silicon)&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/Download.png" width="285" height="77" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;h5&gt;This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you'll receive special priority support.&lt;/h5&gt; &lt;h6&gt;These Pre-builts are perfect for non-technical users or those who don't have time to, or can't manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually.&lt;/h6&gt; &lt;h2&gt;TLDR; Live Deepfake in just 3 Clicks&lt;/h2&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6" alt="easysteps" /&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Select a face&lt;/li&gt; 
  &lt;li&gt;Select which camera to use&lt;/li&gt; 
  &lt;li&gt;Press live!&lt;/li&gt; 
 &lt;/ol&gt; &lt;h2&gt;Features &amp;amp; Uses - Everything is in real-time&lt;/h2&gt; &lt;h3&gt;Mouth Mask&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Retain your original mouth for accurate movement using Mouth Mask&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif" alt="resizable-gif" /&gt; &lt;/p&gt; &lt;h3&gt;Face Mapping&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Use different faces on multiple subjects simultaneously&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif" alt="face_mapping_source" /&gt; &lt;/p&gt; &lt;h3&gt;Your Movie, Your Face&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Watch movies with any face in real-time&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif" alt="movie" /&gt; &lt;/p&gt; &lt;h3&gt;Live Show&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Run Live shows and performances&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif" alt="show" /&gt; &lt;/p&gt; &lt;h3&gt;Memes&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Create Your Most Viral Meme Yet&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif" alt="show" width="450" /&gt; &lt;br /&gt; &lt;sub&gt;Created using Many Faces feature in Deep-Live-Cam&lt;/sub&gt; &lt;/p&gt; &lt;h3&gt;Omegle&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Surprise people on Omegle&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; 
  &lt;video src="https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0" width="450" controls&gt;&lt;/video&gt; &lt;/p&gt; &lt;h2&gt;Installation (Manual)&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;
&lt;details&gt;
 &lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;summary&gt;Click to see the process&lt;/summary&gt; &lt;h3&gt;Installation&lt;/h3&gt; &lt;p&gt;This is more likely to work on your computer but will be slower as it utilizes the CPU.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;1. Set up Your Platform&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python (3.11 recommended)&lt;/li&gt; 
   &lt;li&gt;pip&lt;/li&gt; 
   &lt;li&gt;git&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OlNWCpFdVMA"&gt;ffmpeg&lt;/a&gt; - &lt;code&gt;iex (irm ffmpeg.tc.ht)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Visual Studio 2022 Runtimes (Windows)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;strong&gt;2. Clone the Repository&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/hacksider/Deep-Live-Cam.git
cd Deep-Live-Cam
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Download the Models&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth"&gt;GFPGANv1.4&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx"&gt;inswapper_128_fp16.onnx&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Place these files in the "&lt;strong&gt;models&lt;/strong&gt;" folder.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4. Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We highly recommend using a &lt;code&gt;venv&lt;/code&gt; to avoid issues.&lt;/p&gt; 
 &lt;p&gt;For Windows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Ensure you use the installed Python 3.10
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) requires specific setup:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Python 3.11 (specific version is important)
brew install python@3.11

# Install tkinter package (required for the GUI)
brew install python-tk@3.10

# Create and activate virtual environment with Python 3.11
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;** In case something goes wrong and you need to reinstall the virtual environment **&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Deactivate the virtual environment
rm -rf venv

# Reinstall the virtual environment
python -m venv venv
source venv/bin/activate

# install the dependencies again
pip install -r requirements.txt

# gfpgan and basicsrs issue fix
pip install git+https://github.com/xinntao/BasicSR.git@master
pip uninstall gfpgan -y
pip install git+https://github.com/TencentARC/GFPGAN.git@master
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Run:&lt;/strong&gt; If you don't have a GPU, you can run Deep-Live-Cam using &lt;code&gt;python run.py&lt;/code&gt;. Note that initial execution will download models (~300MB).&lt;/p&gt; 
 &lt;h3&gt;GPU Acceleration&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;CUDA Execution Provider (Nvidia)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/cuda-12-8-0-download-archive"&gt;CUDA Toolkit 12.8.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/rdp/cudnn-archive"&gt;cuDNN v8.9.7 for CUDA 12.x&lt;/a&gt; (required for onnxruntime-gpu): 
   &lt;ul&gt; 
    &lt;li&gt;Download cuDNN v8.9.7 for CUDA 12.x&lt;/li&gt; 
    &lt;li&gt;Make sure the cuDNN bin directory is in your system PATH&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider cuda
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Silicon)&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) specific installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Make sure you've completed the macOS setup above using Python 3.10.&lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage (important: specify Python 3.10):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3.10 run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important Notes for macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;You &lt;strong&gt;must&lt;/strong&gt; use Python 3.10, not newer versions like 3.11 or 3.13&lt;/li&gt; 
  &lt;li&gt;Always run with &lt;code&gt;python3.10&lt;/code&gt; command not just &lt;code&gt;python&lt;/code&gt; if you have multiple Python versions installed&lt;/li&gt; 
  &lt;li&gt;If you get error about &lt;code&gt;_tkinter&lt;/code&gt; missing, reinstall the tkinter package: &lt;code&gt;brew reinstall python-tk@3.10&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;If you get model loading errors, check that your models are in the correct folder&lt;/li&gt; 
  &lt;li&gt;If you encounter conflicts with other Python versions, consider uninstalling them: &lt;pre&gt;&lt;code class="language-bash"&gt;# List all installed Python versions
brew list | grep python

# Uninstall conflicting versions if needed
brew uninstall --ignore-dependencies python@3.11 python@3.13

# Keep only Python 3.11
brew cleanup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Legacy)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;DirectML Execution Provider (Windows)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider directml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;OpenVINO‚Ñ¢ Execution Provider (Intel)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider openvino
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Image/Video Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Choose a source face image and a target image/video.&lt;/li&gt; 
 &lt;li&gt;Click "Start".&lt;/li&gt; 
 &lt;li&gt;The output will be saved in a directory named after the target video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Webcam Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Select a source face image.&lt;/li&gt; 
 &lt;li&gt;Click "Live".&lt;/li&gt; 
 &lt;li&gt;Wait for the preview to appear (10-30 seconds).&lt;/li&gt; 
 &lt;li&gt;Use a screen capture tool like OBS to stream.&lt;/li&gt; 
 &lt;li&gt;To change the face, select a new source image.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command Line Arguments (Unmaintained)&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --map-faces                                              map source target faces
  --mouth-mask                                             mask the mouth region
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program's version number and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.&lt;/p&gt; 
&lt;h2&gt;Press&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We are always open to criticism and are ready to improve, that's why we didn't cherry-pick anything.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/"&gt;&lt;em&gt;"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger"&lt;/em&gt;&lt;/a&gt; - Ars Technica&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/"&gt;&lt;em&gt;"Thanks Deep Live Cam, shapeshifters are among us now"&lt;/em&gt;&lt;/a&gt; - Dataconomy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story"&gt;&lt;em&gt;"This free AI tool lets you become anyone during video-calls"&lt;/em&gt;&lt;/a&gt; - NewsBytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying"&gt;&lt;em&gt;"OK, this viral AI live stream software is truly terrifying"&lt;/em&gt;&lt;/a&gt; - Creative Bloq&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/"&gt;&lt;em&gt;"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo"&lt;/em&gt;&lt;/a&gt; - PetaPixel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.techeblog.com/deep-live-cam-ai-transform-face/"&gt;&lt;em&gt;"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included"&lt;/em&gt;&lt;/a&gt; - TechEBlog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/"&gt;&lt;em&gt;"An AI tool that "makes you look like anyone" during a video call is going viral online"&lt;/em&gt;&lt;/a&gt; - Telegrafi&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts"&gt;&lt;em&gt;"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts"&lt;/em&gt;&lt;/a&gt; - Emerge&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/"&gt;&lt;em&gt;"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces"&lt;/em&gt;&lt;/a&gt; - Digital Music News&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/"&gt;&lt;em&gt;"This real-time webcam deepfake tool raises alarms about the future of identity theft"&lt;/em&gt;&lt;/a&gt; - DIYPhotography&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?time_continue=1074&amp;amp;v=py4Tc-Y8BcY"&gt;&lt;em&gt;"That's Crazy, Oh God. That's Fucking Freaky Dude... That's So Wild Dude"&lt;/em&gt;&lt;/a&gt; - SomeOrdinaryGamers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;amp;t=2686"&gt;&lt;em&gt;"Alright look look look, now look chat, we can do any face we want to look like chat"&lt;/em&gt;&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wnCghLjqv3s&amp;amp;t=551s"&gt;&lt;em&gt;"They do a pretty good job matching poses, expression and even the lighting"&lt;/em&gt;&lt;/a&gt; - TechLinked (LTT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html"&gt;&lt;em&gt;"Als Sean Connery an der Redaktionskonferenz teilnahm"&lt;/em&gt;&lt;/a&gt; - Golem.de (German)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/JbUPRmXRUtE?t=3964"&gt;&lt;em&gt;"What the F&lt;/em&gt;**! Why do I look like Vinny Jr? I look exactly like Vinny Jr!? No, this shit is crazy! Bro This is F*** Crazy! "*&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ffmpeg.org/"&gt;ffmpeg&lt;/a&gt;: for making video-related operations easy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/henryruhs"&gt;Henry&lt;/a&gt;: One of the major contributor in this repo&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepinsight"&gt;deepinsight&lt;/a&gt;: for their &lt;a href="https://github.com/deepinsight/insightface"&gt;insightface&lt;/a&gt; project which provided a well-made library and models. Please be reminded that the &lt;a href="https://github.com/deepinsight/insightface?tab=readme-ov-file#license"&gt;use of the model is for non-commercial research purposes only&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/havok2-htwo"&gt;havok2-htwo&lt;/a&gt;: for sharing the code for webcam&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GosuDRM"&gt;GosuDRM&lt;/a&gt;: for the open version of roop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pereiraroland26"&gt;pereiraroland26&lt;/a&gt;: Multiple faces support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vic4key"&gt;vic4key&lt;/a&gt;: For supporting/contributing to this project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kier007"&gt;kier007&lt;/a&gt;: for improving the user experience&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qitianai"&gt;qitianai&lt;/a&gt;: for multi-lingual support&lt;/li&gt; 
 &lt;li&gt;and &lt;a href="https://github.com/hacksider/Deep-Live-Cam/graphs/contributors"&gt;all developers&lt;/a&gt; behind libraries used in this project.&lt;/li&gt; 
 &lt;li&gt;Footnote: Please be informed that the base author of the code is &lt;a href="https://github.com/s0md3v/roop"&gt;s0md3v&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All the wonderful users who helped make this project go viral by starring the repo ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/hacksider/Deep-Live-Cam/stargazers"&gt;&lt;img src="https://reporoster.com/stars/hacksider/Deep-Live-Cam" alt="Stargazers" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Stars to the Moon üöÄ&lt;/h2&gt; 
&lt;a href="https://star-history.com/#hacksider/deep-live-cam&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
  </channel>
</rss>