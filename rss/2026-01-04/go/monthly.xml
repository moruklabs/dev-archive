<rss version="2.0">
  <channel>
    <title>GitHub Go Monthly Trending</title>
    <description>Monthly Trending of Go in GitHub</description>
    <pubDate>Sat, 03 Jan 2026 01:53:30 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>golang/go</title>
      <link>https://github.com/golang/go</link>
      <description>&lt;p&gt;The Go programming language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Go Programming Language&lt;/h1&gt; 
&lt;p&gt;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://golang.org/doc/gopher/fiveyears.jpg" alt="Gopher image" /&gt; &lt;em&gt;Gopher image by &lt;a href="https://reneefrench.blogspot.com/"&gt;Renee French&lt;/a&gt;, licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;Creative Commons 4.0 Attribution license&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Our canonical Git repository is located at &lt;a href="https://go.googlesource.com/go"&gt;https://go.googlesource.com/go&lt;/a&gt;. There is a mirror of the repository at &lt;a href="https://github.com/golang/go"&gt;https://github.com/golang/go&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unless otherwise noted, the Go source files are distributed under the BSD-style license found in the LICENSE file.&lt;/p&gt; 
&lt;h3&gt;Download and Install&lt;/h3&gt; 
&lt;h4&gt;Binary Distributions&lt;/h4&gt; 
&lt;p&gt;Official binary distributions are available at &lt;a href="https://go.dev/dl/"&gt;https://go.dev/dl/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After downloading a binary release, visit &lt;a href="https://go.dev/doc/install"&gt;https://go.dev/doc/install&lt;/a&gt; for installation instructions.&lt;/p&gt; 
&lt;h4&gt;Install From Source&lt;/h4&gt; 
&lt;p&gt;If a binary distribution is not available for your combination of operating system and architecture, visit &lt;a href="https://go.dev/doc/install/source"&gt;https://go.dev/doc/install/source&lt;/a&gt; for source installation instructions.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Go is the work of thousands of contributors. We appreciate your help!&lt;/p&gt; 
&lt;p&gt;To contribute, please read the contribution guidelines at &lt;a href="https://go.dev/doc/contribute"&gt;https://go.dev/doc/contribute&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Note that the Go project uses the issue tracker for bug reports and proposals only. See &lt;a href="https://go.dev/wiki/Questions"&gt;https://go.dev/wiki/Questions&lt;/a&gt; for a list of places to ask questions about the Go language.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fatedier/frp</title>
      <link>https://github.com/fatedier/frp</link>
      <description>&lt;p&gt;A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;frp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://circleci.com/gh/fatedier/frp"&gt;&lt;img src="https://circleci.com/gh/fatedier/frp.svg?style=shield" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fatedier/frp/releases"&gt;&lt;img src="https://img.shields.io/github/tag/fatedier/frp.svg?label=release" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/fatedier/frp"&gt;&lt;img src="https://goreportcard.com/badge/github.com/fatedier/frp" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://somsubhra.github.io/github-release-stats/?username=fatedier&amp;amp;repository=frp"&gt;&lt;img src="https://img.shields.io/github/downloads/fatedier/frp/total.svg?logo=github" alt="GitHub Releases Stats" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/README.md"&gt;README&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/README_zh.md"&gt;中文文档&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;frp is an open source project with its ongoing development made possible entirely by the support of our awesome sponsors. If you'd like to join them, please consider &lt;a href="https://github.com/sponsors/fatedier"&gt;sponsoring frp's development&lt;/a&gt;.&lt;/p&gt; 
&lt;h3 align="center"&gt;Gold Sponsors&lt;/h3&gt; 
&lt;!--gold sponsors start--&gt; 
&lt;p align="center"&gt; &lt;a href="https://jb.gg/frp" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_jetbrains.jpg" /&gt; &lt;br /&gt; &lt;b&gt;The complete IDE crafted for professional Go developers&lt;/b&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/beclab/Olares" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_olares.jpeg" /&gt; &lt;br /&gt; &lt;b&gt;The sovereign cloud that puts you in control&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;An open source, self-hosted alternative to public clouds, built for data ownership and privacy&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;Recall.ai - API for meeting recordings&lt;/h2&gt; 
 &lt;p&gt;If you're looking for a meeting recording API, consider checking out &lt;a href="https://www.recall.ai/?utm_source=github&amp;amp;utm_medium=sponsorship&amp;amp;utm_campaign=fatedier-frp"&gt;Recall.ai&lt;/a&gt;,&lt;/p&gt; 
 &lt;p&gt;an API that records Zoom, Google Meet, Microsoft Teams, in-person meetings, and more.&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://requestly.com/?utm_source=github&amp;amp;utm_medium=partnered&amp;amp;utm_campaign=frp" target="_blank"&gt; &lt;img width="480px" src="https://github.com/user-attachments/assets/24670320-997d-4d62-9bca-955c59fe883d" /&gt; &lt;br /&gt; &lt;b&gt;Requestly - Free &amp;amp; Open-Source alternative to Postman&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;All-in-one platform to Test, Mock and Intercept APIs.&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://go.warp.dev/frp" target="_blank"&gt; &lt;img width="360px" src="https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-01.png" /&gt; &lt;br /&gt; &lt;b&gt;Warp, built for collaborating with AI Agents&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;Available for macOS, Linux and Windows&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;!--gold sponsors end--&gt; 
&lt;h2&gt;What is frp?&lt;/h2&gt; 
&lt;p&gt;frp is a fast reverse proxy that allows you to expose a local server located behind a NAT or firewall to the Internet. It currently supports &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;, as well as &lt;strong&gt;HTTP&lt;/strong&gt; and &lt;strong&gt;HTTPS&lt;/strong&gt; protocols, enabling requests to be forwarded to internal services via domain name.&lt;/p&gt; 
&lt;p&gt;frp also offers a P2P connect mode.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- vim-markdown-toc GFM --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#development-status"&gt;Development Status&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#about-v2"&gt;About V2&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage"&gt;Example Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#access-your-computer-in-a-lan-network-via-ssh"&gt;Access your computer in a LAN network via SSH&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#multiple-ssh-services-sharing-the-same-port"&gt;Multiple SSH services sharing the same port&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#accessing-internal-web-services-with-custom-domains-in-lan"&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#forward-dns-query-requests"&gt;Forward DNS query requests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#forward-unix-domain-socket"&gt;Forward Unix Domain Socket&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#expose-a-simple-http-file-server"&gt;Expose a simple HTTP file server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#enable-https-for-a-local-https-service"&gt;Enable HTTPS for a local HTTP(S) service&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#expose-your-service-privately"&gt;Expose your service privately&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#p2p-mode"&gt;P2P Mode&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#configuration-files"&gt;Configuration Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#using-environment-variables"&gt;Using Environment Variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#split-configures-into-different-files"&gt;Split Configures Into Different Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#server-dashboard"&gt;Server Dashboard&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#client-admin-ui"&gt;Client Admin UI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#monitor"&gt;Monitor&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#prometheus"&gt;Prometheus&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#authenticating-the-client"&gt;Authenticating the Client&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#token-authentication"&gt;Token Authentication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#oidc-authentication"&gt;OIDC Authentication&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#encryption-and-compression"&gt;Encryption and Compression&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tls"&gt;TLS&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#hot-reloading-frpc-configuration"&gt;Hot-Reloading frpc configuration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#get-proxy-status-from-client"&gt;Get proxy status from client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#only-allowing-certain-ports-on-the-server"&gt;Only allowing certain ports on the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#port-reuse"&gt;Port Reuse&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#bandwidth-limit"&gt;Bandwidth Limit&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#for-each-proxy"&gt;For Each Proxy&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-stream-multiplexing"&gt;TCP Stream Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#support-kcp-protocol"&gt;Support KCP Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#support-quic-protocol"&gt;Support QUIC Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#connection-pooling"&gt;Connection Pooling&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#load-balancing"&gt;Load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#service-health-check"&gt;Service Health Check&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#rewriting-the-http-host-header"&gt;Rewriting the HTTP Host Header&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#setting-other-http-headers"&gt;Setting other HTTP Headers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#get-real-ip"&gt;Get Real IP&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#http-x-forwarded-for"&gt;HTTP X-Forwarded-For&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#proxy-protocol"&gt;Proxy Protocol&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#require-http-basic-auth-password-for-web-services"&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#custom-subdomain-names"&gt;Custom Subdomain Names&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#url-routing"&gt;URL Routing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-port-multiplexing"&gt;TCP Port Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#connecting-to-frps-via-proxy"&gt;Connecting to frps via PROXY&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#port-range-mapping"&gt;Port range mapping&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#client-plugins"&gt;Client Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#server-manage-plugins"&gt;Server Manage Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#ssh-tunnel-gateway"&gt;SSH Tunnel Gateway&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#virtual-network-virtualnet"&gt;Virtual Network (VirtualNet)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#feature-gates"&gt;Feature Gates&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#available-feature-gates"&gt;Available Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#enabling-feature-gates"&gt;Enabling Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#feature-lifecycle"&gt;Feature Lifecycle&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#related-projects"&gt;Related Projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#donation"&gt;Donation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#github-sponsors"&gt;GitHub Sponsors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#paypal"&gt;PayPal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- vim-markdown-toc --&gt; 
&lt;h2&gt;Development Status&lt;/h2&gt; 
&lt;p&gt;frp is currently under development. You can try the latest release version in the &lt;code&gt;master&lt;/code&gt; branch, or use the &lt;code&gt;dev&lt;/code&gt; branch to access the version currently in development.&lt;/p&gt; 
&lt;p&gt;We are currently working on version 2 and attempting to perform some code refactoring and improvements. However, please note that it will not be compatible with version 1.&lt;/p&gt; 
&lt;p&gt;We will transition from version 0 to version 1 at the appropriate time and will only accept bug fixes and improvements, rather than big feature requests.&lt;/p&gt; 
&lt;h3&gt;About V2&lt;/h3&gt; 
&lt;p&gt;The complexity and difficulty of the v2 version are much higher than anticipated. I can only work on its development during fragmented time periods, and the constant interruptions disrupt productivity significantly. Given this situation, we will continue to optimize and iterate on the current version until we have more free time to proceed with the major version overhaul.&lt;/p&gt; 
&lt;p&gt;The concept behind v2 is based on my years of experience and reflection in the cloud-native domain, particularly in K8s and ServiceMesh. Its core is a modernized four-layer and seven-layer proxy, similar to envoy. This proxy itself is highly scalable, not only capable of implementing the functionality of intranet penetration but also applicable to various other domains. Building upon this highly scalable core, we aim to implement all the capabilities of frp v1 while also addressing the functionalities that were previously unachievable or difficult to implement in an elegant manner. Furthermore, we will maintain efficient development and iteration capabilities.&lt;/p&gt; 
&lt;p&gt;In addition, I envision frp itself becoming a highly extensible system and platform, similar to how we can provide a range of extension capabilities based on K8s. In K8s, we can customize development according to enterprise needs, utilizing features such as CRD, controller mode, webhook, CSI, and CNI. In frp v1, we introduced the concept of server plugins, which implemented some basic extensibility. However, it relies on a simple HTTP protocol and requires users to start independent processes and manage them on their own. This approach is far from flexible and convenient, and real-world demands vary greatly. It is unrealistic to expect a non-profit open-source project maintained by a few individuals to meet everyone's needs.&lt;/p&gt; 
&lt;p&gt;Finally, we acknowledge that the current design of modules such as configuration management, permission verification, certificate management, and API management is not modern enough. While we may carry out some optimizations in the v1 version, ensuring compatibility remains a challenging issue that requires a considerable amount of effort to address.&lt;/p&gt; 
&lt;p&gt;We sincerely appreciate your support for frp.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/architecture.png" alt="architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Example Usage&lt;/h2&gt; 
&lt;p&gt;To begin, download the latest program for your operating system and architecture from the &lt;a href="https://github.com/fatedier/frp/releases"&gt;Release&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;Next, place the &lt;code&gt;frps&lt;/code&gt; binary and server configuration file on Server A, which has a public IP address.&lt;/p&gt; 
&lt;p&gt;Finally, place the &lt;code&gt;frpc&lt;/code&gt; binary and client configuration file on Server B, which is located on a LAN that cannot be directly accessed from the public internet.&lt;/p&gt; 
&lt;p&gt;Some antiviruses improperly mark frpc as malware and delete it. This is due to frp being a networking tool capable of creating reverse proxies. Antiviruses sometimes flag reverse proxies due to their ability to bypass firewall port restrictions. If you are using antivirus, then you may need to whitelist/exclude frpc in your antivirus settings to avoid accidental quarantine/deletion. See &lt;a href="https://github.com/fatedier/frp/issues/3637"&gt;issue 3637&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Access your computer in a LAN network via SSH&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; on server A by setting the &lt;code&gt;bindPort&lt;/code&gt; for frp clients to connect to:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt; on server A:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; on server B and set the &lt;code&gt;serverAddr&lt;/code&gt; field to the public IP address of your frps server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the &lt;code&gt;localPort&lt;/code&gt; (listened on the client) and &lt;code&gt;remotePort&lt;/code&gt; (exposed on the server) are used for traffic going in and out of the frp system, while the &lt;code&gt;serverPort&lt;/code&gt; is used for communication between frps and frpc.&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on server B:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;To access server B from another machine through server A via SSH (assuming the username is &lt;code&gt;test&lt;/code&gt;), use the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 test@x.x.x.x&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Multiple SSH services sharing the same port&lt;/h3&gt; 
&lt;p&gt;This example implements multiple SSH services exposed through the same port using a proxy of type tcpmux. Similarly, as long as the client supports the HTTP Connect proxy connection method, port reuse can be achieved in this way.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Deploy frps on a machine with a public IP and modify the frps.toml file. Here is a simplified configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;bindPort = 7000
tcpmuxHTTPConnectPort = 5002
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Deploy frpc on the internal machine A with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh1"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["machine-a.example.com"]
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Deploy another frpc on the internal machine B with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh2"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["machine-b.example.com"]
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;To access internal machine A using SSH ProxyCommand, assuming the username is "test":&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o 'proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002' test@machine-a.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;To access internal machine B, the only difference is the domain name, assuming the username is "test":&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o 'proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002' test@machine-b.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/h3&gt; 
&lt;p&gt;Sometimes we need to expose a local web service behind a NAT network to others for testing purposes with our own domain name.&lt;/p&gt; 
&lt;p&gt;Unfortunately, we cannot resolve a domain name to a local IP. However, we can use frp to expose an HTTP(S) service.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; and set the HTTP port for vhost to 8080:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
vhostHTTPPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to configure an https proxy, you need to set up the &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Specify the &lt;code&gt;localPort&lt;/code&gt; of your web service:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["www.example.com"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt; &lt;p&gt;Map the A record of &lt;code&gt;www.example.com&lt;/code&gt; to either the public IP of the remote frps server or a CNAME record pointing to your original domain.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Visit your local web service using url &lt;code&gt;http://www.example.com:8080&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Forward DNS query requests&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Forward DNS query requests to the Google Public DNS server &lt;code&gt;8.8.8.8:53&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "dns"
type = "udp"
localIP = "8.8.8.8"
localPort = 53
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start frpc:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Test DNS resolution using the &lt;code&gt;dig&lt;/code&gt; command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;dig @x.x.x.x -p 6000 www.google.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Forward Unix Domain Socket&lt;/h3&gt; 
&lt;p&gt;Expose a Unix domain socket (e.g. the Docker daemon socket) as TCP.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "unix_domain_socket"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "unix_domain_socket"
unixPath = "/var/run/docker.sock"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Test the configuration by getting the docker version using &lt;code&gt;curl&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;curl http://x.x.x.x:6000/version&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Expose a simple HTTP file server&lt;/h3&gt; 
&lt;p&gt;Expose a simple HTTP file server to access files stored in the LAN from the public Internet.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as described above, then:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "test_static_file"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "static_file"
localPath = "/tmp/files"
stripPrefix = "static"
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Visit &lt;code&gt;http://x.x.x.x:6000/static/&lt;/code&gt; from your browser and specify correct username and password to view files in &lt;code&gt;/tmp/files&lt;/code&gt; on the &lt;code&gt;frpc&lt;/code&gt; machine.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Enable HTTPS for a local HTTP(S) service&lt;/h3&gt; 
&lt;p&gt;You may substitute &lt;code&gt;https2https&lt;/code&gt; for the plugin, and point the &lt;code&gt;localAddr&lt;/code&gt; to a HTTPS endpoint.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "test_https2http"
type = "https"
customDomains = ["test.example.com"]

[proxies.plugin]
type = "https2http"
localAddr = "127.0.0.1:80"
crtPath = "./server.crt"
keyPath = "./server.key"
hostHeaderRewrite = "127.0.0.1"
requestHeaders.set.x-from-where = "frp"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Visit &lt;code&gt;https://test.example.com&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Expose your service privately&lt;/h3&gt; 
&lt;p&gt;To mitigate risks associated with exposing certain services directly to the public network, STCP (Secret TCP) mode requires a preshared key to be used for access to the service from other clients.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; same as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B with the following config. This example is for exposing the SSH service (port 22), and note the &lt;code&gt;secretKey&lt;/code&gt; field for the preshared key, and that the &lt;code&gt;remotePort&lt;/code&gt; field is removed here:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "secret_ssh"
type = "stcp"
secretKey = "abcdefg"
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the following config to access the SSH service with a security key (&lt;code&gt;secretKey&lt;/code&gt; field):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[visitors]]
name = "secret_ssh_visitor"
type = "stcp"
serverName = "secret_ssh"
secretKey = "abcdefg"
bindAddr = "127.0.0.1"
bindPort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;P2P Mode&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;xtcp&lt;/strong&gt; is designed to transmit large amounts of data directly between clients. A frps server is still needed, as P2P here only refers to the actual data transmission.&lt;/p&gt; 
&lt;p&gt;Note that it may not work with all types of NAT devices. You might want to fallback to stcp if xtcp doesn't work.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B, and expose the SSH port. Note that the &lt;code&gt;remotePort&lt;/code&gt; field is removed:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = "xxx"

[[proxies]]
name = "p2p_ssh"
type = "xtcp"
secretKey = "abcdefg"
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the configuration to connect to SSH using P2P mode:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = "xxx"

[[visitors]]
name = "p2p_ssh_visitor"
type = "xtcp"
serverName = "p2p_ssh"
secretKey = "abcdefg"
bindAddr = "127.0.0.1"
bindPort = 6000
# when automatic tunnel persistence is required, set it to true
keepTunnelOpen = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;Since v0.52.0, we support TOML, YAML, and JSON for configuration. Please note that INI is deprecated and will be removed in future releases. New features will only be available in TOML, YAML, or JSON. Users wanting these new features should switch their configuration format accordingly.&lt;/p&gt; 
&lt;p&gt;Read the full example configuration files to find out even more features not described here.&lt;/p&gt; 
&lt;p&gt;Examples use TOML format, but you can still use YAML or JSON.&lt;/p&gt; 
&lt;p&gt;These configuration files is for reference only. Please do not use this configuration directly to run the program as it may have various issues.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/conf/frps_full_example.toml"&gt;Full configuration file for frps (Server)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/conf/frpc_full_example.toml"&gt;Full configuration file for frpc (Client)&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using Environment Variables&lt;/h3&gt; 
&lt;p&gt;Environment variables can be referenced in the configuration file, using Go's standard format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "{{ .Envs.FRP_SERVER_ADDR }}"
serverPort = 7000

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = {{ .Envs.FRP_SSH_REMOTE_PORT }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With the config above, variables can be passed into &lt;code&gt;frpc&lt;/code&gt; program like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export FRP_SERVER_ADDR=x.x.x.x
export FRP_SSH_REMOTE_PORT=6000
./frpc -c ./frpc.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;frpc&lt;/code&gt; will render configuration file template using OS environment variables. Remember to prefix your reference with &lt;code&gt;.Envs&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Split Configures Into Different Files&lt;/h3&gt; 
&lt;p&gt;You can split multiple proxy configs into different files and include them in the main file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
includes = ["./confd/*.toml"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# ./confd/test.toml

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Server Dashboard&lt;/h3&gt; 
&lt;p&gt;Check frp's status and proxies' statistics information by Dashboard.&lt;/p&gt; 
&lt;p&gt;Configure a port for dashboard to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# The default value is 127.0.0.1. Change it to 0.0.0.0 when you want to access it from a public network.
webServer.addr = "0.0.0.0"
webServer.port = 7500
# dashboard's username and password are both optional
webServer.user = "admin"
webServer.password = "admin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://[serverAddr]:7500&lt;/code&gt; to see the dashboard, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, you can use HTTPS port by using your domains wildcard or normal SSL certificate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;webServer.port = 7500
# dashboard's username and password are both optional
webServer.user = "admin"
webServer.password = "admin"
webServer.tls.certFile = "server.crt"
webServer.tls.keyFile = "server.key"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;https://[serverAddr]:7500&lt;/code&gt; to see the dashboard in secure HTTPS connection, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/dashboard.png" alt="dashboard" /&gt;&lt;/p&gt; 
&lt;h3&gt;Client Admin UI&lt;/h3&gt; 
&lt;p&gt;The Client Admin UI helps you check and manage frpc's configuration.&lt;/p&gt; 
&lt;p&gt;Configure an address for admin UI to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;webServer.addr = "127.0.0.1"
webServer.port = 7400
webServer.user = "admin"
webServer.password = "admin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://127.0.0.1:7400&lt;/code&gt; to see admin UI, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Monitor&lt;/h3&gt; 
&lt;p&gt;When web server is enabled, frps will save monitor data in cache for 7 days. It will be cleared after process restart.&lt;/p&gt; 
&lt;p&gt;Prometheus is also supported.&lt;/p&gt; 
&lt;h4&gt;Prometheus&lt;/h4&gt; 
&lt;p&gt;Enable dashboard first, then configure &lt;code&gt;enablePrometheus = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;http://{dashboard_addr}/metrics&lt;/code&gt; will provide prometheus monitor data.&lt;/p&gt; 
&lt;h3&gt;Authenticating the Client&lt;/h3&gt; 
&lt;p&gt;There are 2 authentication methods to authenticate frpc with frps.&lt;/p&gt; 
&lt;p&gt;You can decide which one to use by configuring &lt;code&gt;auth.method&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt;, the default one is token.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = ["HeartBeats"]&lt;/code&gt; will use the configured authentication method to add and validate authentication on every heartbeat between frpc and frps.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = ["NewWorkConns"]&lt;/code&gt; will do the same for every new work connection between frpc and frps.&lt;/p&gt; 
&lt;h4&gt;Token Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = "token"&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - token based authentication will be used.&lt;/p&gt; 
&lt;p&gt;Make sure to specify the same &lt;code&gt;auth.token&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt; for frpc to pass frps validation&lt;/p&gt; 
&lt;h5&gt;Token Source&lt;/h5&gt; 
&lt;p&gt;frp supports reading authentication tokens from external sources using the &lt;code&gt;tokenSource&lt;/code&gt; configuration. Currently, file-based token source is supported.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;File-based token source:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
auth.method = "token"
auth.tokenSource.type = "file"
auth.tokenSource.file.path = "/path/to/token/file"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The token will be read from the specified file at startup. This is useful for scenarios where tokens are managed by external systems or need to be kept separate from configuration files for security reasons.&lt;/p&gt; 
&lt;h4&gt;OIDC Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = "oidc"&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - OIDC based authentication will be used.&lt;/p&gt; 
&lt;p&gt;OIDC stands for OpenID Connect, and the flow used is called &lt;a href="https://tools.ietf.org/html/rfc6749#section-4.4"&gt;Client Credentials Grant&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use this authentication type - configure &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
auth.method = "oidc"
auth.oidc.issuer = "https://example-oidc-issuer.com/"
auth.oidc.audience = "https://oidc-audience.com/.default"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
auth.method = "oidc"
auth.oidc.clientID = "98692467-37de-409a-9fac-bb2585826f18" # Replace with OIDC client ID
auth.oidc.clientSecret = "oidc_secret"
auth.oidc.audience = "https://oidc-audience.com/.default"
auth.oidc.tokenEndpointURL = "https://example-oidc-endpoint.com/oauth2/v2.0/token"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Encryption and Compression&lt;/h3&gt; 
&lt;p&gt;The features are off by default. You can turn on encryption and/or compression:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "ssh"
type = "tcp"
localPort = 22
remotePort = 6000
transport.useEncryption = true
transport.useCompression = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;TLS&lt;/h4&gt; 
&lt;p&gt;Since v0.50.0, the default value of &lt;code&gt;transport.tls.enable&lt;/code&gt; and &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; has been changed to true, and tls is enabled by default.&lt;/p&gt; 
&lt;p&gt;For port multiplexing, frp sends a first byte &lt;code&gt;0x17&lt;/code&gt; to dial a TLS connection. This only takes effect when you set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;To &lt;strong&gt;enforce&lt;/strong&gt; &lt;code&gt;frps&lt;/code&gt; to only accept TLS connections - configure &lt;code&gt;transport.tls.force = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;. &lt;strong&gt;This is optional.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frpc&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;transport.tls.enable = true
transport.tls.certFile = "certificate.crt"
transport.tls.keyFile = "certificate.key"
transport.tls.trustedCaFile = "ca.crt"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frps&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;transport.tls.force = true
transport.tls.certFile = "certificate.crt"
transport.tls.keyFile = "certificate.key"
transport.tls.trustedCaFile = "ca.crt"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will need &lt;strong&gt;a root CA cert&lt;/strong&gt; and &lt;strong&gt;at least one SSL/TLS certificate&lt;/strong&gt;. It &lt;strong&gt;can&lt;/strong&gt; be self-signed or regular (such as Let's Encrypt or another SSL/TLS certificate provider).&lt;/p&gt; 
&lt;p&gt;If you using &lt;code&gt;frp&lt;/code&gt; via IP address and not hostname, make sure to set the appropriate IP address in the Subject Alternative Name (SAN) area when generating SSL/TLS Certificates.&lt;/p&gt; 
&lt;p&gt;Given an example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prepare openssl config file. It exists at &lt;code&gt;/etc/pki/tls/openssl.cnf&lt;/code&gt; in Linux System and &lt;code&gt;/System/Library/OpenSSL/openssl.cnf&lt;/code&gt; in MacOS, and you can copy it to current path, like &lt;code&gt;cp /etc/pki/tls/openssl.cnf ./my-openssl.cnf&lt;/code&gt;. If not, you can build it by yourself, like:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;cat &amp;gt; my-openssl.cnf &amp;lt;&amp;lt; EOF
[ ca ]
default_ca = CA_default
[ CA_default ]
x509_extensions = usr_cert
[ req ]
default_bits        = 2048
default_md          = sha256
default_keyfile     = privkey.pem
distinguished_name  = req_distinguished_name
attributes          = req_attributes
x509_extensions     = v3_ca
string_mask         = utf8only
[ req_distinguished_name ]
[ req_attributes ]
[ usr_cert ]
basicConstraints       = CA:FALSE
nsComment              = "OpenSSL Generated Certificate"
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid,issuer
[ v3_ca ]
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid:always,issuer
basicConstraints       = CA:true
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build ca certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out ca.key 2048
openssl req -x509 -new -nodes -key ca.key -subj "/CN=example.ca.com" -days 5000 -out ca.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frps certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048

openssl req -new -sha256 -key server.key \
    -subj "/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=server.com" \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf "\n[SAN]\nsubjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com")) \
    -out server.csr

openssl x509 -req -days 365 -sha256 \
	-in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf "subjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com") \
	-out server.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frpc certificates：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out client.key 2048
openssl req -new -sha256 -key client.key \
    -subj "/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=client.com" \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf "\n[SAN]\nsubjectAltName=DNS:client.com,DNS:example.client.com")) \
    -out client.csr

openssl x509 -req -days 365 -sha256 \
    -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf "subjectAltName=DNS:client.com,DNS:example.client.com") \
	-out client.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hot-Reloading frpc configuration&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
webServer.addr = "127.0.0.1"
webServer.port = 7400
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run command &lt;code&gt;frpc reload -c ./frpc.toml&lt;/code&gt; and wait for about 10 seconds to let &lt;code&gt;frpc&lt;/code&gt; create or update or remove proxies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that global client parameters won't be modified except 'start'.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can run command &lt;code&gt;frpc verify -c ./frpc.toml&lt;/code&gt; before reloading to check if there are config errors.&lt;/p&gt; 
&lt;h3&gt;Get proxy status from client&lt;/h3&gt; 
&lt;p&gt;Use &lt;code&gt;frpc status -c ./frpc.toml&lt;/code&gt; to get status of all proxies. The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API.&lt;/p&gt; 
&lt;h3&gt;Only allowing certain ports on the server&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;allowPorts&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; is used to avoid abuse of ports:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
allowPorts = [
  { start = 2000, end = 3000 },
  { single = 3001 },
  { single = 3003 },
  { start = 4000, end = 50000 }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port Reuse&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt; in frps can use same port with &lt;code&gt;bindPort&lt;/code&gt;. frps will detect the connection's protocol and handle it correspondingly.&lt;/p&gt; 
&lt;p&gt;What you need to pay attention to is that if you want to configure &lt;code&gt;vhostHTTPSPort&lt;/code&gt; and &lt;code&gt;bindPort&lt;/code&gt; to the same port, you need to first set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;We would like to try to allow multiple proxies bind a same remote port with different protocols in the future.&lt;/p&gt; 
&lt;h3&gt;Bandwidth Limit&lt;/h3&gt; 
&lt;h4&gt;For Each Proxy&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "ssh"
type = "tcp"
localPort = 22
remotePort = 6000
transport.bandwidthLimit = "1MB"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimit&lt;/code&gt; in each proxy's configure to enable this feature. Supported units are &lt;code&gt;MB&lt;/code&gt; and &lt;code&gt;KB&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimitMode&lt;/code&gt; to &lt;code&gt;client&lt;/code&gt; or &lt;code&gt;server&lt;/code&gt; to limit bandwidth on the client or server side. Default is &lt;code&gt;client&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Stream Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports tcp stream multiplexing since v0.10.0 like HTTP2 Multiplexing, in which case all logic connections to the same frpc are multiplexed into the same TCP connection.&lt;/p&gt; 
&lt;p&gt;You can disable this feature by modify &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml and frpc.toml, must be same
transport.tcpMux = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support KCP Protocol&lt;/h3&gt; 
&lt;p&gt;KCP is a fast and reliable protocol that can achieve the transmission effect of a reduction of the average latency by 30% to 40% and reduction of the maximum delay by a factor of three, at the cost of 10% to 20% more bandwidth wasted than TCP.&lt;/p&gt; 
&lt;p&gt;KCP mode uses UDP as the underlying transport. Using KCP in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable KCP in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for KCP.
kcpBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;kcpBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use KCP to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
# Same as the 'kcpBindPort' in frps.toml
serverPort = 7000
transport.protocol = "kcp"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support QUIC Protocol&lt;/h3&gt; 
&lt;p&gt;QUIC is a new multiplexed transport built on top of UDP.&lt;/p&gt; 
&lt;p&gt;Using QUIC in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable QUIC in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for QUIC.
quicBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;quicBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use QUIC to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
# Same as the 'quicBindPort' in frps.toml
serverPort = 7000
transport.protocol = "quic"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connection Pooling&lt;/h3&gt; 
&lt;p&gt;By default, frps creates a new frpc connection to the backend service upon a user request. With connection pooling, frps keeps a certain number of pre-established connections, reducing the time needed to establish a connection.&lt;/p&gt; 
&lt;p&gt;This feature is suitable for a large number of short connections.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Configure the limit of pool count each proxy can use in &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
transport.maxPoolCount = 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Enable and specify the number of connection pool:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
transport.poolCount = 1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Load balancing&lt;/h3&gt; 
&lt;p&gt;Load balancing is supported by &lt;code&gt;group&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This feature is only available for types &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;tcpmux&lt;/code&gt; now.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "test1"
type = "tcp"
localPort = 8080
remotePort = 80
loadBalancer.group = "web"
loadBalancer.groupKey = "123"

[[proxies]]
name = "test2"
type = "tcp"
localPort = 8081
remotePort = 80
loadBalancer.group = "web"
loadBalancer.groupKey = "123"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;loadBalancer.groupKey&lt;/code&gt; is used for authentication.&lt;/p&gt; 
&lt;p&gt;Connections to port 80 will be dispatched to proxies in the same group randomly.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;remotePort&lt;/code&gt; in the same group should be the same.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;customDomains&lt;/code&gt;, &lt;code&gt;subdomain&lt;/code&gt;, &lt;code&gt;locations&lt;/code&gt; should be the same.&lt;/p&gt; 
&lt;h3&gt;Service Health Check&lt;/h3&gt; 
&lt;p&gt;Health check feature can help you achieve high availability with load balancing.&lt;/p&gt; 
&lt;p&gt;Add &lt;code&gt;healthCheck.type = "tcp"&lt;/code&gt; or &lt;code&gt;healthCheck.type = "http"&lt;/code&gt; to enable health check.&lt;/p&gt; 
&lt;p&gt;With health check type &lt;strong&gt;tcp&lt;/strong&gt;, the service port will be pinged (TCPing):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "test1"
type = "tcp"
localPort = 22
remotePort = 6000
# Enable TCP health check
healthCheck.type = "tcp"
# TCPing timeout seconds
healthCheck.timeoutSeconds = 3
# If health check failed 3 times in a row, the proxy will be removed from frps
healthCheck.maxFailed = 3
# A health check every 10 seconds
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With health check type &lt;strong&gt;http&lt;/strong&gt;, an HTTP request will be sent to the service and an HTTP 2xx OK response is expected:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localIP = "127.0.0.1"
localPort = 80
customDomains = ["test.example.com"]
# Enable HTTP health check
healthCheck.type = "http"
# frpc will send a GET request to '/status'
# and expect an HTTP 2xx OK response
healthCheck.path = "/status"
healthCheck.timeoutSeconds = 3
healthCheck.maxFailed = 3
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rewriting the HTTP Host Header&lt;/h3&gt; 
&lt;p&gt;By default frp does not modify the tunneled HTTP requests at all as it's a byte-for-byte copy.&lt;/p&gt; 
&lt;p&gt;However, speaking of web servers and HTTP requests, your web server might rely on the &lt;code&gt;Host&lt;/code&gt; HTTP header to determine the website to be accessed. frp can rewrite the &lt;code&gt;Host&lt;/code&gt; header when forwarding the HTTP requests, with the &lt;code&gt;hostHeaderRewrite&lt;/code&gt; field:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
hostHeaderRewrite = "dev.example.com"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The HTTP request will have the &lt;code&gt;Host&lt;/code&gt; header rewritten to &lt;code&gt;Host: dev.example.com&lt;/code&gt; when it reaches the actual web server, although the request from the browser probably has &lt;code&gt;Host: test.example.com&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Setting other HTTP Headers&lt;/h3&gt; 
&lt;p&gt;Similar to &lt;code&gt;Host&lt;/code&gt;, You can override other HTTP request and response headers with proxy type &lt;code&gt;http&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
hostHeaderRewrite = "dev.example.com"
requestHeaders.set.x-from-where = "frp"
responseHeaders.set.foo = "bar"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this example, it will set header &lt;code&gt;x-from-where: frp&lt;/code&gt; in the HTTP request and &lt;code&gt;foo: bar&lt;/code&gt; in the HTTP response.&lt;/p&gt; 
&lt;h3&gt;Get Real IP&lt;/h3&gt; 
&lt;h4&gt;HTTP X-Forwarded-For&lt;/h4&gt; 
&lt;p&gt;This feature is for &lt;code&gt;http&lt;/code&gt; proxies or proxies with the &lt;code&gt;https2http&lt;/code&gt; and &lt;code&gt;https2https&lt;/code&gt; plugins enabled.&lt;/p&gt; 
&lt;p&gt;You can get user's real IP from HTTP request headers &lt;code&gt;X-Forwarded-For&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Proxy Protocol&lt;/h4&gt; 
&lt;p&gt;frp supports Proxy Protocol to send user's real IP to local services.&lt;/p&gt; 
&lt;p&gt;Here is an example for https service:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "https"
localPort = 443
customDomains = ["test.example.com"]

# now v1 and v2 are supported
transport.proxyProtocolVersion = "v2"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can enable Proxy Protocol support in nginx to expose user's real IP in HTTP header &lt;code&gt;X-Real-IP&lt;/code&gt;, and then read &lt;code&gt;X-Real-IP&lt;/code&gt; header in your web service for the real IP.&lt;/p&gt; 
&lt;h3&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/h3&gt; 
&lt;p&gt;Anyone who can guess your tunnel URL can access your local web server unless you protect it with a password.&lt;/p&gt; 
&lt;p&gt;This enforces HTTP Basic Auth on all requests with the username and password specified in frpc's configure file.&lt;/p&gt; 
&lt;p&gt;It can only be enabled when proxy type is http.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit &lt;code&gt;http://test.example.com&lt;/code&gt; in the browser and now you are prompted to enter the username and password.&lt;/p&gt; 
&lt;h3&gt;Custom Subdomain Names&lt;/h3&gt; 
&lt;p&gt;It is convenient to use &lt;code&gt;subdomain&lt;/code&gt; configure for http and https types when many people share one frps server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
subDomainHost = "frps.com"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Resolve &lt;code&gt;*.frps.com&lt;/code&gt; to the frps server's IP. This is usually called a Wildcard DNS record.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
subdomain = "test"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can visit your web service on &lt;code&gt;test.frps.com&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that if &lt;code&gt;subdomainHost&lt;/code&gt; is not empty, &lt;code&gt;customDomains&lt;/code&gt; should not be the subdomain of &lt;code&gt;subdomainHost&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;URL Routing&lt;/h3&gt; 
&lt;p&gt;frp supports forwarding HTTP requests to different backend web services by url routing.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;locations&lt;/code&gt; specifies the prefix of URL used for routing. frps first searches for the most specific prefix location given by literal strings regardless of the listed order.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web01"
type = "http"
localPort = 80
customDomains = ["web.example.com"]
locations = ["/"]

[[proxies]]
name = "web02"
type = "http"
localPort = 81
customDomains = ["web.example.com"]
locations = ["/news", "/about"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;HTTP requests with URL prefix &lt;code&gt;/news&lt;/code&gt; or &lt;code&gt;/about&lt;/code&gt; will be forwarded to &lt;strong&gt;web02&lt;/strong&gt; and other requests to &lt;strong&gt;web01&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Port Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports receiving TCP sockets directed to different proxies on a single port on frps, similar to &lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The only supported TCP port multiplexing method available at the moment is &lt;code&gt;httpconnect&lt;/code&gt; - HTTP CONNECT tunnel.&lt;/p&gt; 
&lt;p&gt;When setting &lt;code&gt;tcpmuxHTTPConnectPort&lt;/code&gt; to anything other than 0 in frps, frps will listen on this port for HTTP CONNECT requests.&lt;/p&gt; 
&lt;p&gt;The host of the HTTP CONNECT request will be used to match the proxy in frps. Proxy hosts can be configured in frpc by configuring &lt;code&gt;customDomains&lt;/code&gt; and / or &lt;code&gt;subdomain&lt;/code&gt; under &lt;code&gt;tcpmux&lt;/code&gt; proxies, when &lt;code&gt;multiplexer = "httpconnect"&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
tcpmuxHTTPConnectPort = 1337
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "proxy1"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["test1"]
localPort = 80

[[proxies]]
name = "proxy2"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["test2"]
localPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the above configuration - frps can be contacted on port 1337 with a HTTP CONNECT header such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CONNECT test1 HTTP/1.1\r\n\r\n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and the connection will be routed to &lt;code&gt;proxy1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Connecting to frps via PROXY&lt;/h3&gt; 
&lt;p&gt;frpc can connect to frps through proxy if you set OS environment variable &lt;code&gt;HTTP_PROXY&lt;/code&gt;, or if &lt;code&gt;transport.proxyURL&lt;/code&gt; is set in frpc.toml file.&lt;/p&gt; 
&lt;p&gt;It only works when protocol is tcp.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
transport.proxyURL = "http://user:pwd@192.168.1.128:8080"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port range mapping&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Added in v0.56.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;We can use the range syntax of Go template combined with the built-in &lt;code&gt;parseNumberRangePair&lt;/code&gt; function to achieve port range mapping.&lt;/p&gt; 
&lt;p&gt;The following example, when run, will create 8 proxies named &lt;code&gt;test-6000, test-6001 ... test-6007&lt;/code&gt;, each mapping the remote port to the local port.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{{- range $_, $v := parseNumberRangePair "6000-6006,6007" "6000-6006,6007" }}
[[proxies]]
name = "tcp-{{ $v.First }}"
type = "tcp"
localPort = {{ $v.First }}
remotePort = {{ $v.Second }}
{{- end }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Client Plugins&lt;/h3&gt; 
&lt;p&gt;frpc only forwards requests to local TCP or UDP ports by default.&lt;/p&gt; 
&lt;p&gt;Plugins are used for providing rich features. There are built-in plugins such as &lt;code&gt;unix_domain_socket&lt;/code&gt;, &lt;code&gt;http_proxy&lt;/code&gt;, &lt;code&gt;socks5&lt;/code&gt;, &lt;code&gt;static_file&lt;/code&gt;, &lt;code&gt;http2https&lt;/code&gt;, &lt;code&gt;https2http&lt;/code&gt;, &lt;code&gt;https2https&lt;/code&gt; and you can see &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage"&gt;example usage&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Using plugin &lt;strong&gt;http_proxy&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "http_proxy"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "http_proxy"
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;httpUser&lt;/code&gt; and &lt;code&gt;httpPassword&lt;/code&gt; are configuration parameters used in &lt;code&gt;http_proxy&lt;/code&gt; plugin.&lt;/p&gt; 
&lt;h3&gt;Server Manage Plugins&lt;/h3&gt; 
&lt;p&gt;Read the &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/server_plugin.md"&gt;document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Find more plugins in &lt;a href="https://github.com/gofrp/plugin"&gt;gofrp/plugin&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SSH Tunnel Gateway&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;added in v0.53.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;frp supports listening to an SSH port on the frps side and achieves TCP protocol proxying through the SSH -R protocol, without relying on frpc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
sshTunnelGateway.bindPort = 2200
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running &lt;code&gt;./frps -c frps.toml&lt;/code&gt;, a private key file named &lt;code&gt;.autogen_ssh_key&lt;/code&gt; will be automatically created in the current working directory. This generated private key file will be used by the SSH server in frps.&lt;/p&gt; 
&lt;p&gt;Executing the command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ssh -R :80:127.0.0.1:8080 v0@{frp address} -p 2200 tcp --proxy_name "test-tcp" --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;sets up a proxy on frps that forwards the local 8080 service to the port 9090.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;frp (via SSH) (Ctrl+C to quit)

User:
ProxyName: test-tcp
Type: tcp
RemoteAddress: :9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is equivalent to:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;frpc tcp --proxy_name "test-tcp" --local_ip 127.0.0.1 --local_port 8080 --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to this &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/ssh_tunnel_gateway.md"&gt;document&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Virtual Network (VirtualNet)&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Alpha feature added in v0.62.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;The VirtualNet feature enables frp to create and manage virtual network connections between clients and visitors through a TUN interface. This allows for IP-level routing between machines, extending frp beyond simple port forwarding to support full network connectivity.&lt;/p&gt; 
&lt;p&gt;For detailed information about configuration and usage, please refer to the &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/virtual_net.md"&gt;VirtualNet documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feature Gates&lt;/h2&gt; 
&lt;p&gt;frp supports feature gates to enable or disable experimental features. This allows users to try out new features before they're considered stable.&lt;/p&gt; 
&lt;h3&gt;Available Feature Gates&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Stage&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VirtualNet&lt;/td&gt; 
   &lt;td&gt;ALPHA&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Virtual network capabilities for frp&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Enabling Feature Gates&lt;/h3&gt; 
&lt;p&gt;To enable an experimental feature, add the feature gate to your configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;featureGates = { VirtualNet = true }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Feature Lifecycle&lt;/h3&gt; 
&lt;p&gt;Features typically go through three stages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ALPHA&lt;/strong&gt;: Disabled by default, may be unstable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;BETA&lt;/strong&gt;: May be enabled by default, more stable but still evolving&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GA (Generally Available)&lt;/strong&gt;: Enabled by default, ready for production use&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gofrp/plugin"&gt;gofrp/plugin&lt;/a&gt; - A repository for frp plugins that contains a variety of plugins implemented based on the frp extension mechanism, meeting the customization needs of different scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gofrp/tiny-frpc"&gt;gofrp/tiny-frpc&lt;/a&gt; - A lightweight version of the frp client (around 3.5MB at minimum) implemented using the ssh protocol, supporting some of the most commonly used features, suitable for devices with limited resources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in getting involved? We would like to help you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Take a look at our &lt;a href="https://github.com/fatedier/frp/issues"&gt;issues list&lt;/a&gt; and consider sending a Pull Request to &lt;strong&gt;dev branch&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to add a new feature, please create an issue first to describe the new feature, as well as the implementation approach. Once a proposal is accepted, create an implementation of the new features and submit it as a pull request.&lt;/li&gt; 
 &lt;li&gt;Sorry for my poor English. Improvements for this document are welcome, even some typo fixes.&lt;/li&gt; 
 &lt;li&gt;If you have great ideas, send an email to &lt;a href="mailto:fatedier@gmail.com"&gt;fatedier@gmail.com&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note: We prefer you to give your advise in &lt;a href="https://github.com/fatedier/frp/issues"&gt;issues&lt;/a&gt;, so others with a same question can search it quickly and we don't need to answer them repeatedly.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Donation&lt;/h2&gt; 
&lt;p&gt;If frp helps you a lot, you can support us by:&lt;/p&gt; 
&lt;h3&gt;GitHub Sponsors&lt;/h3&gt; 
&lt;p&gt;Support us by &lt;a href="https://github.com/sponsors/fatedier"&gt;Github Sponsors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can have your company's logo placed on README file of this project.&lt;/p&gt; 
&lt;h3&gt;PayPal&lt;/h3&gt; 
&lt;p&gt;Donate money by &lt;a href="https://www.paypal.me/fatedier"&gt;PayPal&lt;/a&gt; to my account &lt;strong&gt;&lt;a href="mailto:fatedier@gmail.com"&gt;fatedier@gmail.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>apernet/hysteria</title>
      <link>https://github.com/apernet/hysteria</link>
      <description>&lt;p&gt;Hysteria is a powerful, lightning fast and censorship resistant proxy.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/apernet/hysteria/master/logo.svg?sanitize=true" alt="Hysteria 2" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/apernet/hysteria/master/LICENSE.md"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/apernet/hysteria/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/apernet/hysteria?style=flat-square" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://t.me/hysteria_github"&gt;&lt;img src="https://img.shields.io/badge/chat-Telegram-blue?style=flat-square" alt="Telegram" /&gt;&lt;/a&gt; &lt;a href="https://github.com/apernet/hysteria/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/apernet/hysteria?style=flat-square" alt="Discussions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2 style="text-align: center;"&gt;Hysteria is a powerful, lightning fast and censorship resistant proxy.&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://v2.hysteria.network/"&gt;Get Started&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;&lt;a href="https://v2.hysteria.network/zh/"&gt;中文文档&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;&lt;a href="https://v1.hysteria.network/"&gt;Hysteria 1.x (legacy)&lt;/a&gt;&lt;/h3&gt; 
&lt;hr /&gt; 
&lt;div class="feature-grid"&gt; 
 &lt;div&gt; 
  &lt;h3&gt;🛠️ Jack of all trades&lt;/h3&gt; 
  &lt;p&gt;Wide range of modes including SOCKS5, HTTP Proxy, TCP/UDP Forwarding, Linux TProxy, TUN - with more features being added constantly.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;h3&gt;⚡ Blazing fast&lt;/h3&gt; 
  &lt;p&gt;Powered by a customized QUIC protocol, Hysteria is designed to deliver unparalleled performance over unreliable and lossy networks.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;h3&gt;✊ Censorship resistant&lt;/h3&gt; 
  &lt;p&gt;The protocol masquerades as standard HTTP/3 traffic, making it very difficult for censors to detect and block without widespread collateral damage.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;h3&gt;💻 Cross-platform&lt;/h3&gt; 
  &lt;p&gt;We have builds for every major platform and architecture. Deploy anywhere &amp;amp; use everywhere. Not to mention the long list of 3rd party apps.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;h3&gt;🔗 Easy integration&lt;/h3&gt; 
  &lt;p&gt;With built-in support for custom authentication, traffic statistics &amp;amp; access control, Hysteria is easy to integrate into your infrastructure.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;h3&gt;🤗 Chill and supportive&lt;/h3&gt; 
  &lt;p&gt;We have well-documented specifications and code for developers to contribute and/or build their own apps. And a helpful community, too.&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;If you find Hysteria useful, consider giving it a ⭐️!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#apernet/hysteria&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=apernet/hysteria&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-weed-mini"&gt;Quick Start with weed mini&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start with weed mini&lt;/h2&gt; 
&lt;p&gt;The easiest way to get started with SeaweedFS for development and testing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# remove quarantine on macOS
# xattr -d com.apple.quarantine  ./weed
export AWS_ACCESS_KEY_ID=admin
export AWS_SECRET_ACCESS_KEY=key
./weed mini -dir=/data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This single command starts a complete SeaweedFS setup with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Master UI&lt;/strong&gt;: &lt;a href="http://localhost:9333"&gt;http://localhost:9333&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Volume Server&lt;/strong&gt;: &lt;a href="http://localhost:9340"&gt;http://localhost:9340&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Filer UI&lt;/strong&gt;: &lt;a href="http://localhost:8888"&gt;http://localhost:8888&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3 Endpoint&lt;/strong&gt;: &lt;a href="http://localhost:8333"&gt;http://localhost:8333&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WebDAV&lt;/strong&gt;: &lt;a href="http://localhost:7333"&gt;http://localhost:7333&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Admin UI&lt;/strong&gt;: &lt;a href="http://localhost:23646"&gt;http://localhost:23646&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Perfect for development, testing, learning SeaweedFS, and single node deployments!&lt;/p&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway. The difference with &lt;code&gt;weed mini&lt;/code&gt; is that &lt;code&gt;weed mini&lt;/code&gt; can auto configure based on the single host environment, while &lt;code&gt;weed server&lt;/code&gt; requires manual configuration and are designed for production use.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -master="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook’s Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook’s Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -master="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -master="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;For more installation options, including how to run with Docker, see the &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Getting-Started"&gt;Getting Started guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2025-12-05[194844]-kBpU.csv.zst"

Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 42s.
 * Throughput: 55.13 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 42s.
 * Throughput: 2477.45 MiB/s, 247.75 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 42s.
 * Throughput: 825.85 MiB/s, 82.59 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 42s.
 * Throughput: 165.27 obj/s

Cluster Total: 3302.88 MiB/s, 550.51 obj/s over 43s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/typescript-go</title>
      <link>https://github.com/microsoft/typescript-go</link>
      <description>&lt;p&gt;Staging repo for development of native port of TypeScript&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TypeScript 7&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://devblogs.microsoft.com/typescript/typescript-native-port/"&gt;Not sure what this is? Read the announcement post!&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Preview&lt;/h2&gt; 
&lt;p&gt;A preview build is available on npm as &lt;a href="https://www.npmjs.com/package/@typescript/native-preview"&gt;&lt;code&gt;@typescript/native-preview&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm install @typescript/native-preview
npx tsgo # Use this as you would tsc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A preview VS Code extension is &lt;a href="https://marketplace.visualstudio.com/items?itemName=TypeScriptTeam.native-preview"&gt;available on the VS Code marketplace&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use this, set this in your VS Code settings:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "typescript.experimental.useTsgo": true
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What Works So Far?&lt;/h2&gt; 
&lt;p&gt;This is still a work in progress and is not yet at full feature parity with TypeScript. Bugs may exist. Please check this list carefully before logging a new issue or assuming an intentional change.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Program creation&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Same files and module resolution as TS 5.9. Not all resolution modes supported yet.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Parsing/scanning&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Exact same syntax errors as TS 5.9&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Commandline and &lt;code&gt;tsconfig.json&lt;/code&gt; parsing&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Done, though &lt;code&gt;tsconfig&lt;/code&gt; errors may not be as helpful.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Type resolution&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Same types as TS 5.9.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Type checking&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Same errors, locations, and messages as TS 5.9. Types printback in errors may display differently.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript-specific inference and JSDoc&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;Mostly complete, but intentionally lacking some features. Declaration emit not complete.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JSX&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Declaration emit&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;Most common features are in place, but some edge cases and feature flags are still unhandled.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Emit (JS output)&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;target: esnext&lt;/code&gt; well-supported, other targets may have gaps.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Watch mode&lt;/td&gt; 
   &lt;td&gt;prototype&lt;/td&gt; 
   &lt;td&gt;Watches files and rebuilds, but no incremental rechecking. Not optimized.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Build mode / project references&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Incremental build&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Language service (LSP)&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;Most functionality. More features coming soon.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;API&lt;/td&gt; 
   &lt;td&gt;not ready&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Definitions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;done&lt;/strong&gt; aka "believed done": We're not currently aware of any deficits or major left work to do. OK to log bugs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;in progress&lt;/strong&gt;: currently being worked on; some features may work and some might not. OK to log panics, but nothing else please&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;prototype&lt;/strong&gt;: proof-of-concept only; do not log bugs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;not ready&lt;/strong&gt;: either haven't even started yet, or far enough from ready that you shouldn't bother messing with it yet&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other Notes&lt;/h2&gt; 
&lt;p&gt;Long-term, we expect that this repo and its contents will be merged into &lt;code&gt;microsoft/TypeScript&lt;/code&gt;. As a result, the repo and issue tracker for typescript-go will eventually be closed, so treat discussions/issues accordingly.&lt;/p&gt; 
&lt;p&gt;For a list of intentional changes with respect to TypeScript 5.9, see CHANGES.md.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;Contributor License Agreements&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>autobrr/qui</title>
      <link>https://github.com/autobrr/qui</link>
      <description>&lt;p&gt;A fast, single-binary qBittorrent web UI: manage multiple instances, automate torrent workflows, and cross-seed across trackers. Go + React.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;qui&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The README for the latest version can be found here: &lt;a href="https://github.com/autobrr/qui/raw/v1.11.0/README.md"&gt;v1.11.0&lt;/a&gt; Everything below this line is not yet in a tagged release.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A fast, modern web interface for qBittorrent. Supports managing multiple qBittorrent instances from a single, lightweight application.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/autobrr/qui/develop/.github/assets/qui.png" alt="qui" width="100%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Full documentation available at &lt;strong&gt;&lt;a href="https://getqui.com"&gt;getqui.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Linux x86_64&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and extract the latest release
wget $(curl -s https://api.github.com/repos/autobrr/qui/releases/latest | grep browser_download_url | grep linux_x86_64 | cut -d\" -f4)
tar -C /usr/local/bin -xzf qui*.tar.gz

# Run
./qui serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The web interface will be available at &lt;a href="http://localhost:7476"&gt;http://localhost:7476&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  -p 7476:7476 \
  -v $(pwd)/config:/config \
  ghcr.io/autobrr/qui:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Single Binary&lt;/strong&gt;: No dependencies, just download and run&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Instance Support&lt;/strong&gt;: Manage all your qBittorrent instances from one place&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast &amp;amp; Responsive&lt;/strong&gt;: Optimized for performance with large torrent collections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Seed&lt;/strong&gt;: Automatically find and add matching torrents across trackers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automations&lt;/strong&gt;: Rule-based torrent management with conditions and actions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backups &amp;amp; Restore&lt;/strong&gt;: Scheduled snapshots with multiple restore modes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reverse Proxy&lt;/strong&gt;: Transparent qBittorrent proxy for external apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our community on &lt;a href="https://discord.autobrr.com/qui"&gt;Discord&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/autobrr/qui/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;GPL-2.0-or-later&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>psviderski/uncloud</title>
      <link>https://github.com/psviderski/uncloud</link>
      <description>&lt;p&gt;A lightweight tool for deploying and managing containerised applications across a network of Docker hosts. Bridging the gap between Docker and Kubernetes ✨&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/psviderski/uncloud/main/website/landing/images/logo-title.svg#gh-light-mode-only" alt="Uncloud logo" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/psviderski/uncloud/main/website/landing/images/logo-title-dark.svg#gh-dark-mode-only" alt="Uncloud logo" /&gt; 
 &lt;p&gt;&lt;strong&gt;▸ Docker simplicity. Multi-machine power ◂&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://uncloud.run/docs"&gt;&lt;img src="https://img.shields.io/badge/Docs-blue.svg?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/eR35KQJhPu"&gt;&lt;img src="https://img.shields.io/badge/discord-5865F2.svg?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Join Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/psviderski"&gt;&lt;img src="https://img.shields.io/badge/follow-black?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=while" alt="Follow on X" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/psviderski"&gt;&lt;img src="https://img.shields.io/badge/Donate-EA4AAA.svg?style=for-the-badge&amp;amp;logo=githubsponsors&amp;amp;logoColor=white" alt="Donate" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Uncloud is a lightweight clustering and container orchestration tool that lets you deploy and manage web apps across cloud VMs and bare metal with minimised cluster management overhead. It creates a secure WireGuard mesh network between your Docker hosts and provides automatic service discovery, load balancing, ingress with HTTPS, and simple CLI commands to manage your apps.&lt;/p&gt; 
&lt;p&gt;Unlike traditional orchestrators, there's no central control plane and quorum to maintain. Each machine maintains a synchronised copy of the cluster state through peer-to-peer communication, keeping cluster operations functional even if some machines go offline.&lt;/p&gt; 
&lt;p&gt;Uncloud is the solution for developers who want the flexibility of self-hosted infrastructure without the operational complexity of Kubernetes.&lt;/p&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Deploy anywhere&lt;/strong&gt;: Combine cloud VMs, dedicated servers, and bare metal into a unified computing environment, regardless of location or provider.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;: Familiar &lt;a href="https://compose-spec.io/"&gt;Docker Compose&lt;/a&gt; format for defining services and volumes. No need to learn a new bespoke DSL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-downtime deployments&lt;/strong&gt;: Rolling updates without service interruption. Automatic rollback on failure is coming soon.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/psviderski/unregistry"&gt;Unregistry&lt;/a&gt; integration&lt;/strong&gt;: Build and push your Docker images directly to your machines without an external registry. It will transfer only the missing layers, making it fast and efficient.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Service discovery&lt;/strong&gt;: Built-in DNS server resolves service names to container IPs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistent storage&lt;/strong&gt;: Run stateful services with Docker volumes managed across machines.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-config private network&lt;/strong&gt;: Automatic WireGuard mesh with peer discovery and NAT traversal. Containers get unique IPs for direct cross-machine communication.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No control plane&lt;/strong&gt;: Fully decentralised design eliminates single points of failure and reduces operational overhead.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Imperative over declarative&lt;/strong&gt;: Favoring imperative operations over state reconciliation simplifies both the mental model and troubleshooting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Managed DNS&lt;/strong&gt;: Automatic DNS records &lt;code&gt;*.xxxxxx.uncld.dev&lt;/code&gt; for services with public access via managed &lt;a href="https://github.com/psviderski/uncloud-dns"&gt;Uncloud DNS&lt;/a&gt; service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic HTTPS&lt;/strong&gt;: Built-in Caddy reverse proxy handles TLS certificate provisioning and renewal using Let's Encrypt.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker-like CLI&lt;/strong&gt;: Familiar commands for managing both infrastructure and applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote management&lt;/strong&gt;: Control your entire infrastructure through SSH access to any single machine in the cluster.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎬 Quick demo&lt;/h2&gt; 
&lt;p&gt;The screenshot below demonstrates how I use Uncloud to deploy &lt;a href="https://uncloud.run"&gt;https://uncloud.run&lt;/a&gt; website to 2 remote machines from the &lt;a href="https://raw.githubusercontent.com/psviderski/uncloud/main/website/compose.yaml"&gt;&lt;code&gt;compose.yaml&lt;/code&gt;&lt;/a&gt; file on my local machine.&lt;/p&gt; 
&lt;p&gt;It exposes the container port &lt;code&gt;8000/tcp&lt;/code&gt; as HTTPS on the domain &lt;code&gt;uncloud.run&lt;/code&gt;, served by the Caddy reverse proxy on the remote machines. All managed by Uncloud.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/psviderski/uncloud/main/.github/images/compose-deploy.jpg" alt="Uncloud compose deployment demo" /&gt;&lt;/p&gt; 
&lt;p&gt;Here is a more advanced use case. Deploy a highly available web app with automatic HTTPS across multiple regions and on-premises in just a couple minutes.&lt;/p&gt; 
&lt;a href="https://uncloud.wistia.com/medias/k47uwt9uau?wvideo=k47uwt9uau"&gt; &lt;img src="https://embed-ssl.wistia.com/deliveries/3cf7014a48b93afc556444bed3e39a8c.jpg?image_crop_resized=900x526&amp;amp;image_play_button_rounded=true&amp;amp;image_play_button_size=2x&amp;amp;image_play_button_color=18181Be0" alt="Uncloud demo" width="450" height="263" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;📚 Want more examples?&lt;/strong&gt; Check out the &lt;a href="https://github.com/psviderski/uncloud-recipes"&gt;&lt;strong&gt;uncloud-recipes&lt;/strong&gt;&lt;/a&gt; repository for community recipes and templates for deploying popular services on Uncloud.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;💫 Why Uncloud?&lt;/h2&gt; 
&lt;p&gt;Modern cloud platforms like Heroku and Render offer amazing developer experiences but at a premium price. Traditional container orchestrators like Kubernetes provide power and flexibility but require significant operational expertise. I believe there's a sweet spot in between — a pragmatic solution for the majority of us who aren't running at Google scale. You should be able to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Own your infrastructure and data&lt;/strong&gt;: Whether driven by costs, compliance, or flexibility, run applications on any combination of cloud VMs and personal hardware while controlling your data and maintaining the cloud-like experience you love.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stay simple as you grow&lt;/strong&gt;: Start with a single machine and add more whenever you need without changing your workflow. No worrying about highly-available control planes or complex YAML configurations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build with proven primitives&lt;/strong&gt;: Get production-grade networking, deployment primitives, service discovery, load balancing, and ingress with HTTPS out of the box without becoming a distributed systems expert.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support sustainable computing&lt;/strong&gt; 🌿: Minimise system overhead to maximise resources available for your applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Uncloud's goal is to make deployment and management of containerised applications feel as seamless as using a cloud platform, whether you're running on a $5 VPS, a spare Mac mini, or a rack of bare metal servers.&lt;/p&gt; 
&lt;h2&gt;🚀 Quick start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install Uncloud CLI:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;brew install psviderski/tap/uncloud

# or using curl (macOS/Linux)
curl -fsS https://get.uncloud.run/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;See &lt;a href="https://uncloud.run/docs/getting-started/install-cli"&gt;Installation&lt;/a&gt; for more options.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Initialise your first machine:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uc machine init root@your-server-ip
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Deploy your app from a Docker image and publish its container port 8000 as HTTPS using &lt;code&gt;app.example.com&lt;/code&gt; domain:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uc run -p app.example.com:8000/https image/my-app
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a DNS A record in your DNS provider (Cloudflare, Namecheap, etc.) that points &lt;code&gt;app.example.com&lt;/code&gt; to your server's IP address. Allow a few minutes for DNS propagation.&lt;/p&gt; &lt;p&gt;That's it! Your app is now running and accessible at &lt;a href="https://app.example.com"&gt;https://app.example.com&lt;/a&gt; ✨&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clean up when you're done:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uc ls
# Copy the service name from the output and run the rm command:
uc rm my-app-name
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you want to fully uninstall Uncloud on a machine, run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uncloud-uninstall
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;View the &lt;a href="https://uncloud.run/docs"&gt;Documentation&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;⚙️ How it works&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://raw.githubusercontent.com/psviderski/uncloud/main/misc/design.md"&gt;design document&lt;/a&gt; to understand Uncloud's design philosophy and goals.&lt;/p&gt; 
&lt;p&gt;Here is a diagram of an Uncloud multi-provider cluster of 3 machines:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/psviderski/uncloud/main/website/landing/images/diagram.webp" alt="Diagram: multi-provider cluster of 3 machines" /&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Peek under the hood to see what happens when you run certain commands.&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;When you initialise a new cluster on a machine:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;$ uc machine init --name oracle-vm ubuntu@152.67.101.197

Downloading Uncloud install script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/install.sh
⏳ Running Uncloud install script...
✓ Docker is already installed.
⏳ Installing Docker...
...
✓ Docker installed successfully.
✓ Linux user and group 'uncloud' created.
✓ Linux user 'ubuntu' added to group 'uncloud'.
⏳ Installing Uncloud binaries...
⏳ Downloading uncloudd binary: https://github.com/psviderski/uncloud/releases/latest/download/uncloudd_linux_arm64.tar.gz
✓ uncloudd binary installed: /usr/local/bin/uncloudd
⏳ Downloading uninstall script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/uninstall.sh
✓ uncloud-uninstall script installed: /usr/local/bin/uncloud-uninstall
✓ Systemd unit file created: /etc/systemd/system/uncloud.service
Created symlink /etc/systemd/system/multi-user.target.wants/uncloud.service → /etc/systemd/system/uncloud.service.
⏳ Downloading uncloud-corrosion binary: https://github.com/psviderski/corrosion/releases/latest/download/corrosion-aarch64-unknown-linux-gnu.tar.gz
✓ uncloud-corrosion binary installed: /usr/local/bin/uncloud-corrosion
✓ Systemd unit file created: /etc/systemd/system/uncloud-corrosion.service
⏳ Starting Uncloud machine daemon (uncloud.service)...
✓ Uncloud machine daemon started.
✓ Uncloud installed on the machine successfully! 🎉
Cluster "default" initialised with machine "oracle-vm"
Waiting for the machine to be ready...

Reserved cluster domain: xuw3xd.cluster.uncloud.run
[+] Deploying service caddy 1/1
 ✔ Container caddy-c47x on oracle-vm  Started                                                                                                                                          0.9s

Updating cluster domain records in Uncloud DNS to point to machines running caddy service...
[+] Verifying internet access to caddy service 1/1
 ✔ Machine oracle-vm (152.67.101.197)  Reachable                                                                                                                                       0.1s

DNS records updated to use only the internet-reachable machines running caddy service:
  *.xuw3xd.cluster.uncloud.run  A → 152.67.101.197
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol&gt; 
  &lt;li&gt;The CLI SSHs into the machine and installs Docker, the &lt;code&gt;uncloudd&lt;/code&gt; machine daemon and &lt;a href="https://github.com/superfly/corrosion"&gt;corrosion&lt;/a&gt; service, managed by systemd.&lt;/li&gt; 
  &lt;li&gt;Generates a unique WireGuard key pair, allocates a dedicated subnet &lt;code&gt;10.210.0.0/24&lt;/code&gt; for the machine and its containers, and configures &lt;code&gt;uncloudd&lt;/code&gt; accordingly. All subsequent communication happens with &lt;code&gt;uncloudd&lt;/code&gt; through its gRPC API over SSH.&lt;/li&gt; 
  &lt;li&gt;Configures and starts &lt;code&gt;corrosion&lt;/code&gt;, a CRDT-based distributed SQLite database to share cluster state between machines.&lt;/li&gt; 
  &lt;li&gt;Creates a Docker bridge network connected to the WireGuard interface.&lt;/li&gt; 
  &lt;li&gt;This machine becomes an entry point for the newly created cluster which is stored in the cluster config under &lt;code&gt;~/.config/uncloud&lt;/code&gt; on your local machine.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;When you add another machine:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;$ uc machine add --name hetzner-server root@5.223.45.199
Downloading Uncloud install script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/install.sh
⏳ Running Uncloud install script...
✓ Docker is already installed.
✓ Linux user and group 'uncloud' created.
⏳ Installing Uncloud binaries...
⏳ Downloading uncloudd binary: https://github.com/psviderski/uncloud/releases/latest/download/uncloudd_linux_amd64.tar.gz
✓ uncloudd binary installed: /usr/local/bin/uncloudd
⏳ Downloading uninstall script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/uninstall.sh
✓ uncloud-uninstall script installed: /usr/local/bin/uncloud-uninstall
✓ Systemd unit file created: /etc/systemd/system/uncloud.service
Created symlink /etc/systemd/system/multi-user.target.wants/uncloud.service → /etc/systemd/system/uncloud.service.
⏳ Downloading uncloud-corrosion binary: https://github.com/psviderski/corrosion/releases/latest/download/corrosion-x86_64-unknown-linux-gnu.tar.gz
✓ uncloud-corrosion binary installed: /usr/local/bin/uncloud-corrosion
✓ Systemd unit file created: /etc/systemd/system/uncloud-corrosion.service
⏳ Starting Uncloud machine daemon (uncloud.service)...
✓ Uncloud machine daemon started.
✓ Uncloud installed on the machine successfully! 🎉
Machine "hetzner-server" added to cluster
Waiting for the machine to be ready...

[+] Deploying service caddy 1/1
 ✔ Container caddy-d36c on hetzner-server  Started                                                                                                                                     1.0s

Updating cluster domain records in Uncloud DNS to point to machines running caddy service...
[+] Verifying internet access to caddy service 2/2
 ✔ Machine hetzner-server (5.223.45.199)  Reachable                                                                                                                                    0.2s
 ✔ Machine oracle-vm (152.67.101.197)     Reachable                                                                                                                                    0.1s

DNS records updated to use only the internet-reachable machines running caddy service:
  *.xuw3xd.cluster.uncloud.run  A → 152.67.101.197, 5.223.45.199

$ uc machine ls
NAME             STATE   ADDRESS         PUBLIC IP        WIREGUARD ENDPOINTS
oracle-vm        Up      10.210.0.1/24   152.67.101.197   10.0.0.95:51820, 152.67.101.197:51820
hetzner-server   Up      10.210.1.1/24   5.223.45.199     5.223.45.199:51820, [2a01:4ff:2f0:128b::1]:51820
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol&gt; 
  &lt;li&gt;The second machine gets provisioned just like the first. A non-root SSH user will need &lt;code&gt;sudo&lt;/code&gt; access.&lt;/li&gt; 
  &lt;li&gt;Allocates a new subnet &lt;code&gt;10.210.1.0/24&lt;/code&gt; for the second machine and its containers.&lt;/li&gt; 
  &lt;li&gt;Registers the second machine in the cluster state and exchanges WireGuard keys with the first machine.&lt;/li&gt; 
  &lt;li&gt;Both machines establish a WireGuard tunnel between each other, allowing Docker containers connected to the bridge network to communicate directly across machines.&lt;/li&gt; 
  &lt;li&gt;Configures and starts &lt;code&gt;corrosion&lt;/code&gt; on the second machine to sync the cluster state.&lt;/li&gt; 
  &lt;li&gt;The second machine is added as an alternative entry point in the cluster config.&lt;/li&gt; 
  &lt;li&gt;If one of the machines goes offline, the other machine can still serve cluster operations.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;If one more machine is added, the process repeats with a new subnet. The new machine needs to establish a WireGuard connection with only one of the existing machines. Other machines will learn about it through the shared cluster state and automatically establish a WireGuard tunnel with it.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;When you run a service:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;$ uc run -p app.example.com:8000/https image/my-app

[+] Running service my-app-1b3b (replicated mode) 1/1
 ✔ Container my-app-1b3b-tcex on oracle-vm  Started

my-app-1b3b endpoints:
 • https://app.example.com → :8000
 • https://my-app-1b3b.xuw3xd.cluster.uncloud.run → :8000
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol&gt; 
  &lt;li&gt;CLI picks a machine to run your container.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;uncloudd&lt;/code&gt; that the CLI communicates with uses &lt;a href="https://github.com/siderolabs/grpc-proxy"&gt;&lt;code&gt;grpc-proxy&lt;/code&gt;&lt;/a&gt; to forward the request to the target machine to launch a container there.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;uncloudd&lt;/code&gt; on the target machine starts the Docker container in the bridge network and stores its info in the cluster's distributed state.&lt;/li&gt; 
  &lt;li&gt;The container gets a cluster-unique IP address from the bridge network (in the &lt;code&gt;10.210.X.2-254&lt;/code&gt; range) and becomes accessible from other machines in the cluster.&lt;/li&gt; 
  &lt;li&gt;Caddy reverse proxy which runs in &lt;a href="https://github.com/compose-spec/compose-spec/raw/main/deploy.md#mode"&gt;&lt;code&gt;global&lt;/code&gt;&lt;/a&gt; mode on each machine watches the cluster state for new services and updates its configuration to route traffic to the new container.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Look ma, no control plane or master nodes to maintain! Just a simple overlay network and eventually consistent state sync that lets machines work together. Want to check on things or make changes? Connect to any machine either implicitly using the CLI or directly over SSH. They all have the complete cluster state and can control everything. It's like each machine is a full backup of your control plane.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;🧪 Interactive tutorials&lt;/h2&gt; 
&lt;p&gt;To give you a chance to play with Uncloud without even leaving your browser, we're providing interactive tutorials and playgrounds on the &lt;a href="https://labs.iximiuz.com/"&gt;iximiuz Labs&lt;/a&gt; platform.&lt;/p&gt; 
&lt;p&gt;Available tutorials:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://labs.iximiuz.com/tutorials/uncloud-create-cluster-ebebf72b"&gt;Setting up a new Uncloud cluster&lt;/a&gt; - the tutorial walks you through creating a new cluster with two machines and then deploying a simple web service to it.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You can also launch the &lt;a href="https://labs.iximiuz.com/playgrounds/uncloud-cluster-64523f7c"&gt;Uncloud playground&lt;/a&gt; where you can play with an already initialized Uncloud cluster.&lt;/p&gt; 
&lt;h2&gt;🏗 Project status&lt;/h2&gt; 
&lt;p&gt;Uncloud is currently in active development and is &lt;strong&gt;not ready for production use&lt;/strong&gt;. Features may change significantly and there may be breaking changes between releases.&lt;/p&gt; 
&lt;p&gt;We'd love your input! Here's how you can contribute:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🐛 Found a bug? &lt;a href="https://github.com/psviderski/uncloud/issues"&gt;Open an issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💡 Have questions, ideas, or need help? 
  &lt;ul&gt; 
   &lt;li&gt;Start a discussion or join an existing one in the &lt;a href="https://github.com/psviderski/uncloud/discussions"&gt;Discussions&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Join our &lt;a href="https://discord.gg/eR35KQJhPu"&gt;Discord community&lt;/a&gt; where we discuss features, roadmap, implementation details, and help each other out.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🙏 Inspiration &amp;amp; Acknowledgements&lt;/h2&gt; 
&lt;p&gt;I'm grateful to the following projects that inspired Uncloud's design and implementation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kamal-deploy.org/"&gt;Kamal&lt;/a&gt; — for proving that even in the declarative era of Kubernetes there is a place for simple deployment tools that use imperative commands without complex orchestration. Kamal powers the multi-billion dollar company &lt;a href="https://37signals.com/"&gt;37signals&lt;/a&gt; where it was created, and that's truly inspiring!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fly.io/"&gt;Fly.io&lt;/a&gt; — for inspiring my vision for what self-hosted infrastructure should feel like, proving that developer experience and powerful infrastructure can coexist beautifully.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tailscale.com/"&gt;Tailscale&lt;/a&gt; — for pioneering the vision of decentralised flat mesh networking with an amazing user experience that feels like magic.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siderolabs/talos"&gt;Talos Linux&lt;/a&gt; and &lt;a href="https://www.talos.dev/v1.10/talos-guides/network/kubespan/"&gt;KubeSpan&lt;/a&gt; — for the machine API design using &lt;a href="https://github.com/siderolabs/grpc-proxy"&gt;grpc-proxy&lt;/a&gt; and for its elegant approach to secure WireGuard-based overlay networking with zero configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/docker-archive/classicswarm"&gt;Docker Swarm Classic&lt;/a&gt; and &lt;a href="http://rancher-com-website-main-elb-elb-1798790864.us-west-2.elb.amazonaws.com/docs/rancher/v1.6/en/"&gt;Rancher 1.x&lt;/a&gt; — for showing the power of simplicity and pragmatism in container orchestration and that not every problem needs the complexity of Kubernetes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Special thanks to the &lt;a href="https://github.com/superfly/corrosion"&gt;Corrosion&lt;/a&gt; project by Fly.io for providing the distributed SQLite database used to share Uncloud's cluster state.&lt;/p&gt; 
&lt;h2&gt;📫 Stay updated&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join our &lt;a href="https://discord.gg/eR35KQJhPu"&gt;Discord server&lt;/a&gt; for real-time discussions, support, and updates.&lt;/li&gt; 
 &lt;li&gt;Follow &lt;a href="https://x.com/psviderski"&gt;@psviderski&lt;/a&gt; on X/Twitter.&lt;/li&gt; 
 &lt;li&gt;Subscribe to &lt;a href="https://uncloud.run/#subscribe"&gt;my newsletter&lt;/a&gt; to follow the progress, get early insights into new features, and be the first to know when it's ready for production use.&lt;/li&gt; 
 &lt;li&gt;Watch this repository for releases.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;💖 Sponsors&lt;/h2&gt; 
&lt;p&gt;These companies and projects are helping Uncloud with their generous sponsorship and/or services:&lt;/p&gt; 
&lt;!-- Sentry --&gt; 
&lt;a href="https://sentry.io/welcome/"&gt; &lt;img height="100" alt="Sentry" src="https://github.com/user-attachments/assets/6c1439c0-d20d-40dc-a669-c9aa94651dfa" /&gt; &lt;/a&gt; 
&lt;h2&gt;❤️ Contributors&lt;/h2&gt; 
&lt;a href="https://trendshift.io/repositories/14069"&gt; &lt;img alt="Trendshift" src="https://trendshift.io/api/badge/repositories/14069" /&gt; &lt;/a&gt; 
&lt;p&gt;Thank you &lt;a href="https://github.com/cedws"&gt;@cedws&lt;/a&gt; for being the first contributor to Uncloud! 🎉&lt;/p&gt; 
&lt;a href="https://github.com/psviderski/uncloud/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=psviderski/uncloud" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>v2fly/domain-list-community</title>
      <link>https://github.com/v2fly/domain-list-community</link>
      <description>&lt;p&gt;Community managed domain list. Generate geosite.dat for V2Ray.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Domain list community&lt;/h1&gt; 
&lt;p&gt;This project manages a list of domains, to be used as geosites for routing purpose in Project V.&lt;/p&gt; 
&lt;h2&gt;Purpose of this project&lt;/h2&gt; 
&lt;p&gt;This project is not opinionated. In other words, it does NOT endorse, claim or imply that a domain should be blocked or proxied. It can be used to generate routing rules on demand.&lt;/p&gt; 
&lt;h2&gt;Download links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;dlc.dat&lt;/strong&gt;：&lt;a href="https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat"&gt;https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;dlc.dat.sha256sum&lt;/strong&gt;：&lt;a href="https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum"&gt;https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage example&lt;/h2&gt; 
&lt;p&gt;Each file in the &lt;code&gt;data&lt;/code&gt; directory can be used as a rule in this format: &lt;code&gt;geosite:filename&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"routing": {
  "domainStrategy": "IPIfNonMatch",
  "rules": [
    {
      "type": "field",
      "outboundTag": "Reject",
      "domain": [
        "geosite:category-ads-all",
        "geosite:category-porn"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Direct",
      "domain": [
        "domain:icloud.com",
        "domain:icloud-content.com",
        "domain:cdn-apple.com",
        "geosite:cn",
        "geosite:private"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-1",
      "domain": [
        "geosite:category-anticensorship",
        "geosite:category-media",
        "geosite:category-vpnservices"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-2",
      "domain": [
        "geosite:category-dev"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-3",
      "domain": [
        "geosite:geolocation-!cn"
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Generate &lt;code&gt;dlc.dat&lt;/code&gt; manually&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;golang&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Clone project code: &lt;code&gt;git clone https://github.com/v2fly/domain-list-community.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Navigate to project root directory: &lt;code&gt;cd domain-list-community&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install project dependencies: &lt;code&gt;go mod download&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Generate &lt;code&gt;dlc.dat&lt;/code&gt; (without &lt;code&gt;datapath&lt;/code&gt; option means to use domain lists in &lt;code&gt;data&lt;/code&gt; directory of current working directory): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;go run ./&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;go run ./ --datapath=/path/to/your/custom/data/directory&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run &lt;code&gt;go run ./ --help&lt;/code&gt; for more usage information.&lt;/p&gt; 
&lt;h2&gt;Structure of data&lt;/h2&gt; 
&lt;p&gt;All data are under &lt;code&gt;data&lt;/code&gt; directory. Each file in the directory represents a sub-list of domains, named by the file name. File content is in the following format.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# comments
include:another-file
domain:google.com @attr1 @attr2
keyword:google
regexp:www\.google\.com$
full:www.google.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Syntax:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following types of rules are &lt;strong&gt;NOT&lt;/strong&gt; fully compatible with the ones that defined by user in V2Ray config file. Do &lt;strong&gt;Not&lt;/strong&gt; copy and paste directly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Comment begins with &lt;code&gt;#&lt;/code&gt;. It may begin anywhere in the file. The content in the line after &lt;code&gt;#&lt;/code&gt; is treated as comment and ignored in production.&lt;/li&gt; 
 &lt;li&gt;Inclusion begins with &lt;code&gt;include:&lt;/code&gt;, followed by the file name of an existing file in the same directory.&lt;/li&gt; 
 &lt;li&gt;Subdomain begins with &lt;code&gt;domain:&lt;/code&gt;, followed by a valid domain name. The prefix &lt;code&gt;domain:&lt;/code&gt; may be omitted.&lt;/li&gt; 
 &lt;li&gt;Keyword begins with &lt;code&gt;keyword:&lt;/code&gt;, followed by a string.&lt;/li&gt; 
 &lt;li&gt;Regular expression begins with &lt;code&gt;regexp:&lt;/code&gt;, followed by a valid regular expression (per Golang's standard).&lt;/li&gt; 
 &lt;li&gt;Full domain begins with &lt;code&gt;full:&lt;/code&gt;, followed by a complete and valid domain name.&lt;/li&gt; 
 &lt;li&gt;Domains (including &lt;code&gt;domain&lt;/code&gt;, &lt;code&gt;keyword&lt;/code&gt;, &lt;code&gt;regexp&lt;/code&gt; and &lt;code&gt;full&lt;/code&gt;) may have one or more attributes. Each attribute begins with &lt;code&gt;@&lt;/code&gt; and followed by the name of the attribute.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Adding new &lt;code&gt;regexp&lt;/code&gt; and &lt;code&gt;keyword&lt;/code&gt; rules is discouraged because it is easy to use them incorrectly, and proxy software cannot efficiently match these types of rules.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;How it works&lt;/h2&gt; 
&lt;p&gt;The entire &lt;code&gt;data&lt;/code&gt; directory will be built into an external &lt;code&gt;geosite&lt;/code&gt; file for Project V. Each file in the directory represents a section in the generated file.&lt;/p&gt; 
&lt;p&gt;To generate a section:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Remove all the comments in the file.&lt;/li&gt; 
 &lt;li&gt;Replace &lt;code&gt;include:&lt;/code&gt; lines with the actual content of the file.&lt;/li&gt; 
 &lt;li&gt;Omit all empty lines.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;domain:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L21"&gt;sub-domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;full:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L23"&gt;full domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;keyword:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L17"&gt;plain domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;regexp:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L19"&gt;regex domain routing rule&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;How to organize domains&lt;/h2&gt; 
&lt;h3&gt;File name&lt;/h3&gt; 
&lt;p&gt;Theoretically any string can be used as the name, as long as it is a valid file name. In practice, we prefer names for determinic group of domains, such as the owner (usually a company name) of the domains, e.g., "google", "netflix". Names with unclear scope are generally unrecommended, such as "evil", or "local".&lt;/p&gt; 
&lt;h3&gt;Attributes&lt;/h3&gt; 
&lt;p&gt;Attribute is useful for sub-group of domains, especially for filtering purpose. For example, the list of &lt;code&gt;google&lt;/code&gt; domains may contains its main domains, as well as domains that serve ads. The ads domains may be marked by attribute &lt;code&gt;@ads&lt;/code&gt;, and can be used as &lt;code&gt;geosite:google@ads&lt;/code&gt; in V2Ray routing.&lt;/p&gt; 
&lt;h2&gt;Contribution guideline&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fork this repo, make modifications to your own repo, file a PR.&lt;/li&gt; 
 &lt;li&gt;Please begin with small size PRs, say modification in a single file.&lt;/li&gt; 
 &lt;li&gt;A PR must be reviewed and approved by another member.&lt;/li&gt; 
 &lt;li&gt;A script will verify your pull request to test whether your PR is correct or not every time you update the PR. Only the PR which passes the test will be merged. Please go to the Action label to get detailed information if you didn't pass it. We also provide the file which has been generated to make you test.&lt;/li&gt; 
 &lt;li&gt;After a few successful PRs, you may apply for manager access to this repository.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>SagerNet/sing-box</title>
      <link>https://github.com/SagerNet/sing-box</link>
      <description>&lt;p&gt;The universal proxy platform&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;Sponsored by &lt;a href="https://go.warp.dev/sing-box"&gt;Warp&lt;/a&gt;, built for coding with multiple AI agents&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a href="https://go.warp.dev/sing-box"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/warpdotdev/brand-assets/raw/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;h1&gt;sing-box&lt;/h1&gt; 
&lt;p&gt;The universal proxy platform.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/sing-box/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/sing-box.svg?sanitize=true" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://sing-box.sagernet.org"&gt;https://sing-box.sagernet.org&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (C) 2022 by nekohasekai &amp;lt;contact-sagernet@sekai.icu&amp;gt;

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see &amp;lt;http://www.gnu.org/licenses/&amp;gt;.

In addition, no derivative work may use the name or imply association
with this application without prior consent.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>simulot/immich-go</title>
      <link>https://github.com/simulot/immich-go</link>
      <description>&lt;p&gt;An alternative to the immich-CLI command that doesn't depend on nodejs installation. It tries its best for importing google photos takeout archives.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Immich-Go: Upload Your Photos to Your Immich Server&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Immich-Go&lt;/strong&gt; is an open-source tool designed to streamline uploading large photo collections to your self-hosted Immich server.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⚠️ This is an early version, not yet extensively tested&lt;br /&gt; ⚠️ Keep a backup copy of your files for safety&lt;br /&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;🌟 Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Simple Installation&lt;/strong&gt;: No NodeJS or Docker required&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Sources&lt;/strong&gt;: Upload from Google Photos Takeouts, iCloud, local folders, ZIP archives, and other Immich servers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Large Collections&lt;/strong&gt;: Successfully handles 100,000+ photos&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Management&lt;/strong&gt;: Duplicate detection, burst photo stacking, RAW+JPEG handling&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Platform&lt;/strong&gt;: Available for Windows, macOS, Linux, and FreeBSD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Install Immich-Go&lt;/h3&gt; 
&lt;p&gt;Download the pre-built binary for your system from the &lt;a href="https://github.com/simulot/immich-go/releases"&gt;GitHub releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;2. Basic Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Upload photos from a local folder
immich-go upload from-folder --server=http://your-ip:2283 --api-key=your-api-key /path/to/your/photos

# Upload Google Photos takeout
immich-go upload from-google-photos --server=http://your-ip:2283 --api-key=your-api-key /path/to/takeout-*.zip

# Archive photos from Immich server
immich-go archive from-immich --server=http://your-ip:2283 --api-key=your-api-key --write-to-folder=/path/to/archive
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;A running Immich server with API access&lt;/li&gt; 
 &lt;li&gt;API key with appropriate permissions (&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/installation.md#api-permissions"&gt;see full list&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⚠️ &lt;strong&gt;Breaking Change&lt;/strong&gt;: API keys must now include the &lt;code&gt;asset.copy&lt;/code&gt; and &lt;code&gt;asset.delete&lt;/code&gt; permissions in addition to previously required permissions. Please update your API keys accordingly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;🙈 Skip System Files&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;--ban-file&lt;/code&gt; to exclude junk artifacts. Patterns ending with &lt;code&gt;/&lt;/code&gt; apply to directories (for example, &lt;code&gt;--ban-file .Spotlight-V100/&lt;/code&gt;), while patterns without the trailing slash apply to individual files (for example, &lt;code&gt;--ban-file .DS_Store&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Immich-Go ships with sensible defaults that already skip common clutter such as &lt;code&gt;@eaDir/&lt;/code&gt;, &lt;code&gt;@__thumb/&lt;/code&gt;, &lt;code&gt;SYNOFILE_THUMB_*.*&lt;/code&gt;, &lt;code&gt;Lightroom Catalog/&lt;/code&gt;, &lt;code&gt;thumbnails/&lt;/code&gt;, &lt;code&gt;.DS_Store&lt;/code&gt;, &lt;code&gt;/._*&lt;/code&gt;, &lt;code&gt;.Spotlight-V100/&lt;/code&gt;, &lt;code&gt;.photostructure/&lt;/code&gt;, and &lt;code&gt;Recently Deleted/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Add additional patterns as needed to keep uploads focused on real photos. See the &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/technical.md#banned-files"&gt;banned files reference&lt;/a&gt; for details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📚 Documentation&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/installation.md"&gt;Installation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Detailed installation instructions for all platforms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/commands/"&gt;Commands&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Complete command reference and options&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/configuration.md"&gt;Configuration&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Configuration options and environment variables&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/examples.md"&gt;Examples&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Common use cases and practical examples&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/best-practices.md"&gt;Best Practices&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Tips for optimal performance and reliability&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/technical.md"&gt;Technical Details&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;File processing, metadata handling, and advanced features&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/upload-commands-overview.md"&gt;Upload Commands Overview&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;How &lt;code&gt;immich-go&lt;/code&gt; processes files from different sources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/releases/"&gt;Release Notes&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Version history and release notes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;✨ How immich-go Works&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;immich-go&lt;/code&gt; offers a versatile set of commands to handle your photo and video uploads. Whether you're uploading from a simple folder, migrating from a Google Photos Takeout, or transferring assets between Immich servers, the tool provides intelligent features to preserve your metadata and organization.&lt;/p&gt; 
&lt;p&gt;Here's a brief overview of the main upload commands:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-folder&lt;/code&gt;&lt;/strong&gt;: The basic command for uploading from any local folder. It can create albums from your directory structure and read XMP sidecar files.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-google-photos&lt;/code&gt;&lt;/strong&gt;: A powerful command to migrate from a Google Photos Takeout. It intelligently matches photos with their JSON metadata to preserve albums, descriptions, and locations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-immich&lt;/code&gt;&lt;/strong&gt;: A server-to-server migration tool that allows you to copy assets between two Immich instances with fine-grained filtering.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-picasa&lt;/code&gt;&lt;/strong&gt;: A specialized version of &lt;code&gt;from-folder&lt;/code&gt; that automatically reads &lt;code&gt;.picasa.ini&lt;/code&gt; files to restore your Picasa album organization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-icloud&lt;/code&gt;&lt;/strong&gt;: Another specialized command that handles the complexity of an iCloud Photos takeout, correctly identifying creation dates and album structures from the included CSV files.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Leveraging Immich's Features&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;immich-go&lt;/code&gt; is more than just an uploader; it intelligently interacts with the Immich server to preserve your library's structure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Albums and Tags&lt;/strong&gt;: Automatically creates albums and tags on the server to match your source organization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stacking&lt;/strong&gt;: Groups related images, like RAW+JPEG pairs or photo bursts, into stacks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Duplicate Detection&lt;/strong&gt;: Avoids re-uploading files that already exist on the server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Uploads&lt;/strong&gt;: Can pause Immich's background jobs (like thumbnailing) during an upload for better performance.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a detailed explanation of how each upload command works, please see the &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/upload-commands-overview.md"&gt;Upload Commands Overview&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🎯 Popular Use Cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Google Photos Migration&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/best-practices.md#google-photos-migration"&gt;Complete guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;iCloud Import&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/examples.md#icloud-import"&gt;Step-by-step instructions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server Migration&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/examples.md#server-migration"&gt;Transfer between Immich instances&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bulk Organization&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/best-practices.md#organization-strategies"&gt;Stacking and tagging strategies&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;💡 Support the Project&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sponsors/simulot"&gt;GitHub Sponsor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.paypal.com/donate/?hosted_button_id=VGU2SQE88T2T4"&gt;PayPal Donation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please see our &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the terms specified in the &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Need help?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/"&gt;documentation&lt;/a&gt; or open an issue on GitHub.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>heroiclabs/nakama</title>
      <link>https://github.com/heroiclabs/nakama</link>
      <description>&lt;p&gt;Distributed server for social and realtime games and apps.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://heroiclabs.com" target="_blank" rel="noopener"&gt; &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/nakama.png" alt="Nakama - Distributed server for social and realtime games and apps" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://heroiclabs.com/docs/nakama/getting-started/install/"&gt;&lt;img src="https://img.shields.io/github/release/heroiclabs/nakama.svg?colorA=18181B&amp;amp;colorB=825df2" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/heroiclabs/nakama"&gt;&lt;img src="https://img.shields.io/docker/pulls/heroiclabs/nakama?colorA=18181B&amp;amp;colorB=825df2&amp;amp;label=downloads" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/heroiclabs/nakama/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/heroiclabs/nakama.svg?colorA=18181B&amp;amp;colorB=825df2" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://forum.heroiclabs.com"&gt;&lt;img src="https://img.shields.io/badge/Nakama%20Forum-18181B?logo=discourse" alt="Nakama Forum" /&gt;&lt;/a&gt; &lt;a href="https://heroiclabs.com/docs"&gt;&lt;img src="https://img.shields.io/badge/Nakama%20Docs-18181B?logo=data:image/svg+xml;base64,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" alt="Nakama Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Users&lt;/strong&gt; - Register/login new users via social networks, email, or device ID.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt; - Store user records, settings, and other objects in collections.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Social&lt;/strong&gt; - Users can connect with friends, and join groups. Builtin social graph to see how users can be connected.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat&lt;/strong&gt; - 1-on-1, group, and global chat between users. Persist messages for chat history.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiplayer&lt;/strong&gt; - Realtime, or turn-based active and passive multiplayer.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leaderboards&lt;/strong&gt; - Dynamic, seasonal, get top members, or members around a user. Have as many as you need.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tournaments&lt;/strong&gt; - Invite players to compete together over prizes. Link many together to create leagues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parties&lt;/strong&gt; - Add team play to a game. Users can form a party and communicate with party members.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Purchase Validation&lt;/strong&gt; - Validate in-app purchases and subscriptions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;In-App Notifications&lt;/strong&gt; - Send messages and notifications to connected client sockets.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime code&lt;/strong&gt; - Extend the server with custom logic written in Lua, TypeScript/JavaScript, or native Go code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Matchmaker&lt;/strong&gt;, &lt;strong&gt;dashboard&lt;/strong&gt;, &lt;strong&gt;metrics&lt;/strong&gt;, and &lt;a href="https://heroiclabs.com/docs"&gt;more&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Build scalable games and apps with a production ready server used by ambitious game studios and app developers &lt;a href="https://heroiclabs.com/customers/"&gt;all around the world&lt;/a&gt;. Have a look at the &lt;a href="https://heroiclabs.com/docs"&gt;documentation&lt;/a&gt; and join the &lt;a href="https://forum.heroiclabs.com"&gt;developer community&lt;/a&gt; for more info.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;The server is simple to setup and run for local development and can be deployed to any cloud provider. See the &lt;a href="https://raw.githubusercontent.com/heroiclabs/nakama/master/#deployment"&gt;deployment notes&lt;/a&gt; for recommendations on how to deploy the project for production. Nakama server requires CockroachDB or another Postgres wire-compatible server as it's database.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://heroiclabs.com/docs/install-docker-quickstart/"&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/en/f/f4/Docker_logo.svg?sanitize=true" width="170" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The fastest way to run the server and the database is with Docker. Setup Docker and start the daemon.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Set up a &lt;a href="https://heroiclabs.com/docs/nakama/getting-started/install/docker/#running-nakama"&gt;docker-compose file&lt;/a&gt; and place it in a folder for your project.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run &lt;code&gt;docker-compose -f ./docker-compose.yml up&lt;/code&gt; to download container images and run the servers.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For more detailed instructions have a look at our &lt;a href="https://heroiclabs.com/docs/nakama/getting-started/install/docker"&gt;Docker quickstart&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;Nakama Docker images are maintained on &lt;a href="https://hub.docker.com/r/heroiclabs/nakama/tags"&gt;Docker Hub&lt;/a&gt; and &lt;a href="https://hub.docker.com/r/heroiclabs/nakama-prerelease/tags"&gt;prerelease&lt;/a&gt; images are occasionally published for cutting edge features of the server.&lt;/p&gt; 
&lt;h3&gt;Binaries&lt;/h3&gt; 
&lt;p&gt;You can run the servers with native binaries for your platform.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Download the server from our &lt;a href="https://github.com/heroiclabs/nakama/releases"&gt;releases&lt;/a&gt; page and the &lt;a href="https://www.cockroachlabs.com/docs/stable/install-cockroachdb.html"&gt;database&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Follow the database &lt;a href="https://www.cockroachlabs.com/docs/stable/start-a-local-cluster.html#before-you-begin"&gt;instructions&lt;/a&gt; to start it.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run a migration which will setup or upgrade the database schema:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;nakama migrate up --database.address "root@127.0.0.1:26257"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start Nakama and connect to the database:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;nakama --database.address "root@127.0.0.1:26257"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;When connected you'll see server output which describes all settings the server uses for &lt;a href="https://heroiclabs.com/docs/nakama/getting-started/configuration"&gt;configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;{"level":"info","ts":"2018-04-29T10:14:41.249+0100","msg":"Node","name":"nakama","version":"2.0.0+7e18b09","runtime":"go1.10.1","cpu":4} &lt;br /&gt; {"level":"info","ts":"2018-04-29T10:14:41.249+0100","msg":"Database connections","dsns":["root@127.0.0.1:26257"]} &lt;br /&gt; ...&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Nakama supports a variety of protocols optimized for various gameplay or app use cases. For request/response it can use GRPC or the HTTP1.1+JSON fallback (REST). For realtime communication you can use WebSockets or rUDP.&lt;/p&gt; 
&lt;p&gt;For example with the REST API to authenticate a user account with a device identifier.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl "127.0.0.1:7350/v2/account/authenticate/device?create=true" \
  --user "defaultkey:" \
  --data '{"id": "someuniqueidentifier"}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Response:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;{ &lt;br /&gt; "token":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1MjQ5OTU2NDksInVpZCI6Ijk5Y2Q1YzUyLWE5ODgtNGI2NC04YThhLTVmMTM5YTg4MTgxMiIsInVzbiI6InhBb1RxTUVSdFgifQ.-3_rXNYx3Q4jKuS7RkxeMWBzMNAm0vl93QxzRI8p_IY" &lt;br /&gt; }&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;There's a number of official &lt;a href="https://github.com/heroiclabs"&gt;client libraries&lt;/a&gt; available on GitHub with &lt;a href="https://heroiclabs.com/docs"&gt;documentation&lt;/a&gt;. The current platform/language support includes: .NET (in C#), Unity engine, JavaScript, Java (with Android), Unreal engine, Godot, Defold, and Swift (with iOS). If you'd like to contribute a client or request one let us know.&lt;/p&gt; 
&lt;h2&gt;Nakama Console&lt;/h2&gt; 
&lt;p&gt;The server provides a web UI which teams can use to inspect various data stored through the server APIs, view lightweight service metrics, manage player data, update storage objects, restrict access to production with permission profiles, and gain visibility into realtime features like active multiplayer matches. There is no separate installation required as it is embedded as part of the single server binary.&lt;/p&gt; 
&lt;p&gt;You can navigate to it on your browser on &lt;a href="http://127.0.0.1:7351"&gt;http://127.0.0.1:7351&lt;/a&gt;.&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;View Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/dashboard.png" alt="Nakama Console dashboard view" title="Dashboard view" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/players.png" alt="Nakama Console players view" title="Players view" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/api-explorer.png" alt="Nakama Console API explorer view" title="API explorer view" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/storage.png" alt="Nakama Console storage view" title="Storage object view" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/modules.png" alt="Nakama Console modules view" title="Runtime modules view" /&gt; 
&lt;/details&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;p&gt;Nakama can be deployed to any cloud provider such as Google Cloud, Azure, AWS, Digital Ocean, Heroku, or your own private cloud. You should setup and provision separate nodes for Nakama and CockroachDB.&lt;/p&gt; 
&lt;p&gt;The recommended minimum production infrastructure for CockroachDB is outlined in &lt;a href="https://www.cockroachlabs.com/docs/stable/recommended-production-settings.html#basic-hardware-recommendations"&gt;these docs&lt;/a&gt; and Nakama can be run on instance types as small as "g1-small" on Google Cloud although we recommend a minimum of "n1-standard-1" in production. The specific hardware requirements will depend on what features of the server are used. Reach out to us for help and advice on what servers to run.&lt;/p&gt; 
&lt;h3&gt;Heroic Cloud&lt;/h3&gt; 
&lt;p&gt;You can support development, new features, and maintainance of the server by using the Heroic Labs' &lt;a href="https://heroiclabs.com/heroic-cloud/"&gt;Heroic Cloud&lt;/a&gt; for deployment. This service handles the uptime, replication, backups, logs, data upgrades, and all other tasks involved with production server environments.&lt;/p&gt; 
&lt;p&gt;Have a look at our &lt;a href="https://heroiclabs.com/heroic-cloud/"&gt;Heroic Cloud&lt;/a&gt; service for more details.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;The development roadmap is managed as GitHub issues and pull requests are welcome. If you're interested to add a feature which is not mentioned on the issue tracker please open one to create a discussion or drop in and discuss it in the &lt;a href="https://forum.heroiclabs.com"&gt;community forum&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Simple Builds&lt;/h3&gt; 
&lt;p&gt;All dependencies required for a build are vendored as part of the Go project. We recommend a modern release of the Go toolchain and do not store the codebase in the old GOPATH.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Download the source tree.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git clone "https://github.com/heroiclabs/nakama" nakama
cd nakama
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the project from source.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;go build -trimpath -mod=vendor
./nakama --version
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Full Source Builds&lt;/h3&gt; 
&lt;p&gt;The codebase uses Protocol Buffers, GRPC, GRPC-Gateway, buf, and the OpenAPI spec as part of the project. These dependencies are generated as sources and committed to the repository to simplify builds for contributors.&lt;/p&gt; 
&lt;p&gt;To build the codebase and generate all sources follow these steps.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install the toolchain.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;go install \
    "google.golang.org/protobuf/cmd/protoc-gen-go" \
    "google.golang.org/grpc/cmd/protoc-gen-go-grpc" \
    "github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway" \
    "github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://buf.build/docs/cli/installation/"&gt;buf&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Re-generate the protocol buffers and gateway code.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;# Run the shell script:
./buf.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the codebase.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;go build -trimpath -mod=vendor
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;p&gt;In order to run all the unit and integration tests run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker-compose -f ./docker-compose-tests.yml up --build --abort-on-container-exit; docker-compose -f ./docker-compose-tests.yml down -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create an isolated environment with Nakama and database instances, run all the tests, and drop the environment afterwards.&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://github.com/heroiclabs/nakama/raw/master/LICENSE"&gt;Apache-2 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;a href="https://trendshift.io/repositories/15289" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15289" alt="Tencent%2FWeKnora | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="官方网站" src="https://img.shields.io/badge/官方网站-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="微信对话开放平台" src="https://img.shields.io/badge/微信对话开放平台-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.6-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;简体中文&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;日本語&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;💡 WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;📌 Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🤖 &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;📚 &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;⚙️ &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;🌐 &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;🔌 &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;🎨 &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;⚡ &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔒 Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🏗️ Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;🎯 Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🤖 Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔍 Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🧠 Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📚 Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔧 Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;⚡ Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🌐 Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔌 MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;⚙️ Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎯 User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔒 Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📊 Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🧩 Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;✅ ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;✅ FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;✅ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;✅ Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;✅ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;✅ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;✅ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;✅ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;✅ Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;✅ Extensible search engines, DuckDuckGo&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;✅ uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;✅ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;✅ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;✅ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;✅ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;✅ MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;h3&gt;🛠 Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📦 Installation&lt;/h3&gt; 
&lt;h4&gt;① Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;② Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;③ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;③.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;③.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;④ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;🌐 Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔌 Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔗 Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1️⃣ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2️⃣ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🔧 Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ①② and go directly to steps ③④.&lt;/p&gt; 
&lt;h3&gt;① Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;② Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;③ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;④ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;📱 Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;📘 API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/api/README.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🧭 Developer Guide&lt;/h2&gt; 
&lt;h3&gt;⚡ Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;✅ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;✅ No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;✅ Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;📁 Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
├── client/      # go client
├── cmd/         # Main entry point
├── config/      # Configuration files
├── docker/      # docker images files
├── docreader/   # Document parsing app
├── docs/        # Project documentation
├── frontend/    # Frontend app
├── internal/    # Core business logic
├── mcp-server/  # MCP server
├── migrations/  # DB migration scripts
└── scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;🎯 How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;🐛 &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;✨ &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;📚 &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;🧪 &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;🎨 &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📋 Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🎨 Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📝 Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;👥 Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;📈 Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>schollz/croc</title>
      <link>https://github.com/schollz/croc</link>
      <description>&lt;p&gt;Easily and securely send things from one computer to another 🐊 📦&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://user-images.githubusercontent.com/6550035/46709024-9b23ad00-cbf6-11e8-9fb2-ca8b20b7dbec.jpg" width="408px" border="0" alt="croc" /&gt; &lt;br /&gt; &lt;a href="https://github.com/schollz/croc/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/schollz/croc" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/schollz/croc/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/schollz/croc/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/schollz"&gt;&lt;img alt="GitHub Sponsors" src="https://img.shields.io/github/sponsors/schollz" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;This project’s future depends on community support. &lt;a href="https://github.com/sponsors/schollz"&gt;Become a sponsor today&lt;/a&gt;.&lt;/strong&gt; &lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;croc&lt;/code&gt; is a tool that allows any two computers to simply and securely transfer files and folders. AFAIK, &lt;em&gt;croc&lt;/em&gt; is the only CLI file-transfer tool that does &lt;strong&gt;all&lt;/strong&gt; of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Allows &lt;strong&gt;any two computers&lt;/strong&gt; to transfer data (using a relay)&lt;/li&gt; 
 &lt;li&gt;Provides &lt;strong&gt;end-to-end encryption&lt;/strong&gt; (using PAKE)&lt;/li&gt; 
 &lt;li&gt;Enables easy &lt;strong&gt;cross-platform&lt;/strong&gt; transfers (Windows, Linux, Mac)&lt;/li&gt; 
 &lt;li&gt;Allows &lt;strong&gt;multiple file&lt;/strong&gt; transfers&lt;/li&gt; 
 &lt;li&gt;Allows &lt;strong&gt;resuming transfers&lt;/strong&gt; that are interrupted&lt;/li&gt; 
 &lt;li&gt;No need for local server or port-forwarding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;IPv6-first&lt;/strong&gt; with IPv4 fallback&lt;/li&gt; 
 &lt;li&gt;Can &lt;strong&gt;use a proxy&lt;/strong&gt;, like Tor&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about &lt;code&gt;croc&lt;/code&gt;, see &lt;a href="https://schollz.com/tinker/croc6/"&gt;my blog post&lt;/a&gt; or read a &lt;a href="https://console.substack.com/p/console-91"&gt;recent interview I did&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/schollz/croc/main/src/install/customization.gif" alt="Example" /&gt;&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;You can download &lt;a href="https://github.com/schollz/croc/releases/latest"&gt;the latest release for your system&lt;/a&gt;, or install a release from the command-line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl https://getcroc.schollz.com | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On macOS&lt;/h3&gt; 
&lt;p&gt;Using &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Using &lt;a href="https://www.macports.org/"&gt;MacPorts&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo port selfupdate
sudo port install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Windows&lt;/h3&gt; 
&lt;p&gt;You can install the latest release with &lt;a href="https://scoop.sh/"&gt;Scoop&lt;/a&gt;, &lt;a href="https://chocolatey.org/"&gt;Chocolatey&lt;/a&gt;, or &lt;a href="https://learn.microsoft.com/windows/package-manager/"&gt;Winget&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;scoop install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;choco install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;winget install schollz.croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using nix-env&lt;/h3&gt; 
&lt;p&gt;You can install the latest release with &lt;a href="https://nixos.org/"&gt;Nix&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nix-env -i croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On NixOS&lt;/h3&gt; 
&lt;p&gt;You can add this to your &lt;a href="https://nixos.org/manual/nixos/stable/#ch-configuration"&gt;configuration.nix&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;environment.systemPackages = [
  pkgs.croc
];
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Alpine Linux&lt;/h3&gt; 
&lt;p&gt;First, install dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;apk add bash coreutils
wget -qO- https://getcroc.schollz.com | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Arch Linux&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;pacman&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pacman -S croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Fedora&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;dnf&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;dnf install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Gentoo&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;portage&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;emerge net-misc/croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Termux&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;pkg&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pkg install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On FreeBSD&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;pkg&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pkg install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Linux, macOS, and Windows via Conda&lt;/h3&gt; 
&lt;p&gt;You can install from &lt;a href="https://github.com/conda-forge/croc-feedstock"&gt;conda-forge&lt;/a&gt; globally with &lt;a href="https://pixi.sh/"&gt;&lt;code&gt;pixi&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pixi global install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or install into a particular environment with &lt;a href="https://docs.conda.io/projects/conda/"&gt;&lt;code&gt;conda&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda install --channel conda-forge croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Linux, macOS via Docker&lt;/h3&gt; 
&lt;p&gt;Add the following one-liner function to your ~/.profile (works with any POSIX-compliant shell):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc() { [ $# -eq 0 ] &amp;amp;&amp;amp; set -- ""; mkdir -p "$HOME/.config/croc"; docker run --rm -it --user "$(id -u):$(id -g)" -v "$(pwd):/c" -v "$HOME/.config/croc:/.config/croc" -w /c -e CROC_SECRET docker.io/schollz/croc "$@"; }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also just paste it in the terminal for current session. On first run Docker will pull the image. &lt;code&gt;croc&lt;/code&gt; via Docker will only work within the current directory and its subdirectories.&lt;/p&gt; 
&lt;h3&gt;Build from Source&lt;/h3&gt; 
&lt;p&gt;If you prefer, you can &lt;a href="https://go.dev/dl/"&gt;install Go&lt;/a&gt; and build from source (requires Go 1.22+):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/schollz/croc/v10@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Android&lt;/h3&gt; 
&lt;p&gt;There is a 3rd-party F-Droid app &lt;a href="https://f-droid.org/packages/com.github.howeyc.crocgui/"&gt;available to download&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;To send a file, simply do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ croc send [file(s)-or-folder]
Sending 'file-or-folder' (X MB)
Code is: code-phrase
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, to receive the file (or folder) on another computer, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc code-phrase
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The code phrase is used to establish password-authenticated key agreement (&lt;a href="https://en.wikipedia.org/wiki/Password-authenticated_key_agreement"&gt;PAKE&lt;/a&gt;) which generates a secret key for the sender and recipient to use for end-to-end encryption.&lt;/p&gt; 
&lt;h3&gt;Customizations &amp;amp; Options&lt;/h3&gt; 
&lt;h4&gt;Using &lt;code&gt;croc&lt;/code&gt; on Linux or macOS&lt;/h4&gt; 
&lt;p&gt;On Linux and macOS, the sending and receiving process is slightly different to avoid &lt;a href="https://nvd.nist.gov/vuln/detail/CVE-2023-43621"&gt;leaking the secret via the process name&lt;/a&gt;. You will need to run &lt;code&gt;croc&lt;/code&gt; with the secret as an environment variable. For example, to receive with the secret &lt;code&gt;***&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CROC_SECRET=*** croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For single-user systems, the default behavior can be permanently enabled by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --classic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Custom Code Phrase&lt;/h4&gt; 
&lt;p&gt;You can send with your own code phrase (must be more than 6 characters):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --code [code-phrase] [file(s)-or-folder]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Allow Overwriting Without Prompt&lt;/h4&gt; 
&lt;p&gt;To automatically overwrite files without prompting, use the &lt;code&gt;--overwrite&lt;/code&gt; flag:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --yes --overwrite &amp;lt;code&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Excluding Folders&lt;/h4&gt; 
&lt;p&gt;To exclude folders from being sent, use the &lt;code&gt;--exclude&lt;/code&gt; flag with comma-delimited exclusions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --exclude "node_modules,.venv" [folder]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use Pipes - stdin and stdout&lt;/h4&gt; 
&lt;p&gt;You can pipe to &lt;code&gt;croc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat [filename] | croc send
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To receive the file to &lt;code&gt;stdout&lt;/code&gt;, you can use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --yes [code-phrase] &amp;gt; out
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send Text&lt;/h4&gt; 
&lt;p&gt;To send URLs or short text, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --text "hello world"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send Multiple Files&lt;/h4&gt; 
&lt;p&gt;You can send multiple files directly by listing the files and/or folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send [file1] [file2] [file3] [folder1] [folder2]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Show QR Code&lt;/h4&gt; 
&lt;p&gt;To show QR code (for mobile devices), use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --qr [file(s)-or-folder]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use a Proxy&lt;/h4&gt; 
&lt;p&gt;You can send files via a proxy by adding &lt;code&gt;--socks5&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --socks5 "127.0.0.1:9050" send SOMEFILE
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Change Encryption Curve&lt;/h4&gt; 
&lt;p&gt;To choose a different elliptic curve for encryption, use the &lt;code&gt;--curve&lt;/code&gt; flag:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --curve p521 &amp;lt;codephrase&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Change Hash Algorithm&lt;/h4&gt; 
&lt;p&gt;For faster hashing, use the &lt;code&gt;imohash&lt;/code&gt; algorithm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --hash imohash SOMEFILE
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Clipboard Options&lt;/h4&gt; 
&lt;p&gt;By default, the code phrase is copied to your clipboard. To disable this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --disable-clipboard send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To copy the full command with the secret as an environment variable (useful on Linux/macOS):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --extended-clipboard send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This copies the full command like &lt;code&gt;CROC_SECRET="code-phrase" croc&lt;/code&gt; (including any relay/pass flags).&lt;/p&gt; 
&lt;h4&gt;Quiet Mode&lt;/h4&gt; 
&lt;p&gt;To suppress all output (useful for scripts and automation):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --quiet send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Self-host Relay&lt;/h4&gt; 
&lt;p&gt;You can run your own relay:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc relay
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, it uses TCP ports 9009-9013. You can customize the ports (e.g., &lt;code&gt;croc relay --ports 1111,1112&lt;/code&gt;), but at least &lt;strong&gt;2&lt;/strong&gt; ports are required.&lt;/p&gt; 
&lt;p&gt;To send files using your relay:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --relay "myrelay.example.com:9009" send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Self-host Relay with Docker&lt;/h4&gt; 
&lt;p&gt;You can also run a relay with Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 9009-9013:9009-9013 -e CROC_PASS='YOURPASSWORD' docker.io/schollz/croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To send files using your custom relay:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --pass YOURPASSWORD --relay "myreal.example.com:9009" send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;croc&lt;/code&gt; has evolved through many iterations, and I am thankful for the contributions! Special thanks to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/warner"&gt;@warner&lt;/a&gt; for the &lt;a href="https://github.com/magic-wormhole/magic-wormhole"&gt;idea&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tscholl2"&gt;@tscholl2&lt;/a&gt; for the &lt;a href="https://gist.github.com/tscholl2/dc7dc15dc132ea70a98e8542fefffa28"&gt;encryption gists&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/skorokithakis"&gt;@skorokithakis&lt;/a&gt; for &lt;a href="https://www.stavros.io/posts/proxying-two-connections-go/"&gt;proxying two connections&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And many more!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>danielmiessler/Fabric</title>
      <link>https://github.com/danielmiessler/Fabric</link>
      <description>&lt;p&gt;Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://go.warp.dev/fabric" target="_blank"&gt; &lt;sup&gt;Special thanks to:&lt;/sup&gt; &lt;br /&gt; &lt;img alt="Warp sponsorship" width="400" src="https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;br /&gt; 
  &lt;h&gt;
   Warp, built for coding with multiple AI agents 
   &lt;br /&gt; 
   &lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt; 
  &lt;/h&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/danielmiessler/Fabric/main/docs/images/fabric-logo-gif.gif" alt="fabriclogo" width="400" height="400" /&gt; 
 &lt;h1&gt;&lt;code&gt;fabric&lt;/code&gt;&lt;/h1&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple" alt="Static Badge" /&gt; &lt;br /&gt; &lt;img src="https://img.shields.io/github/languages/top/danielmiessler/fabric" alt="GitHub top language" /&gt; &lt;img src="https://img.shields.io/github/last-commit/danielmiessler/fabric" alt="GitHub last commit" /&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/danielmiessler/fabric"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;h4&gt;&lt;code&gt;fabric&lt;/code&gt; is an open-source framework for augmenting humans using AI.&lt;/h4&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/danielmiessler/Fabric/main/docs/images/fabric-summarize.png" alt="Screenshot of fabric" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#updates"&gt;Updates&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#what-and-why"&gt;What and Why&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#philosophy"&gt;Philosophy&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#installation"&gt;Installation&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#usage"&gt;Usage&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#rest-api-server"&gt;REST API&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#examples"&gt;Examples&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#just-use-the-patterns"&gt;Just Use the Patterns&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#custom-patterns"&gt;Custom Patterns&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#helper-apps"&gt;Helper Apps&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#meta"&gt;Meta&lt;/a&gt;&lt;/p&gt;  
&lt;h2&gt;What and why&lt;/h2&gt; 
&lt;p&gt;Since the start of modern AI in late 2022 we've seen an &lt;strong&gt;&lt;em&gt;extraordinary&lt;/em&gt;&lt;/strong&gt; number of AI applications for accomplishing tasks. There are thousands of websites, chat-bots, mobile apps, and other interfaces for using all the different AI out there.&lt;/p&gt; 
&lt;p&gt;It's all really exciting and powerful, but &lt;em&gt;it's not easy to integrate this functionality into our lives.&lt;/em&gt;&lt;/p&gt; 
&lt;div class="align center"&gt; 
 &lt;h4&gt;In other words, AI doesn't have a capabilities problem—it has an &lt;em&gt;integration&lt;/em&gt; problem.&lt;/h4&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Fabric was created to address this by creating and organizing the fundamental units of AI—the prompts themselves!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Fabric organizes prompts by real-world task, allowing people to create, collect, and organize their most important AI solutions in a single place for use in their favorite tools. And if you're command-line focused, you can use Fabric itself as the interface!&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view recent updates&lt;/summary&gt; 
 &lt;p&gt;Dear Users,&lt;/p&gt; 
 &lt;p&gt;We've been doing so many exciting things here at Fabric, I wanted to give a quick summary here to give you a sense of our development velocity!&lt;/p&gt; 
 &lt;p&gt;Below are the &lt;strong&gt;new features and capabilities&lt;/strong&gt; we've added (newest first):&lt;/p&gt; 
 &lt;h3&gt;Recent Major Features&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.356"&gt;v1.4.356&lt;/a&gt; (Dec 22, 2025) — &lt;strong&gt;Complete Internationalization&lt;/strong&gt;: Full i18n support for setup prompts across all 10 languages with intelligent environment variable handling—making Fabric truly accessible worldwide while maintaining configuration consistency.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.350"&gt;v1.4.350&lt;/a&gt; (Dec 18, 2025) — &lt;strong&gt;Interactive API Documentation&lt;/strong&gt;: Adds Swagger/OpenAPI UI at &lt;code&gt;/swagger/index.html&lt;/code&gt; with comprehensive REST API documentation, enhanced developer guides, and improved endpoint discoverability for easier integration.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.338"&gt;v1.4.338&lt;/a&gt; (Dec 4, 2025) — Add Abacus vendor support for Chat-LLM models (see &lt;a href="https://abacus.ai/app/route-llm-apis"&gt;RouteLLM APIs&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.337"&gt;v1.4.337&lt;/a&gt; (Dec 4, 2025) — Add "Z AI" vendor support. See the &lt;a href="https://docs.z.ai/guides/overview/overview"&gt;Z AI overview&lt;/a&gt; page for more details.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.334"&gt;v1.4.334&lt;/a&gt; (Nov 26, 2025) — &lt;strong&gt;Claude Opus 4.5&lt;/strong&gt;: Updates the Anthropic SDK to the latest and adds the new &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Claude Opus 4.5&lt;/a&gt; to the available models.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.331"&gt;v1.4.331&lt;/a&gt; (Nov 23, 2025) — &lt;strong&gt;Support for GitHub Models&lt;/strong&gt;: Adds support for using GitHub Models.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.322"&gt;v1.4.322&lt;/a&gt; (Nov 5, 2025) — &lt;strong&gt;Interactive HTML Concept Maps and Claude Sonnet 4.5&lt;/strong&gt;: Adds &lt;code&gt;create_conceptmap&lt;/code&gt; pattern for visual knowledge representation using Vis.js, introduces WELLNESS category with psychological analysis patterns, and upgrades to Claude Sonnet 4.5&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.317"&gt;v1.4.317&lt;/a&gt; (Sep 21, 2025) — &lt;strong&gt;Portuguese Language Variants&lt;/strong&gt;: Adds BCP 47 locale normalization with support for Brazilian Portuguese (pt-BR) and European Portuguese (pt-PT) with intelligent fallback chains&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.314"&gt;v1.4.314&lt;/a&gt; (Sep 17, 2025) — &lt;strong&gt;Azure OpenAI Migration&lt;/strong&gt;: Migrates to official &lt;code&gt;openai-go/azure&lt;/code&gt; SDK with improved authentication and default API version support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.311"&gt;v1.4.311&lt;/a&gt; (Sep 13, 2025) — &lt;strong&gt;More internationalization support&lt;/strong&gt;: Adds de (German), fa (Persian / Farsi), fr (French), it (Italian), ja (Japanese), pt (Portuguese), zh (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.309"&gt;v1.4.309&lt;/a&gt; (Sep 9, 2025) — &lt;strong&gt;Comprehensive internationalization support&lt;/strong&gt;: Includes English and Spanish locale files.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.303"&gt;v1.4.303&lt;/a&gt; (Aug 29, 2025) — &lt;strong&gt;New Binary Releases&lt;/strong&gt;: Linux ARM and Windows ARM targets. You can run Fabric on the Raspberry PI and on your Windows Surface!&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.294"&gt;v1.4.294&lt;/a&gt; (Aug 20, 2025) — &lt;strong&gt;Venice AI Support&lt;/strong&gt;: Added the Venice AI provider. Venice is a Privacy-First, Open-Source AI provider. See their &lt;a href="https://docs.venice.ai/overview/about-venice"&gt;"About Venice"&lt;/a&gt; page for details.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.291"&gt;v1.4.291&lt;/a&gt; (Aug 18, 2025) — &lt;strong&gt;Speech To Text&lt;/strong&gt;: Add OpenAI speech-to-text support with &lt;code&gt;--transcribe-file&lt;/code&gt;, &lt;code&gt;--transcribe-model&lt;/code&gt;, and &lt;code&gt;--split-media-file&lt;/code&gt; flags.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.287"&gt;v1.4.287&lt;/a&gt; (Aug 16, 2025) — &lt;strong&gt;AI Reasoning&lt;/strong&gt;: Add Thinking to Gemini models and introduce &lt;code&gt;readme_updates&lt;/code&gt; python script&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.286"&gt;v1.4.286&lt;/a&gt; (Aug 14, 2025) — &lt;strong&gt;AI Reasoning&lt;/strong&gt;: Introduce Thinking Config Across Anthropic and OpenAI Providers&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.285"&gt;v1.4.285&lt;/a&gt; (Aug 13, 2025) — &lt;strong&gt;Extended Context&lt;/strong&gt;: Enable One Million Token Context Beta Feature for Sonnet-4&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.284"&gt;v1.4.284&lt;/a&gt; (Aug 12, 2025) — &lt;strong&gt;Easy Shell Completions Setup&lt;/strong&gt;: Introduce One-Liner Curl Install for Completions&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.283"&gt;v1.4.283&lt;/a&gt; (Aug 12, 2025) — &lt;strong&gt;Model Management&lt;/strong&gt;: Add Vendor Selection Support for Models&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.282"&gt;v1.4.282&lt;/a&gt; (Aug 11, 2025) — &lt;strong&gt;Enhanced Shell Completions&lt;/strong&gt;: Enhanced Shell Completions for Fabric CLI Binaries&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.281"&gt;v1.4.281&lt;/a&gt; (Aug 11, 2025) — &lt;strong&gt;Gemini Search Tool&lt;/strong&gt;: Add Web Search Tool Support for Gemini Models&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.278"&gt;v1.4.278&lt;/a&gt; (Aug 9, 2025) — &lt;strong&gt;Enhance YouTube Transcripts&lt;/strong&gt;: Enhance YouTube Support with Custom yt-dlp Arguments&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.277"&gt;v1.4.277&lt;/a&gt; (Aug 8, 2025) — &lt;strong&gt;Desktop Notifications&lt;/strong&gt;: Add cross-platform desktop notifications to Fabric CLI&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.274"&gt;v1.4.274&lt;/a&gt; (Aug 7, 2025) — &lt;strong&gt;Claude 4.1 Added&lt;/strong&gt;: Add Support for Claude Opus 4.1 Model&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.271"&gt;v1.4.271&lt;/a&gt; (Jul 28, 2025) — &lt;strong&gt;AI Summarized Release Notes&lt;/strong&gt;: Enable AI summary updates for GitHub releases&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.268"&gt;v1.4.268&lt;/a&gt; (Jul 26, 2025) — &lt;strong&gt;Gemini TTS Voice Selection&lt;/strong&gt;: add Gemini TTS voice selection and listing functionality&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.267"&gt;v1.4.267&lt;/a&gt; (Jul 26, 2025) — &lt;strong&gt;Text-to-Speech&lt;/strong&gt;: Update Gemini Plugin to New SDK with TTS Support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.258"&gt;v1.4.258&lt;/a&gt; (Jul 17, 2025) — &lt;strong&gt;Onboarding Improved&lt;/strong&gt;: Add startup check to initialize config and .env file automatically&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.257"&gt;v1.4.257&lt;/a&gt; (Jul 17, 2025) — &lt;strong&gt;OpenAI Routing Control&lt;/strong&gt;: Introduce CLI Flag to Disable OpenAI Responses API&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.252"&gt;v1.4.252&lt;/a&gt; (Jul 16, 2025) — &lt;strong&gt;Hide Thinking Block&lt;/strong&gt;: Optional Hiding of Model Thinking Process with Configurable Tags&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.246"&gt;v1.4.246&lt;/a&gt; (Jul 14, 2025) — &lt;strong&gt;Automatic ChangeLog Updates&lt;/strong&gt;: Add AI-powered changelog generation with high-performance Go tool and comprehensive caching&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.245"&gt;v1.4.245&lt;/a&gt; (Jul 11, 2025) — &lt;strong&gt;Together AI&lt;/strong&gt;: Together AI Support with OpenAI Fallback Mechanism Added&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.232"&gt;v1.4.232&lt;/a&gt; (Jul 6, 2025) — &lt;strong&gt;Add Custom&lt;/strong&gt;: Add Custom Patterns Directory Support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.231"&gt;v1.4.231&lt;/a&gt; (Jul 5, 2025) — &lt;strong&gt;OAuth Auto-Auth&lt;/strong&gt;: OAuth Authentication Support for Anthropic (Use your Max Subscription)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.230"&gt;v1.4.230&lt;/a&gt; (Jul 5, 2025) — &lt;strong&gt;Model Management&lt;/strong&gt;: Add advanced image generation parameters for OpenAI models with four new CLI flags&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.227"&gt;v1.4.227&lt;/a&gt; (Jul 4, 2025) — &lt;strong&gt;Add Image&lt;/strong&gt;: Add Image Generation Support to Fabric&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.226"&gt;v1.4.226&lt;/a&gt; (Jul 4, 2025) — &lt;strong&gt;Web Search&lt;/strong&gt;: OpenAI Plugin Now Supports Web Search Functionality&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.225"&gt;v1.4.225&lt;/a&gt; (Jul 4, 2025) — &lt;strong&gt;Web Search&lt;/strong&gt;: Runtime Web Search Control via Command-Line &lt;code&gt;--search&lt;/code&gt; Flag&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.224"&gt;v1.4.224&lt;/a&gt; (Jul 1, 2025) — &lt;strong&gt;Add code_review&lt;/strong&gt;: Add code_review pattern and updates in Pattern_Descriptions&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.222"&gt;v1.4.222&lt;/a&gt; (Jul 1, 2025) — &lt;strong&gt;OpenAI Plugin&lt;/strong&gt;: OpenAI Plugin Migrates to New Responses API&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.218"&gt;v1.4.218&lt;/a&gt; (Jun 27, 2025) — &lt;strong&gt;Model Management&lt;/strong&gt;: Add Support for OpenAI Search and Research Model Variants&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.217"&gt;v1.4.217&lt;/a&gt; (Jun 26, 2025) — &lt;strong&gt;New YouTube&lt;/strong&gt;: New YouTube Transcript Endpoint Added to REST API&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.212"&gt;v1.4.212&lt;/a&gt; (Jun 23, 2025) — &lt;strong&gt;Add Langdock&lt;/strong&gt;: Add Langdock AI and enhance generic OpenAI compatible support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.211"&gt;v1.4.211&lt;/a&gt; (Jun 19, 2025) — &lt;strong&gt;REST API&lt;/strong&gt;: REST API and Web UI Now Support Dynamic Pattern Variables&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.210"&gt;v1.4.210&lt;/a&gt; (Jun 18, 2025) — &lt;strong&gt;Add Citations&lt;/strong&gt;: Add Citation Support to Perplexity Response&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.208"&gt;v1.4.208&lt;/a&gt; (Jun 17, 2025) — &lt;strong&gt;Add Perplexity&lt;/strong&gt;: Add Perplexity AI Provider with Token Limits Support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.203"&gt;v1.4.203&lt;/a&gt; (Jun 14, 2025) — &lt;strong&gt;Add Amazon Bedrock&lt;/strong&gt;: Add support for Amazon Bedrock&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;These features represent our commitment to making Fabric the most powerful and flexible AI augmentation framework available!&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Intro videos&lt;/h2&gt; 
&lt;p&gt;Keep in mind that many of these were recorded when Fabric was Python-based, so remember to use the current &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#installation"&gt;install instructions&lt;/a&gt; below.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=UbDyjIIGaxQ"&gt;Network Chuck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=vF-MQmVxnCs"&gt;David Bombal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wPEyyigh10g"&gt;My Own Intro to the Tool&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/results?search_query=fabric+ai"&gt;More Fabric YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Navigation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#fabric"&gt;&lt;code&gt;fabric&lt;/code&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#what-and-why"&gt;What and why&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#updates"&gt;Updates&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#recent-major-features"&gt;Recent Major Features&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#intro-videos"&gt;Intro videos&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#navigation"&gt;Navigation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#changelog"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#philosophy"&gt;Philosophy&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#breaking-problems-into-components"&gt;Breaking problems into components&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#too-many-prompts"&gt;Too many prompts&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#installation"&gt;Installation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#one-line-install-recommended"&gt;One-Line Install (Recommended)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#manual-binary-downloads"&gt;Manual Binary Downloads&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#using-package-managers"&gt;Using package managers&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#macos-homebrew"&gt;macOS (Homebrew)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#arch-linux-aur"&gt;Arch Linux (AUR)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#windows"&gt;Windows&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#from-source"&gt;From Source&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#environment-variables"&gt;Environment Variables&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#setup"&gt;Setup&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#per-pattern-model-mapping"&gt;Per-Pattern Model Mapping&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#add-aliases-for-all-patterns"&gt;Add aliases for all patterns&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#save-your-files-in-markdown-using-aliases"&gt;Save your files in markdown using aliases&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#migration"&gt;Migration&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#upgrading"&gt;Upgrading&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#shell-completions"&gt;Shell Completions&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#quick-install-no-clone-required"&gt;Quick install (no clone required)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#zsh-completion"&gt;Zsh Completion&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#bash-completion"&gt;Bash Completion&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#fish-completion"&gt;Fish Completion&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#usage"&gt;Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#debug-levels"&gt;Debug Levels&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#extensions"&gt;Extensions&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#rest-api-server"&gt;REST API Server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#our-approach-to-prompting"&gt;Our approach to prompting&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#just-use-the-patterns"&gt;Just use the Patterns&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#prompt-strategies"&gt;Prompt Strategies&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#custom-patterns"&gt;Custom Patterns&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#setting-up-custom-patterns"&gt;Setting Up Custom Patterns&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#using-custom-patterns"&gt;Using Custom Patterns&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#how-it-works"&gt;How It Works&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#helper-apps"&gt;Helper Apps&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#to_pdf"&gt;&lt;code&gt;to_pdf&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#to_pdf-installation"&gt;&lt;code&gt;to_pdf&lt;/code&gt; Installation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#code_helper"&gt;&lt;code&gt;code_helper&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#pbpaste"&gt;pbpaste&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#web-interface-fabric-web-app"&gt;Web Interface (Fabric Web App)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#meta"&gt;Meta&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#primary-contributors"&gt;Primary contributors&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;Fabric is evolving rapidly.&lt;/p&gt; 
&lt;p&gt;Stay current with the latest features by reviewing the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt; for all recent changes.&lt;/p&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;AI isn't a thing; it's a &lt;em&gt;magnifier&lt;/em&gt; of a thing. And that thing is &lt;strong&gt;human creativity&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the &lt;strong&gt;human&lt;/strong&gt; problems we want to solve.&lt;/p&gt; 
&lt;h3&gt;Breaking problems into components&lt;/h3&gt; 
&lt;p&gt;Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.&lt;/p&gt; 
&lt;img width="2078" alt="augmented_challenges" src="https://github.com/danielmiessler/fabric/assets/50654/31997394-85a9-40c2-879b-b347e4701f06" /&gt; 
&lt;h3&gt;Too many prompts&lt;/h3&gt; 
&lt;p&gt;Prompts are good for this, but the biggest challenge I faced in 2023——which still exists today—is &lt;strong&gt;the sheer number of AI prompts out there&lt;/strong&gt;. We all have prompts that are useful, but it's hard to discover new ones, know if they are good or not, &lt;em&gt;and manage different versions of the ones we like&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;One of &lt;code&gt;fabric&lt;/code&gt;'s primary features is helping people collect and integrate prompts, which we call &lt;em&gt;Patterns&lt;/em&gt;, into various parts of their lives.&lt;/p&gt; 
&lt;p&gt;Fabric has Patterns for all sorts of life and work activities, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extracting the most interesting parts of YouTube videos and podcasts&lt;/li&gt; 
 &lt;li&gt;Writing an essay in your own voice with just an idea as an input&lt;/li&gt; 
 &lt;li&gt;Summarizing opaque academic papers&lt;/li&gt; 
 &lt;li&gt;Creating perfectly matched AI art prompts for a piece of writing&lt;/li&gt; 
 &lt;li&gt;Rating the quality of content to see if you want to read/watch the whole thing&lt;/li&gt; 
 &lt;li&gt;Getting summaries of long, boring content&lt;/li&gt; 
 &lt;li&gt;Explaining code to you&lt;/li&gt; 
 &lt;li&gt;Turning bad documentation into usable documentation&lt;/li&gt; 
 &lt;li&gt;Creating social media posts from any content input&lt;/li&gt; 
 &lt;li&gt;And a million more…&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;One-Line Install (Recommended)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Unix/Linux/macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows PowerShell:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;iwr -useb https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/scripts/installer/README.md"&gt;scripts/installer/README.md&lt;/a&gt; for custom installation options and troubleshooting.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Manual Binary Downloads&lt;/h3&gt; 
&lt;p&gt;The latest release binary archives and their expected SHA256 hashes can be found at &lt;a href="https://github.com/danielmiessler/fabric/releases/latest"&gt;https://github.com/danielmiessler/fabric/releases/latest&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using package managers&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; using Homebrew or the Arch Linux package managers makes &lt;code&gt;fabric&lt;/code&gt; available as &lt;code&gt;fabric-ai&lt;/code&gt;, so add the following alias to your shell startup files to account for this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;alias fabric='fabric-ai'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;macOS (Homebrew)&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;brew install fabric-ai&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Arch Linux (AUR)&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;yay -S fabric-ai&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;p&gt;Use the official Microsoft supported &lt;code&gt;Winget&lt;/code&gt; tool:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;winget install danielmiessler.Fabric&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;p&gt;To install Fabric, &lt;a href="https://go.dev/doc/install"&gt;make sure Go is installed&lt;/a&gt;, and then run the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Fabric directly from the repo
go install github.com/danielmiessler/fabric/cmd/fabric@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Run Fabric using pre-built Docker images:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use latest image from Docker Hub
docker run --rm -it kayvan/fabric:latest --version

# Use specific version from GHCR
docker run --rm -it ghcr.io/ksylvan/fabric:v1.4.305 --version

# Run setup (first time)
mkdir -p $HOME/.fabric-config
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --setup

# Use Fabric with your patterns
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest -p summarize

# Run the REST API server (see REST API Server section)
docker run --rm -it -p 8080:8080 -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Images available at:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker Hub: &lt;a href="https://hub.docker.com/repository/docker/kayvan/fabric/general"&gt;kayvan/fabric&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GHCR: &lt;a href="https://github.com/ksylvan/fabric/pkgs/container/fabric"&gt;ksylvan/fabric&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/scripts/docker/README.md"&gt;scripts/docker/README.md&lt;/a&gt; for building custom images and advanced configuration.&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;You may need to set some environment variables in your &lt;code&gt;~/.bashrc&lt;/code&gt; on linux or &lt;code&gt;~/.zshrc&lt;/code&gt; file on mac to be able to run the &lt;code&gt;fabric&lt;/code&gt; command. Here is an example of what you can add:&lt;/p&gt; 
&lt;p&gt;For Intel based macs or linux&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Golang environment variables
export GOROOT=/usr/local/go
export GOPATH=$HOME/go

# Update PATH to include GOPATH and GOROOT binaries
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;for Apple Silicon based macs&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Golang environment variables
export GOROOT=$(brew --prefix go)/libexec
export GOPATH=$HOME/go
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;p&gt;Now run the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the setup to set up your directories and keys
fabric --setup
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If everything works you are good to go.&lt;/p&gt; 
&lt;h3&gt;Per-Pattern Model Mapping&lt;/h3&gt; 
&lt;p&gt;You can configure specific models for individual patterns using environment variables like &lt;code&gt;FABRIC_MODEL_PATTERN_NAME=vendor|model&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This makes it easy to maintain these per-pattern model mappings in your shell startup files.&lt;/p&gt; 
&lt;h3&gt;Add aliases for all patterns&lt;/h3&gt; 
&lt;p&gt;In order to add aliases for all your patterns and use them directly as commands, for example, &lt;code&gt;summarize&lt;/code&gt; instead of &lt;code&gt;fabric --pattern summarize&lt;/code&gt; You can add the following to your &lt;code&gt;.zshrc&lt;/code&gt; or &lt;code&gt;.bashrc&lt;/code&gt; file. You can also optionally set the &lt;code&gt;FABRIC_ALIAS_PREFIX&lt;/code&gt; environment variable before, if you'd prefer all the fabric aliases to start with the same prefix.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in $HOME/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name="$(basename "$pattern_file")"
    alias_name="${FABRIC_ALIAS_PREFIX:-}${pattern_name}"

    # Create an alias in the form: alias pattern_name="fabric --pattern pattern_name"
    alias_command="alias $alias_name='fabric --pattern $pattern_name'"

    # Evaluate the alias command to add it to the current shell
    eval "$alias_command"
done

yt() {
    if [ "$#" -eq 0 ] || [ "$#" -gt 2 ]; then
        echo "Usage: yt [-t | --timestamps] youtube-link"
        echo "Use the '-t' flag to get the transcript with timestamps."
        return 1
    fi

    transcript_flag="--transcript"
    if [ "$1" = "-t" ] || [ "$1" = "--timestamps" ]; then
        transcript_flag="--transcript-with-timestamps"
        shift
    fi
    local video_link="$1"
    fabric -y "$video_link" $transcript_flag
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can add the below code for the equivalent aliases inside PowerShell by running &lt;code&gt;notepad $PROFILE&lt;/code&gt; inside a PowerShell window:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# Path to the patterns directory
$patternsPath = Join-Path $HOME ".config/fabric/patterns"
foreach ($patternDir in Get-ChildItem -Path $patternsPath -Directory) {
    # Prepend FABRIC_ALIAS_PREFIX if set; otherwise use empty string
    $prefix = $env:FABRIC_ALIAS_PREFIX ?? ''
    $patternName = "$($patternDir.Name)"
    $aliasName = "$prefix$patternName"
    # Dynamically define a function for each pattern
    $functionDefinition = @"
function $aliasName {
    [CmdletBinding()]
    param(
        [Parameter(ValueFromPipeline = `$true)]
        [string] `$InputObject,

        [Parameter(ValueFromRemainingArguments = `$true)]
        [String[]] `$patternArgs
    )

    begin {
        # Initialize an array to collect pipeline input
        `$collector = @()
    }

    process {
        # Collect pipeline input objects
        if (`$InputObject) {
            `$collector += `$InputObject
        }
    }

    end {
        # Join all pipeline input into a single string, separated by newlines
        `$pipelineContent = `$collector -join "`n"

        # If there's pipeline input, include it in the call to fabric
        if (`$pipelineContent) {
            `$pipelineContent | fabric --pattern $patternName `$patternArgs
        } else {
            # No pipeline input; just call fabric with the additional args
            fabric --pattern $patternName `$patternArgs
        }
    }
}
"@
    # Add the function to the current session
    Invoke-Expression $functionDefinition
}

# Define the 'yt' function as well
function yt {
    [CmdletBinding()]
    param(
        [Parameter()]
        [Alias("timestamps")]
        [switch]$t,

        [Parameter(Position = 0, ValueFromPipeline = $true)]
        [string]$videoLink
    )

    begin {
        $transcriptFlag = "--transcript"
        if ($t) {
            $transcriptFlag = "--transcript-with-timestamps"
        }
    }

    process {
        if (-not $videoLink) {
            Write-Error "Usage: yt [-t | --timestamps] youtube-link"
            return
        }
    }

    end {
        if ($videoLink) {
            # Execute and allow output to flow through the pipeline
            fabric -y $videoLink $transcriptFlag
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This also creates a &lt;code&gt;yt&lt;/code&gt; alias that allows you to use &lt;code&gt;yt https://www.youtube.com/watch?v=4b0iet22VIk&lt;/code&gt; to get transcripts, comments, and metadata.&lt;/p&gt; 
&lt;h4&gt;Save your files in markdown using aliases&lt;/h4&gt; 
&lt;p&gt;If in addition to the above aliases you would like to have the option to save the output to your favorite markdown note vault like Obsidian then instead of the above add the following to your &lt;code&gt;.zshrc&lt;/code&gt; or &lt;code&gt;.bashrc&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Define the base directory for Obsidian notes
obsidian_base="/path/to/obsidian"

# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in ~/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name=$(basename "$pattern_file")

    # Remove any existing alias with the same name
    unalias "$pattern_name" 2&amp;gt;/dev/null

    # Define a function dynamically for each pattern
    eval "
    $pattern_name() {
        local title=\$1
        local date_stamp=\$(date +'%Y-%m-%d')
        local output_path=\"\$obsidian_base/\${date_stamp}-\${title}.md\"

        # Check if a title was provided
        if [ -n \"\$title\" ]; then
            # If a title is provided, use the output path
            fabric --pattern \"$pattern_name\" -o \"\$output_path\"
        else
            # If no title is provided, use --stream
            fabric --pattern \"$pattern_name\" --stream
        fi
    }
    "
done
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will allow you to use the patterns as aliases like in the above for example &lt;code&gt;summarize&lt;/code&gt; instead of &lt;code&gt;fabric --pattern summarize --stream&lt;/code&gt;, however if you pass in an extra argument like this &lt;code&gt;summarize "my_article_title"&lt;/code&gt; your output will be saved in the destination that you set in &lt;code&gt;obsidian_base="/path/to/obsidian"&lt;/code&gt; in the following format &lt;code&gt;YYYY-MM-DD-my_article_title.md&lt;/code&gt; where the date gets autogenerated for you. You can tweak the date format by tweaking the &lt;code&gt;date_stamp&lt;/code&gt; format.&lt;/p&gt; 
&lt;h3&gt;Migration&lt;/h3&gt; 
&lt;p&gt;If you have the Legacy (Python) version installed and want to migrate to the Go version, here's how you do it. It's basically two steps: 1) uninstall the Python version, and 2) install the Go version.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Uninstall Legacy Fabric
pipx uninstall fabric

# Clear any old Fabric aliases
(check your .bashrc, .zshrc, etc.)
# Install the Go version
go install github.com/danielmiessler/fabric/cmd/fabric@latest
# Run setup for the new version. Important because things have changed
fabric --setup
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#environment-variables"&gt;set your environmental variables&lt;/a&gt; as shown above.&lt;/p&gt; 
&lt;h3&gt;Upgrading&lt;/h3&gt; 
&lt;p&gt;The great thing about Go is that it's super easy to upgrade. Just run the same command you used to install it in the first place and you'll always get the latest version.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/fabric@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Shell Completions&lt;/h3&gt; 
&lt;p&gt;Fabric provides shell completion scripts for Zsh, Bash, and Fish shells, making it easier to use the CLI by providing tab completion for commands and options.&lt;/p&gt; 
&lt;h4&gt;Quick install (no clone required)&lt;/h4&gt; 
&lt;p&gt;You can install completions directly via a one-liner:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions/setup-completions.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optional variants:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Dry-run (see actions without changing your system)
curl -fsSL https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions/setup-completions.sh | sh -s -- --dry-run

# Override the download source (advanced)
FABRIC_COMPLETIONS_BASE_URL="https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions" \
    sh -c "$(curl -fsSL https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions/setup-completions.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Zsh Completion&lt;/h4&gt; 
&lt;p&gt;To enable Zsh completion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the completion file to a directory in your $fpath
mkdir -p ~/.zsh/completions
cp completions/_fabric ~/.zsh/completions/

# Add the directory to fpath in your .zshrc before compinit
echo 'fpath=(~/.zsh/completions $fpath)' &amp;gt;&amp;gt; ~/.zshrc
echo 'autoload -Uz compinit &amp;amp;&amp;amp; compinit' &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Bash Completion&lt;/h4&gt; 
&lt;p&gt;To enable Bash completion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Source the completion script in your .bashrc
echo 'source /path/to/fabric/completions/fabric.bash' &amp;gt;&amp;gt; ~/.bashrc

# Or copy to the system-wide bash completion directory
sudo cp completions/fabric.bash /etc/bash_completion.d/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Fish Completion&lt;/h4&gt; 
&lt;p&gt;To enable Fish completion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the completion file to the fish completions directory
mkdir -p ~/.config/fish/completions
cp completions/fabric.fish ~/.config/fish/completions/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Once you have it all set up, here's how to use it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fabric -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-plaintext"&gt;Usage:
  fabric [OPTIONS]

Application Options:
  -p, --pattern=                    Choose a pattern from the available patterns
  -v, --variable=                   Values for pattern variables, e.g. -v=#role:expert -v=#points:30
  -C, --context=                    Choose a context from the available contexts
      --session=                    Choose a session from the available sessions
  -a, --attachment=                 Attachment path or URL (e.g. for OpenAI image recognition messages)
  -S, --setup                       Run setup for all reconfigurable parts of fabric
  -t, --temperature=                Set temperature (default: 0.7)
  -T, --topp=                       Set top P (default: 0.9)
  -s, --stream                      Stream
  -P, --presencepenalty=            Set presence penalty (default: 0.0)
  -r, --raw                         Use the defaults of the model without sending chat options
                                    (temperature, top_p, etc.). Only affects OpenAI-compatible providers.
                                    Anthropic models always use smart parameter selection to comply with
                                    model-specific requirements.
  -F, --frequencypenalty=           Set frequency penalty (default: 0.0)
  -l, --listpatterns                List all patterns
  -L, --listmodels                  List all available models
  -x, --listcontexts                List all contexts
  -X, --listsessions                List all sessions
  -U, --updatepatterns              Update patterns
  -c, --copy                        Copy to clipboard
  -m, --model=                      Choose model
  -V, --vendor=                     Specify vendor for chosen model (e.g., -V "LM Studio" -m openai/gpt-oss-20b)
      --modelContextLength=         Model context length (only affects ollama)
  -o, --output=                     Output to file
      --output-session              Output the entire session (also a temporary one) to the output file
  -n, --latest=                     Number of latest patterns to list (default: 0)
  -d, --changeDefaultModel          Change default model
  -y, --youtube=                    YouTube video or play list "URL" to grab transcript, comments from it
                                    and send to chat or print it put to the console and store it in the
                                    output file
      --playlist                    Prefer playlist over video if both ids are present in the URL
      --transcript                  Grab transcript from YouTube video and send to chat (it is used per
                                    default).
      --transcript-with-timestamps  Grab transcript from YouTube video with timestamps and send to chat
      --comments                    Grab comments from YouTube video and send to chat
      --metadata                    Output video metadata
  -g, --language=                   Specify the Language Code for the chat, e.g. -g=en -g=zh
  -u, --scrape_url=                 Scrape website URL to markdown using Jina AI
  -q, --scrape_question=            Search question using Jina AI
  -e, --seed=                       Seed to be used for LMM generation
  -w, --wipecontext=                Wipe context
  -W, --wipesession=                Wipe session
      --printcontext=               Print context
      --printsession=               Print session
      --readability                 Convert HTML input into a clean, readable view
      --input-has-vars              Apply variables to user input
      --no-variable-replacement     Disable pattern variable replacement
      --dry-run                     Show what would be sent to the model without actually sending it
      --serve                       Serve the Fabric Rest API
      --serveOllama                 Serve the Fabric Rest API with ollama endpoints
      --address=                    The address to bind the REST API (default: :8080)
      --api-key=                    API key used to secure server routes
      --config=                     Path to YAML config file
      --version                     Print current version
      --listextensions              List all registered extensions
      --addextension=               Register a new extension from config file path
      --rmextension=                Remove a registered extension by name
      --strategy=                   Choose a strategy from the available strategies
      --liststrategies              List all strategies
      --listvendors                 List all vendors
      --shell-complete-list         Output raw list without headers/formatting (for shell completion)
      --search                      Enable web search tool for supported models (Anthropic, OpenAI, Gemini)
      --search-location=            Set location for web search results (e.g., 'America/Los_Angeles')
      --image-file=                 Save generated image to specified file path (e.g., 'output.png')
      --image-size=                 Image dimensions: 1024x1024, 1536x1024, 1024x1536, auto (default: auto)
      --image-quality=              Image quality: low, medium, high, auto (default: auto)
      --image-compression=          Compression level 0-100 for JPEG/WebP formats (default: not set)
      --image-background=           Background type: opaque, transparent (default: opaque, only for
                                    PNG/WebP)
      --suppress-think              Suppress text enclosed in thinking tags
      --think-start-tag=            Start tag for thinking sections (default: &amp;lt;think&amp;gt;)
      --think-end-tag=              End tag for thinking sections (default: &amp;lt;/think&amp;gt;)
      --disable-responses-api       Disable OpenAI Responses API (default: false)
      --voice=                      TTS voice name for supported models (e.g., Kore, Charon, Puck)
                                    (default: Kore)
      --list-gemini-voices          List all available Gemini TTS voices
      --notification                Send desktop notification when command completes
      --notification-command=       Custom command to run for notifications (overrides built-in
                                    notifications)
      --yt-dlp-args=                Additional arguments to pass to yt-dlp (e.g. '--cookies-from-browser brave')
      --thinking=                   Set reasoning/thinking level (e.g., off, low, medium, high, or
                                    numeric tokens for Anthropic or Google Gemini)
      --debug=                     Set debug level (0: off, 1: basic, 2: detailed, 3: trace)
Help Options:
  -h, --help                        Show this help message
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debug Levels&lt;/h3&gt; 
&lt;p&gt;Use the &lt;code&gt;--debug&lt;/code&gt; flag to control runtime logging:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;0&lt;/code&gt;: off (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1&lt;/code&gt;: basic debug info&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2&lt;/code&gt;: detailed debugging&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;3&lt;/code&gt;: trace level&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extensions&lt;/h3&gt; 
&lt;p&gt;Fabric supports extensions that can be called within patterns. See the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/internal/plugins/template/Examples/README.md"&gt;Extension Guide&lt;/a&gt; for complete documentation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Extensions only work within pattern files, not via direct stdin. See the guide for details and examples.&lt;/p&gt; 
&lt;h2&gt;REST API Server&lt;/h2&gt; 
&lt;p&gt;Fabric includes a built-in REST API server that exposes all core functionality over HTTP. Start the server with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fabric --serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The server provides endpoints for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chat completions with streaming responses&lt;/li&gt; 
 &lt;li&gt;Pattern management (create, read, update, delete)&lt;/li&gt; 
 &lt;li&gt;Context and session management&lt;/li&gt; 
 &lt;li&gt;Model and vendor listing&lt;/li&gt; 
 &lt;li&gt;YouTube transcript extraction&lt;/li&gt; 
 &lt;li&gt;Configuration management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For complete endpoint documentation, authentication setup, and usage examples, see &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/docs/rest-api.md"&gt;REST API Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Our approach to prompting&lt;/h2&gt; 
&lt;p&gt;Fabric &lt;em&gt;Patterns&lt;/em&gt; are different than most prompts you'll see.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;First, we use &lt;code&gt;Markdown&lt;/code&gt; to help ensure maximum readability and editability&lt;/strong&gt;. This not only helps the creator make a good one, but also anyone who wants to deeply understand what it does. &lt;em&gt;Importantly, this also includes the AI you're sending it to!&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here's an example of a Fabric Pattern.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;https://github.com/danielmiessler/Fabric/blob/main/data/patterns/extract_wisdom/system.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;img width="1461" alt="pattern-example" src="https://github.com/danielmiessler/fabric/assets/50654/b910c551-9263-405f-9735-71ca69bbab6d" /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Next, we are extremely clear in our instructions&lt;/strong&gt;, and we use the Markdown structure to emphasize what we want the AI to do, and in what order.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;And finally, we tend to use the System section of the prompt almost exclusively&lt;/strong&gt;. In over a year of being heads-down with this stuff, we've just seen more efficacy from doing that. If that changes, or we're shown data that says otherwise, we will adjust.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following examples use the macOS &lt;code&gt;pbpaste&lt;/code&gt; to paste from the clipboard. See the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#pbpaste"&gt;pbpaste&lt;/a&gt; section below for Windows and Linux alternatives.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Now let's look at some things you can do with Fabric.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run the &lt;code&gt;summarize&lt;/code&gt; Pattern based on input from &lt;code&gt;stdin&lt;/code&gt;. In this case, the body of an article.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pbpaste | fabric --pattern summarize
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the &lt;code&gt;analyze_claims&lt;/code&gt; Pattern with the &lt;code&gt;--stream&lt;/code&gt; option to get immediate and streaming results.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pbpaste | fabric --stream --pattern analyze_claims
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the &lt;code&gt;extract_wisdom&lt;/code&gt; Pattern with the &lt;code&gt;--stream&lt;/code&gt; option to get immediate and streaming results from any Youtube video (much like in the original introduction video).&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric -y "https://youtube.com/watch?v=uXs-zPc63kM" --stream --pattern extract_wisdom
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create patterns- you must create a .md file with the pattern and save it to &lt;code&gt;~/.config/fabric/patterns/[yourpatternname]&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run a &lt;code&gt;analyze_claims&lt;/code&gt; pattern on a website. Fabric uses Jina AI to scrape the URL into markdown format before sending it to the model.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric -u https://github.com/danielmiessler/fabric/ -p analyze_claims
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Just use the Patterns&lt;/h2&gt; 
&lt;img width="1173" alt="fabric-patterns-screenshot" src="https://github.com/danielmiessler/fabric/assets/50654/9186a044-652b-4673-89f7-71cf066f32d8" /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;If you're not looking to do anything fancy, and you just want a lot of great prompts, you can navigate to the &lt;a href="https://github.com/danielmiessler/fabric/tree/main/data/patterns"&gt;&lt;code&gt;/patterns&lt;/code&gt;&lt;/a&gt; directory and start exploring!&lt;/p&gt; 
&lt;p&gt;We hope that if you used nothing else from Fabric, the Patterns by themselves will make the project useful.&lt;/p&gt; 
&lt;p&gt;You can use any of the Patterns you see there in any AI application that you have, whether that's ChatGPT or some other app or website. Our plan and prediction is that people will soon be sharing many more than those we've published, and they will be way better than ours.&lt;/p&gt; 
&lt;p&gt;The wisdom of crowds for the win.&lt;/p&gt; 
&lt;h3&gt;Prompt Strategies&lt;/h3&gt; 
&lt;p&gt;Fabric also implements prompt strategies like "Chain of Thought" or "Chain of Draft" which can be used in addition to the basic patterns.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://arxiv.org/pdf/2502.18600"&gt;Thinking Faster by Writing Less&lt;/a&gt; paper and the &lt;a href="https://learnprompting.org/docs/advanced/thought_generation/introduction"&gt;Thought Generation section of Learn Prompting&lt;/a&gt; for examples of prompt strategies.&lt;/p&gt; 
&lt;p&gt;Each strategy is available as a small &lt;code&gt;json&lt;/code&gt; file in the &lt;a href="https://github.com/danielmiessler/fabric/tree/main/data/strategies"&gt;&lt;code&gt;/strategies&lt;/code&gt;&lt;/a&gt; directory.&lt;/p&gt; 
&lt;p&gt;The prompt modification of the strategy is applied to the system prompt and passed on to the LLM in the chat session.&lt;/p&gt; 
&lt;p&gt;Use &lt;code&gt;fabric -S&lt;/code&gt; and select the option to install the strategies in your &lt;code&gt;~/.config/fabric&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Custom Patterns&lt;/h2&gt; 
&lt;p&gt;You may want to use Fabric to create your own custom Patterns—but not share them with others. No problem!&lt;/p&gt; 
&lt;p&gt;Fabric now supports a dedicated custom patterns directory that keeps your personal patterns separate from the built-in ones. This means your custom patterns won't be overwritten when you update Fabric's built-in patterns.&lt;/p&gt; 
&lt;h3&gt;Setting Up Custom Patterns&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run the Fabric setup:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric --setup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select the "Custom Patterns" option from the Tools menu and enter your desired directory path (e.g., &lt;code&gt;~/my-custom-patterns&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Fabric will automatically create the directory if it does not exist.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Using Custom Patterns&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create your custom pattern directory structure:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p ~/my-custom-patterns/my-analyzer
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create your pattern file&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;echo "You are an expert analyzer of ..." &amp;gt; ~/my-custom-patterns/my-analyzer/system.md
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Use your custom pattern:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric --pattern my-analyzer "analyze this text"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;How It Works&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Priority System&lt;/strong&gt;: Custom patterns take precedence over built-in patterns with the same name&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integration&lt;/strong&gt;: Custom patterns appear in &lt;code&gt;fabric --listpatterns&lt;/code&gt; alongside built-in ones&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update Safe&lt;/strong&gt;: Your custom patterns are never affected by &lt;code&gt;fabric --updatepatterns&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Private by Default&lt;/strong&gt;: Custom patterns remain private unless you explicitly share them&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your custom patterns are completely private and won't be affected by Fabric updates!&lt;/p&gt; 
&lt;h2&gt;Helper Apps&lt;/h2&gt; 
&lt;p&gt;Fabric also makes use of some core helper apps (tools) to make it easier to integrate with your various workflows. Here are some examples:&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;to_pdf&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;to_pdf&lt;/code&gt; is a helper command that converts LaTeX files to PDF format. You can use it like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;to_pdf input.tex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create a PDF file from the input LaTeX file in the same directory.&lt;/p&gt; 
&lt;p&gt;You can also use it with stdin which works perfectly with the &lt;code&gt;write_latex&lt;/code&gt; pattern:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo "ai security primer" | fabric --pattern write_latex | to_pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create a PDF file named &lt;code&gt;output.pdf&lt;/code&gt; in the current directory.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;to_pdf&lt;/code&gt; Installation&lt;/h3&gt; 
&lt;p&gt;To install &lt;code&gt;to_pdf&lt;/code&gt;, install it the same way as you install Fabric, just with a different repo name.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/to_pdf@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure you have a LaTeX distribution (like TeX Live or MiKTeX) installed on your system, as &lt;code&gt;to_pdf&lt;/code&gt; requires &lt;code&gt;pdflatex&lt;/code&gt; to be available in your system's PATH.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;code_helper&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;code_helper&lt;/code&gt; is used in conjunction with the &lt;code&gt;create_coding_feature&lt;/code&gt; pattern. It generates a &lt;code&gt;json&lt;/code&gt; representation of a directory of code that can be fed into an AI model with instructions to create a new feature or edit the code in a specified way.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/data/patterns/create_coding_feature/README.md"&gt;the Create Coding Feature Pattern README&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Install it first using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/code_helper@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;pbpaste&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#examples"&gt;examples&lt;/a&gt; use the macOS program &lt;code&gt;pbpaste&lt;/code&gt; to paste content from the clipboard to pipe into &lt;code&gt;fabric&lt;/code&gt; as the input. &lt;code&gt;pbpaste&lt;/code&gt; is not available on Windows or Linux, but there are alternatives.&lt;/p&gt; 
&lt;p&gt;On Windows, you can use the PowerShell command &lt;code&gt;Get-Clipboard&lt;/code&gt; from a PowerShell command prompt. If you like, you can also alias it to &lt;code&gt;pbpaste&lt;/code&gt;. If you are using classic PowerShell, edit the file &lt;code&gt;~\Documents\WindowsPowerShell\.profile.ps1&lt;/code&gt;, or if you are using PowerShell Core, edit &lt;code&gt;~\Documents\PowerShell\.profile.ps1&lt;/code&gt; and add the alias,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;Set-Alias pbpaste Get-Clipboard
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Linux, you can use &lt;code&gt;xclip -selection clipboard -o&lt;/code&gt; to paste from the clipboard. You will likely need to install &lt;code&gt;xclip&lt;/code&gt; with your package manager. For Debian based systems including Ubuntu,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt update
sudo apt install xclip -y
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also create an alias by editing &lt;code&gt;~/.bashrc&lt;/code&gt; or &lt;code&gt;~/.zshrc&lt;/code&gt; and adding the alias,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;alias pbpaste='xclip -selection clipboard -o'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Web Interface (Fabric Web App)&lt;/h2&gt; 
&lt;p&gt;Fabric now includes a built-in web interface that provides a GUI alternative to the command-line interface. Refer to &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/web/README.md"&gt;Web App README&lt;/a&gt; for installation instructions and an overview of features.&lt;/p&gt; 
&lt;h2&gt;Meta&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Special thanks to the following people for their inspiration and contributions!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;Jonathan Dunn&lt;/em&gt; for being the absolute MVP dev on the project, including spearheading the new Go version, as well as the GUI! All this while also being a full-time medical doctor!&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Caleb Sima&lt;/em&gt; for pushing me over the edge of whether to make this a public project or not.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Eugen Eisler&lt;/em&gt; and &lt;em&gt;Frederick Ros&lt;/em&gt; for their invaluable contributions to the Go version&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;David Peters&lt;/em&gt; for his work on the web interface.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Joel Parish&lt;/em&gt; for super useful input on the project's Github directory structure..&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Joseph Thacker&lt;/em&gt; for the idea of a &lt;code&gt;-c&lt;/code&gt; context flag that adds pre-created context in the &lt;code&gt;./config/fabric/&lt;/code&gt; directory to all Pattern queries.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Jason Haddix&lt;/em&gt; for the idea of a stitch (chained Pattern) to filter content using a local model before sending on to a cloud model, i.e., cleaning customer data using &lt;code&gt;llama2&lt;/code&gt; before sending on to &lt;code&gt;gpt-4&lt;/code&gt; for analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Andre Guerra&lt;/em&gt; for assisting with numerous components to make things simpler and more maintainable.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Primary contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/danielmiessler"&gt;&lt;img src="https://avatars.githubusercontent.com/u/50654?v=4" title="Daniel Miessler" width="50" height="50" alt="Daniel Miessler" /&gt;&lt;/a&gt; &lt;a href="https://github.com/xssdoctor"&gt;&lt;img src="https://avatars.githubusercontent.com/u/9218431?v=4" title="Jonathan Dunn" width="50" height="50" alt="Jonathan Dunn" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sbehrens"&gt;&lt;img src="https://avatars.githubusercontent.com/u/688589?v=4" title="Scott Behrens" width="50" height="50" alt="Scott Behrens" /&gt;&lt;/a&gt; &lt;a href="https://github.com/agu3rra"&gt;&lt;img src="https://avatars.githubusercontent.com/u/10410523?v=4" title="Andre Guerra" width="50" height="50" alt="Andre Guerra" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;a href="https://github.com/danielmiessler/fabric/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=danielmiessler/fabric" alt="contrib.rocks" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;fabric&lt;/code&gt; was created by &lt;a href="https://danielmiessler.com/subscribe" target="_blank"&gt;Daniel Miessler&lt;/a&gt; in January of 2024. &lt;br /&gt;&lt;br /&gt; &lt;a href="https://twitter.com/intent/user?screen_name=danielmiessler"&gt;&lt;img src="https://img.shields.io/twitter/follow/danielmiessler" alt="X (formerly Twitter) Follow" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>beclab/Olares</title>
      <link>https://github.com/beclab/Olares</link>
      <description>&lt;p&gt;Olares: An Open-Source Personal Cloud to Reclaim Your Data&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;Olares: An Open-Source Personal Cloud to &lt;br /&gt;Reclaim Your Data
  &lt;!-- omit in toc --&gt;&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/#"&gt;&lt;img src="https://img.shields.io/badge/Mission-Let%20people%20own%20their%20data%20again-purple" alt="Mission" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/beclab/olares/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/beclab/olares" alt="Last Commit" /&gt;&lt;/a&gt; &lt;img src="https://github.com/beclab/olares/actions/workflows/release-daily.yaml/badge.svg?sanitize=true" alt="Build Status" /&gt; &lt;a href="https://github.com/beclab/olares/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/beclab/olares" alt="GitHub release (latest by date)" /&gt;&lt;/a&gt; &lt;a href="https://github.com/beclab/olares/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/beclab/olares?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/olares"&gt;&lt;img src="https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/beclab/olares/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-AGPL--3.0-blue" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15376" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15376" alt="beclab%2FOlares | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/README.md"&gt;&lt;img alt="Readme in English" src="https://img.shields.io/badge/English-FFFFFF" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/README_CN.md"&gt;&lt;img alt="Readme in Chinese" src="https://img.shields.io/badge/简体中文-FFFFFF" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/README_JP.md"&gt;&lt;img alt="Readme in Japanese" src="https://img.shields.io/badge/日本語-FFFFFF" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://olares.com"&gt;Website&lt;/a&gt; · &lt;a href="https://docs.olares.com"&gt;Documentation&lt;/a&gt; · &lt;a href="https://www.olares.com/larepass"&gt;Download LarePass&lt;/a&gt; · &lt;a href="https://github.com/beclab/apps"&gt;Olares Apps&lt;/a&gt; · &lt;a href="https://space.olares.com"&gt;Olares Space&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;The modern internet built on public clouds is increasingly threatening your personal data privacy. As reliance on services like ChatGPT, Midjourney, and Facebook grows, so does the risk to your digital autonomy. Your data lives on their servers, subject to their terms, tracking, and potential censorship.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;It's time for a change.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://app.cdn.olares.com/github/olares/public-cloud-to-personal-cloud.jpg" alt="Personal Cloud" /&gt; We believe you have a fundamental right to control your digital life. The most effective way to uphold this right is by hosting your data locally, on your own hardware.&lt;/p&gt; 
&lt;p&gt;Olares is an &lt;strong&gt;open-source personal cloud operating system&lt;/strong&gt; designed to empower you to own and manage your digital assets locally. Instead of relying on public cloud services, you can deploy powerful open-source alternatives locally on Olares, such as Ollama for hosting LLMs, ComfyUI for image generation, and Perplexica for private, AI-driven search and reasoning. Imagine the power of the cloud, but with you in complete command.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🌟 &lt;em&gt;Star us to receive instant notifications about new releases and updates.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Just as Public clouds offer IaaS, PaaS, and SaaS layers, Olares provides open-source alternatives to each of these layers.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://app.cdn.olares.com/github/olares/olares-architecture.jpg" alt="Tech Stacks" /&gt;&lt;/p&gt; 
&lt;p&gt;For detailed description of each component, refer to &lt;a href="https://docs.olares.com/manual/concepts/system-architecture.html"&gt;Olares architecture&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🔍 &lt;strong&gt;How is Olares different from traditional NAS?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Olares focuses on building an all-in-one self-hosted personal cloud experience. Its core features and target users differ significantly from traditional Network Attached Storage (NAS) systems, which primarily focus on network storage. For more details, see &lt;a href="https://docs.olares.com/manual/olares-vs-nas.html"&gt;Compare Olares and NAS&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;Olares offers a wide array of features designed to enhance security, ease of use, and development flexibility:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise-grade security&lt;/strong&gt;: Simplified network configuration using Tailscale, Headscale, Cloudflare Tunnel, and FRP.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Secure and permissionless application ecosystem&lt;/strong&gt;: Sandboxing ensures application isolation and security.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unified file system and database&lt;/strong&gt;: Automated scaling, backups, and high availability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single sign-on&lt;/strong&gt;: Log in once to access all applications within Olares with a shared authentication service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI capabilities&lt;/strong&gt;: Comprehensive solution for GPU management, local AI model hosting, and private knowledge bases while maintaining data privacy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in applications&lt;/strong&gt;: Includes file manager, sync drive, vault, reader, app market, settings, and dashboard.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless anywhere access&lt;/strong&gt;: Access your devices from anywhere using dedicated clients for mobile, desktop, and browsers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development tools&lt;/strong&gt;: Comprehensive development tools for effortless application development and porting.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here are some screenshots from the UI for a sneak peek:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Desktop–Streamlined and familiar portal&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Files–A secure home to your data&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/desktop.jpg" alt="Desktop" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/files.jpg" alt="Files" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Vault–1Password alternative&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Market–App ecosystem in your control&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/vault.jpg" alt="vault" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/market.jpg" alt="market" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Wise–Your digital secret garden&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Settings–Manage Olares efficiently&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/wise.jpg" alt="settings" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/settings.jpg" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Dashboard–Constant system monitoring&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Profile–Your unique homepage&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/dashboard.jpg" alt="dashboard" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/profile.jpg" alt="profile" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Studio–Develop, debug, and deploy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Control Hub–Manage Kubernetes clusters easily&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/devbox.jpg" alt="Studio" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://app.cdn.olares.com/github/terminus/v2/controlhub.jpg" alt="Controlhub" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Key use cases&lt;/h2&gt; 
&lt;p&gt;Here is why and where you can count on Olares for private, powerful, and secure sovereign cloud experience:&lt;/p&gt; 
&lt;p&gt;🤖 &lt;strong&gt;Edge AI&lt;/strong&gt;: Run cutting-edge open AI models locally, including large language models, computer vision, and speech recognition. Create private AI services tailored to your data for enhanced functionality and privacy. &lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;📊 &lt;strong&gt;Personal data repository&lt;/strong&gt;: Securely store, sync, and manage your important files, photos, and documents across devices and locations.&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;🚀 &lt;strong&gt;Self-hosted workspace&lt;/strong&gt;: Build a free collaborative workspace for your team using secure, open-source SaaS alternatives.&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;🎥 &lt;strong&gt;Private media server&lt;/strong&gt;: Host your own streaming services with your personal media collections. &lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;🏡 &lt;strong&gt;Smart Home Hub&lt;/strong&gt;: Create a central control point for your IoT devices and home automation. &lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;🤝 &lt;strong&gt;User-owned decentralized social media&lt;/strong&gt;: Easily install decentralized social media apps such as Mastodon, Ghost, and WordPress on Olares, allowing you to build a personal brand without the risk of being banned or paying platform commissions.&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;📚 &lt;strong&gt;Learning platform&lt;/strong&gt;: Explore self-hosting, container orchestration, and cloud technologies hands-on.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;h3&gt;System compatibility&lt;/h3&gt; 
&lt;p&gt;Olares has been tested and verified on the following Linux platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ubuntu 24.04 LTS or later&lt;/li&gt; 
 &lt;li&gt;Debian 11 or later&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Set up Olares&lt;/h3&gt; 
&lt;p&gt;To get started with Olares on your own device, follow the &lt;a href="https://docs.olares.com/manual/get-started/"&gt;Getting Started Guide&lt;/a&gt; for step-by-step instructions.&lt;/p&gt; 
&lt;h2&gt;Project navigation&lt;/h2&gt; 
&lt;p&gt;This section lists the main directories in the Olares repository:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/apps"&gt;&lt;code&gt;apps&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Contains the code for system applications, primarily for &lt;code&gt;larepass&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/cli"&gt;&lt;code&gt;cli&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Contains the code for &lt;code&gt;olares-cli&lt;/code&gt;, the command-line interface tool for Olares.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/daemon"&gt;&lt;code&gt;daemon&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Contains the code for &lt;code&gt;olaresd&lt;/code&gt;, the system daemon process.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/docs"&gt;&lt;code&gt;docs&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Contains documentation for the project.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/framework"&gt;&lt;code&gt;framework&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Contains the Olares system services.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/infrastructure"&gt;&lt;code&gt;infrastructure&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Contains code related to infrastructure components such as computing, storage, networking, and GPUs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/beclab/Olares/main/platform"&gt;&lt;code&gt;platform&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Contains code for cloud-native components like databases and message queues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;vendor&lt;/code&gt;&lt;/strong&gt;: Contains code from third-party hardware vendors.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing to Olares&lt;/h2&gt; 
&lt;p&gt;We are welcoming contributions in any form:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;If you want to develop your own applications on Olares, refer to:&lt;br /&gt; &lt;a href="https://docs.olares.com/developer/develop/"&gt;https://docs.olares.com/developer/develop/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you want to help improve Olares, refer to:&lt;br /&gt; &lt;a href="https://docs.olares.com/developer/contribute/olares.html"&gt;https://docs.olares.com/developer/contribute/olares.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community &amp;amp; contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/beclab/olares/discussions"&gt;&lt;strong&gt;GitHub Discussion&lt;/strong&gt;&lt;/a&gt;. Best for sharing feedback and asking questions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/beclab/olares/issues"&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;&lt;/a&gt;. Best for filing bugs you encounter using Olares and submitting feature proposals.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/olares"&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/a&gt;. Best for sharing anything Olares.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Special thanks&lt;/h2&gt; 
&lt;p&gt;The Olares project has incorporated numerous third-party open source projects, including: &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt;, &lt;a href="https://github.com/kubesphere/kubesphere"&gt;Kubesphere&lt;/a&gt;, &lt;a href="https://padloc.app/"&gt;Padloc&lt;/a&gt;, &lt;a href="https://k3s.io/"&gt;K3S&lt;/a&gt;, &lt;a href="https://github.com/juicedata/juicefs"&gt;JuiceFS&lt;/a&gt;, &lt;a href="https://github.com/minio/minio"&gt;MinIO&lt;/a&gt;, &lt;a href="https://github.com/envoyproxy/envoy"&gt;Envoy&lt;/a&gt;, &lt;a href="https://github.com/authelia/authelia"&gt;Authelia&lt;/a&gt;, &lt;a href="https://github.com/Infisical/infisical"&gt;Infisical&lt;/a&gt;, &lt;a href="https://github.com/langgenius/dify"&gt;Dify&lt;/a&gt;, &lt;a href="https://github.com/haiwen/seafile"&gt;Seafile&lt;/a&gt;,&lt;a href="https://headscale.net/"&gt;HeadScale&lt;/a&gt;, &lt;a href="https://tailscale.com/"&gt;tailscale&lt;/a&gt;, &lt;a href="https://github.com/spotahome/redis-operator"&gt;Redis Operator&lt;/a&gt;, &lt;a href="https://nitro.jan.ai/"&gt;Nitro&lt;/a&gt;, &lt;a href="http://rsshub.app/"&gt;RssHub&lt;/a&gt;, &lt;a href="https://github.com/joyieldInc/predixy"&gt;predixy&lt;/a&gt;, &lt;a href="https://github.com/grgalex/nvshare"&gt;nvshare&lt;/a&gt;, &lt;a href="https://www.langchain.com/"&gt;LangChain&lt;/a&gt;, &lt;a href="https://quasar.dev/"&gt;Quasar&lt;/a&gt;, &lt;a href="https://trustwallet.com/"&gt;TrustWallet&lt;/a&gt;, &lt;a href="https://restic.net/"&gt;Restic&lt;/a&gt;, &lt;a href="https://zincsearch-docs.zinc.dev/"&gt;ZincSearch&lt;/a&gt;, &lt;a href="https://filebrowser.org/"&gt;filebrowser&lt;/a&gt;, &lt;a href="https://go-acme.github.io/lego/"&gt;lego&lt;/a&gt;, &lt;a href="https://velero.io/"&gt;Velero&lt;/a&gt;, &lt;a href="https://github.com/jamhall/s3rver"&gt;s3rver&lt;/a&gt;, &lt;a href="https://www.citusdata.com/"&gt;Citusdata&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aquasecurity/trivy</title>
      <link>https://github.com/aquasecurity/trivy</link>
      <description>&lt;p&gt;Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/logo.png" width="200" /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml"&gt;&lt;img src="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/aquasecurity/trivy"&gt;&lt;img src="https://goreportcard.com/badge/github.com/aquasecurity/trivy" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github" alt="GitHub Downloads" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;amp;label=docker%20pulls%20%2F%20trivy" alt="Docker Pulls" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trivy.dev/docs/latest/"&gt;📖 Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Trivy (&lt;a href="https://raw.githubusercontent.com/aquasecurity/trivy/main/#how-to-pronounce-the-name-trivy"&gt;pronunciation&lt;/a&gt;) is a comprehensive and versatile security scanner. Trivy has &lt;em&gt;scanners&lt;/em&gt; that look for security issues, and &lt;em&gt;targets&lt;/em&gt; where it can find those issues.&lt;/p&gt; 
&lt;p&gt;Targets (what Trivy can scan):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Container Image&lt;/li&gt; 
 &lt;li&gt;Filesystem&lt;/li&gt; 
 &lt;li&gt;Git Repository (remote)&lt;/li&gt; 
 &lt;li&gt;Virtual Machine Image&lt;/li&gt; 
 &lt;li&gt;Kubernetes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Scanners (what Trivy can find there):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OS packages and software dependencies in use (SBOM)&lt;/li&gt; 
 &lt;li&gt;Known vulnerabilities (CVEs)&lt;/li&gt; 
 &lt;li&gt;IaC issues and misconfigurations&lt;/li&gt; 
 &lt;li&gt;Sensitive information and secrets&lt;/li&gt; 
 &lt;li&gt;Software licenses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the &lt;a href="https://trivy.dev/docs/latest/coverage/"&gt;Scanning Coverage&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;To learn more, go to the &lt;a href="https://trivy.dev"&gt;Trivy homepage&lt;/a&gt; for feature highlights, or to the &lt;a href="https://trivy.dev/docs/latest/"&gt;Documentation site&lt;/a&gt; for detailed information.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Get Trivy&lt;/h3&gt; 
&lt;p&gt;Trivy is available in most common distribution channels. The full list of installation options is available in the &lt;a href="https://trivy.dev/docs/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;brew install trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;docker run aquasec/trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Download binary from &lt;a href="https://github.com/aquasecurity/trivy/releases/latest/"&gt;https://github.com/aquasecurity/trivy/releases/latest/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/docs/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the &lt;a href="https://trivy.dev/docs/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-action"&gt;GitHub Actions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-operator"&gt;Kubernetes operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-vscode-extension"&gt;VS Code plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/docs/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Canary builds&lt;/h3&gt; 
&lt;p&gt;There are canary builds (&lt;a href="https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;amp;name=canary"&gt;Docker Hub&lt;/a&gt;, &lt;a href="https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary"&gt;GitHub&lt;/a&gt;, &lt;a href="https://gallery.ecr.aws/aquasecurity/trivy#canary"&gt;ECR&lt;/a&gt; images and &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml"&gt;binaries&lt;/a&gt;) generated with every push to the main branch.&lt;/p&gt; 
&lt;p&gt;Please be aware: canary builds might have critical bugs, so they are not recommended for use in production.&lt;/p&gt; 
&lt;h3&gt;General usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy &amp;lt;target&amp;gt; [--scanners &amp;lt;scanner1,scanner2&amp;gt;] &amp;lt;subject&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy image python:3.4-alpine
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov"&gt;https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy fs --scanners vuln,secret,misconfig myproject/
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov"&gt;https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy k8s --report summary cluster
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/trivy-k8s.png" alt="k8s summary" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;How to pronounce the name "Trivy"?&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;tri&lt;/code&gt; is pronounced like &lt;strong&gt;tri&lt;/strong&gt;gger, &lt;code&gt;vy&lt;/code&gt; is pronounced like en&lt;strong&gt;vy&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Want more? Check out Aqua&lt;/h2&gt; 
&lt;p&gt;If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.&lt;br /&gt; You can find a high level comparison table specific to Trivy users &lt;a href="https://trivy.dev/docs/latest/commercial/compare/"&gt;here&lt;/a&gt;. In addition check out the &lt;a href="https://aquasec.com"&gt;https://aquasec.com&lt;/a&gt; website for more information about our products and services. If you'd like to contact Aqua or request a demo, please use this form: &lt;a href="https://www.aquasec.com/demo"&gt;https://www.aquasec.com/demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Trivy is an &lt;a href="https://aquasec.com"&gt;Aqua Security&lt;/a&gt; open source project.&lt;br /&gt; Learn about our open source work and portfolio &lt;a href="https://www.aquasec.com/products/open-source-projects/"&gt;here&lt;/a&gt;.&lt;br /&gt; Contact us about any matter by opening a GitHub Discussion &lt;a href="https://github.com/aquasecurity/trivy/discussions"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please ensure to abide by our &lt;a href="https://github.com/aquasecurity/community/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; during all interactions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>m1k1o/neko</title>
      <link>https://github.com/m1k1o/neko</link>
      <description>&lt;p&gt;A self hosted virtual browser that runs in docker and uses WebRTC.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/m1k1o/neko" title="Neko's Github repository."&gt; &lt;img src="https://neko.m1k1o.net/img/logo.png" width="400" height="auto" /&gt; &lt;/a&gt; 
 &lt;p align="center"&gt; &lt;a href="https://github.com/m1k1o/neko/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/m1k1o/neko" alt="release" /&gt; &lt;/a&gt; &lt;a href="https://github.com/m1k1o/neko/raw/master/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/m1k1o/neko" alt="license" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/m1k1o/neko"&gt; &lt;img src="https://img.shields.io/docker/pulls/m1k1o/neko" alt="pulls" /&gt; &lt;/a&gt; &lt;a href="https://github.com/m1k1o/neko/issues"&gt; &lt;img src="https://img.shields.io/github/issues/m1k1o/neko" alt="issues" /&gt; &lt;/a&gt; &lt;a href="https://github.com/sponsors/m1k1o"&gt; &lt;img src="https://img.shields.io/badge/-sponsor-red" alt="issues" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/3U6hWpC"&gt; &lt;img src="https://discordapp.com/api/guilds/665851821906067466/widget.png" alt="Chat on discord" /&gt; &lt;/a&gt; &lt;a href="https://hellogithub.com/repository/4536d4546af24196af3f08a023dfa007" target="_blank"&gt; &lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=4536d4546af24196af3f08a023dfa007&amp;amp;claim_uid=0x19e4dJwD83aW2&amp;amp;theme=small" alt="Featured｜HelloGitHub" /&gt; &lt;/a&gt; &lt;a href="https://github.com/m1k1o/neko/actions"&gt; &lt;img src="https://github.com/m1k1o/neko/actions/workflows/ghcr.yml/badge.svg?sanitize=true" alt="build" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;img src="https://neko.m1k1o.net/img/intro.gif" width="650" height="auto" /&gt; 
&lt;/div&gt; 
&lt;h1&gt;n.eko&lt;/h1&gt; 
&lt;p&gt;Welcome to Neko, a self-hosted virtual browser that runs in Docker and uses WebRTC technology. Neko is a powerful tool that allows you to &lt;strong&gt;run a fully-functional browser in a virtual environment&lt;/strong&gt;, giving you the ability to &lt;strong&gt;access the internet securely and privately from anywhere&lt;/strong&gt;. With Neko, you can browse the web, &lt;strong&gt;run applications&lt;/strong&gt;, and perform other tasks just as you would on a regular browser, all within a &lt;strong&gt;secure and isolated environment&lt;/strong&gt;. Whether you are a developer looking to test web applications, a &lt;strong&gt;privacy-conscious user seeking a secure browsing experience&lt;/strong&gt;, or simply someone who wants to take advantage of the &lt;strong&gt;convenience and flexibility of a virtual browser&lt;/strong&gt;, Neko is the perfect solution.&lt;/p&gt; 
&lt;p&gt;In addition to its security and privacy features, Neko offers the &lt;strong&gt;ability for multiple users to access it simultaneously&lt;/strong&gt;. This makes it an ideal solution for teams or organizations that need to share access to a browser, as well as for individuals who want to use &lt;strong&gt;multiple devices to access the same virtual environment&lt;/strong&gt;. With Neko, you can &lt;strong&gt;easily and securely share access to a browser with others&lt;/strong&gt;, without having to worry about maintaining separate configurations or settings. Whether you need to &lt;strong&gt;collaborate on a project&lt;/strong&gt;, access shared resources, or simply want to &lt;strong&gt;share access to a browser with friends or family&lt;/strong&gt;, Neko makes it easy to do so.&lt;/p&gt; 
&lt;p&gt;Neko is also a great tool for &lt;strong&gt;hosting watch parties&lt;/strong&gt; and interactive presentations. With its virtual browser capabilities, Neko allows you to host watch parties and presentations that are &lt;strong&gt;accessible from anywhere&lt;/strong&gt;, without the need for in-person gatherings. This makes it easy to &lt;strong&gt;stay connected with friends and colleagues&lt;/strong&gt;, even when you are unable to meet in person. With Neko, you can easily host a watch party or give an &lt;strong&gt;interactive presentation&lt;/strong&gt;, whether it's for leisure or work. Simply invite your guests to join the virtual environment, and you can share the screen and &lt;strong&gt;interact with them in real-time&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;This app uses WebRTC to stream a desktop inside of a docker container, original author made this because &lt;a href="https://en.wikipedia.org/wiki/Rabb.it"&gt;rabb.it&lt;/a&gt; went under and his internet could not handle streaming and discord kept crashing when his friend attempted to. He just wanted to watch anime with his friends ლ(ಠ益ಠლ) so he started digging throughout the internet and found a few &lt;em&gt;kinda&lt;/em&gt; clones, but none of them had the virtual browser, then he found &lt;a href="https://github.com/Khauri/Turtus"&gt;Turtus&lt;/a&gt; and he was able to figure out the rest.&lt;/p&gt; 
&lt;p&gt;Then I found &lt;a href="https://github.com/nurdism/neko"&gt;this&lt;/a&gt; project and started to dig into it. I really liked the idea of having collaborative browser browsing together with multiple people, so I created a fork. Initially, I wanted to merge my changes to the upstream repository, but the original author did not have time for this project anymore and it got eventually archived.&lt;/p&gt; 
&lt;h2&gt;Use-cases and comparison&lt;/h2&gt; 
&lt;p&gt;Neko started as a virtual browser that is streamed using WebRTC to multiple users.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;It is &lt;strong&gt;not only limited to a browser&lt;/strong&gt;; it can run anything that runs on linux (e.g. VLC). Browser only happens to be the most popular and widely used use-case.&lt;/li&gt; 
 &lt;li&gt;In fact, it is not limited to a single program either; you can install a full desktop environment (e.g. XFCE, KDE).&lt;/li&gt; 
 &lt;li&gt;Speaking of limits, it does not need to run in a container; you could install neko on your host, connect to your X server and control your whole VM.&lt;/li&gt; 
 &lt;li&gt;Theoretically it is not limited to only X server, anything that can be controlled and scraped periodically for images could be used instead. 
  &lt;ul&gt; 
   &lt;li&gt;Like implementing RDP or VNC protocol, where neko would only act as WebRTC relay server. This is currently only future.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Primary use case is connecting with multiple people, leveraging real time synchronization and interactivity:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Watch party&lt;/strong&gt; - watching video content together with multiple people and reacting to it (chat, emotes) - open source alternative to &lt;a href="https://giggl.app/"&gt;giggl.app&lt;/a&gt; or &lt;a href="https://watch.hyperbeam.com"&gt;hyperbeam&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive presentation&lt;/strong&gt; - not only screen sharing, but others can control the screen.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Collaborative tool&lt;/strong&gt; - brainstorming ideas, cobrowsing, code debugging together.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support/Teaching&lt;/strong&gt; - interactively guiding people in controlled environment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embed anything&lt;/strong&gt; - embed virtual browser in your web app - open source alternative to &lt;a href="https://hyperbeam.com/"&gt;hyperbeam API&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;open any third-party website or application, synchronize audio and video flawlessly among multiple participants.&lt;/li&gt; 
   &lt;li&gt;request rooms using API with &lt;a href="https://github.com/m1k1o/neko-rooms"&gt;neko-rooms&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other use cases that benefit from single-user:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Personal workspace&lt;/strong&gt; - streaming containerized apps and desktops to end-users - similar to &lt;a href="https://www.kasmweb.com/"&gt;kasm&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistent browser&lt;/strong&gt; - own browser with persistent cookies available anywhere - similar to &lt;a href="https://www.mightyapp.com/"&gt;mightyapp&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;no state is left on the host browser after terminating the connection.&lt;/li&gt; 
   &lt;li&gt;sensitive data like cookies are not transferred - only video is shared.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Throwaway browser&lt;/strong&gt; - a better solution for planning secret parties and buying birthday gifts off the internet. 
  &lt;ul&gt; 
   &lt;li&gt;use Tor Browser and &lt;a href="https://github.com/m1k1o/neko-vpn"&gt;VPN&lt;/a&gt; for additional anonymity.&lt;/li&gt; 
   &lt;li&gt;mitigates risk of OS fingerprinting and browser vulnerabilities by running in container.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session broadcasting&lt;/strong&gt; - broadcast room content using RTMP (to e.g. twitch or youtube...).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session recording&lt;/strong&gt; - broadcast RTMP can be saved to a file using e.g. &lt;a href="https://www.nginx.com/products/nginx/modules/rtmp-media-streaming/"&gt;nginx-rtmp&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;have clean environment when recording tutorials.&lt;/li&gt; 
   &lt;li&gt;no need to hide bookmarks or use incognito mode.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jump host&lt;/strong&gt; - access your internal applications securely without the need for VPN.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automated browser&lt;/strong&gt; - you can install &lt;a href="https://playwright.dev/"&gt;playwright&lt;/a&gt; or &lt;a href="https://pptr.dev/"&gt;puppeteer&lt;/a&gt; and automate tasks while being able to actively intercept them.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Compared to clientless remote desktop gateway (e.g. &lt;a href="https://guacamole.apache.org/"&gt;Apache Guacamole&lt;/a&gt; or &lt;a href="https://github.com/novnc/websockify"&gt;websockify&lt;/a&gt; with &lt;a href="https://novnc.com/"&gt;noVNC&lt;/a&gt;), installed with remote desktop server along with desired program (e.g. &lt;a href="https://docs.linuxserver.io/images/docker-firefox"&gt;linuxserver/firefox&lt;/a&gt;) provides neko additionally:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Smooth video&lt;/strong&gt; because it uses WebRTC and not images sent over WebSockets.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built in audio&lt;/strong&gt; support, what is not part of Apache Guacamole or noVNC.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-participant control&lt;/strong&gt;, what is not natively supported by Apache Guacamole or noVNC.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported browsers&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#firefox"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/firefox.svg?sanitize=true" title="ghcr.io/m1k1o/neko/firefox" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#tor-browser"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/tor-browser.svg?sanitize=true" title="ghcr.io/m1k1o/neko/tor-browser" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#waterfox"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/waterfox.svg?sanitize=true" title="ghcr.io/m1k1o/neko/waterfox" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#chromium"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/chromium.svg?sanitize=true" title="ghcr.io/m1k1o/neko/chromium" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#google-chrome"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/google-chrome.svg?sanitize=true" title="ghcr.io/m1k1o/neko/google-chrome" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#ungoogled-chromium"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/ungoogled-chromium.svg?sanitize=true" title="ghcr.io/m1k1o/neko/google-chrome" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#microsoft-edge"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/microsoft-edge.svg?sanitize=true" title="ghcr.io/m1k1o/neko/microsoft-edge" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#brave"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/brave.svg?sanitize=true" title="ghcr.io/m1k1o/neko/brave" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#vivaldi"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/vivaldi.svg?sanitize=true" title="ghcr.io/m1k1o/neko/vivaldi" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#opera"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/opera.svg?sanitize=true" title="ghcr.io/m1k1o/neko/opera" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;p&gt;... see &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images"&gt;all available images&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;Other applications&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#xfce"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/xfce.svg?sanitize=true" title="ghcr.io/m1k1o/neko/xfce" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#kde"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/kde.svg?sanitize=true" title="ghcr.io/m1k1o/neko/kde" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#remmina"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/remmina.svg?sanitize=true" title="ghcr.io/m1k1o/neko/remmina" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#vlc"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/vlc.svg?sanitize=true" title="ghcr.io/m1k1o/neko/vlc" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;p&gt;... others in &lt;a href="https://github.com/m1k1o/neko-apps"&gt;m1k1o/neko-apps&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;Why neko?&lt;/h3&gt; 
&lt;p&gt;I like cats 🐱 (&lt;code&gt;Neko&lt;/code&gt; is the Japanese word for cat), I'm a weeb/nerd.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;But why the cat butt?&lt;/strong&gt;&lt;/em&gt; Because cats are &lt;em&gt;assholes&lt;/em&gt;, but you love them anyways.&lt;/p&gt; 
&lt;h2&gt;Multiple rooms&lt;/h2&gt; 
&lt;p&gt;For neko room management software, visit &lt;a href="https://github.com/m1k1o/neko-rooms"&gt;neko-rooms&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;It also offers &lt;a href="https://github.com/m1k1o/neko-rooms/?tab=readme-ov-file#zero-knowledge-installation-with-https"&gt;Zero-knowledge installation (with HTTPS)&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Full documentation is available at &lt;a href="https://neko.m1k1o.net/"&gt;neko.m1k1o.net&lt;/a&gt;. Key sections include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/migration-from-v2"&gt;Migration from V2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/quick-start"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/installation/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/faq"&gt;Frequently Asked Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Contribute&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Check the &lt;a href="https://neko.m1k1o.net/contributing"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;If you find Neko useful, consider supporting the project via &lt;a href="https://github.com/sponsors/m1k1o"&gt;GitHub Sponsors&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jorgerojas26/lazysql</title>
      <link>https://github.com/jorgerojas26/lazysql</link>
      <description>&lt;p&gt;A cross-platform TUI database management tool written in Go.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jorgerojas26/lazysql/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/jorgerojas26/lazysql?style=for-the-badge" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jorgerojas26/lazysql/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/jorgerojas26/lazysql?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jorgerojas26/lazysql/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/jorgerojas26/lazysql?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jorgerojas26/lazysql/issues"&gt;&lt;img src="https://img.shields.io/github/issues/jorgerojas26/lazysql?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jorgerojas26/lazysql/raw/main/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/jorgerojas26/lazysql.svg?style=for-the-badge" alt="MIT License" /&gt;&lt;/a&gt; &lt;a href="https://linkedin.com/in/jorgerojas26"&gt;&lt;img src="https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;colorB=555" alt="LinkedIn" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;div align="center"&gt; 
 &lt;!-- &lt;a href="https://github.com/jorgerojas26/lazysql"&gt; --&gt; 
 &lt;!--   &lt;img src="images/logo.png" alt="Logo" width="80" height="80"&gt; --&gt; 
 &lt;!-- &lt;/a&gt; --&gt; 
 &lt;h3 align="center"&gt;LAZYSQL&lt;/h3&gt; 
 &lt;p align="center"&gt; A cross-platform TUI database management tool written in Go. &lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details&gt; 
 &lt;summary&gt;Table of Contents&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#about-the-project"&gt;About The Project&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#built-with"&gt;Built With&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt; &lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#usage"&gt;Usage&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#commands"&gt;Commands&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#keybindings"&gt;Keybindings&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#roadmap"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#contact"&gt;Contact&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;!-- ABOUT THE PROJECT --&gt; 
&lt;h2&gt;About The Project&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/images/lazysql-connection-selection.png" alt="Product Name Screen Shot" /&gt; &lt;img src="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/images/lazysql.png" alt="Product Name Screen Shot" /&gt;&lt;/p&gt; 
&lt;p&gt;This project is heavily inspired by &lt;a href="https://github.com/jesseduffield/lazygit"&gt;Lazygit&lt;/a&gt;, which I think is the best TUI client for Git.&lt;/p&gt; 
&lt;p&gt;I wanted to have a tool like that, but for SQL. I didn't find one that fits my needs, so I created one myself.&lt;/p&gt; 
&lt;p&gt;I live in the terminal, so if you are like me, this tool can become handy for you too.&lt;/p&gt; 
&lt;p&gt;This is my first Open Source project, also, this is my first Go project. I am not a brilliant programmer. I am just a typical JavaScript developer that wanted to learn a new language, I also wanted a TUI SQL Client, so blanca y en botella, leche! (white and bottled).&lt;/p&gt; 
&lt;p&gt;This project is in ALPHA stage, please feel free to complain about my spaghetti code.&lt;/p&gt; 
&lt;p&gt;I use Lazysql daily in my full-time job as a full-stack javascript developer in its current (buggy xD) state. So, the plan is to improve and fix my little boy as a side-project in my free time.&lt;/p&gt; 
&lt;h3&gt;Built With&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Golang-gray?style=for-the-badge&amp;amp;logo=go" alt="Golang" /&gt; &lt;img src="https://img.shields.io/badge/tview-gray?style=for-the-badge&amp;amp;logo=go" alt="Golang" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Cross-platform (macOS, Windows, Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Vim Keybindings&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Can manage multiple connections (Backspace)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Tabs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; SQL Editor (CTRL + e)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- GETTING STARTED --&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Homebrew (macOS/Linux)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ brew install lazysql
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install with go package manager&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/jorgerojas26/lazysql@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Binary Releases&lt;/h4&gt; 
&lt;p&gt;For Windows, macOS or Linux, you can download a binary release &lt;a href="https://github.com/jorgerojas26/lazysql/releases"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Third party (maintained by the community)&lt;/h4&gt; 
&lt;p&gt;Arch Linux users can install it from the AUR with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;paru -S lazysql

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yay -S lazysql

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or install it manual with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://aur.archlinux.org/lazysql.git
cd lazysql
makepkg -si
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- USAGE EXAMPLES --&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;If the &lt;code&gt;XDG_CONFIG_HOME&lt;/code&gt; environment variable is set, the configuration file will be located at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/lazysql/config.toml&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If not, the configuration file will be located at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows: &lt;code&gt;%APPDATA%\lazysql\config.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;macOS: &lt;code&gt;~/Library/Application Support/lazysql/config.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Linux: &lt;code&gt;~/.config/lazysql/config.toml&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The configuration file is a TOML file and can be used to define multiple connections.&lt;/p&gt; 
&lt;h3&gt;Example configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[[database]]
Name = 'Production database'
Provider = 'postgres'
DBName = 'foo'
URL = 'postgres://${user}:urlencodedpassword@localhost:${port}/foo'
ReadOnly = true
Commands = [
  { Command = 'ssh -tt remote-bastion -L ${port}:localhost:5432', WaitForPort = '${port}' },
  { Command = 'whoami', SaveOutputTo = 'user' },
]
[[database]]
Name = 'Development database'
Provider = 'postgres'
DBName = 'foo'
URL = 'postgres://postgres:urlencodedpassword@localhost:5432/foo'
[application]
DefaultPageSize = 300
DisableSidebar = false
SidebarOverlay = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;ReadOnly&lt;/code&gt; field (optional, defaults to &lt;code&gt;false&lt;/code&gt;) can be set to &lt;code&gt;true&lt;/code&gt; to enable read-only mode for a connection. When enabled, all mutation queries (INSERT, UPDATE, DELETE, DROP, etc.) will be blocked.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;[application]&lt;/code&gt; section is used to define some app settings. Not all settings are available yet, this is a work in progress.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For a list of keyboard shortcuts press &lt;code&gt;?&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Open the TUI with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ lazysql
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To launch lazysql with the ability to pick from the saved connections.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ lazysql [connection_url]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To launch lazysql and connect to database at [connection_url].&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ lazysql --read-only [connection_url]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To launch lazysql in read-only mode.&lt;/p&gt; 
&lt;h3&gt;Connect to a DB&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;lazysql&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create a new connection (press &lt;code&gt;n&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Provide a name for the connection as well as the URL to connect to (see &lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#example-connection-urls"&gt;example connection URL&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Connect to the DB (press &lt;code&gt;&amp;lt;Enter&amp;gt;&lt;/code&gt;)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If you already have a connection set up:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;lazysql&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select the right connection (press &lt;code&gt;j&lt;/code&gt; and &lt;code&gt;h&lt;/code&gt; for navigation)&lt;/li&gt; 
 &lt;li&gt;Connect to the DB (press &lt;code&gt;c&lt;/code&gt; or &lt;code&gt;&amp;lt;Enter&amp;gt;&lt;/code&gt;)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Create a table&lt;/h3&gt; 
&lt;p&gt;There is currently no way to create a table from the TUI. However you can run the query to create the table as a SQL-Query, inside the &lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#execute-sql-queries"&gt;SQL Editor&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can update the tree by pressing &lt;code&gt;R&lt;/code&gt;, so you can see your newly created table.&lt;/p&gt; 
&lt;h3&gt;Execute SQL queries&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Press &lt;code&gt;&amp;lt;Ctrl+E&amp;gt;&lt;/code&gt; to open the built-in SQL Editor&lt;/li&gt; 
 &lt;li&gt;Write the SQL query&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;&amp;lt;Ctrl+R&amp;gt;&lt;/code&gt; to execute the SQL query&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To switch back to the table-tree press &lt;code&gt;H&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;After executing a &lt;code&gt;SELECT&lt;/code&gt;-query a table will be displayed under the SQL-Editor with the query-result. &lt;br /&gt; To switch focus back to SQL-Editor press &lt;code&gt;/&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Open/view a table&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Expand the table-tree by pressing &lt;code&gt;e&lt;/code&gt; or &lt;code&gt;&amp;lt;Enter&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select the table you want to view 
  &lt;ul&gt; 
   &lt;li&gt;next node &lt;code&gt;j&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;previous node &lt;code&gt;k&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;last node &lt;code&gt;G&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;first node &lt;code&gt;g&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;&amp;lt;Enter&amp;gt;&lt;/code&gt; to open the table&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To switch back to the table-tree press &lt;code&gt;H&lt;/code&gt; &lt;br /&gt; To switch back to the table press &lt;code&gt;L&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Filter rows&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#openview-a-table"&gt;Open a table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;/&lt;/code&gt; to focus the filter input&lt;/li&gt; 
 &lt;li&gt;Write a &lt;code&gt;WHERE&lt;/code&gt;-clause to filter the table&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;&amp;lt;Enter&amp;gt;&lt;/code&gt; to submit your filter&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To remove the filter, focus the filter input (press &lt;code&gt;/&lt;/code&gt;) and press &lt;code&gt;&amp;lt;Esc&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Insert a row&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#openview-a-table"&gt;Open a table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;1&lt;/code&gt; to switch to the record tab&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;o&lt;/code&gt; to insert a new row&lt;/li&gt; 
 &lt;li&gt;Fill out all columns&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;&amp;lt;Ctrl+S&amp;gt;&lt;/code&gt; to save the changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Edit a column&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#openview-a-table"&gt;Open a table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;1&lt;/code&gt; to switch to the record tab&lt;/li&gt; 
 &lt;li&gt;Move to the column you want to edit&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;c&lt;/code&gt; to edit, Press &lt;code&gt;&amp;lt;Enter&amp;gt;&lt;/code&gt; to submit&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;&amp;lt;Ctrl+S&amp;gt;&lt;/code&gt; to save the changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Export to CSV&lt;/h3&gt; 
&lt;h4&gt;From Table View&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#openview-a-table"&gt;Open a table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apply filters or sorting as needed&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;E&lt;/code&gt; to open the export dialog&lt;/li&gt; 
 &lt;li&gt;Optionally modify the file path and batch size&lt;/li&gt; 
 &lt;li&gt;Select export scope: 
  &lt;ul&gt; 
   &lt;li&gt;Export Current Page: Export only the currently displayed rows&lt;/li&gt; 
   &lt;li&gt;Export All Records: Fetch and export all records from the table&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Batch size (default: 10000): When exporting all records, data is fetched in batches to avoid timeout or memory issues with large tables. Increase for faster exports, decrease if you encounter any errors.&lt;/p&gt; 
 &lt;p&gt;The default file path is &lt;code&gt;~/Downloads/{database}_{table}_{timestamp}.csv&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;From SQL Editor&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#execute-sql-queries"&gt;Execute a SQL query&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;E&lt;/code&gt; to open the export dialog&lt;/li&gt; 
 &lt;li&gt;Optionally modify the file path&lt;/li&gt; 
 &lt;li&gt;Select &lt;strong&gt;Export&lt;/strong&gt; to save all query results&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; MySQL&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; PostgreSQL&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; SQLite&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; MSSQL&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; MongoDB&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Support for multiple RDBMS is a work in progress.&lt;/p&gt; 
&lt;!-- COMMANDS --&gt; 
&lt;h2&gt;Commands&lt;/h2&gt; 
&lt;p&gt;In some cases, mostly when connecting to remote databases, it might be necessary to run a custom command before being able to connect to the database. For example when you can only access the database through a remote bastion, you would probably first need to open an SSH tunnel by running the following command in a separate terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ssh remote-bastion -L 5432:localhost:5432
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In order to make it easier to run these commands, lazysql supports running custom commands before connecting to the database. You can define these commands in the configuration file like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[[database]]
Name = 'server'
Provider = 'postgres'
DBName = 'foo'
URL = 'postgres://${user}:password@localhost:${port}/foo'
Commands = [
  { Command = 'ssh -tt remote-bastion -L ${port}:localhost:5432', WaitForPort = '${port}' },
  { Command = 'whoami', SaveOutputTo = 'user' },
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;Command&lt;/code&gt; field is required and can contain any command that you would normally run in your terminal. The &lt;code&gt;WaitForPort&lt;/code&gt; field is optional and can be used to wait for a specific port to be open before continuing. The &lt;code&gt;SaveOutputTo&lt;/code&gt; field is optional and can be used to make user-defined variables. The output (&lt;code&gt;stdout&lt;/code&gt;) from the command will be saved into the variable, and the variable can be used in the URL or future commands via the &lt;code&gt;${VARIABLE}&lt;/code&gt; syntax.&lt;/p&gt; 
&lt;p&gt;When you define the &lt;code&gt;${port}&lt;/code&gt; variable in the URL field, lazysql will automatically replace it with a random free port number. This port number will then be used in the connection URL and is available in the &lt;code&gt;Commands&lt;/code&gt; field so that you can use it to configure the command.&lt;/p&gt; 
&lt;p&gt;You can even chain commands to, for example, connect to a remote server and then to a postgres container running in a remote k8s cluster:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[[database]]
Name = 'container'
Provider = 'postgres'
DBName = 'foo'
URL = 'postgres://postgres:password@localhost:${port}/foo'
Commands = [
  { Command = 'ssh -tt remote-bastion -L 6443:localhost:6443', WaitForPort = '6443' },
  { Command = 'kubectl port-forward service/postgres ${port}:5432 --kubeconfig /path/to/kube.conf', WaitForPort = '${port}' }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- KEYBINDINGS --&gt; 
&lt;h2&gt;Keybindings&lt;/h2&gt; 
&lt;h3&gt;Global&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
   &lt;th&gt;Action&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;q&lt;/td&gt; 
   &lt;td&gt;Quit&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CTRL + e&lt;/td&gt; 
   &lt;td&gt;Open SQL editor&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Backspace&lt;/td&gt; 
   &lt;td&gt;Return to connection selection&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;Show keybindings popup&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Table&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
   &lt;th&gt;Action&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;c&lt;/td&gt; 
   &lt;td&gt;Edit table cell&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;d&lt;/td&gt; 
   &lt;td&gt;Delete row&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;o&lt;/td&gt; 
   &lt;td&gt;Add row&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;/&lt;/td&gt; 
   &lt;td&gt;Focus the filter input or SQL editor&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CTRL + s&lt;/td&gt; 
   &lt;td&gt;Commit changes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;gt;&lt;/td&gt; 
   &lt;td&gt;Next page&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;lt;&lt;/td&gt; 
   &lt;td&gt;Previous page&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;K&lt;/td&gt; 
   &lt;td&gt;Sort ASC&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;J&lt;/td&gt; 
   &lt;td&gt;Sort DESC&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;H&lt;/td&gt; 
   &lt;td&gt;Focus tree panel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;{&lt;/td&gt; 
   &lt;td&gt;Focus previous tab&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;}&lt;/td&gt; 
   &lt;td&gt;Focus next tab&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;X&lt;/td&gt; 
   &lt;td&gt;Close current tab&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;R&lt;/td&gt; 
   &lt;td&gt;Refresh the current table&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E&lt;/td&gt; 
   &lt;td&gt;Export to CSV&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Tree&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
   &lt;th&gt;Action&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L&lt;/td&gt; 
   &lt;td&gt;Focus table panel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G&lt;/td&gt; 
   &lt;td&gt;Focus last database tree node&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;g&lt;/td&gt; 
   &lt;td&gt;Focus first database tree node&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CTRL+u&lt;/td&gt; 
   &lt;td&gt;Scroll 5 items up&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CTRL+d&lt;/td&gt; 
   &lt;td&gt;Scroll 5 items down&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;SQL Editor&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
   &lt;th&gt;Action&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CTRL + R&lt;/td&gt; 
   &lt;td&gt;Run the SQL statement&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CTRL + Space&lt;/td&gt; 
   &lt;td&gt;Open external editor (Linux only)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Specific editor for lazysql can be set by &lt;code&gt;$SQL_EDITOR&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Specific terminal for opening editor can be set by &lt;code&gt;$SQL_TERMINAL&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Example connection URLs&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;postgres://user:pass@localhost/dbname
pg://user:pass@localhost/dbname?sslmode=disable
mysql://user:pass@localhost/dbname
mysql:/var/run/mysqld/mysqld.sock
sqlserver://user:pass@remote-host.com/dbname
mssql://user:pass@remote-host.com/instance/dbname
ms://user:pass@remote-host.com:port/instance/dbname?keepAlive=10
oracle://user:pass@somehost.com/sid
sap://user:pass@localhost/dbname
file:myfile.sqlite3?loc=auto
/path/to/sqlite/file/test.db
odbc+postgres://user:pass@localhost:port/dbname?option1=
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- ROADMAP --&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Support for NoSQL databases&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Columns and indexes creation through TUI&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Table tree input filter&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Custom keybindings&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Show keybindings on a modal&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Rewrite row &lt;code&gt;create&lt;/code&gt;, &lt;code&gt;update&lt;/code&gt; and &lt;code&gt;delete&lt;/code&gt; logic&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/jorgerojas26/lazysql/issues"&gt;open issues&lt;/a&gt; for a full list of proposed features (and known issues).&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;Clipboard support&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/atotto/clipboard?tab=readme-ov-file#clipboard-for-go"&gt;atotto/clipboard&lt;/a&gt; to copy to clipboard.&lt;/p&gt; 
&lt;p&gt;Platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OSX&lt;/li&gt; 
 &lt;li&gt;Windows 7 (probably work on other Windows)&lt;/li&gt; 
 &lt;li&gt;Linux, Unix (requires 'xclip' or 'xsel' command to be installed)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- CONTRIBUTING --&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions, issues, and pull requests are welcome!&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- LICENSE --&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Distributed under the MIT License. See &lt;code&gt;LICENSE.txt&lt;/code&gt; for more information.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- CONTACT --&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Jorge Rojas - &lt;a href="https://www.linkedin.com/in/jorgerojas26/"&gt;LinkedIn&lt;/a&gt; - &lt;a href="mailto:jorgeluisrojasb@gmail.com"&gt;jorgeluisrojasb@gmail.com&lt;/a&gt;&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;Alternatives&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vladbalmos/mitzasql"&gt;Mitzasql&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TaKO8Ki/gobang"&gt;Gobang&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/jorgerojas26/lazysql/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>safing/portmaster</title>
      <link>https://github.com/safing/portmaster</link>
      <description>&lt;p&gt;🏔 Love Freedom - ❌ Block Mass Surveillance&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Get Peace of Mind &lt;br /&gt; with &lt;a href="https://safing.io/"&gt;Easy Privacy&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;Portmaster is a free and open-source application firewall that does the heavy lifting for you. Restore privacy and take back control over all your computer's network activity.&lt;/p&gt; 
&lt;p&gt;With great defaults your privacy improves without any effort. And if you want to configure and control everything down to the last detail - Portmaster has you covered too. Developed in the EU 🇪🇺, Austria.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://safing.io/download/"&gt;Download for Free&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://safing.io/about/"&gt;About Us&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://safing.io/assets/img/page-specific/landing/portmaster-thumbnail.png?" alt="Portmaster User Interface" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;seen on:&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.heise.de/tests/Datenschutz-Firewall-Portmaster-im-Test-9611687.html"&gt;&lt;img src="https://safing.io/assets/img/external/heise_online.svg?sanitize=true" height="35" /&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://www.ghacks.net/2022/11/08/portmaster-1-0-released-open-source-application-firewall/"&gt;&lt;img src="https://safing.io/assets/img/external/ghacks.png" alt="ghacks.net" /&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://www.youtube.com/watch?v=E8cTRhGtmcM"&gt;&lt;img src="https://safing.io/assets/img/external/techlore.png" alt="Techlore" /&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://lifehacker.com/the-lesser-known-apps-everyone-should-install-on-a-new-1850223434"&gt;&lt;img src="https://safing.io/assets/img/external/logos/lifehacker.webp" alt="Lifehacker" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://safing.io/features/"&gt;Features&lt;/a&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Monitor All Network Activity&lt;/li&gt; 
 &lt;li&gt;Full Control: Block Anything&lt;/li&gt; 
 &lt;li&gt;Automatically Block Trackers &amp;amp; Malware&lt;/li&gt; 
 &lt;li&gt;Set Global &amp;amp; Per‑App Settings&lt;/li&gt; 
 &lt;li&gt;Secure DNS (Doh/DoT)&lt;/li&gt; 
 &lt;li&gt;Record and Search Network Activity (&lt;a href="https://safing.io/pricing/"&gt;$&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Per-App Bandwidth Usage (&lt;a href="https://safing.io/pricing/"&gt;$&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://safing.io/spn/"&gt;SPN, our Next-Gen Privacy Network&lt;/a&gt; (&lt;a href="https://safing.io/pricing/"&gt;$$&lt;/a&gt;)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Technical Introduction&lt;/h1&gt; 
&lt;p&gt;Portmaster is a privacy suite for your Windows and Linux desktop.&lt;/p&gt; 
&lt;h3&gt;Base Technology&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Portmaster integrates into network stack using nfqueue on Linux and a kernel driver (WFP) on Windows.&lt;/li&gt; 
 &lt;li&gt;Packets are intercepted at the raw packet level - every packet is seen and can be stopped.&lt;/li&gt; 
 &lt;li&gt;Ownership of connections is found using eBPF and &lt;code&gt;/proc&lt;/code&gt; on Linux and a kernel driver and the IP Helper API (&lt;code&gt;iphlpapi.dll&lt;/code&gt;) on Windows.&lt;/li&gt; 
 &lt;li&gt;Most settings can be defined per app, which can be matched in different ways.&lt;/li&gt; 
 &lt;li&gt;Support for special processes with weird or concealed paths/actors: 
  &lt;ul&gt; 
   &lt;li&gt;Snap, AppImage and Script support on Linux&lt;/li&gt; 
   &lt;li&gt;Windows Store apps and svchost.exe system services support on Windows&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Everything is 100% local on your device. (except the SPN, naturally) 
  &lt;ul&gt; 
   &lt;li&gt;Updates are fully signed and downloaded automatically.&lt;/li&gt; 
   &lt;li&gt;Intelligence data (block lists, geoip) is downloaded and applied automatically.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;The Portmaster Core Service runs as a system service, the UI elements (App, Notifier) run in user context.&lt;/li&gt; 
 &lt;li&gt;The main UI still uses electron as a wrapper :/ - but this will change in the future. You can also open the UI in the browser&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Feature: Secure DNS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Portmaster intercepts "astray" DNS queries and reroutes them to itself for seamless integration.&lt;/li&gt; 
 &lt;li&gt;DNS queries are resolved by the default or configured DoT/DoH resolvers.&lt;/li&gt; 
 &lt;li&gt;Full support for split horizon and horizon validation to defend against rebinding attacks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Feature: Privacy Filter&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Define allowed network scopes: Localhost, LAN, Internet, P2P, Inbound.&lt;/li&gt; 
 &lt;li&gt;Easy rules based on Internet entities: Domain, IP, Country and more.&lt;/li&gt; 
 &lt;li&gt;Filter Lists block common malware, ad, tracker domains etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Feature: Network History ($)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Record connections and their details in a local database and search all of it later&lt;/li&gt; 
 &lt;li&gt;Auto-delete old history or delete on demand&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Feature: Bandwidth Visibility ($)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Monitor bandwidth usage per connection and app&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Feature: SPN - Safing Privacy Network ($$)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Privacy Network aimed at use cases "between" VPN and Tor.&lt;/li&gt; 
 &lt;li&gt;Uses onion encryption over multiple hops just like Tor.&lt;/li&gt; 
 &lt;li&gt;Routes are chosen to cover most distance within the network to increase privacy.&lt;/li&gt; 
 &lt;li&gt;Exits are chosen near the destination server. This automatically geo-unblocks in many cases.&lt;/li&gt; 
 &lt;li&gt;Exclude apps and domains/entities from using SPN.&lt;/li&gt; 
 &lt;li&gt;Change routing algorithm and focus per app.&lt;/li&gt; 
 &lt;li&gt;Nodes are hosted by Safing (company behind Portmaster) and the community.&lt;/li&gt; 
 &lt;li&gt;Speeds are pretty decent (&amp;gt;100MBit/s).&lt;/li&gt; 
 &lt;li&gt;Further Reading: &lt;a href="https://safing.io/files/whitepaper/Gate17.pdf"&gt;SPN Whitepaper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;All details and guides in the dedicated &lt;a href="https://wiki.safing.io/"&gt;wiki&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://wiki.safing.io/en/Portmaster/App"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://wiki.safing.io/en/Portmaster/Install/Windows"&gt;on Windows&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://wiki.safing.io/en/Portmaster/Install/Linux"&gt;on Linux&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wiki.safing.io/en/Contribute"&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wiki.safing.io/en/Portmaster/App/Compatibility#vpn-compatibly"&gt;VPN Compatibility&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wiki.safing.io/en/Portmaster/App/Compatibility"&gt;Software Compatibility&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wiki.safing.io/en/Portmaster/Architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.safing.io/portmaster/settings"&gt;Settings Handbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.safing.io/portmaster/api"&gt;Portmaster Developer API&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Build Portmaster Yourself (WIP)&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://earthly.dev/get-earthly"&gt;Install Earthly CLI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/engine/install/"&gt;Install Docker Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;earthly +release&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Find artifacts in &lt;code&gt;./dist&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>keploy/keploy</title>
      <link>https://github.com/keploy/keploy</link>
      <description>&lt;p&gt;API, Integration, E2E Testing Agent for Developers that actually work. Generate tests, mocks/stubs for your APIs!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://docs.keploy.io/img/keploy-logo-dark.svg?s=200&amp;amp;v=4" height="80" alt="Keploy Logo" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/3262" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/3262" alt="keploy%2Fkeploy | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt;&lt;b&gt;⚡️ API tests faster than unit tests, from user traffic ⚡️&lt;/b&gt;&lt;/h3&gt; 
&lt;p align="center"&gt;🌟 The must-have tool for developers in the AI-Gen era for 90% test coverage 🌟&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg"&gt;&lt;img src="https://img.shields.io/badge/Slack-4A154B?style=flat&amp;amp;logo=slack&amp;amp;logoColor=white" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/keploy/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-%230077B5.svg?style=flat&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg"&gt;&lt;img src="https://img.shields.io/badge/YouTube-%23FF0000.svg?style=flat&amp;amp;logo=YouTube&amp;amp;logoColor=white" alt="YouTube" /&gt;&lt;/a&gt; &lt;a href="https://x.com/Keployio"&gt;&lt;img src="https://img.shields.io/badge/X-%231DA1F2.svg?style=flat&amp;amp;logo=X&amp;amp;logoColor=white" alt="X" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://landscape.cncf.io/?item=app-definition-and-development--continuous-integration-delivery--keploy"&gt; &lt;img src="https://img.shields.io/badge/CNCF%20Landscape-5699C6?logo=cncf&amp;amp;style=social" alt="Keploy CNCF Landscape" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Keploy/Keploy/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;amp;logo=github" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Keploy/Keploy/"&gt; &lt;img src="https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;amp;logo=github&amp;amp;label=Help%20us%20reach%2020K%20stars!%20Now%20at:" alt="Help us reach 20k stars!" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://keploy.io"&gt;Keploy&lt;/a&gt; is a &lt;strong&gt;developer‑centric API and integration testing tool&lt;/strong&gt; that auto‑generates &lt;strong&gt;tests and data‑mocks&lt;/strong&gt; faster than unit tests.&lt;/p&gt; 
&lt;p&gt;It records API calls, database queries, and streaming events — then replays them as tests. Under the hood, Keploy &lt;strong&gt;uses eBPF to capture traffic at the network layer,&lt;/strong&gt; but for you it’s completely &lt;strong&gt;code‑less&lt;/strong&gt; and &lt;strong&gt;language‑agnostic&lt;/strong&gt;.&lt;/p&gt; 
&lt;img align="center" src="https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-replay.gif" width="100%" alt="Convert API calls to API tests test cases and Data Mocks using AI" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🐰 &lt;strong&gt;Fun fact:&lt;/strong&gt; Keploy uses itself for testing! Check out our swanky coverage badge: &lt;a href="https://coveralls.io/github/keploy/keploy?branch=main&amp;amp;kill_cache=1"&gt;&lt;img src="https://coveralls.io/repos/github/keploy/keploy/badge.svg?branch=main&amp;amp;kill_cache=1" alt="Coverage Status" /&gt;&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Key Highlights&lt;/h1&gt; 
&lt;h2&gt;🎯 No code changes&lt;/h2&gt; 
&lt;p&gt;Just run your app with &lt;code&gt;keploy record&lt;/code&gt;. Real API + integration flows are automatically captured as tests and mocks. &lt;em&gt;(Keploy uses eBPF under the hood to capture traffic, so you &lt;strong&gt;don’t need&lt;/strong&gt; to add any SDKs or modify code.)&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;📹 Record and Replay complex Flows&lt;/h2&gt; 
&lt;p&gt;Keploy can record and replay complex, distributed API flows as mocks and stubs. It's like having a very light-weight time machine for your tests—saving you tons of time!&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://keploy.io/docs/keploy-explained/introduction/"&gt;Read the docs on record-replay&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-tc.gif" width="60%" alt="Convert API calls to test cases" /&gt; 
&lt;h2&gt;🐇 Complete Infra‑Virtualization (beyond HTTP mocks)&lt;/h2&gt; 
&lt;p&gt;Unlike tools that only mock HTTP endpoints, Keploy records &lt;strong&gt;databases&lt;/strong&gt; (Postgres, MySQL, MongoDB), &lt;strong&gt;streaming/queues&lt;/strong&gt; (Kafka, RabbitMQ), external APIs, and more.&lt;/p&gt; 
&lt;p&gt;It replays them deterministically so you can run tests without re‑provisioning infra.&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://keploy.io/docs/keploy-explained/how-keploy-works/"&gt;Read the docs on infra virtualisation&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://keploy-devrel.s3.us-west-2.amazonaws.com/Group+1261152745.png" width="100%" alt="Convert API calls to test cases" /&gt; 
&lt;h2&gt;🧪 Combined Test Coverage&lt;/h2&gt; 
&lt;p&gt;If you’re a &lt;strong&gt;developer&lt;/strong&gt;, you probably care about &lt;em&gt;statement&lt;/em&gt; and &lt;em&gt;branch&lt;/em&gt; coverage — Keploy calculates that for you.&lt;/p&gt; 
&lt;p&gt;If you’re a &lt;strong&gt;QA&lt;/strong&gt;, you focus more on &lt;em&gt;API schema&lt;/em&gt; and &lt;em&gt;business use‑case coverage&lt;/em&gt; — Keploy calculates that too. This way coverage isn’t subjective anymore.&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://keploy.io/docs/server/sdk-installation/go/"&gt;Read the docs on coverage&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://keploy-devrel.s3.us-west-2.amazonaws.com/keploy+ai+test+gen+for+api+statement+schema+and+branch+coverage.jpg" width="100%" alt="ai test gen for api statement schema and branch coverage" /&gt; 
&lt;h2&gt;🤖 Expand API Coverage using AI&lt;/h2&gt; 
&lt;p&gt;Keploy uses existing recordings, Swagger/OpenAPI Schema to find: boundary values, missing/extra fields, wrong types, out‑of‑order sequences, retries/timeouts.&lt;/p&gt; 
&lt;p&gt;This helps expand API Schema, Statement, and Branch Coverage.&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://app.keploy.io/"&gt;Read the docs on coverage&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://keploy-devrel.s3.us-west-2.amazonaws.com/ai+test+case+generation+that+works.png" width="100%" alt="ai test gen for api statement schema and branch coverage" /&gt; 
&lt;h3&gt;Other Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;🌐 &lt;strong&gt;CI/CD Integration:&lt;/strong&gt; Run tests with mocks anywhere you like—locally on the CLI, in your CI pipeline (Jenkins, Github Actions..) , or even across a Kubernetes cluster. &lt;a href="https://keploy.io/docs/running-keploy/api-testing-cicd/"&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🎭 &lt;strong&gt;Multi-Purpose Mocks&lt;/strong&gt;: You can also use Keploy-generated Mocks, as server Tests!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;📊 &lt;strong&gt;Reporting:&lt;/strong&gt; Unified reports for API, integration, unit, and e2e coverage with insights directly in your CI or PRs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🖥️ &lt;strong&gt;Console:&lt;/strong&gt; A developer-friendly console to view, manage, and debug recorded tests and mocks.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;⏱️ &lt;strong&gt;Time Freezing:&lt;/strong&gt; Deterministically replay tests by freezing system time during execution. &lt;a href="https://keploy.io/docs/keploy-cloud/time-freezing/"&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;📚 &lt;strong&gt;Mock Registry:&lt;/strong&gt; Centralized registry to manage, reuse, and version mocks across teams and environments. &lt;a href="https://keploy.io/docs/keploy-cloud/mock-registry/"&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Install Keploy Agent&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl --silent -O -L https://keploy.io/install.sh &amp;amp;&amp;amp; source install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Record Test Cases&lt;/h3&gt; 
&lt;p&gt;Start your app under Keploy to convert real API calls into tests and mocks.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;keploy record -c "CMD_TO_RUN_APP"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example for Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;keploy record -c "python main.py"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run Tests&lt;/h3&gt; 
&lt;p&gt;Run tests offline without external dependencies.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;keploy test -c "CMD_TO_RUN_APP" --delay 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;h3&gt;- 📘 &lt;a href="https://keploy.io/docs/server/installation/"&gt;Installation&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;- 🏁 &lt;a href="https://keploy.io/docs/quickstart/quickstart-filter/"&gt;QuickStarts&lt;/a&gt;&lt;/h3&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Languages &amp;amp; Frameworks (Any stack)&lt;/h2&gt; 
&lt;p&gt;Because Keploy intercepts at the &lt;strong&gt;network layer (eBPF)&lt;/strong&gt;, it works with &lt;strong&gt;any language, framework, or runtime&lt;/strong&gt;—no SDK required.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Some of the dependencies are not open-source by nature because their protocols and parsings are not open-sourced. It's not supported in Keploy enterprise.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Languages --&gt; &lt;img src="https://img.shields.io/badge/Go-00ADD8?logo=go&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Java-ED8B00?logo=openjdk&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Node.js-43853D?logo=node.js&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Python-3776AB?logo=python&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Rust-000000?logo=rust&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/C%23-239120?logo=csharp&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/C/C++-00599C?logo=cplusplus&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/TypeScript-3178C6?logo=typescript&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Scala-DC322F?logo=scala&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Kotlin-7F52FF?logo=kotlin&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Swift-FA7343?logo=swift&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Dart-0175C2?logo=dart&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/PHP-777BB4?logo=php&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Ruby-CC342D?logo=ruby&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Elixir-4B275F?logo=elixir&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/.NET-512BD4?logo=dotnet&amp;amp;logoColor=white" /&gt; 
 &lt;!-- Protocols &amp;amp; infra commonly virtualized --&gt; &lt;img src="https://img.shields.io/badge/gRPC-5E35B1?logo=grpc&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/GraphQL-E10098?logo=graphql&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/HTTP%2FREST-0A84FF?logo=httpie&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Kafka-231F20?logo=apachekafka&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/RabbitMQ-FF6600?logo=rabbitmq&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/PostgreSQL-4169E1?logo=postgresql&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/MySQL-4479A1?logo=mysql&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/MongoDB-47A248?logo=mongodb&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Redis-DC382D?logo=redis&amp;amp;logoColor=white" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Questions?&lt;/h2&gt; 
&lt;h3&gt;Book a Live Demo / Enterprise Support&lt;/h3&gt; 
&lt;p&gt;Want a guided walkthrough, dedicated support, or help planning enterprise rollout?&lt;/p&gt; 
&lt;p&gt; &lt;a href="https://calendar.app.google/4ZKd1nz9A5wLuP4W7"&gt; &lt;img src="https://img.shields.io/badge/Request%20a%20Demo-Email-2ea44f?logo=gmail" /&gt; &lt;/a&gt; &amp;nbsp; &lt;a href="https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg"&gt; &lt;img src="https://img.shields.io/badge/Chat%20with%20Us-Slack-4A154B?logo=slack&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;!-- Optional: replace with your scheduling link (Cal.com/Calendly) --&gt; 
 &lt;!-- &lt;a href="https://cal.com/keploy/demo"&gt;&lt;img src="https://img.shields.io/badge/Book%20via%20Calendar-Cal.com-111111" /&gt;&lt;/a&gt; --&gt; &lt;/p&gt; 
&lt;p&gt;Prefer a calendar invite? Mention your availability in the email—we’ll send a &lt;strong&gt;calendar invite&lt;/strong&gt; right away.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation &amp;amp; Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;📘 &lt;a href="https://keploy.io/docs/"&gt;Documentation&lt;/a&gt; — Explore the full docs&lt;/li&gt; 
 &lt;li&gt;💬 &lt;a href="https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg"&gt;Slack Community&lt;/a&gt; — Join the conversation&lt;/li&gt; 
 &lt;li&gt;📜 &lt;a href="https://keploy.io/docs/keploy-explained/contribution-guide/"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;❤️ &lt;a href="https://github.com/keploy/keploy/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📢 &lt;a href="https://keploy.io/blog/"&gt;Blog&lt;/a&gt; — Read articles and updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contribute &amp;amp; Collaborate&lt;/h2&gt; 
&lt;p&gt;Whether you're new or experienced, your input matters. Help us improve Keploy by contributing code, reporting issues, or sharing feedback.&lt;/p&gt; 
&lt;p&gt;Together, let's build better testing tools for modern applications.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>woodpecker-ci/woodpecker</title>
      <link>https://github.com/woodpecker-ci/woodpecker</link>
      <description>&lt;p&gt;Woodpecker is a simple, yet powerful CI/CD engine with great extensibility.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Woodpecker&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/woodpecker-ci/woodpecker/"&gt; &lt;img alt="Woodpecker" src="https://raw.githubusercontent.com/woodpecker-ci/woodpecker/main/docs/static/img/logo.svg?sanitize=true" width="220" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://ci.woodpecker-ci.org/repos/3780" title="Pipeline Status"&gt; &lt;img src="https://ci.woodpecker-ci.org/api/badges/3780/status.svg?sanitize=true" alt="Pipeline Status" /&gt; &lt;/a&gt; &lt;a href="https://codecov.io/gh/woodpecker-ci/woodpecker"&gt; &lt;img src="https://codecov.io/gh/woodpecker-ci/woodpecker/branch/main/graph/badge.svg?sanitize=true" alt="Code coverage" /&gt; &lt;/a&gt; &lt;a href="https://translate.woodpecker-ci.org/engage/woodpecker-ci/"&gt; &lt;img src="https://translate.woodpecker-ci.org/widgets/woodpecker-ci/-/ui/svg-badge.svg?sanitize=true" alt="Translation status" /&gt; &lt;/a&gt; &lt;a href="https://matrix.to/#/#woodpecker:matrix.org" title="Join the Matrix space at https://matrix.to/#/#woodpecker:matrix.org"&gt; &lt;img src="https://img.shields.io/matrix/woodpecker:matrix.org?label=matrix" alt="Matrix space" /&gt; &lt;/a&gt; &lt;a href="https://goreportcard.com/report/go.woodpecker-ci.org/woodpecker/v3" title="Go Report Card"&gt; &lt;img src="https://goreportcard.com/badge/go.woodpecker-ci.org/woodpecker/v3" alt="Go Report Card" /&gt; &lt;/a&gt; &lt;a href="https://pkg.go.dev/go.woodpecker-ci.org/woodpecker/v3" title="go reference"&gt; &lt;img src="https://pkg.go.dev/badge/go.woodpecker-ci.org/woodpecker/v3" alt="go reference" /&gt; &lt;/a&gt; &lt;a href="https://github.com/woodpecker-ci/woodpecker/releases/latest" title="GitHub release"&gt; &lt;img src="https://img.shields.io/github/v/release/woodpecker-ci/woodpecker?sort=semver" alt="GitHub release" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/woodpeckerci/woodpecker-server" title="Docker pulls"&gt; &lt;img src="https://img.shields.io/docker/pulls/woodpeckerci/woodpecker-server" alt="Docker pulls" /&gt; &lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0" title="License: Apache-2.0"&gt; &lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt; &lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/5309"&gt; &lt;img src="https://bestpractices.coreinfrastructure.org/projects/5309/badge" alt="OpenSSF best practices" /&gt; &lt;/a&gt; &lt;a href="https://results.pre-commit.ci/repo/github/179344069" title="pre-commit.ci"&gt; &lt;img src="https://results.pre-commit.ci/badge/github/woodpecker-ci/woodpecker/main.svg?sanitize=true" alt="pre-commit.ci" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;Woodpecker is a simple, yet powerful CI/CD engine with great extensibility.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/woodpecker-ci/woodpecker/main/docs/woodpecker.png" alt="woodpecker" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation &amp;amp; Resources&lt;/h2&gt; 
&lt;p&gt;Woodpecker can be installed in various ways (see the &lt;a href="https://woodpecker-ci.org/docs/administration/general"&gt;Installation Instructions&lt;/a&gt;) and runs with SQLite as database by default. It requires around 100 MB of RAM (Server) and 30 MB (Agent) at runtime in idle mode.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;You can support the project by becoming a backer on &lt;a href="https://opencollective.com/woodpecker-ci#category-CONTRIBUTE"&gt;Open Collective&lt;/a&gt; or via &lt;a href="https://github.com/sponsors/woodpecker-ci"&gt;GitHub Sponsors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/woodpecker-ci" target="_blank"&gt;&lt;img src="https://opencollective.com/woodpecker-ci/backers.svg?width=890" alt="Open Collective backers" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Our documentation can be found at &lt;a href="https://woodpecker-ci.org/docs/intro"&gt;https://woodpecker-ci.org/docs/intro&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Translation&lt;/h2&gt; 
&lt;p&gt;We have a self-hosted &lt;a href="https://weblate.org/en/"&gt;Weblate&lt;/a&gt; instance at &lt;a href="https://translate.woodpecker-ci.org"&gt;translate.woodpecker-ci.org&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;An overview of the current translation state is available at &lt;a href="https://translate.woodpecker-ci.org/projects/woodpecker-ci/#languages"&gt;https://translate.woodpecker-ci.org/projects/woodpecker-ci/#languages&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Public Woodpecker Instances&lt;/h2&gt; 
&lt;p&gt;Woodpecker is used as the main CI/CD engine at &lt;a href="https://codeberg.org"&gt;Codeberg&lt;/a&gt;, an alternative Git hosting platform with a focus on privacy and free software development.&lt;/p&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;Woodpecker can be extended via plugins. The &lt;a href="https://woodpecker-ci.org/plugins"&gt;plugin overview website&lt;/a&gt; helps browsing available plugins. It combines both plugins by the Woodpecker core team and community-maintained ones.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#woodpecker-ci/woodpecker&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=woodpecker-ci/woodpecker&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Woodpecker is Apache 2.0 licensed. The source files have a header indicating which license they are under and what copyrights apply.&lt;/p&gt; 
&lt;p&gt;Everything in &lt;code&gt;docs/&lt;/code&gt; is licensed under the Creative Commons Attribution-ShareAlike 4.0 International Public License.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>