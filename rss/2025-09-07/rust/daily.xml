<rss version="2.0">
  <channel>
    <title>GitHub Rust Daily Trending</title>
    <description>Daily Trending of Rust in GitHub</description>
    <pubDate>Sat, 06 Sep 2025 01:36:41 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>denoland/deno</title>
      <link>https://github.com/denoland/deno</link>
      <description>&lt;p&gt;A modern runtime for JavaScript and TypeScript.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deno&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/deno"&gt;&lt;img src="https://img.shields.io/crates/v/deno.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=deno_land"&gt;&lt;img src="https://img.shields.io/twitter/follow/deno_land.svg?style=social&amp;amp;label=Follow" alt="Twitter badge" /&gt;&lt;/a&gt; &lt;a href="https://bsky.app/profile/deno.land"&gt;&lt;img src="https://img.shields.io/badge/Follow-whitesmoke?logo=bluesky" alt="Bluesky badge" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/deno"&gt;&lt;img src="https://img.shields.io/discord/684898665143206084?logo=discord&amp;amp;style=social" alt="Discord badge" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/@deno_land"&gt;&lt;img src="https://img.shields.io/youtube/channel/subscribers/UCqC2G2M-rg4fzg1esKFLFIw?style=social" alt="YouTube badge" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img align="right" src="https://deno.land/logo.svg?sanitize=true" height="150px" alt="the deno mascot dinosaur standing in the rain" /&gt; 
&lt;p&gt;&lt;a href="https://deno.com"&gt;Deno&lt;/a&gt; (&lt;a href="https://ipa-reader.com/?text=%CB%88di%CB%90no%CA%8A"&gt;/ˈdiːnoʊ/&lt;/a&gt;, pronounced &lt;code&gt;dee-no&lt;/code&gt;) is a JavaScript, TypeScript, and WebAssembly runtime with secure defaults and a great developer experience. It's built on &lt;a href="https://v8.dev/"&gt;V8&lt;/a&gt;, &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, and &lt;a href="https://tokio.rs/"&gt;Tokio&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Learn more about the Deno runtime &lt;a href="https://docs.deno.com/runtime/manual"&gt;in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install the Deno runtime on your system using one of the commands below. Note that there are a number of ways to install Deno - a comprehensive list of installation options can be found &lt;a href="https://docs.deno.com/runtime/manual/getting_started/installation"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Shell (Mac, Linux):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -fsSL https://deno.land/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;PowerShell (Windows):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://deno.land/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://formulae.brew.sh/formula/deno"&gt;Homebrew&lt;/a&gt; (Mac):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install deno
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://chocolatey.org/packages/deno"&gt;Chocolatey&lt;/a&gt; (Windows):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;choco install deno
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://winstall.app/apps/DenoLand.Deno"&gt;WinGet&lt;/a&gt; (Windows):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;winget install --id=DenoLand.Deno
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build and install from source&lt;/h3&gt; 
&lt;p&gt;Complete instructions for building Deno from source can be found &lt;a href="https://github.com/denoland/deno/raw/main/.github/CONTRIBUTING.md#building-from-source"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Your first Deno program&lt;/h2&gt; 
&lt;p&gt;Deno can be used for many different applications, but is most commonly used to build web servers. Create a file called &lt;code&gt;server.ts&lt;/code&gt; and include the following TypeScript code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;Deno.serve((_req: Request) =&amp;gt; {
  return new Response("Hello, world!");
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run your server with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;deno run --allow-net server.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This should start a local web server on &lt;a href="http://localhost:8000"&gt;http://localhost:8000&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Learn more about writing and running Deno programs &lt;a href="https://docs.deno.com/runtime/manual"&gt;in the docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Additional resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.deno.com"&gt;Deno Docs&lt;/a&gt;&lt;/strong&gt;: official guides and reference docs for the Deno runtime, &lt;a href="https://deno.com/deploy"&gt;Deno Deploy&lt;/a&gt;, and beyond.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://jsr.io/@std"&gt;Deno Standard Library&lt;/a&gt;&lt;/strong&gt;: officially supported common utilities for Deno programs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://jsr.io/"&gt;JSR&lt;/a&gt;&lt;/strong&gt;: The open-source package registry for modern JavaScript and TypeScript&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://deno.com/blog"&gt;Developer Blog&lt;/a&gt;&lt;/strong&gt;: Product updates, tutorials, and more from the Deno team.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We appreciate your help! To contribute, please read our &lt;a href="https://raw.githubusercontent.com/denoland/deno/main/.github/CONTRIBUTING.md"&gt;contributing instructions&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zed-industries/zed</title>
      <link>https://github.com/zed-industries/zed</link>
      <description>&lt;p&gt;Code at the speed of thought – Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Zed&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://zed.dev"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json" alt="Zed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zed-industries/zed/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/zed-industries/zed/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Welcome to Zed, a high-performance, multiplayer code editor from the creators of &lt;a href="https://github.com/atom/atom"&gt;Atom&lt;/a&gt; and &lt;a href="https://github.com/tree-sitter/tree-sitter"&gt;Tree-sitter&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;On macOS and Linux you can &lt;a href="https://zed.dev/download"&gt;download Zed directly&lt;/a&gt; or &lt;a href="https://zed.dev/docs/linux#installing-via-a-package-manager"&gt;install Zed via your local package manager&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Other platforms are not yet available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows (&lt;a href="https://github.com/zed-industries/zed/issues/5394"&gt;tracking issue&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Web (&lt;a href="https://github.com/zed-industries/zed/issues/5396"&gt;tracking issue&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developing Zed&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/macos.md"&gt;Building Zed for macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/linux.md"&gt;Building Zed for Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/windows.md"&gt;Building Zed for Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/local-collaboration.md"&gt;Running Collaboration Locally&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for ways you can contribute to Zed.&lt;/p&gt; 
&lt;p&gt;Also... we're hiring! Check out our &lt;a href="https://zed.dev/jobs"&gt;jobs&lt;/a&gt; page for open roles.&lt;/p&gt; 
&lt;h3&gt;Licensing&lt;/h3&gt; 
&lt;p&gt;License information for third party dependencies must be correctly provided for CI to pass.&lt;/p&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/EmbarkStudios/cargo-about"&gt;&lt;code&gt;cargo-about&lt;/code&gt;&lt;/a&gt; to automatically comply with open source licenses. If CI is failing, check the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Is it showing a &lt;code&gt;no license specified&lt;/code&gt; error for a crate you've created? If so, add &lt;code&gt;publish = false&lt;/code&gt; under &lt;code&gt;[package]&lt;/code&gt; in your crate's Cargo.toml.&lt;/li&gt; 
 &lt;li&gt;Is the error &lt;code&gt;failed to satisfy license requirements&lt;/code&gt; for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license's requirements. If you're unsure, ask a lawyer. Once you've verified that this system is acceptable add the license's SPDX identifier to the &lt;code&gt;accepted&lt;/code&gt; array in &lt;code&gt;script/licenses/zed-licenses.toml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Is &lt;code&gt;cargo-about&lt;/code&gt; unable to find the license for a dependency? If so, add a clarification field at the end of &lt;code&gt;script/licenses/zed-licenses.toml&lt;/code&gt;, as specified in the &lt;a href="https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration"&gt;cargo-about book&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ast-grep/ast-grep</title>
      <link>https://github.com/ast-grep/ast-grep</link>
      <description>&lt;p&gt;⚡A CLI tool for code structural search, lint and rewriting. Written in Rust&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://ast-grep.github.io/logo.svg?sanitize=true" alt="ast-grep" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/ast-grep/ast-grep/actions/workflows/coverage.yaml/badge.svg?sanitize=true" alt="coverage badge" /&gt; &lt;a href="https://app.codecov.io/gh/ast-grep/ast-grep"&gt;&lt;img src="https://codecov.io/gh/ast-grep/ast-grep/branch/main/graph/badge.svg?token=37VX8H2EWV" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/4YZjf6htSQ" target="_blank"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1107749847722889217?label=Discord" /&gt;&lt;/a&gt; &lt;a href="https://repology.org/project/ast-grep/versions" target="_blank"&gt;&lt;img alt="Repology" src="https://repology.org/badge/tiny-repos/ast-grep.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/ast-grep/ast-grep?style=social" alt="Badge" /&gt; &lt;img src="https://img.shields.io/github/forks/ast-grep/ast-grep?style=social" alt="Badge" /&gt; &lt;img alt="GitHub Sponsors" src="https://img.shields.io/github/sponsors/HerringtonDarkholme?style=social" /&gt; &lt;a href="https://gurubase.io/g/ast-grep"&gt;&lt;img alt="Gurubase" src="https://img.shields.io/badge/Gurubase-Ask%20ast--grep%20Guru-006BFF" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;ast-grep(sg)&lt;/h2&gt; 
&lt;p&gt;ast-grep(sg) is a CLI tool for code structural search, lint, and rewriting.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;ast-grep is an &lt;a href="https://dev.to/balapriya/abstract-syntax-tree-ast-explained-in-plain-english-1h38"&gt;abstract syntax tree&lt;/a&gt; based tool to search code by pattern code. Think of it as your old-friend &lt;a href="https://en.wikipedia.org/wiki/Grep#:~:text=grep%20is%20a%20command%2Dline,which%20has%20the%20same%20effect."&gt;&lt;code&gt;grep&lt;/code&gt;&lt;/a&gt;, but matching AST nodes instead of text. You can write patterns as if you are writing ordinary code. It will match all code that has the same syntactical structure. You can use &lt;code&gt;$&lt;/code&gt; sign + upper case letters as a &lt;a href="https://en.wikipedia.org/wiki/Wildcard_character"&gt;wildcard&lt;/a&gt;, e.g. &lt;code&gt;$MATCH&lt;/code&gt;, to match any single AST node. Think of it as &lt;a href="https://regexone.com/lesson/wildcards_dot"&gt;regular expression dot&lt;/a&gt; &lt;code&gt;.&lt;/code&gt;, except it is not textual.&lt;/p&gt; 
&lt;p&gt;Try the &lt;a href="https://ast-grep.github.io/playground.html"&gt;online playground&lt;/a&gt; for a taste!&lt;/p&gt; 
&lt;h2&gt;Screenshot&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://ast-grep.github.io/image/search-replace.png" alt="demo" /&gt;&lt;/p&gt; 
&lt;p&gt;See more screenshots on the &lt;a href="https://ast-grep.github.io/"&gt;website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can install it from &lt;a href="https://docs.npmjs.com/downloading-and-installing-node-js-and-npm"&gt;npm&lt;/a&gt;, &lt;a href="https://pypi.org/"&gt;pip&lt;/a&gt;, &lt;a href="https://doc.rust-lang.org/cargo/getting-started/installation.html"&gt;cargo&lt;/a&gt;, &lt;a href="https://github.com/cargo-bins/cargo-binstall"&gt;cargo-binstall&lt;/a&gt;, &lt;a href="https://brew.sh/"&gt;homebrew&lt;/a&gt;, &lt;a href="https://scoop.sh/"&gt;scoop&lt;/a&gt; or &lt;a href="https://www.macports.org"&gt;MacPorts&lt;/a&gt;!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install --global @ast-grep/cli
pip install ast-grep-cli
brew install ast-grep
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click for more installation methods&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cargo install ast-grep --locked
cargo binstall ast-grep

# install via scoop, thank @brian6932
scoop install main/ast-grep

# install via MacPorts
sudo port install ast-grep

# try ast-grep in nix-shell
nix-shell -p ast-grep
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;Or you can build ast-grep from source. You need to install rustup, clone the repository and then&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install --path ./crates/cli --locked
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/ast-grep/versions"&gt;Packages&lt;/a&gt; are available on other platforms too.&lt;/p&gt; 
&lt;h2&gt;Command line usage example&lt;/h2&gt; 
&lt;p&gt;ast-grep has following form.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ast-grep --pattern 'var code = $PATTERN' --rewrite 'let code = new $PATTERN' --lang ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Hchan_mgn/status/1547061516993699841?s=20&amp;amp;t=ldDoj4U2nq-FRKQkU5GWXA"&gt;Rewrite code in null coalescing operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ast-grep -p '$A &amp;amp;&amp;amp; $A()' -l ts -r '$A?.()'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Hchan_mgn/status/1561802312846278657"&gt;Rewrite&lt;/a&gt; &lt;a href="https://github.com/ecyrbe/zodios#migrate-to-v8"&gt;Zodios&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ast-grep -p 'new Zodios($URL,  $CONF as const,)' -l ts -r 'new Zodios($URL, $CONF)' -i
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Hchan_mgn/status/1560108625460355073"&gt;Implement eslint rule using YAML.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsor&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HerringtonDarkholme/sponsors/main/sponsorkit/sponsors.svg?sanitize=true" alt="Sponsors" /&gt;&lt;/p&gt; 
&lt;p&gt;If you find ast-grep interesting and useful for your work, please &lt;a href="https://github.com/sponsors/HerringtonDarkholme"&gt;buy me a coffee&lt;/a&gt; so I can spend more time on the project!&lt;/p&gt; 
&lt;h2&gt;Feature Highlight&lt;/h2&gt; 
&lt;p&gt;ast-grep's core is an algorithm to search and replace code based on abstract syntax tree produced by tree-sitter. It can help you to do lightweight static analysis and massive scale code manipulation in an intuitive way.&lt;/p&gt; 
&lt;p&gt;Key highlights:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;An intuitive pattern to find and replace AST. ast-grep's pattern looks like ordinary code you would write every day (you could say the pattern is isomorphic to code).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;jQuery like API for AST traversal and manipulation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;YAML configuration to write new linting rules or code modification.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Written in compiled language, with tree-sitter based parsing and utilizing multiple cores.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Beautiful command line interface :)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ast-grep's vision is to democratize abstract syntax tree magic and to liberate one from cumbersome AST programming!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you are an open-source library author, ast-grep can help your library users adopt breaking changes more easily.&lt;/li&gt; 
 &lt;li&gt;if you are a tech lead in your team, ast-grep can help you enforce code best practice tailored to your business need.&lt;/li&gt; 
 &lt;li&gt;If you are a security researcher, ast-grep can help you write rules much faster.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/uv</title>
      <link>https://github.com/astral-sh/uv</link>
      <description>&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;uv&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json" alt="uv" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/v/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/l/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv/actions"&gt;&lt;img src="https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Actions status" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
  &lt;img alt="Shows a bar chart with benchmark results." src="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Installing &lt;a href="https://trio.readthedocs.io/"&gt;Trio&lt;/a&gt;'s dependencies with a warm cache.&lt;/i&gt; &lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🚀 A single tool to replace &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;twine&lt;/code&gt;, &lt;code&gt;virtualenv&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;⚡️ &lt;a href="https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md"&gt;10-100x faster&lt;/a&gt; than &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;🗂️ Provides &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#projects"&gt;comprehensive project management&lt;/a&gt;, with a &lt;a href="https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile"&gt;universal lockfile&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;❇️ &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#scripts"&gt;Runs scripts&lt;/a&gt;, with support for &lt;a href="https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies"&gt;inline dependency metadata&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;🐍 &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#python-versions"&gt;Installs and manages&lt;/a&gt; Python versions.&lt;/li&gt; 
 &lt;li&gt;🛠️ &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#tools"&gt;Runs and installs&lt;/a&gt; tools published as Python packages.&lt;/li&gt; 
 &lt;li&gt;🔩 Includes a &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#the-pip-interface"&gt;pip-compatible interface&lt;/a&gt; for a performance boost with a familiar CLI.&lt;/li&gt; 
 &lt;li&gt;🏢 Supports Cargo-style &lt;a href="https://docs.astral.sh/uv/concepts/projects/workspaces"&gt;workspaces&lt;/a&gt; for scalable projects.&lt;/li&gt; 
 &lt;li&gt;💾 Disk-space efficient, with a &lt;a href="https://docs.astral.sh/uv/concepts/cache"&gt;global cache&lt;/a&gt; for dependency deduplication.&lt;/li&gt; 
 &lt;li&gt;⏬ Installable without Rust or Python via &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;🖥️ Supports macOS, Linux, and Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uv is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;, the creators of &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install uv with our standalone installers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, from &lt;a href="https://pypi.org/project/uv/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# With pip.
pip install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Or pipx.
pipx install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If installed via the standalone installer, uv can update itself to the latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv self update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;installation documentation&lt;/a&gt; for details and alternative installation methods.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;uv's documentation is available at &lt;a href="https://docs.astral.sh/uv"&gt;docs.astral.sh/uv&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, the command line reference documentation can be viewed with &lt;code&gt;uv help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Projects&lt;/h3&gt; 
&lt;p&gt;uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to &lt;code&gt;rye&lt;/code&gt; or &lt;code&gt;poetry&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/projects/"&gt;project documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;uv also supports building and publishing projects, even if they're not managed with uv. See the &lt;a href="https://docs.astral.sh/uv/guides/publish/"&gt;publish guide&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h3&gt;Scripts&lt;/h3&gt; 
&lt;p&gt;uv manages dependencies and environments for single-file scripts.&lt;/p&gt; 
&lt;p&gt;Create a new script and add inline metadata declaring its dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ echo 'import requests; print(requests.get("https://astral.sh"))' &amp;gt; example.py

$ uv add --script example.py requests
Updated `example.py`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the script in an isolated virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&amp;lt;Response [200]&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/scripts/"&gt;scripts documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;uv executes and installs command-line tools provided by Python packages, similar to &lt;code&gt;pipx&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Run a tool in an ephemeral environment using &lt;code&gt;uvx&lt;/code&gt; (an alias for &lt;code&gt;uv tool run&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uvx pycowsay 'hello world!'
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  """

  ------------
&amp;lt; hello world! &amp;gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install a tool with &lt;code&gt;uv tool install&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/tools/"&gt;tools documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Python versions&lt;/h3&gt; 
&lt;p&gt;uv installs Python and allows quickly switching between versions.&lt;/p&gt; 
&lt;p&gt;Install multiple Python versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download Python versions as needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use a specific Python version in the current directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python pin 3.11
Pinned `.python-version` to `3.11`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/install-python/"&gt;Python installation documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;The pip interface&lt;/h3&gt; 
&lt;p&gt;uv provides a drop-in replacement for common &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more.&lt;/p&gt; 
&lt;p&gt;Migrate to uv without changing your existing workflows — and experience a 10-100x speedup — with the &lt;code&gt;uv pip&lt;/code&gt; interface.&lt;/p&gt; 
&lt;p&gt;Compile requirements into a platform-independent requirements file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the locked requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/pip/index/"&gt;pip interface documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/platforms/"&gt;platform support&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Versioning policy&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/versioning/"&gt;versioning policy&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the &lt;a href="https://github.com/astral-sh/uv/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h4&gt;How do you pronounce uv?&lt;/h4&gt; 
&lt;p&gt;It's pronounced as "you - vee" (&lt;a href="https://en.wikipedia.org/wiki/Help:IPA/English#Key"&gt;&lt;code&gt;/juː viː/&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; 
&lt;h4&gt;How should I stylize uv?&lt;/h4&gt; 
&lt;p&gt;Just "uv", please. See the &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/STYLE.md#styling-uv"&gt;style guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;uv's dependency resolver uses &lt;a href="https://github.com/pubgrub-rs/pubgrub"&gt;PubGrub&lt;/a&gt; under the hood. We're grateful to the PubGrub maintainers, especially &lt;a href="https://github.com/Eh2406"&gt;Jacob Finkelman&lt;/a&gt;, for their support.&lt;/p&gt; 
&lt;p&gt;uv's Git implementation is based on &lt;a href="https://github.com/rust-lang/cargo"&gt;Cargo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some of uv's optimizations are inspired by the great work we've seen in &lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt;, &lt;a href="https://github.com/orogene/orogene"&gt;Orogene&lt;/a&gt;, and &lt;a href="https://github.com/oven-sh/bun"&gt;Bun&lt;/a&gt;. We've also learned a lot from Nathaniel J. Smith's &lt;a href="https://github.com/njsmith/posy"&gt;Posy&lt;/a&gt; and adapted its &lt;a href="https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline"&gt;trampoline&lt;/a&gt; for Windows support.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uv is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral" /&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>helix-editor/helix</title>
      <link>https://github.com/helix-editor/helix</link>
      <description>&lt;p&gt;A post-modern modal text editor.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="logo_dark.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="logo_light.svg" /&gt; 
   &lt;img alt="Helix" height="128" src="https://raw.githubusercontent.com/helix-editor/helix/master/logo_light.svg?sanitize=true" /&gt; 
  &lt;/picture&gt; &lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/actions"&gt;&lt;img src="https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/helix-editor/helix" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://docs.helix-editor.com/"&gt;&lt;img src="https://shields.io/badge/-documentation-452859" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/helix-editor/helix" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/#helix-community:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/helix-community:matrix.org" alt="Matrix Space" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/helix-editor/helix/master/screenshot.png" alt="Screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://github.com/mawww/kakoune"&gt;Kakoune&lt;/a&gt; / &lt;a href="https://github.com/neovim/neovim"&gt;Neovim&lt;/a&gt; inspired editor, written in Rust.&lt;/p&gt; 
&lt;p&gt;The editing model is very heavily based on Kakoune; during development I found myself agreeing with most of Kakoune's design decisions.&lt;/p&gt; 
&lt;p&gt;For more information, see the &lt;a href="https://helix-editor.com"&gt;website&lt;/a&gt; or &lt;a href="https://docs.helix-editor.com/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All shortcuts/keymaps can be found &lt;a href="https://docs.helix-editor.com/keymap.html"&gt;in the documentation on the website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/wiki/Troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vim-like modal editing&lt;/li&gt; 
 &lt;li&gt;Multiple selections&lt;/li&gt; 
 &lt;li&gt;Built-in language server support&lt;/li&gt; 
 &lt;li&gt;Smart, incremental syntax highlighting and code editing via tree-sitter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although it's primarily a terminal-based editor, I am interested in exploring a custom renderer (similar to Emacs) using wgpu or skulpin.&lt;/p&gt; 
&lt;p&gt;Note: Only certain languages have indentation definitions at the moment. Check &lt;code&gt;runtime/queries/&amp;lt;lang&amp;gt;/&lt;/code&gt; for &lt;code&gt;indents.scm&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://docs.helix-editor.com/install.html"&gt;Installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/helix-editor/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Contributing guidelines can be found &lt;a href="https://raw.githubusercontent.com/helix-editor/helix/master/docs/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Getting help&lt;/h1&gt; 
&lt;p&gt;Your question might already be answered on the &lt;a href="https://github.com/helix-editor/helix/wiki/FAQ"&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Discuss the project on the community &lt;a href="https://matrix.to/#/#helix-community:matrix.org"&gt;Matrix Space&lt;/a&gt; (make sure to join &lt;code&gt;#helix-editor:matrix.org&lt;/code&gt; if you're on a client that doesn't support Matrix Spaces yet).&lt;/p&gt; 
&lt;h1&gt;Credits&lt;/h1&gt; 
&lt;p&gt;Thanks to &lt;a href="https://github.com/jakenvac"&gt;@jakenvac&lt;/a&gt; for designing the logo!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zama-ai/fhevm</title>
      <link>https://github.com/zama-ai/fhevm</link>
      <description>&lt;p&gt;FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/.gitbook/assets/fhevm-header-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/.gitbook/assets/fhevm-header-light.png" /&gt; 
  &lt;img width="500" alt="fhevm" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/fhevm-whitepaper.pdf"&gt; 📃 Read white paper&lt;/a&gt; |&lt;a href="https://docs.zama.ai/protocol"&gt; 📒 Documentation&lt;/a&gt; | &lt;a href="https://zama.ai/community"&gt; 💛 Community support&lt;/a&gt; | &lt;a href="https://github.com/zama-ai/awesome-zama"&gt; 📚 FHE resources by Zama&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/zama-ai/fhevm/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/zama-ai/fhevm?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zama-ai/fhevm/raw/main/LICENSE"&gt; 
  &lt;!-- markdown-link-check-disable-next-line --&gt; &lt;img src="https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zama-ai/bounty-program"&gt; 
  &lt;!-- markdown-link-check-disable-next-line --&gt; &lt;img src="https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img alt="SLSA 3" src="https://slsa.dev/images/gh-badge-level3.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;h3&gt;What is FHEVM?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;FHEVM&lt;/strong&gt; is the core framework of the &lt;em&gt;Zama Confidential Blockchain Protocol&lt;/em&gt;. It enables confidential smart contracts on EVM-compatible blockchains by leveraging Fully Homomorphic Encryption (FHE), allowing encrypted data to be processed directly onchain.&lt;/p&gt; 
&lt;p&gt;FHEVM ensures both confidentiality and composability, with the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end encryption of transactions and state:&lt;/strong&gt; Data included in transactions is encrypted and never visible to anyone.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Composability and data availability on-chain:&lt;/strong&gt; States are updated while remaining encrypted at all times.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No impact on existing dApps and state:&lt;/strong&gt; Encrypted state co-exists alongside public one, and doesn't impact existing dApps. &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Table of contents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt;About&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#what-is-fhevm"&gt;What is FHEVM?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#project-structure"&gt;Project structure&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#main-features"&gt;Main features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#use-cases"&gt;Use cases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#working-with-fhevm"&gt;Working with FHEVM&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#citations"&gt;Citations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#support"&gt;Support&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Project structure&lt;/h3&gt; 
&lt;p&gt;The directories of this repository are organized in the following way:&lt;/p&gt; 
&lt;h6&gt;FHEVM Contracts&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;gateway-contracts/&lt;/code&gt;&lt;/strong&gt;: Smart contracts managing the gateway between on-chain and off-chain components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;host-contracts/&lt;/code&gt;&lt;/strong&gt;: Smart Contracts deployed on the host chain for orchestrating FHE workflows.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;FHEVM Compute Engines&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;coprocessor/&lt;/code&gt;&lt;/strong&gt;: Rust-based coprocessor implementation for FHE operations.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;kms-connector/&lt;/code&gt;&lt;/strong&gt;: Interface for integrating with Key Management Services (KMS) to handle encryption keys securely.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;FHEVM Utilities&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;charts/&lt;/code&gt;&lt;/strong&gt;: Helm charts and deployment configurations for the stack.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;golden-container-images/&lt;/code&gt;&lt;/strong&gt;: Docker golden images for Node.js and Rust environments used as base images by the stack.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;test-suite/&lt;/code&gt;&lt;/strong&gt;: Integration with docker-compose and tests covering end-to-end FHEVM stack behavior.&lt;/p&gt; &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Main features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy by design:&lt;/strong&gt; Building decentralized apps with full privacy and confidentiality on Ethereum, leveraging FHE.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solidity integration:&lt;/strong&gt; Write FHEVM contracts like any standard Solidity contract using Solidity. Compatible with existing toolchains — such as Hardhat and Foundry (&lt;em&gt;coming soon&lt;/em&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Programmable privacy:&lt;/strong&gt; Define exactly what data is encrypted and write the access control logic directly in your smart contracts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High precision encrypted integers :&lt;/strong&gt; Up to 256 bits of precision for integers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full range of operators:&lt;/strong&gt; All typical operators are available: &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;, ternary-if, boolean operations…. Consecutive FHE operations are not limited.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security:&lt;/strong&gt; The underlying FHE crypto-scheme of FHEVM is quantum-resistant. Decryption is managed via a key management system (KMS) using multi-party computation (MPC), ensuring security even if some parties are compromised or misbehaving.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Symbolic execution of FHE computations:&lt;/strong&gt; All FHE operations are executed symbolically on the host chain, significantly reducing execution time. The actual computations on encrypted data are offloaded asynchronously to our coprocessor, allowing for faster, efficient, and scalable processing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Learn more about FHEVM features in the &lt;a href="https://docs.zama.ai/protocol"&gt;documentation&lt;/a&gt; and in our &lt;a href="https://github.com/zama-ai/fhevm/raw/main/fhevm-whitepaper.pdf"&gt;whitepaper&lt;/a&gt;.&lt;/em&gt; &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Use cases&lt;/h3&gt; 
&lt;p&gt;FHEVM is built for developers to write confidential smart contracts without the need to learn cryptography. Leveraging FHEVM, you can unlock a myriad of new use cases such as DeFi, gaming, and more. For instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Confidential transfers&lt;/strong&gt;: Keep balances and amounts private, without using mixers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tokenization&lt;/strong&gt;: Swap tokens and RWAs on-chain without others seeing the amounts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Blind auctions&lt;/strong&gt;: Bid on items without revealing the amount or the winner.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-chain games&lt;/strong&gt;: Keep moves, selections, cards, or items hidden until ready to reveal.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Confidential voting&lt;/strong&gt;: Prevents bribery and blackmailing by keeping votes private.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Encrypted DIDs&lt;/strong&gt;: Store identities on-chain and generate attestations without ZK.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Learn more use cases in the &lt;a href="https://docs.zama.ai/protocol/examples"&gt;list of examples&lt;/a&gt;.&lt;/em&gt; &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.zama.ai/protocol"&gt;Documentation&lt;/a&gt; — Official documentation of FHEVM.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/fhevm-whitepaper.pdf"&gt;Whitepaper&lt;/a&gt; — Technical overview of FHEVM's cryptographic design.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.zama.ai/protocol/examples"&gt;Examples&lt;/a&gt; — Examples of building confidential smart contracts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zama-ai/awesome-zama?tab=readme-ov-file#fhevm"&gt;Awesome Zama – FHEVM&lt;/a&gt; — Curated articles, talks, and ecosystem projects.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt; ↑ Back to top &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Working with FHEVM&lt;/h2&gt; 
&lt;h3&gt;Citations&lt;/h3&gt; 
&lt;p&gt;To cite FHEVM or the whitepaper in academic papers, please use the following entries:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;@Misc{FHEVM,
title={{FHEVM: A full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications},
author={Zama},
year={2025},
note={\url{https://github.com/zama-ai/fhevm}},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;There are two ways to contribute to FHEVM:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zama-ai/fhevm/issues/new/choose"&gt;Open issues&lt;/a&gt; to report bugs and typos, or to suggest new ideas&lt;/li&gt; 
 &lt;li&gt;Request to become an official contributor by emailing &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do! &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;This software is distributed under the &lt;strong&gt;BSD-3-Clause-Clear&lt;/strong&gt; license. Read &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/LICENSE"&gt;this&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Is Zama’s technology free to use?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Zama’s libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama's open source code, companies must purchase Zama’s commercial patent license.&lt;/p&gt; 
 &lt;p&gt;Everything we do is open source, and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in &lt;a href="https://www.zama.ai/post/open-source"&gt;this blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;What do I need to do if I want to use Zama’s technology for commercial purposes?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To commercially use Zama’s technology you need to be granted Zama’s patent license. Please contact us at &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Do you file IP on your technology?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Yes, all Zama’s technologies are patented.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Can you customize a solution for my specific use case?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;a target="_blank" href="https://community.zama.ai"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/.gitbook/assets/support-banner-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/.gitbook/assets/support-banner-light.png" /&gt; 
  &lt;img alt="Support" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;🌟 If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development.&lt;/p&gt; 
&lt;p align="right"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt; ↑ Back to top &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>idootop/open-xiaoai</title>
      <link>https://github.com/idootop/open-xiaoai</link>
      <description>&lt;p&gt;让小爱音箱「听见你的声音」，解锁无限可能。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open-XiaoAI&lt;/h1&gt; 
&lt;p&gt;让小爱音箱「听见你的声音」，解锁无限可能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/images/cover.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;简介&lt;/h2&gt; 
&lt;p&gt;2017 年，当全球首款千万级销量的智能音箱诞生时，我们以为触摸到了未来。但很快发现，这些设备被困在「指令-响应」的牢笼里：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;它听得见分贝，却听不懂情感&lt;/li&gt; 
 &lt;li&gt;它能执行命令，却不会主动思考&lt;/li&gt; 
 &lt;li&gt;它有千万用户，却只有一套思维&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们曾幻想中的"贾维斯"级人工智能，在现实场景中沦为"天气预报+音乐播放器"。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;真正的智能不应被预设的代码逻辑所束缚，而应像生命体般在交互中进化。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在上一个 &lt;a href="https://github.com/idootop/mi-gpt"&gt;MiGPT&lt;/a&gt; 项目中，我们已经实现将 ChatGPT 接入到小爱音箱。&lt;/p&gt; 
&lt;p&gt;这一次 &lt;a href="https://github.com/idootop/open-xiaoai"&gt;Open-XiaoAI&lt;/a&gt; 再次进化，直接接管小爱音箱的“耳朵”和“嘴巴”，&lt;/p&gt; 
&lt;p&gt;通过多模态大模型和 AI Agent，将小爱音箱的潜力完全释放，解锁无限可能。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;未来由你定义!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;你的声音 + 小爱音箱 = 无限可能&lt;/h2&gt; 
&lt;p&gt;👉 &lt;a href="https://www.bilibili.com/video/BV1TxJhzvEhz"&gt;小爱音箱接入小智 AI 演示视频&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1TxJhzvEhz"&gt;&lt;img src="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/images/xiaozhi.jpg" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://www.bilibili.com/video/BV1YfVUz5EMj"&gt;小爱音箱自定义唤醒词演示视频&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1YfVUz5EMj"&gt;&lt;img src="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/images/kws.jpg" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://www.bilibili.com/video/BV1N1421y7qn"&gt;小爱音箱接入 MiGPT 演示视频&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1N1421y7qn"&gt;&lt;img src="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/images/migpt.jpg" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;快速开始&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] 本教程仅适用于 &lt;strong&gt;小爱音箱 Pro（LX06）&lt;/strong&gt; 和 &lt;strong&gt;Xiaomi 智能音箱 Pro（OH2P）&lt;/strong&gt; 这两款机型，&lt;strong&gt;其他型号&lt;/strong&gt;的小爱音箱请勿直接使用！🚨&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;本项目由 Client 端 + Server 端两部分组成，你可以按照以下顺序运行该项目：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;刷机更新小爱音箱补丁固件，开启并 SSH 连接到小爱音箱 👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/flash.md"&gt;教程&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;在小爱音箱上安装运行 Client 端补丁程序 👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/packages/client-rust/README.md"&gt;教程&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;运行以下演示程序，体验小爱音箱的全新能力 ✨ 
  &lt;ul&gt; 
   &lt;li&gt;👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/examples/xiaozhi/README.md"&gt;小爱音箱接入小智 AI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/examples/kws/README.md"&gt;小爱音箱自定义唤醒词&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/examples/migpt/README.md"&gt;小爱音箱接入 MiGPT（完美版）&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/examples/gemini/README.md"&gt;小爱音箱接入 Gemini Live API&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;以上皆为抛砖引玉，你也可以亲手编写自己想要的功能，一切由你定义！&lt;/p&gt; 
&lt;h2&gt;相关项目&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] 技术的意义在于分享与共创。如果你打算或正在使用本项目做些有趣的事情， 欢迎提交 PR 或 issue 分享你的项目和创意。✨&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;如果你不想刷机，或者不是小爱音箱 Pro，下面的项目或许对你有用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/idootop/mi-gpt"&gt;https://github.com/idootop/mi-gpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/idootop/migpt-next"&gt;https://github.com/idootop/migpt-next&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yihong0618/xiaogpt"&gt;https://github.com/yihong0618/xiaogpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hanxi/xiaomusic"&gt;https://github.com/hanxi/xiaomusic&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;参考链接&lt;/h2&gt; 
&lt;p&gt;如果你想要了解更多技术细节，下面的链接可能对你有用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yihong0618/gitblog/issues/258"&gt;https://github.com/yihong0618/gitblog/issues/258&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jialeicui/open-lx01"&gt;https://github.com/jialeicui/open-lx01&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/duhow/xiaoai-patch"&gt;https://github.com/duhow/xiaoai-patch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://javabin.cn/2021/xiaoai_fm.html"&gt;https://javabin.cn/2021/xiaoai_fm.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xuanxuanblingbling.github.io/iot/2022/09/16/mi/"&gt;https://xuanxuanblingbling.github.io/iot/2022/09/16/mi/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;免责声明&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;适用范围&lt;/strong&gt; 本项目为开源非营利项目，仅供学术研究或个人测试用途。严禁用于商业服务、网络攻击、数据窃取、系统破坏等违反《网络安全法》及使用者所在地司法管辖区的法律规定的场景。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;非官方声明&lt;/strong&gt; 本项目由第三方开发者独立开发，与小米集团及其关联方（下称"权利方"）无任何隶属/合作关系，亦未获其官方授权/认可或技术支持。项目中涉及的商标、固件、云服务的所有权利归属小米集团。若权利方主张权益，使用者应立即主动停止使用并删除本项目。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;继续下载或运行本项目，即表示您已完整阅读并同意&lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/agreement.md"&gt;用户协议&lt;/a&gt;，否则请立即终止使用并彻底删除本项目。&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/LICENSE"&gt;MIT&lt;/a&gt; License © 2024-PRESENT Del Wang&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aws/amazon-q-developer-cli</title>
      <link>https://github.com/aws/amazon-q-developer-cli</link>
      <description>&lt;p&gt;✨ Agentic chat experience in your terminal. Build applications using natural language.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Amazon Q CLI&lt;/h1&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;DMG&lt;/strong&gt;: &lt;a href="https://desktop-release.q.us-east-1.amazonaws.com/latest/Amazon%20Q.dmg"&gt;Download now&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-ubuntu"&gt;Ubuntu/Debian&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-appimage"&gt;AppImage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-alternative-linux"&gt;Alternative Linux builds&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you so much for considering to contribute to Amazon Q.&lt;/p&gt; 
&lt;p&gt;Before getting started, see our &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/CONTRIBUTING.md#security-issue-notifications"&gt;contributing docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;MacOS 
  &lt;ul&gt; 
   &lt;li&gt;Xcode 13 or later&lt;/li&gt; 
   &lt;li&gt;Brew&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1. Clone repo&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/aws/amazon-q-developer-cli.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Install the Rust toolchain using &lt;a href="https://rustup.rs"&gt;Rustup&lt;/a&gt;:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup default stable
rustup toolchain install nightly
cargo install typos-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Develop locally&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;To compile and run: &lt;code&gt;cargo run --bin chat_cli&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To run tests: &lt;code&gt;cargo test&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To run lints: &lt;code&gt;cargo clippy&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To format rust files: &lt;code&gt;cargo +nightly fmt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To run subcommands: &lt;code&gt;cargo run --bin chat_cli -- {subcommand}&lt;/code&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;Login would then be: &lt;code&gt;cargo run --bin chat_cli -- login&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Project Layout&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/crates/chat_cli/"&gt;&lt;code&gt;chat_cli&lt;/code&gt;&lt;/a&gt; - the &lt;code&gt;q&lt;/code&gt; CLI, allows users to interface with Amazon Q Developer from the command line&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/scripts/"&gt;&lt;code&gt;scripts/&lt;/code&gt;&lt;/a&gt; - Contains ops and build related scripts&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/crates/"&gt;&lt;code&gt;crates/&lt;/code&gt;&lt;/a&gt; - Contains all rust crates&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/docs/"&gt;&lt;code&gt;docs/&lt;/code&gt;&lt;/a&gt; - Contains technical documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;For security related concerns, see &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/SECURITY.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;This repo is dual licensed under MIT and Apache 2.0 licenses.&lt;/p&gt; 
&lt;p&gt;Those licenses can be found &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/LICENSE.MIT"&gt;here&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/LICENSE.APACHE"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;“Amazon Web Services” and all related marks, including logos, graphic designs, and service names, are trademarks or trade dress of AWS in the U.S. and other countries. AWS’s trademarks and trade dress may not be used in connection with any product or service that is not AWS’s, in any manner that is likely to cause confusion among customers, or in any manner that disparages or discredits AWS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mainmatter/100-exercises-to-learn-rust</title>
      <link>https://github.com/mainmatter/100-exercises-to-learn-rust</link>
      <description>&lt;p&gt;A self-paced course to learn Rust, one exercise at a time.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Learn Rust, one exercise at a time&lt;/h1&gt; 
&lt;p&gt;You've heard about Rust, but you never had the chance to try it out?&lt;br /&gt; This course is for you!&lt;/p&gt; 
&lt;p&gt;You'll learn Rust by solving 100 exercises.&lt;br /&gt; You'll go from knowing nothing about Rust to being able to start writing your own programs, one exercise at a time.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This course has been written by &lt;a href="https://mainmatter.com/rust-consulting/"&gt;Mainmatter&lt;/a&gt;.&lt;br /&gt; It's one of the trainings in &lt;a href="https://mainmatter.com/services/workshops/rust/"&gt;our portfolio of Rust workshops&lt;/a&gt;.&lt;br /&gt; Check out our &lt;a href="https://mainmatter.com/rust-consulting/"&gt;landing page&lt;/a&gt; if you're looking for Rust consulting or training!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Go to &lt;a href="https://rust-exercises.com"&gt;rust-exercises.com&lt;/a&gt; and follow the instructions there to get started with the course.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Rust&lt;/strong&gt; (follow instructions &lt;a href="https://www.rust-lang.org/tools/install"&gt;here&lt;/a&gt;).&lt;br /&gt; If &lt;code&gt;rustup&lt;/code&gt; is already installed on your system, run &lt;code&gt;rustup update&lt;/code&gt; (or another appropriate command depending on how you installed Rust on your system) to make sure you're running on the latest stable version.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;(Optional but recommended)&lt;/em&gt; An IDE with Rust autocompletion support. We recommend one of the following: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.jetbrains.com/rust/"&gt;RustRover&lt;/a&gt;;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://code.visualstudio.com"&gt;Visual Studio Code&lt;/a&gt; with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=matklad.rust-analyzer"&gt;&lt;code&gt;rust-analyzer&lt;/code&gt;&lt;/a&gt; extension.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Solutions&lt;/h2&gt; 
&lt;p&gt;You can find the solutions to the exercises in the &lt;a href="https://github.com/mainmatter/100-exercises-to-learn-rust/tree/solutions"&gt;&lt;code&gt;solutions&lt;/code&gt; branch&lt;/a&gt; of this repository.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Copyright © 2024- Mainmatter GmbH (&lt;a href="https://mainmatter.com"&gt;https://mainmatter.com&lt;/a&gt;), released under the &lt;a href="https://creativecommons.org/licenses/by-nc/4.0/"&gt;Creative Commons Attribution-NonCommercial 4.0 International license&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DioxusLabs/dioxus</title>
      <link>https://github.com/DioxusLabs/dioxus</link>
      <description>&lt;p&gt;Fullstack app framework for web, desktop, and mobile.&lt;/p&gt;&lt;hr&gt;&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; 
 &lt;!-- &lt;img src="./notes/header-light-updated.svg#gh-light-mode-only" &gt;
      &lt;img src="./notes/header-dark-updated.svg#gh-dark-mode-only" &gt; --&gt; 
 &lt;!-- &lt;a href="https://dioxuslabs.com"&gt;
          &lt;img src="./notes/flat-splash.avif"&gt;
      &lt;/a&gt; --&gt; &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/splash-header-darkmode.svg#gh-dark-mode-only" style="width: 80%; height: auto;" /&gt; &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/splash-header.svg#gh-light-mode-only" style="width: 80%; height: auto;" /&gt; &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/image-splash.avif" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Crates version --&gt; 
 &lt;a href="https://crates.io/crates/dioxus"&gt; &lt;img src="https://img.shields.io/crates/v/dioxus.svg?style=flat-square" alt="Crates.io version" /&gt; &lt;/a&gt; 
 &lt;!-- Downloads --&gt; 
 &lt;a href="https://crates.io/crates/dioxus"&gt; &lt;img src="https://img.shields.io/crates/d/dioxus.svg?style=flat-square" alt="Download" /&gt; &lt;/a&gt; 
 &lt;!-- docs --&gt; 
 &lt;a href="https://docs.rs/dioxus"&gt; &lt;img src="https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square" alt="docs.rs docs" /&gt; &lt;/a&gt; 
 &lt;!-- CI --&gt; 
 &lt;a href="https://github.com/jkelleyrtp/dioxus/actions"&gt; &lt;img src="https://github.com/dioxuslabs/dioxus/actions/workflows/main.yml/badge.svg?sanitize=true" alt="CI status" /&gt; &lt;/a&gt; 
 &lt;!--Awesome --&gt; 
 &lt;a href="https://dioxuslabs.com/awesome"&gt; &lt;img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" alt="Awesome Page" /&gt; &lt;/a&gt; 
 &lt;!-- Discord --&gt; 
 &lt;a href="https://discord.gg/XgGxMSkvUM"&gt; &lt;img src="https://img.shields.io/discord/899851952891002890.svg?logo=discord&amp;amp;style=flat-square" alt="Discord Link" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt; &lt;a href="https://dioxuslabs.com"&gt; Website &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/tree/main/examples"&gt; Examples &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://dioxuslabs.com/learn/0.6/guide"&gt; Guide &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/zh-cn/README.md"&gt; 中文 &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/pt-br/README.md"&gt; PT-BR &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/ja-jp/README.md"&gt; 日本語 &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/tr-tr"&gt; Türkçe &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/ko-kr"&gt; 한국어 &lt;/a&gt; &lt;/h3&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/releases/tag/v0.7.0-alpha.0"&gt;✨ Dioxus 0.7 is in alpha - test it out! ✨&lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;Build for web, desktop, and mobile, and more with a single codebase. Zero-config setup, integrated hot-reloading, and signals-based state management. Add backend functionality with Server Functions and bundle with our CLI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;fn app() -&amp;gt; Element {
    let mut count = use_signal(|| 0);

    rsx! {
        h1 { "High-Five counter: {count}" }
        button { onclick: move |_| count += 1, "Up high!" }
        button { onclick: move |_| count -= 1, "Down low!" }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;⭐️ Unique features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cross-platform apps in three lines of code (web, desktop, mobile, server, and more)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dioxuslabs.com/blog/release-050"&gt;Ergonomic state management&lt;/a&gt; combines the best of React, Solid, and Svelte&lt;/li&gt; 
 &lt;li&gt;Built-in featureful, type-safe, fullstack web framework&lt;/li&gt; 
 &lt;li&gt;Integrated bundler for deploying to the web, macOS, Linux, and Windows&lt;/li&gt; 
 &lt;li&gt;Subsecond Rust hot-patching and asset hot-reloading&lt;/li&gt; 
 &lt;li&gt;And more! &lt;a href="https://dioxuslabs.com/learn/0.6/"&gt;Take a tour of Dioxus&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Instant hot-reloading&lt;/h2&gt; 
&lt;p&gt;With one command, &lt;code&gt;dx serve&lt;/code&gt; and your app is running. Edit your markup, styles, and see changes in milliseconds. Use our experimental &lt;code&gt;dx serve --hotpatch&lt;/code&gt; to update Rust code in real time.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/hotreload-video.webp" /&gt; 
 &lt;!-- &lt;video src="https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov" width="500"&gt;&lt;/video&gt; --&gt; 
 &lt;!-- &lt;video src="https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov" width="500"&gt;&lt;/video&gt; --&gt; 
&lt;/div&gt; 
&lt;h2&gt;Build Beautiful Apps&lt;/h2&gt; 
&lt;p&gt;Dioxus apps are styled with HTML and CSS. Use the built-in TailwindCSS support or load your favorite CSS library. Easily call into native code (objective-c, JNI, Web-Sys) for a perfect native touch.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/ebou2.avif" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Experimental Native Renderer&lt;/h2&gt; 
&lt;p&gt;Render using web-sys, webview, server-side-rendering, liveview, or even with our experimental WGPU-based renderer. Embed Dioxus in Bevy, WGPU, or even run on embedded Linux!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/native-blitz-wgpu.webp" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;First-party primitive components&lt;/h2&gt; 
&lt;p&gt;Get started quickly with a complete set of primitives modeled after shadcn/ui and Radix-Primitives.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/primitive-components.avif" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;First-class Android and iOS support&lt;/h2&gt; 
&lt;p&gt;Dioxus is the fastest way to build native mobile apps with Rust. Simply run &lt;code&gt;dx serve --platform android&lt;/code&gt; and your app is running in an emulator or on device in seconds. Call directly into JNI and Native APIs.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/android_and_ios2.avif" width="500" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Productive, typesafe, fullstack web framework&lt;/h2&gt; 
&lt;p&gt;Directly call your backend from your frontend with our built-in type-safe RPC using &lt;a href="http://crates.io/crates/server_fn"&gt;&lt;code&gt;server_fn&lt;/code&gt;&lt;/a&gt;. Supports streaming, suspense, bundle splitting, websockets, and more.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;fn app() -&amp;gt; Element {
  let mut fortune = use_signal(|| "Fetch a fortune!");
  rsx! {
    h1 { "{fortune}" }
    button {
      onclick: move |_| async move {
        fortune.set(fetch_fortune().await.unwrap());
      }
    }
  }
}

#[server]
async fn fetch_fortune() -&amp;gt; ServerFnResult&amp;lt;String&amp;gt; {
  "Dioxus is super productive!".to_string()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Bundle for web, desktop, and mobile&lt;/h2&gt; 
&lt;p&gt;Simply run &lt;code&gt;dx bundle&lt;/code&gt; and your app will be built and bundled with maximization optimizations. On the web, take advantage of &lt;a href="https://dioxuslabs.com/learn/0.6/guides/assets"&gt;&lt;code&gt;.avif&lt;/code&gt; generation, &lt;code&gt;.wasm&lt;/code&gt; compression, minification&lt;/a&gt;, and more. Build WebApps weighing &lt;a href="https://github.com/ealmloff/tiny-dioxus/"&gt;less than 50kb&lt;/a&gt; and desktop/mobile apps less than 5mb.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/bundle.gif" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Fantastic documentation&lt;/h2&gt; 
&lt;p&gt;We've put a ton of effort into building clean, readable, and comprehensive documentation. All html elements and listeners are documented with MDN docs, and our Docs runs continuous integration with Dioxus itself to ensure that the docs are always up to date. Check out the &lt;a href="https://dioxuslabs.com/learn/0.6/"&gt;Dioxus website&lt;/a&gt; for guides, references, recipes, and more. Fun fact: we use the Dioxus website as a testbed for new Dioxus features - &lt;a href="https://github.com/dioxusLabs/docsite"&gt;check it out!&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/docs.avif" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Modular and Customizable&lt;/h2&gt; 
&lt;p&gt;Build your own renderer, or use a community renderer like &lt;a href="http://freyaui.dev"&gt;Freya&lt;/a&gt;. Use our modular components like RSX, VirtualDom, Blitz, Taffy, and Subsecond.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/freya-todo-example.webp" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Dioxus is a community-driven project, with a very active &lt;a href="https://discord.gg/XgGxMSkvUM"&gt;Discord&lt;/a&gt; and &lt;a href="https://github.com/DioxusLabs/dioxus/issues"&gt;GitHub&lt;/a&gt; community. We're always looking for help, and we're happy to answer questions and help you get started. &lt;a href="https://github.com/DioxusLabs/dioxus-std"&gt;Our SDK&lt;/a&gt; is community-run and we even have a &lt;a href="https://github.com/dioxus-community/"&gt;GitHub organization&lt;/a&gt; for the best Dioxus crates that receive free upgrades and support.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/dioxus-community.avif" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Full-time core team&lt;/h2&gt; 
&lt;p&gt;Dioxus has grown from a side project to a small team of fulltime engineers. Thanks to the generous support of FutureWei, Satellite.im, the GitHub Accelerator program, we're able to work on Dioxus full-time. Our long term goal is for Dioxus to become self-sustaining by providing paid high-quality enterprise tools. If your company is interested in adopting Dioxus and would like to work with us, please reach out!&lt;/p&gt; 
&lt;h2&gt;Supported Platforms&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table style="width:100%"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;b&gt;Web&lt;/b&gt; &lt;/td&gt; 
    &lt;td&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Render directly to the DOM using WebAssembly&lt;/li&gt; 
      &lt;li&gt;Pre-render with SSR and rehydrate on the client&lt;/li&gt; 
      &lt;li&gt;Simple "hello world" at about 50kb, comparable to React&lt;/li&gt; 
      &lt;li&gt;Built-in dev server and hot reloading for quick iteration&lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; &lt;b&gt;Desktop&lt;/b&gt; &lt;/td&gt; 
    &lt;td&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Render using Webview or - experimentally - with WGPU or &lt;a href="https://freyaui.dev"&gt;Freya&lt;/a&gt; (Skia) &lt;/li&gt; 
      &lt;li&gt;Zero-config setup. Simply `cargo run` or `dx serve` to build your app &lt;/li&gt; 
      &lt;li&gt;Full support for native system access without IPC &lt;/li&gt; 
      &lt;li&gt;Supports macOS, Linux, and Windows. Portable &amp;lt;3mb binaries &lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; &lt;b&gt;Mobile&lt;/b&gt; &lt;/td&gt; 
    &lt;td&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Render using Webview or - experimentally - with WGPU or Skia &lt;/li&gt; 
      &lt;li&gt;Build .ipa and .apk files for iOS and Android &lt;/li&gt; 
      &lt;li&gt;Call directly into Java and Objective-C with minimal overhead&lt;/li&gt; 
      &lt;li&gt;From "hello world" to running on device in seconds&lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; &lt;b&gt;Server-side Rendering&lt;/b&gt; &lt;/td&gt; 
    &lt;td&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Suspense, hydration, and server-side rendering&lt;/li&gt; 
      &lt;li&gt;Quickly drop in backend functionality with server functions&lt;/li&gt; 
      &lt;li&gt;Extractors, middleware, and routing integrations&lt;/li&gt; 
      &lt;li&gt;Static-site generation and incremental regeneration&lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Running the examples&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The examples in the main branch of this repository target the git version of dioxus and the CLI. If you are looking for examples that work with the latest stable release of dioxus, check out the &lt;a href="https://github.com/DioxusLabs/dioxus/tree/v0.6/examples"&gt;0.6 branch&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The examples in the top level of this repository can be run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo run --example &amp;lt;example&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;However, we encourage you to download the dioxus-cli to test out features like hot-reloading. To install the most recent binary CLI, you can use cargo binstall.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo binstall dioxus-cli@0.7.0-rc.0 --force
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If this CLI is out-of-date, you can install it directly from git&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo install --git https://github.com/DioxusLabs/dioxus dioxus-cli --locked
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With the CLI, you can also run examples with the web platform. You will need to disable the default desktop feature and enable the web feature with this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;dx serve --example &amp;lt;example&amp;gt; --platform web -- --no-default-features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out the website &lt;a href="https://dioxuslabs.com/learn/0.6/contributing"&gt;section on contributing&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Report issues on our &lt;a href="https://github.com/dioxuslabs/dioxus/issues"&gt;issue tracker&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/XgGxMSkvUM"&gt;Join&lt;/a&gt; the discord and ask questions!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;a href="https://github.com/dioxuslabs/dioxus/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=dioxuslabs/dioxus&amp;amp;max=30&amp;amp;columns=10" /&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under either the &lt;a href="https://github.com/DioxusLabs/dioxus/raw/master/LICENSE-MIT"&gt;MIT license&lt;/a&gt; or the &lt;a href="https://github.com/DioxusLabs/dioxus/raw/master/LICENSE-APACHE"&gt;Apache-2 License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Dioxus by you, shall be licensed as MIT or Apache-2, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tursodatabase/turso</title>
      <link>https://github.com/tursodatabase/turso</link>
      <description>&lt;p&gt;Turso Database is a project to build the next evolution of SQLite.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/turso.png" alt="Turso Database" width="800" /&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;Turso Database&lt;/h1&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; An in-process SQL database, compatible with SQLite. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a title="Build Status" target="_blank" href="https://github.com/tursodatabase/turso/actions/workflows/rust.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/tursodatabase/turso/rust.yml?style=flat-square" /&gt;&lt;/a&gt; &lt;a title="Releases" target="_blank" href="https://github.com/tursodatabase/turso/releases"&gt;&lt;img src="https://img.shields.io/github/release/tursodatabase/turso?style=flat-square&amp;amp;color=9CF" /&gt;&lt;/a&gt; &lt;a title="Rust" target="_blank" href="https://crates.io/crates/turso"&gt;&lt;img alt="PyPI" src="https://img.shields.io/crates/v/turso" /&gt;&lt;/a&gt; &lt;a title="JavaScript" target="_blank" href="https://www.npmjs.com/package/@tursodatabase/database"&gt;&lt;img alt="PyPI" src="https://img.shields.io/npm/v/@tursodatabase/database" /&gt;&lt;/a&gt; &lt;a title="Python" target="_blank" href="https://pypi.org/project/pyturso/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/pyturso" /&gt;&lt;/a&gt; &lt;a title="MIT" target="_blank" href="https://github.com/tursodatabase/turso/raw/main/LICENSE.md"&gt;&lt;img src="http://img.shields.io/badge/license-MIT-orange.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a title="GitHub Pull Requests" target="_blank" href="https://github.com/tursodatabase/turso/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr-closed/tursodatabase/turso.svg?style=flat-square&amp;amp;color=FF9966" /&gt;&lt;/a&gt; &lt;a title="GitHub Commits" target="_blank" href="https://github.com/tursodatabase/turso/commits/main"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/tursodatabase/turso.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;a title="Last Commit" target="_blank" href="https://github.com/tursodatabase/turso/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/tursodatabase/turso.svg?style=flat-square&amp;amp;color=FF9900" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a title="Developer's Discord" target="_blank" href="https://discord.gg/jgjmyYgHwB"&gt;&lt;img alt="Chat with the Core Developers on Discord" src="https://img.shields.io/discord/1258658826257961020?label=Discord&amp;amp;logo=Discord&amp;amp;style=social&amp;amp;label=Core%20Developers" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a title="Users's Discord" target="_blank" href="https://tur.so/discord"&gt;&lt;img alt="Chat with other users of Turso (and Turso Cloud) on Discord" src="https://img.shields.io/discord/933071162680958986?label=Discord&amp;amp;logo=Discord&amp;amp;style=social&amp;amp;label=Users" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Turso Database is an in-process SQL database written in Rust, compatible with SQLite.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;⚠️ Warning:&lt;/strong&gt; This software is ALPHA, only use for development, testing, and experimentation. We are working to make it production ready, but do not use it for critical data right now.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features and Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite compatibility&lt;/strong&gt; for SQL dialect, file formats, and the C API [see &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/COMPAT.md"&gt;document&lt;/a&gt; for details]&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change data capture (CDC)&lt;/strong&gt; for real-time tracking of database changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Language support&lt;/strong&gt; for 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tursodatabase/turso-go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/javascript"&gt;JavaScript&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/java"&gt;Java&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/rust"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/javascript"&gt;WebAssembly&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Asynchronous I/O&lt;/strong&gt; support on Linux with &lt;code&gt;io_uring&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-platform&lt;/strong&gt; support for Linux, macOS, Windows and browsers (through WebAssembly)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vector support&lt;/strong&gt; support including exact search and vector manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Improved schema management&lt;/strong&gt; including extended &lt;code&gt;ALTER&lt;/code&gt; support and faster schema changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The database has the following experimental features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;BEGIN CONCURRENT&lt;/code&gt;&lt;/strong&gt; for improved write throughput using multi-version concurrency control (MVCC).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incremental computation&lt;/strong&gt; using DBSP for incremental view mainatenance and query subscriptions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following features are on our current roadmap:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Vector indexing&lt;/strong&gt; for fast approximate vector search, similar to &lt;a href="https://turso.tech/vector"&gt;libSQL vector search&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/docs/manual.md"&gt;Turso Database Manual&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;💻 Command Line&lt;/summary&gt; 
 &lt;br /&gt; You can install the latest `turso` release with: 
 &lt;pre&gt;&lt;code class="language-shell"&gt;curl --proto '=https' --tlsv1.2 -LsSf \
  https://github.com/tursodatabase/turso/releases/latest/download/turso_cli-installer.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Then launch the interactive shell:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;$ tursodb
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This will start the Turso interactive shell where you can execute SQL statements:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;Turso
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database
turso&amp;gt; CREATE TABLE users (id INT, username TEXT);
turso&amp;gt; INSERT INTO users VALUES (1, 'alice');
turso&amp;gt; INSERT INTO users VALUES (2, 'bob');
turso&amp;gt; SELECT * FROM users;
1|alice
2|bob
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You can also build and run the latest development version with:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo run
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you like docker, we got you covered. Simply run this in the root folder:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;make docker-cli-build &amp;amp;&amp;amp; \
make docker-cli-run
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🦀 Rust&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;cargo add turso
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-rust"&gt;let db = Builder::new_local("sqlite.db").build().await?;
let conn = db.connect()?;

let res = conn.query("SELECT * FROM users", ()).await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;✨ JavaScript&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;npm i @tursodatabase/database
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-js"&gt;import { connect } from '@tursodatabase/database';

const db = await connect('sqlite.db');
const stmt = db.prepare('SELECT * FROM users');
const users = stmt.all();
console.log(users);
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🐍 Python&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;uv pip install pyturso
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import turso

con = turso.connect("sqlite.db")
cur = con.cursor()
res = cur.execute("SELECT * FROM users")
print(res.fetchone())
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🦫 Go&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;go get github.com/tursodatabase/turso-go
go install github.com/tursodatabase/turso-go
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-go"&gt;import (
    "database/sql"
    _ "github.com/tursodatabase/turso-go"
)

conn, _ = sql.Open("turso", "sqlite.db")
defer conn.Close()

stmt, _ := conn.Prepare("select * from users")
defer stmt.Close()

rows, _ = stmt.Query()
for rows.Next() {
    var id int
    var username string
    _ := rows.Scan(&amp;amp;id, &amp;amp;username)
    fmt.Printf("User: ID: %d, Username: %s\n", id, username)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;☕️ Java&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;We integrated Turso Database into JDBC. For detailed instructions on how to use Turso Database with java, please refer to the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/java/README.md"&gt;README.md under bindings/java&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🤖 MCP Server Mode&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;The Turso CLI includes a built-in &lt;a href="https://modelcontextprotocol.io/"&gt;Model Context Protocol (MCP)&lt;/a&gt; server that allows AI assistants to interact with your databases.&lt;/p&gt; 
 &lt;p&gt;Start the MCP server with:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;tursodb your_database.db --mcp
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The MCP server provides seven tools for database interaction:&lt;/p&gt; 
 &lt;h4&gt;Available Tools&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;open_database&lt;/code&gt;&lt;/strong&gt; - Open a new database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;current_database&lt;/code&gt;&lt;/strong&gt; - Describe the current database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;list_tables&lt;/code&gt;&lt;/strong&gt; - List all tables in the database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;describe_table&lt;/code&gt;&lt;/strong&gt; - Describe the structure of a specific table&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;execute_query&lt;/code&gt;&lt;/strong&gt; - Execute read-only SELECT queries&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;insert_data&lt;/code&gt;&lt;/strong&gt; - Insert new data into tables&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;update_data&lt;/code&gt;&lt;/strong&gt; - Update existing data in tables&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;delete_data&lt;/code&gt;&lt;/strong&gt; - Delete data from tables&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;schema_change&lt;/code&gt;&lt;/strong&gt; - Execute schema modification statements (CREATE TABLE, ALTER TABLE, DROP TABLE)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;Example Usage&lt;/h4&gt; 
 &lt;p&gt;The MCP server runs as a single process that handles multiple JSON-RPC requests over stdin/stdout. Here's how to interact with it:&lt;/p&gt; 
 &lt;h4&gt;Example with In-Memory Database&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cat &amp;lt;&amp;lt; 'EOF' | tursodb --mcp
{"jsonrpc": "2.0", "id": 1, "method": "initialize", "params": {"protocolVersion": "2024-11-05", "capabilities": {}, "clientInfo": {"name": "client", "version": "1.0"}}}
{"jsonrpc": "2.0", "id": 2, "method": "tools/call", "params": {"name": "schema_change", "arguments": {"query": "CREATE TABLE users (id INTEGER, name TEXT, email TEXT)"}}}
{"jsonrpc": "2.0", "id": 3, "method": "tools/call", "params": {"name": "list_tables", "arguments": {}}}
{"jsonrpc": "2.0", "id": 4, "method": "tools/call", "params": {"name": "insert_data", "arguments": {"query": "INSERT INTO users VALUES (1, 'Alice', 'alice@example.com')"}}}
{"jsonrpc": "2.0", "id": 5, "method": "tools/call", "params": {"name": "execute_query", "arguments": {"query": "SELECT * FROM users"}}}
EOF
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example with Existing Database&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Working with an existing database file
cat &amp;lt;&amp;lt; 'EOF' | tursodb mydb.db --mcp
{"jsonrpc": "2.0", "id": 1, "method": "initialize", "params": {"protocolVersion": "2024-11-05", "capabilities": {}, "clientInfo": {"name": "client", "version": "1.0"}}}
{"jsonrpc": "2.0", "id": 2, "method": "tools/call", "params": {"name": "list_tables", "arguments": {}}}
EOF
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Using with Claude Code&lt;/h4&gt; 
 &lt;p&gt;If you're using &lt;a href="https://claude.ai/code"&gt;Claude Code&lt;/a&gt;, you can easily connect to your Turso MCP server using the built-in MCP management commands:&lt;/p&gt; 
 &lt;h5&gt;Quick Setup&lt;/h5&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Add the MCP server&lt;/strong&gt; to Claude Code:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add my-database -- tursodb ./path/to/your/database.db --mcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Restart Claude Code&lt;/strong&gt; to activate the connection&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start querying&lt;/strong&gt; your database through natural language!&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h5&gt;Command Breakdown&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add my-database -- tursodb ./path/to/your/database.db --mcp
#              ↑            ↑       ↑                           ↑
#              |            |       |                           |
#              Name         |       Database path               MCP flag
#                          Separator
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;my-database&lt;/code&gt;&lt;/strong&gt; - Choose any name for your MCP server&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;--&lt;/code&gt;&lt;/strong&gt; - Required separator between Claude options and your command&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;tursodb&lt;/code&gt;&lt;/strong&gt; - The Turso database CLI&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;./path/to/your/database.db&lt;/code&gt;&lt;/strong&gt; - Path to your SQLite database file&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;--mcp&lt;/code&gt;&lt;/strong&gt; - Enables MCP server mode&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h5&gt;Example Usage&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# For a local project database
cd /your/project
claude mcp add my-project-db -- tursodb ./data/app.db --mcp

# For an absolute path
claude mcp add analytics-db -- tursodb /Users/you/databases/analytics.db --mcp

# For a specific project (local scope)
claude mcp add project-db --local -- tursodb ./database.db --mcp
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;Managing MCP Servers&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# List all configured MCP servers
claude mcp list

# Get details about a specific server
claude mcp get my-database

# Remove an MCP server
claude mcp remove my-database
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Once configured, you can ask Claude Code to:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Show me all tables in the database"&lt;/li&gt; 
  &lt;li&gt;"What's the schema for the users table?"&lt;/li&gt; 
  &lt;li&gt;"Find all posts with more than 100 upvotes"&lt;/li&gt; 
  &lt;li&gt;"Insert a new user with name 'Alice' and email '&lt;a href="mailto:alice@example.com"&gt;alice@example.com&lt;/a&gt;'"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We'd love to have you contribute to Turso Database! Please check out the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Found a data corruption bug? Get up to $1,000.00&lt;/h3&gt; 
&lt;p&gt;SQLite is loved because it is the most reliable database in the world. The next evolution of SQLite has to match or surpass this level of reliability. Turso is built with &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/simulator/"&gt;Deterministic Simulation Testing&lt;/a&gt; from the ground up, and is also tested by &lt;a href="https://antithesis.com"&gt;Antithesis&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Even during Alpha, if you find a bug that leads to a data corruption and demonstrate how our simulator failed to catch it, you can get up to $1,000.00. As the project matures we will increase the size of the prize, and the scope of the bugs.&lt;/p&gt; 
&lt;p&gt;More details &lt;a href="https://turso.algora.io"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can see an example of an awarded case on &lt;a href="https://github.com/tursodatabase/turso/issues/2049"&gt;#2049&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Turso core staff are not eligible.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Is Turso Database ready for production use?&lt;/h3&gt; 
&lt;p&gt;Turso Database is currently under heavy development and is &lt;strong&gt;not&lt;/strong&gt; ready for production use.&lt;/p&gt; 
&lt;h3&gt;How is Turso Database different from Turso's libSQL?&lt;/h3&gt; 
&lt;p&gt;Turso Database is a project to build the next evolution of SQLite in Rust, with a strong open contribution focus and features like native async support, vector search, and more. The libSQL project is also an attempt to evolve SQLite in a similar direction, but through a fork rather than a rewrite.&lt;/p&gt; 
&lt;p&gt;Rewriting SQLite in Rust started as an unassuming experiment, and due to its incredible success, replaces libSQL as our intended direction. At this point, libSQL is production ready, Turso Database is not - although it is evolving rapidly. More details &lt;a href="https://turso.tech/blog/we-will-rewrite-sqlite-and-we-are-going-all-in"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Publications&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pekka Enberg, Sasu Tarkoma, Jon Crowcroft Ashwin Rao (2024). Serverless Runtime / Database Co-Design With Asynchronous I/O. In &lt;em&gt;EdgeSys ‘24&lt;/em&gt;. &lt;a href="https://penberg.org/papers/penberg-edgesys24.pdf"&gt;[PDF]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Pekka Enberg, Sasu Tarkoma, and Ashwin Rao (2023). Towards Database and Serverless Runtime Co-Design. In &lt;em&gt;CoNEXT-SW ’23&lt;/em&gt;. [&lt;a href="https://penberg.org/papers/penberg-conext-sw-23.pdf"&gt;PDF&lt;/a&gt;] [&lt;a href="https://penberg.org/papers/penberg-conext-sw-23-slides.pdf"&gt;Slides&lt;/a&gt;]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/LICENSE.md"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contribution&lt;/h3&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Turso Database by you, shall be licensed as MIT, without any additional terms or conditions.&lt;/p&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;p&gt;Thanks to all the partners of Turso!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://antithesis.com/"&gt;&lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/antithesis.jpg" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://blacksmith.sh"&gt;&lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/blacksmith.svg?sanitize=true" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://nyrkio.com/"&gt;&lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/turso-nyrkio.png" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to all the contributors to Turso Database!&lt;/p&gt; 
&lt;a href="https://github.com/tursodatabase/turso/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=tursodatabase/turso" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>slint-ui/slint</title>
      <link>https://github.com/slint-ui/slint</link>
      <description>&lt;p&gt;Slint is an open-source declarative GUI toolkit to build native user interfaces for Rust, C++, JavaScript, or Python apps.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/slint-ui/slint/master/logo/slint-logo-full-light.svg#gh-light-mode-only" alt="Slint" /&gt; &lt;img src="https://raw.githubusercontent.com/slint-ui/slint/master/logo/slint-logo-full-dark.svg#gh-dark-mode-only" alt="Slint" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/slint-ui/slint/actions"&gt;&lt;img src="https://github.com/slint-ui/slint/workflows/CI/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://api.reuse.software/info/github.com/slint-ui/slint"&gt;&lt;img src="https://api.reuse.software/badge/github.com/slint-ui/slint" alt="REUSE status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/slint-ui/slint/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/slint-ui/slint" alt="Discussions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Slint&lt;/strong&gt; is an open-source declarative GUI toolkit for building native user interfaces for embedded systems, desktops, and mobile platforms.&lt;/p&gt; 
&lt;p&gt;Write your UI once in &lt;code&gt;.slint&lt;/code&gt;, a simple markup language. Connect it to business logic written in Rust, C++, JavaScript, or Python.&lt;/p&gt; 
&lt;h2&gt;Why Slint?&lt;/h2&gt; 
&lt;p&gt;The name &lt;em&gt;Slint&lt;/em&gt; is derived from our design goals:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable&lt;/strong&gt;: Slint should support responsive UI design, allow cross-platform usage across operating systems and processor architectures and support multiple programming languages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: Slint should require minimal resources, in terms of memory and processing power, and yet deliver a smooth, smartphone-like user experience on any device.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intuitive&lt;/strong&gt;: Designers and developers should feel productive while enjoying the GUI design and development process. The design creation tools should be intuitive to use for the designers. Similarly for the developers, the APIs should be consistent and easy to use, no matter which programming language they choose.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native&lt;/strong&gt;: GUI built with Slint should match the end users' expectations of a native application irrespective of the platform - desktop, mobile, web or embedded system. The UI design should be compiled to machine code and provide flexibility that only a native application can offer: Access full operating system APIs, utilize all CPU and GPU cores, connect to any peripheral.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Beyond the design goals, here’s what makes Slint stand out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Independent UI Design&lt;/strong&gt;: Use a declarative language similar to separate your UI from business logic. Designers can work in parallel with developers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tooling&lt;/strong&gt;: Iterate quickly with our Live Preview &amp;amp; editor integrations. Integrate from Figma with the &lt;a href="https://www.figma.com/community/plugin/1474418299182276871/figma-to-slint"&gt;Slint To Figma plugin&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stable APIs&lt;/strong&gt;: Slint follows a stable 1.x API. We evolve carefully without breaking your code.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See what others have built: &lt;a href="https://madewithslint.com"&gt;#MadeWithSlint&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;h3&gt;Embedded&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;RaspberryPi&lt;/th&gt; 
   &lt;th&gt;STM32&lt;/th&gt; 
   &lt;th&gt;RP2040&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=_BDbNHrjK7g"&gt;Video of Slint on Raspberry Pi&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=NNNOJJsOAis"&gt;Video of Slint on STM32&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=dkBwNocItGs"&gt;Video of Slint on RP2040&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Desktop&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Windows&lt;/th&gt; 
   &lt;th&gt;macOS&lt;/th&gt; 
   &lt;th&gt;Linux&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://slint.dev/resources/gallery_win_screenshot.png" alt="Screenshot of the Gallery on Windows" title="Gallery" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://slint.dev/resources/gallery_mac_screenshot.png" alt="Screenshot of the Gallery on macOS" title="Gallery" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://slint.dev/resources/gallery_linux_screenshot.png" alt="Screenshot of the Gallery on Linux" title="Gallery" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Web using WebAssembly&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Printer Demo&lt;/th&gt; 
   &lt;th&gt;Slide Puzzle&lt;/th&gt; 
   &lt;th&gt;Energy Monitor&lt;/th&gt; 
   &lt;th&gt;Widget Gallery&lt;/th&gt; 
   &lt;th&gt;Weather demo&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/printerdemo/"&gt;&lt;img src="https://slint.dev/resources/printerdemo_screenshot.png" alt="Screenshot of the Printer Demo" title="Printer Demo" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/slide_puzzle/"&gt;&lt;img src="https://slint.dev/resources/puzzle_screenshot.png" alt="Screenshot of the Slide Puzzle" title="Slide Puzzle" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/energy-monitor/"&gt;&lt;img src="https://slint.dev/resources/energy-monitor-screenshot.png" alt="Screenshot of the Energy Monitor Demo" title="Energy Monitor Demo" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/gallery/"&gt;&lt;img src="https://slint.dev/resources/gallery_screenshot.png" alt="Screenshot of the Gallery Demo" title="Gallery Demo" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://slint.dev/demos/weather-demo/"&gt;&lt;img src="https://raw.githubusercontent.com/slint-ui/slint/master/demos/weather-demo/docs/img/desktop-preview.png" alt="Screenshot of the weather Demo" title="Weather Demo" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More examples and demos in the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/examples#examples"&gt;examples folder&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;h3&gt;Hello World&lt;/h3&gt; 
&lt;p&gt;The UI is defined in a Domain Specific Language that is declarative, easy to use, intuitive, and provides a powerful way to describe graphical elements, their placement, their hierarchy, property bindings, and the flow of data through the different states.&lt;/p&gt; 
&lt;p&gt;Here's the obligatory "Hello World":&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-slint"&gt;export component HelloWorld inherits Window {
    width: 400px;
    height: 400px;

    Text {
       y: parent.width / 2;
       x: parent.x + 200px;
       text: "Hello, world";
       color: blue;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;For more details, check out the &lt;a href="https://slint.dev/docs/slint"&gt;Slint Language Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/examples"&gt;examples&lt;/a&gt; folder contains examples and demos, showing how to use the Slint markup language and how to interact with a Slint user interface from supported programming languages.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;docs&lt;/code&gt; folder contains a lot more information, including &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/docs/building.md"&gt;build instructions&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/docs/development.md"&gt;internal developer docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Refer to the README of each language directory in the &lt;code&gt;api&lt;/code&gt; folder:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/api/cpp"&gt;C++&lt;/a&gt; (&lt;a href="https://slint.dev/latest/docs/cpp"&gt;Documentation&lt;/a&gt; | &lt;a href="https://github.com/slint-ui/slint-cpp-template"&gt;Getting Started Template&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/api/rs/slint"&gt;Rust&lt;/a&gt; &lt;a href="https://crates.io/crates/slint"&gt;&lt;img src="https://img.shields.io/crates/v/slint" alt="Crates.io" /&gt;&lt;/a&gt; (&lt;a href="https://slint.dev/latest/docs/rust/slint/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://youtu.be/WBcv4V-whHk"&gt;Tutorial Video&lt;/a&gt; | &lt;a href="https://github.com/slint-ui/slint-rust-template"&gt;Getting Started Template&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/api/node"&gt;JavaScript/NodeJS (Beta)&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/slint-ui"&gt;&lt;img src="https://img.shields.io/npm/v/slint-ui" alt="npm" /&gt;&lt;/a&gt; (&lt;a href="https://slint.dev/latest/docs/node"&gt;Documentation&lt;/a&gt; | &lt;a href="https://github.com/slint-ui/slint-nodejs-template"&gt;Getting Started Template&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/api/python/slint"&gt;Python (Beta)&lt;/a&gt; &lt;a href="https://pypi.org/project/slint/"&gt;&lt;img src="https://img.shields.io/pypi/v/slint" alt="pypi" /&gt;&lt;/a&gt; (&lt;a href="http://snapshots.slint.dev/master/docs/python/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://github.com/slint-ui/slint-python-template"&gt;Getting Started Template&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;An application is composed of the business logic written in Rust, C++, or JavaScript and the &lt;code&gt;.slint&lt;/code&gt; user interface design markup, which is compiled to native code.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://slint.dev/resources/architecture.drawio.svg?sanitize=true" alt="Architecture Overview" /&gt;&lt;/p&gt; 
&lt;h3&gt;Compiler&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;.slint&lt;/code&gt; files are compiled ahead of time. The expressions in the &lt;code&gt;.slint&lt;/code&gt; are pure functions that the compiler can optimize. For example, the compiler could choose to "inline" properties and remove those that are constant or unchanged.&lt;/p&gt; 
&lt;p&gt;The compiler uses the typical compiler phases of lexing, parsing, optimization, and finally code generation. It provides different back-ends for code generation in the target language. The C++ code generator produces a C++ header file, the Rust generator produces Rust code, and so on. An interpreter for dynamic languages is also included.&lt;/p&gt; 
&lt;h3&gt;Runtime&lt;/h3&gt; 
&lt;p&gt;The runtime library consists of an engine that supports properties declared in the &lt;code&gt;.slint&lt;/code&gt; language. Components with their elements, items, and properties are laid out in a single memory region, to reduce memory allocations.&lt;/p&gt; 
&lt;p&gt;Rendering backends and styles are configurable at compile time:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;femtovg&lt;/code&gt; renderer uses OpenGL ES 2.0 for rendering.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;skia&lt;/code&gt; renderer uses &lt;a href="https://skia.org"&gt;Skia&lt;/a&gt; for rendering.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;software&lt;/code&gt; renderer uses the CPU with no additional dependencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;NOTE: When Qt is installed on the system, the &lt;code&gt;qt&lt;/code&gt; style becomes available, using Qt's QStyle to achieve native looking widgets.&lt;/p&gt; 
&lt;h3&gt;Tooling&lt;/h3&gt; 
&lt;p&gt;We have a few tools to help with the development of .slint files:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/tools/lsp"&gt;&lt;strong&gt;LSP Server&lt;/strong&gt;&lt;/a&gt; that adds features like auto-complete and live preview of the .slint files to many editors.&lt;/li&gt; 
 &lt;li&gt;It is bundled in a &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/editors/vscode"&gt;&lt;strong&gt;Visual Studio Code Extension&lt;/strong&gt;&lt;/a&gt; available from the market place.&lt;/li&gt; 
 &lt;li&gt;A &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/tools/viewer"&gt;&lt;strong&gt;slint-viewer&lt;/strong&gt;&lt;/a&gt; tool which displays the .slint files. The &lt;code&gt;--auto-reload&lt;/code&gt; argument makes it easy to preview your UI while you are working on it (when using the LSP preview is not possible).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slintpad.com/"&gt;&lt;strong&gt;SlintPad&lt;/strong&gt;&lt;/a&gt;, an online editor to try out .slint syntax without installing anything (&lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/tools/slintpad"&gt;sources&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;A &lt;a href="https://www.figma.com/community/plugin/1474418299182276871/figma-to-slint"&gt;&lt;strong&gt;Figma to Slint&lt;/strong&gt;&lt;/a&gt; plugin.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please check our &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/editors/README.md"&gt;Editors README&lt;/a&gt; for tips on how to configure your favorite editor to work well with Slint.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;You can use Slint under &lt;em&gt;&lt;strong&gt;any&lt;/strong&gt;&lt;/em&gt; of the following licenses, at your choice:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Build proprietary desktop, mobile, or web applications for free with the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/LICENSES/LicenseRef-Slint-Royalty-free-2.0.md"&gt;Royalty-free License&lt;/a&gt;,&lt;/li&gt; 
 &lt;li&gt;Build open source embedded, desktop, mobile, or web applications for free with the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/LICENSES/GPL-3.0-only.txt"&gt;GNU GPLv3&lt;/a&gt;,&lt;/li&gt; 
 &lt;li&gt;Build proprietary embedded, desktop, mobile, or web applications with the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/LICENSES/LicenseRef-Slint-Software-3.0.md"&gt;Paid license&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the &lt;a href="https://slint.dev/pricing.html"&gt;Slint licensing options on the website&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/FAQ.md#licensing"&gt;Licensing FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;We welcome your contributions: in the form of code, bug reports or feedback. For contribution guidelines see &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; 
&lt;p&gt;Please see our separate &lt;a href="https://raw.githubusercontent.com/slint-ui/slint/master/FAQ.md"&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;About us (SixtyFPS GmbH)&lt;/h2&gt; 
&lt;p&gt;We are passionate about software - API design, cross-platform software development and user interface components. Our aim is to make developing user interfaces fun for everyone: from Python, JavaScript, C++, or Rust developers all the way to UI/UX designers. We believe that software grows organically and keeping it open source is the best way to sustain that growth. Our team members are located remotely in Germany, Finland, and US.&lt;/p&gt; 
&lt;h3&gt;Stay up to date&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://twitter.com/slint_ui"&gt;@slint_ui&lt;/a&gt; on X/Twitter.&lt;/li&gt; 
 &lt;li&gt;Follow &lt;a href="https://mastodon.social/@slint@fosstodon.org"&gt;@slint@fosstodon.org&lt;/a&gt; on Mastodon.&lt;/li&gt; 
 &lt;li&gt;Follow &lt;a href="https://www.linkedin.com/company/slint-ui/"&gt;@slint-ui&lt;/a&gt; on LinkedIn.&lt;/li&gt; 
 &lt;li&gt;Follow &lt;a href="https://bsky.app/profile/slint.dev"&gt;@slint.dev&lt;/a&gt; on Bluesky&lt;/li&gt; 
 &lt;li&gt;Subscribe to our &lt;a href="https://www.youtube.com/@Slint-UI"&gt;YouTube channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contact us&lt;/h3&gt; 
&lt;p&gt;Feel free to join &lt;a href="https://github.com/slint-ui/slint/discussions"&gt;Github discussions&lt;/a&gt; for general chat or questions. Use &lt;a href="https://github.com/slint-ui/slint/issues"&gt;Github issues&lt;/a&gt; to report public suggestions or bugs.&lt;/p&gt; 
&lt;p&gt;We chat in &lt;a href="https://chat.slint.dev"&gt;our Mattermost instance&lt;/a&gt; where you are welcome to listen in or ask your questions.&lt;/p&gt; 
&lt;p&gt;You can of course also contact us privately via email to &lt;a href="mailto://info@slint.dev"&gt;info@slint.dev&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tensorzero/tensorzero</title>
      <link>https://github.com/tensorzero/tensorzero</link>
      <description>&lt;p&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" alt="TensorZero Logo" width="128" height="128" /&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;h1&gt;TensorZero&lt;/h1&gt; 
&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://www.tensorzero.com/github-trending-badge.svg?sanitize=true" alt="#1 Repository Of The Day" /&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TensorZero is an open-source stack for &lt;em&gt;industrial-grade LLM applications&lt;/em&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gateway:&lt;/strong&gt; access every LLM provider through a unified API, built for performance (&amp;lt;1ms p99 latency)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability:&lt;/strong&gt; store inferences and feedback in your database, available programmatically or in the UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimization:&lt;/strong&gt; collect metrics and human feedback to optimize prompts, models, and inference strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluation:&lt;/strong&gt; benchmark individual inferences or end-to-end workflows using heuristics, LLM judges, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Experimentation:&lt;/strong&gt; ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Take what you need, adopt incrementally, and complement with other tools.&lt;/p&gt; 
&lt;p&gt;
 &lt;video src="https://github.com/user-attachments/assets/04a8466e-27d8-4189-b305-e7cecb6881ee"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/" target="_blank"&gt;Website&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs" target="_blank"&gt;Docs&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.x.com/tensorzero" target="_blank"&gt;Twitter&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/slack" target="_blank"&gt;Slack&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/discord" target="_blank"&gt;Discord&lt;/a&gt;&lt;/b&gt; &lt;br /&gt; &lt;br /&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart" target="_blank"&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank"&gt;API Reference&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;What is TensorZero?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How is TensorZero different from other LLM frameworks?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt; 1. TensorZero enables you to optimize complex LLM applications based on production metrics and human feedback.&lt;br /&gt; 2. TensorZero supports the needs of industrial-grade LLM applications: low latency, high throughput, type safety, self-hosted, GitOps, customizability, etc.&lt;br /&gt; 3. TensorZero unifies the entire LLMOps stack, creating compounding benefits. For example, LLM evaluations can be used for fine-tuning models alongside AI judges. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Can I use TensorZero with ___?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Yes. Every major programming language is supported. You can use TensorZero with our Python client, any OpenAI SDK or OpenAI-compatible client, or our HTTP API.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Is TensorZero production-ready?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Yes. Here's a case study: &lt;b&gt;&lt;a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms"&gt;Automating Code Changelogs at a Large Bank with LLMs&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How much does TensorZero cost?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Nothing. TensorZero is 100% self-hosted and open-source. There are no paid features.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Who is building TensorZero?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Our technical team includes a former Rust compiler maintainer, machine learning researchers (Stanford, CMU, Oxford, Columbia) with thousands of citations, and the chief product officer of a decacorn startup. We're backed by the same investors as leading open-source projects (e.g. ClickHouse, CockroachDB) and AI labs (e.g. OpenAI, Anthropic). See our &lt;b&gt;&lt;a href="https://www.tensorzero.com/blog/tensorzero-raises-7-3m-seed-round-to-build-an-open-source-stack-for-industrial-grade-llm-applications/"&gt;$7.3M seed round announcement&lt;/a&gt;&lt;/b&gt; and &lt;b&gt;&lt;a href="https://venturebeat.com/ai/tensorzero-nabs-7-3m-seed-to-solve-the-messy-world-of-enterprise-llm-development/" rel="nofollow" target="_blank"&gt;coverage from VentureBeat&lt;/a&gt;&lt;/b&gt;. We're &lt;b&gt;&lt;a href="https://www.tensorzero.com/jobs" rel="nofollow" target="_blank"&gt;hiring in NYC&lt;/a&gt;&lt;/b&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How do I get started?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;You can adopt TensorZero incrementally. Our &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/b&gt; goes from a vanilla OpenAI wrapper to a production-ready LLM application with observability and fine-tuning in just 5 minutes.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;🌐 LLM Gateway&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Integrate with TensorZero once and access every major LLM provider.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Access every major LLM provider (API or self-hosted) through a single unified API&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Infer with streaming, tool use, structured generation (JSON mode), batch, embeddings, multimodal (VLMs), file inputs, caching, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Define prompt templates and schemas to enforce a consistent, typed interface between your application and the LLMs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Satisfy extreme throughput and latency needs, thanks to 🦀 Rust: &amp;lt;1ms p99 latency overhead at 10k+ QPS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Integrate using our Python client, any OpenAI SDK or OpenAI-compatible client, or our HTTP API (use any programming language)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Ensure high availability with routing, retries, fallbacks, load balancing, granular timeouts, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: rate limits, spend tracking and budgeting, service accounts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Model Providers&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="left" valign="top"&gt; &lt;p&gt; The TensorZero Gateway natively supports: &lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic"&gt;Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock"&gt;AWS Bedrock&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker"&gt;AWS SageMaker&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure"&gt;Azure OpenAI Service&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek"&gt;DeepSeek&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks"&gt;Fireworks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic"&gt;GCP Vertex AI Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini"&gt;GCP Vertex AI Gemini&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini"&gt;Google AI Studio (Gemini API)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/groq"&gt;Groq&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic"&gt;Hyperbolic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral"&gt;Mistral&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai"&gt;OpenAI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openrouter"&gt;OpenRouter&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/sglang"&gt;SGLang&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/tgi"&gt;TGI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/together"&gt;Together AI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm"&gt;vLLM&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai"&gt;xAI (Grok)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt; &lt;em&gt; Need something else? Your provider is most likely supported because TensorZero integrates with &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible"&gt;any OpenAI-compatible API (e.g. Ollama)&lt;/a&gt;&lt;/b&gt;. &lt;/em&gt; &lt;/p&gt; &lt;/td&gt; 
   &lt;td width="50%" align="left" valign="top"&gt; &lt;p&gt; The TensorZero Gateway supports advanced features like: &lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks"&gt;Retries &amp;amp; Fallbacks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations"&gt;Inference-Time Optimizations&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas"&gt;Prompt Templates &amp;amp; Schemas&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/experimentation/"&gt;Experimentation (A/B Testing)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/configuration-reference"&gt;Configuration-as-Code (GitOps)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference"&gt;Batch Inference&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference"&gt;Multimodal Inference (VLMs)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching"&gt;Inference Caching&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback"&gt;Metrics &amp;amp; Feedback&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/episodes"&gt;Multi-Step LLM Workflows (Episodes)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;em&gt;&amp;amp; a lot more...&lt;/em&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt; The TensorZero Gateway is written in Rust 🦀 with &lt;b&gt;performance&lt;/b&gt; in mind (&amp;lt;1ms p99 latency overhead @ 10k QPS). See &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/benchmarks"&gt;Benchmarks&lt;/a&gt;&lt;/b&gt;.&lt;br /&gt; &lt;/p&gt; &lt;p&gt; You can run inference using the &lt;b&gt;TensorZero client&lt;/b&gt; (recommended), the &lt;b&gt;OpenAI client&lt;/b&gt;, or the &lt;b&gt;HTTP API&lt;/b&gt;. &lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python — TensorZero Client (Recommended)&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the TensorZero Python client.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from tensorzero import TensorZeroGateway  # or AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # Try other providers easily: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Write a haiku about artificial intelligence.",
                }
            ]
        },
    )
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python — OpenAI Client&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Python client with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI  # or AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()

patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)

response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "Write a haiku about artificial intelligence.",
        }
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: JavaScript / TypeScript (Node) — OpenAI Client&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Node client with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions →&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-ts"&gt;import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});

const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "Write a haiku about artificial intelligence.",
    },
  ],
});
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Other Languages &amp;amp; Platforms — HTTP API&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;TensorZero supports virtually any programming language or platform via its HTTP API.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions →&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "Write a haiku about artificial intelligence."
        }
      ]
    }
  }'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;🔍 LLM Observability&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Zoom in to debug individual API calls, or zoom out to monitor metrics across models and prompts over time — all using the open-source TensorZero UI.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Store inferences and feedback (metrics, human edits, etc.) in your own database&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Dive into individual inferences or high-level aggregate patterns using the TensorZero UI or programmatically&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Build datasets for optimization, evaluation, and other workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Replay historical inferences with new prompts, models, inference strategies, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Export OpenTelemetry (OTLP) traces to your favorite general-purpose observability tool&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: AI-assisted debugging and root cause analysis; AI-assisted data labeling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability » UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability » Programmatic&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;
    &lt;video src="https://github.com/user-attachments/assets/a23e4c95-18fa-482c-8423-6078fb4cf285"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td width="50%" align="left" valign="middle"&gt; &lt;pre&gt;&lt;code class="language-python"&gt;t0.experimental_list_inferences(
  function_name="sales_agent",
  variant_name="qwen3-promptv2",
  filters=BooleanMetricFilter(
      metric_name="converted_sale",
      value=True,
  ),
  order_by=[OrderBy(by="timestamp", direction="DESC")],
  limit=100_000,
  # ... and more ...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h3&gt;📈 LLM Optimization&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Send production metrics and human feedback to easily optimize your prompts, models, and inference strategies — using the UI or programmatically.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize your models with supervised fine-tuning, RLHF, and other techniques&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize your prompts with automated prompt engineering algorithms like MIPROv2&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize your inference strategy with dynamic in-context learning, chain of thought, best/mixture-of-N sampling, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Enable a feedback loop for your LLMs: a data &amp;amp; learning flywheel turning production data into smarter, faster, and cheaper models&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: synthetic data generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Model Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize closed-source and open-source models using supervised fine-tuning (SFT) and preference fine-tuning (DPO).&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Supervised Fine-tuning — UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Preference Fine-tuning (DPO) — Jupyter Notebook&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;
    &lt;video src="https://github.com/user-attachments/assets/82f76be7-5e02-4ada-b503-69dfa209a442"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Inference-Time Optimization&lt;/h4&gt; 
&lt;p&gt;Boost performance by dynamically updating your prompts with relevant examples, combining responses from multiple inferences, and more.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;Best-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling"&gt;Mixture-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic In-Context Learning (DICL)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot"&gt;Chain-of-Thought (CoT)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h4&gt;Prompt Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize your prompts programmatically using research-driven optimization techniques.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;MIPROv2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;DSPy Integration&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt; TensorZero comes with several optimization recipes, but you can also easily create your own. This example shows how to optimize a TensorZero function using an arbitrary tool — here, DSPy, a popular library for automated prompt engineering. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;📊 LLM Evaluation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Compare prompts, models, and inference strategies using evaluations powered by heuristics and LLM judges.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Evaluate individual inferences with &lt;em&gt;static evaluations&lt;/em&gt; powered by heuristics or LLM judges (≈ unit tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Evaluate end-to-end workflows with &lt;em&gt;dynamic evaluations&lt;/em&gt; with complete flexibility (≈ integration tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize LLM judges just like any other TensorZero function to align them to human preferences&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: more built-in evaluators; headless evaluations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation » UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation » CLI&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="left" valign="middle"&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
██████████████████████████████████████ 100/100
exact_match: 0.83 ± 0.03
semantic_match: 0.98 ± 0.01
item_count: 7.15 ± 0.39&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;🧪 LLM Experimentation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Ship with confidence with built-in A/B testing for models, prompts, providers, hyperparameters, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Enforce principled experiments (RCTs) in complex workflows, including multi-turn and compound LLM systems&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: multi-armed bandits; AI-managed experiments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&amp;amp; more!&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Build with an open-source stack well-suited for prototypes but designed from the ground up to support the most complex LLM applications and deployments.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Build simple applications or massive deployments with GitOps-friendly orchestration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Extend TensorZero with built-in escape hatches, programmatic-first usage, direct database access, and more&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Integrate with third-party tools: specialized observability and evaluations, model providers, agent orchestration frameworks, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Iterate quickly by experimenting with prompts interactively using the Playground UI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Watch LLMs get better at data extraction in real-time with TensorZero!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic in-context learning (DICL)&lt;/a&gt;&lt;/strong&gt; is a powerful inference-time optimization available out of the box with TensorZero. It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb"&gt;https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Start building today.&lt;/strong&gt; The &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; shows it's easy to set up an LLM application with TensorZero.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Questions?&lt;/strong&gt; Ask us on &lt;strong&gt;&lt;a href="https://www.tensorzero.com/slack"&gt;Slack&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href="https://www.tensorzero.com/discord"&gt;Discord&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Using TensorZero at work?&lt;/strong&gt; Email us at &lt;strong&gt;&lt;a href="mailto:hello@tensorzero.com"&gt;hello@tensorzero.com&lt;/a&gt;&lt;/strong&gt; to set up a Slack or Teams channel with your team (free).&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;We are working on a series of &lt;strong&gt;complete runnable examples&lt;/strong&gt; illustrating TensorZero's data &amp;amp; learning flywheel.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner"&gt;Optimizing Data Extraction (NER) with TensorZero&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to use TensorZero to optimize a data extraction pipeline. We demonstrate techniques like fine-tuning and dynamic in-context learning (DICL). In the end, an optimized GPT-4o Mini model outperforms GPT-4o on this task — at a fraction of the cost and latency — using a small amount of training data.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/"&gt;Agentic RAG — Multi-Hop Question Answering with LLMs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to build a multi-hop retrieval agent using TensorZero. The agent iteratively searches Wikipedia to gather information, and decides when it has enough context to answer a complex question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences"&gt;Writing Haikus to Satisfy a Judge with Hidden Preferences&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste. You'll see TensorZero's "data flywheel in a box" in action: better variants leads to better data, and better data leads to better variants. You'll see progress by fine-tuning the LLM multiple times.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/multimodal-vision-finetuning"&gt;Image Data Extraction — Multimodal (Vision) Fine-tuning&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to fine-tune multimodal models (VLMs) like GPT-4o to improve their performance on vision-language tasks. Specifically, we'll build a system that categorizes document images (screenshots of computer science research papers).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/"&gt;Improving LLM Chess Ability with Best-of-N Sampling&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example showcases how best-of-N sampling can significantly enhance an LLM's chess-playing abilities by selecting the most promising moves from multiple generated options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;Improving Math Reasoning with a Custom Recipe for Automated Prompt Engineering (DSPy)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;TensorZero provides a number of pre-built optimization recipes covering common LLM engineering workflows. But you can also easily create your own recipes and workflows! This example shows how to optimize a TensorZero function using an arbitrary tool — here, DSPy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&amp;amp; many more on the way!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ai-dynamo/dynamo</title>
      <link>https://github.com/ai-dynamo/dynamo</link>
      <description>&lt;p&gt;A Datacenter Scale Distributed Inference Serving Framework&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-banner.png" alt="Dynamo banner" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ai-dynamo/dynamo/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/ai-dynamo/dynamo" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/D92uqZRjCZ"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ai-dynamo/dynamo"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/issues/762"&gt;Roadmap&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/raw/main/docs/support_matrix.md"&gt;Support matrix&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://docs.nvidia.com/dynamo/latest/index.html"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/tree/main/examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo"&gt;Prebuilt containers&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/enhancements"&gt;Design Proposals&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://developer.nvidia.com/blog/tag/nvidia-dynamo"&gt;Blogs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;NVIDIA Dynamo&lt;/h1&gt; 
&lt;p&gt;High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.&lt;/p&gt; 
&lt;h2&gt;Latest News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[08/05] Deploy &lt;code&gt;openai/gpt-oss-120b&lt;/code&gt; with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/trtllm/gpt-oss.md"&gt;➡️ link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;The Era of Multi-GPU, Multi-Node&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-gpu-vertical.png" alt="Multi Node Multi-GPU topology" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs—and sometimes many servers—but it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.&lt;/p&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Disaggregated prefill &amp;amp; decode inference&lt;/strong&gt; – Maximizes GPU throughput and facilitates trade off between throughput and latency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic GPU scheduling&lt;/strong&gt; – Optimizes performance based on fluctuating demand&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-aware request routing&lt;/strong&gt; – Eliminates unnecessary KV cache re-computation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accelerated data transfer&lt;/strong&gt; – Reduces inference response time using NIXL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;KV cache offloading&lt;/strong&gt; – Leverages multiple memory hierarchies for higher system throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-architecture.png" alt="Dynamo architecture" width="600" /&gt; &lt;/p&gt; 
&lt;h2&gt;Framework Support Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;vLLM&lt;/th&gt; 
   &lt;th&gt;SGLang&lt;/th&gt; 
   &lt;th&gt;TensorRT-LLM&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/disagg_serving.md"&gt;&lt;strong&gt;Disaggregated Serving&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/disagg_serving.md#conditional-disaggregation"&gt;&lt;strong&gt;Conditional Disaggregation&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/kv_cache_routing.md"&gt;&lt;strong&gt;KV-Aware Routing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/load_planner.md"&gt;&lt;strong&gt;Load Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/sla_planner.md"&gt;&lt;strong&gt;SLA-Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/kvbm_architecture.md"&gt;&lt;strong&gt;KVBM&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about each framework and their capabilities, check out each framework's README!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/vllm/README.md"&gt;vLLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/sglang/README.md"&gt;SGLang&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/trtllm/README.md"&gt;TensorRT-LLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;The following examples require a few system level packages. Recommended to use Ubuntu 24.04 with a x86_64 CPU. See &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/support_matrix.md"&gt;docs/support_matrix.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;1. Initial setup&lt;/h2&gt; 
&lt;p&gt;The Dynamo team recommends the &lt;code&gt;uv&lt;/code&gt; Python package manager, although any way works. Install uv:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install etcd and NATS (required)&lt;/h3&gt; 
&lt;p&gt;To coordinate across a data center, Dynamo relies on etcd and NATS. To run Dynamo locally, these need to be available.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; can be run directly as &lt;code&gt;./etcd&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nats.io/"&gt;nats&lt;/a&gt; needs jetstream enabled: &lt;code&gt;nats-server -js&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To quickly setup etcd &amp;amp; NATS, you can also run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# At the root of the repository:
docker compose -f deploy/docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;2. Select an engine&lt;/h2&gt; 
&lt;p&gt;We publish Python wheels specialized for each of our supported engines: vllm, sglang, trtllm, and llama.cpp. The examples that follow use SGLang; continue reading for other engines.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install "ai-dynamo[sglang]"  #replace with [vllm], [trtllm], etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Run Dynamo&lt;/h2&gt; 
&lt;h3&gt;Running an LLM API server&lt;/h3&gt; 
&lt;p&gt;Dynamo provides a simple way to spin up a local set of inference components including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI Compatible Frontend&lt;/strong&gt; – High performance OpenAI compatible http api server written in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic and Kv Aware Router&lt;/strong&gt; – Route and load balance traffic to a set of workers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt; – Set of pre-configured LLM serving engines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang.worker --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B --skip-tokenizer-init
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send a Request&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl localhost:8000/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "messages": [
    {
        "role": "user",
        "content": "Hello, how are you?"
    }
    ],
    "stream":false,
    "max_tokens": 300
  }' | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Rerun with &lt;code&gt;curl -N&lt;/code&gt; and change &lt;code&gt;stream&lt;/code&gt; in the request to &lt;code&gt;true&lt;/code&gt; to get the responses as soon as the engine issues them.&lt;/p&gt; 
&lt;h3&gt;Deploying Dynamo&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/guides/dynamo_deploy/README.md"&gt;Quickstart Guide&lt;/a&gt; to deploy on Kubernetes.&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends"&gt;Backends&lt;/a&gt; to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)&lt;/li&gt; 
 &lt;li&gt;Run some &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples"&gt;Examples&lt;/a&gt; to learn about building components in Dynamo and exploring various integrations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Benchmarking Dynamo&lt;/h3&gt; 
&lt;p&gt;Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/benchmarks/benchmarking.md"&gt;Benchmarking Guide&lt;/a&gt;&lt;/strong&gt; – Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using GenAI-Perf&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/benchmarks/pre_deployment_profiling.md"&gt;Pre-Deployment Profiling&lt;/a&gt;&lt;/strong&gt; – Optimize configurations before deployment to meet SLA requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Engines&lt;/h1&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (&lt;code&gt;python -m dynamo.frontend [--interactive]&lt;/code&gt;).&lt;/p&gt; 
&lt;h2&gt;vLLM&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[vllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.vllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass &lt;code&gt;--context-length &amp;lt;value&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;SGLang&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.sglang.worker --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can pass any sglang flags directly to this worker, see &lt;a href="https://docs.sglang.ai/advanced_features/server_arguments.html"&gt;https://docs.sglang.ai/advanced_features/server_arguments.html&lt;/a&gt; . See there to use multiple GPUs.&lt;/p&gt; 
&lt;h2&gt;TensorRT-LLM&lt;/h2&gt; 
&lt;p&gt;It is recommended to use &lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch"&gt;NGC PyTorch Container&lt;/a&gt; for running the TensorRT-LLM engine.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using. For example, if you are using &lt;code&gt;tensorrt-llm==1.0.0rc6&lt;/code&gt;, use the PyTorch container image version &lt;code&gt;25.06&lt;/code&gt;. To find the correct PyTorch container version for your desired &lt;code&gt;tensorrt-llm&lt;/code&gt; release, visit the &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/docker/Dockerfile.multi"&gt;TensorRT-LLM Dockerfile.multi&lt;/a&gt; on GitHub. Switch to the branch that matches your &lt;code&gt;tensorrt-llm&lt;/code&gt; version, and look for the &lt;code&gt;BASE_TAG&lt;/code&gt; line to identify the recommended PyTorch container tag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] Launch container with the following additional settings &lt;code&gt;--shm-size=1g --ulimit memlock=-1&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Install prerequisites&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install "cuda-python&amp;gt;=12,&amp;lt;13"

sudo apt-get -y install libopenmpi-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Tip] You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation &lt;a href="https://nvidia.github.io/TensorRT-LLM/installation/linux.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;After installing the pre-requisites above, install Dynamo&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[trtllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.trtllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Developing Locally&lt;/h1&gt; 
&lt;h2&gt;1. Install libraries&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Ubuntu:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# if brew is not installed on your system, install it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If Metal is accessible, you should see an error like &lt;code&gt;metal: error: no input files&lt;/code&gt;, which confirms it is installed correctly.&lt;/p&gt; 
&lt;h2&gt;2. Install Rust&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Create a Python virtual env:&lt;/h2&gt; 
&lt;p&gt;Follow the instructions in &lt;a href="https://docs.astral.sh/uv/#installation"&gt;uv installation&lt;/a&gt; guide to install uv if you don't have &lt;code&gt;uv&lt;/code&gt; installed. Once uv is installed, create a virtual environment and activate it.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv dynamo
source dynamo/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Install build tools&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install pip maturin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/PyO3/maturin"&gt;Maturin&lt;/a&gt; is the Rust&amp;lt;-&amp;gt;Python bindings build tool.&lt;/p&gt; 
&lt;h2&gt;5. Build the Rust bindings&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd lib/bindings/python
maturin develop --uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;6. Install the wheel&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd $PROJECT_ROOT
uv pip install .
# For development, use
export PYTHONPATH="${PYTHONPATH}:$(pwd)/components/frontend/src:$(pwd)/components/planner/src:$(pwd)/components/backends/vllm/src:$(pwd)/components/backends/sglang/src:$(pwd)/components/backends/trtllm/src:$(pwd)/components/backends/llama_cpp/src:$(pwd)/components/backends/mocker/src"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Editable (&lt;code&gt;-e&lt;/code&gt;) does not work because the &lt;code&gt;dynamo&lt;/code&gt; package is split over multiple directories, one per backend.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You should now be able to run &lt;code&gt;python -m dynamo.frontend&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Remember that nats and etcd must be running (see earlier).&lt;/p&gt; 
&lt;p&gt;Set the environment variable &lt;code&gt;DYN_LOG&lt;/code&gt; to adjust the logging level; for example, &lt;code&gt;export DYN_LOG=debug&lt;/code&gt;. It has the same syntax as &lt;code&gt;RUST_LOG&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use vscode or cursor, we have a .devcontainer folder built on &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers"&gt;Microsofts Extension&lt;/a&gt;. For instructions see the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/.devcontainer/README.md"&gt;ReadMe&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vectordotdev/vector</title>
      <link>https://github.com/vectordotdev/vector</link>
      <description>&lt;p&gt;A high-performance observability data pipeline.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/vectordotdev/vector/actions/workflows/nightly.yml"&gt;&lt;img src="https://github.com/vectordotdev/vector/actions/workflows/nightly.yml/badge.svg?sanitize=true" alt="Nightly" /&gt;&lt;/a&gt; &lt;a href="https://github.com/vectordotdev/vector/actions/workflows/e2e.yml"&gt;&lt;img src="https://github.com/vectordotdev/vector/actions/workflows/e2e.yml/badge.svg?sanitize=true" alt="E2E Test Suite" /&gt;&lt;/a&gt; &lt;a href="https://github.com/vectordotdev/vector/actions/workflows/component_features.yml"&gt;&lt;img src="https://github.com/vectordotdev/vector/actions/workflows/component_features.yml/badge.svg?sanitize=true" alt="Component Features" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/vectordotdev/vector/master/website/static/img/diagram.svg?sanitize=true" alt="Vector" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://vector.dev/docs/setup/quickstart/"&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://vector.dev/docs/"&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://vector.dev/guides/"&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://vector.dev/components/"&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://chat.vector.dev"&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://vector.dev/releases/latest/download/"&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://rust-doc.vector.dev/"&gt;Rust Crate Docs&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;h2&gt;What is Vector?&lt;/h2&gt; 
&lt;p&gt;Vector is a high-performance, end-to-end (agent &amp;amp; aggregator) observability data pipeline that puts you in control of your observability data. &lt;a href="https://vector.dev/docs/reference/configuration/sources/"&gt;Collect&lt;/a&gt;, &lt;a href="https://vector.dev/docs/reference/configuration/transforms/"&gt;transform&lt;/a&gt;, and &lt;a href="https://vector.dev/docs/reference/configuration/sinks/"&gt;route&lt;/a&gt; all your logs and metrics to any vendors you want today and any other vendors you may want tomorrow. Vector enables dramatic cost reduction, novel data enrichment, and data security where you need it, not where it is most convenient for your vendors. Additionally, it is open source and up to 10x faster than every alternative in the space.&lt;/p&gt; 
&lt;p&gt;To get started, follow our &lt;a href="https://vector.dev/docs/setup/quickstart/"&gt;&lt;strong&gt;quickstart guide&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://vector.dev/docs/setup/installation/"&gt;&lt;strong&gt;install Vector&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Vector is maintained by Datadog's &lt;a href="https://opensource.datadoghq.com/about/#the-community-open-source-engineering-team"&gt;Community Open Source Engineering team&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Principles&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable&lt;/strong&gt; - Built in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, Vector's primary design goal is reliability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end&lt;/strong&gt; - Deploys as an &lt;a href="https://vector.dev/docs/setup/deployment/roles/#agent"&gt;agent&lt;/a&gt; or &lt;a href="https://vector.dev/docs/setup/deployment/roles/#aggregator"&gt;aggregator&lt;/a&gt;. Vector is a complete platform.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unified&lt;/strong&gt; - &lt;a href="https://vector.dev/docs/architecture/data-model/log/"&gt;Logs&lt;/a&gt;, &lt;a href="https://vector.dev/docs/architecture/data-model/metric/"&gt;metrics&lt;/a&gt; (beta), and traces (coming soon). One tool for all of your data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Use cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reduce total observability costs.&lt;/li&gt; 
 &lt;li&gt;Transition vendors without disrupting workflows.&lt;/li&gt; 
 &lt;li&gt;Enhance data quality and improve insights.&lt;/li&gt; 
 &lt;li&gt;Consolidate agents and eliminate agent fatigue.&lt;/li&gt; 
 &lt;li&gt;Improve overall observability performance and reliability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vector is relied on by startups and enterprises like &lt;strong&gt;Atlassian&lt;/strong&gt;, &lt;strong&gt;T-Mobile&lt;/strong&gt;, &lt;strong&gt;Comcast&lt;/strong&gt;, &lt;strong&gt;Zendesk&lt;/strong&gt;, &lt;strong&gt;Discord&lt;/strong&gt;, &lt;strong&gt;Fastly&lt;/strong&gt;, &lt;strong&gt;CVS&lt;/strong&gt;, &lt;strong&gt;Trivago&lt;/strong&gt;, &lt;strong&gt;Tuple&lt;/strong&gt;, &lt;strong&gt;Douban&lt;/strong&gt;, &lt;strong&gt;Visa&lt;/strong&gt;, &lt;strong&gt;Mambu&lt;/strong&gt;, &lt;strong&gt;Blockfi&lt;/strong&gt;, &lt;strong&gt;Claranet&lt;/strong&gt;, &lt;strong&gt;Instacart&lt;/strong&gt;, &lt;strong&gt;Forcepoint&lt;/strong&gt;, and &lt;a href="https://github.com/vectordotdev/vector/issues/790"&gt;many more&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Vector is &lt;strong&gt;downloaded over 100,000 times per day&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Vector's largest user &lt;strong&gt;processes over 500TB daily&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Vector has &lt;strong&gt;over 500 contributors&lt;/strong&gt; and growing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;All user documentation is available at &lt;strong&gt;&lt;a href="https://vector.dev/docs"&gt;vector.dev/docs&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Other Resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://calendar.vector.dev"&gt;&lt;strong&gt;Vector Calendar&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Policies&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/CODE_OF_CONDUCT.md"&gt;&lt;strong&gt;Code of Conduct&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/PRIVACY.md"&gt;&lt;strong&gt;Privacy&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/RELEASES.md"&gt;&lt;strong&gt;Releases&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/VERSIONING.md"&gt;&lt;strong&gt;Versioning&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/security/policy"&gt;&lt;strong&gt;Security&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Comparisons&lt;/h2&gt; 
&lt;h3&gt;Performance&lt;/h3&gt; 
&lt;p&gt;The following performance tests demonstrate baseline performance between common protocols with the exception of the Regex Parsing test.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Test&lt;/th&gt; 
   &lt;th&gt;Vector&lt;/th&gt; 
   &lt;th&gt;Filebeat&lt;/th&gt; 
   &lt;th&gt;FluentBit&lt;/th&gt; 
   &lt;th&gt;FluentD&lt;/th&gt; 
   &lt;th&gt;Logstash&lt;/th&gt; 
   &lt;th&gt;SplunkUF&lt;/th&gt; 
   &lt;th&gt;SplunkHF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance"&gt;TCP to Blackhole&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;86mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;64.4mib/s&lt;/td&gt; 
   &lt;td&gt;27.7mib/s&lt;/td&gt; 
   &lt;td&gt;40.6mib/s&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance"&gt;File to TCP&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;76.7mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;7.8mib/s&lt;/td&gt; 
   &lt;td&gt;35mib/s&lt;/td&gt; 
   &lt;td&gt;26.1mib/s&lt;/td&gt; 
   &lt;td&gt;3.1mib/s&lt;/td&gt; 
   &lt;td&gt;40.1mib/s&lt;/td&gt; 
   &lt;td&gt;39mib/s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance"&gt;Regex Parsing&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;13.2mib/s&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;20.5mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;2.6mib/s&lt;/td&gt; 
   &lt;td&gt;4.6mib/s&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;7.8mib/s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance"&gt;TCP to HTTP&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;26.7mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;19.6mib/s&lt;/td&gt; 
   &lt;td&gt;&amp;lt;1mib/s&lt;/td&gt; 
   &lt;td&gt;2.7mib/s&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance"&gt;TCP to TCP&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;69.9mib/s&lt;/td&gt; 
   &lt;td&gt;5mib/s&lt;/td&gt; 
   &lt;td&gt;67.1mib/s&lt;/td&gt; 
   &lt;td&gt;3.9mib/s&lt;/td&gt; 
   &lt;td&gt;10mib/s&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;70.4mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;7.6mib/s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about our performance tests, please see the &lt;a href="https://github.com/vectordotdev/vector-test-harness/"&gt;Vector test harness&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Correctness&lt;/h3&gt; 
&lt;p&gt;The following correctness tests are not exhaustive, but they demonstrate fundamental differences in quality and attention to detail:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Test&lt;/th&gt; 
   &lt;th&gt;Vector&lt;/th&gt; 
   &lt;th&gt;Filebeat&lt;/th&gt; 
   &lt;th&gt;FluentBit&lt;/th&gt; 
   &lt;th&gt;FluentD&lt;/th&gt; 
   &lt;th&gt;Logstash&lt;/th&gt; 
   &lt;th&gt;Splunk UF&lt;/th&gt; 
   &lt;th&gt;Splunk HF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness"&gt;Disk Buffer Persistence&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness"&gt;File Rotate (create)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness"&gt;File Rotate (copytruncate)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness"&gt;File Truncation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness"&gt;Process (SIGHUP)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness"&gt;JSON (wrapped)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about our correctness tests, please see the &lt;a href="https://github.com/vectordotdev/vector-test-harness/"&gt;Vector test harness&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;p&gt;Vector is an end-to-end, unified, open data platform.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Vector&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;Beats&lt;/th&gt; 
   &lt;th&gt;Fluentbit&lt;/th&gt; 
   &lt;th&gt;Fluentd&lt;/th&gt; 
   &lt;th&gt;Logstash&lt;/th&gt; 
   &lt;th&gt;Splunk UF&lt;/th&gt; 
   &lt;th&gt;Splunk HF&lt;/th&gt; 
   &lt;th&gt;Telegraf&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;End-to-end&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Aggregator&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Unified&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Logs&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Metrics&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Traces&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Open&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Open-source&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vendor-neutral&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Reliability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory-safe&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Delivery guarantees&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multi-core&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;⚠ = Not interoperable, metrics are represented as structured logs&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; Developed with ❤️ by &lt;strong&gt;&lt;a href="https://datadoghq.com"&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href="https://github.com/vectordotdev/vector/security/policy"&gt;Security Policy&lt;/a&gt; - &lt;a href="https://github.com/vectordotdev/vector/raw/master/PRIVACY.md"&gt;Privacy Policy&lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;OpenAI Codex CLI&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.&lt;br /&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, see &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager. If you use npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, if you use Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="80%" /&gt; &lt;/p&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. &lt;a href="https://help.openai.com/en/articles/11369540-codex-in-chatgpt"&gt;Learn more about what's included in your ChatGPT plan&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also use Codex with an API key, but this requires &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key"&gt;additional setup&lt;/a&gt;. If you previously used an API key for usage-based billing, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#migrating-from-usage-based-billing-api-key"&gt;migration steps&lt;/a&gt;. If you're having trouble with login, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Model Context Protocol (MCP)&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;MCP servers&lt;/a&gt;. Enable by adding an &lt;code&gt;mcp_servers&lt;/code&gt; section to your &lt;code&gt;~/.codex/config.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports a rich set of configuration options, with preferences stored in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For full configuration options, see &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Docs &amp;amp; FAQ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md"&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#cli-usage"&gt;CLI usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#memory--project-docs"&gt;Memory with AGENTS.md&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/sandbox.md"&gt;&lt;strong&gt;Sandbox &amp;amp; approvals&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md"&gt;&lt;strong&gt;Authentication&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#forcing-a-specific-auth-method-advanced"&gt;Auth methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#connecting-on-a-headless-machine"&gt;Login on a "Headless" machine&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md"&gt;&lt;strong&gt;Advanced&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#non-interactive--ci-mode"&gt;Non-interactive / CI mode&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/zdr.md"&gt;&lt;strong&gt;Zero data retention (ZDR)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/contributing.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md"&gt;&lt;strong&gt;Install &amp;amp; build&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#system-requirements"&gt;System Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#build-from-source"&gt;Build from source&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/open-source-fund.md"&gt;&lt;strong&gt;Open source fund&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>carthage-software/mago</title>
      <link>https://github.com/carthage-software/mago</link>
      <description>&lt;p&gt;Mago is a toolchain for PHP that aims to provide a set of tools to help developers write better code.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/carthage-software/mago/main/docs/public/assets/banner.svg?sanitize=true" alt="Mago Banner" width="600" /&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;An extremely fast PHP linter, formatter, and static analyzer, written in Rust.&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/carthage-software/mago/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/carthage-software/mago/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/carthage-software/mago/actions/workflows/cd.yml"&gt;&lt;img src="https://github.com/carthage-software/mago/actions/workflows/cd.yml/badge.svg?sanitize=true" alt="CD Status" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/mago"&gt;&lt;img src="https://img.shields.io/crates/v/mago.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://packagist.org/packages/carthage-software/mago"&gt;&lt;img src="https://poser.pugx.org/carthage-software/mago/v" alt="Latest Stable Version for PHP" /&gt;&lt;/a&gt; &lt;a href="https://packagist.org/packages/carthage-software/mago"&gt;&lt;img src="https://poser.pugx.org/carthage-software/mago/v/unstable" alt="Latest Unstable Version for PHP" /&gt;&lt;/a&gt; &lt;a href="https://packagist.org/packages/carthage-software/mago"&gt;&lt;img src="http://poser.pugx.org/carthage-software/mago/downloads" alt="Total Composer Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/carthage-software/mago/raw/main/LICENSE-MIT"&gt;&lt;img src="https://img.shields.io/crates/l/mago.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Mago&lt;/strong&gt; is a comprehensive toolchain for PHP that helps developers write better code. Inspired by the Rust ecosystem, Mago brings speed, reliability, and an exceptional developer experience to PHP projects of all sizes.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/#getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/#our-sponsors"&gt;Our Sponsors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/#inspiration--acknowledgements"&gt;Inspiration &amp;amp; Acknowledgements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The most common way to install Mago on macOS and Linux is by using our shell script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl --proto '=https' --tlsv1.2 -sSf https://carthage.software/mago.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For all other installation methods, including Homebrew, Composer, and Cargo, please refer to our official &lt;strong&gt;&lt;a href="https://mago.carthage.software/guide/installation"&gt;Installation Guide&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To get started with Mago and learn how to configure your project, please visit our &lt;strong&gt;&lt;a href="https://mago.carthage.software/guide/getting-started"&gt;Getting Started Guide&lt;/a&gt;&lt;/strong&gt; in the official documentation.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡️ Extremely Fast: Built in Rust for maximum performance.&lt;/li&gt; 
 &lt;li&gt;🔍 Lint: Identify issues in your codebase with customizable rules.&lt;/li&gt; 
 &lt;li&gt;🔬 Static Analysis: Perform deep analysis of your codebase to catch potential type errors and bugs.&lt;/li&gt; 
 &lt;li&gt;🛠️ Automated Fixes: Apply fixes for many lint issues automatically.&lt;/li&gt; 
 &lt;li&gt;📜 Formatting: Automatically format your code to adhere to best practices and style guides.&lt;/li&gt; 
 &lt;li&gt;🧠 Semantic Checks: Ensure code correctness with robust semantic analysis.&lt;/li&gt; 
 &lt;li&gt;🌳 AST Visualization: Explore your code’s structure with Abstract Syntax Tree (AST) parsing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- START-SPONSORS --&gt; 
&lt;h2&gt;Our Sponsors&lt;/h2&gt; 
&lt;p align="center"&gt;&lt;a href="https://github.com/jasonrm" title="Jason R. McNeil"&gt;&lt;kbd&gt;&lt;img src="https://avatars.githubusercontent.com/u/39949?u=69c0e4fb08c439250978d41dbc3371d2f0609b98&amp;amp;v=4&amp;amp;s=160" width="80" height="80" alt="Jason R. McNeil" /&gt;&lt;/kbd&gt;&lt;/a&gt;&lt;a href="https://github.com/vvvinceocam" title="Vincent Berset"&gt;&lt;kbd&gt;&lt;img src="https://avatars.githubusercontent.com/u/5173120?u=95efc76cd8fc804536dc6dd25781a95b650bf902&amp;amp;v=4&amp;amp;s=160" width="80" height="80" alt="Vincent Berset" /&gt;&lt;/kbd&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;a href="https://github.com/TicketSwap" title="TicketSwap"&gt;&lt;kbd&gt;&lt;img src="https://avatars.githubusercontent.com/u/5766233?v=4&amp;amp;s=120" width="60" height="60" alt="TicketSwap" /&gt;&lt;/kbd&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/SPONSORS.md"&gt;See all sponsors&lt;/a&gt;&lt;/p&gt; 
&lt;!-- END-SPONSORS --&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Mago is a community-driven project, and we welcome contributions! Whether you're reporting bugs, suggesting features, writing documentation, or submitting code, your help is valued.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;See our &lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; to get started.&lt;/li&gt; 
 &lt;li&gt;Join the discussion on &lt;a href="https://discord.gg/mwyyjr27eu"&gt;Discord&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Inspiration &amp;amp; Acknowledgements&lt;/h2&gt; 
&lt;p&gt;Mago stands on the shoulders of giants. Our design and functionality are heavily inspired by pioneering tools in both the Rust and PHP ecosystems.&lt;/p&gt; 
&lt;h3&gt;Inspirations:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rust-lang/rust-clippy"&gt;Clippy&lt;/a&gt;: For its comprehensive linting approach.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oxc-project/oxc/"&gt;OXC&lt;/a&gt;: A major inspiration for building a high-performance toolchain in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/slackhq/hakana/"&gt;Hakana&lt;/a&gt;: For its deep static analysis capabilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Acknowledgements:&lt;/h3&gt; 
&lt;p&gt;We deeply respect the foundational work of tools like &lt;a href="https://github.com/PHP-CS-Fixer/PHP-CS-Fixer"&gt;PHP-CS-Fixer&lt;/a&gt;, &lt;a href="https://github.com/vimeo/psalm"&gt;Psalm&lt;/a&gt;, &lt;a href="https://github.com/phpstan/phpstan"&gt;PHPStan&lt;/a&gt;, and &lt;a href="https://github.com/squizlabs/PHP_CodeSniffer"&gt;PHP_CodeSniffer&lt;/a&gt;. While Mago aims to offer a unified and faster alternative, these tools paved the way for modern PHP development.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Mago is dual-licensed under your choice of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MIT License (&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Apache License, Version 2.0 (&lt;a href="https://raw.githubusercontent.com/carthage-software/mago/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>kata-containers/kata-containers</title>
      <link>https://github.com/kata-containers/kata-containers</link>
      <description>&lt;p&gt;Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/&lt;/p&gt;&lt;hr&gt;&lt;img src="https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-images-prod/openstack-logo/kata/SVG/kata-1.svg?sanitize=true" width="900" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml"&gt;&lt;img src="https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml/badge.svg?sanitize=true" alt="CI | Publish Kata Containers payload" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml"&gt;&lt;img src="https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml/badge.svg?sanitize=true" alt="Kata Containers Nightly CI" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/kata-containers/kata-containers"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/kata-containers/kata-containers/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Kata Containers&lt;/h1&gt; 
&lt;p&gt;Welcome to Kata Containers!&lt;/p&gt; 
&lt;p&gt;This repository is the home of the Kata Containers code for the 2.0 and newer releases.&lt;/p&gt; 
&lt;p&gt;If you want to learn about Kata Containers, visit the main &lt;a href="https://katacontainers.io"&gt;Kata Containers website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The code is licensed under the Apache 2.0 license. See &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/LICENSE"&gt;the license file&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;Kata Containers currently runs on 64-bit systems supporting the following technologies:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;Virtualization technology&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x86_64&lt;/code&gt;, &lt;code&gt;amd64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.intel.com"&gt;Intel&lt;/a&gt; VT-x, AMD SVM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;aarch64&lt;/code&gt; ("&lt;code&gt;arm64&lt;/code&gt;")&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.arm.com"&gt;ARM&lt;/a&gt; Hyp&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ppc64le&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.ibm.com"&gt;IBM&lt;/a&gt; Power&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;s390x&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.ibm.com"&gt;IBM&lt;/a&gt; Z &amp;amp; LinuxONE SIE&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware requirements&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;Kata Containers runtime&lt;/a&gt; provides a command to determine if your host system is capable of running and creating a Kata Container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ kata-runtime check
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;This command runs a number of checks including connecting to the network to determine if a newer release of Kata Containers is available on GitHub. If you do not wish this to check to run, add the &lt;code&gt;--no-network-checks&lt;/code&gt; option.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;By default, only a brief success / failure message is printed. If more details are needed, the &lt;code&gt;--verbose&lt;/code&gt; flag can be used to display the list of all the checks performed.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;If the command is run as the &lt;code&gt;root&lt;/code&gt; user additional checks are run (including checking if another incompatible hypervisor is running). When running as &lt;code&gt;root&lt;/code&gt;, network checks are automatically disabled.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install"&gt;installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs"&gt;official documentation&lt;/a&gt; including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install"&gt;Installation guides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/Developer-Guide.md"&gt;Developer guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design"&gt;Design documents&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design/architecture"&gt;Architecture overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design/architecture_3.0/"&gt;Architecture 3.0 overview&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Kata Containers uses a single &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime/README.md#configuration"&gt;configuration file&lt;/a&gt; which contains a number of sections for various parts of the Kata Containers system including the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;runtime&lt;/a&gt;, the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/agent"&gt;agent&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/#hypervisors"&gt;hypervisor&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Hypervisors&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/hypervisors.md"&gt;hypervisors document&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime/README.md#hypervisor-specific-configuration"&gt;Hypervisor specific configuration details&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;To learn more about the project, its community and governance, see the &lt;a href="https://github.com/kata-containers/community"&gt;community repository&lt;/a&gt;. This is the first place to go if you wish to contribute to the project.&lt;/p&gt; 
&lt;h2&gt;Getting help&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/#community"&gt;community&lt;/a&gt; section for ways to contact us.&lt;/p&gt; 
&lt;h3&gt;Raising issues&lt;/h3&gt; 
&lt;p&gt;Please raise an issue &lt;a href="https://github.com/kata-containers/kata-containers/issues"&gt;in this repository&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you are reporting a security issue, please follow the &lt;a href="https://github.com/kata-containers/community#vulnerability-handling"&gt;vulnerability reporting process&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Developers&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/Developer-Guide.md"&gt;developer guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Components&lt;/h3&gt; 
&lt;h3&gt;Main components&lt;/h3&gt; 
&lt;p&gt;The table below lists the core parts of the project:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;runtime&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;Main component run by a container manager and providing a containerd shimv2 runtime implementation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime-rs"&gt;runtime-rs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;The Rust version runtime.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/agent"&gt;agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;Management process running inside the virtual machine / POD that sets up the container environment.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/dragonball"&gt;&lt;code&gt;dragonball&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;An optional built-in VMM brings out-of-the-box Kata Containers experience with optimizations on container workloads&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs"&gt;documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;documentation&lt;/td&gt; 
   &lt;td&gt;Documentation common to all components (such as design and install documentation).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests"&gt;tests&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;tests&lt;/td&gt; 
   &lt;td&gt;Excludes unit tests which live with the main code.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Additional components&lt;/h3&gt; 
&lt;p&gt;The table below lists the remaining parts of the project:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging"&gt;packaging&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Scripts and metadata for producing packaged binaries&lt;br /&gt;(components, hypervisors, kernel and rootfs).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.kernel.org"&gt;kernel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;kernel&lt;/td&gt; 
   &lt;td&gt;Linux kernel used by the hypervisor to boot the guest image. Patches are stored &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kernel"&gt;here&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/osbuilder"&gt;osbuilder&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Tool to create "mini O/S" rootfs and initrd images and kernel for the hypervisor.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-debug/README.md"&gt;kata-debug&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Utility tool to gather Kata Containers debug information from Kubernetes clusters.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/agent-ctl"&gt;&lt;code&gt;agent-ctl&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Tool that provides low-level access for testing the agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/kata-ctl"&gt;&lt;code&gt;kata-ctl&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Tool that provides advanced commands and debug facilities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/trace-forwarder"&gt;&lt;code&gt;trace-forwarder&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Agent tracing helper.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/runk"&gt;&lt;code&gt;runk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Standard OCI container runtime based on the agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/.github/workflows"&gt;&lt;code&gt;ci&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CI&lt;/td&gt; 
   &lt;td&gt;Continuous Integration configuration files and scripts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/ci/openshift-ci/README.md"&gt;&lt;code&gt;ocp-ci&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CI&lt;/td&gt; 
   &lt;td&gt;Continuous Integration configuration for the OpenShift pipelines.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kata-containers/www.katacontainers.io"&gt;&lt;code&gt;katacontainers.io&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Source for the &lt;a href="https://www.katacontainers.io"&gt;&lt;code&gt;katacontainers.io&lt;/code&gt;&lt;/a&gt; site.&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/testing/kata-webhook/README.md"&gt;&lt;code&gt;Webhook&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Example of a simple admission controller webhook to annotate pods with the Kata runtime class&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Packaging and releases&lt;/h3&gt; 
&lt;p&gt;Kata Containers is now &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install/README.md#packaged-installation-methods"&gt;available natively for most distributions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;General tests&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests/README.md"&gt;tests documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Metrics tests&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests/metrics/README.md"&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Glossary of Terms&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/kata-containers/kata-containers/wiki/Glossary"&gt;glossary of terms&lt;/a&gt; related to Kata Containers.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>j178/prek</title>
      <link>https://github.com/j178/prek</link>
      <description>&lt;p&gt;⚡ Better `pre-commit`, re-engineered in Rust&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;prek&lt;/h1&gt; 
 &lt;img width="220" alt="prek" src="https://github.com/user-attachments/assets/3a87815a-9f3c-48e7-8c1d-384b07ad3b35" /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/j178/prek/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/j178/prek/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/j178/prek/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/j178/prek/total?logo=github" alt="GitHub Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/prek"&gt;&lt;img src="https://img.shields.io/pypi/dm/prek?logo=python" alt="PyPI Downloads" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/3NRJUqJz86"&gt;&lt;img src="https://img.shields.io/discord/1403581202102878289?logo=discord" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://pre-commit.com/"&gt;pre-commit&lt;/a&gt; is a framework to run hooks written in many languages, and it manages the language toolchain and dependencies for running the hooks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;prek&lt;/strong&gt; is a reimagined version of pre-commit, built in Rust. It is designed to be a faster, dependency-free and drop-in alternative for it, while also providing some additional long-requested features.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] prek is not production-ready yet, a few subcommands and languages are still in works. But it's already being adopted by &lt;a href="https://raw.githubusercontent.com/j178/prek/master/#who-are-using-prek"&gt;some projects&lt;/a&gt;, please give it a try - we'd love your feedback!&lt;/p&gt; 
 &lt;p&gt;Current supported languages are &lt;code&gt;python&lt;/code&gt;, &lt;code&gt;node&lt;/code&gt;, &lt;code&gt;go&lt;/code&gt;, &lt;code&gt;docker&lt;/code&gt;, &lt;code&gt;docker-image&lt;/code&gt;, &lt;code&gt;pygrep&lt;/code&gt;, &lt;code&gt;system&lt;/code&gt;, &lt;code&gt;script&lt;/code&gt; and &lt;code&gt;fail&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🚀 A single binary with no dependencies, does not require Python or any other runtime.&lt;/li&gt; 
 &lt;li&gt;⚡ About &lt;a href="https://github.com/j178/prek/raw/master/docs/BENCHMARK.md"&gt;10x faster&lt;/a&gt; than &lt;code&gt;pre-commit&lt;/code&gt; and uses only a third of disk space.&lt;/li&gt; 
 &lt;li&gt;🔄 Fully compatible with the original pre-commit configurations and hooks.&lt;/li&gt; 
 &lt;li&gt;🐍 Integration with &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt; for managing Python virtual environments and dependencies.&lt;/li&gt; 
 &lt;li&gt;🛠️ Improved toolchain installations for Python, Node.js, Go, Rust and Ruby, shared between hooks.&lt;/li&gt; 
 &lt;li&gt;📦 Built-in implementation of some common hooks.&lt;/li&gt; 
 &lt;li&gt;🏗️ (TODO) Built-in support for monorepos.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to migrate&lt;/h2&gt; 
&lt;p&gt;prek is designed as a drop-in replacement:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/j178/prek/master/#installation"&gt;Install prek&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Replace &lt;code&gt;pre-commit&lt;/code&gt; with &lt;code&gt;prek&lt;/code&gt; in your commands&lt;/li&gt; 
 &lt;li&gt;Your existing &lt;code&gt;.pre-commit-config.yaml&lt;/code&gt; works unchanged&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ prek run
trim trailing whitespace.................................................Passed
fix end of files.........................................................Passed
typos....................................................................Passed
cargo fmt................................................................Passed
cargo clippy.............................................................Passed
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For configuring &lt;code&gt;.pre-commit-config.yaml&lt;/code&gt; and writing hooks, you can refer to the &lt;a href="https://pre-commit.com/"&gt;pre-commit documentation&lt;/a&gt; as prek is fully compatible with it.&lt;/p&gt; 
&lt;h2&gt;Why prek?&lt;/h2&gt; 
&lt;h3&gt;prek is way faster&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;It is about &lt;a href="https://github.com/j178/prek/raw/master/docs/BENCHMARK.md"&gt;10x faster&lt;/a&gt; than &lt;code&gt;pre-commit&lt;/code&gt; and uses only a third of disk space.&lt;/li&gt; 
 &lt;li&gt;It redesigned how hook environments and toolchains are managed, they are all shared between hooks, which reduces the disk space usage and speeds up the installation process.&lt;/li&gt; 
 &lt;li&gt;Repositories are cloned in parallel, and hooks are installed in parallel if their dependencies are disjoint.&lt;/li&gt; 
 &lt;li&gt;It uses &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt; for creating Python virtualenvs and installing dependencies, which is known for its speed and efficiency.&lt;/li&gt; 
 &lt;li&gt;It implements some common hooks in Rust, built in prek, which are faster than their Python counterparts.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;prek provides a better user experience&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;No need to install Python or any other runtime, just download a single binary.&lt;/li&gt; 
 &lt;li&gt;No hassle with your Python version or virtual environments, prek automatically installs the required Python version and creates a virtual environment for you.&lt;/li&gt; 
 &lt;li&gt;(TODO): Built-in support for workspaces (or monorepos), each subproject can have its own &lt;code&gt;.pre-commit-config.yaml&lt;/code&gt; file.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;prek run&lt;/code&gt; has some improvements over &lt;code&gt;pre-commit run&lt;/code&gt;, such as: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;prek run --directory &amp;lt;dir&amp;gt;&lt;/code&gt; runs hooks for files in the specified directory, no need to use &lt;code&gt;git ls-files -- &amp;lt;dir&amp;gt; | xargs pre-commit run --files&lt;/code&gt; anymore.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;prek run --last-commit&lt;/code&gt; runs hooks for files changed in the last commit.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;prek list&lt;/code&gt; command lists all available hooks, their ids, and descriptions, providing a better overview of the configured hooks.&lt;/li&gt; 
 &lt;li&gt;prek provides shell completions for &lt;code&gt;prek run &amp;lt;hook_id&amp;gt;&lt;/code&gt; command, making it easier to run specific hooks without remembering their ids.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Who are using prek?&lt;/h2&gt; 
&lt;p&gt;prek is pretty new, but it is already being used or recommend by some projects and organizations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apache/airflow/issues/44995"&gt;Airflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pdm-project/pdm/pull/3593"&gt;PDM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DetachHead/basedpyright/pull/1413"&gt;basedpyright&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenLineage/OpenLineage/pull/3965"&gt;OpenLineage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/authlib/authlib/pull/804"&gt;Authlib&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Standalone installer&lt;/summary&gt; 
 &lt;p&gt;prek provides a standalone installer script to download and install the tool:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;# On Linux and macOS
curl --proto '=https' --tlsv1.2 -LsSf https://github.com/j178/prek/releases/download/v0.1.6/prek-installer.sh | sh

# On Windows
powershell -ExecutionPolicy ByPass -c "irm https://github.com/j178/prek/releases/download/v0.1.6/prek-installer.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;PyPI&lt;/summary&gt; 
 &lt;p&gt;prek is published as Python binary wheel to PyPI, you can install it using &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;uv&lt;/code&gt; (recommended), or &lt;code&gt;pipx&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;pip install prek

# or

uv tool install prek

# or

pipx install prek
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Homebrew&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;brew install prek
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;mise&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;mise use prek
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Cargo&lt;/summary&gt; 
 &lt;p&gt;Build from source using Cargo:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;cargo install --locked --git https://github.com/j178/prek
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;GitHub Releases&lt;/summary&gt; 
 &lt;p&gt;prek release artifacts can be downloaded directly from the &lt;a href="https://github.com/j178/prek/releases"&gt;GitHub releases&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;If installed via the standalone installer, prek can update itself to the latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ prek self update
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is heavily inspired by the original &lt;a href="https://pre-commit.com/"&gt;pre-commit&lt;/a&gt; tool, and it wouldn't be possible without the hard work of the maintainers and contributors of that project.&lt;/p&gt; 
&lt;p&gt;And a special thanks to the &lt;a href="https://github.com/astral-sh"&gt;Astral&lt;/a&gt; team for their remarkable projects, particularly &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt;, from which I've learned a lot on how to write efficient and idiomatic Rust code.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pola-rs/polars</title>
      <link>https://github.com/pola-rs/polars</link>
      <description>&lt;p&gt;Dataframes powered by a multithreaded, vectorized query engine, written in Rust&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://pola.rs"&gt; &lt;img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/banner/polars_github_banner.svg?sanitize=true" alt="Polars logo" /&gt; &lt;/a&gt; &lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://crates.io/crates/polars"&gt; &lt;img src="https://img.shields.io/crates/v/polars.svg?sanitize=true" alt="crates.io Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://pypi.org/project/polars/"&gt; &lt;img src="https://img.shields.io/pypi/v/polars.svg?sanitize=true" alt="PyPi Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://www.npmjs.com/package/nodejs-polars"&gt; &lt;img src="https://img.shields.io/npm/v/nodejs-polars.svg?sanitize=true" alt="NPM Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://community.r-multiverse.org/polars"&gt; &lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fcommunity.r-multiverse.org%2Fapi%2Fpackages%2Fpolars&amp;amp;query=%24.Version&amp;amp;label=r-multiverse" alt="R-multiverse Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://doi.org/10.5281/zenodo.7697217"&gt; &lt;img src="https://zenodo.org/badge/DOI/10.5281/zenodo.7697217.svg?sanitize=true" alt="DOI Latest Release" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;b&gt;Documentation&lt;/b&gt;: &lt;a href="https://docs.pola.rs/api/python/stable/reference/index.html"&gt;Python&lt;/a&gt; - &lt;a href="https://docs.rs/polars/latest/polars/"&gt;Rust&lt;/a&gt; - &lt;a href="https://pola-rs.github.io/nodejs-polars/index.html"&gt;Node.js&lt;/a&gt; - &lt;a href="https://pola-rs.github.io/r-polars/index.html"&gt;R&lt;/a&gt; | &lt;b&gt;StackOverflow&lt;/b&gt;: &lt;a href="https://stackoverflow.com/questions/tagged/python-polars"&gt;Python&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/rust-polars"&gt;Rust&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/nodejs-polars"&gt;Node.js&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/r-polars"&gt;R&lt;/a&gt; | &lt;a href="https://docs.pola.rs/"&gt;User guide&lt;/a&gt; | &lt;a href="https://discord.gg/4UfP5cfBE7"&gt;Discord&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Polars: Blazingly fast DataFrames in Rust, Python, Node.js, R, and SQL&lt;/h2&gt; 
&lt;p&gt;Polars is a DataFrame interface on top of an OLAP Query Engine implemented in Rust using &lt;a href="https://arrow.apache.org/docs/format/Columnar.html"&gt;Apache Arrow Columnar Format&lt;/a&gt; as the memory model.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Lazy | eager execution&lt;/li&gt; 
 &lt;li&gt;Multi-threaded&lt;/li&gt; 
 &lt;li&gt;SIMD&lt;/li&gt; 
 &lt;li&gt;Query optimization&lt;/li&gt; 
 &lt;li&gt;Powerful expression API&lt;/li&gt; 
 &lt;li&gt;Hybrid Streaming (larger-than-RAM datasets)&lt;/li&gt; 
 &lt;li&gt;Rust | Python | NodeJS | R | ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To learn more, read the &lt;a href="https://docs.pola.rs/"&gt;user guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Python&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; import polars as pl
&amp;gt;&amp;gt;&amp;gt; df = pl.DataFrame(
...     {
...         "A": [1, 2, 3, 4, 5],
...         "fruits": ["banana", "banana", "apple", "apple", "banana"],
...         "B": [5, 4, 3, 2, 1],
...         "cars": ["beetle", "audi", "beetle", "beetle", "beetle"],
...     }
... )

# embarrassingly parallel execution &amp;amp; very expressive query language
&amp;gt;&amp;gt;&amp;gt; df.sort("fruits").select(
...     "fruits",
...     "cars",
...     pl.lit("fruits").alias("literal_string_fruits"),
...     pl.col("B").filter(pl.col("cars") == "beetle").sum(),
...     pl.col("A").filter(pl.col("B") &amp;gt; 2).sum().over("cars").alias("sum_A_by_cars"),
...     pl.col("A").sum().over("fruits").alias("sum_A_by_fruits"),
...     pl.col("A").reverse().over("fruits").alias("rev_A_by_fruits"),
...     pl.col("A").sort_by("B").over("fruits").alias("sort_A_by_B_by_fruits"),
... )
shape: (5, 8)
┌──────────┬──────────┬──────────────┬─────┬─────────────┬─────────────┬─────────────┬─────────────┐
│ fruits   ┆ cars     ┆ literal_stri ┆ B   ┆ sum_A_by_ca ┆ sum_A_by_fr ┆ rev_A_by_fr ┆ sort_A_by_B │
│ ---      ┆ ---      ┆ ng_fruits    ┆ --- ┆ rs          ┆ uits        ┆ uits        ┆ _by_fruits  │
│ str      ┆ str      ┆ ---          ┆ i64 ┆ ---         ┆ ---         ┆ ---         ┆ ---         │
│          ┆          ┆ str          ┆     ┆ i64         ┆ i64         ┆ i64         ┆ i64         │
╞══════════╪══════════╪══════════════╪═════╪═════════════╪═════════════╪═════════════╪═════════════╡
│ "apple"  ┆ "beetle" ┆ "fruits"     ┆ 11  ┆ 4           ┆ 7           ┆ 4           ┆ 4           │
│ "apple"  ┆ "beetle" ┆ "fruits"     ┆ 11  ┆ 4           ┆ 7           ┆ 3           ┆ 3           │
│ "banana" ┆ "beetle" ┆ "fruits"     ┆ 11  ┆ 4           ┆ 8           ┆ 5           ┆ 5           │
│ "banana" ┆ "audi"   ┆ "fruits"     ┆ 11  ┆ 2           ┆ 8           ┆ 2           ┆ 2           │
│ "banana" ┆ "beetle" ┆ "fruits"     ┆ 11  ┆ 4           ┆ 8           ┆ 1           ┆ 1           │
└──────────┴──────────┴──────────────┴─────┴─────────────┴─────────────┴─────────────┴─────────────┘
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;SQL&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; df = pl.scan_csv("docs/assets/data/iris.csv")
&amp;gt;&amp;gt;&amp;gt; ## OPTION 1
&amp;gt;&amp;gt;&amp;gt; # run SQL queries on frame-level
&amp;gt;&amp;gt;&amp;gt; df.sql("""
...	SELECT species,
...	  AVG(sepal_length) AS avg_sepal_length
...	FROM self
...	GROUP BY species
...	""").collect()
shape: (3, 2)
┌────────────┬──────────────────┐
│ species    ┆ avg_sepal_length │
│ ---        ┆ ---              │
│ str        ┆ f64              │
╞════════════╪══════════════════╡
│ Virginica  ┆ 6.588            │
│ Versicolor ┆ 5.936            │
│ Setosa     ┆ 5.006            │
└────────────┴──────────────────┘
&amp;gt;&amp;gt;&amp;gt; ## OPTION 2
&amp;gt;&amp;gt;&amp;gt; # use pl.sql() to operate on the global context
&amp;gt;&amp;gt;&amp;gt; df2 = pl.LazyFrame({
...    "species": ["Setosa", "Versicolor", "Virginica"],
...    "blooming_season": ["Spring", "Summer", "Fall"]
...})
&amp;gt;&amp;gt;&amp;gt; pl.sql("""
... SELECT df.species,
...     AVG(df.sepal_length) AS avg_sepal_length,
...     df2.blooming_season
... FROM df
... LEFT JOIN df2 ON df.species = df2.species
... GROUP BY df.species, df2.blooming_season
... """).collect()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SQL commands can also be run directly from your terminal using the Polars CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# run an inline SQL query
&amp;gt; polars -c "SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv('docs/assets/data/iris.csv') GROUP BY species;"

# run interactively
&amp;gt; polars
Polars CLI v0.3.0
Type .help for help.

&amp;gt; SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv('docs/assets/data/iris.csv') GROUP BY species;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to the &lt;a href="https://github.com/pola-rs/polars-cli"&gt;Polars CLI repository&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Performance 🚀🚀&lt;/h2&gt; 
&lt;h3&gt;Blazingly fast&lt;/h3&gt; 
&lt;p&gt;Polars is very fast. In fact, it is one of the best performing solutions available. See the &lt;a href="https://www.pola.rs/benchmarks.html"&gt;PDS-H benchmarks&lt;/a&gt; results.&lt;/p&gt; 
&lt;h3&gt;Lightweight&lt;/h3&gt; 
&lt;p&gt;Polars is also very lightweight. It comes with zero required dependencies, and this shows in the import times:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;polars: 70ms&lt;/li&gt; 
 &lt;li&gt;numpy: 104ms&lt;/li&gt; 
 &lt;li&gt;pandas: 520ms&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Handles larger-than-RAM data&lt;/h3&gt; 
&lt;p&gt;If you have data that does not fit into memory, Polars' query engine is able to process your query (or parts of your query) in a streaming fashion. This drastically reduces memory requirements, so you might be able to process your 250GB dataset on your laptop. Collect with &lt;code&gt;collect(engine='streaming')&lt;/code&gt; to run the query streaming. (This might be a little slower, but it is still very fast!)&lt;/p&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;p&gt;Install the latest Polars version with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install polars
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We also have a conda package (&lt;code&gt;conda install -c conda-forge polars&lt;/code&gt;), however pip is the preferred way to install Polars.&lt;/p&gt; 
&lt;p&gt;Install Polars with all optional dependencies.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install 'polars[all]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also install a subset of all optional dependencies.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install 'polars[numpy,pandas,pyarrow]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.pola.rs/user-guide/installation/#feature-flags"&gt;User Guide&lt;/a&gt; for more details on optional dependencies&lt;/p&gt; 
&lt;p&gt;To see the current Polars version and a full list of its optional dependencies, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pl.show_versions()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Releases happen quite often (weekly / every few days) at the moment, so updating Polars regularly to get the latest bugfixes / features might not be a bad idea.&lt;/p&gt; 
&lt;h3&gt;Rust&lt;/h3&gt; 
&lt;p&gt;You can take latest release from &lt;code&gt;crates.io&lt;/code&gt;, or if you want to use the latest features / performance improvements point to the &lt;code&gt;main&lt;/code&gt; branch of this repo.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;polars = { git = "https://github.com/pola-rs/polars", rev = "&amp;lt;optional git tag&amp;gt;" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Requires Rust version &lt;code&gt;&amp;gt;=1.80&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute? Read our &lt;a href="https://docs.pola.rs/development/contributing/"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Python: compile Polars from source&lt;/h2&gt; 
&lt;p&gt;If you want a bleeding edge release or maximal performance you should compile Polars from source.&lt;/p&gt; 
&lt;p&gt;This can be done by going through the following steps in sequence:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the latest &lt;a href="https://www.rust-lang.org/tools/install"&gt;Rust compiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://maturin.rs/"&gt;maturin&lt;/a&gt;: &lt;code&gt;pip install maturin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cd py-polars&lt;/code&gt; and choose one of the following: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;make build&lt;/code&gt;, slow binary with debug assertions and symbols, fast compile times&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-release&lt;/code&gt;, fast binary without debug assertions, minimal debug symbols, long compile times&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-nodebug-release&lt;/code&gt;, same as build-release but without any debug symbols, slightly faster to compile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-debug-release&lt;/code&gt;, same as build-release but with full debug symbols, slightly slower to compile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-dist-release&lt;/code&gt;, fastest binary, extreme compile times&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;By default the binary is compiled with optimizations turned on for a modern CPU. Specify &lt;code&gt;LTS_CPU=1&lt;/code&gt; with the command if your CPU is older and does not support e.g. AVX2.&lt;/p&gt; 
&lt;p&gt;Note that the Rust crate implementing the Python bindings is called &lt;code&gt;py-polars&lt;/code&gt; to distinguish from the wrapped Rust crate &lt;code&gt;polars&lt;/code&gt; itself. However, both the Python package and the Python module are named &lt;code&gt;polars&lt;/code&gt;, so you can &lt;code&gt;pip install polars&lt;/code&gt; and &lt;code&gt;import polars&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Using custom Rust functions in Python&lt;/h2&gt; 
&lt;p&gt;Extending Polars with UDFs compiled in Rust is easy. We expose PyO3 extensions for &lt;code&gt;DataFrame&lt;/code&gt; and &lt;code&gt;Series&lt;/code&gt; data structures. See more in &lt;a href="https://github.com/pola-rs/polars/tree/main/pyo3-polars"&gt;https://github.com/pola-rs/polars/tree/main/pyo3-polars&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Going big...&lt;/h2&gt; 
&lt;p&gt;Do you expect more than 2^32 (~4.2 billion) rows? Compile Polars with the &lt;code&gt;bigidx&lt;/code&gt; feature flag or, for Python users, install &lt;code&gt;pip install polars-u64-idx&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Don't use this unless you hit the row boundary as the default build of Polars is faster and consumes less memory.&lt;/p&gt; 
&lt;h2&gt;Legacy&lt;/h2&gt; 
&lt;p&gt;Do you want Polars to run on an old CPU (e.g. dating from before 2011), or on an &lt;code&gt;x86-64&lt;/code&gt; build of Python on Apple Silicon under Rosetta? Install &lt;code&gt;pip install polars-lts-cpu&lt;/code&gt;. This version of Polars is compiled without &lt;a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions"&gt;AVX&lt;/a&gt; target features.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.jetbrains.com"&gt;&lt;img src="https://www.jetbrains.com/company/brand/img/jetbrains_logo.png" height="50" alt="JetBrains logo" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/edit</title>
      <link>https://github.com/microsoft/edit</link>
      <description>&lt;p&gt;We all edit.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/edit/main/assets/edit.svg?sanitize=true" alt="Application Icon for Edit" /&gt; Edit&lt;/h1&gt; 
&lt;p&gt;A simple editor for simple needs.&lt;/p&gt; 
&lt;p&gt;This editor pays homage to the classic &lt;a href="https://en.wikipedia.org/wiki/MS-DOS_Editor"&gt;MS-DOS Editor&lt;/a&gt;, but with a modern interface and input controls similar to VS Code. The goal is to provide an accessible editor that even users largely unfamiliar with terminals can easily use.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/edit/main/assets/edit_hero_image.png" alt="Screenshot of Edit with the About dialog in the foreground" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/microsoft-edit/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/microsoft-edit.svg?exclude_unsupported=1" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also download binaries from &lt;a href="https://github.com/microsoft/edit/releases/latest"&gt;our Releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;You can install the latest version with WinGet:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;winget install Microsoft.Edit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Build Instructions&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.rust-lang.org/tools/install"&gt;Install Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install the nightly toolchain: &lt;code&gt;rustup install nightly&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternatively, set the environment variable &lt;code&gt;RUSTC_BOOTSTRAP=1&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Clone the repository&lt;/li&gt; 
 &lt;li&gt;For a release build, run: &lt;code&gt;cargo build --config .cargo/release.toml --release&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build Configuration&lt;/h3&gt; 
&lt;p&gt;During compilation you can set various environment variables to configure the build. The following table lists the available configuration options:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Environment variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;EDIT_CFG_ICU*&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;See &lt;a href="https://raw.githubusercontent.com/microsoft/edit/main/#icu-library-name-soname"&gt;ICU library name (SONAME)&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;EDIT_CFG_LANGUAGES&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A comma-separated list of languages to include in the build. See &lt;a href="https://raw.githubusercontent.com/microsoft/edit/main/i18n/edit.toml"&gt;i18n/edit.toml&lt;/a&gt; for available languages.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Notes to Package Maintainers&lt;/h2&gt; 
&lt;h3&gt;Package Naming&lt;/h3&gt; 
&lt;p&gt;The canonical executable name is "edit" and the alternative name is "msedit". We're aware of the potential conflict of "edit" with existing commands and recommend alternatively naming packages and executables "msedit". Names such as "ms-edit" should be avoided. Assigning an "edit" alias is recommended, if possible.&lt;/p&gt; 
&lt;h3&gt;ICU library name (SONAME)&lt;/h3&gt; 
&lt;p&gt;This project &lt;em&gt;optionally&lt;/em&gt; depends on the ICU library for its Search and Replace functionality. By default, the project will look for a SONAME without version suffix:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows: &lt;code&gt;icuuc.dll&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;macOS: &lt;code&gt;libicuuc.dylib&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;UNIX, and other OS: &lt;code&gt;libicuuc.so&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If your installation uses a different SONAME, please set the following environment variable at build time:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;EDIT_CFG_ICUUC_SONAME&lt;/code&gt;: For instance, &lt;code&gt;libicuuc.so.76&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;EDIT_CFG_ICUI18N_SONAME&lt;/code&gt;: For instance, &lt;code&gt;libicui18n.so.76&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, this project assumes that the ICU exports are exported without &lt;code&gt;_&lt;/code&gt; prefix and without version suffix, such as &lt;code&gt;u_errorName&lt;/code&gt;. If your installation uses versioned exports, please set:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;EDIT_CFG_ICU_CPP_EXPORTS&lt;/code&gt;: If set to &lt;code&gt;true&lt;/code&gt;, it'll look for C++ symbols such as &lt;code&gt;_u_errorName&lt;/code&gt;. Enabled by default on macOS.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;EDIT_CFG_ICU_RENAMING_VERSION&lt;/code&gt;: If set to a version number, such as &lt;code&gt;76&lt;/code&gt;, it'll look for symbols such as &lt;code&gt;u_errorName_76&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, you can set the following environment variables:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;EDIT_CFG_ICU_RENAMING_AUTO_DETECT&lt;/code&gt;: If set to &lt;code&gt;true&lt;/code&gt;, the executable will try to detect the &lt;code&gt;EDIT_CFG_ICU_RENAMING_VERSION&lt;/code&gt; value at runtime. The way it does this is not officially supported by ICU and as such is not recommended to be relied upon. Enabled by default on UNIX (excluding macOS) if no other options are set.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To test your settings, run &lt;code&gt;cargo test&lt;/code&gt; again but with the &lt;code&gt;--ignored&lt;/code&gt; flag. For instance:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo test -- --ignored
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>