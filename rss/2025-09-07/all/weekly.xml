<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Sat, 06 Sep 2025 01:40:52 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>bytebot-ai/bytebot</title>
      <link>https://github.com/bytebot-ai/bytebot</link>
      <description>&lt;p&gt;Bytebot is a self-hosted AI desktop agent that automates computer tasks through natural language commands, operating within a containerized Linux desktop environment.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytebot-ai/bytebot/main/docs/images/bytebot-logo.png" width="500" alt="Bytebot Logo" /&gt; 
 &lt;h1&gt;Bytebot: Open-Source AI Desktop Agent&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14624" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14624" alt="bytebot-ai%2Fbytebot | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;An AI that has its own computer to complete tasks for you&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://railway.com/deploy/bytebot?referralCode=L9lKXQ"&gt;&lt;img src="https://railway.com/button.svg?sanitize=true" alt="Deploy on Railway" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/bytebot-ai/bytebot/tree/main/docker"&gt;&lt;img src="https://img.shields.io/badge/docker-ready-blue.svg?sanitize=true" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/bytebot-ai/bytebot/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-green.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/d9ewZkWPTP"&gt;&lt;img src="https://img.shields.io/discord/1232768900274585720?color=7289da&amp;amp;label=discord" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://bytebot.ai"&gt;ğŸŒ Website&lt;/a&gt; â€¢ &lt;a href="https://docs.bytebot.ai"&gt;ğŸ“š Documentation&lt;/a&gt; â€¢ &lt;a href="https://discord.com/invite/d9ewZkWPTP"&gt;ğŸ’¬ Discord&lt;/a&gt; â€¢ &lt;a href="https://x.com/bytebot_ai"&gt;ğ• Twitter&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f271282a-27a3-43f3-9b99-b34007fdd169"&gt;https://github.com/user-attachments/assets/f271282a-27a3-43f3-9b99-b34007fdd169&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/72a43cf2-bd87-44c5-a582-e7cbe176f37f"&gt;https://github.com/user-attachments/assets/72a43cf2-bd87-44c5-a582-e7cbe176f37f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What is a Desktop Agent?&lt;/h2&gt; 
&lt;p&gt;A desktop agent is an AI that has its own computer. Unlike browser-only agents or traditional RPA tools, Bytebot comes with a full virtual desktop where it can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use any application (browsers, email clients, office tools, IDEs)&lt;/li&gt; 
 &lt;li&gt;Download and organize files with its own file system&lt;/li&gt; 
 &lt;li&gt;Log into websites and applications using password managers&lt;/li&gt; 
 &lt;li&gt;Read and process documents, PDFs, and spreadsheets&lt;/li&gt; 
 &lt;li&gt;Complete complex multi-step workflows across different programs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Think of it as a virtual employee with their own computer who can see the screen, move the mouse, type on the keyboard, and complete tasks just like a human would.&lt;/p&gt; 
&lt;h2&gt;Why Give AI Its Own Computer?&lt;/h2&gt; 
&lt;p&gt;When AI has access to a complete desktop environment, it unlocks capabilities that aren't possible with browser-only agents or API integrations:&lt;/p&gt; 
&lt;h3&gt;Complete Task Autonomy&lt;/h3&gt; 
&lt;p&gt;Give Bytebot a task like "Download all invoices from our vendor portals and organize them into a folder" and it will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open the browser&lt;/li&gt; 
 &lt;li&gt;Navigate to each portal&lt;/li&gt; 
 &lt;li&gt;Handle authentication (including 2FA via password managers)&lt;/li&gt; 
 &lt;li&gt;Download the files to its local file system&lt;/li&gt; 
 &lt;li&gt;Organize them into a folder&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Process Documents&lt;/h3&gt; 
&lt;p&gt;Upload files directly to Bytebot's desktop and it can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read entire PDFs into its context&lt;/li&gt; 
 &lt;li&gt;Extract data from complex documents&lt;/li&gt; 
 &lt;li&gt;Cross-reference information across multiple files&lt;/li&gt; 
 &lt;li&gt;Create new documents based on analysis&lt;/li&gt; 
 &lt;li&gt;Handle formats that APIs can't access&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Use Real Applications&lt;/h3&gt; 
&lt;p&gt;Bytebot isn't limited to web interfaces. It can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use desktop applications like text editors, VS Code, or email clients&lt;/li&gt; 
 &lt;li&gt;Run scripts and command-line tools&lt;/li&gt; 
 &lt;li&gt;Install new software as needed&lt;/li&gt; 
 &lt;li&gt;Configure applications for specific workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Deploy in 2 Minutes&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Railway (Easiest)&lt;/strong&gt; &lt;a href="https://railway.com/deploy/bytebot?referralCode=L9lKXQ"&gt;&lt;img src="https://railway.com/button.svg?sanitize=true" alt="Deploy on Railway" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Just click and add your AI provider API key.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Docker Compose&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/bytebot-ai/bytebot.git
cd bytebot

# Add your AI provider key (choose one)
echo "ANTHROPIC_API_KEY=sk-ant-..." &amp;gt; docker/.env
# Or: echo "OPENAI_API_KEY=sk-..." &amp;gt; docker/.env
# Or: echo "GEMINI_API_KEY=..." &amp;gt; docker/.env

docker-compose -f docker/docker-compose.yml up -d

# Open http://localhost:9992
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.bytebot.ai/quickstart"&gt;Full deployment guide â†’&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;Bytebot consists of four integrated components:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Virtual Desktop&lt;/strong&gt;: A complete Ubuntu Linux environment with pre-installed applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Agent&lt;/strong&gt;: Understands your tasks and controls the desktop to complete them&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task Interface&lt;/strong&gt;: Web UI where you create tasks and watch Bytebot work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;APIs&lt;/strong&gt;: REST endpoints for programmatic task creation and desktop control&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Natural Language Tasks&lt;/strong&gt;: Just describe what you need done&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Uploads&lt;/strong&gt;: Drop files onto tasks for Bytebot to process&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live Desktop View&lt;/strong&gt;: Watch Bytebot work in real-time&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Takeover Mode&lt;/strong&gt;: Take control when you need to help or configure something&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Password Manager Support&lt;/strong&gt;: Install 1Password, Bitwarden, etc. for automatic authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistent Environment&lt;/strong&gt;: Install programs and they stay available for future tasks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Example Tasks&lt;/h2&gt; 
&lt;h3&gt;Basic Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;"Go to Wikipedia and create a summary of quantum computing"
"Research flights from NYC to London and create a comparison document"
"Take screenshots of the top 5 news websites"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Document Processing&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;"Read the uploaded contracts.pdf and extract all payment terms and deadlines"
"Process these 5 invoice PDFs and create a summary report"
"Download and analyze the latest financial report and answer: What were the key risks mentioned?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multi-Application Workflows&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;"Download last month's bank statements from our three banks and consolidate them"
"Check all our vendor portals for new invoices and create a summary report"
"Log into our CRM, export the customer list, and update records in the ERP system"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Programmatic Control&lt;/h2&gt; 
&lt;h3&gt;Create Tasks via API&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import requests

# Simple task
response = requests.post('http://localhost:9991/tasks', json={
    'description': 'Download the latest sales report and create a summary'
})

# Task with file upload
files = {'files': open('contracts.pdf', 'rb')}
response = requests.post('http://localhost:9991/tasks',
    data={'description': 'Review these contracts for important dates'},
    files=files
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Direct Desktop Control&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Take a screenshot
curl -X POST http://localhost:9990/computer-use \
  -H "Content-Type: application/json" \
  -d '{"action": "screenshot"}'

# Click at specific coordinates
curl -X POST http://localhost:9990/computer-use \
  -H "Content-Type: application/json" \
  -d '{"action": "click_mouse", "coordinate": [500, 300]}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.bytebot.ai/api-reference/introduction"&gt;Full API documentation â†’&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Setting Up Your Desktop Agent&lt;/h2&gt; 
&lt;h3&gt;1. Deploy Bytebot&lt;/h3&gt; 
&lt;p&gt;Use one of the deployment methods above to get Bytebot running.&lt;/p&gt; 
&lt;h3&gt;2. Configure the Desktop&lt;/h3&gt; 
&lt;p&gt;Use the Desktop tab in the UI to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install additional programs you need&lt;/li&gt; 
 &lt;li&gt;Set up password managers for authentication&lt;/li&gt; 
 &lt;li&gt;Configure applications with your preferences&lt;/li&gt; 
 &lt;li&gt;Log into websites you want Bytebot to access&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Start Giving Tasks&lt;/h3&gt; 
&lt;p&gt;Create tasks in natural language and watch Bytebot complete them using the configured desktop.&lt;/p&gt; 
&lt;h2&gt;Use Cases&lt;/h2&gt; 
&lt;h3&gt;Business Process Automation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Invoice processing and data extraction&lt;/li&gt; 
 &lt;li&gt;Multi-system data synchronization&lt;/li&gt; 
 &lt;li&gt;Report generation from multiple sources&lt;/li&gt; 
 &lt;li&gt;Compliance checking across platforms&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Development &amp;amp; Testing&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Automated UI testing&lt;/li&gt; 
 &lt;li&gt;Cross-browser compatibility checks&lt;/li&gt; 
 &lt;li&gt;Documentation generation with screenshots&lt;/li&gt; 
 &lt;li&gt;Code deployment verification&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Research &amp;amp; Analysis&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Competitive analysis across websites&lt;/li&gt; 
 &lt;li&gt;Data gathering from multiple sources&lt;/li&gt; 
 &lt;li&gt;Document analysis and summarization&lt;/li&gt; 
 &lt;li&gt;Market research compilation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Bytebot is built with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Desktop&lt;/strong&gt;: Ubuntu 22.04 with XFCE, Firefox, VS Code, and other tools&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt;: NestJS service that coordinates AI and desktop actions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: Next.js application for task management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Support&lt;/strong&gt;: Works with Anthropic Claude, OpenAI GPT, Google Gemini&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Docker containers for easy self-hosting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Self-Host?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data Privacy&lt;/strong&gt;: Everything runs on your infrastructure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full Control&lt;/strong&gt;: Customize the desktop environment as needed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Limits&lt;/strong&gt;: Use your own AI API keys without platform restrictions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexibility&lt;/strong&gt;: Install any software, access any systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Advanced Features&lt;/h2&gt; 
&lt;h3&gt;Multiple AI Providers&lt;/h3&gt; 
&lt;p&gt;Use any AI provider through our &lt;a href="https://docs.bytebot.ai/deployment/litellm"&gt;LiteLLM integration&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Azure OpenAI&lt;/li&gt; 
 &lt;li&gt;AWS Bedrock&lt;/li&gt; 
 &lt;li&gt;Local models via Ollama&lt;/li&gt; 
 &lt;li&gt;100+ other providers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise Deployment&lt;/h3&gt; 
&lt;p&gt;Deploy on Kubernetes with Helm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/bytebot-ai/bytebot.git
cd bytebot

# Install with Helm
helm install bytebot ./helm \
  --set agent.env.ANTHROPIC_API_KEY=sk-ant-...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.bytebot.ai/deployment/helm"&gt;Enterprise deployment guide â†’&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;a href="https://discord.com/invite/d9ewZkWPTP"&gt;Join our community&lt;/a&gt; for help and discussions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Comprehensive guides at &lt;a href="https://docs.bytebot.ai"&gt;docs.bytebot.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: Report bugs and request features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Whether it's:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› Bug fixes&lt;/li&gt; 
 &lt;li&gt;âœ¨ New features&lt;/li&gt; 
 &lt;li&gt;ğŸ“š Documentation improvements&lt;/li&gt; 
 &lt;li&gt;ğŸŒ Translations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check existing &lt;a href="https://github.com/bytebot-ai/bytebot/issues"&gt;issues&lt;/a&gt; first&lt;/li&gt; 
 &lt;li&gt;Open an issue to discuss major changes&lt;/li&gt; 
 &lt;li&gt;Submit PRs with clear descriptions&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://discord.com/invite/d9ewZkWPTP"&gt;Discord&lt;/a&gt; to discuss ideas&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Bytebot is open source under the Apache 2.0 license.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Give your AI its own computer. See what it can do.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://railway.com/deploy/bytebot?referralCode=L9lKXQ"&gt;&lt;img src="https://railway.com/button.svg?sanitize=true" alt="Deploy on Railway" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;sub&gt;Built by &lt;a href="https://tantl.com"&gt;Tantl Labs&lt;/a&gt; and the open source community&lt;/sub&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>laramies/theHarvester</title>
      <link>https://github.com/laramies/theHarvester</link>
      <description>&lt;p&gt;E-mails, subdomains and names Harvester - OSINT&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>humanlayer/humanlayer</title>
      <link>https://github.com/humanlayer/humanlayer</link>
      <description>&lt;p&gt;HumanLayer enables AI agents to communicate with humans in tool-based and async workflows. Guarantee human oversight of high-stakes function calls with approval workflows across slack, email and more. Bring your LLM and Framework of choice and start giving your AI agents safe access to the world. Agentic Workflows, human in the loop, tool calling&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/humanlayer/humanlayer/main/docs/images/wordmark-light.svg?sanitize=true" alt="Wordmark Logo of HumanLayer" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;ğŸš§ &lt;strong&gt;HumanLayer&lt;/strong&gt; is undergoing some changes...stay tuned! ğŸš§&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://humanlayer.dev/code"&gt;HumanLayer Code&lt;/a&gt; | &lt;a href="https://humanlayer.dev/discord"&gt;Discord&lt;/a&gt; | &lt;a href="https://github.com/humanlayer/humanlayer/releases"&gt;Release&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;&lt;img src="https://img.shields.io/github/stars/humanlayer/humanlayer" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2"&gt;&lt;img src="https://img.shields.io/badge/License-Apache-green.svg?sanitize=true" alt="License: Apache-2" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=fcfc0926-d841-47fb-b8a6-6aba3a6c3228" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/#getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/#why-humanlayer"&gt;Why HumanLayer?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/#key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/#roadmap"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why HumanLayer?&lt;/h2&gt; 
&lt;p&gt;Functions and tools are a key part of &lt;a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance"&gt;Agentic Workflows&lt;/a&gt;. They enable LLMs to interact meaningfully with the outside world and automate broad scopes of impactful work. Correct and accurate function calling is essential for AI agents that do meaningful things like book appointments, interact with customers, manage billing information, write+execute code, and more.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://louis-dupont.medium.com/transforming-software-interactions-with-tool-calling-and-llms-dc39185247e9"&gt;&lt;img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8rEqjGZs_e6dibWeaqaQg.png" alt="Tool Calling Loop from Louis Dupont" /&gt;&lt;/a&gt; &lt;em&gt;From &lt;a href="https://louis-dupont.medium.com/transforming-software-interactions-with-tool-calling-and-llms-dc39185247e9"&gt;https://louis-dupont.medium.com/transforming-software-interactions-with-tool-calling-and-llms-dc39185247e9&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;However&lt;/strong&gt;, the most useful functions we can give to an LLM are also the most risky. We can all imagine the value of an AI Database Administrator that constantly tunes and refactors our SQL database, but most teams wouldn't give an LLM access to run arbitrary SQL statements against a production database (heck, we mostly don't even let humans do that). That is:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;
  &lt;blockquote&gt;
   Even with state-of-the-art agentic reasoning and prompt routing, LLMs are not sufficiently reliable to be given access to high-stakes functions without human oversight
  &lt;/blockquote&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p&gt;To better define what is meant by "high stakes", some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Low Stakes&lt;/strong&gt;: Read Access to public data (e.g. search wikipedia, access public APIs and DataSets)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Low Stakes&lt;/strong&gt;: Communicate with agent author (e.g. an engineer might empower an agent to send them a private Slack message with updates on progress)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium Stakes&lt;/strong&gt;: Read Access to Private Data (e.g. read emails, access calendars, query a CRM)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium Stakes&lt;/strong&gt;: Communicate with strict rules (e.g. sending based on a specific sequence of hard-coded email templates)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Stakes&lt;/strong&gt;: Communicate on my Behalf or on behalf of my Company (e.g. send emails, post to slack, publish social/blog content)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Stakes&lt;/strong&gt;: Write Access to Private Data (e.g. update CRM records, modify feature toggles, update billing information)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt;
 &lt;img style="width: 600px" alt="Image showing the levels of function stakes stacked on top of one another" src="https://raw.githubusercontent.com/humanlayer/humanlayer/main/docs/images/function_stakes.png" /&gt;
&lt;/div&gt; 
&lt;p&gt;The high stakes functions are the ones that are the most valuable and promise the most impact in automating away human workflows. But they are also the ones where "90% accuracy" is not acceptable. Reliability is further impacted by today's LLMs' tendency to hallucinate or craft low-quality text that is clearly AI generated. The sooner teams can get Agents reliably and safely calling these tools with high-quality inputs, the sooner they can reap massive benefits.&lt;/p&gt; 
&lt;p&gt;HumanLayer provides a set of tools to &lt;em&gt;deterministically&lt;/em&gt; guarantee human oversight of high stakes function calls. Even if the LLM makes a mistake or hallucinates, HumanLayer is baked into the tool/function itself, guaranteeing a human in the loop.&lt;/p&gt; 
&lt;div align="center"&gt;
 &lt;img style="width: 400px" alt="HumanLayer @require_approval decorator wrapping the Commnicate on my behalf function" src="https://raw.githubusercontent.com/humanlayer/humanlayer/main/docs/images/humanlayer_require_approval.png" /&gt;
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;
  &lt;blockquote&gt;
    HumanLayer provides a set of tools to *deterministically* guarantee human oversight of high stakes function calls 
  &lt;/blockquote&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;h3&gt;The Future: Autonomous Agents and the "Outer Loop"&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Read More: &lt;a href="https://theouterloop.substack.com/p/openais-realtime-api-is-a-step-towards"&gt;OpenAI's RealTime API is a step towards outer-loop agents&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Between &lt;code&gt;require_approval&lt;/code&gt; and &lt;code&gt;human_as_tool&lt;/code&gt;, HumanLayer is built to empower the next generation of AI agents - Autonomous Agents, but it's just a piece of the puzzle. To clarify "next generation", we can summarize briefly the history of LLM applications.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gen 1&lt;/strong&gt;: Chat - human-initiated question / response interface&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gen 2&lt;/strong&gt;: Agentic Assistants - frameworks drive prompt routing, tool calling, chain of thought, and context window management to get much more reliability and functionality. Most workflows are initiated by humans in single-shot "here's a task, go do it" or rolling chat interfaces.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gen 3&lt;/strong&gt;: Autonomous Agents - no longer human initiated, agents will live in the "outer loop" driving toward their goals using various tools and functions. Human/Agent communication is Agent-initiated rather than human-initiated.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/humanlayer/humanlayer/main/docs/images/gen-2-gen-3-agents.png" alt="gen2 vs gen 3 agents" /&gt;&lt;/p&gt; 
&lt;p&gt;Gen 3 autonomous agents will need ways to consult humans for input on various tasks. In order for these agents to perform actual useful work, they'll need human oversight for sensitive operations.&lt;/p&gt; 
&lt;p&gt;These agents will require ways to contact one or more humans across various channels including chat, email, sms, and more.&lt;/p&gt; 
&lt;p&gt;While early versions of these agents may technically be "human initiated" in that they get kicked off on a regular schedule by e.g. a cron or similar, the best ones will be managing their own scheduling and costs. This will require toolkits for inspecting costs and something akin to &lt;code&gt;sleep_until&lt;/code&gt;. They'll need to run in orchestration frameworks that can durably serialize and resume agent workflows across tool calls that might not return for hours or days. These frameworks will need to support context window management by a "manager LLM" and enable agents to fork sub-chains to handle specialized tasks and roles.&lt;/p&gt; 
&lt;p&gt;Example use cases for these outer loop agents include &lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/examples/langchain/04-human_as_tool_linkedin.py"&gt;the linkedin inbox assistant&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/examples/langchain/05-approvals_and_humans_composite.py"&gt;the customer onboarding assistant&lt;/a&gt;, but that's really just scratching the surface.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;The HumanLayer SDK and docs are open-source and we welcome contributions in the form of issues, documentation, pull requests, and more. See &lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Fun Stuff&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#humanlayer/humanlayer&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=humanlayer/humanlayer&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Development Conventions&lt;/h2&gt; 
&lt;h3&gt;TODO Annotations&lt;/h3&gt; 
&lt;p&gt;We use a priority-based TODO annotation system throughout the codebase:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;TODO(0)&lt;/code&gt;: Critical - never merge&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TODO(1)&lt;/code&gt;: High - architectural flaws, major bugs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TODO(2)&lt;/code&gt;: Medium - minor bugs, missing features&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TODO(3)&lt;/code&gt;: Low - polish, tests, documentation&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TODO(4)&lt;/code&gt;: Questions/investigations needed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;PERF&lt;/code&gt;: Performance optimization opportunities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The HumanLayer SDK and CodeLayer sources in this repo are licensed under the Apache 2 License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•      â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/ğŸPython-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;ğŸ–¥ï¸ &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸš€ Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;âš¡ Fast command-line workflow&lt;br /&gt;ğŸ”§ Developer-friendly interface&lt;br /&gt;ğŸ“Š Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸ¨ Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;ğŸ–±ï¸ Intuitive drag-and-drop&lt;br /&gt;ğŸ“± Responsive design&lt;br /&gt;ğŸ¯ Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;ğŸ¬ &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;ğŸ¯ &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/â–¶ï¸_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“‘ Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;ğŸš€ Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;ğŸ—ï¸ Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;ğŸš€ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;ğŸ’¡ Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;ğŸ¬ Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;â­ Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;ğŸ“„ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸš€ &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸ¨ &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;âš™ï¸ &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Autonomous Multi-Agent Workflow&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ“„ &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”¬ &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;â±ï¸ &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”„ &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["ğŸ“„ Research Papers&amp;lt;br/&amp;gt;ğŸ’¬ Text Prompts&amp;lt;br/&amp;gt;ğŸŒ URLs &amp;amp; Document&amp;lt;br/&amp;gt;ğŸ“ Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["ğŸ§  DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["ğŸš€ Algorithm Implementation &amp;lt;br/&amp;gt;ğŸ¨ Frontend Development &amp;lt;br/&amp;gt;âš™ï¸ Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ—ï¸ Architecture&lt;/h2&gt; 
&lt;h3&gt;ğŸ“Š &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;ğŸ¯ &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;ğŸ§¬ &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;ğŸª„ &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;âš¡ &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;ğŸ’ &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;ğŸ”® &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ”§ &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ§  &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’¾ &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ” &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¤– &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ¯ Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“ Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“„ Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ—ï¸ Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“š Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ§¬ Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ”§ Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;ğŸ“¡ &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ”§ &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ’¡ &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ” brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‚ filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“¥ github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‹ file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš¡ command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ§¬ code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“š code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;ğŸ”§ &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ¯ &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âœï¸ write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“ get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš™ï¸ set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“Š get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;ğŸ›ï¸ &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸš€ Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;ğŸŒŸ &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ğŸ’¡ &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; ğŸ“„ Research Papers â€¢ ğŸ’¬ Natural Language â€¢ ğŸŒ URLs â€¢ ğŸ“‹ Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ¯ &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making â€¢ Workflow Coordination â€¢ Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“ &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“„ &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ“‹ &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis â€¢ Code Requirements Parsing â€¢ Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ” &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“š &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ§¬ &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation â€¢ Testing â€¢ Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; âš¡ &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; ğŸ“¦ Complete Codebase â€¢ ğŸ§ª Test Suite â€¢ ğŸ“š Documentation â€¢ ğŸš€ Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;ğŸ”„ &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;ğŸ¯ Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;ğŸ§  Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;ğŸ” Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;âš¡ Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;h3&gt;ğŸ“¦ &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸš€ Install DeepCode package directly
pip install deepcode-hku

# ğŸ”‘ Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‚ Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;ğŸ”¥ &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# ğŸ”§ Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;ğŸ &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install dependencies
pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;ğŸªŸ &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;ğŸ” &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸŒ Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ’¡ Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;âš¡ &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸš€ &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸŒ Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“„ Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ’¡ Examples&lt;/h2&gt; 
&lt;h3&gt;ğŸ¬ &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ“„ &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ–¼ï¸ &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;ğŸ†• &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸ“„ &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ğŸ“Š &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/ğŸš€_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/ğŸ›ï¸_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/â­_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;ğŸ“„ &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
 &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>weaviate/elysia</title>
      <link>https://github.com/weaviate/elysia</link>
      <description>&lt;p&gt;Python package and backend for the Elysia platform app.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Elysia: Agentic Framework Powered by Decision Trees&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;âš ï¸ Elysia is in beta!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;If you encounter any issues, please &lt;a href="https://github.com/weaviate/elysia/issues"&gt;open an issue on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://pepy.tech/projects/elysia-ai"&gt;&lt;img src="https://static.pepy.tech/badge/elysia-ai" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://elysia.weaviate.io/"&gt;&lt;img src="https://img.shields.io/badge/Check%20out%20the%20demo!-yellow?&amp;amp;style=flat-square&amp;amp;logo=react&amp;amp;logoColor=white" alt="Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Elysia is an agentic platform designed to use tools in a decision tree. A decision agent decides which tools to use dynamically based on its environment and context. You can use custom tools or use the pre-built tools designed to retrieve your data in a Weaviate cluster.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://weaviate.github.io/elysia/"&gt;Read the docs!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Installation is as simple as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install elysia-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Get started (App)&lt;/h2&gt; 
&lt;p&gt;Run the app via&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;elysia start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate to the settings page, add your required API keys, Weaviate cloud cluster details and specify your models.&lt;/p&gt; 
&lt;p&gt;Don't forget to check out &lt;a href="https://github.com/weaviate/elysia-frontend"&gt;the Github Repository for the Frontend&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Alternatively, we have created a demo version of Elysia (rate-limited, fixed datasets) to experiment with. Find it at: &lt;a href="https://elysia.weaviate.io/"&gt;https://elysia.weaviate.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started (Python)&lt;/h2&gt; 
&lt;p&gt;To use Elysia, you need to either set up your models and API keys in your &lt;code&gt;.env&lt;/code&gt; file, or specify them in the config. &lt;a href="https://weaviate.github.io/elysia/setting_up/"&gt;See the setup page to get started.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Elysia can be used very simply:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from elysia import tool, Tree

tree = Tree()

@tool(tree=tree)
async def add(x: int, y: int) -&amp;gt; int:
    return x + y

tree("What is the sum of 9009 and 6006?")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Elysia is pre-configured to be capable of connecting to and interacting with your &lt;a href="https://weaviate.io/deployment/serverless"&gt;Weaviate&lt;/a&gt; clusters!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import elysia
tree = elysia.Tree()
response, objects = tree(
    "What are the 10 most expensive items in the Ecommerce collection?",
    collection_names = ["Ecommerce"]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will use the built-in open source &lt;em&gt;query&lt;/em&gt; tool or &lt;em&gt;aggregate&lt;/em&gt; tool to interact with your Weaviate collections. To get started connecting to Weaviate, &lt;a href="https://weaviate.github.io/elysia/setting_up/"&gt;see the setting up page in the docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation (bash) (Linux/MacOS)&lt;/h2&gt; 
&lt;h3&gt;PyPi (Recommended)&lt;/h3&gt; 
&lt;p&gt;Elysia requires Python 3.12:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://formulae.brew.sh/formula/python@3.12"&gt;Installation via brew (macOS)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/release/python-3120/"&gt;Installation via installer (Windows)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ubuntuhandbook.org/index.php/2023/05/install-python-3-12-ubuntu/"&gt;Installation (Ubuntu)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Optionally create a virtual environment via&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3.12 -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install elysia-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;to install straight away!&lt;/p&gt; 
&lt;h3&gt;GitHub&lt;/h3&gt; 
&lt;p&gt;To get the latest development version, you can clone the github repo by running&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/weaviate/elysia
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;move to the working directory via&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd elysia
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment with Python (version 3.10 - 3.12)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3.12 -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and then install Elysia via pip&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Done! You can now use the Elysia python package&lt;/p&gt; 
&lt;h3&gt;Configuring Settings&lt;/h3&gt; 
&lt;p&gt;To use Elysia with Weaviate, i.e. for agentic searching and retrieval, you need to either have a &lt;em&gt;locally running&lt;/em&gt; instance of Weaviate, or access to a &lt;em&gt;Weaviate cloud cluster&lt;/em&gt; via an api key and URL. This can be specific in the app directly, or by creating a &lt;code&gt;.env&lt;/code&gt; file with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;WCD_URL=...
WCD_API_KEY=...
WEAVIATE_IS_LOCAL=... # True or False
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Elysia will automatically detect these when running locally, and this will be the default Weaviate cluster for all users logging into the Elysia app. But these can be configured on a user-by-user basis through the config.&lt;/p&gt; 
&lt;p&gt;Whichever vectoriser you use for your Weaviate collection you will need to specify your corresponding API key, e.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OPENAI_API_KEY=...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These will automatically be added to the headers for the Weaviate client.&lt;/p&gt; 
&lt;p&gt;Same for whichever model you choose for the LLM in Elysia, so if you are using GPT-4o, for example, specify an &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Elysia's recommended config is to use &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; to give easy access to a variety of models. So this requires&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OPENROUTER_API_KEY=...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;How do I use Elysia with my own data?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can connect to your own Weaviate cloud cluster, which will automatically identify any collections that exist in the cluster.&lt;/p&gt; 
 &lt;p&gt;Collections require being &lt;em&gt;preprocessed&lt;/em&gt; for Elysia. In the app, you just click the 'analyze' button in the Data tab. In Python you can do:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from elysia.preprocessing.collection import preprocess

preprocess(collection_names=["YourCollectionName"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Can I run Elysia completely locally? (Locally running Weaviate, local models)&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Yes!&lt;/p&gt; 
 &lt;p&gt;You can connect to a locally running Weaviate instance in Docker, and connect to Ollama for locally running language models. &lt;a href="https://weaviate.github.io/elysia/setting_up/"&gt;See the setup page to get started.&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;How do I clear all my Elysia data?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Everything Elysia doesn't store locally will be a collection in your Weaviate cluster. You can delete any collections that start with &lt;code&gt;ELYSIA_&lt;/code&gt; to reset all your Elysia data.&lt;/p&gt; 
 &lt;p&gt;For example, in Python:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from elysia.util.client import ClientManager()
with ClientManager().connect_to_client() as client:
    for collection_name in client.collections.list_all():
        if collection_name.startswith("ELYSIA_"):
            client.collections.delete(collection_name)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Can I contribute to Elysia?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Elysia is &lt;strong&gt;fully open source&lt;/strong&gt;, so yes of course you can! Clone and create a new branch of Elysia via&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/weaviate/elysia
git checkout -b &amp;lt;branch_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Make your changes, push them to your branch, go to GitHub and submit a pull request.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Where is the best place I can start contributing?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;There are no 'huge' new features we are planning for Elysia (for the moment). You could start with creating a new tool, or multiple new tools to create a custom workflow for something specific. Look for pain points you experience from your user journey and find what exactly is causing these. Then try to fix them or create an alternative way of doing things!&lt;/p&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>dotnet/eShop</title>
      <link>https://github.com/dotnet/eShop</link>
      <description>&lt;p&gt;A reference .NET application implementing an eCommerce site&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;eShop Reference Application - "AdventureWorks"&lt;/h1&gt; 
&lt;p&gt;A reference .NET application implementing an e-commerce website using a services-based architecture using &lt;a href="https://learn.microsoft.com/dotnet/aspire/"&gt;.NET Aspire&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/dotnet/eShop/main/img/eshop_architecture.png" alt="eShop Reference Application architecture diagram" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/dotnet/eShop/main/img/eshop_homepage.png" alt="eShop homepage screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;This version of eShop is based on .NET 9.&lt;/p&gt; 
&lt;p&gt;Previous eShop versions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dotnet/eShop/tree/release/8.0"&gt;.NET 8&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Clone the eShop repository: &lt;a href="https://github.com/dotnet/eshop"&gt;https://github.com/dotnet/eshop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/engine/install/"&gt;Install &amp;amp; start Docker Desktop&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Windows with Visual Studio&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;a href="https://visualstudio.microsoft.com/vs/"&gt;Visual Studio 2022 version 17.10 or newer&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;Select the following workloads: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;ASP.NET and web development&lt;/code&gt; workload.&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;.NET Aspire SDK&lt;/code&gt; component in &lt;code&gt;Individual components&lt;/code&gt;.&lt;/li&gt; 
     &lt;li&gt;Optional: &lt;code&gt;.NET Multi-platform App UI development&lt;/code&gt; to run client apps&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Or&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run the following commands in a Powershell &amp;amp; Terminal running as &lt;code&gt;Administrator&lt;/code&gt; to automatically configure your environment with the required tools to build and run this application. (Note: A restart is required and included in the script below.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;install-Module -Name Microsoft.WinGet.Configuration -AllowPrerelease -AcceptLicense -Force
$env:Path = [System.Environment]::GetEnvironmentVariable("Path","Machine") + ";" + [System.Environment]::GetEnvironmentVariable("Path","User")
get-WinGetConfiguration -file .\.configurations\vside.dsc.yaml | Invoke-WinGetConfiguration -AcceptConfigurationAgreements
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;From Dev Home go to &lt;code&gt;Machine Configuration -&amp;gt; Clone repositories&lt;/code&gt;. Enter the URL for this repository. In the confirmation screen look for the section &lt;code&gt;Configuration File Detected&lt;/code&gt; and click &lt;code&gt;Run File&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Mac, Linux, &amp;amp; Windows without Visual Studio&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the latest &lt;a href="https://dot.net/download?cid=eshop"&gt;.NET 9 SDK&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Or&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run the following commands in a Powershell &amp;amp; Terminal running as &lt;code&gt;Administrator&lt;/code&gt; to automatically configuration your environment with the required tools to build and run this application. (Note: A restart is required after running the script below.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Install Visual Studio Code and related extensions&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;install-Module -Name Microsoft.WinGet.Configuration -AllowPrerelease -AcceptLicense  -Force
$env:Path = [System.Environment]::GetEnvironmentVariable("Path","Machine") + ";" + [System.Environment]::GetEnvironmentVariable("Path","User")
get-WinGetConfiguration -file .\.configurations\vscode.dsc.yaml | Invoke-WinGetConfiguration -AcceptConfigurationAgreements
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: These commands may require &lt;code&gt;sudo&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Optional: Install &lt;a href="https://code.visualstudio.com/docs/csharp/get-started"&gt;Visual Studio Code with C# Dev Kit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Optional: Install &lt;a href="https://learn.microsoft.com/dotnet/maui/get-started/installation?tabs=visual-studio-code"&gt;.NET MAUI Workload&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: When running on Mac with Apple Silicon (M series processor), Rosetta 2 for grpc-tools.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Running the solution&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Remember to ensure that Docker is started&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;(Windows only) Run the application from Visual Studio:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open the &lt;code&gt;eShop.Web.slnf&lt;/code&gt; file in Visual Studio&lt;/li&gt; 
 &lt;li&gt;Ensure that &lt;code&gt;eShop.AppHost.csproj&lt;/code&gt; is your startup project&lt;/li&gt; 
 &lt;li&gt;Hit Ctrl-F5 to launch Aspire&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Or run the application from your terminal:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;dotnet run --project src/eShop.AppHost/eShop.AppHost.csproj
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;then look for lines like this in the console output in order to find the URL to open the Aspire dashboard:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;Login to the dashboard at: http://localhost:19888/login?t=uniquelogincodeforyou
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You may need to install ASP.NET Core HTTPS development certificates first, and then close all browser tabs. Learn more at &lt;a href="https://aka.ms/aspnet/https-trust-dev-cert"&gt;https://aka.ms/aspnet/https-trust-dev-cert&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Azure Open AI&lt;/h3&gt; 
&lt;p&gt;When using Azure OpenAI, inside &lt;em&gt;eShop.AppHost/appsettings.json&lt;/em&gt;, add the following section:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;  "ConnectionStrings": {
    "OpenAi": "Endpoint=xxx;Key=xxx;"
  }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace the values with your own. Then, in the eShop.AppHost &lt;em&gt;Program.cs&lt;/em&gt;, set this value to &lt;strong&gt;true&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-csharp"&gt;bool useOpenAI = false;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's additional guidance on the &lt;a href="https://learn.microsoft.com/dotnet/aspire/azureai/azureai-openai-component?tabs=dotnet-cli"&gt;.NET Aspire OpenAI component&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Use Azure Developer CLI&lt;/h3&gt; 
&lt;p&gt;You can use the &lt;a href="https://aka.ms/azd"&gt;Azure Developer CLI&lt;/a&gt; to run this project on Azure with only a few commands. Follow the next instructions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the latest or update to the latest &lt;a href="https://aka.ms/azure-dev/install"&gt;Azure Developer CLI (azd)&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Log in &lt;code&gt;azd&lt;/code&gt; (if you haven't done it before) to your Azure account:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;azd auth login
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Initialize &lt;code&gt;azd&lt;/code&gt; from the root of the repo.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;azd init
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;During init:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Select &lt;code&gt;Use code in the current directory&lt;/code&gt;. Azd will automatically detect the .NET Aspire project.&lt;/li&gt; 
   &lt;li&gt;Confirm &lt;code&gt;.NET (Aspire)&lt;/code&gt; and continue.&lt;/li&gt; 
   &lt;li&gt;Select which services to expose to the Internet (exposing &lt;code&gt;webapp&lt;/code&gt; is enough to test the sample).&lt;/li&gt; 
   &lt;li&gt;Finalize the initialization by giving a name to your environment.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create Azure resources and deploy the sample by running:&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;azd up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The operation takes a few minutes the first time it is ever run for an environment.&lt;/li&gt; 
 &lt;li&gt;At the end of the process, &lt;code&gt;azd&lt;/code&gt; will display the &lt;code&gt;url&lt;/code&gt; for the webapp. Follow that link to test the sample.&lt;/li&gt; 
 &lt;li&gt;You can run &lt;code&gt;azd up&lt;/code&gt; after saving changes to the sample to re-deploy and update the sample.&lt;/li&gt; 
 &lt;li&gt;Report any issues to &lt;a href="https://github.com/Azure/azure-dev/issues"&gt;azure-dev&lt;/a&gt; repo.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/azure/developer/azure-developer-cli/troubleshoot?tabs=Browser"&gt;FAQ and troubleshoot&lt;/a&gt; for azd.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;For more information on contributing to this repo, read &lt;a href="https://raw.githubusercontent.com/dotnet/eShop/main/CONTRIBUTING.md"&gt;the contribution documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/dotnet/eShop/main/CODE-OF-CONDUCT.md"&gt;the Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Sample data&lt;/h3&gt; 
&lt;p&gt;The sample catalog data is defined in &lt;a href="https://github.com/dotnet/eShop/raw/main/src/Catalog.API/Setup/catalog.json"&gt;catalog.json&lt;/a&gt;. Those product names, descriptions, and brand names are fictional and were generated using &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt"&gt;GPT-35-Turbo&lt;/a&gt;, and the corresponding &lt;a href="https://github.com/dotnet/eShop/tree/main/src/Catalog.API/Pics"&gt;product images&lt;/a&gt; were generated using &lt;a href="https://openai.com/dall-e-3"&gt;DALLÂ·E 3&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;eShop on Azure&lt;/h2&gt; 
&lt;p&gt;For a version of this app configured for deployment on Azure, please view &lt;a href="https://github.com/Azure-Samples/eShopOnAzure"&gt;the eShop on Azure&lt;/a&gt; repo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dockur/windows</title>
      <link>https://github.com/dockur/windows</link>
      <description>&lt;p&gt;Windows inside a Docker container.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Windows&lt;br /&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://github.com/dockur/windows"&gt;&lt;img src="https://github.com/dockur/windows/raw/master/.github/logo.png" title="Logo" style="max-width:100%;" width="128" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;p&gt;&lt;a href="https://github.com/dockur/windows/"&gt;&lt;img src="https://github.com/dockur/windows/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dockurr/windows/tags"&gt;&lt;img src="https://img.shields.io/docker/v/dockurr/windows/latest?arch=amd64&amp;amp;sort=semver&amp;amp;color=066da5" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dockurr/windows/tags"&gt;&lt;img src="https://img.shields.io/docker/image-size/dockurr/windows/latest?color=066da5&amp;amp;label=size" alt="Size" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dockur/windows/pkgs/container/windows"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fipitio.github.io%2Fbackage%2Fdockur%2Fwindows%2Fwindows.json&amp;amp;query=%24.downloads&amp;amp;logo=github&amp;amp;style=flat&amp;amp;color=066da5&amp;amp;label=pulls" alt="Package" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dockurr/windows/"&gt;&lt;img src="https://img.shields.io/docker/pulls/dockurr/windows.svg?style=flat&amp;amp;label=pulls&amp;amp;logo=docker" alt="Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt;&lt;/h1&gt; 
&lt;p&gt;Windows inside a Docker container.&lt;/p&gt; 
&lt;h2&gt;Features âœ¨&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ISO downloader&lt;/li&gt; 
 &lt;li&gt;KVM acceleration&lt;/li&gt; 
 &lt;li&gt;Web-based viewer&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Video ğŸ“º&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=xhGYobuG508"&gt;&lt;img src="https://img.youtube.com/vi/xhGYobuG508/0.jpg" alt="Youtube" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Usage ğŸ³&lt;/h2&gt; 
&lt;h5&gt;Via Docker Compose:&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  windows:
    image: dockurr/windows
    container_name: windows
    environment:
      VERSION: "11"
    devices:
      - /dev/kvm
      - /dev/net/tun
    cap_add:
      - NET_ADMIN
    ports:
      - 8006:8006
      - 3389:3389/tcp
      - 3389:3389/udp
    volumes:
      - ./windows:/storage
    restart: always
    stop_grace_period: 2m
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Via Docker CLI:&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --rm --name windows -p 8006:8006 --device=/dev/kvm --device=/dev/net/tun --cap-add NET_ADMIN -v "${PWD:-.}/windows:/storage" --stop-timeout 120 dockurr/windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Via Kubernetes:&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl apply -f https://raw.githubusercontent.com/dockur/windows/refs/heads/master/kubernetes.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Via Github Codespaces:&lt;/h5&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/dockur/windows"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="Open in GitHub Codespaces" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;FAQ ğŸ’¬&lt;/h2&gt; 
&lt;h3&gt;How do I use it?&lt;/h3&gt; 
&lt;p&gt;Very simple! These are the steps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Start the container and connect to &lt;a href="http://127.0.0.1:8006/"&gt;port 8006&lt;/a&gt; using your web browser.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Sit back and relax while the magic happens, the whole installation will be performed fully automatic.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Once you see the desktop, your Windows installation is ready for use.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Enjoy your brand new machine, and don't forget to star this repo!&lt;/p&gt; 
&lt;h3&gt;How do I select the Windows version?&lt;/h3&gt; 
&lt;p&gt;By default, Windows 11 Pro will be installed. But you can add the &lt;code&gt;VERSION&lt;/code&gt; environment variable to your compose file, in order to specify an alternative Windows version to be downloaded:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  VERSION: "11"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Select from the values below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Value&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Version&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Size&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;11&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows 11 Pro&lt;/td&gt; 
   &lt;td&gt;5.4 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;11l&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows 11 LTSC&lt;/td&gt; 
   &lt;td&gt;4.7 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;11e&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows 11 Enterprise&lt;/td&gt; 
   &lt;td&gt;4.0 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows 10 Pro&lt;/td&gt; 
   &lt;td&gt;5.7 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;10l&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows 10 LTSC&lt;/td&gt; 
   &lt;td&gt;4.6 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;10e&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows 10 Enterprise&lt;/td&gt; 
   &lt;td&gt;5.2 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;8e&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows 8.1 Enterprise&lt;/td&gt; 
   &lt;td&gt;3.7 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;7u&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows 7 Ultimate&lt;/td&gt; 
   &lt;td&gt;3.1 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vu&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows Vista Ultimate&lt;/td&gt; 
   &lt;td&gt;3.0 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;xp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows XP Professional&lt;/td&gt; 
   &lt;td&gt;0.6 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;2k&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows 2000 Professional&lt;/td&gt; 
   &lt;td&gt;0.4 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;2025&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows Server 2025&lt;/td&gt; 
   &lt;td&gt;5.6 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;2022&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows Server 2022&lt;/td&gt; 
   &lt;td&gt;4.7 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;2019&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows Server 2019&lt;/td&gt; 
   &lt;td&gt;5.3 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;2016&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows Server 2016&lt;/td&gt; 
   &lt;td&gt;6.5 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;2012&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows Server 2012&lt;/td&gt; 
   &lt;td&gt;4.3 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;2008&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows Server 2008&lt;/td&gt; 
   &lt;td&gt;3.0 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;2003&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Windows Server 2003&lt;/td&gt; 
   &lt;td&gt;0.6 GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] To install ARM64 versions of Windows use &lt;a href="https://github.com/dockur/windows-arm/"&gt;dockur/windows-arm&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;How do I change the storage location?&lt;/h3&gt; 
&lt;p&gt;To change the storage location, include the following bind mount in your compose file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;volumes:
  - ./windows:/storage
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace the example path &lt;code&gt;./windows&lt;/code&gt; with the desired storage folder or named volume.&lt;/p&gt; 
&lt;h3&gt;How do I change the size of the disk?&lt;/h3&gt; 
&lt;p&gt;To expand the default size of 64 GB, add the &lt;code&gt;DISK_SIZE&lt;/code&gt; setting to your compose file and set it to your preferred capacity:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  DISK_SIZE: "256G"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] This can also be used to resize the existing disk to a larger capacity without any data loss.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;How do I share files with the host?&lt;/h3&gt; 
&lt;p&gt;Open 'File Explorer' and click on the 'Network' section, you will see a computer called &lt;code&gt;host.lan&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Double-click it and it will show a folder called &lt;code&gt;Data&lt;/code&gt;, which can be bound to any folder on your host via the compose file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;volumes:
  -  ./example:/data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The example folder &lt;code&gt;./example&lt;/code&gt; will be available as &lt;code&gt; \\host.lan\Data&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] You can map this path to a drive letter in Windows, for easier access.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;How do I change the amount of CPU or RAM?&lt;/h3&gt; 
&lt;p&gt;By default, the container will be allowed to use a maximum of 2 CPU cores and 4 GB of RAM.&lt;/p&gt; 
&lt;p&gt;If you want to adjust this, you can specify the desired amount using the following environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  RAM_SIZE: "8G"
  CPU_CORES: "4"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How do I configure the username and password?&lt;/h3&gt; 
&lt;p&gt;By default, a user called &lt;code&gt;Docker&lt;/code&gt; is created during installation and its password is &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to use different credentials, you can configure them in your compose file (only before installation):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  USERNAME: "bill"
  PASSWORD: "gates"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How do I select the Windows language?&lt;/h3&gt; 
&lt;p&gt;By default, the English version of Windows will be downloaded.&lt;/p&gt; 
&lt;p&gt;But before installation you can add the &lt;code&gt;LANGUAGE&lt;/code&gt; environment variable to your compose file, in order to specify an alternative language:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  LANGUAGE: "French"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can choose between: ğŸ‡¦ğŸ‡ª Arabic, ğŸ‡§ğŸ‡¬ Bulgarian, ğŸ‡¨ğŸ‡³ Chinese, ğŸ‡­ğŸ‡· Croatian, ğŸ‡¨ğŸ‡¿ Czech, ğŸ‡©ğŸ‡° Danish, ğŸ‡³ğŸ‡± Dutch, ğŸ‡¬ğŸ‡§ English, ğŸ‡ªğŸ‡ª Estonian, ğŸ‡«ğŸ‡® Finnish, ğŸ‡«ğŸ‡· French, ğŸ‡©ğŸ‡ª German, ğŸ‡¬ğŸ‡· Greek, ğŸ‡®ğŸ‡± Hebrew, ğŸ‡­ğŸ‡º Hungarian, ğŸ‡®ğŸ‡¹ Italian, ğŸ‡¯ğŸ‡µ Japanese, ğŸ‡°ğŸ‡· Korean, ğŸ‡±ğŸ‡» Latvian, ğŸ‡±ğŸ‡¹ Lithuanian, ğŸ‡³ğŸ‡´ Norwegian, ğŸ‡µğŸ‡± Polish, ğŸ‡µğŸ‡¹ Portuguese, ğŸ‡·ğŸ‡´ Romanian, ğŸ‡·ğŸ‡º Russian, ğŸ‡·ğŸ‡¸ Serbian, ğŸ‡¸ğŸ‡° Slovak, ğŸ‡¸ğŸ‡® Slovenian, ğŸ‡ªğŸ‡¸ Spanish, ğŸ‡¸ğŸ‡ª Swedish, ğŸ‡¹ğŸ‡­ Thai, ğŸ‡¹ğŸ‡· Turkish and ğŸ‡ºğŸ‡¦ Ukrainian.&lt;/p&gt; 
&lt;h3&gt;How do I select the keyboard layout?&lt;/h3&gt; 
&lt;p&gt;If you want to use a keyboard layout or locale that is not the default for your selected language, you can add &lt;code&gt;KEYBOARD&lt;/code&gt; and &lt;code&gt;REGION&lt;/code&gt; variables like this (before installation):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  REGION: "en-US"
  KEYBOARD: "en-US"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How do I select the edition?&lt;/h3&gt; 
&lt;p&gt;Windows Server offers a minimalistic Core edition without a GUI. To select those non-standard editions, you can add a &lt;code&gt;EDITION&lt;/code&gt; variable like this (before installation):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  EDITION: "core"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How do I install a custom image?&lt;/h3&gt; 
&lt;p&gt;In order to download an unsupported ISO image, specify its URL in the &lt;code&gt;VERSION&lt;/code&gt; environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  VERSION: "https://example.com/win.iso"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can also skip the download and use a local file instead, by binding it in your compose file in this way:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;volumes:
  - ./example.iso:/boot.iso
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace the example path &lt;code&gt;./example.iso&lt;/code&gt; with the filename of your desired ISO file. The value of &lt;code&gt;VERSION&lt;/code&gt; will be ignored in this case.&lt;/p&gt; 
&lt;h3&gt;How do I run a script after installation?&lt;/h3&gt; 
&lt;p&gt;To run your own script after installation, you can create a file called &lt;code&gt;install.bat&lt;/code&gt; and place it in a folder together with any additional files it needs (software to be installed for example).&lt;/p&gt; 
&lt;p&gt;Then bind that folder in your compose file like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;volumes:
  -  ./example:/oem
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The example folder &lt;code&gt;./example&lt;/code&gt; will be copied to &lt;code&gt;C:\OEM&lt;/code&gt; and the containing &lt;code&gt;install.bat&lt;/code&gt; will be executed during the last step of the automatic installation.&lt;/p&gt; 
&lt;h3&gt;How do I perform a manual installation?&lt;/h3&gt; 
&lt;p&gt;It's recommended to stick to the automatic installation, as it adjusts various settings to prevent common issues when running Windows inside a virtual environment.&lt;/p&gt; 
&lt;p&gt;However, if you insist on performing the installation manually at your own risk, add the following environment variable to your compose file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  MANUAL: "Y"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How do I connect using RDP?&lt;/h3&gt; 
&lt;p&gt;The web-viewer is mainly meant to be used during installation, as its picture quality is low, and it has no audio or clipboard for example.&lt;/p&gt; 
&lt;p&gt;So for a better experience you can connect using any Microsoft Remote Desktop client to the IP of the container, using the username &lt;code&gt;Docker&lt;/code&gt; and password &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;There is a RDP client for &lt;a href="https://play.google.com/store/apps/details?id=com.microsoft.rdc.androidx"&gt;Android&lt;/a&gt; available from the Play Store and one for &lt;a href="https://apps.apple.com/nl/app/microsoft-remote-desktop/id714464092?l=en-GB"&gt;iOS&lt;/a&gt; in the Apple Store. For Linux you can use &lt;a href="https://www.freerdp.com/"&gt;FreeRDP&lt;/a&gt; and on Windows just type &lt;code&gt;mstsc&lt;/code&gt; in the search box.&lt;/p&gt; 
&lt;h3&gt;How do I assign an individual IP address to the container?&lt;/h3&gt; 
&lt;p&gt;By default, the container uses bridge networking, which shares the IP address with the host.&lt;/p&gt; 
&lt;p&gt;If you want to assign an individual IP address to the container, you can create a macvlan network as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker network create -d macvlan \
    --subnet=192.168.0.0/24 \
    --gateway=192.168.0.1 \
    --ip-range=192.168.0.100/28 \
    -o parent=eth0 vlan
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Be sure to modify these values to match your local subnet.&lt;/p&gt; 
&lt;p&gt;Once you have created the network, change your compose file to look as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  windows:
    container_name: windows
    ..&amp;lt;snip&amp;gt;..
    networks:
      vlan:
        ipv4_address: 192.168.0.100

networks:
  vlan:
    external: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An added benefit of this approach is that you won't have to perform any port mapping anymore, since all ports will be exposed by default.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;br /&gt; This IP address won't be accessible from the Docker host due to the design of macvlan, which doesn't permit communication between the two. If this is a concern, you need to create a &lt;a href="https://blog.oddbit.com/post/2018-03-12-using-docker-macvlan-networks/#host-access"&gt;second macvlan&lt;/a&gt; as a workaround.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;How can Windows acquire an IP address from my router?&lt;/h3&gt; 
&lt;p&gt;After configuring the container for &lt;a href="https://raw.githubusercontent.com/dockur/windows/master/#how-do-i-assign-an-individual-ip-address-to-the-container"&gt;macvlan&lt;/a&gt;, it is possible for Windows to become part of your home network by requesting an IP from your router, just like a real PC.&lt;/p&gt; 
&lt;p&gt;To enable this mode, in which the container and Windows will have separate IP addresses, add the following lines to your compose file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  DHCP: "Y"
devices:
  - /dev/vhost-net
device_cgroup_rules:
  - 'c *:* rwm'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How do I add multiple disks?&lt;/h3&gt; 
&lt;p&gt;To create additional disks, modify your compose file like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  DISK2_SIZE: "32G"
  DISK3_SIZE: "64G"
volumes:
  - ./example2:/storage2
  - ./example3:/storage3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How do I pass-through a disk?&lt;/h3&gt; 
&lt;p&gt;It is possible to pass-through disk devices or partitions directly by adding them to your compose file in this way:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;devices:
  - /dev/sdb:/disk1
  - /dev/sdc1:/disk2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;/disk1&lt;/code&gt; if you want it to become your main drive (which will be formatted during installation), and use &lt;code&gt;/disk2&lt;/code&gt; and higher to add them as secondary drives (which will stay untouched).&lt;/p&gt; 
&lt;h3&gt;How do I pass-through a USB device?&lt;/h3&gt; 
&lt;p&gt;To pass-through a USB device, first lookup its vendor and product id via the &lt;code&gt;lsusb&lt;/code&gt; command, then add them to your compose file like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  ARGUMENTS: "-device usb-host,vendorid=0x1234,productid=0x1234"
devices:
  - /dev/bus/usb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the device is a USB disk drive, please wait until after the installation is fully completed before connecting it. Otherwise the installation may fail, as the order of the disks can get rearranged.&lt;/p&gt; 
&lt;h3&gt;How do I verify if my system supports KVM?&lt;/h3&gt; 
&lt;p&gt;First check if your software is compatible using this chart:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Product&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Linux&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Win11&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Win10&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Docker CLI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Docker Desktop&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Podman CLI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Podman Desktop&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;After that you can run the following commands in Linux to check your system:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt install cpu-checker
sudo kvm-ok
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you receive an error from &lt;code&gt;kvm-ok&lt;/code&gt; indicating that KVM cannot be used, please check whether:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;the virtualization extensions (&lt;code&gt;Intel VT-x&lt;/code&gt; or &lt;code&gt;AMD SVM&lt;/code&gt;) are enabled in your BIOS.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;you enabled "nested virtualization" if you are running the container inside a virtual machine.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;you are not using a cloud provider, as most of them do not allow nested virtualization for their VPS's.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you did not receive any error from &lt;code&gt;kvm-ok&lt;/code&gt; but the container still complains about a missing KVM device, it could help to add &lt;code&gt;privileged: true&lt;/code&gt; to your compose file (or &lt;code&gt;sudo&lt;/code&gt; to your &lt;code&gt;docker&lt;/code&gt; command) to rule out any permission issue.&lt;/p&gt; 
&lt;h3&gt;How do I run macOS in a container?&lt;/h3&gt; 
&lt;p&gt;You can use &lt;a href="https://github.com/dockur/macos"&gt;dockur/macos&lt;/a&gt; for that. It shares many of the same features, except for the automatic installation.&lt;/p&gt; 
&lt;h3&gt;How do I run a Linux desktop in a container?&lt;/h3&gt; 
&lt;p&gt;You can use &lt;a href="https://github.com/qemus/qemu"&gt;qemus/qemu&lt;/a&gt; in that case.&lt;/p&gt; 
&lt;h3&gt;Is this project legal?&lt;/h3&gt; 
&lt;p&gt;Yes, this project contains only open-source code and does not distribute any copyrighted material. Any product keys found in the code are just generic placeholders provided by Microsoft for trial purposes. So under all applicable laws, this project will be considered legal.&lt;/p&gt; 
&lt;h2&gt;Disclaimer âš–ï¸&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;The product names, logos, brands, and other trademarks referred to within this project are the property of their respective trademark holders. This project is not affiliated, sponsored, or endorsed by Microsoft Corporation.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pedroslopez/whatsapp-web.js</title>
      <link>https://github.com/pedroslopez/whatsapp-web.js</link>
      <description>&lt;p&gt;A WhatsApp client library for NodeJS that connects through the WhatsApp Web browser app&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;p&gt; &lt;a href="https://wwebjs.dev"&gt;&lt;img src="https://github.com/wwebjs/logos/raw/main/4_Full%20Logo%20Lockup_Small/small_banner_blue.png?raw=true" title="whatsapp-web.js" alt="WWebJS Website" width="500" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt; &lt;a href="https://www.npmjs.com/package/whatsapp-web.js"&gt;&lt;img src="https://img.shields.io/npm/v/whatsapp-web.js.svg?sanitize=true" alt="npm" /&gt;&lt;/a&gt; &lt;a href="https://depfu.com/github/pedroslopez/whatsapp-web.js?project_id=9765"&gt;&lt;img src="https://badges.depfu.com/badges/4a65a0de96ece65fdf39e294e0c8dcba/overview.svg?sanitize=true" alt="Depfu" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/WhatsApp_Web-2.3000.1017054665-brightgreen.svg?sanitize=true" alt="WhatsApp_Web 2.2346.52" /&gt; &lt;a href="https://discord.gg/H7DqQs4"&gt;&lt;img src="https://img.shields.io/discord/698610475432411196.svg?logo=discord" alt="Discord server" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;A WhatsApp API client that connects through the WhatsApp Web browser app&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The library works by launching the WhatsApp Web browser application and managing it using Puppeteer to create an instance of WhatsApp Web, thereby mitigating the risk of being blocked. The WhatsApp API client connects through the WhatsApp Web browser app, accessing its internal functions. This grants you access to nearly all the features available on WhatsApp Web, enabling dynamic handling similar to any other Node.js application.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;It is not guaranteed you will not be blocked by using this method. WhatsApp does not allow bots or unofficial clients on their platform, so this shouldn't be considered totally safe.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://wwebjs.dev"&gt;Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://guide.wwebjs.dev/guide"&gt;Guide&lt;/a&gt; (&lt;a href="https://github.com/wwebjs/wwebjs.dev/tree/main"&gt;source&lt;/a&gt;) &lt;em&gt;(work in progress)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.wwebjs.dev/"&gt;Documentation&lt;/a&gt; (&lt;a href="https://github.com/pedroslopez/whatsapp-web.js/tree/main/docs"&gt;source&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/H7DqQs4"&gt;WWebJS Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pedroslopez/whatsapp-web.js"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://npmjs.org/package/whatsapp-web.js"&gt;npm&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The module is now available on npm! &lt;code&gt;npm i whatsapp-web.js&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] &lt;strong&gt;Node &lt;code&gt;v18+&lt;/code&gt; is required.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;QUICK STEPS TO UPGRADE NODE&lt;/h2&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;h4&gt;Manual&lt;/h4&gt; 
&lt;p&gt;Just get the latest LTS from the &lt;a href="https://nodejs.org/en/download/"&gt;official node website&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;npm&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;sudo npm install -g n
sudo n stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Choco&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;choco install nodejs-lts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Winget&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;winget install OpenJS.NodeJS.LTS
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ubuntu / Debian&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash - &amp;amp;&amp;amp;\
sudo apt-get install -y nodejs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;const { Client } = require('whatsapp-web.js');

const client = new Client();

client.on('qr', (qr) =&amp;gt; {
    // Generate and scan this code with your phone
    console.log('QR RECEIVED', qr);
});

client.on('ready', () =&amp;gt; {
    console.log('Client is ready!');
});

client.on('message', msg =&amp;gt; {
    if (msg.body == '!ping') {
        msg.reply('pong');
    }
});

client.initialize();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Take a look at &lt;a href="https://github.com/pedroslopez/whatsapp-web.js/raw/master/example.js"&gt;example.js&lt;/a&gt; for another examples with additional use cases.&lt;br /&gt; For further details on saving and restoring sessions, explore the provided &lt;a href="https://wwebjs.dev/guide/creating-your-bot/authentication.html"&gt;Authentication Strategies&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Supported features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multi Device&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Send messages&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Receive messages&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Send media (images/audio/documents)&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Send media (video)&lt;/td&gt; 
   &lt;td&gt;âœ… &lt;a href="https://wwebjs.dev/guide/creating-your-bot/handling-attachments.html#caveat-for-sending-videos-and-gifs"&gt;(requires Google Chrome)&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Send stickers&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Receive media (images/audio/video/documents)&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Send contact cards&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Send location&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Send buttons&lt;/td&gt; 
   &lt;td&gt;âŒ &lt;a href="https://www.youtube.com/watch?v=hv1R1rLeVVE"&gt;(DEPRECATED)&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Send lists&lt;/td&gt; 
   &lt;td&gt;âŒ &lt;a href="https://www.youtube.com/watch?v=hv1R1rLeVVE"&gt;(DEPRECATED)&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Receive location&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Message replies&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Join groups by invite&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Get invite for group&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Modify group info (subject, description)&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Modify group settings (send messages, edit info)&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add group participants&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Kick group participants&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Promote/demote group participants&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mention users&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mention groups&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mute/unmute chats&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Block/unblock contacts&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Get contact info&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Get profile pictures&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Set user status message&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;React to messages&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Create polls&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Channels&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vote in polls&lt;/td&gt; 
   &lt;td&gt;ğŸ”œ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Communities&lt;/td&gt; 
   &lt;td&gt;ğŸ”œ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Something missing? Make an issue and let us know!&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Feel free to open pull requests; we welcome contributions! However, for significant changes, it's best to open an issue beforehand. Make sure to review our &lt;a href="https://github.com/pedroslopez/whatsapp-web.js/raw/main/CODE_OF_CONDUCT.md"&gt;contribution guidelines&lt;/a&gt; before creating a pull request. Before creating your own issue or pull request, always check to see if one already exists!&lt;/p&gt; 
&lt;h2&gt;Supporting the project&lt;/h2&gt; 
&lt;p&gt;You can support the maintainer of this project through the links below&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sponsors/pedroslopez"&gt;Support via GitHub Sponsors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.paypal.me/psla/"&gt;Support via PayPal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://m.do.co/c/73f906a36ed4"&gt;Sign up for DigitalOcean&lt;/a&gt; and get $200 in credit when you sign up (Referral)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is not affiliated, associated, authorized, endorsed by, or in any way officially connected with WhatsApp or any of its subsidiaries or its affiliates. The official WhatsApp website can be found at &lt;a href="https://whatsapp.com"&gt;whatsapp.com&lt;/a&gt;. "WhatsApp" as well as related names, marks, emblems and images are registered trademarks of their respective owners. Also it is not guaranteed you will not be blocked by using this method. WhatsApp does not allow bots or unofficial clients on their platform, so this shouldn't be considered totally safe.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright 2019 Pedro S Lopez&lt;/p&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License");&lt;br /&gt; you may not use this project except in compliance with the License.&lt;br /&gt; You may obtain a copy of the License at &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software&lt;br /&gt; distributed under the License is distributed on an "AS IS" BASIS,&lt;br /&gt; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br /&gt; See the License for the specific language governing permissions and&lt;br /&gt; limitations under the License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>JetBrains/koog</title>
      <link>https://github.com/JetBrains/koog</link>
      <description>&lt;p&gt;Koog is the official Kotlin framework for building and running robust, scalable and production-ready AI agents across all platforms â€“ from backend services to Android and iOS, JVM, and even in-browser environments. Koog is based on our AI products expertise and provides proven solutions for complex LLM and AI problems&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Koog&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://kotlinlang.org/docs/components-stability.html"&gt;&lt;img src="https://kotl.in/badges/alpha.svg?sanitize=true" alt="Kotlin Alpha" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/artifact/ai.koog/koog-agents"&gt;&lt;img src="https://img.shields.io/maven-central/v/ai.koog/koog-agents" alt="Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://github.com/JetBrains#jetbrains-on-github"&gt;&lt;img src="https://jb.gg/badges/incubator.svg?sanitize=true" alt="JetBrains incubator project" /&gt;&lt;/a&gt; &lt;a href="http://kotlinlang.org"&gt;&lt;img src="https://img.shields.io/badge/kotlin-2.1-blue.svg?logo=kotlin" alt="Kotlin" /&gt;&lt;/a&gt; &lt;a href="https://github.com/JetBrains/koog/actions?query=branch%3Amain"&gt;&lt;img src="https://img.shields.io/github/checks-status/JetBrains/koog/main" alt="CI status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/JetBrains/koog/develop/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/JetBrains/koog" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://docs.koog.ai"&gt;&lt;img src="https://img.shields.io/badge/documentation-blue" alt="docs" /&gt;&lt;/a&gt; &lt;a href="https://kotlinlang.slack.com/messages/koog-agentic-framework/"&gt;&lt;img src="https://img.shields.io/badge/chat-slack-green.svg?logo=slack" alt="Slack channel" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Koog is a Kotlin-based framework designed to build and run AI agents entirely in idiomatic Kotlin. It lets you create agents that can interact with tools, handle complex workflows, and communicate with users.&lt;/p&gt; 
&lt;h3&gt;Key features&lt;/h3&gt; 
&lt;p&gt;Key features of Koog include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pure Kotlin implementation&lt;/strong&gt;: Build AI agents entirely in natural and idiomatic Kotlin.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP integration&lt;/strong&gt;: Connect to Model Context Protocol for enhanced model management.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embedding capabilities&lt;/strong&gt;: Use vector embeddings for semantic search and knowledge retrieval.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom tool creation&lt;/strong&gt;: Extend your agents with tools that access external systems and APIs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ready-to-use components&lt;/strong&gt;: Speed up development with pre-built solutions for common AI engineering challenges.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent history compression&lt;/strong&gt;: Optimize token usage while maintaining conversation context using various pre-built strategies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Powerful Streaming API&lt;/strong&gt;: Process responses in real-time with streaming support and parallel tool calls.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistent agent memory&lt;/strong&gt;: Enable knowledge retention across sessions and even different agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive tracing&lt;/strong&gt;: Debug and monitor agent execution with detailed and configurable tracing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible graph workflows&lt;/strong&gt;: Design complex agent behaviors using intuitive graph-based workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modular feature system&lt;/strong&gt;: Customize agent capabilities through a composable architecture.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable architecture&lt;/strong&gt;: Handle workloads from simple chatbots to enterprise applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiplatform&lt;/strong&gt;: Run agents on JVM, JS, WasmJS, iOS targets with Kotlin Multiplatform.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Available LLM providers and platforms&lt;/h3&gt; 
&lt;p&gt;The LLM providers and platforms whose LLMs you can use to power your agent capabilities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Google&lt;/li&gt; 
 &lt;li&gt;OpenAI&lt;/li&gt; 
 &lt;li&gt;Anthropic&lt;/li&gt; 
 &lt;li&gt;OpenRouter&lt;/li&gt; 
 &lt;li&gt;Ollama&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quickstart example&lt;/h3&gt; 
&lt;p&gt;To help you get started with AI agents, here is a quick example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-kotlin"&gt;fun main() = runBlocking {
    // Before you run the example, assign a corresponding API key as an environment variable.
   val apiKey = System.getenv("OPENAI_API_KEY") // or Anthropic, Google, OpenRouter, etc.

   val agent = AIAgent(
      executor = simpleOpenAIExecutor(apiKey), // or Anthropic, Google, OpenRouter, etc.
      systemPrompt = "You are a helpful assistant. Answer user questions concisely.",
      llmModel = OpenAIModels.Chat.GPT4o
   )

   val result = agent.run("Hello! How can you help me?")
   println(result)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using in your projects&lt;/h2&gt; 
&lt;h3&gt;Supported targets&lt;/h3&gt; 
&lt;p&gt;Currently, the framework supports the JVM, JS, WasmJS and iOS targets.&lt;/p&gt; 
&lt;p&gt;On JVM, JDK 17 or higher is required to use the framework.&lt;/p&gt; 
&lt;p&gt;Please check the &lt;a href="https://raw.githubusercontent.com/JetBrains/koog/develop/gradle/libs.versions.toml"&gt;libs.versions.toml&lt;/a&gt; to know more about the Koog dependencies.&lt;/p&gt; 
&lt;h3&gt;Gradle (Kotlin DSL)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Add dependencies to the &lt;code&gt;build.gradle.kts&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dependencies {
    implementation("ai.koog:koog-agents:0.4.1")
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Make sure that you have &lt;code&gt;mavenCentral()&lt;/code&gt; in the list of repositories.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Gradle (Groovy)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Add dependencies to the &lt;code&gt;build.gradle&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dependencies {
    implementation 'ai.koog:koog-agents:0.4.1'
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Make sure that you have &lt;code&gt;mavenCentral()&lt;/code&gt; in the list of repositories.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Maven&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Add dependencies to the &lt;code&gt;pom.xml&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;ai.koog&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;koog-agents-jvm&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;0.4.1&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Make sure that you have &lt;code&gt;mavenCentral&lt;/code&gt; in the list of repositories.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Read the &lt;a href="https://raw.githubusercontent.com/JetBrains/koog/develop/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;This project and the corresponding community are governed by the &lt;a href="https://github.com/jetbrains#code-of-conduct"&gt;JetBrains Open Source and Community Code of Conduct&lt;/a&gt;. Please make sure you read it.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Koog is licensed under the &lt;a href="https://raw.githubusercontent.com/JetBrains/koog/develop/LICENSE.txt"&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Please feel free to ask any questions in our official Slack channel (&lt;a href="https://kotlinlang.slack.com/messages/koog-agentic-framework/"&gt;link&lt;/a&gt;) and to use &lt;a href="https://youtrack.jetbrains.com/issues/KG"&gt;Koog official YouTrack project&lt;/a&gt; for filing feature requests and bug reports.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>QuentinFuxa/WhisperLiveKit</title>
      <link>https://github.com/QuentinFuxa/WhisperLiveKit</link>
      <description>&lt;p&gt;Real-time &amp; local speech-to-text, translation, and speaker diarization. With server &amp; web UI.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;WhisperLiveKit&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/refs/heads/main/demo.png" alt="WhisperLiveKit Demo" width="730" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt;&lt;b&gt;Real-time, Fully Local Speech-to-Text with Speaker Identification&lt;/b&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://pypi.org/project/whisperlivekit/"&gt;&lt;img alt="PyPI Version" src="https://img.shields.io/pypi/v/whisperlivekit?color=g" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/whisperlivekit"&gt;&lt;img alt="PyPI Downloads" src="https://static.pepy.tech/personalized-badge/whisperlivekit?period=total&amp;amp;units=international_system&amp;amp;left_color=grey&amp;amp;right_color=brightgreen&amp;amp;left_text=installations" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/whisperlivekit/"&gt;&lt;img alt="Python Versions" src="https://img.shields.io/badge/python-3.9--3.15-dark_green" /&gt;&lt;/a&gt; &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/LICENSE"&gt;&lt;img alt="License" src="https://img.shields.io/badge/License-MIT/Dual Licensed-dark_green" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Real-time speech transcription directly to your browser, with a ready-to-use backend+server and a simple frontend. âœ¨&lt;/p&gt; 
&lt;h4&gt;Powered by Leading Research:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ufal/SimulStreaming"&gt;SimulStreaming&lt;/a&gt; (SOTA 2025) - Ultra-low latency transcription with AlignAtt policy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ufal/whisper_streaming"&gt;WhisperStreaming&lt;/a&gt; (SOTA 2023) - Low latency transcription with LocalAgreement policy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2507.18446"&gt;Streaming Sortformer&lt;/a&gt; (SOTA 2025) - Advanced real-time speaker diarization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/juanmc2005/diart"&gt;Diart&lt;/a&gt; (SOTA 2021) - Real-time speaker diarization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/snakers4/silero-vad"&gt;Silero VAD&lt;/a&gt; (2024) - Enterprise-grade Voice Activity Detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Why not just run a simple Whisper model on every audio batch?&lt;/strong&gt; Whisper is designed for complete utterances, not real-time chunks. Processing small segments loses context, cuts off words mid-syllable, and produces poor transcription. WhisperLiveKit uses state-of-the-art simultaneous speech research for intelligent buffering and incremental processing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;img alt="Architecture" src="https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/refs/heads/main/architecture.png" /&gt; 
&lt;p&gt;&lt;em&gt;The backend supports multiple concurrent users. Voice Activity Detection reduces overhead when no voice is detected.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Installation &amp;amp; Quick Start&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install whisperlivekit
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You can also clone the repo and &lt;code&gt;pip install -e .&lt;/code&gt; for the latest version.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;FFmpeg is required&lt;/strong&gt; and must be installed before using WhisperLiveKit&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;OS&lt;/th&gt; 
    &lt;th&gt;How to install&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Ubuntu/Debian&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;sudo apt install ffmpeg&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MacOS&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;brew install ffmpeg&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Windows&lt;/td&gt; 
    &lt;td&gt;Download .exe from &lt;a href="https://ffmpeg.org/download.html"&gt;https://ffmpeg.org/download.html&lt;/a&gt; and add to PATH&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Quick Start&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start the transcription server:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;whisperlivekit-server --model base --language en
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open your browser&lt;/strong&gt; and navigate to &lt;code&gt;http://localhost:8000&lt;/code&gt;. Start speaking and watch your words appear in real-time!&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;See &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/simul_whisper/whisper/tokenizer.py"&gt;tokenizer.py&lt;/a&gt; for the list of all available languages.&lt;/li&gt; 
  &lt;li&gt;For HTTPS requirements, see the &lt;strong&gt;Parameters&lt;/strong&gt; section for SSL configuration options.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Optional Dependencies&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Optional&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;pip install&lt;/code&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Speaker diarization with Sortformer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[asr]&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apple Silicon optimized backend&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mlx-whisper&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;[Not recommanded]&lt;/em&gt; Speaker diarization with Diart&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;diart&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;[Not recommanded]&lt;/em&gt; Original Whisper backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;whisper&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;[Not recommanded]&lt;/em&gt; Improved timestamps backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;whisper-timestamped&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI API backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See &lt;strong&gt;Parameters &amp;amp; Configuration&lt;/strong&gt; below on how to use them.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Command-line Interface&lt;/strong&gt;: Start the transcription server with various options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use better model than default (small)
whisperlivekit-server --model large-v3

# Advanced configuration with diarization and language
whisperlivekit-server --host 0.0.0.0 --port 8000 --model medium --diarization --language fr
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Python API Integration&lt;/strong&gt;: Check &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/basic_server.py"&gt;basic_server&lt;/a&gt; for a more complete example of how to use the functions and classes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from whisperlivekit import TranscriptionEngine, AudioProcessor, parse_args
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from contextlib import asynccontextmanager
import asyncio

transcription_engine = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global transcription_engine
    transcription_engine = TranscriptionEngine(model="medium", diarization=True, lan="en")
    yield

app = FastAPI(lifespan=lifespan)

async def handle_websocket_results(websocket: WebSocket, results_generator):
    async for response in results_generator:
        await websocket.send_json(response)
    await websocket.send_json({"type": "ready_to_stop"})

@app.websocket("/asr")
async def websocket_endpoint(websocket: WebSocket):
    global transcription_engine

    # Create a new AudioProcessor for each connection, passing the shared engine
    audio_processor = AudioProcessor(transcription_engine=transcription_engine)    
    results_generator = await audio_processor.create_tasks()
    results_task = asyncio.create_task(handle_websocket_results(websocket, results_generator))
    await websocket.accept()
    while True:
        message = await websocket.receive_bytes()
        await audio_processor.process_audio(message)        
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Frontend Implementation&lt;/strong&gt;: The package includes an HTML/JavaScript implementation &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/web/live_transcription.html"&gt;here&lt;/a&gt;. You can also import it using &lt;code&gt;from whisperlivekit import get_inline_ui_html&lt;/code&gt; &amp;amp; &lt;code&gt;page = get_inline_ui_html()&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Parameters &amp;amp; Configuration&lt;/h2&gt; 
&lt;p&gt;An important list of parameters can be changed. But what &lt;em&gt;should&lt;/em&gt; you change?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;code&gt;--model&lt;/code&gt; size. List and recommandations &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/available_models.md"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;--language&lt;/code&gt;. List &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/simul_whisper/whisper/tokenizer.py"&gt;here&lt;/a&gt;. If you use &lt;code&gt;auto&lt;/code&gt;, the model attempts to detect the language automatically, but it tends to bias towards English.&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;--backend&lt;/code&gt; ? you can switch to &lt;code&gt;--backend faster-whisper&lt;/code&gt; if &lt;code&gt;simulstreaming&lt;/code&gt; does not work correctly or if you prefer to avoid the dual-license requirements.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--warmup-file&lt;/code&gt;, if you have one&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--task translate&lt;/code&gt;, to translate in english&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--host&lt;/code&gt;, &lt;code&gt;--port&lt;/code&gt;, &lt;code&gt;--ssl-certfile&lt;/code&gt;, &lt;code&gt;--ssl-keyfile&lt;/code&gt;, if you set up a server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--diarization&lt;/code&gt;, if you want to use it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The rest I don't recommend. But below are your options.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Parameter&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--model&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whisper model size.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;small&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--language&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Source language code or &lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--task&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Set to &lt;code&gt;translate&lt;/code&gt; to translate to english&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;transcribe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--target-language&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;[NOT FUNCTIONAL YET]&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--backend&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Processing backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;simulstreaming&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--min-chunk-size&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Minimum audio chunk size (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-vac&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disable Voice Activity Controller&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-vad&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disable Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--warmup-file&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Audio file path for model warmup&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;jfk.wav&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--host&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Server host address&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;localhost&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--port&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Server port&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;8000&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--ssl-certfile&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to the SSL certificate file (for HTTPS support)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--ssl-keyfile&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to the SSL private key file (for HTTPS support)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SimulStreaming backend options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--disable-fast-encoder&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disable Faster Whisper or MLX Whisper backends for the encoder (if installed). Inference can be slower but helpful when GPU memory is limited&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--frame-threshold&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;AlignAtt frame threshold (lower = faster, higher = more accurate)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;25&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--beams&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Number of beams for beam search (1 = greedy decoding)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--decoder&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Force decoder type (&lt;code&gt;beam&lt;/code&gt; or &lt;code&gt;greedy&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--audio-max-len&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum audio buffer length (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;30.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--audio-min-len&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Minimum audio length to process (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--cif-ckpt-path&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to CIF model for word boundary detection&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--never-fire&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Never truncate incomplete words&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--init-prompt&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Initial prompt for the model&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--static-init-prompt&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Static prompt that doesn't scroll&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--max-context-tokens&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum context tokens&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--model-path&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Direct path to .pt model file. Download it if not found&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;./base.pt&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--preloaded-model-count&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Optional. Number of models to preload in memory to speed up loading (set up to the expected number of concurrent users)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;WhisperStreaming backend options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--confidence-validation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use confidence scores for faster validation&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--buffer_trimming&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Buffer trimming strategy (&lt;code&gt;sentence&lt;/code&gt; or &lt;code&gt;segment&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;segment&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Diarization options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--diarization&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable speaker identification&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--diarization-backend&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;diart&lt;/code&gt; or &lt;code&gt;sortformer&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sortformer&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--segmentation-model&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Hugging Face model ID for Diart segmentation model. &lt;a href="https://github.com/juanmc2005/diart/tree/main?tab=readme-ov-file#pre-trained-models"&gt;Available models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pyannote/segmentation-3.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--embedding-model&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Hugging Face model ID for Diart embedding model. &lt;a href="https://github.com/juanmc2005/diart/tree/main?tab=readme-ov-file#pre-trained-models"&gt;Available models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;speechbrain/spkrec-ecapa-voxceleb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For diarization using Diart, you need access to pyannote.audio models:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/pyannote/segmentation"&gt;Accept user conditions&lt;/a&gt; for the &lt;code&gt;pyannote/segmentation&lt;/code&gt; model&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/pyannote/segmentation-3.0"&gt;Accept user conditions&lt;/a&gt; for the &lt;code&gt;pyannote/segmentation-3.0&lt;/code&gt; model&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/pyannote/embedding"&gt;Accept user conditions&lt;/a&gt; for the &lt;code&gt;pyannote/embedding&lt;/code&gt; model&lt;/li&gt; 
  &lt;li&gt;Login with HuggingFace: &lt;code&gt;huggingface-cli login&lt;/code&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ğŸš€ Deployment Guide&lt;/h3&gt; 
&lt;p&gt;To deploy WhisperLiveKit in production:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Server Setup&lt;/strong&gt;: Install production ASGI server &amp;amp; launch with multiple workers&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install uvicorn gunicorn
gunicorn -k uvicorn.workers.UvicornWorker -w 4 your_app:app
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: Host your customized version of the &lt;code&gt;html&lt;/code&gt; example &amp;amp; ensure WebSocket connection points correctly&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nginx Configuration&lt;/strong&gt; (recommended for production):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-nginx"&gt;server {
   listen 80;
   server_name your-domain.com;
    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
}}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTPS Support&lt;/strong&gt;: For secure deployments, use "wss://" instead of "ws://" in WebSocket URL&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ‹ Docker&lt;/h2&gt; 
&lt;p&gt;Deploy the application easily using Docker with GPU or CPU support.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker installed on your system&lt;/li&gt; 
 &lt;li&gt;For GPU support: NVIDIA Docker runtime installed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;With GPU acceleration (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t wlk .
docker run --gpus all -p 8000:8000 --name wlk wlk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;CPU only:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -f Dockerfile.cpu -t wlk .
docker run -p 8000:8000 --name wlk wlk
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Usage&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Custom configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Example with custom model and language
docker run --gpus all -p 8000:8000 --name wlk wlk --model large-v3 --language fr
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Memory Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Large models&lt;/strong&gt;: Ensure your Docker runtime has sufficient memory allocated&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Customization&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--build-arg&lt;/code&gt; Options: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;EXTRAS="whisper-timestamped"&lt;/code&gt; - Add extras to the image's installation (no spaces). Remember to set necessary container options!&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;HF_PRECACHE_DIR="./.cache/"&lt;/code&gt; - Pre-load a model cache for faster first-time start&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;HF_TKN_FILE="./token"&lt;/code&gt; - Add your Hugging Face Hub access token to download gated models&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”® Use Cases&lt;/h2&gt; 
&lt;p&gt;Capture discussions in real-time for meeting transcription, help hearing-impaired users follow conversations through accessibility tools, transcribe podcasts or videos automatically for content creation, transcribe support calls with speaker identification for customer service...&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gristlabs/grist-core</title>
      <link>https://github.com/gristlabs/grist-core</link>
      <description>&lt;p&gt;Grist is the evolution of spreadsheets.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Grist&lt;/h1&gt; 
&lt;p&gt;Grist is a modern relational spreadsheet. It combines the flexibility of a spreadsheet with the robustness of a database.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;grist-core&lt;/code&gt; (this repo) has what you need to run a powerful server for hosting spreadsheets.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/gristlabs/grist-desktop"&gt;&lt;code&gt;grist-desktop&lt;/code&gt;&lt;/a&gt; is a Linux/macOS/Windows desktop app for viewing and editing spreadsheets stored locally.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/gristlabs/grist-static"&gt;&lt;code&gt;grist-static&lt;/code&gt;&lt;/a&gt; is a fully in-browser build of Grist for displaying spreadsheets on a website without back-end support.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Grist is developed by &lt;a href="https://www.linkedin.com/company/grist-labs/"&gt;Grist Labs&lt;/a&gt;, an NYC-based company ğŸ‡ºğŸ‡¸ğŸ—½. The French government ğŸ‡«ğŸ‡· organizations &lt;a href="https://donnees.incubateur.anct.gouv.fr/toolbox/grist"&gt;ANCT DonnÃ©es et Territoires&lt;/a&gt; and &lt;a href="https://www.numerique.gouv.fr/dinum/"&gt;DINUM (Direction InterministÃ©rielle du NumÃ©rique)&lt;/a&gt; have also made significant contributions to the codebase.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;grist-core&lt;/code&gt;, &lt;code&gt;grist-desktop&lt;/code&gt;, and &lt;code&gt;grist-static&lt;/code&gt; repositories are all open source (Apache License, Version 2.0). Grist Labs offers free and paid hosted services at &lt;a href="https://getgrist.com"&gt;getgrist.com&lt;/a&gt;, sells an Enterprise product, and offers &lt;a href="https://support.getgrist.com/install/grist-builder-edition/"&gt;cloud packaging&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Questions? Feedback? Want to share what you're building with Grist? Join our &lt;a href="https://discord.gg/MYKpYQ3fbP"&gt;official Discord server&lt;/a&gt; or visit our &lt;a href="https://community.getgrist.com/"&gt;Community forum&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/118367/151245587-892e50a6-41f5-4b74-9786-fe3566f6b1fb.mp4"&gt;https://user-images.githubusercontent.com/118367/151245587-892e50a6-41f5-4b74-9786-fe3566f6b1fb.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features in &lt;code&gt;grist-core&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;To see exactly what is present in &lt;code&gt;grist-core&lt;/code&gt;, you can run the &lt;a href="https://github.com/gristlabs/grist-desktop"&gt;desktop app&lt;/a&gt;, or use &lt;a href="https://raw.githubusercontent.com/gristlabs/grist-core/main/#using-grist"&gt;&lt;code&gt;docker&lt;/code&gt;&lt;/a&gt;. The absolute fastest way to try Grist out is to visit &lt;a href="https://docs.getgrist.com"&gt;docs.getgrist.com&lt;/a&gt; and play with a spreadsheet there immediately â€“&amp;nbsp;though if you do, please read the list of &lt;a href="https://raw.githubusercontent.com/gristlabs/grist-core/main/#features-not-in-grist-core"&gt;extra extensions&lt;/a&gt; that are not in &lt;code&gt;grist-core&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;However you try it, you'll quickly see that Grist is a hybrid database/spreadsheet, meaning that:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Columns work like they do in databases: they are named, and they hold one kind of data.&lt;/li&gt; 
 &lt;li&gt;Columns can be filled by formula, spreadsheet-style, with automatic updates when referenced cells change.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This difference can confuse people coming directly from Excel or Google Sheets. Give it a chance! There's also a &lt;a href="https://www.getgrist.com/blog/grist-for-spreadsheet-users/"&gt;Grist for Spreadsheet Users&lt;/a&gt; article to help get you oriented. If you're coming from Airtable, you'll find the model familiar (and there's also our &lt;a href="https://www.getgrist.com/blog/grist-v-airtable/"&gt;Grist vs Airtable&lt;/a&gt; article for a direct comparison).&lt;/p&gt; 
&lt;p&gt;Here are some specific feature highlights of Grist:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python formulas. 
  &lt;ul&gt; 
   &lt;li&gt;Full &lt;a href="https://support.getgrist.com/formulas/#python"&gt;Python syntax is supported&lt;/a&gt;, including the standard library.&lt;/li&gt; 
   &lt;li&gt;Many &lt;a href="https://support.getgrist.com/functions/"&gt;Excel functions&lt;/a&gt; also available.&lt;/li&gt; 
   &lt;li&gt;An &lt;a href="https://www.getgrist.com/ai-formula-assistant/"&gt;AI Assistant&lt;/a&gt; specifically tuned for formula generation (using OpenAI gpt-3.5-turbo or &lt;a href="https://ai.meta.com/llama/"&gt;Llama&lt;/a&gt; via &lt;a href="https://github.com/abetlen/llama-cpp-python"&gt;llama-cpp-python&lt;/a&gt;).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;A portable, self-contained format. 
  &lt;ul&gt; 
   &lt;li&gt;Based on SQLite, the most widely deployed database engine.&lt;/li&gt; 
   &lt;li&gt;Any tool that can read SQLite can read numeric and text data from a Grist file.&lt;/li&gt; 
   &lt;li&gt;Enables &lt;a href="https://support.getgrist.com/exports/#backing-up-an-entire-document"&gt;backups&lt;/a&gt; that you can confidently restore in full.&lt;/li&gt; 
   &lt;li&gt;Great for moving between different hosts.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Can be displayed on a static website with &lt;a href="https://github.com/gristlabs/grist-static"&gt;&lt;code&gt;grist-static&lt;/code&gt;&lt;/a&gt; â€“ no special server needed.&lt;/li&gt; 
 &lt;li&gt;A self-contained desktop app for viewing and editing locally: &lt;a href="https://github.com/gristlabs/grist-desktop"&gt;&lt;code&gt;grist-desktop&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Convenient editing and formatting features. 
  &lt;ul&gt; 
   &lt;li&gt;Choices and &lt;a href="https://support.getgrist.com/col-types/#choice-list-columns"&gt;choice lists&lt;/a&gt;, for adding colorful tags to records.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://support.getgrist.com/col-refs/#creating-a-new-reference-list-column"&gt;References&lt;/a&gt; and reference lists, for cross-referencing records in other tables.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://support.getgrist.com/col-types/#attachment-columns"&gt;Attachments&lt;/a&gt;, to include media or document files in records.&lt;/li&gt; 
   &lt;li&gt;Dates and times, toggles, and special numerics such as currency all have specialized editors and formatting options.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://support.getgrist.com/conditional-formatting/"&gt;Conditional Formatting&lt;/a&gt;, letting you control the style of cells with formulas to draw attention to important information.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Drag-and-drop dashboards. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://support.getgrist.com/widget-chart/"&gt;Charts&lt;/a&gt;, &lt;a href="https://support.getgrist.com/widget-card/"&gt;card views&lt;/a&gt; and a &lt;a href="https://support.getgrist.com/widget-calendar/"&gt;calendar widget&lt;/a&gt; for visualization.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://support.getgrist.com/summary-tables/"&gt;Summary tables&lt;/a&gt; for summing and counting across groups.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://support.getgrist.com/linking-widgets/"&gt;Widget linking&lt;/a&gt; streamlines filtering and editing data. Grist has a unique approach to visualization, where you can lay out and link distinct widgets to show together, without cramming mixed material into a table.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://support.getgrist.com/search-sort-filter/#filter-buttons"&gt;Filter bar&lt;/a&gt; for quick slicing and dicing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.getgrist.com/imports/#updating-existing-records"&gt;Incremental imports&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;Import a CSV of the last three months activity from your bank...&lt;/li&gt; 
   &lt;li&gt;...and import new activity a month later without fuss or duplication.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.getgrist.com/widget-form/"&gt;Native forms&lt;/a&gt;. Create forms that feed directly into your spreadsheet without fuss.&lt;/li&gt; 
 &lt;li&gt;Integrations. 
  &lt;ul&gt; 
   &lt;li&gt;A &lt;a href="https://support.getgrist.com/api/"&gt;REST API&lt;/a&gt;, &lt;a href="https://support.getgrist.com/integrators/#integrations-via-zapier"&gt;Zapier actions/triggers&lt;/a&gt;, and support from similar &lt;a href="https://support.getgrist.com/integrators/"&gt;integrators&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Import/export to Google drive, Excel format, CSV.&lt;/li&gt; 
   &lt;li&gt;Link data with &lt;a href="https://support.getgrist.com/widget-custom/#_top"&gt;custom widgets&lt;/a&gt;, hosted externally.&lt;/li&gt; 
   &lt;li&gt;Configurable outgoing webhooks.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://templates.getgrist.com/"&gt;Many templates&lt;/a&gt; to get you started, from investment research to organizing treasure hunts.&lt;/li&gt; 
 &lt;li&gt;Access control options. 
  &lt;ul&gt; 
   &lt;li&gt;(You'll need SSO logins set up to make use of these options; &lt;a href="https://github.com/gristlabs/grist-omnibus"&gt;&lt;code&gt;grist-omnibus&lt;/code&gt;&lt;/a&gt; has a prepackaged solution if configuring this feels daunting)&lt;/li&gt; 
   &lt;li&gt;Share &lt;a href="https://support.getgrist.com/sharing/"&gt;individual documents&lt;/a&gt;, workspaces, or &lt;a href="https://support.getgrist.com/team-sharing/"&gt;team sites&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Control access to &lt;a href="https://support.getgrist.com/access-rules/"&gt;individual rows, columns, and tables&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Control access based on cell values and user attributes.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Self-maintainable. 
  &lt;ul&gt; 
   &lt;li&gt;Useful for intranet operation and specific compliance requirements.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Sandboxing options for untrusted documents. 
  &lt;ul&gt; 
   &lt;li&gt;On Linux or with Docker, you can enable &lt;a href="https://github.com/google/gvisor"&gt;gVisor&lt;/a&gt; sandboxing at the individual document level.&lt;/li&gt; 
   &lt;li&gt;On macOS, you can use native sandboxing.&lt;/li&gt; 
   &lt;li&gt;On any OS, including Windows, you can use a wasm-based sandbox.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Translated to many languages.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;F1&lt;/code&gt; key brings up some quick help. This used to go without saying, but in general Grist has good keyboard support.&lt;/li&gt; 
 &lt;li&gt;We post progress on &lt;a href="https://twitter.com/getgrist"&gt;ğ• or Twitter or whatever&lt;/a&gt; and publish &lt;a href="https://support.getgrist.com/newsletters/"&gt;monthly newsletters&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are curious about where Grist is heading, see &lt;a href="https://github.com/gristlabs/grist-core/projects/1"&gt;our roadmap&lt;/a&gt;, drop a question in &lt;a href="https://community.getgrist.com"&gt;our forum&lt;/a&gt;, or browse &lt;a href="https://support.getgrist.com"&gt;our extensive documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features not in &lt;code&gt;grist-core&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;If you evaluate Grist by using the hosted version at &lt;a href="https://getgrist.com"&gt;getgrist.com&lt;/a&gt;, be aware that it includes some extensions to Grist that aren't present in &lt;code&gt;grist-core&lt;/code&gt;. To be sure you're seeing exactly what is present in &lt;code&gt;grist-core&lt;/code&gt;, you can run the &lt;a href="https://github.com/gristlabs/grist-desktop"&gt;desktop app&lt;/a&gt;, or use &lt;a href="https://raw.githubusercontent.com/gristlabs/grist-core/main/#using-grist"&gt;&lt;code&gt;docker&lt;/code&gt;&lt;/a&gt;. Here is a list of features you may see in Grist Labs' hosting or Enterprise offerings that are not in &lt;code&gt;grist-core&lt;/code&gt;, in chronological order of creation. If self-hosting, you can get access to a free trial of all of them using the Enterprise toggle on the &lt;a href="https://support.getgrist.com/admin-panel/"&gt;Admin Panel&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://support.getgrist.com/install/grist-connect/"&gt;GristConnect&lt;/a&gt; (2022) 
  &lt;ul&gt; 
   &lt;li&gt;Any site that has plugins for letting Discourse use its logins (such as WordPress) can also let Grist use its logins.&lt;/li&gt; 
   &lt;li&gt;GristConnect is a niche feature built for a specific client which you probably don't care about â€“ &lt;code&gt;OIDC&lt;/code&gt; and &lt;code&gt;SAML&lt;/code&gt; support &lt;em&gt;is&lt;/em&gt; part of &lt;code&gt;grist-core&lt;/code&gt; and covers most authentication use cases.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.getgrist.com/install/cloud-storage/#azure"&gt;Azure back-end for document storage&lt;/a&gt; (2022) 
  &lt;ul&gt; 
   &lt;li&gt;With &lt;code&gt;grist-core&lt;/code&gt; you can store document versions in anything S3-compatible, which covers a lot of services, but not Azure specifically. The Azure back-end fills that gap.&lt;/li&gt; 
   &lt;li&gt;Unless you are a Microsoft shop you probably don't care about this.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.getgrist.com/install/audit-log-streaming/"&gt;Audit log streaming&lt;/a&gt; (2024) 
  &lt;ul&gt; 
   &lt;li&gt;With &lt;code&gt;grist-core&lt;/code&gt; a lot of useful information is logged, but not organized specifically with auditing in mind. Audit log streaming supplies that organization, and a UI for setting things up.&lt;/li&gt; 
   &lt;li&gt;Enterprises may care about this.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.getgrist.com/admin-controls/"&gt;Advanced Admin Controls&lt;/a&gt; (2025) 
  &lt;ul&gt; 
   &lt;li&gt;This is a special page for a Grist installation administrator to monitor and edit user access to resources.&lt;/li&gt; 
   &lt;li&gt;It uses a special set of administrative endpoints not present on &lt;code&gt;grist-core&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;If you're going to be running a large Grist installation, with employees coming and going, you may care about this.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.getgrist.com/assistant/#assistant"&gt;Grist Assistant&lt;/a&gt; (2025) 
  &lt;ul&gt; 
   &lt;li&gt;An AI Formula Assistant - limited to working with formulas - is present in &lt;code&gt;grist-core&lt;/code&gt;, but the newer Assistant can help with a wider range of tasks like building tables and dashboards and modifying data.&lt;/li&gt; 
   &lt;li&gt;If you have many users who need help building documents or working with data, you may care about this one.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.getgrist.com/self-managed/#how-do-i-set-up-email-notifications"&gt;Invite Notifications&lt;/a&gt; (2025) 
  &lt;ul&gt; 
   &lt;li&gt;When a user is added to a document, or a workspace, or a site, with email notifications they will get emailed a link to access the resource.&lt;/li&gt; 
   &lt;li&gt;This link isn't special, with &lt;code&gt;grist-core&lt;/code&gt; you can just send a link yourself or a colleague.&lt;/li&gt; 
   &lt;li&gt;For a big Grist installation with users who aren't in close communication, emails might be nice? Hard to guess if you'll care about this one.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.getgrist.com/document-settings/#notifications"&gt;Document Change and Comment Notifications&lt;/a&gt; (2025) 
  &lt;ul&gt; 
   &lt;li&gt;You can achieve change notifications in &lt;code&gt;grist-core&lt;/code&gt; using webhooks, but it is less convenient.&lt;/li&gt; 
   &lt;li&gt;People have been asking for this one for years. If you need an excuse to get your boss to pay for Grist, this might finally be the one that works?&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Using Grist&lt;/h2&gt; 
&lt;p&gt;To get the default version of &lt;code&gt;grist-core&lt;/code&gt; running on your computer with &lt;a href="https://www.docker.com/get-started"&gt;Docker&lt;/a&gt;, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker pull gristlabs/grist
docker run -p 8484:8484 -it gristlabs/grist
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://localhost:8484&lt;/code&gt; in your browser. You'll be able to create, edit, import, and export documents. To preserve your work across docker runs, share a directory as &lt;code&gt;/persist&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 8484:8484 -v $PWD/persist:/persist -it gristlabs/grist
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Get templates at &lt;a href="https://templates.getgrist.com"&gt;templates.getgrist.com&lt;/a&gt; for payroll, inventory management, invoicing, D&amp;amp;D encounter tracking, and a lot more, or use any document you've created on &lt;a href="https://docs.getgrist.com"&gt;docs.getgrist.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you need to change the port Grist runs on, set a &lt;code&gt;PORT&lt;/code&gt; variable, don't just change the port mapping:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --env PORT=9999 -p 9999:9999 -v $PWD/persist:/persist -it gristlabs/grist
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To enable gVisor sandboxing, set &lt;code&gt;--env GRIST_SANDBOX_FLAVOR=gvisor&lt;/code&gt;. This should work with default docker settings, but may not work in all environments.&lt;/p&gt; 
&lt;p&gt;You can find a lot more about configuring Grist, setting up authentication, and running it on a public server in our &lt;a href="https://support.getgrist.com/self-managed/"&gt;Self-Managed Grist&lt;/a&gt; handbook.&lt;/p&gt; 
&lt;h2&gt;Using Grist with OpenRouter for Model Agnostic and Claude Support&lt;/h2&gt; 
&lt;p&gt;(Instructions contributed by @lshalon)&lt;/p&gt; 
&lt;p&gt;Grist's AI Formula Assistant can be configured to use OpenRouter instead of connecting directly to OpenAI, allowing you to access a wide range of AI models including Anthropic's Claude models. This isn't the only way to use Claude models, but it's a good option if you want to use Claude models with Grist or intend to use other cheaper, faster, or potentially newer models. That's because this configuration gives you more flexibility in choosing the AI model that works best for your formula generation needs. To set up OpenRouter integration, configure the following environment variables:&lt;/p&gt; 
&lt;h3&gt;Required: Set the endpoint to OpenRouter's API&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ASSISTANT_CHAT_COMPLETION_ENDPOINT=https://openrouter.ai/api/v1/chat/completions
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Required: Your OpenRouter API key&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ASSISTANT_API_KEY=your_openrouter_api_key_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sign up for an OpenRouter API key at &lt;a href="https://openrouter.ai/"&gt;https://openrouter.ai/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Optional: Specify which model to use (examples below)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ASSISTANT_MODEL=anthropic/claude-3.7-sonnet
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;or other options like&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ASSISTANT_MODEL=deepseek/deepseek-r1-zero:free
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;ASSISTANT_MODEL=qwen/qwq-32b:free
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;ASSISTANT_MODEL=mistralai/mistral-saba
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional: Set a larger context model for fallback&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ASSISTANT_LONGER_CONTEXT_MODEL=anthropic/claude-3-opus-20240229
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With this configuration, Grist's AI Formula Assistant will route requests through OpenRouter to your specified model. This allows you to:&lt;/p&gt; 
&lt;p&gt;Access Anthropic's Claude models which excel at understanding context and generating accurate formulas Switch between different AI models without changing your Grist configuration Take advantage of OpenRouter's routing capabilities to optimize for cost, speed, or quality&lt;/p&gt; 
&lt;p&gt;You can find the available models and their identifiers on the OpenRouter website. Note: Make sure not to set the OPENAI_API_KEY variable when using OpenRouter, as this would override the OpenRouter configuration.&lt;/p&gt; 
&lt;h2&gt;Available Docker images&lt;/h2&gt; 
&lt;p&gt;The default Docker image is &lt;code&gt;gristlabs/grist&lt;/code&gt;. This contains all of the standard Grist functionality, as well as extra source-available code for enterprise customers taken from the &lt;a href="https://github.com/gristlabs/grist-ee"&gt;grist-ee&lt;/a&gt; repository. This extra code is not under a free or open source license. By default, however, the code from the &lt;code&gt;grist-ee&lt;/code&gt; repository is completely inert and inactive. This code becomes active only when enabled from the administrator panel.&lt;/p&gt; 
&lt;p&gt;If you would rather use an image that contains exclusively free and open source code, the &lt;code&gt;gristlabs/grist-oss&lt;/code&gt; Docker image is available for this purpose. It is by default functionally equivalent to the &lt;code&gt;gristlabs/grist&lt;/code&gt; image.&lt;/p&gt; 
&lt;h2&gt;The administrator panel&lt;/h2&gt; 
&lt;p&gt;You can turn on a special admininistrator panel to inspect the status of your installation. Just visit &lt;code&gt;/admin&lt;/code&gt; on your Grist server for instructions. Since it is useful for the admin panel to be available even when authentication isn't set up, you can give it a special access key by setting &lt;code&gt;GRIST_BOOT_KEY&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -p 8484:8484 -e GRIST_BOOT_KEY=secret -it gristlabs/grist
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The boot page should then be available at &lt;code&gt;/admin?boot-key=&amp;lt;GRIST_BOOT_KEY&amp;gt;&lt;/code&gt;. We are collecting probes for common problems there. If you hit a problem that isn't covered, it would be great if you could add a probe for it in &lt;a href="https://github.com/gristlabs/grist-core/raw/main/app/server/lib/BootProbes.ts"&gt;BootProbes&lt;/a&gt;. You may instead file an issue so someone else can add it.&lt;/p&gt; 
&lt;h2&gt;Building from source&lt;/h2&gt; 
&lt;p&gt;To build Grist from source, follow these steps:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yarn install
yarn run build
yarn run install:python
yarn start
# Grist will be available at http://localhost:8484/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Grist formulas in documents will be run using Python executed directly on your machine. You can configure sandboxing using a &lt;code&gt;GRIST_SANDBOX_FLAVOR&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;On macOS, &lt;code&gt;export GRIST_SANDBOX_FLAVOR=macSandboxExec&lt;/code&gt; uses the native &lt;code&gt;sandbox-exec&lt;/code&gt; command for sandboxing.&lt;/li&gt; 
 &lt;li&gt;On Linux with &lt;a href="https://github.com/google/gvisor"&gt;gVisor's runsc&lt;/a&gt; installed, &lt;code&gt;export GRIST_SANDBOX_FLAVOR=gvisor&lt;/code&gt; is an option.&lt;/li&gt; 
 &lt;li&gt;On any OS including Windows, &lt;code&gt;export GRIST_SANDBOX_FLAVOR=pyodide&lt;/code&gt; is available.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These sandboxing methods have been written for our own use at Grist Labs and may need tweaking to work in your own environment - pull requests very welcome here!&lt;/p&gt; 
&lt;h2&gt;Logins&lt;/h2&gt; 
&lt;p&gt;Like git, Grist has features to track document revision history. So for full operation, Grist expects to know who the user modifying a document is. Until it does, it operates in a limited anonymous mode. To get you going, the docker image is configured so that when you click on the "sign in" button Grist will attribute your work to &lt;code&gt;you@example.com&lt;/code&gt;. Change this by setting &lt;code&gt;GRIST_DEFAULT_EMAIL&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --env GRIST_DEFAULT_EMAIL=my@email -p 8484:8484 -v $PWD/persist:/persist -it gristlabs/grist
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can change your name in &lt;code&gt;Profile Settings&lt;/code&gt; in the &lt;a href="https://support.getgrist.com/glossary/#user-menu"&gt;User Menu&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For multi-user operation, or if you wish to access Grist across the public internet, you'll want to connect it to your own Single Sign-On service. There are a lot of ways to do this, including &lt;a href="https://support.getgrist.com/self-managed/#how-do-i-set-up-authentication"&gt;SAML and forward authentication&lt;/a&gt;. Grist has been tested with &lt;a href="https://goauthentik.io/"&gt;Authentik&lt;/a&gt;, &lt;a href="https://auth0.com/"&gt;Auth0&lt;/a&gt;, and Google/Microsoft sign-ins via &lt;a href="https://dexidp.io/"&gt;Dex&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://hosted.weblate.org/engage/grist/"&gt;Weblate&lt;/a&gt; to manage translations. Thanks to everyone who is pitching in. Thanks especially to the ANCT developers who did the hard work of making a good chunk of the application localizable. Merci beaucoup !&lt;/p&gt; 
&lt;a href="https://hosted.weblate.org/engage/grist/"&gt; &lt;img src="https://hosted.weblate.org/widgets/grist/-/open-graph.png" alt="Translation status" width="480" /&gt; &lt;/a&gt; 
&lt;p&gt;&lt;a href="https://hosted.weblate.org/engage/grist/"&gt;&lt;img src="https://hosted.weblate.org/widgets/grist/-/multi-green.svg?sanitize=true" alt="Translation detail" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why free and open source software&lt;/h2&gt; 
&lt;p&gt;This repository, &lt;code&gt;grist-core&lt;/code&gt;, is maintained by Grist Labs. Our flagship product available at &lt;a href="https://www.getgrist.com"&gt;getgrist.com&lt;/a&gt; is built from the code you see here, combined with business-specific software designed to scale to many users, handle billing, etc.&lt;/p&gt; 
&lt;p&gt;Grist Labs is an open-core company. We offer Grist hosting as a service, with free and paid plans. We also develop and sell features related to Grist using a proprietary license, targeted at the needs of enterprises with large self-managed installations.&lt;/p&gt; 
&lt;p&gt;We see data portability and autonomy as a key value, and &lt;code&gt;grist-core&lt;/code&gt; is an essential part of that. We are committed to maintaining and improving the &lt;code&gt;grist-core&lt;/code&gt; codebase, and to be thoughtful about how proprietary offerings impact data portability and autonomy.&lt;/p&gt; 
&lt;p&gt;By opening its source code and offering an &lt;a href="https://opensource.org/"&gt;OSI&lt;/a&gt;-approved free license, Grist benefits its users:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Developer community.&lt;/strong&gt; The freedom to examine source code, make bug fixes, and develop new features is a big deal for a general-purpose spreadsheet-like product, where there is a very long tail of features vital to someone somewhere.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Increased trust.&lt;/strong&gt; Because anyone can examine the source code, â€œsecurity by obscurityâ€ is not an option. Vulnerabilities in the code can be found by others and reported before they cause damage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Independence.&lt;/strong&gt; Grist is available to you regardless of the fortunes of the Grist Labs business, since it is open source and can be self-hosted. Using our hosted solution is convenient, but you are not locked in.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Price flexibility.&lt;/strong&gt; If you are low on funds but have time to invest, self-hosting is a great option to have. And DIY users may have the technical savvy and motivation to delve in and make improvements, which can benefit all users of Grist.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensibility.&lt;/strong&gt; For developers, having the source open makes it easier to build extensions (such as &lt;a href="https://support.getgrist.com/widget-custom/"&gt;Custom Widgets&lt;/a&gt;). You can more easily include Grist in your pipeline. And if a feature is missing, you can just take the source code and build on top of it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more on Grist Labs' history and principles, see our &lt;a href="https://www.getgrist.com/about/"&gt;About Us&lt;/a&gt; page.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.dotphoton.com/"&gt; &lt;img width="11%" src="https://user-images.githubusercontent.com/11277225/228914729-ae581352-b37a-4ca8-b220-b1463dd1ade0.png" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Reviews&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.producthunt.com/posts/grist-2"&gt;Grist on ProductHunt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://appsumo.com/products/grist/"&gt;Grist on AppSumo&lt;/a&gt; (life-time deal is sold out)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.capterra.com/p/232821/Grist/#reviews"&gt;Capterra&lt;/a&gt;, &lt;a href="https://www.g2.com/products/grist/reviews"&gt;G2&lt;/a&gt;, &lt;a href="https://www.trustradius.com/products/grist/reviews"&gt;TrustRadius&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Environment variables&lt;/h2&gt; 
&lt;p&gt;Grist can be configured in many ways. Here are the main environment variables it is sensitive to:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ALLOWED_WEBHOOK_DOMAINS&lt;/td&gt; 
   &lt;td&gt;comma-separated list of permitted domains to use in webhooks (e.g. webhook.site,zapier.com). You can set this to &lt;code&gt;*&lt;/code&gt; to allow all domains, but if doing so, we recommend using a carefully locked-down proxy (see &lt;code&gt;GRIST_PROXY_FOR_UNTRUSTED_URLS&lt;/code&gt;) if you do not entirely trust users. Otherwise services on your internal network may become vulnerable to manipulation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;APP_DOC_URL&lt;/td&gt; 
   &lt;td&gt;doc worker url, set when starting an individual doc worker (other servers will find doc worker urls via redis)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;APP_DOC_INTERNAL_URL&lt;/td&gt; 
   &lt;td&gt;like &lt;code&gt;APP_DOC_URL&lt;/code&gt; but used by the home server to reach the server using an internal domain name resolution (like in a docker environment). It only makes sense to define this value in the doc worker. Defaults to &lt;code&gt;APP_DOC_URL&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;APP_HOME_URL&lt;/td&gt; 
   &lt;td&gt;url prefix for home api (home and doc servers need this)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;APP_HOME_INTERNAL_URL&lt;/td&gt; 
   &lt;td&gt;like &lt;code&gt;APP_HOME_URL&lt;/code&gt; but used by the home and the doc servers to reach any home workers using an internal domain name resolution (like in a docker environment). Defaults to &lt;code&gt;APP_HOME_URL&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;APP_STATIC_URL&lt;/td&gt; 
   &lt;td&gt;url prefix for static resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;APP_STATIC_INCLUDE_CUSTOM_CSS&lt;/td&gt; 
   &lt;td&gt;set to "true" to include custom.css (from APP_STATIC_URL) in static pages&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;APP_UNTRUSTED_URL&lt;/td&gt; 
   &lt;td&gt;URL at which to serve/expect plugin content.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ACTION_HISTORY_MAX_ROWS&lt;/td&gt; 
   &lt;td&gt;Maximum number of rows allowed in ActionHistory before pruning (up to a 1.25 grace factor). Defaults to 1000. âš ï¸ A too low value may make the "&lt;a href="https://support.getgrist.com/newsletters/2021-06/#work-on-a-copy"&gt;Work on a copy&lt;/a&gt;" feature &lt;a href="https://github.com/gristlabs/grist-core/issues/1121#issuecomment-2248112023"&gt;malfunction&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ACTION_HISTORY_MAX_BYTES&lt;/td&gt; 
   &lt;td&gt;Maximum number of rows allowed in ActionHistory before pruning (up to a 1.25 grace factor). Defaults to 1Gb. âš ï¸ A too low value may make the "&lt;a href="https://support.getgrist.com/newsletters/2021-06/#work-on-a-copy"&gt;Work on a copy&lt;/a&gt;" feature &lt;a href="https://github.com/gristlabs/grist-core/issues/1121#issuecomment-2248112023"&gt;malfunction&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ADAPT_DOMAIN&lt;/td&gt; 
   &lt;td&gt;set to "true" to support multiple base domains (careful, host header should be trustworthy)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ALLOW_AUTOMATIC_VERSION_CHECKING&lt;/td&gt; 
   &lt;td&gt;Whether Grist is allowed to automatically check if a newer Grist version is available. Defaults to "true" on the default &lt;code&gt;grist&lt;/code&gt; and &lt;code&gt;grist-ee&lt;/code&gt; Docker images. Defaults false in &lt;code&gt;grist-oss&lt;/code&gt; and everywhere else.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ALLOW_DEPRECATED_BARE_ORG_DELETE&lt;/td&gt; 
   &lt;td&gt;If set, the deprecated DELETE /api/orgs/:orgId endpoint is available.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_APP_ROOT&lt;/td&gt; 
   &lt;td&gt;directory containing Grist sandbox and assets (specifically the sandbox and static subdirectories).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ATTACHMENT_THRESHOLD_MB&lt;/td&gt; 
   &lt;td&gt;attachment storage limit per document beyond which Grist will recommend external storage (if available). Defaults to 50MB.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_BACKUP_DELAY_SECS&lt;/td&gt; 
   &lt;td&gt;wait this long after a doc change before making a backup&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_BOOT_KEY&lt;/td&gt; 
   &lt;td&gt;if set, offer diagnostics at /boot/GRIST_BOOT_KEY&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_DATA_DIR&lt;/td&gt; 
   &lt;td&gt;Directory in which to store documents. Defaults to &lt;code&gt;docs/&lt;/code&gt; relative to the Grist application directory. In Grist's default Docker image, its default value is /persist/docs so that it will be used as a mounted volume.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_DEFAULT_EMAIL&lt;/td&gt; 
   &lt;td&gt;if set, login as this user if no other credentials presented&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_DEFAULT_PRODUCT&lt;/td&gt; 
   &lt;td&gt;if set, this controls enabled features and limits of new sites. See names of PRODUCTS in Product.ts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_DEFAULT_LOCALE&lt;/td&gt; 
   &lt;td&gt;Locale to use as fallback when Grist cannot honour the browser locale.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_DOMAIN&lt;/td&gt; 
   &lt;td&gt;in hosted Grist, Grist is served from subdomains of this domain. Defaults to "getgrist.com".&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_EXPERIMENTAL_PLUGINS&lt;/td&gt; 
   &lt;td&gt;enables experimental plugins&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_EXTERNAL_ATTACHMENTS_MODE&lt;/td&gt; 
   &lt;td&gt;required to enable external storage for attachments. Set to "snapshots" to enable external storage. Default value is "none". Note that when enabled, a &lt;a href="https://support.getgrist.com/self-managed/#how-do-i-set-up-snapshots"&gt;snapshot storage has to be configured&lt;/a&gt; as well.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ENABLE_REQUEST_FUNCTION&lt;/td&gt; 
   &lt;td&gt;enables the REQUEST function. This function performs HTTP requests in a similar way to &lt;code&gt;requests.request&lt;/code&gt;. This function presents a significant security risk, since it can let users call internal endpoints when Grist is available publicly. This function can also cause performance issues. Unset by default.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_HIDE_UI_ELEMENTS&lt;/td&gt; 
   &lt;td&gt;comma-separated list of UI features to disable. Allowed names of parts: &lt;code&gt;helpCenter&lt;/code&gt;, &lt;code&gt;billing&lt;/code&gt;, &lt;code&gt;templates&lt;/code&gt;, &lt;code&gt;createSite&lt;/code&gt;, &lt;code&gt;multiSite&lt;/code&gt;, &lt;code&gt;multiAccounts&lt;/code&gt;, &lt;code&gt;sendToDrive&lt;/code&gt;, &lt;code&gt;tutorials&lt;/code&gt;, &lt;code&gt;supportGrist&lt;/code&gt;, &lt;code&gt;themes&lt;/code&gt;. If a part also exists in GRIST_UI_FEATURES, it will still be disabled.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_HOST&lt;/td&gt; 
   &lt;td&gt;hostname to use when listening on a port.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_PROXY_FOR_UNTRUSTED_URLS&lt;/td&gt; 
   &lt;td&gt;Full URL of proxy for delivering webhook payloads. Default value is &lt;code&gt;direct&lt;/code&gt; for delivering payloads without proxying.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HTTPS_PROXY or https_proxy&lt;/td&gt; 
   &lt;td&gt;Full URL of reverse web proxy (corporate proxy) for fetching the custom widgets repository or the OIDC config from the issuer.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ID_PREFIX&lt;/td&gt; 
   &lt;td&gt;for subdomains of form o-&lt;em&gt;, expect or produce o-${GRIST_ID_PREFIX}&lt;/em&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_IGNORE_SESSION&lt;/td&gt; 
   &lt;td&gt;if set, Grist will not use a session for authentication.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_INCLUDE_CUSTOM_SCRIPT_URL&lt;/td&gt; 
   &lt;td&gt;if set, will load the referenced URL in a &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag on all app pages.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_INST_DIR&lt;/td&gt; 
   &lt;td&gt;path to Grist instance configuration files, for Grist server.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_LIST_PUBLIC_SITES&lt;/td&gt; 
   &lt;td&gt;if set to true, sites shared with the public will be listed for anonymous users. Defaults to false.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_MANAGED_WORKERS&lt;/td&gt; 
   &lt;td&gt;if set, Grist can assume that if a url targeted at a doc worker returns a 404, that worker is gone&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_MAX_NEW_USER_INVITES_PER_ORG&lt;/td&gt; 
   &lt;td&gt;if set, limits the number of invites to new users per org. Once exceeded, additional invites are blocked until invited users log in for the first time or are uninvited&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_MAX_BILLING_MANAGERS_PER_ORG&lt;/td&gt; 
   &lt;td&gt;if set, limits the number of billing managers per org&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_MAX_PARALLEL_REQUESTS_PER_DOC&lt;/td&gt; 
   &lt;td&gt;max number of concurrent API requests allowed per document (default is 10, set to 0 for unlimited)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_MAX_UPLOAD_ATTACHMENT_MB&lt;/td&gt; 
   &lt;td&gt;max allowed size for attachments (0 or empty for unlimited).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_MAX_UPLOAD_IMPORT_MB&lt;/td&gt; 
   &lt;td&gt;max allowed size for imports (except .grist files) (0 or empty for unlimited).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_OFFER_ALL_LANGUAGES&lt;/td&gt; 
   &lt;td&gt;if set, all translated langauages are offered to the user (by default, only languages with a special 'good enough' key set are offered to user).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ORG_IN_PATH&lt;/td&gt; 
   &lt;td&gt;if true, encode org in path rather than domain&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_PAGE_TITLE_SUFFIX&lt;/td&gt; 
   &lt;td&gt;a string to append to the end of the &lt;code&gt;&amp;lt;title&amp;gt;&lt;/code&gt; in HTML documents. Defaults to &lt;code&gt;" - Grist"&lt;/code&gt;. Set to &lt;code&gt;_blank&lt;/code&gt; for no suffix at all.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;del&gt;GRIST_PROXY_AUTH_HEADER&lt;/del&gt;&lt;/td&gt; 
   &lt;td&gt;Deprecated, and interpreted as a synonym for GRIST_FORWARD_AUTH_HEADER.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ROUTER_URL&lt;/td&gt; 
   &lt;td&gt;optional url for an api that allows servers to be (un)registered with a load balancer&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SERVE_SAME_ORIGIN&lt;/td&gt; 
   &lt;td&gt;set to "true" to access home server and doc workers on the same protocol-host-port as the top-level page, same as for custom domains (careful, host header should be trustworthy)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SERVERS&lt;/td&gt; 
   &lt;td&gt;the types of server to setup. Comma separated values which may contain "home", "docs", static" and/or "app". Defaults to "home,docs,static".&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SESSION_COOKIE&lt;/td&gt; 
   &lt;td&gt;if set, overrides the name of Grist's cookie&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SESSION_DOMAIN&lt;/td&gt; 
   &lt;td&gt;if set, associates the cookie with the given domain - otherwise defaults to GRIST_DOMAIN&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SESSION_SECRET&lt;/td&gt; 
   &lt;td&gt;a key used to encode sessions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SKIP_BUNDLED_WIDGETS&lt;/td&gt; 
   &lt;td&gt;if set, Grist will ignore any bundled widgets included via NPM packages.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SQLITE_MODE&lt;/td&gt; 
   &lt;td&gt;if set to &lt;code&gt;wal&lt;/code&gt;, use SQLite in &lt;a href="https://www.sqlite.org/wal.html"&gt;WAL mode&lt;/a&gt;, if set to &lt;code&gt;sync&lt;/code&gt;, use SQLite with &lt;a href="https://www.sqlite.org/pragma.html#pragma_synchronous"&gt;SYNCHRONOUS=full&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ANON_PLAYGROUND&lt;/td&gt; 
   &lt;td&gt;When set to &lt;code&gt;false&lt;/code&gt; deny anonymous users access to the home page (but documents can still be shared to anonymous users). Defaults to &lt;code&gt;true&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_FORCE_LOGIN&lt;/td&gt; 
   &lt;td&gt;Setting it to &lt;code&gt;true&lt;/code&gt; is similar to setting &lt;code&gt;GRIST_ANON_PLAYGROUND: false&lt;/code&gt; but it blocks any anonymous access (thus any document shared publicly actually requires the users to be authenticated before consulting them)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SINGLE_ORG&lt;/td&gt; 
   &lt;td&gt;set to an org "domain" to pin client to that org&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TEMPLATE_ORG&lt;/td&gt; 
   &lt;td&gt;set to an org "domain" to show public docs from that org&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_HELP_CENTER&lt;/td&gt; 
   &lt;td&gt;set the help center link ref&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TERMS_OF_SERVICE_URL&lt;/td&gt; 
   &lt;td&gt;if set, adds terms of service link&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FREE_COACHING_CALL_URL&lt;/td&gt; 
   &lt;td&gt;set the link to the human help (example: email adress or meeting scheduling tool)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_CONTACT_SUPPORT_URL&lt;/td&gt; 
   &lt;td&gt;set the link to contact support on error pages (example: email adress or online form)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ONBOARDING_VIDEO_ID&lt;/td&gt; 
   &lt;td&gt;set the ID of the YouTube video shown on the homepage and during onboarding&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_CUSTOM_COMMON_URLS&lt;/td&gt; 
   &lt;td&gt;overwrite the default commons URLs. Its value is expected to be a JSON object and a subset of the &lt;a href="https://raw.githubusercontent.com/gristlabs/grist-core/main/app/common/ICommonUrls.ts"&gt;ICommonUrls interface&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SUPPORT_ANON&lt;/td&gt; 
   &lt;td&gt;if set to 'true', show UI for anonymous access (not shown by default)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SUPPORT_EMAIL&lt;/td&gt; 
   &lt;td&gt;if set, give a user with the specified email support powers. The main extra power is the ability to share sites, workspaces, and docs with all users in a listed way.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_OPEN_GRAPH_PREVIEW_IMAGE&lt;/td&gt; 
   &lt;td&gt;the URL of the preview image when sharing the link on websites like social medias or chat applications.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TELEMETRY_LEVEL&lt;/td&gt; 
   &lt;td&gt;the telemetry level. Can be set to: &lt;code&gt;off&lt;/code&gt; (default), &lt;code&gt;limited&lt;/code&gt;, or &lt;code&gt;full&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_THROTTLE_CPU&lt;/td&gt; 
   &lt;td&gt;if set, CPU throttling is enabled&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TRUST_PLUGINS&lt;/td&gt; 
   &lt;td&gt;if set, plugins are expect to be served from the same host as the rest of the Grist app, rather than from a distinct host. Ordinarily, plugins are served from a distinct host so that the cookies used by the Grist app are not automatically available to them. Enable this only if you understand the security implications.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_USER_ROOT&lt;/td&gt; 
   &lt;td&gt;an extra path to look for plugins in - Grist will scan for plugins in &lt;code&gt;$GRIST_USER_ROOT/plugins&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_UI_FEATURES&lt;/td&gt; 
   &lt;td&gt;comma-separated list of UI features to enable. Allowed names of parts: &lt;code&gt;helpCenter&lt;/code&gt;, &lt;code&gt;billing&lt;/code&gt;, &lt;code&gt;templates&lt;/code&gt;, &lt;code&gt;createSite&lt;/code&gt;, &lt;code&gt;multiSite&lt;/code&gt;, &lt;code&gt;multiAccounts&lt;/code&gt;, &lt;code&gt;sendToDrive&lt;/code&gt;, &lt;code&gt;tutorials&lt;/code&gt;, &lt;code&gt;supportGrist&lt;/code&gt;, &lt;code&gt;themes&lt;/code&gt;. If a part also exists in GRIST_HIDE_UI_ELEMENTS, it won't be enabled.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_UNTRUSTED_PORT&lt;/td&gt; 
   &lt;td&gt;if set, plugins will be served from the given port. This is an alternative to setting APP_UNTRUSTED_URL.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_WIDGET_LIST_URL&lt;/td&gt; 
   &lt;td&gt;a url pointing to a widget manifest, by default &lt;a href="https://github.com/gristlabs/grist-widget/releases/download/latest/manifest.json"&gt;https://github.com/gristlabs/grist-widget/releases/download/latest/manifest.json&lt;/a&gt; is used&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_LOG_HTTP&lt;/td&gt; 
   &lt;td&gt;When set to &lt;code&gt;true&lt;/code&gt;, log HTTP requests and responses information. Defaults to &lt;code&gt;false&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_LOG_HTTP_BODY&lt;/td&gt; 
   &lt;td&gt;When this variable and &lt;code&gt;GRIST_LOG_HTTP&lt;/code&gt; are set to &lt;code&gt;true&lt;/code&gt; , log the body along with the HTTP requests. &lt;span&gt;âš &lt;/span&gt; Be aware it may leak confidential information in the logs.&lt;span&gt;âš &lt;/span&gt; Defaults to &lt;code&gt;false&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_LOG_AS_JSON&lt;/td&gt; 
   &lt;td&gt;When this variable is set to &lt;code&gt;true&lt;/code&gt; or a truthy value, output log lines in JSON as opposed to a plain text format.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_LOG_API_DETAILS&lt;/td&gt; 
   &lt;td&gt;When this variable is set to &lt;code&gt;true&lt;/code&gt; or a truthy value, log the API calls details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;COOKIE_MAX_AGE&lt;/td&gt; 
   &lt;td&gt;session cookie max age, defaults to 90 days; can be set to "none" to make it a session cookie&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HOME_PORT&lt;/td&gt; 
   &lt;td&gt;port number to listen on for REST API server; if set to "share", add API endpoints to regular grist port.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PORT&lt;/td&gt; 
   &lt;td&gt;port number to listen on for Grist server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;REDIS_URL&lt;/td&gt; 
   &lt;td&gt;optional redis server for browser sessions and db query caching&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SNAPSHOT_TIME_CAP&lt;/td&gt; 
   &lt;td&gt;optional. Define the caps for tracking buckets. Usage: {"hour": 25, "day": 32, "isoWeek": 12, "month": 96, "year": 1000}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SNAPSHOT_KEEP&lt;/td&gt; 
   &lt;td&gt;optional. Number of recent snapshots to retain unconditionally for a document, regardless of when they were made&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_PROMCLIENT_PORT&lt;/td&gt; 
   &lt;td&gt;optional. If set, serve the Prometheus metrics on the specified port number. âš ï¸ Be sure to use a port which is not publicly exposed âš ï¸.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ENABLE_SCIM&lt;/td&gt; 
   &lt;td&gt;optional. If set, enable the &lt;a href="https://support.getgrist.com/install/scim/"&gt;SCIM API Endpoint&lt;/a&gt; (experimental)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_OIDC_...&lt;/td&gt; 
   &lt;td&gt;optional. Environment variables used to configure OpenID authentification. See &lt;a href="https://support.getgrist.com/install/oidc/"&gt;OpenID Connect&lt;/a&gt; documentation for full related list of environment variables.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SAML_...&lt;/td&gt; 
   &lt;td&gt;optional. Environment variables used to configure SAML authentification. See &lt;a href="https://support.getgrist.com/install/saml/"&gt;SAML&lt;/a&gt; documentation for full related list of environment variables.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_IDP_EXTRA_PROPS&lt;/td&gt; 
   &lt;td&gt;optional. If set, defines which extra fields returned by your identity provider will be stored in the users table of the home database (in the &lt;code&gt;options.ssoExtraInfo&lt;/code&gt; object). Usage: 'onekey,anotherkey'.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_FEATURE_FORM_FRAMING&lt;/td&gt; 
   &lt;td&gt;optional. Configures a border around a rendered form that is added for security reasons; Can be set to: &lt;code&gt;border&lt;/code&gt; or &lt;code&gt;minimal&lt;/code&gt;. Defaults to &lt;code&gt;border&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TRUTHY_VALUES&lt;/td&gt; 
   &lt;td&gt;optional. Comma-separated list of extra words that should be considered as truthy by the data engine beyond english defaults. Ex: "oui,ja,si"&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_FALSY_VALUES&lt;/td&gt; 
   &lt;td&gt;optional. Comma-separated list of extra words that should be considered as falsy by the data engine beyond english defaults. Ex: "non,nein,no"&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_ENABLE_USER_PRESENCE&lt;/td&gt; 
   &lt;td&gt;optional, disabled by default. If set to 'false', disables all user presence features.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;AI Formula Assistant related variables (all optional):&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ASSISTANT_API_KEY&lt;/td&gt; 
   &lt;td&gt;optional. An API key to pass when making requests to an external AI conversational endpoint.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ASSISTANT_CHAT_COMPLETION_ENDPOINT&lt;/td&gt; 
   &lt;td&gt;optional. A chat-completion style endpoint to call. Not needed if OpenAI is being used.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ASSISTANT_MODEL&lt;/td&gt; 
   &lt;td&gt;optional. If set, this string is passed along in calls to the AI conversational endpoint.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ASSISTANT_LONGER_CONTEXT_MODEL&lt;/td&gt; 
   &lt;td&gt;optional. If set, requests that fail because of a context length limitation will be retried with this model set.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OPENAI_API_KEY&lt;/td&gt; 
   &lt;td&gt;optional. Synonym for ASSISTANT_API_KEY that assumes an OpenAI endpoint is being used. Sign up for an account on OpenAI and then generate a secret key &lt;a href="https://platform.openai.com/account/api-keys"&gt;here&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;At the time of writing, the AI Assistant is known to function against OpenAI chat completion endpoints (those ending in &lt;code&gt;/v1/chat/completions&lt;/code&gt;). It is also known to function against the chat completion endpoint provided by &lt;a href="https://github.com/abetlen/llama-cpp-python"&gt;llama-cpp-python&lt;/a&gt; and by &lt;a href="https://lmstudio.ai/"&gt;LM Studio&lt;/a&gt;. For useful results, the LLM should be on par with GPT 3.5 or above.&lt;/p&gt; 
&lt;h4&gt;Sandbox related variables:&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SANDBOX_FLAVOR&lt;/td&gt; 
   &lt;td&gt;can be gvisor, pynbox, unsandboxed, docker, or macSandboxExec. If set, forces Grist to use the specified kind of sandbox.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_SANDBOX&lt;/td&gt; 
   &lt;td&gt;a program or image name to run as the sandbox. See NSandbox.ts for nerdy details.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Forward authentication variables:&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_FORWARD_AUTH_HEADER&lt;/td&gt; 
   &lt;td&gt;if set, trust the specified header (e.g. "x-forwarded-user") to contain authorized user emails, and enable "forward auth" logins.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_FORWARD_AUTH_LOGIN_PATH&lt;/td&gt; 
   &lt;td&gt;if GRIST_FORWARD_AUTH_HEADER is set, Grist will listen at this path for logins. Defaults to &lt;code&gt;/auth/login&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_FORWARD_AUTH_LOGOUT_PATH&lt;/td&gt; 
   &lt;td&gt;if GRIST_FORWARD_AUTH_HEADER is set, Grist will forward to this path when user logs out.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Forward authentication supports two modes, distinguished by &lt;code&gt;GRIST_IGNORE_SESSION&lt;/code&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;With sessions, and forward-auth on login endpoints.&lt;/p&gt; &lt;p&gt;For example, using traefik reverse proxy with &lt;a href="https://github.com/thomseddon/traefik-forward-auth"&gt;traefik-forward-auth&lt;/a&gt; middleware:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;GRIST_IGNORE_SESSION&lt;/code&gt;: do NOT set, or set to a falsy value.&lt;/li&gt; 
   &lt;li&gt;Make sure your reverse proxy applies the forward auth middleware to &lt;code&gt;GRIST_FORWARD_AUTH_LOGIN_PATH&lt;/code&gt; and &lt;code&gt;GRIST_FORWARD_AUTH_LOGOUT_PATH&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;If you want to allow anonymous access in some cases, make sure all other paths are free of the forward auth middleware. Grist will trigger it as needed by redirecting to &lt;code&gt;GRIST_FORWARD_AUTH_LOGIN_PATH&lt;/code&gt;. Once the user is logged in, Grist will use sessions to identify the user until logout.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;With no sessions, and forward-auth on all endpoints.&lt;/p&gt; &lt;p&gt;For example, using HTTP Basic Auth and server configuration that sets the header (specified in &lt;code&gt;GRIST_FORWARD_AUTH_HEADER&lt;/code&gt;) to the logged-in user.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GRIST_IGNORE_SESSION&lt;/code&gt;: set to &lt;code&gt;true&lt;/code&gt;. Grist sessions will not be used.&lt;/li&gt; 
 &lt;li&gt;Make sure your reverse proxy sets the header you specified for all requests that may need login information. It is imperative that this header cannot be spoofed by the user, since Grist will trust whatever is in it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When using forward authentication, you may wish to also set the following variables:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GRIST_FORCE_LOGIN=true&lt;/code&gt; to disable anonymous access.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Plugins:&lt;/h4&gt; 
&lt;p&gt;Grist has a plugin system, used internally. One useful thing you can do with it is include custom widgets in a build of Grist. Custom widgets are usually made available just by setting &lt;code&gt;GRIST_WIDGET_LIST_URL&lt;/code&gt;, but that has the downside of being an external dependency, which can be awkward for offline use or for archiving. Plugins offer an alternative.&lt;/p&gt; 
&lt;p&gt;To "bundle" custom widgets as a plugin:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add a subdirectory of &lt;code&gt;plugins&lt;/code&gt;, e.g. &lt;code&gt;plugins/my-widgets&lt;/code&gt;. Alternatively, you can set the &lt;code&gt;GRIST_USER_ROOT&lt;/code&gt; environment variable to any path you want, and then create &lt;code&gt;plugins/my-widgets&lt;/code&gt; within that.&lt;/li&gt; 
 &lt;li&gt;Add a &lt;code&gt;manifest.yml&lt;/code&gt; file in that subdirectory that looks like this:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;name: My Widgets
components:
  widgets: widgets.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;widgets.json&lt;/code&gt; file should be in the format produced by the &lt;a href="https://github.com/gristlabs/grist-widget"&gt;grist-widget&lt;/a&gt; repository, and should be placed in the same directory as &lt;code&gt;manifest.yml&lt;/code&gt;. Any material in &lt;code&gt;plugins/my-widgets&lt;/code&gt; will be served by Grist, and relative URLs can be used in &lt;code&gt;widgets.json&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Once all files are in place, restart Grist. Your widgets should now be available in the custom widgets dropdown, along with any others from &lt;code&gt;GRIST_WIDGET_LIST_URL&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;If you like, you can add multiple plugin subdirectories, with multiple sets of widgets, and they'll all be made available.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Google Drive integrations:&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GOOGLE_CLIENT_ID&lt;/td&gt; 
   &lt;td&gt;set to the Google Client Id to be used with Google API client&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GOOGLE_CLIENT_SECRET&lt;/td&gt; 
   &lt;td&gt;set to the Google Client Secret to be used with Google API client&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GOOGLE_API_KEY&lt;/td&gt; 
   &lt;td&gt;set to the Google API Key to be used with Google API client (accessing public files)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GOOGLE_DRIVE_SCOPE&lt;/td&gt; 
   &lt;td&gt;set to the scope requested for Google Drive integration (defaults to drive.file)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Database variables:&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPEORM_DATABASE&lt;/td&gt; 
   &lt;td&gt;database filename for sqlite or database name for other db types&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPEORM_HOST&lt;/td&gt; 
   &lt;td&gt;host for db&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPEORM_LOGGING&lt;/td&gt; 
   &lt;td&gt;set to 'true' to see all sql queries&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPEORM_PASSWORD&lt;/td&gt; 
   &lt;td&gt;password to use&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPEORM_PORT&lt;/td&gt; 
   &lt;td&gt;port number for db if not the default for that db type&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPEORM_TYPE&lt;/td&gt; 
   &lt;td&gt;set to 'sqlite' or 'postgres'&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPEORM_USERNAME&lt;/td&gt; 
   &lt;td&gt;username to connect as&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPEORM_EXTRA&lt;/td&gt; 
   &lt;td&gt;any other properties to pass to TypeORM in JSON format&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Docker-only variables:&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_DOCKER_USER&lt;/td&gt; 
   &lt;td&gt;optional. When the container runs as the root user, this is the user the Grist services run as. Overrides the default.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_DOCKER_GROUP&lt;/td&gt; 
   &lt;td&gt;optional. When the container runs as the root user, this is the group the Grist services run as. Overrides the default.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Testing:&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TESTING_SOCKET&lt;/td&gt; 
   &lt;td&gt;a socket used for out-of-channel communication during tests only.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TEST_HTTPS_OFFSET&lt;/td&gt; 
   &lt;td&gt;if set, adds https ports at the specified offset. This is useful in testing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TEST_SSL_CERT&lt;/td&gt; 
   &lt;td&gt;if set, contains filename of SSL certificate.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TEST_SSL_KEY&lt;/td&gt; 
   &lt;td&gt;if set, contains filename of SSL private key.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TEST_LOGIN&lt;/td&gt; 
   &lt;td&gt;allow fake unauthenticated test logins (suitable for dev environment only).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GRIST_TEST_ROUTER&lt;/td&gt; 
   &lt;td&gt;if set, then the home server will serve a mock version of router api at /test/router&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GREP_TESTS&lt;/td&gt; 
   &lt;td&gt;pattern for selecting specific tests to run (e.g. &lt;code&gt;env GREP_TESTS=ActionLog yarn test&lt;/code&gt;).&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Tests&lt;/h2&gt; 
&lt;p&gt;Tests are run automatically as part of CI when a PR is opened. However, it can be helpful to run tests locally before pushing your changes to GitHub. First, you'll want to make sure you've installed all dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yarn install
yarn install:python
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, you can run the main test suite like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yarn test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Python tests may also be run locally. (Note: currently requires Python 3.10 - 3.11.)&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yarn test:python
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For running specific tests, you can specify a pattern with the &lt;code&gt;GREP_TESTS&lt;/code&gt; variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GREP_TESTS=ChoiceList yarn test
env GREP_TESTS=summary yarn test:python
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository, &lt;code&gt;grist-core&lt;/code&gt;, is released under the &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;Apache License, Version 2.0&lt;/a&gt;, which is an &lt;a href="https://opensource.org/"&gt;OSI&lt;/a&gt;-approved free software license. See LICENSE.txt and NOTICE.txt for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBMB/MiniCPM-V</title>
      <link>https://github.com/OpenBMB/MiniCPM-V</link>
      <description>&lt;p&gt;MiniCPM-V 4.5: A GPT-4o Level MLLM for Single Image, Multi Image and High-FPS Video Understanding on Your Phone&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpm_v_and_minicpm_o_title.png" width="500em" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;A GPT-4o Level MLLM for Single Image, Multi Image and High-FPS Video Understanding on Your Phone&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/README_zh.md"&gt;ä¸­æ–‡&lt;/a&gt; | English&lt;/strong&gt;&lt;/p&gt; 
 &lt;span style="display: inline-flex; align-items: center; margin-right: 2px;"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/wechat.png" alt="WeChat" style="margin-right: 4px;" /&gt; &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/wechat.md" target="_blank"&gt; WeChat&lt;/a&gt; &amp;nbsp;| &lt;/span&gt; &amp;nbsp; 
 &lt;span style="display: inline-flex; align-items: center; margin-left: -8px;"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/discord.png" alt="Discord" style="margin-right: 4px;" /&gt; &lt;a href="https://discord.gg/rftuRMbqzf" target="_blank"&gt; Discord&lt;/a&gt; &amp;nbsp; &lt;/span&gt; 
 &lt;p align="center"&gt; MiniCPM-V 4.5 &lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5"&gt;ğŸ¤—&lt;/a&gt; &lt;a href="http://101.126.42.235:30910/"&gt;ğŸ¤–&lt;/a&gt; | MiniCPM-o 2.6 &lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6"&gt;ğŸ¤—&lt;/a&gt; &lt;a href="https://minicpm-omni-webdemo-us.modelbest.cn/"&gt; ğŸ¤–&lt;/a&gt; | &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-Cookbook"&gt;ğŸ³ Cookbook&lt;/a&gt; | ğŸ“„ Technical Report (Coming Soon) &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;MiniCPM-V&lt;/strong&gt; is a series of efficient end-side multimodal LLMs (MLLMs), which accept images, videos and text as inputs and deliver high-quality text outputs. &lt;strong&gt;MiniCPM-o&lt;/strong&gt; additionally takes audio as inputs and provides high-quality speech outputs in an end-to-end fashion. Since February 2024, we have released 7 versions of the model, aiming to achieve &lt;strong&gt;strong performance and efficient deployment&lt;/strong&gt;. The most notable models in the series currently include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MiniCPM-V 4.5&lt;/strong&gt;: ğŸ”¥ğŸ”¥ğŸ”¥ The latest and most capable model in the MiniCPM-V series. With a total of 8B parameters, this model &lt;strong&gt;outperforms GPT-4o-latest, Gemini-2.0 Pro, and Qwen2.5-VL 72B&lt;/strong&gt; in vision-language capabilities, making it the most performant on-device multimodal model in the open-source community. This version brings &lt;strong&gt;new features including efficient high-FPS and long video understanding (up to 96x compression rate for video tokens), controllable hybrid fast/deep thinking, strong handwritten OCR and complex table/document parsing&lt;/strong&gt;. It also advances MiniCPM-V's popular features such as trustworthy behavior, multilingual support and end-side deployability.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MiniCPM-o 2.6&lt;/strong&gt;: â­ï¸â­ï¸â­ï¸ The most capable model in the MiniCPM-o series. With a total of 8B parameters, this end-to-end model &lt;strong&gt;achieves comparable performance to GPT-4o-202405 in vision, speech, and multimodal live streaming&lt;/strong&gt;, making it one of the most versatile and performant models in the open-source community. For the new voice mode, MiniCPM-o 2.6 &lt;strong&gt;supports bilingual real-time speech conversation with configurable voices&lt;/strong&gt;, and also allows for fun capabilities such as emotion/speed/style control, end-to-end voice cloning, role play, etc. Due to its superior token density, MiniCPM-o 2.6 can for the first time &lt;strong&gt;support multimodal live streaming on end-side devices&lt;/strong&gt; such as iPad.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;News 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;h4&gt;ğŸ“Œ Pinned&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[2025.09.01] â­ï¸â­ï¸â­ï¸ MiniCPM-V 4.5 has been officially supported by &lt;a href="https://github.com/ggml-org/llama.cpp/pull/15575"&gt;llama.cpp&lt;/a&gt;, &lt;a href="https://github.com/vllm-project/vllm/pull/23586"&gt;vLLM&lt;/a&gt;, and &lt;a href="https://github.com/hiyouga/LLaMA-Factory/pull/9022"&gt;LLaMA-Factory&lt;/a&gt;. You are welcome to use it directly through these official channels! Support for additional frameworks such as &lt;a href="https://github.com/ollama/ollama/pull/12078"&gt;Ollama&lt;/a&gt; and &lt;a href="https://github.com/sgl-project/sglang/pull/9610"&gt;SGLang&lt;/a&gt; is actively in progress.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.08.26] ğŸ”¥ğŸ”¥ğŸ”¥ We open-source MiniCPM-V 4.5, which outperforms GPT-4o-latest, Gemini-2.0 Pro, and Qwen2.5-VL 72B. It advances popular capabilities of MiniCPM-V, and brings useful new features. Try it now!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.08.01] â­ï¸â­ï¸â­ï¸ We open-sourced the &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook"&gt;MiniCPM-V &amp;amp; o Cookbook&lt;/a&gt;! It provides comprehensive guides for diverse user scenarios, paired with our new &lt;a href="https://minicpm-o.readthedocs.io/en/latest/index.html"&gt;Docs Site&lt;/a&gt; for smoother onboarding.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.06.20] â­ï¸â­ï¸â­ï¸ Our official &lt;a href="https://ollama.com/openbmb"&gt;Ollama repository&lt;/a&gt; is released. Try our latest models with &lt;a href="https://ollama.com/openbmb/minicpm-o2.6"&gt;one click&lt;/a&gt;ï¼&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.03.01] ğŸš€ğŸš€ğŸš€ RLAIF-V, the alignment technique of MiniCPM-o, is accepted by CVPR 2025 Highlightsï¼The &lt;a href="https://github.com/RLHF-V/RLAIF-V"&gt;code&lt;/a&gt;, &lt;a href="https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset"&gt;dataset&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2405.17220"&gt;paper&lt;/a&gt; are open-sourced!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.24] ğŸ“¢ğŸ“¢ğŸ“¢ MiniCPM-o 2.6 technical report is released! See &lt;a href="https://openbmb.notion.site/MiniCPM-o-2-6-A-GPT-4o-Level-MLLM-for-Vision-Speech-and-Multimodal-Live-Streaming-on-Your-Phone-185ede1b7a558042b5d5e45e6b237da9"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.19] ğŸ“¢ &lt;strong&gt;ATTENTION!&lt;/strong&gt; We are currently working on merging MiniCPM-o 2.6 into the official repositories of llama.cpp, Ollama, and vllm. Until the merge is complete, please USE OUR LOCAL FORKS of &lt;a href="https://github.com/OpenBMB/llama.cpp/raw/minicpm-omni/examples/llava/README-minicpmo2.6.md"&gt;llama.cpp&lt;/a&gt;, &lt;a href="https://github.com/OpenBMB/ollama/raw/minicpm-v2.6/examples/minicpm-v2.6/README.md"&gt;Ollama&lt;/a&gt;, and &lt;a href="https://github.com/OpenBMB/MiniCPM-o?tab=readme-ov-file#efficient-inference-with-llamacpp-ollama-vllm"&gt;vllm&lt;/a&gt;. &lt;strong&gt;Using the official repositories before the merge may lead to unexpected issues&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.19] â­ï¸â­ï¸â­ï¸ MiniCPM-o tops GitHub Trending and reaches top-2 on Hugging Face Trending!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.17] We have updated the usage of MiniCPM-o 2.6 int4 quantization version and resolved the model initialization error. Click &lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-int4"&gt;here&lt;/a&gt; and try it now!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.13] ğŸ”¥ğŸ”¥ğŸ”¥ We open-source MiniCPM-o 2.6, which matches GPT-4o-202405 on vision, speech and multimodal live streaming. It advances popular capabilities of MiniCPM-V 2.6, and supports various new fun features. Try it now!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024.08.17] ğŸš€ğŸš€ğŸš€ MiniCPM-V 2.6 is now fully supported by &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;official&lt;/a&gt; llama.cpp! GGUF models of various sizes are available &lt;a href="https://huggingface.co/openbmb/MiniCPM-V-2_6-gguf"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024.08.06] ğŸ”¥ğŸ”¥ğŸ”¥ We open-source MiniCPM-V 2.6, which outperforms GPT-4V on single image, multi-image and video understanding. It advances popular features of MiniCPM-Llama3-V 2.5, and can support real-time video understanding on iPad. Try it now!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024.08.03] MiniCPM-Llama3-V 2.5 technical report is released! See &lt;a href="https://arxiv.org/abs/2408.01800"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024.05.23] ğŸ”¥ğŸ”¥ğŸ”¥ MiniCPM-V tops GitHub Trending and Hugging Face Trending! Our demo, recommended by Hugging Face Gradioâ€™s official account, is available &lt;a href="https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5"&gt;here&lt;/a&gt;. Come and try it out!&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view more news.&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;[2025.08.02] ğŸš€ğŸš€ğŸš€ We open-source MiniCPM-V 4.0, which outperforms GPT-4.1-mini-20250414 in image understanding. It advances popular features of MiniCPM-V 2.6, and largely improves the efficiency. We also open-source the iOS App on iPhone and iPad. Try it now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2025.01.23] ğŸ’¡ğŸ’¡ğŸ’¡ MiniCPM-o 2.6 is now supported by &lt;a href="https://github.com/PKU-Alignment/align-anything"&gt;Align-Anything&lt;/a&gt;, a framework by PKU-Alignment Team for aligning any-to-any modality large models with human intentions. It supports DPO and SFT fine-tuning on both vision and audio. Try it now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.08.15] We now also support multi-image SFT. For more details, please refer to the &lt;a href="https://github.com/OpenBMB/MiniCPM-V/tree/main/finetune"&gt;document&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.08.14] MiniCPM-V 2.6 now also supports &lt;a href="https://github.com/modelscope/ms-swift/issues/1613"&gt;fine-tuning&lt;/a&gt; with the SWIFT framework!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.08.10] ğŸš€ğŸš€ğŸš€ MiniCPM-Llama3-V 2.5 is now fully supported by &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;official&lt;/a&gt; llama.cpp! GGUF models of various sizes are available &lt;a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.07.19] MiniCPM-Llama3-V 2.5 supports vLLM now! See &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-with-vllm"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.06.03] Now, you can run MiniCPM-Llama3-V 2.5 on multiple low VRAM GPUs(12 GB or 16 GB) by distributing the model's layers across multiple GPUs. For more details, check this &lt;a href="https://github.com/OpenBMB/MiniCPM-V/raw/main/docs/inference_on_multiple_gpus.md"&gt;link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.28] ğŸš€ğŸš€ğŸš€ MiniCPM-Llama3-V 2.5 now fully supports its feature in llama.cpp and Ollama! Please pull the latest code &lt;strong&gt;of our provided forks&lt;/strong&gt; (&lt;a href="https://github.com/OpenBMB/llama.cpp/raw/minicpm-v2.5/examples/minicpmv/README.md"&gt;llama.cpp&lt;/a&gt;, &lt;a href="https://github.com/OpenBMB/ollama/tree/minicpm-v2.5/examples/minicpm-v2.5"&gt;Ollama&lt;/a&gt;). GGUF models in various sizes are available &lt;a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf/tree/main"&gt;here&lt;/a&gt;. MiniCPM-Llama3-V 2.5 series is &lt;strong&gt;not supported by the official repositories yet&lt;/strong&gt;, and we are working hard to merge PRs. Please stay tuned!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.28] ğŸ’« We now support LoRA fine-tuning for MiniCPM-Llama3-V 2.5, using only 2 V100 GPUs! See more statistics &lt;a href="https://github.com/OpenBMB/MiniCPM-V/tree/main/finetune#model-fine-tuning-memory-usage-statistics"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.25] MiniCPM-Llama3-V 2.5 now supports streaming outputs and customized system prompts. Try it &lt;a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5#usage"&gt;here&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.24] We release the MiniCPM-Llama3-V 2.5 &lt;a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf"&gt;gguf&lt;/a&gt;, which supports &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-with-llamacpp"&gt;llama.cpp&lt;/a&gt; inference and provides a 6~8 token/s smooth decoding on mobile phones. Try it now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.23] ğŸ” We've released a comprehensive comparison between Phi-3-vision-128k-instruct and MiniCPM-Llama3-V 2.5, including benchmark evaluations, multilingual capabilities, and inference efficiency ğŸŒŸğŸ“ŠğŸŒğŸš€. Click &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/compare_with_phi-3_vision.md"&gt;here&lt;/a&gt; to view more details.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.20] We open-soure MiniCPM-Llama3-V 2.5, it has improved OCR capability and supports 30+ languages, representing the first end-side MLLM achieving GPT-4V level performance! We provide &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#deployment-on-mobile-phone"&gt;efficient inference&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/finetune/readme.md"&gt;simple fine-tuning&lt;/a&gt;. Try it now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.23] MiniCPM-V-2.0 supports vLLM now! Click &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-with-vllm"&gt;here&lt;/a&gt; to view more details.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.18] We create a HuggingFace Space to host the demo of MiniCPM-V 2.0 at &lt;a href="https://huggingface.co/spaces/openbmb/MiniCPM-V-2"&gt;here&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.17] MiniCPM-V-2.0 supports deploying &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#webui-demo"&gt;WebUI Demo&lt;/a&gt; now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.15] MiniCPM-V-2.0 now also supports &lt;a href="https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v-2%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md"&gt;fine-tuning&lt;/a&gt; with the SWIFT framework!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.12] We open-source MiniCPM-V 2.0, which achieves comparable performance with Gemini Pro in understanding scene text and outperforms strong Qwen-VL-Chat 9.6B and Yi-VL 34B on &lt;a href="https://rank.opencompass.org.cn/leaderboard-multimodal"&gt;OpenCompass&lt;/a&gt;, a comprehensive evaluation over 11 popular benchmarks. Click &lt;a href="https://openbmb.vercel.app/minicpm-v-2"&gt;here&lt;/a&gt; to view the MiniCPM-V 2.0 technical blog.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.03.14] MiniCPM-V now supports &lt;a href="https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md"&gt;fine-tuning&lt;/a&gt; with the SWIFT framework. Thanks to &lt;a href="https://github.com/Jintao-Huang"&gt;Jintao&lt;/a&gt; for the contributionï¼&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.03.01] MiniCPM-V can now be deployed on Mac!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.02.01] We open-source MiniCPM-V and OmniLMM-12B, which support efficient end-side deployment and powerful multimodal capabilities correspondingly.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Contents 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#minicpm-v-45"&gt;MiniCPM-V 4.5&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-efficiency"&gt;Inference Efficiency&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#minicpm-o-26"&gt;MiniCPM-o 2.6&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#minicpm-v--o-cookbook"&gt;MiniCPM-V &amp;amp; o Cookbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-our-demo-on-gradio-"&gt;Chat with Our Demo on Gradio ğŸ¤—&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference"&gt;Inference&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#model-zoo"&gt;Model Zoo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#multi-turn-conversation"&gt;Multi-turn Conversation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-multiple-images"&gt;Chat with Multiple Images&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#in-context-few-shot-learning"&gt;In-context Few-shot Learning&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-video"&gt;Chat with Video&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#speech-and-audio-mode"&gt;Speech and Audio Mode&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#multimodal-live-streaming"&gt;Multimodal Live Streaming&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-on-multiple-gpus"&gt;Inference on Multiple GPUs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-on-mac"&gt;Inference on Mac&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#efficient-inference-with-llamacpp-ollama-vllm"&gt;Efficient Inference with llama.cpp, Ollama, vLLM&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#fine-tuning"&gt;Fine-tuning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#awesome-work-using-minicpm-v--minicpm-o"&gt;Awesome work using MiniCPM-V &amp;amp; MiniCPM-o&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#faqs"&gt;FAQs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#limitations"&gt;Limitations&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;MiniCPM-V 4.5&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;MiniCPM-V 4.5&lt;/strong&gt; is the latest and most capable model in the MiniCPM-V series. The model is built on Qwen3-8B and SigLIP2-400M with a total of 8B parameters. It exhibits a significant performance improvement over previous MiniCPM-V and MiniCPM-o models, and introduces new useful features. Notable features of MiniCPM-V 4.5 include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”¥ &lt;strong&gt;State-of-the-art Vision-Language Capability.&lt;/strong&gt; MiniCPM-V 4.5 achieves an average score of 77.0 on OpenCompass, a comprehensive evaluation of 8 popular benchmarks. &lt;strong&gt;With only 8B parameters, it surpasses widely used proprietary models like GPT-4o-latest, Gemini-2.0 Pro, and strong open-source models like Qwen2.5-VL 72B&lt;/strong&gt; for vision-language capabilities, making it the most performant MLLM under 30B parameters.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ¬ &lt;strong&gt;Efficient High-FPS and Long Video Understanding.&lt;/strong&gt; Powered by a new unified 3D-Resampler over images and videos, MiniCPM-V 4.5 can now achieve 96x compression rate for video tokens, where 6 448x448 video frames can be jointly compressed into 64 video tokens (normally 1,536 tokens for most MLLMs). This means that the model can perceive significantly more video frames without increasing the LLM inference cost. This brings state-of-the-art high-FPS (up to 10FPS) video understanding and long video understanding capabilities on Video-MME, LVBench, MLVU, MotionBench, FavorBench, etc., efficiently.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;âš™ï¸ &lt;strong&gt;Controllable Hybrid Fast/Deep Thinking.&lt;/strong&gt; MiniCPM-V 4.5 supports both fast thinking for efficient frequent usage with competitive performance, and deep thinking for more complex problem solving. To cover efficiency and performance trade-offs in different user scenarios, this fast/deep thinking mode can be switched in a highly controlled fashion.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’ª &lt;strong&gt;Strong OCR, Document Parsing and Others.&lt;/strong&gt; Based on &lt;a href="https://arxiv.org/pdf/2403.11703"&gt;LLaVA-UHD&lt;/a&gt; architecture, MiniCPM-V 4.5 can process high-resolution images with any aspect ratio and up to 1.8 million pixels (e.g., 1344x1344), using 4x fewer visual tokens than most MLLMs. The model achieves &lt;strong&gt;leading performance on OCRBench, surpassing proprietary models such as GPT-4o-latest and Gemini 2.5&lt;/strong&gt;. It also achieves state-of-the-art performance for PDF document parsing capability on OmniDocBench among general MLLMs. Based on the latest &lt;a href="https://github.com/RLHF-V/RLAIF-V/"&gt;RLAIF-V&lt;/a&gt; and &lt;a href="https://github.com/OpenBMB/VisCPM"&gt;VisCPM&lt;/a&gt; techniques, it features &lt;strong&gt;trustworthy behaviors&lt;/strong&gt;, outperforming GPT-4o-latest on MMHal-Bench, and supports &lt;strong&gt;multilingual capabilities&lt;/strong&gt; in more than 30 languages.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’« &lt;strong&gt;Easy Usage.&lt;/strong&gt; MiniCPM-V 4.5 can be easily used in various ways: (1) &lt;a href="https://github.com/tc-mb/llama.cpp/raw/Support-MiniCPM-V-4.5/docs/multimodal/minicpmv4.5.md"&gt;llama.cpp&lt;/a&gt; and &lt;a href="https://github.com/tc-mb/ollama/tree/MIniCPM-V"&gt;ollama&lt;/a&gt; support for efficient CPU inference on local devices, (2) &lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-int4"&gt;int4&lt;/a&gt;, &lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-gguf"&gt;GGUF&lt;/a&gt; and &lt;a href="https://github.com/tc-mb/AutoAWQ"&gt;AWQ&lt;/a&gt; format quantized models in 16 sizes, (3) &lt;a href="https://github.com/tc-mb/sglang/tree/main"&gt;SGLang&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#efficient-inference-with-llamacpp-ollama-vllm"&gt;vLLM&lt;/a&gt; support for high-throughput and memory-efficient inference, (4) fine-tuning on new domains and tasks with &lt;a href="https://github.com/tc-mb/transformers/tree/main"&gt;Transformers&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/llamafactory_train_and_infer.md"&gt;LLaMA-Factory&lt;/a&gt;, (5) quick &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-our-demo-on-gradio"&gt;local WebUI demo&lt;/a&gt;, (6) optimized &lt;a href="https://github.com/tc-mb/MiniCPM-o-demo-iOS"&gt;local iOS app&lt;/a&gt; on iPhone and iPad, and (7) online web demo on &lt;a href="http://101.126.42.235:30910/"&gt;server&lt;/a&gt;. See our &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook"&gt;Cookbook&lt;/a&gt; for full usage!&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Techniques 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpm-v-4dot5-framework.png" , width="100%" /&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Architechture: Unified 3D-Resampler for High-density Video Compression.&lt;/strong&gt; MiniCPM-V 4.5 introduces a 3D-Resampler that overcomes the performance-efficiency trade-off in video understanding. By grouping and jointly compressing up to 6 consecutive video frames into just 64 tokens (the same token count used for a single image in MiniCPM-V series), MiniCPM-V 4.5 achieves a 96Ã— compression rate for video tokens. This allows the model to process more video frames without additional LLM computational cost, enabling high-FPS video and long video understanding. The architecture supports unified encoding for images, multi-image inputs, and videos, ensuring seamless capability and knowledge transfer.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pre-training: Unified Learning for OCR and Knowledge from Documents.&lt;/strong&gt; Existing MLLMs learn OCR capability and knowledge from documents in isolated training approaches. We observe that the essential difference between these two training approaches is the visibility of the text in images. By dynamically corrupting text regions in documents with varying noise levels and asking the model to reconstruct the text, the model learns to adaptively and properly switch between accurate text recognition (when text is visible) and multimodal context-based knowledge reasoning (when text is heavily obscured). This eliminates reliance on error-prone document parsers in knowledge learning from documents, and prevents hallucinations from over-augmented OCR data, resulting in top-tier OCR and multimodal knowledge performance with minimal engineering overhead.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Post-training: Hybrid Fast/Deep Thinking with Multimodal RL.&lt;/strong&gt; MiniCPM-V 4.5 offers a balanced reasoning experience through two switchable modes: fast thinking for efficient daily use and deep thinking for complex tasks. Using a new hybrid reinforcement learning method, the model jointly optimizes both modes, significantly enhancing fast-mode performance without compromising deep-mode capability. Incorporated with &lt;a href="https://github.com/OpenBMB/RLPR"&gt;RLPR&lt;/a&gt; and &lt;a href="https://github.com/RLHF-V/RLAIF-V"&gt;RLAIF-V&lt;/a&gt;, it generalizes robust reasoning skills from broad multimodal data while effectively reducing hallucinations.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Evaluation 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/radar_minicpm_v45.png" , width="60%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv_4_5_evaluation_result.png" , width="80%" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Inference Efficiency&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;OpenCompass&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="left"&gt; 
 &lt;table style="margin: 0px auto;"&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Model&lt;/th&gt; 
    &lt;th&gt;Size&lt;/th&gt; 
    &lt;th&gt;Avg Score â†‘&lt;/th&gt; 
    &lt;th&gt;Total Inference Time â†“&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody align="center"&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;GLM-4.1V-9B-Thinking&lt;/td&gt; 
    &lt;td&gt;10.3B&lt;/td&gt; 
    &lt;td&gt;76.6&lt;/td&gt; 
    &lt;td&gt;17.5h&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiMo-VL-7B-RL&lt;/td&gt; 
    &lt;td&gt;8.3B&lt;/td&gt; 
    &lt;td&gt;76.4&lt;/td&gt; 
    &lt;td&gt;11h&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiniCPM-V 4.5&lt;/td&gt; 
    &lt;td&gt;8.7B&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;77.0&lt;/b&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;7.5h&lt;/b&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Video-MME&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="left"&gt; 
 &lt;table style="margin: 0px auto;"&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Model&lt;/th&gt; 
    &lt;th&gt;Size&lt;/th&gt; 
    &lt;th&gt;Avg Score â†‘&lt;/th&gt; 
    &lt;th&gt;Total Inference Time â†“&lt;/th&gt; 
    &lt;th&gt;GPU Mem â†“&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody align="center"&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;Qwen2.5-VL-7B-Instruct&lt;/td&gt; 
    &lt;td&gt;8.3B&lt;/td&gt; 
    &lt;td&gt;71.6&lt;/td&gt; 
    &lt;td&gt;3h&lt;/td&gt; 
    &lt;td&gt;60G&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;GLM-4.1V-9B-Thinking&lt;/td&gt; 
    &lt;td&gt;10.3B&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;73.6&lt;/b&gt;&lt;/td&gt; 
    &lt;td&gt;2.63h&lt;/td&gt; 
    &lt;td&gt;32G&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiniCPM-V 4.5&lt;/td&gt; 
    &lt;td&gt;8.7B&lt;/td&gt; 
    &lt;td&gt;73.5&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;0.26h&lt;/b&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;28G&lt;/b&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;Both Video-MME and OpenCompass were evaluated using 8Ã—A100 GPUs for inference. The reported inference time of Video-MME includes full model-side computation, and excludes the external cost of video frame extraction (dependent on specific frame extraction tools) for fair comparison.&lt;/p&gt; 
&lt;h3&gt;Examples 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.youtube.com/watch?v=Cn23FujYMMU"&gt;&lt;img src="./assets/minicpmv4_5/MiniCPM-V 4.5-8.26_img.jpeg" , width="70%" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;div style="display: flex; flex-direction: column; align-items: center;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/en_case1.png" alt="en_case1" style="margin-bottom: 5px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/en_case2.png" alt="en_case2" style="margin-bottom: 5px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/en_case3.jpeg" alt="en_case3" style="margin-bottom: 5px;" /&gt; 
&lt;/div&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view more cases.&lt;/summary&gt; 
 &lt;div style="display: flex; flex-direction: column; align-items: center;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/zh_extra.jpeg" alt="zh_extra" style="margin-bottom: 5px;" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;p&gt;We deploy MiniCPM-V 4.5 on iPad M4 with &lt;a href="https://github.com/tc-mb/MiniCPM-o-demo-iOS"&gt;iOS demo&lt;/a&gt;. The demo video is the raw screen recording without edition.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/v45_en_handwriting.gif" width="45%/" /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/v45_en_cot.gif" width="45%/" /&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/v45_cn_handwriting.gif" width="45%/" /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/v45_cn_travel.gif" width="45%/" /&gt; &lt;/p&gt;
&lt;table align="center"&gt;   
&lt;/table&gt; 
&lt;h2&gt;MiniCPM-o 2.6&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;MiniCPM-o 2.6&lt;/strong&gt; is the latest and most capable model in the MiniCPM-o series. The model is built in an end-to-end fashion based on SigLip-400M, Whisper-medium-300M, ChatTTS-200M, and Qwen2.5-7B with a total of 8B parameters. It exhibits a significant performance improvement over MiniCPM-V 2.6, and introduces new features for real-time speech conversation and multimodal live streaming. Notable features of MiniCPM-o 2.6 include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”¥ &lt;strong&gt;Leading Visual Capability.&lt;/strong&gt; MiniCPM-o 2.6 achieves an average score of 70.2 on OpenCompass, a comprehensive evaluation of 8 popular benchmarks. &lt;strong&gt;With only 8B parameters, it surpasses widely used proprietary models like GPT-4o-202405, Gemini 1.5 Pro, and Claude 3.5 Sonnet&lt;/strong&gt; for single image understanding. It also &lt;strong&gt;outperforms GPT-4V and Claude 3.5 Sonnet&lt;/strong&gt; in multi-image and video understanding, and shows promising in-context learning capability.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ™ &lt;strong&gt;State-of-the-art Speech Capability.&lt;/strong&gt; MiniCPM-o 2.6 supports &lt;strong&gt;bilingual real-time speech conversation with configurable voices&lt;/strong&gt; in English and Chinese. It &lt;strong&gt;outperforms GPT-4o-realtime on audio understanding tasks&lt;/strong&gt; such as ASR and STT translation, and shows &lt;strong&gt;state-of-the-art performance on speech conversation in both semantic and acoustic evaluations in the open-source community&lt;/strong&gt;. It also allows for fun features such as emotion/speed/style control, end-to-end voice cloning, role play, etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ¬ &lt;strong&gt;Strong Multimodal Live Streaming Capability.&lt;/strong&gt; As a new feature, MiniCPM-o 2.6 can &lt;strong&gt;accept continuous video and audio streams independent of user queries, and support real-time speech interaction&lt;/strong&gt;. It &lt;strong&gt;outperforms GPT-4o-202408 and Claude 3.5 Sonnet and shows state-of-the-art performance in the open-source community on StreamingBench&lt;/strong&gt;, a comprehensive benchmark for real-time video understanding, omni-source (video &amp;amp; audio) understanding, and multimodal contextual understanding.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’ª &lt;strong&gt;Strong OCR Capability and Others.&lt;/strong&gt; Advancing popular visual capabilities from MiniCPM-V series, MiniCPM-o 2.6 can process images with any aspect ratio and up to 1.8 million pixels (e.g., 1344x1344). It achieves &lt;strong&gt;state-of-the-art performance on OCRBench for models under 25B, surpassing proprietary models such as GPT-4o-202405&lt;/strong&gt;. Based on the latest &lt;a href="https://github.com/RLHF-V/RLAIF-V/"&gt;RLAIF-V&lt;/a&gt; and &lt;a href="https://github.com/OpenBMB/VisCPM"&gt;VisCPM&lt;/a&gt; techniques, it features &lt;strong&gt;trustworthy behaviors&lt;/strong&gt;, outperforming GPT-4o and Claude 3.5 Sonnet on MMHal-Bench, and supports &lt;strong&gt;multilingual capabilities&lt;/strong&gt; on more than 30 languages.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸš€ &lt;strong&gt;Superior Efficiency.&lt;/strong&gt; In addition to its friendly size, MiniCPM-o 2.6 also shows &lt;strong&gt;state-of-the-art token density&lt;/strong&gt; (i.e., the number of pixels encoded into each visual token). &lt;strong&gt;It produces only 640 tokens when processing a 1.8M pixel image, which is 75% fewer than most models&lt;/strong&gt;. This directly improves the inference speed, first-token latency, memory usage, and power consumption. As a result, MiniCPM-o 2.6 can efficiently support &lt;strong&gt;multimodal live streaming&lt;/strong&gt; on end-side devices such as iPads.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’« &lt;strong&gt;Easy Usage.&lt;/strong&gt; MiniCPM-o 2.6 can be easily used in various ways: (1) &lt;a href="https://github.com/OpenBMB/llama.cpp/raw/minicpm-omni/examples/llava/README-minicpmo2.6.md"&gt;llama.cpp&lt;/a&gt; support for efficient CPU inference on local devices, (2) &lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-int4"&gt;int4&lt;/a&gt; and &lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-gguf"&gt;GGUF&lt;/a&gt; format quantized models in 16 sizes, (3) &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#efficient-inference-with-llamacpp-ollama-vllm"&gt;vLLM&lt;/a&gt; support for high-throughput and memory-efficient inference, (4) fine-tuning on new domains and tasks with &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/llamafactory_train_and_infer.md"&gt;LLaMA-Factory&lt;/a&gt;, (5) quick &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-our-demo-on-gradio"&gt;local WebUI demo&lt;/a&gt;, and (6) online web demo on &lt;a href="https://minicpm-omni-webdemo-us.modelbest.cn/"&gt;server&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Model Architecture.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end Omni-modal Architecture.&lt;/strong&gt; Different modality encoders/decoders are connected and trained in an &lt;strong&gt;end-to-end&lt;/strong&gt; fashion to fully exploit rich multimodal knowledge. The model is trained in a fully end-to-end manner with only CE loss.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Omni-modal Live Streaming Mechanism.&lt;/strong&gt; (1) We change the offline modality encoder/decoders into online ones for &lt;strong&gt;streaming inputs/outputs.&lt;/strong&gt; (2) We devise a &lt;strong&gt;time-division multiplexing (TDM) mechanism&lt;/strong&gt; for omni-modality streaming processing in the LLM backbone. It divides parallel omni-modality streams into sequential info within small periodic time slices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Speech Modeling Design.&lt;/strong&gt; We devise a multimodal system prompt, including traditional text system prompt, and &lt;strong&gt;a new audio system prompt to determine the assistant voice&lt;/strong&gt;. This enables flexible voice configurations in inference time, and also facilitates end-to-end voice cloning and description-based voice creation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpm-o-26-framework-v2.png" , width="80%" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Evaluation 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/radar.jpg" , width="80%" /&gt; 
&lt;/div&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view visual understanding results.&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Image Understanding&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Model&lt;/th&gt; 
     &lt;th&gt;Size&lt;/th&gt; 
     &lt;th&gt;Token Density&lt;sup&gt;+&lt;/sup&gt;&lt;/th&gt; 
     &lt;th&gt;OpenCompass&lt;/th&gt; 
     &lt;th&gt;OCRBench&lt;/th&gt; 
     &lt;th&gt;MathVista mini&lt;/th&gt; 
     &lt;th&gt;ChartQA&lt;/th&gt; 
     &lt;th&gt;MMVet&lt;/th&gt; 
     &lt;th&gt;MMStar&lt;/th&gt; 
     &lt;th&gt;MME&lt;/th&gt; 
     &lt;th&gt;MMB1.1 test&lt;/th&gt; 
     &lt;th&gt;AI2D&lt;/th&gt; 
     &lt;th&gt;MMMU val&lt;/th&gt; 
     &lt;th&gt;HallusionBench&lt;/th&gt; 
     &lt;th&gt;TextVQA val&lt;/th&gt; 
     &lt;th&gt;DocVQA test&lt;/th&gt; 
     &lt;th&gt;MathVerse mini&lt;/th&gt; 
     &lt;th&gt;MathVision&lt;/th&gt; 
     &lt;th&gt;MMHal Score&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td colspan="19" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-20240513&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;1088&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;69.9&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;736&lt;/td&gt; 
     &lt;td&gt;61.3&lt;/td&gt; 
     &lt;td&gt;85.7&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;69.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;63.9&lt;/td&gt; 
     &lt;td&gt;2328.7&lt;/td&gt; 
     &lt;td&gt;82.2&lt;/td&gt; 
     &lt;td&gt;84.6&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;69.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;55.0&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;92.8&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;50.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;30.4&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;3.6&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Claude3.5-Sonnet&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;750&lt;/td&gt; 
     &lt;td&gt;67.9&lt;/td&gt; 
     &lt;td&gt;788&lt;/td&gt; 
     &lt;td&gt;61.6&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;90.8&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;66.0&lt;/td&gt; 
     &lt;td&gt;62.2&lt;/td&gt; 
     &lt;td&gt;1920.0&lt;/td&gt; 
     &lt;td&gt;78.5&lt;/td&gt; 
     &lt;td&gt;80.2&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;65.9&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;49.9&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;95.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;3.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Gemini 1.5 Pro&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;64.4&lt;/td&gt; 
     &lt;td&gt;754&lt;/td&gt; 
     &lt;td&gt;57.7&lt;/td&gt; 
     &lt;td&gt;81.3&lt;/td&gt; 
     &lt;td&gt;64.0&lt;/td&gt; 
     &lt;td&gt;59.1&lt;/td&gt; 
     &lt;td&gt;2110.6&lt;/td&gt; 
     &lt;td&gt;73.9&lt;/td&gt; 
     &lt;td&gt;79.1&lt;/td&gt; 
     &lt;td&gt;60.6&lt;/td&gt; 
     &lt;td&gt;45.6&lt;/td&gt; 
     &lt;td&gt;73.5&lt;/td&gt; 
     &lt;td&gt;86.5&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;19.2&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-mini-20240718&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;1088&lt;/td&gt; 
     &lt;td&gt;64.1&lt;/td&gt; 
     &lt;td&gt;785&lt;/td&gt; 
     &lt;td&gt;52.4&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;66.9&lt;/td&gt; 
     &lt;td&gt;54.8&lt;/td&gt; 
     &lt;td&gt;2003.4&lt;/td&gt; 
     &lt;td&gt;76.0&lt;/td&gt; 
     &lt;td&gt;77.8&lt;/td&gt; 
     &lt;td&gt;60.0&lt;/td&gt; 
     &lt;td&gt;46.1&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;3.3&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td colspan="19" align="left"&gt;&lt;strong&gt;Open Source&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Cambrian-34B&lt;/td&gt; 
     &lt;td&gt;34B&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1820&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;58.3&lt;/td&gt; 
     &lt;td&gt;591&lt;/td&gt; 
     &lt;td&gt;50.3&lt;/td&gt; 
     &lt;td&gt;75.6&lt;/td&gt; 
     &lt;td&gt;53.2&lt;/td&gt; 
     &lt;td&gt;54.2&lt;/td&gt; 
     &lt;td&gt;2049.9&lt;/td&gt; 
     &lt;td&gt;77.8&lt;/td&gt; 
     &lt;td&gt;79.5&lt;/td&gt; 
     &lt;td&gt;50.4&lt;/td&gt; 
     &lt;td&gt;41.6&lt;/td&gt; 
     &lt;td&gt;76.7&lt;/td&gt; 
     &lt;td&gt;75.5&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GLM-4V-9B&lt;/td&gt; 
     &lt;td&gt;13B&lt;/td&gt; 
     &lt;td&gt;784&lt;/td&gt; 
     &lt;td&gt;59.1&lt;/td&gt; 
     &lt;td&gt;776&lt;/td&gt; 
     &lt;td&gt;51.1&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;58.0&lt;/td&gt; 
     &lt;td&gt;54.8&lt;/td&gt; 
     &lt;td&gt;2018.8&lt;/td&gt; 
     &lt;td&gt;67.9&lt;/td&gt; 
     &lt;td&gt;71.2&lt;/td&gt; 
     &lt;td&gt;46.9&lt;/td&gt; 
     &lt;td&gt;45.0&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Pixtral-12B&lt;/td&gt; 
     &lt;td&gt;12B&lt;/td&gt; 
     &lt;td&gt;256&lt;/td&gt; 
     &lt;td&gt;61.0&lt;/td&gt; 
     &lt;td&gt;685&lt;/td&gt; 
     &lt;td&gt;56.9&lt;/td&gt; 
     &lt;td&gt;81.8&lt;/td&gt; 
     &lt;td&gt;58.5&lt;/td&gt; 
     &lt;td&gt;54.5&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;72.7&lt;/td&gt; 
     &lt;td&gt;79.0&lt;/td&gt; 
     &lt;td&gt;51.1&lt;/td&gt; 
     &lt;td&gt;47.0&lt;/td&gt; 
     &lt;td&gt;75.7&lt;/td&gt; 
     &lt;td&gt;90.7&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;784&lt;/td&gt; 
     &lt;td&gt;63.3&lt;/td&gt; 
     &lt;td&gt;741&lt;/td&gt; 
     &lt;td&gt;66.2&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;52.7&lt;/td&gt; 
     &lt;td&gt;60.2&lt;/td&gt; 
     &lt;td&gt;2328.1&lt;/td&gt; 
     &lt;td&gt;76.8&lt;/td&gt; 
     &lt;td&gt;79.2&lt;/td&gt; 
     &lt;td&gt;52.6&lt;/td&gt; 
     &lt;td&gt;44.6&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;DeepSeek-VL2-27B (4B)&lt;/td&gt; 
     &lt;td&gt;27B&lt;/td&gt; 
     &lt;td&gt;672&lt;/td&gt; 
     &lt;td&gt;66.4&lt;/td&gt; 
     &lt;td&gt;809&lt;/td&gt; 
     &lt;td&gt;63.9&lt;/td&gt; 
     &lt;td&gt;86.0&lt;/td&gt; 
     &lt;td&gt;60.0&lt;/td&gt; 
     &lt;td&gt;61.9&lt;/td&gt; 
     &lt;td&gt;2253.0&lt;/td&gt; 
     &lt;td&gt;81.2&lt;/td&gt; 
     &lt;td&gt;83.8&lt;/td&gt; 
     &lt;td&gt;54.0&lt;/td&gt; 
     &lt;td&gt;45.3&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;84.2&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;93.3&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;3.0&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Qwen2-VL-7B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;784&lt;/td&gt; 
     &lt;td&gt;67.1&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;866&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;58.2&lt;/td&gt; 
     &lt;td&gt;83.0&lt;/td&gt; 
     &lt;td&gt;62.0&lt;/td&gt; 
     &lt;td&gt;60.7&lt;/td&gt; 
     &lt;td&gt;2326.0&lt;/td&gt; 
     &lt;td&gt;81.8&lt;/td&gt; 
     &lt;td&gt;83.0&lt;/td&gt; 
     &lt;td&gt;54.1&lt;/td&gt; 
     &lt;td&gt;50.6&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;84.3&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;94.5&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;31.9&lt;/td&gt; 
     &lt;td&gt;16.3&lt;/td&gt; 
     &lt;td&gt;3.2&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;LLaVA-OneVision-72B&lt;/td&gt; 
     &lt;td&gt;72B&lt;/td&gt; 
     &lt;td&gt;182&lt;/td&gt; 
     &lt;td&gt;68.1&lt;/td&gt; 
     &lt;td&gt;741&lt;/td&gt; 
     &lt;td&gt;67.5&lt;/td&gt; 
     &lt;td&gt;83.7&lt;/td&gt; 
     &lt;td&gt;60.6&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;65.8&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;2261.0&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;85.0&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;85.6&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;56.8&lt;/td&gt; 
     &lt;td&gt;49.0&lt;/td&gt; 
     &lt;td&gt;80.5&lt;/td&gt; 
     &lt;td&gt;91.3&lt;/td&gt; 
     &lt;td&gt;39.1&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;3.5&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;InternVL2.5-8B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;706&lt;/td&gt; 
     &lt;td&gt;68.3&lt;/td&gt; 
     &lt;td&gt;822&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;64.4&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;84.8&lt;/td&gt; 
     &lt;td&gt;62.8&lt;/td&gt; 
     &lt;td&gt;62.8&lt;/td&gt; 
     &lt;td&gt;2344.0&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;83.6&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;84.5&lt;/td&gt; 
     &lt;td&gt;56.0&lt;/td&gt; 
     &lt;td&gt;50.1&lt;/td&gt; 
     &lt;td&gt;79.1&lt;/td&gt; 
     &lt;td&gt;93.0&lt;/td&gt; 
     &lt;td&gt;39.5&lt;/td&gt; 
     &lt;td&gt;19.7&lt;/td&gt; 
     &lt;td&gt;3.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-V 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;2822&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;65.2&lt;/td&gt; 
     &lt;td&gt;852*&lt;/td&gt; 
     &lt;td&gt;60.6&lt;/td&gt; 
     &lt;td&gt;79.4&lt;/td&gt; 
     &lt;td&gt;60.0&lt;/td&gt; 
     &lt;td&gt;57.5&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;2348.4*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;78.0&lt;/td&gt; 
     &lt;td&gt;82.1&lt;/td&gt; 
     &lt;td&gt;49.8*&lt;/td&gt; 
     &lt;td&gt;48.1*&lt;/td&gt; 
     &lt;td&gt;80.1&lt;/td&gt; 
     &lt;td&gt;90.8&lt;/td&gt; 
     &lt;td&gt;25.7&lt;/td&gt; 
     &lt;td&gt;18.3&lt;/td&gt; 
     &lt;td&gt;3.6&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;2822&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;70.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;897*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;71.9*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;86.9*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;67.5&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;64.0&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;2372.0*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;80.5&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;85.8&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;50.4*&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;51.9&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;82.0&lt;/td&gt; 
     &lt;td&gt;93.5&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;41.4*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;23.1*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;3.8&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; * We evaluate this benchmark using chain-of-thought prompting. Specifically, for MME, we used this technique only for the Cognition set. 
 &lt;p&gt;&lt;sup&gt;+&lt;/sup&gt; Token Density: number of pixels encoded into each visual token at maximum resolution, i.e., # pixels at maximum resolution / # visual tokens.&lt;/p&gt; 
 &lt;p&gt;Note: For proprietary models, we calculate token density based on the image encoding charging strategy defined in the official API documentation, which provides an upper-bound estimation.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Multi-image and Video Understanding&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Model&lt;/th&gt; 
     &lt;th&gt;Size&lt;/th&gt; 
     &lt;th&gt;BLINK val&lt;/th&gt; 
     &lt;th&gt;Mantis Eval&lt;/th&gt; 
     &lt;th&gt;MIRB&lt;/th&gt; 
     &lt;th&gt;Video-MME (wo / w subs)&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td colspan="6" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-20240513&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;68.0&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;71.9/77.2&lt;strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT4V&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;54.6&lt;/td&gt; 
     &lt;td&gt;62.7&lt;/td&gt; 
     &lt;td&gt;53.1&lt;/td&gt; 
     &lt;td&gt;59.9/63.3&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td colspan="6" align="left"&gt;&lt;strong&gt;Open-source&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;45.0&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;56.1/58.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;LLaVA-NeXT-Interleave 14B&lt;/td&gt; 
     &lt;td&gt;14B&lt;/td&gt; 
     &lt;td&gt;52.6&lt;/td&gt; 
     &lt;td&gt;66.4&lt;/td&gt; 
     &lt;td&gt;30.2&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;LLaVA-OneVision-72B&lt;/td&gt; 
     &lt;td&gt;72B&lt;/td&gt; 
     &lt;td&gt;55.4&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;77.6&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;66.2/69.5&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MANTIS 8B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;49.1&lt;/td&gt; 
     &lt;td&gt;59.5&lt;/td&gt; 
     &lt;td&gt;34.8&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Qwen2-VL-7B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;53.2&lt;/td&gt; 
     &lt;td&gt;69.6*&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;67.6*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;63.3/69.0&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;InternVL2.5-8B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;54.8&lt;/td&gt; 
     &lt;td&gt;67.7&lt;/td&gt; 
     &lt;td&gt;52.5&lt;/td&gt; 
     &lt;td&gt;64.2/66.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-V 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;53.0&lt;/td&gt; 
     &lt;td&gt;69.1&lt;/td&gt; 
     &lt;td&gt;53.8&lt;/td&gt; 
     &lt;td&gt;60.9/63.6&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;56.7&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;71.9&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;58.6&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;63.9/67.9&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; * We evaluate officially released checkpoints by ourselves. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view audio understanding and speech conversation results.&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Audio Understanding&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Task&lt;/th&gt; 
     &lt;th&gt;Size&lt;/th&gt; 
     &lt;th colspan="3"&gt;ASR (zh)&lt;/th&gt; 
     &lt;th colspan="3"&gt;ASR (en)&lt;/th&gt; 
     &lt;th colspan="2"&gt;AST&lt;/th&gt; 
     &lt;th&gt;Emotion&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Metric&lt;/th&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;th colspan="3"&gt;CERâ†“&lt;/th&gt; 
     &lt;th colspan="3"&gt;WERâ†“&lt;/th&gt; 
     &lt;th colspan="2"&gt;BLEUâ†‘&lt;/th&gt; 
     &lt;th&gt;ACCâ†‘&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Dataset&lt;/th&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;th&gt;AISHELL-1&lt;/th&gt; 
     &lt;th&gt;Fleurs zh&lt;/th&gt; 
     &lt;th&gt;WenetSpeech test-net&lt;/th&gt; 
     &lt;th&gt;LibriSpeech test-clean&lt;/th&gt; 
     &lt;th&gt;GigaSpeech&lt;/th&gt; 
     &lt;th&gt;TED-LIUM&lt;/th&gt; 
     &lt;th&gt;CoVoST en2zh&lt;/th&gt; 
     &lt;th&gt;CoVoST zh2en&lt;/th&gt; 
     &lt;th&gt;MELD emotion&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td colspan="11" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-Realtime&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;7.3*&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;5.4*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;28.9*&lt;/td&gt; 
     &lt;td&gt;2.6*&lt;/td&gt; 
     &lt;td&gt;12.9*&lt;/td&gt; 
     &lt;td&gt;4.8*&lt;/td&gt; 
     &lt;td&gt;37.1*&lt;/td&gt; 
     &lt;td&gt;15.7*&lt;/td&gt; 
     &lt;td&gt;33.2*&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Gemini 1.5 Pro&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;4.5*&lt;/td&gt; 
     &lt;td&gt;5.9*&lt;/td&gt; 
     &lt;td&gt;14.3*&lt;/td&gt; 
     &lt;td&gt;2.9*&lt;/td&gt; 
     &lt;td&gt;10.6*&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;3.0*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;47.3*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;22.6*&lt;/td&gt; 
     &lt;td&gt;48.4*&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td colspan="11" align="left"&gt;&lt;strong&gt;Open-Source&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Qwen2-Audio-7B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;7.5&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1.6&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;45.2&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;24.4&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;55.3&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Qwen2-Audio-7B-Instruct&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;2.6*&lt;/td&gt; 
     &lt;td&gt;6.9*&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;10.3*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;3.1*&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;9.7&lt;/u&gt;*&lt;/td&gt; 
     &lt;td&gt;5.9*&lt;/td&gt; 
     &lt;td&gt;39.5*&lt;/td&gt; 
     &lt;td&gt;22.9*&lt;/td&gt; 
     &lt;td&gt;17.4*&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;2.16&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;8.4&lt;/td&gt; 
     &lt;td&gt;3.4&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GLM-4-Voice-Base&lt;/td&gt; 
     &lt;td&gt;9B&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;2.5&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;2.8&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1.6&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;4.4&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;6.9&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1.7&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;8.7&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;3.0&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;48.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;27.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;52.4&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; * We evaluate officially released checkpoints by ourselves.
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Speech Generation&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Task&lt;/th&gt; 
     &lt;th&gt;Size&lt;/th&gt; 
     &lt;th colspan="9"&gt;SpeechQA&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Metric&lt;/th&gt; 
     &lt;th&gt;&lt;/th&gt; 
     &lt;th colspan="3"&gt;ACCâ†‘&lt;/th&gt; 
     &lt;th&gt;G-Eval (10 point)â†‘&lt;/th&gt; 
     &lt;th&gt;Semantic ELO scoreâ†‘&lt;/th&gt; 
     &lt;th&gt;Acoustic ELO scoreâ†‘&lt;/th&gt; 
     &lt;th&gt;Overall ELO scoreâ†‘&lt;/th&gt; 
     &lt;th&gt;UTMOSâ†‘&lt;/th&gt; 
     &lt;th&gt;ASR-WERâ†“&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Dataset&lt;/th&gt; 
     &lt;th&gt;&lt;/th&gt; 
     &lt;th&gt;Speech Llama Q.&lt;/th&gt; 
     &lt;th&gt;Speech Web Q.&lt;/th&gt; 
     &lt;th&gt;Speech Trivia QA&lt;/th&gt; 
     &lt;th&gt;Speech AlpacaEval&lt;/th&gt; 
     &lt;th colspan="5"&gt;AudioArena&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td colspan="11" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-Realtime&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;71.7&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;51.6&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;69.7&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;7.4&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1157&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1203&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1200&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;4.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;2.3&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td colspan="11" align="left"&gt;&lt;strong&gt;Open-Source&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GLM-4-Voice&lt;/td&gt; 
     &lt;td&gt;9B&lt;/td&gt; 
     &lt;td&gt;50.0&lt;/td&gt; 
     &lt;td&gt;32.0&lt;/td&gt; 
     &lt;td&gt;36.4&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;5.1&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;999&lt;/td&gt; 
     &lt;td&gt;1147&lt;/td&gt; 
     &lt;td&gt;1035&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;4.1&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;11.7&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Llama-Omni&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;45.3&lt;/td&gt; 
     &lt;td&gt;22.9&lt;/td&gt; 
     &lt;td&gt;10.7&lt;/td&gt; 
     &lt;td&gt;3.9&lt;/td&gt; 
     &lt;td&gt;960&lt;/td&gt; 
     &lt;td&gt;878&lt;/td&gt; 
     &lt;td&gt;897&lt;/td&gt; 
     &lt;td&gt;3.2&lt;/td&gt; 
     &lt;td&gt;24.3&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;46.7&lt;/td&gt; 
     &lt;td&gt;28.1&lt;/td&gt; 
     &lt;td&gt;23.3&lt;/td&gt; 
     &lt;td&gt;2.0&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Moshi&lt;/td&gt; 
     &lt;td&gt;7B&lt;/td&gt; 
     &lt;td&gt;43.7&lt;/td&gt; 
     &lt;td&gt;23.8&lt;/td&gt; 
     &lt;td&gt;16.7&lt;/td&gt; 
     &lt;td&gt;2.4&lt;/td&gt; 
     &lt;td&gt;871&lt;/td&gt; 
     &lt;td&gt;808&lt;/td&gt; 
     &lt;td&gt;875&lt;/td&gt; 
     &lt;td&gt;2.8&lt;/td&gt; 
     &lt;td&gt;8.2&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Mini-Omni&lt;/td&gt; 
     &lt;td&gt;1B&lt;/td&gt; 
     &lt;td&gt;22.0&lt;/td&gt; 
     &lt;td&gt;12.8&lt;/td&gt; 
     &lt;td&gt;6.9&lt;/td&gt; 
     &lt;td&gt;2.5&lt;/td&gt; 
     &lt;td&gt;926&lt;/td&gt; 
     &lt;td&gt;803&lt;/td&gt; 
     &lt;td&gt;865&lt;/td&gt; 
     &lt;td&gt;3.4&lt;/td&gt; 
     &lt;td&gt;10.0&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;61.0&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;40.0&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;40.2&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;5.1&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1088&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1163&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1131&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;4.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;9.8&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; All results are from AudioEvals, and the evaluation methods along with further details can be found in 
 &lt;a href="https://github.com/OpenBMB/UltraEval-Audio" target="_blank"&gt;AudioEvals&lt;/a&gt;.
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;End-to-end Voice Cloning&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Task&lt;/th&gt; 
     &lt;th colspan="2"&gt;Voice cloning&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Metric&lt;/th&gt; 
     &lt;th&gt;SIMOâ†‘&lt;/th&gt; 
     &lt;th&gt;SIMOâ†‘&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Dataset&lt;/th&gt; 
     &lt;th&gt;Seed-TTS test-zh&lt;/th&gt; 
     &lt;th&gt;Seed-TTS test-en&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;F5-TTS&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;76&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;67&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;CosyVoice&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;75&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;64&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;FireRedTTS&lt;/td&gt; 
     &lt;td&gt;63&lt;/td&gt; 
     &lt;td&gt;46&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;57&lt;/td&gt; 
     &lt;td&gt;47&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view multimodal live streaming results.&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Multimodal Live Streaming&lt;/strong&gt;: results on StreamingBench&lt;/p&gt; 
 &lt;table style="margin: 0px auto;"&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Model&lt;/th&gt; 
    &lt;th&gt;Size&lt;/th&gt; 
    &lt;th&gt;Real-Time Video Understanding&lt;/th&gt; 
    &lt;th&gt;Omni-Source Understanding&lt;/th&gt; 
    &lt;th&gt;Contextual Understanding&lt;/th&gt; 
    &lt;th&gt;Overall&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody align="center"&gt; 
   &lt;tr&gt; 
    &lt;td colspan="7" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;Gemini 1.5 Pro&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;&lt;u&gt;77.4&lt;/u&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;67.8&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;51.1&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;70.3&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;GPT-4o-202408&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;74.5&lt;/td&gt; 
    &lt;td&gt;51.0&lt;/td&gt; 
    &lt;td&gt;&lt;u&gt;48.0&lt;/u&gt;&lt;/td&gt; 
    &lt;td&gt;64.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;Claude-3.5-Sonnet&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;74.0&lt;/td&gt; 
    &lt;td&gt;41.4&lt;/td&gt; 
    &lt;td&gt;37.8&lt;/td&gt; 
    &lt;td&gt;59.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="9" align="left"&gt;&lt;strong&gt;Open-source&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;VILA-1.5&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;61.5&lt;/td&gt; 
    &lt;td&gt;37.5&lt;/td&gt; 
    &lt;td&gt;26.7&lt;/td&gt; 
    &lt;td&gt;49.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;LongVA&lt;/td&gt; 
    &lt;td&gt;7B&lt;/td&gt; 
    &lt;td&gt;63.1&lt;/td&gt; 
    &lt;td&gt;35.9&lt;/td&gt; 
    &lt;td&gt;30.2&lt;/td&gt; 
    &lt;td&gt;50.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;LLaVA-Next-Video-34B&lt;/td&gt; 
    &lt;td&gt;34B&lt;/td&gt; 
    &lt;td&gt;69.8&lt;/td&gt; 
    &lt;td&gt;41.7&lt;/td&gt; 
    &lt;td&gt;34.3&lt;/td&gt; 
    &lt;td&gt;56.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;Qwen2-VL-7B&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;71.2&lt;/td&gt; 
    &lt;td&gt;40.7&lt;/td&gt; 
    &lt;td&gt;33.1&lt;/td&gt; 
    &lt;td&gt;57.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;InternVL2-8B&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;70.1&lt;/td&gt; 
    &lt;td&gt;42.7&lt;/td&gt; 
    &lt;td&gt;34.1&lt;/td&gt; 
    &lt;td&gt;57.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;70.9&lt;/td&gt; 
    &lt;td&gt;40.8&lt;/td&gt; 
    &lt;td&gt;35.8&lt;/td&gt; 
    &lt;td&gt;57.4&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;LLaVA-OneVision-7B&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;74.3&lt;/td&gt; 
    &lt;td&gt;40.8&lt;/td&gt; 
    &lt;td&gt;31.0&lt;/td&gt; 
    &lt;td&gt;58.4&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;InternLM-XC2.5-OL-7B&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;75.4&lt;/td&gt; 
    &lt;td&gt;46.2&lt;/td&gt; 
    &lt;td&gt;33.6&lt;/td&gt; 
    &lt;td&gt;60.8&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiniCPM-V 2.6&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;72.4&lt;/td&gt; 
    &lt;td&gt;40.2&lt;/td&gt; 
    &lt;td&gt;33.4&lt;/td&gt; 
    &lt;td&gt;57.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;79.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;u&gt;53.4&lt;/u&gt;&lt;/td&gt; 
    &lt;td&gt;38.5&lt;/td&gt; 
    &lt;td&gt;&lt;u&gt;66.0&lt;/u&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;Examples 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We deploy MiniCPM-o 2.6 on end devices. The demo video is the raw-speed recording on an iPad Pro and a Web demo.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.youtube.com/watch?v=vRIMbxJzStY&amp;amp;t=2s"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/2dot6_o_demo_video_img.png" , width="70%" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div style="display: flex; flex-direction: column; align-items: center;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/minicpmo2_6_math_intersect.png" alt="math" style="margin-bottom: 5px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/minicpmo2_6_diagram_train_NN.png" alt="diagram" style="margin-bottom: 5px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/minicpmo2_6_multi-image_bike.png" alt="bike" style="margin-bottom: 5px;" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Legacy Models 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Introduction and Guidance&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.0&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_v4_en.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 2.6&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_v2dot6_en.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-Llama3-V 2.5&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_llama3_v2dot5.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 2.0&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_v2.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 1.0&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_v1.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;OmniLMM-12B&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/omnilmm_en.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;MiniCPM-V &amp;amp; o Cookbook&lt;/h2&gt; 
&lt;p&gt;Discover comprehensive, ready-to-deploy solutions for the MiniCPM-V and MiniCPM-o model series in our structured &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook"&gt;cookbook&lt;/a&gt;, which empowers developers to rapidly implement multimodal AI applications with integrated vision, speech, and live-streaming capabilities. Key features include:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Easy Usage Documentation&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our comprehensive &lt;a href="https://minicpm-o.readthedocs.io/en/latest/index.html"&gt;documentation website&lt;/a&gt; presents every recipe in a clear, well-organized manner. All features are displayed at a glance, making it easy for you to quickly find exactly what you need.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Broad User Spectrum&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We support a wide range of users, from individuals to enterprises and researchers.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Individuals&lt;/strong&gt;: Enjoy effortless inference using &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/ollama/minicpm-v4_ollama.md"&gt;Ollama&lt;/a&gt; and &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/llama.cpp/minicpm-v4_llamacpp.md"&gt;Llama.cpp&lt;/a&gt; with minimal setup.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprises&lt;/strong&gt;: Achieve high-throughput, scalable performance with &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/vllm/minicpm-v4_vllm.md"&gt;vLLM&lt;/a&gt; and &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/sglang/MiniCPM-v4_sglang.md"&gt;SGLang&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Researchers&lt;/strong&gt;: Leverage advanced frameworks including &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/finetune_full.md"&gt;Transformers&lt;/a&gt;, &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/finetune_llamafactory.md"&gt;LLaMA-Factory&lt;/a&gt;, &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/swift.md"&gt;SWIFT&lt;/a&gt;, and &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/align_anything.md"&gt;Align-anything&lt;/a&gt; to enable flexible model development and cutting-edge experimentation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Versatile Deployment Scenarios&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our ecosystem delivers optimal solution for a variety of hardware environments and deployment demands.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Web demo&lt;/strong&gt;: Launch interactive multimodal AI web demo with &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/README.md"&gt;FastAPI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quantized deployment&lt;/strong&gt;: Maximize efficiency and minimize resource consumption using &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/quantization/gguf/minicpm-v4_gguf_quantize.md"&gt;GGUF&lt;/a&gt; and &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/quantization/bnb/minicpm-v4_bnb_quantize.md"&gt;BNB&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;End devices&lt;/strong&gt;: Bring powerful AI experiences to &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/ios_demo/ios.md"&gt;iPhone and iPad&lt;/a&gt;, supporting offline and privacy-sensitive applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Chat with Our Demo on Gradio ğŸ¤—&lt;/h2&gt; 
&lt;p&gt;We provide online and local demos powered by Hugging Face Gradio &lt;a href="https://github.com/gradio-app/gradio"&gt;&lt;img src="https://img.shields.io/github/stars/gradio-app/gradio" /&gt;&lt;/a&gt;, the most popular model deployment framework nowadays. It supports streaming outputs, progress bars, queuing, alerts, and other useful features.&lt;/p&gt; 
&lt;h3&gt;Online Demo 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;Click here to try out the online demo of &lt;a href="https://minicpm-omni-webdemo-us.modelbest.cn/"&gt;MiniCPM-o 2.6&lt;/a&gt; | &lt;a href="http://120.92.209.146:8887/"&gt;MiniCPM-V 2.6&lt;/a&gt; | &lt;a href="https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5"&gt;MiniCPM-Llama3-V 2.5&lt;/a&gt; | &lt;a href="https://huggingface.co/spaces/openbmb/MiniCPM-V-2"&gt;MiniCPM-V 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Local WebUI Demo 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;You can easily build your own local WebUI demo using the following commands.&lt;/p&gt; 
&lt;p&gt;Please ensure that &lt;code&gt;transformers==4.44.2&lt;/code&gt; is installed, as other versions may have compatibility issues.&lt;/p&gt; 
&lt;p&gt;If you are using an older version of PyTorch, you might encounter this issue &lt;code&gt;"weight_norm_fwd_first_dim_kernel" not implemented for 'BFloat16'&lt;/code&gt;, Please add &lt;code&gt;self.minicpmo_model.tts.float()&lt;/code&gt; during the model initialization.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;For real-time voice/video call demo:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;launch model server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install -r requirements_o2.6.txt

python web_demos/minicpm-o_2.6/model_server.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;launch web server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Make sure Node and PNPM is installed.
sudo apt-get update
sudo apt-get install nodejs npm
npm install -g pnpm


cd web_demos/minicpm-o_2.6/web_server
# create ssl cert for https, https is required to request camera and microphone permissions.
bash ./make_ssl_cert.sh  # output key.pem and cert.pem

pnpm install  # install requirements
pnpm run dev  # start server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;code&gt;https://localhost:8088/&lt;/code&gt; in browser and enjoy the real-time voice/video call.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;For chatbot demo:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install -r requirements_o2.6.txt

python web_demos/minicpm-o_2.6/chatbot_web_demo_o2.6.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;code&gt;http://localhost:8000/&lt;/code&gt; in browser and enjoy the vision mode chatbot.&lt;/p&gt; 
&lt;h2&gt;Inference&lt;/h2&gt; 
&lt;h3&gt;Model Zoo&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Device&lt;/th&gt; 
   &lt;th align="center"&gt;Memory&lt;/th&gt; 
   &lt;th align="left"&gt;â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒ Description&lt;/th&gt; 
   &lt;th align="center"&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.5&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;18 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The latest version, strong end-side multimodal performance for single image, multi-image and video understanding.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5"&gt;ğŸ¤—&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-V-4_5"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.5 gguf&lt;/td&gt; 
   &lt;td align="center"&gt;CPU&lt;/td&gt; 
   &lt;td align="center"&gt;8 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The gguf version, lower memory usage and faster inference.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-gguf"&gt;ğŸ¤—&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-V-4_5-gguf"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.5 int4&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;9 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The int4 quantized version, lower GPU memory usage.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-int4"&gt;ğŸ¤—&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-V-4_5-int4"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.5 AWQ&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;9 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The int4 quantized version, lower GPU memory usage.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-AWQ"&gt;ğŸ¤—&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-V-4_5-AWQ"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;18 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The latest version, achieving GPT-4o level performance for vision, speech and multimodal live streaming on end-side devices.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6"&gt;ğŸ¤—&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-o 2.6 gguf&lt;/td&gt; 
   &lt;td align="center"&gt;CPU&lt;/td&gt; 
   &lt;td align="center"&gt;8 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The gguf version, lower memory usage and faster inference.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-gguf"&gt;ğŸ¤—&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6-gguf"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-o 2.6 int4&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;9 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The int4 quantized version, lower GPU memory usage.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-int4"&gt;ğŸ¤—&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6-int4"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Multi-turn Conversation&lt;/h3&gt; 
&lt;p&gt;If you wish to enable long-thinking mode, provide the argument &lt;code&gt;enable_thinking=True&lt;/code&gt; to the chat function.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install -r requirements_o2.6.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to the following codes to run.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/show_demo.jpg" width="500px" /&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

torch.manual_seed(100)

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True, # or openbmb/MiniCPM-o-2_6
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True) # or openbmb/MiniCPM-o-2_6

image = Image.open('./assets/minicpmo2_6/show_demo.jpg').convert('RGB')

enable_thinking=False # If `enable_thinking=True`, the long-thinking mode is enabled.

# First round chat 
question = "What is the landform in the picture?"
msgs = [{'role': 'user', 'content': [image, question]}]

answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    enable_thinking=enable_thinking
)
print(answer)

# Second round chat, pass history context of multi-turn conversation
msgs.append({"role": "assistant", "content": [answer]})
msgs.append({"role": "user", "content": ["What should I pay attention to when traveling here?"]})

answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will get the following output:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# round1
The landform in the picture is karst topography. Karst landscapes are characterized by distinctive, jagged limestone hills or mountains with steep, irregular peaks and deep valleysâ€”exactly what you see here These unique formations result from the dissolution of soluble rocks like limestone over millions of years through water erosion.

This scene closely resembles the famous karst landscape of Guilin and Yangshuo in Chinaâ€™s Guangxi Province. The area features dramatic, pointed limestone peaks rising dramatically above serene rivers and lush green forests, creating a breathtaking and iconic natural beauty that attracts millions of visitors each year for its picturesque views.

# round2
When traveling to a karst landscape like this, here are some important tips:

1. Wear comfortable shoes: The terrain can be uneven and hilly.
2. Bring water and snacks for energy during hikes or boat rides.
3. Protect yourself from the sun with sunscreen, hats, and sunglassesâ€”especially since youâ€™ll likely spend time outdoors exploring scenic spots.
4. Respect local customs and nature regulations by not littering or disturbing wildlife.

By following these guidelines, you'll have a safe and enjoyable trip while appreciating the stunning natural beauty of places such as Guilinâ€™s karst mountains.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Chat with Multiple Images&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-V-4_5 with multiple images input. &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True,  # or openbmb/MiniCPM-o-2_6
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True)  # or openbmb/MiniCPM-o-2_6

image1 = Image.open('image1.jpg').convert('RGB')
image2 = Image.open('image2.jpg').convert('RGB')
question = 'Compare image 1 and image 2, tell me about the differences between image 1 and image 2.'

msgs = [{'role': 'user', 'content': [image1, image2, question]}]

answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;In-context Few-shot Learning&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-V-4_5 with few-shot input. &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True,  # or openbmb/MiniCPM-o-2_6
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True)  # or openbmb/MiniCPM-o-2_6

question = "production date" 
image1 = Image.open('example1.jpg').convert('RGB')
answer1 = "2023.08.04"
image2 = Image.open('example2.jpg').convert('RGB')
answer2 = "2007.04.24"
image_test = Image.open('test.jpg').convert('RGB')

msgs = [
    {'role': 'user', 'content': [image1, question]}, {'role': 'assistant', 'content': [answer1]},
    {'role': 'user', 'content': [image2, question]}, {'role': 'assistant', 'content': [answer2]},
    {'role': 'user', 'content': [image_test, question]}
]

answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;Chat with Video&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-V-4_5 by with video input and 3D-Resampler. &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;## The 3d-resampler compresses multiple frames into 64 tokens by introducing temporal_ids. 
# To achieve this, you need to organize your video data into two corresponding sequences: 
#   frames: List[Image]
#   temporal_ids: List[List[Int]].

import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer
from decord import VideoReader, cpu    # pip install decord
from scipy.spatial import cKDTree
import numpy as np
import math

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True,  # or openbmb/MiniCPM-o-2_6
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True)  # or openbmb/MiniCPM-o-2_6

MAX_NUM_FRAMES=180 # Indicates the maximum number of frames received after the videos are packed. The actual maximum number of valid frames is MAX_NUM_FRAMES * MAX_NUM_PACKING.
MAX_NUM_PACKING=3  # indicates the maximum packing number of video frames. valid range: 1-6
TIME_SCALE = 0.1 

def map_to_nearest_scale(values, scale):
    tree = cKDTree(np.asarray(scale)[:, None])
    _, indices = tree.query(np.asarray(values)[:, None])
    return np.asarray(scale)[indices]


def group_array(arr, size):
    return [arr[i:i+size] for i in range(0, len(arr), size)]

def encode_video(video_path, choose_fps=3, force_packing=None):
    def uniform_sample(l, n):
        gap = len(l) / n
        idxs = [int(i * gap + gap / 2) for i in range(n)]
        return [l[i] for i in idxs]
    vr = VideoReader(video_path, ctx=cpu(0))
    fps = vr.get_avg_fps()
    video_duration = len(vr) / fps
        
    if choose_fps * int(video_duration) &amp;lt;= MAX_NUM_FRAMES:
        packing_nums = 1
        choose_frames = round(min(choose_fps, round(fps)) * min(MAX_NUM_FRAMES, video_duration))
        
    else:
        packing_nums = math.ceil(video_duration * choose_fps / MAX_NUM_FRAMES)
        if packing_nums &amp;lt;= MAX_NUM_PACKING:
            choose_frames = round(video_duration * choose_fps)
        else:
            choose_frames = round(MAX_NUM_FRAMES * MAX_NUM_PACKING)
            packing_nums = MAX_NUM_PACKING

    frame_idx = [i for i in range(0, len(vr))]      
    frame_idx =  np.array(uniform_sample(frame_idx, choose_frames))

    if force_packing:
        packing_nums = min(force_packing, MAX_NUM_PACKING)
    
    print(video_path, ' duration:', video_duration)
    print(f'get video frames={len(frame_idx)}, packing_nums={packing_nums}')
    
    frames = vr.get_batch(frame_idx).asnumpy()

    frame_idx_ts = frame_idx / fps
    scale = np.arange(0, video_duration, TIME_SCALE)

    frame_ts_id = map_to_nearest_scale(frame_idx_ts, scale) / TIME_SCALE
    frame_ts_id = frame_ts_id.astype(np.int32)

    assert len(frames) == len(frame_ts_id)

    frames = [Image.fromarray(v.astype('uint8')).convert('RGB') for v in frames]
    frame_ts_id_group = group_array(frame_ts_id, packing_nums)
    
    return frames, frame_ts_id_group


video_path="video_test.mp4"
fps = 5 # fps for video
force_packing = None # You can set force_packing to ensure that 3D packing is forcibly enabled; otherwise, encode_video will dynamically set the packing quantity based on the duration.
frames, frame_ts_id_group = encode_video(video_path, fps, force_packing=force_packing)

question = "Describe the video"
msgs = [
    {'role': 'user', 'content': frames + [question]}, 
]


answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    use_image_id=False,
    max_slice_nums=1,
    temporal_ids=frame_ts_id_group
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;Speech and Audio Mode&lt;/h4&gt; 
&lt;p&gt;Model initialization&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torch
import librosa
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-o-2_6', trust_remote_code=True,
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-o-2_6', trust_remote_code=True)

model.init_tts()
model.tts.float()
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Mimick 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;Mimick&lt;/code&gt; task reflects a model's end-to-end speech modeling capability. The model takes audio input, and outputs an ASR transcription and subsequently reconstructs the original audio with high similarity. The higher the similarity between the reconstructed audio and the original audio, the stronger the model's foundational capability in end-to-end speech modeling.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;mimick_prompt = "Please repeat each user's speech, including voice style and speech content."
audio_input, _ = librosa.load('./assets/input_examples/Trump_WEF_2018_10s.mp3', sr=16000, mono=True) # load the audio to be mimicked

# `./assets/input_examples/fast-pace.wav`, 
# `./assets/input_examples/chi-english-1.wav` 
# `./assets/input_examples/exciting-emotion.wav` 
# for different aspects of speech-centric features.

msgs = [{'role': 'user', 'content': [mimick_prompt, audio_input]}]
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    temperature=0.3,
    generate_audio=True,
    output_audio_path='output_mimick.wav', # save the tts result to output_audio_path
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;General Speech Conversation with Configurable Voices 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;A general usage scenario of &lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; is role-playing a specific character based on the audio prompt. It will mimic the voice of the character to some extent and act like the character in text, including language style. In this mode, &lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; sounds &lt;strong&gt;more natural and human-like&lt;/strong&gt;. Self-defined audio prompts can be used to customize the voice of the character in an end-to-end manner.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;ref_audio, _ = librosa.load('./assets/input_examples/icl_20.wav', sr=16000, mono=True) # load the reference audio
sys_prompt = model.get_sys_prompt(ref_audio=ref_audio, mode='audio_roleplay', language='en')

# round one
user_question = {'role': 'user', 'content': [librosa.load('xxx.wav', sr=16000, mono=True)[0]]}
msgs = [sys_prompt, user_question]
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_roleplay_round_1.wav',
)

# round two
history = msgs.append({'role': 'assistant', 'content': res})
user_question = {'role': 'user', 'content': [librosa.load('xxx.wav', sr=16000, mono=True)[0]]}
msgs = history.append(user_question)
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_roleplay_round_2.wav',
)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Speech Conversation as an AI Assistant 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;An enhanced feature of &lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; is to act as an AI assistant, but only with limited choice of voices. In this mode, &lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; is &lt;strong&gt;less human-like and more like a voice assistant&lt;/strong&gt;. In this mode, the model is more instruction-following. For demo, you are suggested to use &lt;code&gt;assistant_female_voice&lt;/code&gt;, &lt;code&gt;assistant_male_voice&lt;/code&gt;, and &lt;code&gt;assistant_default_female_voice&lt;/code&gt;. Other voices may work but not as stable as the default voices.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Please note that, &lt;code&gt;assistant_female_voice&lt;/code&gt; and &lt;code&gt;assistant_male_voice&lt;/code&gt; are more stable but sounds like robots, while &lt;code&gt;assistant_default_female_voice&lt;/code&gt; is more human-alike but not stable, its voice often changes in multiple turns. We suggest you to try stable voices &lt;code&gt;assistant_female_voice&lt;/code&gt; and &lt;code&gt;assistant_male_voice&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;ref_audio, _ = librosa.load('./assets/input_examples/assistant_female_voice.wav', sr=16000, mono=True) # or use `./assets/input_examples/assistant_male_voice.wav`
sys_prompt = model.get_sys_prompt(ref_audio=ref_audio, mode='audio_assistant', language='en') 
user_question = {'role': 'user', 'content': [librosa.load('xxx.wav', sr=16000, mono=True)[0]]} # load the user's audio question

# round one
msgs = [sys_prompt, user_question]
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_assistant_round_1.wav',
)

# round two
history = msgs.append({'role': 'assistant', 'content': res})
user_question = {'role': 'user', 'content': [librosa.load('xxx.wav', sr=16000, mono=True)[0]]}
msgs = history.append(user_question)
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_assistant_round_2.wav',
)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Instruction-to-Speech 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; can also do Instruction-to-Speech, aka &lt;strong&gt;Voice Creation&lt;/strong&gt;. You can describe a voice in detail, and the model will generate a voice that matches the description. For more Instruction-to-Speech sample instructions, you can refer to &lt;a href="https://voxinstruct.github.io/VoxInstruct/"&gt;https://voxinstruct.github.io/VoxInstruct/&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;instruction = 'Speak like a male charming superstar, radiating confidence and style in every word.'

msgs = [{'role': 'user', 'content': [instruction]}]

res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_voice_creation.wav',
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Voice Cloning 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; can also do zero-shot text-to-speech, aka &lt;strong&gt;Voice Cloning&lt;/strong&gt;. With this mode, model will act like a TTS model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;ref_audio, _ = librosa.load('./assets/input_examples/icl_20.wav', sr=16000, mono=True) # load the reference audio
sys_prompt = model.get_sys_prompt(ref_audio=ref_audio, mode='voice_cloning', language='en')
text_prompt = f"Please read the text below."
user_question = {'role': 'user', 'content': [text_prompt, "content that you want to read"]}

msgs = [sys_prompt, user_question]
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_voice_cloning.wav',
)

&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Addressing Various Audio Understanding Tasks 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; can also be used to address various audio understanding tasks, such as ASR, speaker analysis, general audio captioning, and sound scene tagging.&lt;/p&gt; 
&lt;p&gt;For audio-to-text tasks, you can use the following prompts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ASR with ZH(same as AST en2zh): &lt;code&gt;è¯·ä»”ç»†å¬è¿™æ®µéŸ³é¢‘ç‰‡æ®µï¼Œå¹¶å°†å…¶å†…å®¹é€å­—è®°å½•ã€‚&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ASR with EN(same as AST zh2en): &lt;code&gt;Please listen to the audio snippet carefully and transcribe the content.&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Speaker Analysis: &lt;code&gt;Based on the speaker's content, speculate on their gender, condition, age range, and health status.&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;General Audio Caption: &lt;code&gt;Summarize the main content of the audio.&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;General Sound Scene Tagging: &lt;code&gt;Utilize one keyword to convey the audio's content or the associated scene.&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;task_prompt = "Please listen to the audio snippet carefully and transcribe the content." + "\n" # can change to other prompts.
audio_input, _ = librosa.load('./assets/input_examples/audio_understanding.mp3', sr=16000, mono=True) # load the audio to be captioned

msgs = [{'role': 'user', 'content': [task_prompt, audio_input]}]

res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_audio_understanding.wav',
)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Multimodal Live Streaming&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-o 2.6 with chat inference. &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import math
import numpy as np
from PIL import Image
from moviepy.editor import VideoFileClip
import tempfile
import librosa
import soundfile as sf
import torch
from transformers import AutoModel, AutoTokenizer

def get_video_chunk_content(video_path, flatten=True):
    video = VideoFileClip(video_path)
    print('video_duration:', video.duration)
    
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as temp_audio_file:
        temp_audio_file_path = temp_audio_file.name
        video.audio.write_audiofile(temp_audio_file_path, codec="pcm_s16le", fps=16000)
        audio_np, sr = librosa.load(temp_audio_file_path, sr=16000, mono=True)
    num_units = math.ceil(video.duration)
    
    # 1 frame + 1s audio chunk
    contents= []
    for i in range(num_units):
        frame = video.get_frame(i+1)
        image = Image.fromarray((frame).astype(np.uint8))
        audio = audio_np[sr*i:sr*(i+1)]
        if flatten:
            contents.extend(["&amp;lt;unit&amp;gt;", image, audio])
        else:
            contents.append(["&amp;lt;unit&amp;gt;", image, audio])
    
    return contents


model = AutoModel.from_pretrained('openbmb/MiniCPM-o-2_6', trust_remote_code=True,
    attn_implementation='sdpa', torch_dtype=torch.bfloat16)
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-o-2_6', trust_remote_code=True)

model.init_tts()

# If you are using an older version of PyTorch, you might encounter this issue "weight_norm_fwd_first_dim_kernel" not implemented for 'BFloat16', Please convert the TTS to float32 type.
# model.tts.float()

# https://huggingface.co/openbmb/MiniCPM-o-2_6/blob/main/assets/Skiing.mp4
video_path="assets/Skiing.mp4"
sys_msg = model.get_sys_prompt(mode='omni', language='en')
# if use voice clone prompt, please set ref_audio
# ref_audio_path = '/path/to/ref_audio'
# ref_audio, _ = librosa.load(ref_audio_path, sr=16000, mono=True)
# sys_msg = model.get_sys_prompt(ref_audio=ref_audio, mode='omni', language='en')

contents = get_video_chunk_content(video_path)
msg = {"role":"user", "content": contents}
msgs = [sys_msg, msg]

# please set generate_audio=True and output_audio_path to save the tts result
generate_audio = True
output_audio_path = 'output.wav'

res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    temperature=0.5,
    max_new_tokens=4096,
    omni_input=True, # please set omni_input=True when omni inference
    use_tts_template=True,
    generate_audio=generate_audio,
    output_audio_path=output_audio_path,
    max_slice_nums=1,
    use_image_id=False,
    return_dict=True
)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-o 2.6 with streaming inference. &lt;/summary&gt; 
 &lt;p&gt;Note: The streaming inference has a slight performance degradation because the audio encoding is not global.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# a new conversation need reset session first, it will reset the kv-cache
model.reset_session()

contents = get_video_chunk_content(video_path, flatten=False)
session_id = '123'
generate_audio = True

# 1. prefill system prompt
res = model.streaming_prefill(
    session_id=session_id,
    msgs=[sys_msg], 
    tokenizer=tokenizer
)

# 2. prefill video/audio chunks
for content in contents:
    msgs = [{"role":"user", "content": content}]
    res = model.streaming_prefill(
        session_id=session_id,
        msgs=msgs, 
        tokenizer=tokenizer
    )

# 3. generate
res = model.streaming_generate(
    session_id=session_id,
    tokenizer=tokenizer,
    temperature=0.5,
    generate_audio=generate_audio
)

audios = []
text = ""

if generate_audio:
    for r in res:
        audio_wav = r.audio_wav
        sampling_rate = r.sampling_rate
        txt = r.text

        audios.append(audio_wav)
        text += txt
        
    res = np.concatenate(audios)
    sf.write("output.wav", res, samplerate=sampling_rate)
    print("text:", text)
    print("audio saved to output.wav")
else:
    for r in res:
        text += r['text']
    print("text:", text)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Inference on Multiple GPUs&lt;/h3&gt; 
&lt;p&gt;You can run MiniCPM-Llama3-V 2.5 on multiple low VRAM GPUs (12 GB or 16 GB) by distributing the model's layers across multiple GPUs. Please refer to this &lt;a href="https://github.com/OpenBMB/MiniCPM-V/raw/main/docs/inference_on_multiple_gpus.md"&gt;tutorial&lt;/a&gt; for detailed instructions on how to load the model and inference using multiple low VRAM GPUs.&lt;/p&gt; 
&lt;h3&gt;Inference on Mac&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view an example, to run MiniCPM-Llama3-V 2.5 on ğŸ’» Mac with MPS (Apple silicon or AMD GPUs). &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# test.py  Need more than 16GB memory.
import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True, low_cpu_mem_usage=True)
model = model.to(device='mps')

tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True)
model.eval()

image = Image.open('./assets/hk_OCR.jpg').convert('RGB')
question = 'Where is this photo taken?'
msgs = [{'role': 'user', 'content': question}]

answer, context, _ = model.chat(
    image=image,
    msgs=msgs,
    context=None,
    tokenizer=tokenizer,
    sampling=True
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Run with command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;PYTORCH_ENABLE_MPS_FALLBACK=1 python test.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Efficient Inference with llama.cpp, Ollama, vLLM&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://github.com/OpenBMB/llama.cpp/tree/minicpmv-main/examples/llava/README-minicpmv2.6.md"&gt;our fork of llama.cpp&lt;/a&gt; for more detail. This implementation supports smooth inference of 16~18 token/s on iPad (test environmentï¼šiPad Pro + M4).&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/OpenBMB/ollama/raw/minicpm-v2.6/examples/minicpm-v2.6/README.md"&gt;our fork of Ollama&lt;/a&gt; for more detail. This implementation supports smooth inference of 16~18 token/s on iPad (test environmentï¼šiPad Pro + M4).&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; vLLM now officially supports MiniCPM-V 2.6, MiniCPM-Llama3-V 2.5 and MiniCPM-V 2.0. And you can use our fork to run MiniCPM-o 2.6 for now. Click to see. &lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install vLLM(&amp;gt;=0.7.1):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pip install vllm
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Run Example:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/examples/vision_language.html"&gt;Vision Language&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/examples/audio_language.html"&gt;Audio Language&lt;/a&gt; &lt;/li&gt;
 &lt;/ul&gt;
&lt;/details&gt;   
&lt;h2&gt;Fine-tuning&lt;/h2&gt; 
&lt;h3&gt;Simple Fine-tuning 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We support simple fine-tuning with Hugging Face for MiniCPM-o 2.6, MiniCPM-V 2.6, MiniCPM-Llama3-V 2.5 and MiniCPM-V 2.0.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/finetune/readme.md"&gt;Reference Document&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;With Align-Anything 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We support fine-tuning MiniCPM-o 2.6 by PKU-Alignment Team (both vision and audio, SFT and DPO) with the &lt;a href="https://github.com/PKU-Alignment/align-anything"&gt;Align-Anything framework&lt;/a&gt;. Align-Anything is a scalable framework that aims to align any-modality large models with human intentions, open-sourcing the &lt;a href="https://huggingface.co/datasets/PKU-Alignment/align-anything"&gt;datasets, models and benchmarks&lt;/a&gt;. Benefiting from its concise and modular design, it supports 30+ open-source benchmarks, 40+ models and algorithms including SFT, SimPO, RLHF, &lt;em&gt;etc&lt;/em&gt;. It also provides 30+ directly runnable scripts, making it suitable for beginners to quickly get started.&lt;/p&gt; 
&lt;p&gt;Best Practices: &lt;a href="https://github.com/PKU-Alignment/align-anything/tree/main/scripts"&gt;MiniCPM-o 2.6&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;With LLaMA-Factory 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We support fine-tuning MiniCPM-o 2.6 and MiniCPM-V 2.6 with the LLaMA-Factory framework. LLaMA-Factory provides a solution for flexibly customizing the fine-tuning (Lora/Full/Qlora) of 200+ LLMs without the need for coding through the built-in web UI LLaMABoard. It supports various training methods like sft/ppo/dpo/kto and advanced algorithms like Galore/BAdam/LLaMA-Pro/Pissa/LongLoRA.&lt;/p&gt; 
&lt;p&gt;Best Practices: &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/llamafactory_train_and_infer.md"&gt;MiniCPM-o 2.6 | MiniCPM-V 2.6&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;With the SWIFT Framework 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We now support MiniCPM-V series fine-tuning with the SWIFT framework. SWIFT supports training, inference, evaluation and deployment of nearly 200 LLMs and MLLMs . It supports the lightweight training solutions provided by PEFT and a complete Adapters Library including techniques such as NEFTune, LoRA+ and LLaMA-PRO.&lt;/p&gt; 
&lt;p&gt;Best Practicesï¼š&lt;a href="https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md"&gt;MiniCPM-V 1.0&lt;/a&gt;, &lt;a href="https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v-2%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md"&gt;MiniCPM-V 2.0&lt;/a&gt;, &lt;a href="https://github.com/modelscope/ms-swift/issues/1613"&gt;MiniCPM-V 2.6&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Awesome work using MiniCPM-V &amp;amp; MiniCPM-o&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CatchTheTornado/text-extract-api"&gt;text-extract-api&lt;/a&gt;: Document extraction API using OCRs and Ollama supported models &lt;img src="https://img.shields.io/github/stars/CatchTheTornado/text-extract-api" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/heshengtao/comfyui_LLM_party"&gt;comfyui_LLM_party&lt;/a&gt;: Build LLM workflows and integrate into existing image workflows &lt;img src="https://img.shields.io/github/stars/heshengtao/comfyui_LLM_party" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imanoop7/Ollama-OCR"&gt;Ollama-OCR&lt;/a&gt;: OCR package uses vlms through Ollama to extract text from images and PDF &lt;img src="https://img.shields.io/github/stars/imanoop7/Ollama-OCR" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MixLabPro/comfyui-mixlab-nodes"&gt;comfyui-mixlab-nodes&lt;/a&gt;: ComfyUI node suite supports Workflow-to-APPã€GPT&amp;amp;3D and more &lt;img src="https://img.shields.io/github/stars/MixLabPro/comfyui-mixlab-nodes" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HumanAIGC-Engineering/OpenAvatarChat"&gt;OpenAvatarChat&lt;/a&gt;: Interactive digital human conversation implementation on single PC &lt;img src="https://img.shields.io/github/stars/HumanAIGC-Engineering/OpenAvatarChat" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/arkohut/pensieve"&gt;pensieve&lt;/a&gt;: A privacy-focused passive recording project by recording screen content &lt;img src="https://img.shields.io/github/stars/arkohut/pensieve" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/icereed/paperless-gpt"&gt;paperless-gpt&lt;/a&gt;: Use LLMs to handle paperless-ngx, AI-powered titles, tags and OCR &lt;img src="https://img.shields.io/github/stars/icereed/paperless-gpt" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kimjammer/Neuro"&gt;Neuro&lt;/a&gt;: A recreation of Neuro-Sama, but running on local models on consumer hardware &lt;img src="https://img.shields.io/github/stars/kimjammer/Neuro" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQs&lt;/h2&gt; 
&lt;p&gt;Click here to view the &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/faqs.md"&gt;FAQs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Limitations&lt;/h2&gt; 
&lt;p&gt;As an experimental trial, we find MiniCPM-o 2.6 has notable limitations worth further investigation and improvement.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Unstable speech output.&lt;/strong&gt; The speech generation can be flawed with noisy backgrounds and unmeaningful sounds.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repeated response.&lt;/strong&gt; The model tends to repeat its response when encountering similar consecutive user queries.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High-latency on Web Demo.&lt;/strong&gt; Users may experience unusual high-latency when using web demo hosted on overseas servers. We recommend deploying the demo locally or with good network connections.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model License 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;This repository is released under the &lt;a href="https://github.com/OpenBMB/MiniCPM/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt; License.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The usage of MiniCPM-o/V model weights must strictly follow &lt;a href="https://github.com/OpenBMB/MiniCPM/raw/main/MiniCPM%20Model%20License.md"&gt;MiniCPM Model License.md&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The models and weights of MiniCPM are completely free for academic research. after filling out a &lt;a href="https://modelbest.feishu.cn/share/base/form/shrcnpV5ZT9EJ6xYjh3Kx0J6v8g"&gt;"questionnaire"&lt;/a&gt; for registration, are also available for free commercial use.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Statement 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;p&gt;As MLLMs, MiniCPM-o/V models generate content by learning a large number of multimodal corpora, but they cannot comprehend, express personal opinions, or make value judgements. Anything generated by MiniCPM-o/V models does not represent the views and positions of the model developers&lt;/p&gt; 
&lt;p&gt;We will not be liable for any problems arising from the use of MiniCPM-o/V models, including but not limited to data security issues, risk of public opinion, or any risks and problems arising from the misdirection, misuse, dissemination, or misuse of the model.&lt;/p&gt; 
&lt;h2&gt;Institutions 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;p&gt;This project is developed by the following institutions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/thunlp.png" width="28px" /&gt; &lt;a href="https://nlp.csai.tsinghua.edu.cn/"&gt;THUNLP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelbest.png" width="28px" /&gt; &lt;a href="https://modelbest.cn/"&gt;ModelBest&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸŒŸ Star History 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/star-history-25-09-02.png" /&gt; &lt;/p&gt;
&lt;table align="center"&gt;  
&lt;/table&gt; 
&lt;!-- &lt;picture&gt;
  &lt;source
    media="(prefers-color-scheme: dark)"
    srcset="
      https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-o&amp;type=Date&amp;theme=dark
    "
  /&gt;
  &lt;source
    media="(prefers-color-scheme: light)"
    srcset="
      https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-o&amp;type=Date
    "
  /&gt;
  &lt;img
    alt="Star History Chart"
    src="https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-o&amp;type=Date"
  /&gt;
&lt;/picture&gt; --&gt; 
&lt;h2&gt;Key Techniques and Other Multimodal Projects 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;p&gt;ğŸ‘ Welcome to explore key techniques of MiniCPM-o/V and other multimodal projects of our team:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenBMB/VisCPM/tree/main"&gt;VisCPM&lt;/a&gt; | &lt;a href="https://github.com/OpenBMB/RLPR"&gt;RLPR&lt;/a&gt; | &lt;a href="https://github.com/RLHF-V/RLHF-V"&gt;RLHF-V&lt;/a&gt; | &lt;a href="https://github.com/thunlp/LLaVA-UHD"&gt;LLaVA-UHD&lt;/a&gt; | &lt;a href="https://github.com/RLHF-V/RLAIF-V"&gt;RLAIF-V&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citation 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;p&gt;If you find our model/code/paper helpful, please consider citing our papers ğŸ“ and staring us â­ï¸ï¼&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bib"&gt;@article{yao2024minicpm,
  title={MiniCPM-V: A GPT-4V Level MLLM on Your Phone},
  author={Yao, Yuan and Yu, Tianyu and Zhang, Ao and Wang, Chongyi and Cui, Junbo and Zhu, Hongji and Cai, Tianchi and Li, Haoyu and Zhao, Weilin and He, Zhihui and others},
  journal={arXiv preprint arXiv:2408.01800},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>juspay/hyperswitch</title>
      <link>https://github.com/juspay/hyperswitch</link>
      <description>&lt;p&gt;An open source payments switch written in Rust to make payments fast, reliable and affordable&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only" alt="Hyperswitch-Logo" width="40%" /&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only" alt="Hyperswitch-Logo" width="40%" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Composable Open-Source Payments Infrastructure&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/gifs/quickstart.gif" alt="Quickstart demo" /&gt; &lt;/p&gt; 
&lt;!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} --&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain"&gt; &lt;img src="https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/juspay/hyperswitch" /&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/Made_in-Rust-orange" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/company/hyperswitch/"&gt; &lt;img src="https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&amp;amp;labelColor=grey" /&gt; &lt;/a&gt; &lt;a href="https://x.com/hyperswitchio"&gt; &lt;img src="https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&amp;amp;labelColor=grey" /&gt; &lt;/a&gt; &lt;a href="https://inviter.co/hyperswitch-slack"&gt; &lt;img src="https://img.shields.io/badge/chat-on_slack-blue?logo=slack&amp;amp;labelColor=grey&amp;amp;color=%233f0e40" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“ Table of Contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-what-can-i-do-with-hyperswitch"&gt;What Can I Do with Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-quickstart-local-setup"&gt;Quickstart (Local Setup)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#cloud-deployment"&gt;Cloud Deployment&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#hosted-sandbox-no-setup-required"&gt;Hosted Sandbox (No Setup Required)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-why-hyperswitch"&gt;Why Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt;Architectural Overview&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#our-vision"&gt;Our Vision&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#community--contributions"&gt;Community &amp;amp; Contributions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests--bugs"&gt;Feature Requests &amp;amp; Bugs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt;Versioning&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt;Team Behind Hyperswitch&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;summary&gt;&lt;h2&gt; What Can I Do with Hyperswitch?&lt;/h2&gt;&lt;/summary&gt; 
&lt;p&gt;Hyperswitch offers a modular, open-source payments infrastructure designed for flexibility and control. Apart from our Payment Suite offering, this solution allows businesses to pick and integrate only the modules they need on top of their existing payment stack â€” without unnecessary complexity or vendor lock-in.&lt;/p&gt; 
&lt;p&gt;Each module is independent and purpose-built to optimize different aspects of payment processing.&lt;/p&gt; 
&lt;h3&gt; Learn More About The Payment Modules &lt;/h3&gt; 
&lt;details&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cost Observability&lt;/strong&gt;&lt;br /&gt; Advanced observability tools to audit, monitor, and optimize your payment costs. Detect hidden fees, downgrades, and penalties with self-serve dashboards and actionable insights.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/ai-powered-cost-observability"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revenue Recovery&lt;/strong&gt;&lt;br /&gt; Combat passive churn with intelligent retry strategies tuned by card bin, region, method, and more. Offers fine-grained control over retry algorithms, penalty budgets, and recovery transparency.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/revenue-recovery"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vault&lt;/strong&gt;&lt;br /&gt; A PCI-compliant vault service to store cards, tokens, wallets, and bank credentials. Provides a unified, secure, and reusable store of customer-linked payment methods.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/vault"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Intelligent Routing&lt;/strong&gt;&lt;br /&gt; Route each transaction to the PSP with the highest predicted auth rate. Reduce retries, avoid downtime, and minimize latency while maximizing first attempt success.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/intelligent-routing"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reconciliation&lt;/strong&gt;&lt;br /&gt; Automate 2-way and 3-way reconciliation with backdated support, staggered scheduling, and customizable outputs. Reduces manual ops effort and increases audit confidence.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/reconciliation"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternate Payment Methods&lt;/strong&gt;&lt;br /&gt; Drop-in widgets for PayPal, Apple Pay, Google Pay, Samsung Pay, Pay by Bank, and BNPL providers like Klarna. Maximizes conversions with seamless one-click checkout.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/enable-alternate-payment-method-widgets"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt; Local Setup via Docker &lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# One-click local setup

git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch

cd hyperswitch

scripts/setup.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;This script: &lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Detects Docker/Podman&lt;/li&gt; 
  &lt;li&gt;Offers multiple deployment profiles: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Standard&lt;/strong&gt;: App server + Control Center&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Full&lt;/strong&gt;: Includes monitoring + schedulers&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Minimal&lt;/strong&gt;: Standalone App server&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Provides access links when done&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you need further help, check out our &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/overview/unified-local-setup-using-docker"&gt;video tutorial&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;ğŸ‘‰ After setup, &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/using-hyperswitch-control-center#add-a-payment-processor"&gt;configure a connector&lt;/a&gt; and &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/test-a-payment"&gt;test a payment&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Hosted Sandbox (No Setup Required)&lt;/h3&gt; 
&lt;p&gt;Hyperswitch offers a fully hosted sandbox environment that requires no setup. You can explore the Control Center, configure payment connectors, and test payments directly from the UI.&lt;/p&gt; 
&lt;a href="https://app.hyperswitch.io"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/try-the-sandbox.png?raw=true" height="35" /&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt; What you can do in the Hosted Sandbox&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Access the full Control Center&lt;/li&gt; 
  &lt;li&gt;Configure payment connectors&lt;/li&gt; 
  &lt;li&gt;View logs, routing rules, and retry strategies&lt;/li&gt; 
  &lt;li&gt;Try payments directly from the UI&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Cloud Deployment&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;You can deploy to AWS, GCP, or Azure using Helm or CDK scripts. Fastest path:&lt;/p&gt; 
&lt;p&gt;Click to deploy via AWS:&lt;/p&gt; 
&lt;a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&amp;amp;templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/aws_button.png?raw=true" height="35" /&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Cloud Deployment Instructions&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Click the AWS deployment button above to launch the stack.&lt;/li&gt; 
  &lt;li&gt;Follow the guided steps in the AWS Console (approx. 30â€“45 mins).&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;âœ… This setup provisions Hyperswitch on your cloud account using CloudFormation.&lt;/p&gt; 
 &lt;p&gt;ğŸ“˜ For full instructions and Helm-based deployments, check out the&lt;br /&gt; &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm"&gt;Cloud Install Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt; &lt;h2 id="architectural-overview"&gt;Architectural Overview&lt;/h2&gt; &lt;/a&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/features.png" /&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/non-functional-features.png" /&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-architecture-v1.png" /&gt; 
&lt;h2&gt;Why Hyperswitch?&lt;/h2&gt; 
&lt;p&gt;Hyperswitch is a commercial open-source payments stack purpose-built for scale, flexibility, and developer experience. Designed with a modular architecture, Hyperswitch lets you pick only the components you needâ€”whether itâ€™s routing, retries, vaulting, or observabilityâ€”without vendor lock-in or bloated integrations.&lt;/p&gt; 
&lt;p&gt;Built in Rust for performance and reliability, Hyperswitch supports global payment methods (cards, wallets, BNPL, UPI, Pay by Bank), exposes smart routing and retry logic, and provides a visual workflow builder in the Control Center. Whether you're integrating a full payment suite or augmenting an existing stack with a single module, Hyperswitch meets you where you are.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;â€œLinux for Paymentsâ€&lt;/strong&gt; â€” Hyperswitch is a well-architected reference for teams who want to own their payments stack.&lt;/p&gt; 
&lt;p&gt;We believe in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Embracing Payment Diversity:&lt;/strong&gt; Innovation comes from enabling choiceâ€”across payment methods, processors, and flows.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Open Source by Default:&lt;/strong&gt; Transparency drives trust and builds better, reusable software.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven Development:&lt;/strong&gt; Our roadmap is shaped by real-world use cases and contributors.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Systems-Level Engineering:&lt;/strong&gt; We hold ourselves to a high bar for reliability, security, and performance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Maximizing Value Creation:&lt;/strong&gt; For developers, customers, and partners alike.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven, Enterprise-Tested:&lt;/strong&gt; Hyperswitch is built in the open with real-world feedback from developers and contributors, and maintained by Juspay, the team powering payment infrastructure for 400+ leading enterprises worldwide.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributors from around the world to help build Hyperswitch. Whether you're fixing bugs, improving documentation, or adding new features, your help is appreciated.&lt;/p&gt; 
&lt;p&gt;Please read our &lt;a href="https://github.com/juspay/hyperswitch/raw/main/docs/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;Join the conversation on &lt;a href="https://inviter.co/hyperswitch-slack"&gt;Slack&lt;/a&gt; or explore open issues on &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests"&gt; &lt;h2 id="feature-requests"&gt;Feature requests &amp;amp; Bugs&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our &lt;a href="https://github.com/juspay/hyperswitch/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For reporting a bug, please read the issue guidelines and search for &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;existing and closed issues&lt;/a&gt;. If your problem or idea is not addressed yet, please &lt;a href="https://github.com/juspay/hyperswitch/issues/new/choose"&gt;open a new issue&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt; &lt;h2 id="versioning"&gt;Versioning&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt; &lt;h2 id="copyright-and-license"&gt;Copyright and License&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;This product is licensed under the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/LICENSE"&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt; &lt;h2 id="team-behind-hyperswitch"&gt;Team behind Hyperswitch&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;The core team of 150+ engineers building Hyperswitch. Keep up the great work! ğŸ¥‚&lt;/p&gt; 
&lt;a href="https://github.com/juspay/hyperswitch/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=juspay/hyperswitch" alt="Contributors" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>gunnarmorling/1brc</title>
      <link>https://github.com/gunnarmorling/1brc</link>
      <description>&lt;p&gt;1ï¸âƒ£ğŸğŸï¸ The One Billion Row Challenge -- A fun exploration of how quickly 1B rows from a text file can be aggregated with Java&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;1ï¸âƒ£ğŸğŸï¸ The One Billion Row Challenge&lt;/h1&gt; 
&lt;p&gt;&lt;em&gt;Status Feb 4: The final leaderboards &lt;a href="https://www.morling.dev/blog/1brc-results-are-in/"&gt;have been published&lt;/a&gt;. Congrats to all the winners, and a big thank you to everyone participating in this challenge as well as to everyone helping to organize it!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Status Feb 3: All entries have been evaluated and I am in the process of finalizing the leaderboards.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Status Feb 1: The challenge has been closed for new submissions. No new pull requests for adding submissions are accepted at this time. Pending PRs will be evaluated over the next few days.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Status Jan 31: The challenge will close today at midnight UTC.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Status Jan 12: As there has been such a large number of entries to this challenge so far (100+), and this is becoming hard to manage, please only create new submissions if you expect them to run in 10 seconds or less on the evaluation machine.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Status Jan 1: This challenge is &lt;a href="https://www.morling.dev/blog/one-billion-row-challenge/"&gt;open for submissions&lt;/a&gt;!&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Sponsorship&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;A big thank you to my employer &lt;a href="https://www.decodable.co/"&gt;Decodable&lt;/a&gt; for funding the evaluation environment and supporting this challenge!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The One Billion Row Challenge (1BRC) is a fun exploration of how far modern Java can be pushed for aggregating one billion rows from a text file. Grab all your (virtual) threads, reach out to SIMD, optimize your GC, or pull any other trick, and create the fastest implementation for solving this task!&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/gunnarmorling/1brc/main/1brc.png" alt="1BRC" style="display: block; margin-left: auto; margin-right: auto; margin-bottom:1em; width: 50%;" /&gt; 
&lt;p&gt;The text file contains temperature values for a range of weather stations. Each row is one measurement in the format &lt;code&gt;&amp;lt;string: station name&amp;gt;;&amp;lt;double: measurement&amp;gt;&lt;/code&gt;, with the measurement value having exactly one fractional digit. The following shows ten rows as an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Hamburg;12.0
Bulawayo;8.9
Palembang;38.8
St. John's;15.2
Cracow;12.6
Bridgetown;26.9
Istanbul;6.2
Roseau;34.4
Conakry;31.2
Istanbul;23.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The task is to write a Java program which reads the file, calculates the min, mean, and max temperature value per weather station, and emits the results on stdout like this (i.e. sorted alphabetically by station name, and the result values per station in the format &lt;code&gt;&amp;lt;min&amp;gt;/&amp;lt;mean&amp;gt;/&amp;lt;max&amp;gt;&lt;/code&gt;, rounded to one fractional digit):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{Abha=-23.0/18.0/59.2, Abidjan=-16.2/26.0/67.3, AbÃ©chÃ©=-10.0/29.4/69.0, Accra=-10.1/26.4/66.4, Addis Ababa=-23.7/16.0/67.0, Adelaide=-27.8/17.3/58.5, ...}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Submit your implementation by Jan 31 2024 and become part of the leaderboard!&lt;/p&gt; 
&lt;h2&gt;Results&lt;/h2&gt; 
&lt;p&gt;These are the results from running all entries into the challenge on eight cores of a &lt;a href="https://www.hetzner.com/dedicated-rootserver/ax161"&gt;Hetzner AX161&lt;/a&gt; dedicated server (32 core AMD EPYCâ„¢ 7502P (Zen2), 128 GB RAM).&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Result (m:s.ms)&lt;/th&gt; 
   &lt;th&gt;Implementation&lt;/th&gt; 
   &lt;th&gt;JDK&lt;/th&gt; 
   &lt;th&gt;Submitter&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
   &lt;th&gt;Certificates&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;00:01.535&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_thomaswue.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/thomaswue"&gt;Thomas Wuerthinger&lt;/a&gt;, &lt;a href="https://github.com/merykitty"&gt;Quan Anh Mai&lt;/a&gt;, &lt;a href="https://github.com/mukel"&gt;AlfonsoÂ² Peterssen&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/thomaswue_merykitty_mukel.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;00:01.587&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_artsiomkorzun.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/artsiomkorzun"&gt;Artsiom Korzun&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/artsiomkorzun.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;00:01.608&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jerrinot.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jerrinot"&gt;Jaromir Hamala&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/jerrinot.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.880&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_serkan_ozal.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/serkan-ozal"&gt;Serkan Ã–ZAL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/serkan_ozal.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.921&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_abeobk.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/abeobk"&gt;Van Phu DO&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/abeobk.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.018&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_stephenvonworley.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/stephenvonworley"&gt;Stephen Von Worley&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/stephenvonworley.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.157&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_royvanrijn.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/royvanrijn"&gt;Roy van Rijn&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/royvanrijn.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.319&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_yavuztas.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yavuztas"&gt;Yavuz Tas&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/yavuztas.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.332&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_mtopolnik.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mtopolnik"&gt;Marko Topolnik&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/mtopolnik.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.367&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_merykittyunsafe.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/merykitty"&gt;Quan Anh Mai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/merykittyunsafe.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.507&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gonixunsafe.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gonix"&gt;gonix&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/gonixunsafe.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.557&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_yourwass.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yourwass"&gt;yourwass&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/yourwass.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.820&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_linl33.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;22.ea.32-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/linl33"&gt;Li Lin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/linl33.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.995&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_tivrfoa.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tivrfoa"&gt;tivrfoa&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/tivrfoa.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.997&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gonix.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gonix"&gt;gonix&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/gonix.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.095&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JamalMulla.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JamalMulla"&gt;Jamal Mulla&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/JamalMulla.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.210&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_merykitty.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/merykitty"&gt;Quan Anh Mai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/merykitty.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.298&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_vemanaNonIdiomatic.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vemana"&gt;Subrahmanyam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/vemanaNonIdiomatic.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.431&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_roman_r_m.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/roman-r-m"&gt;Roman Musin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/roman_r_m.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.469&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ebarlas.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ebarlas"&gt;Elliot Barlas&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/ebarlas.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.698&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_hundredwatt.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/hundredwatt"&gt;Jason Nochlin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/hundredwatt.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.785&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_zerninv.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/zerninv"&gt;zerninv&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/zerninv.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.820&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_iziamos.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/iziamos"&gt;John Ziamos&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/iziamos.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.902&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jparera.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jparera"&gt;Juan Parera&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/jparera.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.966&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jincongho.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jincongho"&gt;Jin Cong Ho&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/jincongho.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.991&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_vaidhy.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vaidhy"&gt;Vaidhy Mayilrangam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/vaidhy.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.066&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JesseVanRooy.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JesseVanRooy"&gt;JesseVanRooy&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/JesseVanRooy.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.101&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JaimePolidura.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JaimePolidura"&gt;Jaime Polidura&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/JaimePolidura.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.209&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_giovannicuccu.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/giovannicuccu"&gt;Giovanni Cuccu&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/giovannicuccu.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.474&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gamlerhart.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gamlerhart"&gt;Roman Stoffel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/gamlerhart.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.676&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_plevart.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-tem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/plevart"&gt;Peter Levart&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/plevart.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.684&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gigiblender.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gigiblender"&gt;Florin Blanaru&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/gigiblender.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.701&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ianopolousfast.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ianopolousfast"&gt;Dr Ian Preston&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/ianopolousfast.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.741&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_cliffclick.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/cliffclick"&gt;Cliff Click&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/cliffclick.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.800&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_parkertimmins.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/parkertimmins"&gt;Parker Timmins&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/parkertimmins.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.884&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_shipilev.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/shipilev"&gt;Aleksey ShipilÃ«v&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/shipilev.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.920&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_vemana.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vemana"&gt;Subrahmanyam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/vemana.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.077&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jonathanaotearoa.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jonathan-aotearoa"&gt;Jonathan Wright&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/jonathanaotearoa.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.142&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_arjenw.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/arjenw"&gt;Arjen Wisse&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/arjenw.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.167&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_melgenek.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/melgenek"&gt;Yevhenii Melnyk&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/melgenek.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.235&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_unbounded.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/unbounded"&gt;unbounded&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/unbounded.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.336&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_EduardoSaverin.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/EduardoSaverin"&gt;Sumit Chaudhary&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/EduardoSaverin.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.354&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_armandino.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/armandino"&gt;Arman Sharif&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/armandino.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.478&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_obourgain.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/obourgain"&gt;Olivier Bourgain&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/obourgain.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.559&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_PanagiotisDrakatos.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/PanagiotisDrakatos"&gt;Panagiotis Drakatos&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/PanagiotisDrakatos.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.887&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_charlibot.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/charlibot"&gt;Charlie Evans&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/charlibot.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.979&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_spullara.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/spullara"&gt;Sam Pullara&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/spullara.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.166&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_isolgpus.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/isolgpus"&gt;Jamie Stansfield&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/isolgpus.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.257&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_flippingbits.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/flippingbits"&gt;Stefan Sprenger&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/flippingbits.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.392&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_dpsoft.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/dpsoft"&gt;Diego Parra&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/dpsoft.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.576&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_as-com.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/as-com"&gt;Andrew Sun&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/as-com.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.635&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_justplainlaake.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/justplainlaake"&gt;Laake Scates-Gervasi&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/justplainlaake.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.654&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jbachorik.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jbachorik"&gt;Jaroslav Bachorik&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/jbachorik.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.715&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_algirdasrascius.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/algirdasrascius"&gt;Algirdas RaÅ¡Äius&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/algirdasrascius.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.884&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_rcasteltrione.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/rcasteltrione"&gt;rcasteltrione&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/rcasteltrione.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.982&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ChrisBellew.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ChrisBellew"&gt;Chris Bellew&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/ChrisBellew.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.563&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_3j5a.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/3j5a"&gt;3j5a&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/3j5a.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.680&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_C5H12O5.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/C5H12O5"&gt;Xylitol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/C5H12O5.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.712&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_anitasv.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/anitasv"&gt;Anita SV&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/anitasv.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.730&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jotschi.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jotschi"&gt;Johannes SchÃ¼th&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/jotschi.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.894&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_tonivade.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-tem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tonivade"&gt;Antonio MuÃ±oz&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/tonivade.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.925&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ricardopieper.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ricardopieper"&gt;Ricardo Pieper&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/ricardopieper.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.948&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_Smoofie.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Smoofie"&gt;Smoofie&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/Smoofie.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.157&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JurenIvan.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JurenIvan"&gt;JurenIvan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/JurenIvan.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.167&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ddimtirov.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-tem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ddimtirov"&gt;Dimitar Dimitrov&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/ddimtirov.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.214&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_deemkeen.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/deemkeen"&gt;deemkeen&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/deemkeen.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.255&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_mattiz.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mattiz"&gt;Mathias Bjerke&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/mattiz.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.398&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_artpar.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/artpar"&gt;Parth Mudgal&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/artpar.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.489&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gnabyl.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gnabyl"&gt;Bang NGUYEN&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/gnabyl.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.517&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ags313.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ags313"&gt;ags&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/ags313.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.557&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_adriacabeza.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/adriacabeza"&gt;AdriÃ  Cabeza&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/adriacabeza.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.622&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_kuduwa_keshavram.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kuduwa-keshavram"&gt;Keshavram Kuduwa&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/kuduwa_keshavram.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.892&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_fatroom.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/fatroom"&gt;Roman Romanchuk&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/fatroom.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.896&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_anestoruk.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/anestoruk"&gt;Andrzej Nestoruk&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/anestoruk.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:09.020&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_yemreinci.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yemreinci"&gt;yemreinci&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/yemreinci.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:09.071&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gabrielreid.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gabrielreid"&gt;Gabriel Reid&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/gabrielreid.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:09.352&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_filiphr.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/filiphr"&gt;Filip Hrisafov&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/filiphr.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:09.725&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_martin2038.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/martin2038"&gt;Martin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/martin2038.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:09.867&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ricardopieper.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ricardopieper"&gt;Ricardo Pieper&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/ricardopieper.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:09.945&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_japplis.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/japplis"&gt;Anthony Goubard&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/japplis.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:10.092&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_phd3.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/phd3"&gt;Pratham&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/phd3.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:10.127&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_artpar.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/artpar"&gt;Parth Mudgal&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/artpar.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.577&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_netrunnereve.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/netrunnereve"&gt;Eve&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/netrunnereve.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:10.473&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_raipc.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/raipc"&gt;Anton Rybochkin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/raipc.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.119&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_lawrey.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lawrey"&gt;lawrey&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/lawrey.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.156&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_YannMoisan.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/YannMoisan"&gt;Yann Moisan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/YannMoisan.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.167&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_palmr.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/palmr"&gt;Nick Palmer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/palmr.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.352&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_karthikeyan97.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/karthikeyan97"&gt;karthikeyan97&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/karthikeyan97.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.363&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_godofwharf.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-tem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/godofwharf"&gt;Guruprasad Sridharan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/godofwharf.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.405&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_imrafaelmerino.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/imrafaelmerino"&gt;Rafael Merino GarcÃ­a&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/imrafaelmerino.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.406&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gabrielfoo.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gabrielfoo"&gt;gabrielfoo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/gabrielfoo.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.433&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jatingala.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jatingala"&gt;Jatin Gala&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/jatingala.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.505&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_bufistov.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/dmitry-midokura"&gt;Dmitry Bufistov&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/bufistov.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.744&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_slovdahl.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-tem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/slovdahl"&gt;Sebastian LÃ¶vdahl&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/slovdahl.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.805&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_coolmineman.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/coolmineman"&gt;Cool_Mineman&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/coolmineman.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.934&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_arjenvaneerde.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/arjenvaneerde"&gt;arjenvaneerde&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/arjenvaneerde.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:12.220&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_richardstartin.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/richardstartin"&gt;Richard Startin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/richardstartin.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:12.495&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_SamuelYvon.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/SamuelYvon"&gt;Samuel Yvon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/SamuelYvon.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:12.568&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_MeanderingProgrammer.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MeanderingProgrammer"&gt;Vlad&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/MeanderingProgrammer.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:12.800&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_yonatang.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yonatang"&gt;Yonatan Graber&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/yonatang.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:13.013&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_thanhtrinity.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/thanhtrinity"&gt;Thanh Duong&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/thanhtrinity.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:13.071&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ianopolous.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ianopolous"&gt;Dr Ian Preston&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/ianopolous.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:13.729&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_cb0s.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/cb0s"&gt;Cedric Boes&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/cb0s.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:13.817&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_entangled90.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/entangled90"&gt;Carlo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/entangled90.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:14.502&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_eriklumme.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/eriklumme"&gt;eriklumme&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/eriklumme.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:14.772&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_kevinmcmurtrie.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kevinmcmurtrie"&gt;Kevin McMurtrie&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/kevinmcmurtrie.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:14.867&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_berry120.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/berry120"&gt;Michael Berry&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/berry120.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:14.900&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_Judekeyser.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Judekeyser"&gt;Judekeyser&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/Judekeyser.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:15.006&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_PawelAdamski.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/PawelAdamski"&gt;PaweÅ‚ Adamski&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/PawelAdamski.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:15.662&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_semotpan.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/semotpan"&gt;Serghei Motpan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/semotpan.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:16.063&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_makohn.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/makohn"&gt;Marek Kohn&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/makohn.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:16.457&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_bytesfellow.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/bytesfellow"&gt;Aleksei&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/bytesfellow.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:16.953&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gauravdeshmukh.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gauravdeshmukh"&gt;Gaurav Anantrao Deshmukh&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/gauravdeshmukh.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:17.046&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_dkarampi.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/dkarampi"&gt;Dimitris Karampinas&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/dkarampi.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:17.086&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_breejesh.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/breejesh"&gt;Breejesh Rathod&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/breejesh.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:17.490&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_kgeri.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kgeri"&gt;Gergely Kiss&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/kgeri.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:17.255&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_tkosachev.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tkosachev"&gt;tkosachev&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/tkosachev.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:17.520&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_faridtmammadov.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/faridtmammadov"&gt;Farid&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/faridtmammadov.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:17.717&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_omarchenko4j.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/omarchenko4j"&gt;Oleh Marchenko&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/omarchenko4j.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:17.815&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_hallvard.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/hallvard"&gt;Hallvard TrÃ¦tteberg&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/hallvard.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:17.932&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_plbpietrz.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/plbpietrz"&gt;BartÅ‚omiej Pietrzyk&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/plbpietrz.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:18.251&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_seijikun.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/seijikun"&gt;Markus Ebner&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/seijikun.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:18.448&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_moysesb.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/moysesb"&gt;MoysÃ©s Borges Furtado&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/moysesb.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:18.771&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_davecom.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/davecom"&gt;David Kopec&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/davecom.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:18.902&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_maximz101.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/maximz101"&gt;Maxime&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/maximz101.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:19.357&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_truelive.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graalce&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/truelive"&gt;Roman Schweitzer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/truelive.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:20.691&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_Kidlike.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Kidlike"&gt;Kidlike&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/Kidlike.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:21.989&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_couragelee.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/couragelee"&gt;couragelee&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/couragelee.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:22.188&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jgrateron.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jgrateron"&gt;Jairo GraterÃ³n&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/jgrateron.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:22.334&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_albertoventurini.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/albertoventurini"&gt;Alberto Venturini&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/albertoventurini.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:22.457&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_rby.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/rby"&gt;Ramzi Ben Yahya&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/rby.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:22.471&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_0xshivamagarwal.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/0xshivamagarwal"&gt;Shivam Agarwal&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/0xshivamagarwal.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:24.986&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_kumarsaurav123.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kumarsaurav123"&gt;kumarsaurav123&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/kumarsaurav123.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:25.064&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_sudhirtumati.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/sudhirtumati"&gt;Sudhir Tumati&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/sudhirtumati.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:26.500&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_felix19350.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/felix19350"&gt;Bruno FÃ©lix&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/felix19350.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:28.381&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_bjhara.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/bjhara"&gt;Hampus&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/bjhara.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:29.741&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_xpmatteo.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/xpmatteo"&gt;Matteo Vaccari&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/xpmatteo.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:32.018&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_padreati.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/padreati"&gt;Aurelian Tutuianu&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/padreati.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:34.388&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_twobiers.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-tem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/twobiers"&gt;Tobi&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/twobiers.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:35.875&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_MahmoudFawzyKhalil.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MahmoudFawzyKhalil"&gt;MahmoudFawzyKhalil&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/MahmoudFawzyKhalil.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:36.180&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_hchiorean.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/hchiorean"&gt;Horia Chiorean&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/hchiorean.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:36.424&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_manishgarg90.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/manishgarg90"&gt;Manish Garg&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/manishgarg90.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:38.340&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_AbstractKamen.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/AbstractKamen"&gt;AbstractKamen&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/AbstractKamen.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:41.982&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_criccomini.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/criccomini"&gt;Chris Riccomini&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/criccomini.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:42.893&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_javamak.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/javamak"&gt;javamak&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/javamak.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:46.597&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_maeda6uiui.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/maeda6uiui"&gt;Maeda-san&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/maeda6uiui.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:58.811&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_Ujjwalbharti.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Ujjwalbharti"&gt;Ujjwal Bharti&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/Ujjwalbharti.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:05.094&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_muditsaxena.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mudit-saxena"&gt;Mudit Saxena&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/muditsaxena.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:05.979&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_dqhieuu.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/dqhieuu"&gt;Hieu Dao Quang&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/dqhieuu.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:06.790&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_khmarbaise.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/khmarbaise"&gt;Karl Heinz Marbaise&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/khmarbaise.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:06.944&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_santanu.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/santanu"&gt;santanu&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/santanu.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:07.014&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_pedestrianlove.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/pedestrianlove"&gt;pedestrianlove&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/pedestrianlove.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:07.101&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jeevjyot.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jeevjyot"&gt;Jeevjyot Singh Chhabda&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/jeevjyot.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:08.811&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_alesj.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/alesj"&gt;AleÅ¡ Justin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/alesj.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:08.908&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_itaske.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/itaske"&gt;itaske&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/itaske.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:09.595&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_agoncal.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-tem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/agoncal"&gt;Antonio Goncalves&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/agoncal.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:09.882&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_rprabhu.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/rprabhu"&gt;Prabhu R&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/rprabhu.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:14.815&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_anandmattikopp.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/anandmattikopp"&gt;twohardthings&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/anandmattikopp.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:25.801&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ivanklaric.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ivanklaric"&gt;ivanklaric&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/ivanklaric.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:33.594&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gnmathur.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gnmathur"&gt;Gaurav Mathur&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/gnmathur.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:53.208&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_mahadev_k.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mahadev-k"&gt;Mahadev K&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/mahadev_k.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;01:56.607&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_abfrmblr.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/abfrmblr"&gt;Abhilash&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/abfrmblr.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;03:43.521&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_yehwankim23.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yehwankim23"&gt;ê¹€ì˜ˆí™˜ Ye-Hwan Kim (Sam)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/yehwankim23.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;03:59.760&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_fragmede.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/fragmede"&gt;Samson&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://gunnarmorling.github.io/1brc-certificates/fragmede.pdf"&gt;Certificate&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;04:49.679&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_baseline.java"&gt;link&lt;/a&gt; (Baseline)&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling"&gt;Gunnar Morling&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Note that I am not super-scientific in the way I'm running the contenders (see &lt;a href="https://raw.githubusercontent.com/gunnarmorling/1brc/main/#evaluating-results"&gt;Evaluating Results&lt;/a&gt; for the details). This is not a high-fidelity micro-benchmark and there can be variations of up to +-3% between runs. So don't be too hung up on the exact ordering of your entry compared to others in close proximity. The primary purpose of this challenge is to learn something new, have fun along the way, and inspire others to do the same. The leaderboard is only means to an end for achieving this goal. If you observe drastically different results though, please open an issue.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/gunnarmorling/1brc/main/#entering-the-challenge"&gt;Entering the Challenge&lt;/a&gt; for instructions how to enter the challenge with your own implementation. The &lt;a href="https://github.com/gunnarmorling/1brc/discussions/categories/show-and-tell"&gt;Show &amp;amp; Tell&lt;/a&gt; features a wide range of 1BRC entries built using other languages, databases, and tools.&lt;/p&gt; 
&lt;h3&gt;Bonus Results&lt;/h3&gt; 
&lt;p&gt;This section lists results from running the fastest N entries with different configurations. As entries have been optimized towards the specific conditions of the original challenge description and set-up (such as size of the key set), challenge entries may perform very differently across different configurations. These bonus results are provided here for informational purposes only. For the 1BRC challenge, only the results in the previous section are of importance.&lt;/p&gt; 
&lt;h4&gt;32 Cores / 64 Threads&lt;/h4&gt; 
&lt;p&gt;For officially evaluating entries into the challenge, each contender is run on eight cores of the evaluation machine (AMD EPYCâ„¢ 7502P). Here are the results from running the top 50 entries (as of commit &lt;a href="https://github.com/gunnarmorling/1brc/commit/e1fb378acce53d8c3035ee4813ae377aaf51aa3c"&gt;e1fb378a&lt;/a&gt;, Feb 2) on all 32 cores / 64 threads (i.e. SMT is enabled) of the machine:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Result (m:s.ms)&lt;/th&gt; 
   &lt;th&gt;Implementation&lt;/th&gt; 
   &lt;th&gt;JDK&lt;/th&gt; 
   &lt;th&gt;Submitter&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;00:00.323&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jerrinot.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jerrinot"&gt;Jaromir Hamala&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;00:00.326&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_thomaswue.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/thomaswue"&gt;Thomas Wuerthinger&lt;/a&gt;, &lt;a href="https://github.com/merykitty"&gt;Quan Anh Mai&lt;/a&gt;, &lt;a href="https://github.com/mukel"&gt;AlfonsoÂ² Peterssen&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;00:00.349&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_artsiomkorzun.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/artsiomkorzun"&gt;Artsiom Korzun&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.351&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_abeobk.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/abeobk"&gt;Van Phu DO&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.389&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_stephenvonworley.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/stephenvonworley"&gt;Stephen Von Worley&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.408&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_yavuztas.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yavuztas"&gt;Yavuz Tas&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.415&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_royvanrijn.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/royvanrijn"&gt;Roy van Rijn&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.499&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_mtopolnik.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mtopolnik"&gt;Marko Topolnik&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.602&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_roman_r_m.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/roman-r-m"&gt;Roman Musin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.623&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gonixunsafe.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gonixunsafe"&gt;gonix&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.710&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JamalMulla.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JamalMulla"&gt;Jamal Mulla&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.727&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_tivrfoa.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tivrfoa"&gt;tivrfoa&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.774&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_serkan_ozal.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/serkan-ozal"&gt;Serkan Ã–ZAL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.788&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ebarlas.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ebarlas"&gt;Elliot Barlas&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.832&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_zerninv.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/zerninv"&gt;zerninv&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.840&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gonix.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gonix"&gt;gonix&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.857&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JaimePolidura.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JaimePolidura"&gt;Jaime Polidura&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.880&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_iziamos.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/iziamos"&gt;John Ziamos&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:00.939&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_shipilev.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/shipilev"&gt;Aleksey ShipilÃ«v&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.026&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JesseVanRooy.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JesseVanRooy"&gt;JesseVanRooy&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.118&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jonathanaotearoa.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jonathan-aotearoa"&gt;Jonathan Wright&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.140&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_armandino.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/armandino"&gt;Arman Sharif&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.143&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_cliffclick.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/cliffclick"&gt;Cliff Click&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.169&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_melgenek.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/melgenek"&gt;Yevhenii Melnyk&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.188&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_vemanaNonIdiomatic.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vemanaNonIdiomatic"&gt;Subrahmanyam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.193&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gigiblender.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gigiblender"&gt;Florin Blanaru&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.234&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_obourgain.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/obourgain"&gt;Olivier Bourgain&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.242&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_merykittyunsafe.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/merykittyunsafe"&gt;Quan Anh Mai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.252&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jincongho.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jincongho"&gt;Jin Cong Ho&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.267&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_linl33.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;22.ea.32-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/linl33"&gt;Li Lin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.363&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_plevart.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-tem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/plevart"&gt;Peter Levart&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.380&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_hundredwatt.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/hundredwatt"&gt;Jason Nochlin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.391&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_merykitty.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/merykitty"&gt;Quan Anh Mai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.439&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_arjenw.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/arjenw"&gt;Arjen Wisse&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.446&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ianopolousfast.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ianopolousfast"&gt;Dr Ian Preston&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.504&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_isolgpus.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/isolgpus"&gt;Jamie Stansfield&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.514&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_vemana.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vemana"&gt;Subrahmanyam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.516&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_vaidhy.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vaidhy"&gt;Vaidhy Mayilrangam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.586&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_yourwass.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yourwass"&gt;yourwass&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.647&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_dpsoft.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/dpsoft"&gt;Diego Parra&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.694&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_parkertimmins.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/parkertimmins"&gt;Parker Timmins&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.694&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_charlibot.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/charlibot"&gt;Charlie Evans&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.702&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_spullara.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/spullara"&gt;Sam Pullara&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.733&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_EduardoSaverin.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;java&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/EduardoSaverin"&gt;Sumit Chaudhary&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:01.742&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_unbounded.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/unbounded"&gt;unbounded&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.241&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_flippingbits.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/flippingbits"&gt;Stefan Sprenger&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.294&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_giovannicuccu.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/giovannicuccu"&gt;Giovanni Cuccu&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:02.990&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_PanagiotisDrakatos.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/PanagiotisDrakatos"&gt;Panagiotis Drakatos&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.205&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jparera.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jparera"&gt;Juan Parera&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:10.929&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gamlerhart.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gamlerhart"&gt;Roman Stoffel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;10K Key Set&lt;/h4&gt; 
&lt;p&gt;The 1BRC challenge data set contains 413 distinct weather stations, whereas the rules allow for 10,000 different station names to occur. Here are the results from running the top 40 entries (as of commit &lt;a href="https://github.com/gunnarmorling/1brc/commit/e1fb378acce53d8c3035ee4813ae377aaf51aa3c"&gt;e1fb378a&lt;/a&gt;, Feb 2) against 1,000,000,000 measurement values across 10K stations (created via &lt;em&gt;./create_measurements3.sh 1000000000&lt;/em&gt;), using eight cores on the evaluation machine:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Result (m:s.ms)&lt;/th&gt; 
   &lt;th&gt;Implementation&lt;/th&gt; 
   &lt;th&gt;JDK&lt;/th&gt; 
   &lt;th&gt;Submitter&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;00:02.957&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_artsiomkorzun.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/artsiomkorzun"&gt;Artsiom Korzun&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;00:03.058&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_mtopolnik.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mtopolnik"&gt;Marko Topolnik&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;00:03.186&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_stephenvonworley.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/stephenvonworley"&gt;Stephen Von Worley&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:03.998&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_royvanrijn.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/royvanrijn"&gt;Roy van Rijn&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.042&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jerrinot.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jerrinot"&gt;Jaromir Hamala&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.289&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gonixunsafe.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gonixunsafe"&gt;gonix&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.522&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_tivrfoa.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tivrfoa"&gt;tivrfoa&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.653&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JamalMulla.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JamalMulla"&gt;Jamal Mulla&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.733&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gonix.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gonix"&gt;gonix&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.836&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_vemanaNonIdiomatic.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vemanaNonIdiomatic"&gt;Subrahmanyam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:04.870&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_thomaswue.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/thomaswue"&gt;Thomas Wuerthinger&lt;/a&gt;, &lt;a href="https://github.com/merykitty"&gt;Quan Anh Mai&lt;/a&gt;, &lt;a href="https://github.com/mukel"&gt;AlfonsoÂ² Peterssen&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.240&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_zerninv.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/zerninv"&gt;zerninv&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.394&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_yavuztas.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yavuztas"&gt;Yavuz Tas&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:05.906&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ebarlas.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ebarlas"&gt;Elliot Barlas&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.086&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_abeobk.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/abeobk"&gt;Van Phu DO&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:06.379&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_iziamos.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/iziamos"&gt;John Ziamos&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.113&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_melgenek.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/melgenek"&gt;Yevhenii Melnyk&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.542&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jonathan-aotearoa.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jonathan-aotearoa"&gt;Jonathan Wright&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.889&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gigiblender.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gigiblender"&gt;Florin Blanaru&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:07.970&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_cliffclick.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/cliffclick"&gt;Cliff Click&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:08.857&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_serkan-ozal.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/serkan-ozal"&gt;Serkan Ã–ZAL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:09.333&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_yourwass.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yourwass"&gt;yourwass&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:09.722&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_shipilev.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/shipilev"&gt;Aleksey ShipilÃ«v&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:09.777&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_vaidhy.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vaidhy"&gt;Vaidhy Mayilrangam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:10.263&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_merykittyunsafe.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/merykittyunsafe"&gt;Quan Anh Mai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:11.154&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_parkertimmins.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/parkertimmins"&gt;Parker Timmins&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:13.175&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_merykitty.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/merykitty"&gt;Quan Anh Mai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:13.245&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_ianopolousfast.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ianopolousfast"&gt;Dr Ian Preston&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:13.377&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_giovannicuccu.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/giovannicuccu"&gt;Giovanni Cuccu&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:13.761&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jparera.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jparera"&gt;Juan Parera&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:14.441&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_plevart.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-tem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/plevart"&gt;Peter Levart&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:15.548&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_jincongho.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jincongho"&gt;Jin Cong Ho&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:17.906&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_hundredwatt.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/hundredwatt"&gt;Jason Nochlin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:18.770&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_linl33.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;22.ea.32-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/linl33"&gt;Li Lin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:19.106&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_gamlerhart.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gamlerhart"&gt;Roman Stoffel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:20.151&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_roman_r_m.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/roman-r-m"&gt;Roman Musin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe; seg-faults occassionally&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;00:22.953&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JaimePolidura.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.2-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JaimePolidura"&gt;Jaime Polidura&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GraalVM native binary, uses Unsafe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;DNF&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_JesseVanRooy.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/JesseVanRooy"&gt;JesseVanRooy&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Incorrect output&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;DNF&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_vemana.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-graal&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vemana"&gt;Subrahmanyam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Doesn't complete in 60 sec&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;DNF&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gunnarmorling/1brc/raw/main/src/main/java/dev/morling/onebrc/CalculateAverage_arjenw.java"&gt;link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;21.0.1-open&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/arjenw"&gt;Arjen Wisse&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Incorrect output&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://openjdk.org/projects/jdk/21/"&gt;Java 21&lt;/a&gt; must be installed on your system.&lt;/p&gt; 
&lt;h2&gt;Running the Challenge&lt;/h2&gt; 
&lt;p&gt;This repository contains two programs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;dev.morling.onebrc.CreateMeasurements&lt;/code&gt; (invoked via &lt;em&gt;create_measurements.sh&lt;/em&gt;): Creates the file &lt;em&gt;measurements.txt&lt;/em&gt; in the root directory of this project with a configurable number of random measurement values&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dev.morling.onebrc.CalculateAverage&lt;/code&gt; (invoked via &lt;em&gt;calculate_average_baseline.sh&lt;/em&gt;): Calculates the average values for the file &lt;em&gt;measurements.txt&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Execute the following steps to run the challenge:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Build the project using Apache Maven:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./mvnw clean verify
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the measurements file with 1B rows (just once):&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./create_measurements.sh 1000000000
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will take a few minutes. &lt;strong&gt;Attention:&lt;/strong&gt; the generated file has a size of approx. &lt;strong&gt;12 GB&lt;/strong&gt;, so make sure to have enough diskspace.&lt;/p&gt; &lt;p&gt;If you're running the challenge with a non-Java language, there's a non-authoritative Python script to generate the measurements file at &lt;code&gt;src/main/python/create_measurements.py&lt;/code&gt;. The authoritative method for generating the measurements is the Java program &lt;code&gt;dev.morling.onebrc.CreateMeasurements&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Calculate the average measurement values:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./calculate_average_baseline.sh
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The provided naive example implementation uses the Java streams API for processing the file and completes the task in ~2 min on environment used for &lt;a href="https://raw.githubusercontent.com/gunnarmorling/1brc/main/#evaluating-results"&gt;result evaluation&lt;/a&gt;. It serves as the base line for comparing your own implementation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Optimize the heck out of it:&lt;/p&gt; &lt;p&gt;Adjust the &lt;code&gt;CalculateAverage&lt;/code&gt; program to speed it up, in any way you see fit (just sticking to a few rules described below). Options include parallelizing the computation, using the (incubating) Vector API, memory-mapping different sections of the file concurrently, using AppCDS, GraalVM, CRaC, etc. for speeding up the application start-up, choosing and tuning the garbage collector, and much more.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Flamegraph/Profiling&lt;/h2&gt; 
&lt;p&gt;A tip is that if you have &lt;a href="https://jbang.dev"&gt;jbang&lt;/a&gt; installed, you can get a flamegraph of your program by running &lt;a href="https://github.com/jvm-profiling-tools/async-profiler"&gt;async-profiler&lt;/a&gt; via &lt;a href="https://github.com/jvm-profiling-tools/ap-loader"&gt;ap-loader&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;jbang --javaagent=ap-loader@jvm-profiling-tools/ap-loader=start,event=cpu,file=profile.html -m dev.morling.onebrc.CalculateAverage_yourname target/average-1.0.0-SNAPSHOT.jar&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or directly on the .java file:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;jbang --javaagent=ap-loader@jvm-profiling-tools/ap-loader=start,event=cpu,file=profile.html src/main/java/dev/morling/onebrc/CalculateAverage_yourname&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;When you run this, it will generate a flamegraph in profile.html. You can then open this in a browser and see where your program is spending its time.&lt;/p&gt; 
&lt;h2&gt;Rules and limits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Any of these Java distributions may be used: 
  &lt;ul&gt; 
   &lt;li&gt;Any builds provided by &lt;a href="https://sdkman.io/jdks"&gt;SDKMan&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Early access builds available on openjdk.net may be used (including EA builds for OpenJDK projects like Valhalla)&lt;/li&gt; 
   &lt;li&gt;Builds on &lt;a href="https://builds.shipilev.net/openjdk-jdk-lilliput/"&gt;builds.shipilev.net&lt;/a&gt; If you want to use a build not available via these channels, reach out to discuss whether it can be considered.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;No external library dependencies may be used&lt;/li&gt; 
 &lt;li&gt;Implementations must be provided as a single source file&lt;/li&gt; 
 &lt;li&gt;The computation must happen at application &lt;em&gt;runtime&lt;/em&gt;, i.e. you cannot process the measurements file at &lt;em&gt;build time&lt;/em&gt; (for instance, when using GraalVM) and just bake the result into the binary&lt;/li&gt; 
 &lt;li&gt;Input value ranges are as follows: 
  &lt;ul&gt; 
   &lt;li&gt;Station name: non null UTF-8 string of min length 1 character and max length 100 bytes, containing neither &lt;code&gt;;&lt;/code&gt; nor &lt;code&gt;\n&lt;/code&gt; characters. (i.e. this could be 100 one-byte characters, or 50 two-byte characters, etc.)&lt;/li&gt; 
   &lt;li&gt;Temperature value: non null double between -99.9 (inclusive) and 99.9 (inclusive), always with one fractional digit&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;There is a maximum of 10,000 unique station names&lt;/li&gt; 
 &lt;li&gt;Line endings in the file are &lt;code&gt;\n&lt;/code&gt; characters on all platforms&lt;/li&gt; 
 &lt;li&gt;Implementations must not rely on specifics of a given data set, e.g. any valid station name as per the constraints above and any data distribution (number of measurements per station) must be supported&lt;/li&gt; 
 &lt;li&gt;The rounding of output values must be done using the semantics of IEEE 754 rounding-direction "roundTowardPositive"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Entering the Challenge&lt;/h2&gt; 
&lt;p&gt;To submit your own implementation to 1BRC, follow these steps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a fork of the &lt;a href="https://github.com/gunnarmorling/onebrc/"&gt;onebrc&lt;/a&gt; GitHub repository.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;./create_fork.sh &amp;lt;your_GH_user&amp;gt;&lt;/code&gt; to copy the baseline implementation to your personal files, or do this manually: 
  &lt;ul&gt; 
   &lt;li&gt;Create a copy of &lt;em&gt;CalculateAverage_baseline.java&lt;/em&gt;, named &lt;em&gt;CalculateAverage_&amp;lt;your_GH_user&amp;gt;.java&lt;/em&gt;, e.g. &lt;em&gt;CalculateAverage_doloreswilson.java&lt;/em&gt;.&lt;/li&gt; 
   &lt;li&gt;Create a copy of &lt;em&gt;calculate_average_baseline.sh&lt;/em&gt;, named &lt;em&gt;calculate_average_&amp;lt;your_GH_user&amp;gt;.sh&lt;/em&gt;, e.g. &lt;em&gt;calculate_average_doloreswilson.sh&lt;/em&gt;.&lt;/li&gt; 
   &lt;li&gt;Adjust that script so that it references your implementation class name. If needed, provide any JVM arguments via the &lt;code&gt;JAVA_OPTS&lt;/code&gt; variable in that script. Make sure that script does not write anything to standard output other than calculation results.&lt;/li&gt; 
   &lt;li&gt;(Optional) OpenJDK 21 is used by default. If a custom JDK build is required, create a copy of &lt;em&gt;prepare_baseline.sh&lt;/em&gt;, named &lt;em&gt;prepare_&amp;lt;your_GH_user&amp;gt;.sh&lt;/em&gt;, e.g. &lt;em&gt;prepare_doloreswilson.sh&lt;/em&gt;. Include the SDKMAN command &lt;code&gt;sdk use java [version]&lt;/code&gt; in the your prepare script.&lt;/li&gt; 
   &lt;li&gt;(Optional) If you'd like to use native binaries (GraalVM), add all the required build logic to your &lt;em&gt;prepare_&amp;lt;your_GH_user&amp;gt;.sh&lt;/em&gt; script.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Make that implementation fast. Really fast.&lt;/li&gt; 
 &lt;li&gt;Run the test suite by executing &lt;em&gt;/test.sh &amp;lt;your_GH_user&amp;gt;&lt;/em&gt;; if any differences are reported, fix them before submitting your implementation.&lt;/li&gt; 
 &lt;li&gt;Create a pull request against the upstream repository, clearly stating 
  &lt;ul&gt; 
   &lt;li&gt;The name of your implementation class.&lt;/li&gt; 
   &lt;li&gt;The execution time of the program on your system and specs of the same (CPU, number of cores, RAM). This is for informative purposes only, the official runtime will be determined as described below.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;I will run the program and determine its performance as described in the next section, and enter the result to the scoreboard.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I reserve the right to not evaluate specific submissions if I feel doubtful about the implementation (I.e. I won't run your Bitcoin miner ;).&lt;/p&gt; 
&lt;p&gt;If you'd like to discuss any potential ideas for implementing 1BRC with the community, you can use the &lt;a href="https://github.com/gunnarmorling/onebrc/discussions"&gt;GitHub Discussions&lt;/a&gt; of this repository. Please keep it friendly and civil.&lt;/p&gt; 
&lt;p&gt;The challenge runs until Jan 31 2024. Any submissions (i.e. pull requests) created after Jan 31 2024 23:59 UTC will not be considered.&lt;/p&gt; 
&lt;h2&gt;Evaluating Results&lt;/h2&gt; 
&lt;p&gt;Results are determined by running the program on a &lt;a href="https://www.hetzner.com/dedicated-rootserver/ax161"&gt;Hetzner AX161&lt;/a&gt; dedicated server (32 core AMD EPYCâ„¢ 7502P (Zen2), 128 GB RAM).&lt;/p&gt; 
&lt;p&gt;Programs are run from a RAM disk (i.o. the IO overhead for loading the file from disk is not relevant), using 8 cores of the machine. Each contender must pass the 1BRC test suite (&lt;em&gt;/test.sh&lt;/em&gt;). The &lt;code&gt;hyperfine&lt;/code&gt; program is used for measuring execution times of the launch scripts of all entries, i.e. end-to-end times are measured. Each contender is run five times in a row. The slowest and the fastest runs are discarded. The mean value of the remaining three runs is the result for that contender and will be added to the results table above. The exact same &lt;em&gt;measurements.txt&lt;/em&gt; file is used for evaluating all contenders. See the script &lt;em&gt;evaluate.sh&lt;/em&gt; for the exact implementation of the evaluation steps.&lt;/p&gt; 
&lt;h2&gt;Prize&lt;/h2&gt; 
&lt;p&gt;If you enter this challenge, you may learn something new, get to inspire others, and take pride in seeing your name listed in the scoreboard above. Rumor has it that the winner may receive a unique 1ï¸âƒ£ğŸğŸï¸ t-shirt, too!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Q: Can I use Kotlin or other JVM languages other than Java?&lt;/em&gt;&lt;br /&gt; A: No, this challenge is focussed on Java only. Feel free to inofficially share implementations significantly outperforming any listed results, though.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Q: Can I use non-JVM languages and/or tools?&lt;/em&gt;&lt;br /&gt; A: No, this challenge is focussed on Java only. Feel free to inofficially share interesting implementations and results though. For instance it would be interesting to see how DuckDB fares with this task.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Q: I've got an implementationâ€”but it's not in Java. Can I share it somewhere?&lt;/em&gt;&lt;br /&gt; A: Whilst non-Java solutions cannot be formally submitted to the challenge, you are welcome to share them over in the &lt;a href="https://github.com/gunnarmorling/1brc/discussions/categories/show-and-tell"&gt;Show and tell&lt;/a&gt; GitHub discussion area.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Q: Can I use JNI?&lt;/em&gt;&lt;br /&gt; A: Submissions must be completely implemented in Java, i.e. you cannot write JNI glue code in C/C++. You could use AOT compilation of Java code via GraalVM though, either by AOT-compiling the entire application, or by creating a native library (see &lt;a href="https://www.graalvm.org/22.0/reference-manual/native-image/ImplementingNativeMethodsInJavaWithSVM/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Q: What is the encoding of the measurements.txt file?&lt;/em&gt;&lt;br /&gt; A: The file is encoded with UTF-8.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Q: Can I make assumptions on the names of the weather stations showing up in the data set?&lt;/em&gt;&lt;br /&gt; A: No, while only a fixed set of station names is used by the data set generator, any solution should work with arbitrary UTF-8 station names (for the sake of simplicity, names are guaranteed to contain no &lt;code&gt;;&lt;/code&gt; or &lt;code&gt;\n&lt;/code&gt; characters).&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Q: Can I copy code from other submissions?&lt;/em&gt;&lt;br /&gt; A: Yes, you can. The primary focus of the challenge is about learning something new, rather than "winning". When you do so, please give credit to the relevant source submissions. Please don't re-submit other entries with no or only trivial improvements.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Q: Which operating system is used for evaluation?&lt;/em&gt;&lt;br /&gt; A: Fedora 39.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Q: My solution runs in 2 sec on my machine. Am I the fastest 1BRC-er in the world?&lt;/em&gt;&lt;br /&gt; A: Probably not :) 1BRC results are reported in wallclock time, thus results of different implementations are only comparable when obtained on the same machine. If for instance an implementation is faster on a 32 core workstation than on the 8 core evaluation instance, this doesn't allow for any conclusions. When sharing 1BRC results, you should also always share the result of running the baseline implementation on the same hardware.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Q: Why&lt;/em&gt; 1ï¸âƒ£ğŸğŸï¸ &lt;em&gt;?&lt;/em&gt;&lt;br /&gt; A: It's the abbreviation of the project name: &lt;strong&gt;One&lt;/strong&gt; &lt;strong&gt;B&lt;/strong&gt;illion &lt;strong&gt;R&lt;/strong&gt;ow &lt;strong&gt;C&lt;/strong&gt;hallenge.&lt;/p&gt; 
&lt;h2&gt;1BRC on the Web&lt;/h2&gt; 
&lt;p&gt;A list of external resources such as blog posts and videos, discussing 1BRC and specific implementations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.infoq.com/news/2024/01/1brc-fast-java-processing"&gt;The One Billion Row Challenge Shows That Java Can Process a One Billion Rows File in Two Seconds &lt;/a&gt;, by Olimpiu Pop (interview)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=NJNIbgV6j-Y"&gt;Cliff Click discussing his 1BRC solution on the Coffee Compiler Club&lt;/a&gt; (video)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rmoff.net/2024/01/03/1%EF%B8%8F%E2%83%A3%EF%B8%8F-1brc-in-sql-with-duckdb/"&gt;1ï¸âƒ£ğŸğŸï¸ğŸ¦† (1BRC in SQL with DuckDB)&lt;/a&gt;, by Robin Moffatt (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ftisiot.net/posts/1brows/"&gt;1 billion rows challenge in PostgreSQL and ClickHouse&lt;/a&gt;, by Francesco Tisiot (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/snowflake/the-one-billion-row-challenge-with-snowflake-f612ae76dbd5"&gt;The One Billion Row Challenge with Snowflake&lt;/a&gt;, by Sean Falconer (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.r-bloggers.com/2024/01/one-billion-row-challenge-using-base-r/"&gt;One billion row challenge using base R&lt;/a&gt;, by David Schoch (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hubertdulay.substack.com/p/1-billion-row-challenge-in-apache"&gt;1 Billion Row Challenge with Apache Pinot&lt;/a&gt;, by Hubert Dulay (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.dannyvankooten.com/blog/2024/1brc/"&gt;One Billion Row Challenge In C&lt;/a&gt;, by Danny Van Kooten (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://defn.io/2024/01/10/one-billion-row-challenge-in-racket/"&gt;One Billion Row Challenge in Racket&lt;/a&gt;, by Bogdan Popa (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dev.to/mergeconflict/392-the-one-billion-row-challenge-net-edition"&gt;The One Billion Row Challenge - .NET Edition&lt;/a&gt;, by Frank A. Krueger (podcast)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://curiouscoding.nl/posts/1brc/"&gt;One Billion Row Challenge&lt;/a&gt;, by Ragnar Groot Koerkamp (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://clickhouse.com/blog/clickhouse-one-billion-row-challenge"&gt;ClickHouse and The One Billion Row Challenge&lt;/a&gt;, by Dale McDiarmid (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nielsberglund.com/post/2024-01-28-one-billion-row-challenge--azure-data-explorer/"&gt;One Billion Row Challenge &amp;amp; Azure Data Explorer&lt;/a&gt;, by Niels Berglund (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.chashnikov.dev/post/one-billion-row-challenge-view-from-sidelines"&gt;One Billion Row Challenge - view from sidelines&lt;/a&gt;, by Leo Chashnikov (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://geraldonit.com/2024/01/31/1-billion-row-challenge-in-sql-and-oracle-database/"&gt;1 billion row challenge in SQL and Oracle Database&lt;/a&gt;, by Gerald Venzl (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gamlor.info/posts-output/2024-01-12-one-billion-row-challenge/en/"&gt;One Billion Row Challenge: Learned So Far&lt;/a&gt;, by Roman Stoffel (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://defn.io/2024/01/10/one-billion-row-challenge-in-racket/"&gt;One Billion Row Challenge in Racket&lt;/a&gt;, by Bogdan Popa (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@testily/the-1-billion-row-challenge-with-singlestore-224ce97e451f"&gt;The 1 Billion row challenge with Singlestore&lt;/a&gt;, by Anna Semjen (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hotforknowledge.com/2024/01/13/1brc-in-dotnet-among-fastest-on-linux-my-optimization-journey/"&gt;1BRC in .NET among fastest on Linux: My Optimization Journey&lt;/a&gt;, by Victor Baybekov (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://connor-mcdonald.com/2024/02/03/one-billion-rows-geralds-challenge/"&gt;One Billion Rows â€“ Geraldâ€™s Challenge&lt;/a&gt;, by Connor McDonald (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rmannibucau.metawerx.net/reading-a-file-insanely-fast-in-java.html"&gt;Reading a file insanely fast in Java&lt;/a&gt;, by Romain Manni-Bucau (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tivrfoa.github.io/java/benchmark/performance/2024/02/05/1BRC-Timeline.html"&gt;#1BRC Timeline&lt;/a&gt;, by tivrfoa (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.esolutions.tech/1brc-what-a-journey"&gt;1BRC - What a Journey&lt;/a&gt;, by Marius Staicu (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.bytesizego.com/blog/one-billion-row-challenge-go"&gt;One Billion Rows Challenge in Golang&lt;/a&gt;, by Shraddha Agrawal (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://questdb.io/blog/billion-row-challenge-step-by-step/"&gt;The Billion Row Challenge (1BRC) - Step-by-step from 71s to 1.7s&lt;/a&gt; by Marko Topolnik (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devblogs.microsoft.com/java/entering-the-one-billion-row-challenge-with-github-copilot/"&gt;Entering The One Billion Row Challenge With GitHub Copilot&lt;/a&gt; by Antonio Goncalves (blog post)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@zakhav/dataframe-and-one-billion-row-challenge-97b3d0255dd1"&gt;DataFrame and The One Billion Row Challenge--How to use a Java DataFrame to save developer time, produce readable code, and not win any prizes&lt;/a&gt; by Vladimir Zakharov (blog post)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This code base is available under the Apache License, version 2.&lt;/p&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;Be excellent to each other! More than winning, the purpose of this challenge is to have fun and learn something new.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>