<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Sun, 03 Aug 2025 01:40:20 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>cloudwego/eino</title>
      <link>https://github.com/cloudwego/eino</link>
      <description>&lt;p&gt;The ultimate LLM/AI application development framework in Golang.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Eino&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/badges/.badges/main/coverage.svg?sanitize=true" alt="coverage"&gt; &lt;a href="https://github.com/cloudwego/eino/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/cloudwego/eino" alt="Release"&gt;&lt;/a&gt; &lt;a href="https://www.cloudwego.io/"&gt;&lt;img src="https://img.shields.io/website?up_message=cloudwego&amp;amp;url=https%3A%2F%2Fwww.cloudwego.io%2F" alt="WebSite"&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudwego/eino/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/cloudwego/eino" alt="License"&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/cloudwego/eino"&gt;&lt;img src="https://goreportcard.com/badge/github.com/cloudwego/eino" alt="Go Report Card"&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudwego/kitex/eino"&gt;&lt;img src="https://img.shields.io/github/issues/cloudwego/eino" alt="OpenIssue"&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudwego/eino/issues?q=is%3Aissue+is%3Aclosed"&gt;&lt;img src="https://img.shields.io/github/issues-closed/cloudwego/eino" alt="ClosedIssue"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/cloudwego/eino" alt="Stars"&gt; &lt;img src="https://img.shields.io/github/forks/cloudwego/eino" alt="Forks"&gt;&lt;/p&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/cloudwego/eino/main/README.zh_CN.md"&gt;中文&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Eino['aino]&lt;/strong&gt; (pronounced similarly to "I know") aims to be the ultimate LLM application development framework in Golang. Drawing inspirations from many excellent LLM application development frameworks in the open-source community such as LangChain &amp;amp; LlamaIndex, etc., as well as learning from cutting-edge research and real world applications, Eino offers an LLM application development framework that emphasizes on simplicity, scalability, reliability and effectiveness that better aligns with Golang programming conventions.&lt;/p&gt; 
&lt;p&gt;What Eino provides are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a carefully curated list of &lt;strong&gt;component&lt;/strong&gt; abstractions and implementations that can be easily reused and combined to build LLM applications&lt;/li&gt; 
 &lt;li&gt;a powerful &lt;strong&gt;composition&lt;/strong&gt; framework that does the heavy lifting of strong type checking, stream processing, concurrency management, aspect injection, option assignment, etc. for the user.&lt;/li&gt; 
 &lt;li&gt;a set of meticulously designed &lt;strong&gt;API&lt;/strong&gt; that obsesses on simplicity and clarity.&lt;/li&gt; 
 &lt;li&gt;an ever-growing collection of best practices in the form of bundled &lt;strong&gt;flows&lt;/strong&gt; and &lt;strong&gt;examples&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;a useful set of tools that covers the entire development cycle, from visualized development and debugging to online tracing and evaluation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With the above arsenal, Eino can standardize, simplify, and improve efficiency at different stages of the AI application development cycle: &lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/eino_concept.jpeg" alt=""&gt;&lt;/p&gt; 
&lt;h1&gt;A quick walkthrough&lt;/h1&gt; 
&lt;p&gt;Use a component directly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;model, _ := openai.NewChatModel(ctx, config) // create an invokable LLM instance
message, _ := model.Generate(ctx, []*Message{
    SystemMessage("you are a helpful assistant."),
    UserMessage("what does the future AI App look like?")})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Of course, you can do that, Eino provides lots of useful components to use out of the box. But you can do more by using orchestration, for three reasons:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;orchestration encapsulates common patterns of LLM application.&lt;/li&gt; 
 &lt;li&gt;orchestration solves the difficult problem of processing stream response by the LLM.&lt;/li&gt; 
 &lt;li&gt;orchestration handles type safety, concurrency management, aspect injection and option assignment for you.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Eino provides two set of APIs for orchestration&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th&gt;Characteristics and usage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chain&lt;/td&gt; 
   &lt;td&gt;Simple chained directed graph that can only go forward.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Graph&lt;/td&gt; 
   &lt;td&gt;Cyclic or Acyclic directed graph. Powerful and flexible.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Let's create a simple chain: a ChatTemplate followed by a ChatModel.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/simple_chain.png" alt=""&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;chain, _ := NewChain[map[string]any, *Message]().
           AppendChatTemplate(prompt).
           AppendChatModel(model).
           Compile(ctx)

chain.Invoke(ctx, map[string]any{"query": "what's your name?"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now let's create a graph that uses a ChatModel to generate answer or tool calls, then uses a ToolsNode to execute those tools if needed.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/tool_call_graph.png" alt=""&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;graph := NewGraph[map[string]any, *schema.Message]()

_ = graph.AddChatTemplateNode("node_template", chatTpl)
_ = graph.AddChatModelNode("node_model", chatModel)
_ = graph.AddToolsNode("node_tools", toolsNode)
_ = graph.AddLambdaNode("node_converter", takeOne)

_ = graph.AddEdge(START, "node_template")
_ = graph.AddEdge("node_template", "node_model")
_ = graph.AddBranch("node_model", branch)
_ = graph.AddEdge("node_tools", "node_converter")
_ = graph.AddEdge("node_converter", END)

compiledGraph, err := graph.Compile(ctx)
if err != nil {
return err
}
out, err := r.Invoke(ctx, map[string]any{"query":"Beijing's weather this weekend"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now let's create a 'ReAct' agent: A ChatModel binds to Tools. It receives input Messages and decides independently whether to call the Tool or output the final result. The execution result of the Tool will again become the input Message for the ChatModel and serve as the context for the next round of independent judgment.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/react.png" alt=""&gt;&lt;/p&gt; 
&lt;p&gt;We provide a complete implementation for ReAct Agent out of the box in the &lt;code&gt;flow&lt;/code&gt; package. Check out the code here: &lt;a href="https://github.com/cloudwego/eino/raw/main/flow/agent/react/react.go"&gt;flow/agent/react&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Our implementation of ReAct Agent uses Eino's &lt;strong&gt;graph orchestration&lt;/strong&gt; exclusively, which provides the following benefits out of the box:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Type checking: it makes sure the two nodes' input and output types match at compile time.&lt;/li&gt; 
 &lt;li&gt;Stream processing: concatenates message stream before passing to chatModel and toolsNode if needed, and copies the stream into callback handlers.&lt;/li&gt; 
 &lt;li&gt;Concurrency management: the shared state can be safely read and written because the StatePreHandler is concurrency safe.&lt;/li&gt; 
 &lt;li&gt;Aspect injection: injects callback aspects before and after the execution of ChatModel if the specified ChatModel implementation hasn't injected itself.&lt;/li&gt; 
 &lt;li&gt;Option assignment: call options are assigned either globally, to specific component type or to specific node.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, you could easily extend the compiled graph with callbacks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;handler := NewHandlerBuilder().
  OnStartFn(
    func(ctx context.Context, info *RunInfo, input CallbackInput) context.Context) {
        log.Infof("onStart, runInfo: %v, input: %v", info, input)
    }).
  OnEndFn(
    func(ctx context.Context, info *RunInfo, output CallbackOutput) context.Context) {
        log.Infof("onEnd, runInfo: %v, out: %v", info, output)
    }).
  Build()
  
compiledGraph.Invoke(ctx, input, WithCallbacks(handler))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or you could easily assign options to different nodes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Go"&gt;// assign to All nodes
compiledGraph.Invoke(ctx, input, WithCallbacks(handler))

// assign only to ChatModel nodes
compiledGraph.Invoke(ctx, input, WithChatModelOption(WithTemperature(0.5))

// assign only to node_1
compiledGraph.Invoke(ctx, input, WithCallbacks(handler).DesignateNode("node_1"))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Key Features&lt;/h1&gt; 
&lt;h2&gt;Rich Components&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Encapsulates common building blocks into &lt;strong&gt;component abstractions&lt;/strong&gt;, each have multiple &lt;strong&gt;component implementations&lt;/strong&gt; that are ready to be used out of the box.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;component abstractions such as ChatModel, Tool, ChatTemplate, Retriever, Document Loader, Lambda, etc.&lt;/li&gt; 
   &lt;li&gt;each component type has an interface of its own: defined Input &amp;amp; Output Type, defined Option type, and streaming paradigms that make sense.&lt;/li&gt; 
   &lt;li&gt;implementations are transparent. Abstractions are all you care about when orchestrating components together.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Implementations can be nested and captures complex business logic.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ReAct Agent, MultiQueryRetriever, Host MultiAgent, etc. They consist of multiple components and non-trivial business logic.&lt;/li&gt; 
   &lt;li&gt;They are still transparent from the outside. A MultiQueryRetriever can be used anywhere that accepts a Retriever.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Powerful Orchestration&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data flows from Retriever / Document Loaders / ChatTemplate to ChatModel, then flows to Tools and parsed as Final Answer. This directed, controlled flow of data through multiple components can be implemented through &lt;strong&gt;graph orchestration&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Component instances are graph nodes, and edges are data flow channels.&lt;/li&gt; 
 &lt;li&gt;Graph orchestration is powerful and flexible enough to implement complex business logic: 
  &lt;ul&gt; 
   &lt;li&gt;type checking, stream processing, concurrency management, aspect injection and option assignment are handled by the framework.&lt;/li&gt; 
   &lt;li&gt;branch out execution at runtime, read and write global state, or do field level data mapping using workflow(currently in alpha stage).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Complete Stream Processing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stream processing is important because ChatModel outputs chunks of messages in real time as it generates them. It's especially important with orchestration because more components need to handle streaming data.&lt;/li&gt; 
 &lt;li&gt;Eino automatically &lt;strong&gt;concatenates&lt;/strong&gt; stream chunks for downstream nodes that only accepts non-stream input, such as ToolsNode.&lt;/li&gt; 
 &lt;li&gt;Eino automatically &lt;strong&gt;boxes&lt;/strong&gt; non stream into stream when stream is needed during graph execution.&lt;/li&gt; 
 &lt;li&gt;Eino automatically &lt;strong&gt;merges&lt;/strong&gt; multiple streams as they converge into a single downward node.&lt;/li&gt; 
 &lt;li&gt;Eino automatically &lt;strong&gt;copies&lt;/strong&gt; stream as they fan out to different downward node, or is passed to callback handlers.&lt;/li&gt; 
 &lt;li&gt;Orchestration elements such as &lt;strong&gt;branch&lt;/strong&gt; and &lt;strong&gt;state handlers&lt;/strong&gt; are also stream aware.&lt;/li&gt; 
 &lt;li&gt;With these streaming processing abilities, the streaming paradigms of components themselves become transparent to the user.&lt;/li&gt; 
 &lt;li&gt;A compiled Graph can run with 4 different streaming paradigms:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Streaming Paradigm&lt;/th&gt; 
   &lt;th&gt;Explanation&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Invoke&lt;/td&gt; 
   &lt;td&gt;Accepts non-stream type I and returns non-stream type O&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stream&lt;/td&gt; 
   &lt;td&gt;Accepts non-stream type I and returns stream type StreamReader[O]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Collect&lt;/td&gt; 
   &lt;td&gt;Accepts stream type StreamReader[I] and returns non-stream type O&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Transform&lt;/td&gt; 
   &lt;td&gt;Accepts stream type StreamReader[I] and returns stream type StreamReader[O]&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Highly Extensible Aspects (Callbacks)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Aspects handle cross-cutting concerns such as logging, tracing, metrics, etc., as well as exposing internal details of component implementations.&lt;/li&gt; 
 &lt;li&gt;Five aspects are supported: &lt;strong&gt;OnStart, OnEnd, OnError, OnStartWithStreamInput, OnEndWithStreamOutput&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Developers can easily create custom callback handlers, add them during graph run via options, and they will be invoked during graph run.&lt;/li&gt; 
 &lt;li&gt;Graph can also inject aspects to those component implementations that do not support callbacks on their own.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Eino Framework Structure&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/eino_framework.jpeg" alt=""&gt;&lt;/p&gt; 
&lt;p&gt;The Eino framework consists of several parts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Eino(this repo): Contains Eino's type definitions, streaming mechanism, component abstractions, orchestration capabilities, aspect mechanisms, etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/cloudwego/eino-ext"&gt;EinoExt&lt;/a&gt;: Component implementations, callback handlers implementations, component usage examples, and various tools such as evaluators, prompt optimizers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/cloudwego/eino-ext/tree/main/devops"&gt;Eino Devops&lt;/a&gt;: visualized developing, visualized debugging etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/cloudwego/eino-examples"&gt;EinoExamples&lt;/a&gt; is the repo containing example applications and best practices for Eino.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Detailed Documentation&lt;/h2&gt; 
&lt;p&gt;For learning and using Eino, we provide a comprehensive Eino User Manual to help you quickly understand the concepts in Eino and master the skills of developing AI applications based on Eino. Start exploring through the &lt;a href="https://www.cloudwego.io/zh/docs/eino/"&gt;Eino User Manual&lt;/a&gt; now!&lt;/p&gt; 
&lt;p&gt;For a quick introduction to building AI applications with Eino, we recommend starting with &lt;a href="https://www.cloudwego.io/zh/docs/eino/quick_start/"&gt;Eino: Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go 1.18 and above.&lt;/li&gt; 
 &lt;li&gt;Eino relies on &lt;a href="https://github.com/getkin/kin-openapi"&gt;kin-openapi&lt;/a&gt; 's OpenAPI JSONSchema implementation. In order to remain compatible with Go 1.18, we have fixed kin-openapi's version to be v0.118.0.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you discover a potential security issue in this project, or think you may have discovered a security issue, we ask that you notify Bytedance Security via our &lt;a href="https://security.bytedance.com/src"&gt;security center&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/cloudwego/eino/main/sec@bytedance.com"&gt;vulnerability reporting email&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please do &lt;strong&gt;not&lt;/strong&gt; create a public GitHub issue.&lt;/p&gt; 
&lt;h2&gt;Contact US&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;How to become a member: &lt;a href="https://github.com/cloudwego/community/raw/main/COMMUNITY_MEMBERSHIP.md"&gt;COMMUNITY MEMBERSHIP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Issues: &lt;a href="https://github.com/cloudwego/eino/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Lark: Scan the QR code below with &lt;a href="https://www.feishu.cn/en/"&gt;Register Feishu&lt;/a&gt; to join our CloudWeGo/eino user group.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;    &lt;img src="https://raw.githubusercontent.com/cloudwego/eino/main/.github/static/img/eino/lark_group_zh.png" alt="LarkGroup" width="200"&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/cloudwego/eino/main/LICENSE-APACHE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>linshenkx/prompt-optimizer</title>
      <link>https://github.com/linshenkx/prompt-optimizer</link>
      <description>&lt;p&gt;一款提示词优化器，助力于编写高质量的提示词&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Prompt Optimizer (提示词优化器) 🚀&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/README_EN.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/README.md"&gt;中文&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/linshenkx/prompt-optimizer/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/linshenkx/prompt-optimizer" alt="GitHub stars"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/chrome-web-store/users/cakkkhboolfnadechdlgdcnjammejlna?style=flat&amp;amp;label=Chrome%20Users&amp;amp;link=https%3A%2F%2Fchromewebstore.google.com%2Fdetail%2F%25E6%258F%2590%25E7%25A4%25BA%25E8%25AF%258D%25E4%25BC%2598%25E5%258C%2596%25E5%2599%25A8%2Fcakkkhboolfnadechdlgdcnjammejlna" alt="Chrome Web Store Users"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/linshen/prompt-optimizer"&gt;&lt;img src="https://img.shields.io/docker/pulls/linshen/prompt-optimizer" alt="Docker Pulls"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/forks/linshenkx/prompt-optimizer?style=flat" alt="GitHub forks"&gt; &lt;a href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer"&gt;&lt;img src="https://img.shields.io/badge/Vercel-indigo?style=flat&amp;amp;logo=vercel" alt="Deploy with Vercel"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://prompt.always200.com"&gt;在线体验&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;快速开始&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"&gt;常见问题&lt;/a&gt; | &lt;a href="https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna"&gt;Chrome插件&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/dev.md"&gt;开发文档&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/user/deployment/vercel.md"&gt;Vercel部署指南&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/user/mcp-server.md"&gt;MCP部署使用说明&lt;/a&gt; | &lt;a href="https://deepwiki.com/linshenkx/prompt-optimizer"&gt;DeepWiki文档&lt;/a&gt; | &lt;a href="https://zread.ai/linshenkx/prompt-optimizer"&gt;ZRead文档&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;📖 项目简介&lt;/h2&gt; 
&lt;p&gt;Prompt Optimizer是一个强大的AI提示词优化工具，帮助你编写更好的AI提示词，提升AI输出质量。支持Web应用、桌面应用、Chrome插件和Docker部署四种使用方式。&lt;/p&gt; 
&lt;h3&gt;🎥 功能演示&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;b&gt;1. 角色扮演对话：激发小模型潜力&lt;/b&gt;&lt;/p&gt; 
 &lt;p&gt;在追求成本效益的生产或注重隐私的本地化场景中，结构化的提示词能让小模型稳定地进入角色，提供沉浸式、高一致性的角色扮演体验，有效激发其潜力。&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/images/demo/cat-maid-roleplay.png" alt="猫女仆角色扮演演示" width="85%"&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;b&gt;2. 知识图谱提取：保障生产环境的稳定性&lt;/b&gt;&lt;/p&gt; 
 &lt;p&gt;在需要程序化处理的生产环境中，高质量的提示词能显著降低对模型智能程度的要求，使得更经济的小模型也能稳定输出可靠的指定格式。本工具旨在辅助开发者快速达到此目的，从而加速开发、保障稳定，实现降本增效。&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/images/demo/knowledge-graph-extractor.png" alt="知识图谱提取演示" width="85%"&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;b&gt;3. 诗歌写作：辅助创意探索与需求定制&lt;/b&gt;&lt;/p&gt; 
 &lt;p&gt;当面对一个强大的AI，我们的目标不只是得到一个“好”答案，而是得到一个“我们想要的”独特答案。本工具能帮助用户将一个模糊的灵感（如“写首诗”）细化为具体的需求（关于什么主题、何种意象、何种情感），辅助您探索、发掘并精确表达自己的创意，与AI共创独一无二的作品。&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/images/demo/poetry-writing.png" alt="诗歌创作演示" width="85%"&gt; 
&lt;/div&gt; 
&lt;h2&gt;✨ 核心特性&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🎯 &lt;strong&gt;智能优化&lt;/strong&gt;：一键优化提示词，支持多轮迭代改进，提升AI回复准确度&lt;/li&gt; 
 &lt;li&gt;📝 &lt;strong&gt;双模式优化&lt;/strong&gt;：支持系统提示词优化和用户提示词优化，满足不同使用场景&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;对比测试&lt;/strong&gt;：支持原始提示词和优化后提示词的实时对比，直观展示优化效果&lt;/li&gt; 
 &lt;li&gt;🤖 &lt;strong&gt;多模型集成&lt;/strong&gt;：支持OpenAI、Gemini、DeepSeek、智谱AI、SiliconFlow等主流AI模型&lt;/li&gt; 
 &lt;li&gt;🔒 &lt;strong&gt;安全架构&lt;/strong&gt;：纯客户端处理，数据直接与AI服务商交互，不经过中间服务器&lt;/li&gt; 
 &lt;li&gt;📱 &lt;strong&gt;多端支持&lt;/strong&gt;：同时提供Web应用、桌面应用、Chrome插件和Docker部署四种使用方式&lt;/li&gt; 
 &lt;li&gt;🔐 &lt;strong&gt;访问控制&lt;/strong&gt;：支持密码保护功能，保障部署安全&lt;/li&gt; 
 &lt;li&gt;🧩 &lt;strong&gt;MCP协议支持&lt;/strong&gt;：支持Model Context Protocol (MCP) 协议，可与Claude Desktop等MCP兼容应用集成&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速开始&lt;/h2&gt; 
&lt;h3&gt;1. 使用在线版本（推荐）&lt;/h3&gt; 
&lt;p&gt;直接访问：&lt;a href="https://prompt.always200.com"&gt;https://prompt.always200.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;项目是纯前端项目，所有数据只存储在浏览器本地，不会上传至任何服务器，因此直接使用在线版本也是安全可靠的&lt;/p&gt; 
&lt;h3&gt;2. Vercel部署&lt;/h3&gt; 
&lt;p&gt;方式1：一键部署到自己的Vercel(方便，但后续无法自动更新)： &lt;a href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer"&gt;&lt;img src="https://vercel.com/button" alt="部署到 Vercel"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;方式2: Fork项目后在Vercel中导入（推荐，但需参考部署文档进行手动设置）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;先Fork项目到自己的GitHub&lt;/li&gt; 
 &lt;li&gt;然后在Vercel中导入该项目&lt;/li&gt; 
 &lt;li&gt;可跟踪源项目更新，便于同步最新功能和修复&lt;/li&gt; 
 &lt;li&gt;配置环境变量： 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ACCESS_PASSWORD&lt;/code&gt;：设置访问密码，启用访问限制&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;VITE_OPENAI_API_KEY&lt;/code&gt;等：配置各AI服务商的API密钥&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多详细的部署步骤和注意事项，请查看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/user/deployment/vercel.md"&gt;Vercel部署指南&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 下载桌面应用&lt;/h3&gt; 
&lt;p&gt;从 &lt;a href="https://github.com/linshenkx/prompt-optimizer/releases"&gt;GitHub Releases&lt;/a&gt; 下载最新版本。我们为各平台提供&lt;strong&gt;安装程序&lt;/strong&gt;和&lt;strong&gt;压缩包&lt;/strong&gt;两种格式。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安装程序 (推荐)&lt;/strong&gt;: 如 &lt;code&gt;*.exe&lt;/code&gt;, &lt;code&gt;*.dmg&lt;/code&gt;, &lt;code&gt;*.AppImage&lt;/code&gt; 等。&lt;strong&gt;强烈推荐使用此方式，因为它支持自动更新&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;压缩包&lt;/strong&gt;: 如 &lt;code&gt;*.zip&lt;/code&gt;。解压即用，但无法自动更新。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;桌面应用核心优势&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ &lt;strong&gt;无跨域限制&lt;/strong&gt;：作为原生桌面应用，它能彻底摆脱浏览器跨域（CORS）问题的困扰。这意味着您可以直接连接任何AI服务提供商的API，包括本地部署的Ollama或有严格安全策略的商业API，获得最完整、最稳定的功能体验。&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;自动更新&lt;/strong&gt;：通过安装程序（如 &lt;code&gt;.exe&lt;/code&gt;, &lt;code&gt;.dmg&lt;/code&gt;）安装的版本，能够自动检查并更新到最新版。&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;独立运行&lt;/strong&gt;：无需依赖浏览器，提供更快的响应和更佳的性能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. 安装Chrome插件&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;从Chrome商店安装（由于审批较慢，可能不是最新的）：&lt;a href="https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna"&gt;Chrome商店地址&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;点击图标即可打开提示词优化器&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;5. Docker部署&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;点击查看 Docker 部署命令&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 运行容器（默认配置）
docker run -d -p 8081:80 --restart unless-stopped --name prompt-optimizer linshen/prompt-optimizer

# 运行容器（配置API密钥和访问密码）
docker run -d -p 8081:80 \
  -e VITE_OPENAI_API_KEY=your_key \
  -e ACCESS_USERNAME=your_username \  # 可选，默认为"admin"
  -e ACCESS_PASSWORD=your_password \  # 设置访问密码
  --restart unless-stopped \
  --name prompt-optimizer \
  linshen/prompt-optimizer
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;国内镜像&lt;/strong&gt;: 如果Docker Hub访问较慢，可以将上述命令中的 &lt;code&gt;linshen/prompt-optimizer&lt;/code&gt; 替换为 &lt;code&gt;registry.cn-guangzhou.aliyuncs.com/prompt-optimizer/prompt-optimizer&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;6. Docker Compose部署&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;点击查看 Docker Compose 部署步骤&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1. 克隆仓库
git clone https://github.com/linshenkx/prompt-optimizer.git
cd prompt-optimizer

# 2. 可选：创建.env文件配置API密钥和访问认证
cp env.local.example .env
# 编辑 .env 文件，填入实际的 API 密钥和配置

# 3. 启动服务
docker compose up -d

# 4. 查看日志
docker compose logs -f

# 5. 访问服务
Web 界面：http://localhost:8081
MCP 服务器：http://localhost:8081/mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;你还可以直接编辑docker-compose.yml文件，自定义配置：&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;点击查看 docker-compose.yml 示例&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  prompt-optimizer:
    # 使用Docker Hub镜像
    image: linshen/prompt-optimizer:latest
    # 或使用阿里云镜像（国内用户推荐）
    # image: registry.cn-guangzhou.aliyuncs.com/prompt-optimizer/prompt-optimizer:latest
    container_name: prompt-optimizer
    restart: unless-stopped
    ports:
      - "8081:80"  # Web应用端口（包含MCP服务器，通过/mcp路径访问）
    environment:
      # API密钥配置
      - VITE_OPENAI_API_KEY=your_openai_key
      - VITE_GEMINI_API_KEY=your_gemini_key
      # 访问控制（可选）
      - ACCESS_USERNAME=admin
      - ACCESS_PASSWORD=your_password
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;7. MCP Server 使用说明&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;点击查看 MCP Server 使用说明&lt;/summary&gt; 
 &lt;p&gt;Prompt Optimizer 现在支持 Model Context Protocol (MCP) 协议，可以与 Claude Desktop 等支持 MCP 的 AI 应用集成。&lt;/p&gt; 
 &lt;p&gt;当通过 Docker 运行时，MCP Server 会自动启动，并可通过 &lt;code&gt;http://ip:port/mcp&lt;/code&gt; 访问。&lt;/p&gt; 
 &lt;h4&gt;环境变量配置&lt;/h4&gt; 
 &lt;p&gt;MCP Server 需要配置 API 密钥才能正常工作。主要的 MCP 专属配置：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# MCP 服务器配置
MCP_DEFAULT_MODEL_PROVIDER=openai  # 可选值：openai, gemini, deepseek, siliconflow, zhipu, custom
MCP_LOG_LEVEL=info                 # 日志级别
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Docker 环境下使用 MCP&lt;/h4&gt; 
 &lt;p&gt;在 Docker 环境中，MCP Server 会与 Web 应用一起运行，您可以通过 Web 应用的相同端口访问 MCP 服务，路径为 &lt;code&gt;/mcp&lt;/code&gt;。&lt;/p&gt; 
 &lt;p&gt;例如，如果您将容器的 80 端口映射到主机的 8081 端口：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 8081:80 \
  -e VITE_OPENAI_API_KEY=your-openai-key \
  -e MCP_DEFAULT_MODEL_PROVIDER=openai \
  --name prompt-optimizer \
  linshen/prompt-optimizer
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;那么 MCP Server 将可以通过 &lt;code&gt;http://localhost:8081/mcp&lt;/code&gt; 访问。&lt;/p&gt; 
 &lt;h4&gt;Claude Desktop 集成示例&lt;/h4&gt; 
 &lt;p&gt;要在 Claude Desktop 中使用 Prompt Optimizer，您需要在 Claude Desktop 的配置文件中添加服务配置。&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;找到 Claude Desktop 的配置目录：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Windows: &lt;code&gt;%APPDATA%\Claude\services&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;macOS: &lt;code&gt;~/Library/Application Support/Claude/services&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;Linux: &lt;code&gt;~/.config/Claude/services&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;编辑或创建 &lt;code&gt;services.json&lt;/code&gt; 文件，添加以下内容：&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "services": [
    {
      "name": "Prompt Optimizer",
      "url": "http://localhost:8081/mcp"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;请确保将 &lt;code&gt;localhost:8081&lt;/code&gt; 替换为您实际部署 Prompt Optimizer 的地址和端口。&lt;/p&gt; 
 &lt;h4&gt;可用工具&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;optimize-user-prompt&lt;/strong&gt;: 优化用户提示词以提高 LLM 性能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;optimize-system-prompt&lt;/strong&gt;: 优化系统提示词以提高 LLM 性能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;iterate-prompt&lt;/strong&gt;: 对已经成熟/完善的提示词进行定向迭代优化&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;更多详细信息，请查看 &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/user/mcp-server.md"&gt;MCP 服务器用户指南&lt;/a&gt;。&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;⚙️ API密钥配置&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;点击查看API密钥配置方法&lt;/summary&gt; 
 &lt;h3&gt;方式一：通过界面配置（推荐）&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;点击界面右上角的"⚙️设置"按钮&lt;/li&gt; 
  &lt;li&gt;选择"模型管理"选项卡&lt;/li&gt; 
  &lt;li&gt;点击需要配置的模型（如OpenAI、Gemini、DeepSeek等）&lt;/li&gt; 
  &lt;li&gt;在弹出的配置框中输入对应的API密钥&lt;/li&gt; 
  &lt;li&gt;点击"保存"即可&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;支持的模型：OpenAI、Gemini、DeepSeek、Zhipu智谱、SiliconFlow、自定义API（OpenAI兼容接口）&lt;/p&gt; 
 &lt;p&gt;除了API密钥，您还可以在模型配置界面为每个模型单独设置高级LLM参数。这些参数通过一个名为 &lt;code&gt;llmParams&lt;/code&gt; 的字段进行配置，它允许您以键值对的形式指定LLM SDK支持的任何参数，从而更精细地控制模型行为。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;高级LLM参数配置示例：&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;OpenAI/兼容API&lt;/strong&gt;: &lt;code&gt;{"temperature": 0.7, "max_tokens": 4096, "timeout": 60000}&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Gemini&lt;/strong&gt;: &lt;code&gt;{"temperature": 0.8, "maxOutputTokens": 2048, "topP": 0.95}&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;: &lt;code&gt;{"temperature": 0.5, "top_p": 0.9, "frequency_penalty": 0.1}&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;有关 &lt;code&gt;llmParams&lt;/code&gt; 的更详细说明和配置指南，请参阅 &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/developer/llm-params-guide.md"&gt;LLM参数配置指南&lt;/a&gt;。&lt;/p&gt; 
 &lt;h3&gt;方式二：通过环境变量配置&lt;/h3&gt; 
 &lt;p&gt;Docker部署时通过 &lt;code&gt;-e&lt;/code&gt; 参数配置环境变量：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;-e VITE_OPENAI_API_KEY=your_key
-e VITE_GEMINI_API_KEY=your_key
-e VITE_DEEPSEEK_API_KEY=your_key
-e VITE_ZHIPU_API_KEY=your_key
-e VITE_SILICONFLOW_API_KEY=your_key
-e VITE_CUSTOM_API_KEY=your_custom_api_key
-e VITE_CUSTOM_API_BASE_URL=your_custom_api_base_url
-e VITE_CUSTOM_API_MODEL=your_custom_model_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;本地开发&lt;/h2&gt; 
&lt;p&gt;详细文档可查看 &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/dev.md"&gt;开发文档&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;点击查看本地开发命令&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1. 克隆项目
git clone https://github.com/linshenkx/prompt-optimizer.git
cd prompt-optimizer

# 2. 安装依赖
pnpm install

# 3. 启动开发服务
pnpm dev               # 主开发命令：构建core/ui并运行web应用
pnpm dev:web          # 仅运行web应用
pnpm dev:fresh        # 完整重置并重新启动开发环境
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;🗺️ 开发路线&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 基础功能开发&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Web应用发布&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Chrome插件发布&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 国际化支持&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 支持系统提示词优化和用户提示词优化&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 桌面应用发布&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; mcp服务发布&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详细的项目状态可查看 &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/project-status.md"&gt;项目状态文档&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📖 相关文档&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/README.md"&gt;文档索引&lt;/a&gt; - 所有文档的索引&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/developer/technical-development-guide.md"&gt;技术开发指南&lt;/a&gt; - 技术栈和开发规范&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/developer/llm-params-guide.md"&gt;LLM参数配置指南&lt;/a&gt; - 高级LLM参数配置详细说明&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/developer/project-structure.md"&gt;项目结构&lt;/a&gt; - 详细的项目结构说明&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/project/project-status.md"&gt;项目状态&lt;/a&gt; - 当前进度和计划&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/project/prd.md"&gt;产品需求&lt;/a&gt; - 产品需求文档&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/user/deployment/vercel.md"&gt;Vercel部署指南&lt;/a&gt; - Vercel部署详细说明&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#linshenkx/prompt-optimizer&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;amp;type=Date&amp;amp;theme=dark"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;amp;type=Date"&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;amp;type=Date"&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;常见问题&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;点击查看常见问题解答&lt;/summary&gt; 
 &lt;h3&gt;API连接问题&lt;/h3&gt; 
 &lt;h4&gt;Q1: 为什么配置好API密钥后仍然无法连接到模型服务？&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: 大多数连接失败是由&lt;strong&gt;跨域问题&lt;/strong&gt;（CORS）导致的。由于本项目是纯前端应用，浏览器出于安全考虑会阻止直接访问不同源的API服务。模型服务如未正确配置CORS策略，会拒绝来自浏览器的直接请求。&lt;/p&gt; 
 &lt;h4&gt;Q2: 如何解决本地Ollama的连接问题？&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: Ollama完全支持OpenAI标准接口，只需配置正确的跨域策略：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;设置环境变量 &lt;code&gt;OLLAMA_ORIGINS=*&lt;/code&gt; 允许任意来源的请求&lt;/li&gt; 
  &lt;li&gt;如仍有问题，设置 &lt;code&gt;OLLAMA_HOST=0.0.0.0:11434&lt;/code&gt; 监听任意IP地址&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;Q3: 如何解决商业API（如Nvidia的DS API、字节跳动的火山API）的跨域问题？&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: 这些平台通常有严格的跨域限制，推荐以下解决方案：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用Vercel代理&lt;/strong&gt;（便捷方案）&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;使用在线版本：&lt;a href="https://prompt.always200.com"&gt;prompt.always200.com&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;或自行部署到Vercel平台&lt;/li&gt; 
    &lt;li&gt;在模型设置中勾选"使用Vercel代理"选项&lt;/li&gt; 
    &lt;li&gt;请求流向：浏览器→Vercel→模型服务提供商&lt;/li&gt; 
    &lt;li&gt;详细步骤请参考 &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/docs/user/deployment/vercel.md"&gt;Vercel部署指南&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用自部署的API中转服务&lt;/strong&gt;（可靠方案）&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;部署如OneAPI等开源API聚合/代理工具&lt;/li&gt; 
    &lt;li&gt;在设置中配置为自定义API端点&lt;/li&gt; 
    &lt;li&gt;请求流向：浏览器→中转服务→模型服务提供商&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;Q4: Vercel代理有什么缺点或风险？&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: 使用Vercel代理可能会触发某些模型服务提供商的风控机制。部分厂商可能会将来自Vercel的请求判定为代理行为，从而限制或拒绝服务。如遇此问题，建议使用自部署的中转服务。&lt;/p&gt; 
 &lt;h4&gt;Q5: 我已正确配置本地模型（如Ollama）的跨域策略，为什么使用在线版依然无法连接？&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: 这是由浏览器的&lt;strong&gt;混合内容（Mixed Content）安全策略&lt;/strong&gt;导致的。出于安全考虑，浏览器会阻止安全的HTTPS页面（如在线版）向不安全的HTTP地址（如您的本地Ollama服务）发送请求。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;： 为了绕过此限制，您需要让应用和API处于同一种协议下（例如，都是HTTP）。推荐以下几种方式：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;使用桌面版&lt;/strong&gt;：桌面应用没有浏览器限制，是连接本地模型最稳定可靠的方式。&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;docker部署&lt;/strong&gt;：docker部署也是http&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;使用Chrome插件&lt;/strong&gt;：插件在某些情况下也可以绕过部分安全限制。&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;🤝 参与贡献&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;点击查看贡献指南&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Fork 本仓库&lt;/li&gt; 
  &lt;li&gt;创建特性分支 (&lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;提交更改 (&lt;code&gt;git commit -m '添加某个特性'&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;推送到分支 (&lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;提交 Pull Request&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;提示：使用cursor工具开发时，建议在提交前:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;使用"code_review"规则进行代码审查&lt;/li&gt; 
  &lt;li&gt;按照审查报告格式检查: 
   &lt;ul&gt; 
    &lt;li&gt;变更的整体一致性&lt;/li&gt; 
    &lt;li&gt;代码质量和实现方式&lt;/li&gt; 
    &lt;li&gt;测试覆盖情况&lt;/li&gt; 
    &lt;li&gt;文档完善程度&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;根据审查结果进行优化后再提交&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;👏 贡献者名单&lt;/h2&gt; 
&lt;p&gt;感谢所有为项目做出贡献的开发者！&lt;/p&gt; 
&lt;a href="https://github.com/linshenkx/prompt-optimizer/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=linshenkx/prompt-optimizer" alt="贡献者"&gt; &lt;/a&gt; 
&lt;h2&gt;📄 开源协议&lt;/h2&gt; 
&lt;p&gt;本项目采用 &lt;a href="https://raw.githubusercontent.com/linshenkx/prompt-optimizer/develop/LICENSE"&gt;MIT&lt;/a&gt; 协议开源。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;如果这个项目对你有帮助，请考虑给它一个 Star ⭐️&lt;/p&gt; 
&lt;h2&gt;👥 联系我们&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;提交 Issue&lt;/li&gt; 
 &lt;li&gt;发起 Pull Request&lt;/li&gt; 
 &lt;li&gt;加入讨论组&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>roboflow/supervision</title>
      <link>https://github.com/roboflow/supervision</link>
      <description>&lt;p&gt;We write your reusable computer vision tools. 💜&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://supervision.roboflow.com"&gt; &lt;img width="100%" src="https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529"&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://github.com/roboflow/notebooks"&gt;notebooks&lt;/a&gt; | &lt;a href="https://github.com/roboflow/inference"&gt;inference&lt;/a&gt; | &lt;a href="https://github.com/autodistill/autodistill"&gt;autodistill&lt;/a&gt; | &lt;a href="https://github.com/roboflow/multimodal-maestro"&gt;maestro&lt;/a&gt;&lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://badge.fury.io/py/supervision.svg?sanitize=true" alt="version"&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/supervision"&gt;&lt;img src="https://img.shields.io/pypi/dm/supervision" alt="downloads"&gt;&lt;/a&gt; &lt;a href="https://snyk.io/advisor/python/supervision"&gt;&lt;img src="https://snyk.io/advisor/python/supervision/badge.svg?sanitize=true" alt="snyk"&gt;&lt;/a&gt; &lt;a href="https://github.com/roboflow/supervision/raw/main/LICENSE.md"&gt;&lt;img src="https://img.shields.io/pypi/l/supervision" alt="license"&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/supervision" alt="python-version"&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="colab"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/Roboflow/Annotators"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="gradio"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/GbfgXGJ8Bk"&gt;&lt;img src="https://img.shields.io/discord/1159501506232451173?logo=discord&amp;amp;label=discord&amp;amp;labelColor=fff&amp;amp;color=5865f2&amp;amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk" alt="discord"&gt;&lt;/a&gt; &lt;a href="https://squidfunk.github.io/mkdocs-material/"&gt;&lt;img src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white" alt="built-with-material-for-mkdocs"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/124" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/124" alt="roboflow%2Fsupervision | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;👋 hello&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! 🤝&lt;/p&gt; 
&lt;h2&gt;💻 install&lt;/h2&gt; 
&lt;p&gt;Pip install the supervision package in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.9&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install supervision
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href="https://roboflow.github.io/supervision/"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🔥 quickstart&lt;/h2&gt; 
&lt;h3&gt;models&lt;/h3&gt; 
&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href="https://supervision.roboflow.com/latest/detection/core/#detections"&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO("yolov8s.pt")
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;👉 more model connectors&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href="https://github.com/roboflow/inference"&gt;Inference&lt;/a&gt; requires a &lt;a href="https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key"&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from inference import get_model

image = cv2.imread(...)
model = get_model(model_id="yolov8s-640", api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;annotators&lt;/h3&gt; 
&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href="https://supervision.roboflow.com/latest/detection/annotators/"&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce"&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;datasets&lt;/h3&gt; 
&lt;p&gt;Supervision provides a set of &lt;a href="https://supervision.roboflow.com/latest/datasets/core/"&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&amp;lt;WORKSPACE_ID&amp;gt;).project(&amp;lt;PROJECT_ID&amp;gt;)
dataset = project.version(&amp;lt;PROJECT_VERSION&amp;gt;).download("coco")

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f"{dataset.location}/train",
    annotations_path=f"{dataset.location}/train/_annotations.coco.json",
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
&lt;/code&gt;&lt;/pre&gt; 
&lt;details close&gt; 
 &lt;summary&gt;👉 more dataset utils&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
# (700, 150, 150)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;ds_1 = sv.DetectionDataset(...)
len(ds_1)
# 100
ds_1.classes
# ['dog', 'person']

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
# ['cat']

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
# 300
ds_merged.classes
# ['cat', 'dog', 'person']
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;🎬 tutorials&lt;/h2&gt; 
&lt;p&gt;Want to learn how to use Supervision? Explore our &lt;a href="https://supervision.roboflow.com/develop/how_to/detect_and_annotate/"&gt;how-to guides&lt;/a&gt;, &lt;a href="https://github.com/roboflow/supervision/tree/develop/examples"&gt;end-to-end examples&lt;/a&gt;, &lt;a href="https://roboflow.github.io/cheatsheet-supervision/"&gt;cheatsheet&lt;/a&gt;, and &lt;a href="https://supervision.roboflow.com/develop/cookbooks/"&gt;cookbooks&lt;/a&gt;!&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1" alt="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.
&lt;p&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91" alt="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;💜 built with supervision&lt;/h2&gt; 
&lt;p&gt;Did you build something cool using supervision? &lt;a href="https://github.com/roboflow/supervision/discussions/categories/built-with-supervision"&gt;Let us know!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4"&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900"&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f"&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📚 documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://roboflow.github.io/supervision"&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; 
&lt;h2&gt;🏆 contribution&lt;/h2&gt; 
&lt;p&gt;We love your input! Please see our &lt;a href="https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started. Thank you 🙏 to all our contributors!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/roboflow/supervision/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=roboflow/supervision"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://youtube.com/roboflow"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://www.linkedin.com/company/roboflow-ai/"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://docs.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://discuss.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584" width="3%"&gt; &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; &lt;/a&gt;
  &lt;a href="https://blog.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605" width="3%"&gt; &lt;/a&gt;  
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Shubhamsaboo/awesome-llm-apps</title>
      <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
      <description>&lt;p&gt;Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="http://www.theunwindai.com"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/unwind_black.png" width="900px" alt="Unwind AI"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/in/shubhamsaboo/"&gt; &lt;img src="https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;amp;style=flat-square" alt="LinkedIn"&gt; &lt;/a&gt; &lt;a href="https://twitter.com/Saboo_Shubham_"&gt; &lt;img src="https://img.shields.io/twitter/follow/Shubham_Saboo" alt="Twitter"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es"&gt;Español&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr"&gt;français&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja"&gt;日本語&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko"&gt;한국어&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt"&gt;Português&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru"&gt;Русский&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh"&gt;中文&lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;h1&gt;🌟 Awesome LLM Apps&lt;/h1&gt; 
&lt;p&gt;A curated collection of &lt;strong&gt;Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.&lt;/strong&gt; This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/9876" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/9876" alt="Shubhamsaboo%2Fawesome-llm-apps | Trendshift" style="width: 250px; height: 55px;"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;🤔 Why Awesome LLM Apps?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;💡 Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.&lt;/li&gt; 
 &lt;li&gt;🔥 Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp;amp; RAG.&lt;/li&gt; 
 &lt;li&gt;🎓 Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📂 Featured AI Projects&lt;/h2&gt; 
&lt;h3&gt;AI Agents&lt;/h3&gt; 
&lt;h3&gt;🌱 Starter AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_blog_to_podcast_agent/"&gt;🎙️ AI Blog to Podcast Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_breakup_recovery_agent/"&gt;❤️‍🩹 AI Breakup Recovery Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_data_analysis_agent/"&gt;📊 AI Data Analysis Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_medical_imaging_agent/"&gt;🩻 AI Medical Imaging Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_meme_generator_agent_browseruse/"&gt;😂 AI Meme Generator Agent (Browser)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_music_generator_agent/"&gt;🎵 AI Music Generator Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_travel_agent/"&gt;🛫 AI Travel Agent (Local &amp;amp; Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/gemini_multimodal_agent_demo/"&gt;✨ Gemini Multimodal Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/local_news_agent_openai_swarm/"&gt;🌐 Local News Agent (OpenAI Swarm)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/mixture_of_agents/"&gt;🔄 Mixture of Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/xai_finance_agent/"&gt;📊 xAI Finance Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/opeani_research_agent/"&gt;🔍 OpenAI Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/web_scrapping_ai_agent/"&gt;🕸️ Web Scrapping AI Agent (Local &amp;amp; Cloud)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🚀 Advanced AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_deep_research_agent/"&gt;🔍 AI Deep Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_consultant_agent"&gt;🤝 AI Consultant Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_system_architect_r1/"&gt;🏗️ AI System Architect Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/"&gt;🎯 AI Lead Generation Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/"&gt;💰 AI Financial Coach Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_movie_production_agent/"&gt;🎬 AI Movie Production Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_investment_agent/"&gt;📈 AI Investment Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/"&gt;🏋️‍♂️ AI Health &amp;amp; Fitness Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent"&gt;🚀 AI Product Launch Intelligence Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_journalist_agent/"&gt;🗞️ AI Journalist Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/"&gt;🧠 AI Mental Wellbeing Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_meeting_agent/"&gt;📑 AI Meeting Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/"&gt;🧬 AI Self-Evolving Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/"&gt;🎧 AI Social Media News and Podcast Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🎮 Autonomous Game Playing Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/"&gt;🎮 AI 3D Pygame Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/"&gt;♜ AI Chess Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/"&gt;🎲 AI Tic-Tac-Toe Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🤝 Multi-agent Teams&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/"&gt;🧲 AI Competitor Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/"&gt;💲 AI Finance Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/"&gt;🎨 AI Game Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/"&gt;👨‍⚖️ AI Legal Agent Team (Cloud &amp;amp; Local)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/"&gt;💼 AI Recruitment Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/"&gt;👨‍💼 AI Services Agency (CrewAI)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/"&gt;👨‍🏫 AI Teaching Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/"&gt;💻 Multimodal Coding Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/"&gt;✨ Multimodal Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/"&gt;🌏 AI Travel Planner Agent Team&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🗣️ Voice AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/ai_audio_tour_agent/"&gt;🗣️ AI Audio Tour Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/customer_support_voice_agent/"&gt;📞 Customer Support Voice Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/voice_rag_openaisdk/"&gt;🔊 Voice RAG Agent (OpenAI SDK)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🌐 MCP AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/browser_mcp_agent/"&gt;♾️ Browser MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/github_mcp_agent/"&gt;🐙 GitHub MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/notion_mcp_agent"&gt;📑 Notion MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/ai_travel_planner_mcp_agent_team"&gt;🌍 AI Travel Planner MCP Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📀 RAG (Retrieval Augmented Generation)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag/"&gt;🔗 Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag_with_reasoning/"&gt;🧐 Agentic RAG with Reasoning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/ai_blog_search/"&gt;📰 AI Blog Search (RAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/autonomous_rag/"&gt;🔍 Autonomous RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/corrective_rag/"&gt;🔄 Corrective RAG (CRAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/deepseek_local_rag_agent/"&gt;🐋 Deepseek Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/gemini_agentic_rag/"&gt;🤔 Gemini Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/hybrid_search_rag/"&gt;👀 Hybrid Search RAG (Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/llama3.1_local_rag/"&gt;🔄 Llama 3.1 Local RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_hybrid_search_rag/"&gt;🖥️ Local Hybrid Search RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_rag_agent/"&gt;🦙 Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag-as-a-service/"&gt;🧩 RAG-as-a-Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_agent_cohere/"&gt;✨ RAG Agent with Cohere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_chain/"&gt;⛓️ Basic RAG Chain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_database_routing/"&gt;📠 RAG with Database Routing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/vision_rag/"&gt;🖼️ Vision RAG&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;💾 LLM Apps with Memory Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/"&gt;💾 AI ArXiv Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/"&gt;🛩️ AI Travel Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/"&gt;💬 Llama3 Stateful Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/"&gt;📝 LLM App with Personalized Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/"&gt;🗄️ Local ChatGPT Clone with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/"&gt;🧠 Multi-LLM Application with Shared Memory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;💬 Chat with X Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_github/"&gt;💬 Chat with GitHub (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/"&gt;📨 Chat with Gmail&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/"&gt;📄 Chat with PDF (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/"&gt;📚 Chat with Research Papers (ArXiv) (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/"&gt;📝 Chat with Substack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/"&gt;📽️ Chat with YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔧 LLM Fine-tuning Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/"&gt;🔧 Llama 3.2 Fine-tuning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Navigate to the desired project directory&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the required dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Follow the project-specific instructions&lt;/strong&gt; in each project's &lt;code&gt;README.md&lt;/code&gt; file to set up and run the app.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🤝 Contributing to Open Source&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new &lt;a href="https://github.com/Shubhamsaboo/awesome-llm-apps/issues"&gt;GitHub Issue&lt;/a&gt; or submit a pull request. Make sure to follow the existing project structure and include a detailed &lt;code&gt;README.md&lt;/code&gt; for each new app.&lt;/p&gt; 
&lt;h3&gt;Thank You, Community, for the Support! 🙏&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🌟 &lt;strong&gt;Don’t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Investment Research for Everyone, Everywhere.&lt;/p&gt;&lt;hr&gt;&lt;br&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://x.com/openbb_finance"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/xPHTuHCmuV"&gt;&lt;img src="https://img.shields.io/discord/831165782750789672" alt="Discord Shield"&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers"&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/OpenBB-finance/OpenBB"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" height="20"&gt; &lt;/a&gt; &lt;a target="_blank" href="https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/openbb/"&gt;&lt;img src="https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package" alt="PyPI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The first financial Platform that is open source.&lt;/p&gt; 
&lt;p&gt;The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.&lt;/p&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openbb import obb
output = obb.equity.price.historical("AAPL")
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can sign up to the &lt;a href="https://my.openbb.co/login"&gt;OpenBB Hub&lt;/a&gt; to get the most out of the OpenBB ecosystem.&lt;/p&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href="https://docs.openbb.co/platform/reference"&gt;https://docs.openbb.co/platform/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.&lt;/p&gt; 
&lt;p&gt;If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;a href="https://pro.openbb.co"&gt;https://pro.openbb.co&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png" alt="Logo" width="1000"&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href="https://docs.openbb.co/workspace"&gt;docs&lt;/a&gt; or &lt;a href="https://github.com/OpenBB-finance/backends-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href="https://github.com/OpenBB-finance/agents-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating OpenBB Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run OpenBB Platform backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "openbb[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate OpenBB Platform backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href="https://pro.openbb.co/"&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069" alt="CleanShot 2025-05-17 at 09 51 56@2x"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the "Apps" tab&lt;/li&gt; 
 &lt;li&gt;Click on "Connect backend"&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: OpenBB Platform URL: &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on "Test". You should get a "Test successful" with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on "Add".&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it.&lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed="closed"&gt; 
 &lt;summary&gt;&lt;h2 style="display: inline-block"&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts"&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The OpenBB Platform can be installed as a &lt;a href="https://pypi.org/project/openbb/"&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href="https://docs.openbb.co/platform/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenBB Platform CLI installation&lt;/h3&gt; 
&lt;p&gt;The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href="https://docs.openbb.co/cli/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now ⭐️)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href="https://docs.openbb.co/platform/developer_guide/misc/contributing"&gt;Contributing Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn't exist already &lt;a href="https://github.com/OpenBB-finance/OpenBB/issues"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D"&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D"&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href="https://openbb.co/discord"&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href="https://openbb.co/links"&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the OpenBB Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href="https://openbb.co/links"&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href="https://openbb.co/open"&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB" width="800"&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>daveebbelaar/ai-cookbook</title>
      <link>https://github.com/daveebbelaar/ai-cookbook</link>
      <description>&lt;p&gt;Examples and tutorials to help developers build AI systems&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;This Cookbook contains examples and tutorials to help developers build AI systems, offering copy/paste code snippets that you can easily integrate into your own projects.&lt;/p&gt; 
&lt;h2&gt;About Me&lt;/h2&gt; 
&lt;p&gt;Hi! I'm Dave, AI Engineer and founder of Datalumina®. On my &lt;a href="https://www.youtube.com/@daveebbelaar?sub_confirmation=1"&gt;YouTube channel&lt;/a&gt;, I share practical tutorials that teach developers how to build AI systems that actually work in the real world. Beyond these tutorials, I also help people start successful freelancing careers. Check out the links below to learn more!&lt;/p&gt; 
&lt;h3&gt;Explore More Resources&lt;/h3&gt; 
&lt;p&gt;Whether you're a learner, a freelancer, or a business looking for AI expertise, we've got something for you:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Learning Python for AI and Data Science?&lt;/strong&gt;&lt;br&gt; Join our &lt;strong&gt;free community, Data Alchemy&lt;/strong&gt;, where you'll find resources, tutorials, and support&lt;br&gt; ▶︎ &lt;a href="https://www.skool.com/data-alchemy"&gt;Learn Python for AI&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ready to start or scale your freelancing career?&lt;/strong&gt;&lt;br&gt; Learn how to land clients and grow your business&lt;br&gt; ▶︎ &lt;a href="https://www.datalumina.com/data-freelancer"&gt;Find freelance projects&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Need expert help on your next project?&lt;/strong&gt;&lt;br&gt; Work with me and my team to solve your data and AI challenges&lt;br&gt; ▶︎ &lt;a href="https://www.datalumina.com/solutions"&gt;Work with me&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Already building AI applications?&lt;/strong&gt;&lt;br&gt; Explore the &lt;strong&gt;GenAI Launchpad&lt;/strong&gt;, our production framework for AI systems&lt;br&gt; ▶︎ &lt;a href="https://launchpad.datalumina.com/"&gt;Explore the GenAI Launchpad&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>tldr-pages/tldr</title>
      <link>https://github.com/tldr-pages/tldr</link>
      <description>&lt;p&gt;📚 Collaborative cheatsheets for console commands&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;&lt;a href="https://tldr.sh/"&gt;&lt;img alt="tldr-pages" src="https://raw.githubusercontent.com/tldr-pages/tldr/main/images/banner.png" width="600/"&gt;&lt;/a&gt;&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/tldr-pages/tldr/actions"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/tldr-pages/tldr/ci.yml?branch=main&amp;amp;label=Build" alt="Build status"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23tldr-pages:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/tldr-pages:matrix.org?label=Chat+on+Matrix" alt="Matrix chat"&gt;&lt;/a&gt; &lt;a href="https://github.com/tldr-pages/tldr/pulls?q=is:pr+is:merged"&gt;&lt;img src="https://img.shields.io/github/issues-pr-closed-raw/tldr-pages/tldr.svg?label=Merged+PRs&amp;amp;color=green" alt="Merged PRs"&gt;&lt;/a&gt; &lt;a href="https://github.com/tldr-pages/tldr/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/tldr-pages/tldr.svg?label=Contributors" alt="GitHub contributors"&gt;&lt;/a&gt; &lt;a href="https://github.com/tldr-pages/tldr/raw/main/LICENSE.md"&gt;&lt;img src="https://img.shields.io/badge/license-CC_BY_4.0-blue.svg?label=License" alt="license"&gt;&lt;/a&gt; &lt;a href="https://fosstodon.org/@tldr_pages"&gt;&lt;img src="https://img.shields.io/badge/Mastodon-6364FF?logo=mastodon&amp;amp;logoColor=fff" alt="Mastodon"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is tldr-pages?&lt;/h2&gt; 
&lt;p&gt;The &lt;strong&gt;tldr-pages&lt;/strong&gt; project is a collection of community-maintained help pages for command-line tools, that aims to be a simpler, more approachable complement to traditional &lt;a href="https://en.wikipedia.org/wiki/Man_page"&gt;man pages&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Maybe you're new to the command-line world. Perhaps you're just a little rusty or can't always recall the arguments for commands like &lt;code&gt;lsof&lt;/code&gt;, or &lt;code&gt;tar&lt;/code&gt;?&lt;/p&gt; 
&lt;p&gt;It certainly doesn't help that, in the past, the first option explained in &lt;code&gt;man tar&lt;/code&gt; was:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ man tar
...
-b blocksize
   Specify the block size, in 512-byte records, for tape drive I/O.
   As a rule, this argument is only needed when reading from or writing to tape drives,
   and usually not even then as the default block size of 20 records (10240 bytes) is very common.
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There is room for simpler help pages focused on practical examples. How about:&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/tldr-pages/tldr/blob/main/images/tldr-dark.png"&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/tldr-pages/tldr/blob/main/images/tldr-light.png"&gt; 
 &lt;img alt="Screenshot of the tldr client displaying the tar command." src="https://github.com/tldr-pages/tldr/raw/main/images/tldr-dark.png"&gt; 
&lt;/picture&gt; 
&lt;p&gt;This repository is just that: an ever-growing collection of examples for the most common UNIX, Linux, macOS, FreeBSD, NetBSD, OpenBSD, SunOS, Android, Windows, and Cisco IOS command-line tools.&lt;/p&gt; 
&lt;h2&gt;How do I use it?&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] For browsing without installing a client on your computer, see the web client at &lt;a href="https://tldr.inbrowser.app"&gt;https://tldr.inbrowser.app&lt;/a&gt; (with offline support using PWA).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A popular and convenient way to access these pages on your computer is to install the official &lt;a href="https://github.com/tldr-pages/tldr-python-client"&gt;Python client&lt;/a&gt;, which can be installed via &lt;a href="https://pypi.org/project/tldr/"&gt;pip3&lt;/a&gt; (or &lt;a href="https://github.com/tldr-pages/tldr-python-client#installation"&gt;other package managers&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip3 install tldr
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Linux and Mac users can also install the official &lt;a href="https://github.com/tldr-pages/tlrc"&gt;Rust Client&lt;/a&gt; using &lt;a href="https://formulae.brew.sh/formula/tlrc"&gt;Homebrew&lt;/a&gt; (or &lt;a href="https://github.com/tldr-pages/tlrc#installation"&gt;other package managers&lt;/a&gt; on other operating systems):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install tlrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can also use the official &lt;a href="https://github.com/tldr-pages/tldr-node-client"&gt;Node.js client&lt;/a&gt;, although it has fallen behind in updates:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g tldr
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you have direct access to simplified, easy-to-read help for commands, such as &lt;code&gt;tar&lt;/code&gt;, accessible through typing &lt;code&gt;tldr tar&lt;/code&gt; instead of the standard &lt;code&gt;man tar&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you don't want to install any software, check out the &lt;a href="https://github.com/tldr-pages/tldr/releases/latest/download/tldr-book.pdf"&gt;PDF version&lt;/a&gt; instead.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] PDFs for translations are available for most languages. You can find them in the release assets of the &lt;a href="https://github.com/tldr-pages/tldr/releases/latest"&gt;latest release&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;There are also &lt;strong&gt;various other clients&lt;/strong&gt; provided by the community, both for the command-line and for other platforms. For a comprehensive list of clients, head over to our &lt;a href="https://github.com/tldr-pages/tldr/wiki/Clients"&gt;Wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;How do I contribute to tldr-pages?&lt;/h2&gt; 
&lt;p&gt;All contributions are welcome!&lt;/p&gt; 
&lt;p&gt;Some ways to contribute include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adding your favorite command that isn't covered.&lt;/li&gt; 
 &lt;li&gt;Adding examples or improving the content of an existing page.&lt;/li&gt; 
 &lt;li&gt;Adding requested pages from our issues with the &lt;a href="https://github.com/tldr-pages/tldr/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;help wanted&lt;/a&gt; label.&lt;/li&gt; 
 &lt;li&gt;Translating pages into different languages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All &lt;code&gt;tldr&lt;/code&gt; pages are written in Markdown so that they can be edited quite easily and changes can be submitted in pull requests here using Git on the command-line or using the GitHub web interface.&lt;/p&gt; 
&lt;p&gt;We strive to maintain a &lt;a href="https://raw.githubusercontent.com/tldr-pages/tldr/main/GOVERNANCE.md"&gt;welcoming and collaborative&lt;/a&gt; community. If it's your first time contributing, have a look at the &lt;a href="https://raw.githubusercontent.com/tldr-pages/tldr/main/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt;, and go ahead!&lt;/p&gt; 
&lt;p&gt;If you'd like to contribute to translations, you can visit &lt;a href="https://lukwebsforge.github.io/tldri18n/"&gt;https://lukwebsforge.github.io/tldri18n/&lt;/a&gt; to see the overall progress of all translations, and which translations are missing or outdated.&lt;/p&gt; 
&lt;p&gt;You are also welcome to join us on the &lt;a href="https://matrix.to/#/%23tldr-pages:matrix.org"&gt;matrix chatroom&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Similar projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/command-line-interface-pages"&gt;Command Line Interface Pages&lt;/a&gt; allows you to write standardized help pages for CLI, directories, and configs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/cheat/cheat"&gt;Cheat&lt;/a&gt; allows you to create and view interactive cheatsheets on the command-line. It was designed to help remind Unix system administrators of options for commands that they use frequently, but not frequently enough to remember.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://cheat.sh/"&gt;cheat.sh&lt;/a&gt; Aggregates cheat sheets from multiple sources (including tldr-pages) into 1 unified interface.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://devhints.io/"&gt;devhints&lt;/a&gt; Rico's cheatsheets are not just focused on the command-line and include a plethora of other cheatsheets related to programming.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/srsudar/eg"&gt;eg&lt;/a&gt; provides detailed examples with explanations on the command-line. Examples come from the repository, but &lt;code&gt;eg&lt;/code&gt; supports displaying custom examples and commands alongside the defaults.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/gnebbia/kb"&gt;kb&lt;/a&gt; is a minimalist command-line knowledge base manager. kb can be used to organize your notes and cheatsheets in a minimalist and clean way. It also supports non-text files.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/denisidoro/navi"&gt;navi&lt;/a&gt; is an interactive cheatsheet tool, which allows you to browse through specific examples or complete commands on the fly.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://bropages.org"&gt;bropages (deprecated)&lt;/a&gt; are a highly readable supplement to man pages. It shows concise, common-case examples for Unix commands. The examples are submitted by the user base, and can be voted up or down; the best entries are what people see first when they look up a command.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What does "tldr" mean?&lt;/h2&gt; 
&lt;p&gt;TL;DR stands for "Too Long; Didn't Read". It originated as Internet slang, where it is used to indicate that a long text (or parts of it) has been skipped as too lengthy. Read more in How-To Geek's &lt;a href="https://www.howtogeek.com/435266/what-does-tldr-mean-and-how-do-you-use-it/"&gt;article&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>frappe/hrms</title>
      <link>https://github.com/frappe/hrms</link>
      <description>&lt;p&gt;Open Source HR and Payroll Software&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt; &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/frappe-hr-logo.png" height="80px" width="80px" alt="Frappe HR Logo"&gt; &lt;/a&gt; 
 &lt;h2&gt;Frappe HR&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;Open Source, modern, and easy-to-use HR and Payroll Software&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/frappe/hrms/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/frappe/hrms/actions/workflows/ci.yml/badge.svg?branch=develop" alt="CI"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/frappe/hrms"&gt;&lt;img src="https://codecov.io/gh/frappe/hrms/branch/develop/graph/badge.svg?token=0TwvyUg3I5" alt="codecov"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/10972" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10972" alt="frappe%2Fhrms | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-hero.png"&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt;Website&lt;/a&gt; - 
 &lt;a href="https://docs.frappe.io/hr/introduction"&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Frappe HR&lt;/h2&gt; 
&lt;p&gt;Frappe HR has everything you need to drive excellence within the company. It's a complete HRMS solution with over 13 different modules right from Employee Management, Onboarding, Leaves, to Payroll, Taxation, and more!&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;When Frappe team started growing in terms of size, we needed an open-source HR and Payroll software. We didn't find any "true" open-source HR software out there and so decided to build one ourselves. Initially, it was a set of modules within ERPNext but version 14 onwards, as the modules became more mature, Frappe HR was created as a separate product.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Employee Lifecycle&lt;/strong&gt;: From onboarding employees, managing promotions and transfers, all the way to documenting feedback with exit interviews, make life easier for employees throughout their life cycle.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leave and Attendance&lt;/strong&gt;: Configure leave policies, pull regional holidays with a click, check-in and check-out with geolocation capturing, track leave balances and attendance with reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expense Claims and Advances&lt;/strong&gt;: Manage employee advances, claim expenses, configure multi-level approval workflows, all this with seamless integration with ERPNext accounting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Management&lt;/strong&gt;: Track goals, align goals with key result areas (KRAs), enable employees to evaluate themselves, make managing appraisal cycles easy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Payroll &amp;amp; Taxation&lt;/strong&gt;: Create salary structures, configure income tax slabs, run standard payroll, accomodate additional salaries and off cycle payments, view income breakup on salary slips and so much more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frappe HR Mobile App&lt;/strong&gt;: Apply for and approve leaves on the go, check-in and check-out, access employee profile right from the mobile app.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;View Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-appraisal.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-requisition.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-attendance.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-salary.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-pwa.png"&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe"&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe-ui"&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href="https://frappecloud.com"&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href="https://github.com/frappe/press"&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://frappecloud.com/hrms/signup" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/try-on-fc-white.png"&gt; 
   &lt;img src="https://frappe.io/files/try-on-fc-black.png" alt="Try on Frappe Cloud" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Development setup&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;You need Docker, docker-compose and git setup on your machine. Refer &lt;a href="https://docs.docker.com/"&gt;Docker documentation&lt;/a&gt;. After that, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/hrms
cd hrms/docker
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for some time until the setup script creates a site. After that you can access &lt;code&gt;http://localhost:8000&lt;/code&gt; in your browser and the login screen for HR should show up.&lt;/p&gt; 
&lt;p&gt;Use the following credentials to log in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: &lt;code&gt;Administrator&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Password: &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Set up bench by following the &lt;a href="https://frappeframework.com/docs/user/en/installation"&gt;Installation Steps&lt;/a&gt; and start the server and keep it running &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;In a separate terminal window, run the following commands &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench new-site hrms.local
$ bench get-app erpnext
$ bench get-app hrms
$ bench --site hrms.local install-app hrms
$ bench --site hrms.local add-to-hosts
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;You can access the site at &lt;code&gt;http://hrms.local:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and Community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://frappe.school"&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.frappe.io/hr"&gt;Documentation&lt;/a&gt; - Extensive documentation for Frappe HR.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.erpnext.com/"&gt;User Forum&lt;/a&gt; - Engage with the community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/frappehr"&gt;Telegram Group&lt;/a&gt; - Get instant help from the community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines"&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext.com/security"&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/frappe/hrms/develop/TRADEMARK_POLICY.md"&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;div align="center" style="padding-top: 0.75rem;"&gt; 
 &lt;a href="https://frappe.io" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/Frappe-white.png"&gt; 
   &lt;img src="https://frappe.io/files/Frappe-black.png" alt="Frappe Technologies" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>pointfreeco/swift-composable-architecture</title>
      <link>https://github.com/pointfreeco/swift-composable-architecture</link>
      <description>&lt;p&gt;A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Composable Architecture&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI"&gt;&lt;/a&gt; &lt;a href="https://www.pointfree.co/slack-invite"&gt;&lt;img src="https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&amp;amp;logo=slack" alt="Slack"&gt;&lt;/a&gt; &lt;a href="https://swiftpackageindex.com/pointfreeco/swift-composable-architecture"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dswift-versions" alt=""&gt;&lt;/a&gt; &lt;a href="https://swiftpackageindex.com/pointfreeco/swift-composable-architecture"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dplatforms" alt=""&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The Composable Architecture (TCA, for short) is a library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind. It can be used in SwiftUI, UIKit, and more, and on any Apple platform (iOS, macOS, iPadOS, visionOS, tvOS, and watchOS).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/#what-is-the-composable-architecture"&gt;What is the Composable Architecture?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/#learn-more"&gt;Learn more&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/#basic-usage"&gt;Basic usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/#community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/#translations"&gt;Translations&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is the Composable Architecture?&lt;/h2&gt; 
&lt;p&gt;This library provides a few core tools that can be used to build applications of varying purpose and complexity. It provides compelling stories that you can follow to solve many problems you encounter day-to-day when building applications, such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;State management&lt;/strong&gt; &lt;br&gt; How to manage the state of your application using simple value types, and share state across many screens so that mutations in one screen can be immediately observed in another screen.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Composition&lt;/strong&gt; &lt;br&gt; How to break down large features into smaller components that can be extracted to their own, isolated modules and be easily glued back together to form the feature.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Side effects&lt;/strong&gt; &lt;br&gt; How to let certain parts of the application talk to the outside world in the most testable and understandable way possible.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt; &lt;br&gt; How to not only test a feature built in the architecture, but also write integration tests for features that have been composed of many parts, and write end-to-end tests to understand how side effects influence your application. This allows you to make strong guarantees that your business logic is running in the way you expect.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ergonomics&lt;/strong&gt; &lt;br&gt; How to accomplish all of the above in a simple API with as few concepts and moving parts as possible.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Learn More&lt;/h2&gt; 
&lt;p&gt;The Composable Architecture was designed over the course of many episodes on &lt;a href="https://www.pointfree.co"&gt;Point-Free&lt;/a&gt;, a video series exploring advanced programming topics in the Swift language, hosted by &lt;a href="https://twitter.com/mbrandonw"&gt;Brandon Williams&lt;/a&gt; and &lt;a href="https://twitter.com/stephencelis"&gt;Stephen Celis&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can watch all of the episodes &lt;a href="https://www.pointfree.co/collections/composable-architecture"&gt;here&lt;/a&gt;, as well as a dedicated, &lt;a href="https://www.pointfree.co/collections/tours/composable-architecture-1-0"&gt;multipart tour&lt;/a&gt; of the architecture from scratch.&lt;/p&gt; 
&lt;a href="https://www.pointfree.co/collections/tours/composable-architecture-1-0"&gt; &lt;img alt="video poster image" src="https://d3rccdn33rt8ze.cloudfront.net/episodes/0243.jpeg" width="600"&gt; &lt;/a&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples"&gt;&lt;img src="https://d3rccdn33rt8ze.cloudfront.net/composable-architecture/demos.png" alt="Screen shots of example applications"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repo comes with &lt;em&gt;lots&lt;/em&gt; of examples to demonstrate how to solve common and complex problems with the Composable Architecture. Check out &lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples"&gt;this&lt;/a&gt; directory to see them all, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples/CaseStudies"&gt;Case Studies&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Getting started&lt;/li&gt; 
   &lt;li&gt;Effects&lt;/li&gt; 
   &lt;li&gt;Navigation&lt;/li&gt; 
   &lt;li&gt;Higher-order reducers&lt;/li&gt; 
   &lt;li&gt;Reusable components&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pointfreeco/composable-core-location/tree/main/Examples/LocationManager"&gt;Location manager&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pointfreeco/composable-core-motion/tree/main/Examples/MotionManager"&gt;Motion manager&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples/Search"&gt;Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples/SpeechRecognition"&gt;Speech Recognition&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples/SyncUps"&gt;SyncUps app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples/TicTacToe"&gt;Tic-Tac-Toe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples/Todos"&gt;Todos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples/VoiceMemos"&gt;Voice memos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Looking for something more substantial? Check out the source code for &lt;a href="https://github.com/pointfreeco/isowords"&gt;isowords&lt;/a&gt;, an iOS word search game built in SwiftUI and the Composable Architecture.&lt;/p&gt; 
&lt;h2&gt;Basic Usage&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] For a step-by-step interactive tutorial, be sure to check out &lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/tutorials/meetcomposablearchitecture"&gt;Meet the Composable Architecture&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To build a feature using the Composable Architecture you define some types and values that model your domain:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;State&lt;/strong&gt;: A type that describes the data your feature needs to perform its logic and render its UI.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Action&lt;/strong&gt;: A type that represents all of the actions that can happen in your feature, such as user actions, notifications, event sources and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reducer&lt;/strong&gt;: A function that describes how to evolve the current state of the app to the next state given an action. The reducer is also responsible for returning any effects that should be run, such as API requests, which can be done by returning an &lt;code&gt;Effect&lt;/code&gt; value.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Store&lt;/strong&gt;: The runtime that actually drives your feature. You send all user actions to the store so that the store can run the reducer and effects, and you can observe state changes in the store so that you can update UI.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The benefits of doing this are that you will instantly unlock testability of your feature, and you will be able to break large, complex features into smaller domains that can be glued together.&lt;/p&gt; 
&lt;p&gt;As a basic example, consider a UI that shows a number along with "+" and "−" buttons that increment and decrement the number. To make things interesting, suppose there is also a button that when tapped makes an API request to fetch a random fact about that number and displays it in the view.&lt;/p&gt; 
&lt;p&gt;To implement this feature we create a new type that will house the domain and behavior of the feature, and it will be annotated with the &lt;code&gt;@Reducer&lt;/code&gt; macro:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;import ComposableArchitecture

@Reducer
struct Feature {
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In here we need to define a type for the feature's state, which consists of an integer for the current count, as well as an optional string that represents the fact being presented:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;@Reducer
struct Feature {
  @ObservableState
  struct State: Equatable {
    var count = 0
    var numberFact: String?
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] We've applied the &lt;code&gt;@ObservableState&lt;/code&gt; macro to &lt;code&gt;State&lt;/code&gt; in order to take advantage of the observation tools in the library.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We also need to define a type for the feature's actions. There are the obvious actions, such as tapping the decrement button, increment button, or fact button. But there are also some slightly non-obvious ones, such as the action that occurs when we receive a response from the fact API request:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;@Reducer
struct Feature {
  @ObservableState
  struct State: Equatable { /* ... */ }
  enum Action {
    case decrementButtonTapped
    case incrementButtonTapped
    case numberFactButtonTapped
    case numberFactResponse(String)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then we implement the &lt;code&gt;body&lt;/code&gt; property, which is responsible for composing the actual logic and behavior for the feature. In it we can use the &lt;code&gt;Reduce&lt;/code&gt; reducer to describe how to change the current state to the next state, and what effects need to be executed. Some actions don't need to execute effects, and they can return &lt;code&gt;.none&lt;/code&gt; to represent that:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;@Reducer
struct Feature {
  @ObservableState
  struct State: Equatable { /* ... */ }
  enum Action { /* ... */ }

  var body: some Reducer&amp;lt;State, Action&amp;gt; {
    Reduce { state, action in
      switch action {
      case .decrementButtonTapped:
        state.count -= 1
        return .none

      case .incrementButtonTapped:
        state.count += 1
        return .none

      case .numberFactButtonTapped:
        return .run { [count = state.count] send in
          let (data, _) = try await URLSession.shared.data(
            from: URL(string: "http://numbersapi.com/\(count)/trivia")!
          )
          await send(
            .numberFactResponse(String(decoding: data, as: UTF8.self))
          )
        }

      case let .numberFactResponse(fact):
        state.numberFact = fact
        return .none
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then finally we define the view that displays the feature. It holds onto a &lt;code&gt;StoreOf&amp;lt;Feature&amp;gt;&lt;/code&gt; so that it can observe all changes to the state and re-render, and we can send all user actions to the store so that state changes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;struct FeatureView: View {
  let store: StoreOf&amp;lt;Feature&amp;gt;

  var body: some View {
    Form {
      Section {
        Text("\(store.count)")
        Button("Decrement") { store.send(.decrementButtonTapped) }
        Button("Increment") { store.send(.incrementButtonTapped) }
      }

      Section {
        Button("Number fact") { store.send(.numberFactButtonTapped) }
      }
      
      if let fact = store.numberFact {
        Text(fact)
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It is also straightforward to have a UIKit controller driven off of this store. You can observe state changes in the store in &lt;code&gt;viewDidLoad&lt;/code&gt;, and then populate the UI components with data from the store. The code is a bit longer than the SwiftUI version, so we have collapsed it here:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to expand!&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-swift"&gt;class FeatureViewController: UIViewController {
  let store: StoreOf&amp;lt;Feature&amp;gt;

  init(store: StoreOf&amp;lt;Feature&amp;gt;) {
    self.store = store
    super.init(nibName: nil, bundle: nil)
  }

  required init?(coder: NSCoder) {
    fatalError("init(coder:) has not been implemented")
  }

  override func viewDidLoad() {
    super.viewDidLoad()

    let countLabel = UILabel()
    let decrementButton = UIButton()
    let incrementButton = UIButton()
    let factLabel = UILabel()
    
    // Omitted: Add subviews and set up constraints...
    
    observe { [weak self] in
      guard let self 
      else { return }
      
      countLabel.text = "\(self.store.count)"
      factLabel.text = self.store.numberFact
    }
  }

  @objc private func incrementButtonTapped() {
    self.store.send(.incrementButtonTapped)
  }
  @objc private func decrementButtonTapped() {
    self.store.send(.decrementButtonTapped)
  }
  @objc private func factButtonTapped() {
    self.store.send(.numberFactButtonTapped)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;Once we are ready to display this view, for example in the app's entry point, we can construct a store. This can be done by specifying the initial state to start the application in, as well as the reducer that will power the application:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;import ComposableArchitecture

@main
struct MyApp: App {
  var body: some Scene {
    WindowGroup {
      FeatureView(
        store: Store(initialState: Feature.State()) {
          Feature()
        }
      )
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And that is enough to get something on the screen to play around with. It's definitely a few more steps than if you were to do this in a vanilla SwiftUI way, but there are a few benefits. It gives us a consistent manner to apply state mutations, instead of scattering logic in some observable objects and in various action closures of UI components. It also gives us a concise way of expressing side effects. And we can immediately test this logic, including the effects, without doing much additional work.&lt;/p&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] For more in-depth information on testing, see the dedicated &lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/testingtca"&gt;testing&lt;/a&gt; article.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To test use a &lt;code&gt;TestStore&lt;/code&gt;, which can be created with the same information as the &lt;code&gt;Store&lt;/code&gt;, but it does extra work to allow you to assert how your feature evolves as actions are sent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;@Test
func basics() async {
  let store = TestStore(initialState: Feature.State()) {
    Feature()
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once the test store is created we can use it to make an assertion of an entire user flow of steps. Each step of the way we need to prove that state changed how we expect. For example, we can simulate the user flow of tapping on the increment and decrement buttons:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;// Test that tapping on the increment/decrement buttons changes the count
await store.send(.incrementButtonTapped) {
  $0.count = 1
}
await store.send(.decrementButtonTapped) {
  $0.count = 0
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Further, if a step causes an effect to be executed, which feeds data back into the store, we must assert on that. For example, if we simulate the user tapping on the fact button we expect to receive a fact response back with the fact, which then causes the &lt;code&gt;numberFact&lt;/code&gt; state to be populated:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;await store.send(.numberFactButtonTapped)

await store.receive(\.numberFactResponse) {
  $0.numberFact = ???
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;However, how do we know what fact is going to be sent back to us?&lt;/p&gt; 
&lt;p&gt;Currently our reducer is using an effect that reaches out into the real world to hit an API server, and that means we have no way to control its behavior. We are at the whims of our internet connectivity and the availability of the API server in order to write this test.&lt;/p&gt; 
&lt;p&gt;It would be better for this dependency to be passed to the reducer so that we can use a live dependency when running the application on a device, but use a mocked dependency for tests. We can do this by adding a property to the &lt;code&gt;Feature&lt;/code&gt; reducer:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;@Reducer
struct Feature {
  let numberFact: (Int) async throws -&amp;gt; String
  // ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then we can use it in the &lt;code&gt;reduce&lt;/code&gt; implementation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;case .numberFactButtonTapped:
  return .run { [count = state.count] send in 
    let fact = try await self.numberFact(count)
    await send(.numberFactResponse(fact))
  }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And in the entry point of the application we can provide a version of the dependency that actually interacts with the real world API server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;@main
struct MyApp: App {
  var body: some Scene {
    WindowGroup {
      FeatureView(
        store: Store(initialState: Feature.State()) {
          Feature(
            numberFact: { number in
              let (data, _) = try await URLSession.shared.data(
                from: URL(string: "http://numbersapi.com/\(number)")!
              )
              return String(decoding: data, as: UTF8.self)
            }
          )
        }
      )
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;But in tests we can use a mock dependency that immediately returns a deterministic, predictable fact:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;@Test
func basics() async {
  let store = TestStore(initialState: Feature.State()) {
    Feature(numberFact: { "\($0) is a good number Brent" })
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With that little bit of upfront work we can finish the test by simulating the user tapping on the fact button, and then receiving the response from the dependency to present the fact:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;await store.send(.numberFactButtonTapped)

await store.receive(\.numberFactResponse) {
  $0.numberFact = "0 is a good number Brent"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We can also improve the ergonomics of using the &lt;code&gt;numberFact&lt;/code&gt; dependency in our application. Over time the application may evolve into many features, and some of those features may also want access to &lt;code&gt;numberFact&lt;/code&gt;, and explicitly passing it through all layers can get annoying. There is a process you can follow to “register” dependencies with the library, making them instantly available to any layer in the application.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] For more in-depth information on dependency management, see the dedicated &lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/dependencymanagement"&gt;dependencies&lt;/a&gt; article.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We can start by wrapping the number fact functionality in a new type:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;struct NumberFactClient {
  var fetch: (Int) async throws -&amp;gt; String
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then registering that type with the dependency management system by conforming the client to the &lt;code&gt;DependencyKey&lt;/code&gt; protocol, which requires you to specify the live value to use when running the application in simulators or devices:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;extension NumberFactClient: DependencyKey {
  static let liveValue = Self(
    fetch: { number in
      let (data, _) = try await URLSession.shared
        .data(from: URL(string: "http://numbersapi.com/\(number)")!
      )
      return String(decoding: data, as: UTF8.self)
    }
  )
}

extension DependencyValues {
  var numberFact: NumberFactClient {
    get { self[NumberFactClient.self] }
    set { self[NumberFactClient.self] = newValue }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With that little bit of upfront work done you can instantly start making use of the dependency in any feature by using the &lt;code&gt;@Dependency&lt;/code&gt; property wrapper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-diff"&gt; @Reducer
 struct Feature {
-  let numberFact: (Int) async throws -&amp;gt; String
+  @Dependency(\.numberFact) var numberFact
   
   …

-  try await self.numberFact(count)
+  try await self.numberFact.fetch(count)
 }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This code works exactly as it did before, but you no longer have to explicitly pass the dependency when constructing the feature's reducer. When running the app in previews, the simulator or on a device, the live dependency will be provided to the reducer, and in tests the test dependency will be provided.&lt;/p&gt; 
&lt;p&gt;This means the entry point to the application no longer needs to construct dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;@main
struct MyApp: App {
  var body: some Scene {
    WindowGroup {
      FeatureView(
        store: Store(initialState: Feature.State()) {
          Feature()
        }
      )
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And the test store can be constructed without specifying any dependencies, but you can still override any dependency you need to for the purpose of the test:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;let store = TestStore(initialState: Feature.State()) {
  Feature()
} withDependencies: {
  $0.numberFact.fetch = { "\($0) is a good number Brent" }
}

// ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That is the basics of building and testing a feature in the Composable Architecture. There are &lt;em&gt;a lot&lt;/em&gt; more things to be explored, such as composition, modularity, adaptability, and complex effects. The &lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples"&gt;Examples&lt;/a&gt; directory has a bunch of projects to explore to see more advanced usages.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The documentation for releases and &lt;code&gt;main&lt;/code&gt; are available here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/"&gt;&lt;code&gt;main&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.17.0/documentation/composablearchitecture/"&gt;1.17.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.17"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt; Other versions &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.16.0/documentation/composablearchitecture/"&gt;1.16.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.16"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.15.0/documentation/composablearchitecture/"&gt;1.15.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.15"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.14.0/documentation/composablearchitecture/"&gt;1.14.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.14"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.13.0/documentation/composablearchitecture/"&gt;1.13.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.13"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.12.0/documentation/composablearchitecture/"&gt;1.12.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.12"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.11.0/documentation/composablearchitecture/"&gt;1.11.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.11"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.10.0/documentation/composablearchitecture/"&gt;1.10.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.10"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.9.0/documentation/composablearchitecture/"&gt;1.9.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.9"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.8.0/documentation/composablearchitecture/"&gt;1.8.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.8"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.7.0/documentation/composablearchitecture/"&gt;1.7.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.7"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.6.0/documentation/composablearchitecture/"&gt;1.6.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.6"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.5.0/documentation/composablearchitecture/"&gt;1.5.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.5"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.4.0/documentation/composablearchitecture/"&gt;1.4.0&lt;/a&gt; (&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/migratingto1.4"&gt;migration guide&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.3.0/documentation/composablearchitecture/"&gt;1.3.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.2.0/documentation/composablearchitecture/"&gt;1.2.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.1.0/documentation/composablearchitecture/"&gt;1.1.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/1.0.0/documentation/composablearchitecture/"&gt;1.0.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/0.59.0/documentation/composablearchitecture/"&gt;0.59.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/0.58.0/documentation/composablearchitecture/"&gt;0.58.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/0.57.0/documentation/composablearchitecture/"&gt;0.57.0&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;br&gt; 
&lt;p&gt;There are a number of articles in the documentation that you may find helpful as you become more comfortable with the library:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/gettingstarted"&gt;Getting started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/dependencymanagement"&gt;Dependencies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/testingtca"&gt;Testing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/navigation"&gt;Navigation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/sharingstate"&gt;Sharing state&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/performance"&gt;Performance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/swiftconcurrency"&gt;Concurrency&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/bindings"&gt;Bindings&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;We have a &lt;a href="https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/faq"&gt;dedicated article&lt;/a&gt; for all of the most frequently asked questions and comments people have concerning the library.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;If you want to discuss the Composable Architecture or have a question about how to use it to solve a particular problem, there are a number of places you can discuss with fellow &lt;a href="http://www.pointfree.co"&gt;Point-Free&lt;/a&gt; enthusiasts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For long-form discussions, we recommend the &lt;a href="https://github.com/pointfreeco/swift-composable-architecture/discussions"&gt;discussions&lt;/a&gt; tab of this repo.&lt;/li&gt; 
 &lt;li&gt;For casual chat, we recommend the &lt;a href="http://pointfree.co/slack-invite"&gt;Point-Free Community slack&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can add ComposableArchitecture to an Xcode project by adding it as a package dependency.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;From the &lt;strong&gt;File&lt;/strong&gt; menu, select &lt;strong&gt;Add Package Dependencies...&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Enter "&lt;a href="https://github.com/pointfreeco/swift-composable-architecture"&gt;https://github.com/pointfreeco/swift-composable-architecture&lt;/a&gt;" into the package repository URL text field&lt;/li&gt; 
 &lt;li&gt;Depending on how your project is structured: 
  &lt;ul&gt; 
   &lt;li&gt;If you have a single application target that needs access to the library, then add &lt;strong&gt;ComposableArchitecture&lt;/strong&gt; directly to your application.&lt;/li&gt; 
   &lt;li&gt;If you want to use this library from multiple Xcode targets, or mix Xcode targets and SPM targets, you must create a shared framework that depends on &lt;strong&gt;ComposableArchitecture&lt;/strong&gt; and then depend on that framework in all of your targets. For an example of this, check out the &lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples/TicTacToe"&gt;Tic-Tac-Toe&lt;/a&gt; demo application, which splits lots of features into modules and consumes the static library in this fashion using the &lt;strong&gt;tic-tac-toe&lt;/strong&gt; Swift package.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Companion libraries&lt;/h2&gt; 
&lt;p&gt;The Composable Architecture is built with extensibility in mind, and there are a number of community-supported libraries available to enhance your applications:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Ryu0118/swift-composable-architecture-extras"&gt;Composable Architecture Extras&lt;/a&gt;: A companion library to the Composable Architecture.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mentalflux/tca-composer"&gt;TCAComposer&lt;/a&gt;: A macro framework for generating boiler-plate code in the Composable Architecture.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/johnpatrickmorgan/TCACoordinators"&gt;TCACoordinators&lt;/a&gt;: The coordinator pattern in the Composable Architecture.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you'd like to contribute a library, please &lt;a href="https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md"&gt;open a PR&lt;/a&gt; with a link to it!&lt;/p&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;The following translations of this README have been contributed by members of the community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/NorhanBoghdadi/1b98d55c02b683ddef7e05c2ebcccd47"&gt;Arabic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/nikitamounier/0e93eb832cf389db12f9a69da030a2dc"&gt;French&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/akashsoni01/b358ee0b3b747167964ef6946123c88d"&gt;Hindi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/wendyliga/792ea9ac5cc887f59de70a9e39cc7343"&gt;Indonesian&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/Bellaposa/5114e6d4d55fdb1388e8186886d48958"&gt;Italian&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/Achoo-kr/2d0712deb77f78b3379551ac7baea3e4"&gt;Japanese&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/Achoo-kr/5d8936d12e71028fcc4a7c5e078ca038"&gt;Korean&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/MarcelStarczyk/6b6153051f46912a665c32199f0d1d54"&gt;Polish&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/SevioCorrea/2bbf337cd084a58c89f2f7f370626dc8"&gt;Portuguese&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/SubvertDev/3317d0c3b35ed601be330d6fc0df5aba"&gt;Russian&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/sh3l6orrr/10c8f7c634a892a9c37214f3211242ad"&gt;Simplified Chinese&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/pitt500/f5e32fccb575ce112ffea2827c7bf942"&gt;Spanish&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/gokhanamal/93001244ef0c1cec58abeb1afc0de37c"&gt;Turkish&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/barabashd/33b64676195ce41f4bb73c327ea512a8"&gt;Ukrainian&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you'd like to contribute a translation, please &lt;a href="https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md"&gt;open a PR&lt;/a&gt; with a link to a &lt;a href="https://gist.github.com"&gt;Gist&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Credits and thanks&lt;/h2&gt; 
&lt;p&gt;The following people gave feedback on the library at its early stages and helped make the library what it is today:&lt;/p&gt; 
&lt;p&gt;Paul Colton, Kaan Dedeoglu, Matt Diephouse, Josef Doležal, Eimantas, Matthew Johnson, George Kaimakas, Nikita Leonov, Christopher Liscio, Jeffrey Macko, Alejandro Martinez, Shai Mishali, Willis Plummer, Simon-Pierre Roy, Justin Price, Sven A. Schmidt, Kyle Sherman, Petr Šíma, Jasdev Singh, Maxim Smirnov, Ryan Stone, Daniel Hollis Tavares, and all of the &lt;a href="https://www.pointfree.co"&gt;Point-Free&lt;/a&gt; subscribers 😁.&lt;/p&gt; 
&lt;p&gt;Special thanks to &lt;a href="https://twitter.com/liscio"&gt;Chris Liscio&lt;/a&gt; who helped us work through many strange SwiftUI quirks and helped refine the final API.&lt;/p&gt; 
&lt;p&gt;And thanks to &lt;a href="https://github.com/freak4pc"&gt;Shai Mishali&lt;/a&gt; and the &lt;a href="https://github.com/CombineCommunity/CombineExt/"&gt;CombineCommunity&lt;/a&gt; project, from which we took their implementation of &lt;code&gt;Publishers.Create&lt;/code&gt;, which we use in &lt;code&gt;Effect&lt;/code&gt; to help bridge delegate and callback-based APIs, making it much easier to interface with 3rd party frameworks.&lt;/p&gt; 
&lt;h2&gt;Other libraries&lt;/h2&gt; 
&lt;p&gt;The Composable Architecture was built on a foundation of ideas started by other libraries, in particular &lt;a href="https://elm-lang.org"&gt;Elm&lt;/a&gt; and &lt;a href="https://redux.js.org/"&gt;Redux&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;There are also many architecture libraries in the Swift and iOS community. Each one of these has their own set of priorities and trade-offs that differ from the Composable Architecture.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/uber/RIBs"&gt;RIBs&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ReactiveCocoa/Loop"&gt;Loop&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ReSwift/ReSwift"&gt;ReSwift&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/square/workflow"&gt;Workflow&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ReactorKit/ReactorKit"&gt;ReactorKit&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/NoTests/RxFeedback.swift"&gt;RxFeedback&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/spotify/mobius.swift"&gt;Mobius.swift&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;And more&lt;/summary&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://github.com/FluxorOrg/Fluxor"&gt;Fluxor&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/RPallas92/PromisedArchitectureKit"&gt;PromisedArchitectureKit&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This library is released under the MIT license. See &lt;a href="https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mattermost-community/focalboard</title>
      <link>https://github.com/mattermost-community/focalboard</link>
      <description>&lt;p&gt;Focalboard is an open source, self-hosted alternative to Trello, Notion, and Asana.&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] This repository is currently not maintained. If you're interested in becoming a maintainer please &lt;a href="https://github.com/mattermost-community/focalboard/issues/5038"&gt;let us know here&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;This repository only contains standalone Focalboard. If you're looking for the Mattermost plugin please see &lt;a href="https://github.com/mattermost/mattermost-plugin-boards"&gt;mattermost/mattermost-plugin-boards&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Focalboard&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/mattermost/focalboard/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI Status"&gt; &lt;img src="https://github.com/mattermost/focalboard/actions/workflows/codeql-analysis.yml/badge.svg?sanitize=true" alt="CodeQL"&gt; &lt;img src="https://github.com/mattermost/focalboard/actions/workflows/dev-release.yml/badge.svg?sanitize=true" alt="Dev Release"&gt; &lt;img src="https://github.com/mattermost/focalboard/actions/workflows/prod-release.yml/badge.svg?sanitize=true" alt="Prod Release"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/mattermost-community/focalboard/main/website/site/static/img/hero.jpg" alt="Focalboard"&gt;&lt;/p&gt; 
&lt;p&gt;Focalboard is an open source, multilingual, self-hosted project management tool that's an alternative to Trello, Notion, and Asana.&lt;/p&gt; 
&lt;p&gt;It helps define, organize, track and manage work across individuals and teams. Focalboard comes in two editions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.focalboard.com/docs/personal-edition/desktop/"&gt;Personal Desktop&lt;/a&gt;&lt;/strong&gt;: A standalone, single-user &lt;a href="https://apps.apple.com/app/apple-store/id1556908618?pt=2114704&amp;amp;ct=website&amp;amp;mt=8"&gt;macOS&lt;/a&gt;, &lt;a href="https://www.microsoft.com/store/apps/9NLN2T0SX9VF?cid=website"&gt;Windows&lt;/a&gt;, or &lt;a href="https://www.focalboard.com/download/personal-edition/desktop/#linux-desktop"&gt;Linux&lt;/a&gt; desktop app for your own todos and personal projects.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.focalboard.com/download/personal-edition/ubuntu/"&gt;Personal Server&lt;/a&gt;&lt;/strong&gt;: A standalone, multi-user server for development and personal use.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Try Focalboard&lt;/h2&gt; 
&lt;h3&gt;Personal Desktop (Windows, Mac or Linux Desktop)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: Download from the &lt;a href="https://www.microsoft.com/store/productId/9NLN2T0SX9VF"&gt;Windows App Store&lt;/a&gt; or download &lt;code&gt;focalboard-win.zip&lt;/code&gt; from the &lt;a href="https://github.com/mattermost/focalboard/releases"&gt;latest release&lt;/a&gt;, unpack, and run &lt;code&gt;Focalboard.exe&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mac&lt;/strong&gt;: Download from the &lt;a href="https://apps.apple.com/us/app/focalboard-insiders/id1556908618?mt=12"&gt;Mac App Store&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux Desktop&lt;/strong&gt;: Download &lt;code&gt;focalboard-linux.tar.gz&lt;/code&gt; from the &lt;a href="https://github.com/mattermost/focalboard/releases"&gt;latest release&lt;/a&gt;, unpack, and open &lt;code&gt;focalboard-app&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Personal Server&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Ubuntu&lt;/strong&gt;: You can download and run the compiled Focalboard &lt;strong&gt;Personal Server&lt;/strong&gt; on Ubuntu by following &lt;a href="https://www.focalboard.com/download/personal-edition/ubuntu/"&gt;our latest install guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;API Docs&lt;/h3&gt; 
&lt;p&gt;Boards API docs can be found over at &lt;a href="https://htmlpreview.github.io/?https://github.com/mattermost/focalboard/raw/main/server/swagger/docs/html/index.html"&gt;https://htmlpreview.github.io/?https://github.com/mattermost/focalboard/blob/main/server/swagger/docs/html/index.html&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Getting started&lt;/h3&gt; 
&lt;p&gt;Our &lt;a href="https://developers.mattermost.com/contribute/focalboard/personal-server-setup-guide"&gt;developer guide&lt;/a&gt; has detailed instructions on how to set up your development environment for the &lt;strong&gt;Personal Server&lt;/strong&gt;. You can also join the &lt;a href="https://community.mattermost.com/core/channels/focalboard"&gt;~Focalboard community channel&lt;/a&gt; to connect with other developers.&lt;/p&gt; 
&lt;p&gt;Create an &lt;code&gt;.env&lt;/code&gt; file in the focalboard directory that contains:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;EXCLUDE_ENTERPRISE="1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make prebuild
make
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; ./bin/focalboard-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate your browser to &lt;a href="http://localhost:8000"&gt;&lt;code&gt;http://localhost:8000&lt;/code&gt;&lt;/a&gt; to access your Focalboard server. The port is configured in &lt;code&gt;config.json&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Once the server is running, you can rebuild just the web app via &lt;code&gt;make webapp&lt;/code&gt; in a separate terminal window. Reload your browser to see the changes.&lt;/p&gt; 
&lt;h3&gt;Building and running standalone desktop apps&lt;/h3&gt; 
&lt;p&gt;You can build standalone apps that package the server to run locally against SQLite:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;em&gt;Requires Windows 10, &lt;a href="https://developer.microsoft.com/en-us/windows/downloads/sdk-archive/"&gt;Windows 10 SDK&lt;/a&gt; 10.0.19041.0, and .NET 4.8 developer pack&lt;/em&gt;&lt;/li&gt; 
   &lt;li&gt;Open a &lt;code&gt;git-bash&lt;/code&gt; prompt.&lt;/li&gt; 
   &lt;li&gt;Run &lt;code&gt;make prebuild&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;The above prebuild step needs to be run only when you make changes to or want to install your npm dependencies, etc.&lt;/li&gt; 
   &lt;li&gt;Once the prebuild is completed, you can keep repeating the below steps to build the app &amp;amp; see the changes.&lt;/li&gt; 
   &lt;li&gt;Run &lt;code&gt;make win-wpf-app&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Run &lt;code&gt;cd win-wpf/msix &amp;amp;&amp;amp; focalboard.exe&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mac&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;em&gt;Requires macOS 11.3+ and Xcode 13.2.1+&lt;/em&gt;&lt;/li&gt; 
   &lt;li&gt;Run &lt;code&gt;make prebuild&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;The above prebuild step needs to be run only when you make changes to or want to install your npm dependencies, etc.&lt;/li&gt; 
   &lt;li&gt;Once the prebuild is completed, you can keep repeating the below steps to build the app &amp;amp; see the changes.&lt;/li&gt; 
   &lt;li&gt;Run &lt;code&gt;make mac-app&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Run &lt;code&gt;open mac/dist/Focalboard.app&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;em&gt;Tested on Ubuntu 18.04&lt;/em&gt;&lt;/li&gt; 
   &lt;li&gt;Install &lt;code&gt;webgtk&lt;/code&gt; dependencies 
    &lt;ul&gt; 
     &lt;li&gt;Run &lt;code&gt;sudo apt-get install libgtk-3-dev&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;Run &lt;code&gt;sudo apt-get install libwebkit2gtk-4.0-dev&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Run &lt;code&gt;make prebuild&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;The above prebuild step needs to be run only when you make changes to or want to install your npm dependencies, etc.&lt;/li&gt; 
   &lt;li&gt;Once the prebuild is completed, you can keep repeating the below steps to build the app &amp;amp; see the changes.&lt;/li&gt; 
   &lt;li&gt;Run &lt;code&gt;make linux-app&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Uncompress &lt;code&gt;linux/dist/focalboard-linux.tar.gz&lt;/code&gt; to a directory of your choice&lt;/li&gt; 
   &lt;li&gt;Run &lt;code&gt;focalboard-app&lt;/code&gt; from the directory you have chosen&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;To run it locally from offical image: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;docker run -it -p 80:8000 mattermost/focalboard&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;To build it for your current architecture: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;docker build -f docker/Dockerfile .&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;To build it for a custom architecture (experimental): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;docker build -f docker/Dockerfile --platform linux/arm64 .&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Cross-compilation currently isn't fully supported, so please build on the appropriate platform. Refer to the GitHub Actions workflows (&lt;code&gt;build-mac.yml&lt;/code&gt;, &lt;code&gt;build-win.yml&lt;/code&gt;, &lt;code&gt;build-ubuntu.yml&lt;/code&gt;) for the detailed list of steps on each platform.&lt;/p&gt; 
&lt;h3&gt;Unit testing&lt;/h3&gt; 
&lt;p&gt;Before checking in commits, run &lt;code&gt;make ci&lt;/code&gt;, which is similar to the &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; workflow and includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Server unit tests&lt;/strong&gt;: &lt;code&gt;make server-test&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web app ESLint&lt;/strong&gt;: &lt;code&gt;cd webapp; npm run check&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web app unit tests&lt;/strong&gt;: &lt;code&gt;cd webapp; npm run test&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web app UI tests&lt;/strong&gt;: &lt;code&gt;cd webapp; npm run cypress:ci&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Staying informed&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Changes&lt;/strong&gt;: See the &lt;a href="https://raw.githubusercontent.com/mattermost-community/focalboard/main/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt; for the latest updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug Reports&lt;/strong&gt;: &lt;a href="https://github.com/mattermost/focalboard/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title="&gt;File a bug report&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat&lt;/strong&gt;: Join the &lt;a href="https://community.mattermost.com/core/channels/focalboard"&gt;~Focalboard community channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>QwenLM/Qwen3-Coder</title>
      <link>https://github.com/QwenLM/Qwen3-Coder</link>
      <description>&lt;p&gt;Qwen3-Coder is the code version of Qwen3, the large language model series developed by Qwen team, Alibaba Cloud.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3_coder.png" width="400"&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3-coder-main.jpg" width="800"&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; 💜 &lt;a href="https://chat.qwenlm.ai/"&gt;&lt;b&gt;Qwen Chat&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🤗 &lt;a href="https://huggingface.co/collections/Qwen/qwen3-coder-687fc861e53c939e52d52d10"&gt;Hugging Face&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🤖 &lt;a href="https://modelscope.cn/organization/qwen"&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 📑 &lt;a href="https://qwenlm.github.io/blog/qwen3-coder"&gt;Blog&lt;/a&gt; &amp;nbsp;&amp;nbsp; ｜ &amp;nbsp;&amp;nbsp;📖 &lt;a href="https://qwen.readthedocs.io/"&gt;Documentation&lt;/a&gt; &lt;br&gt; &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 🌍 &lt;a href="https://huggingface.co/spaces/Qwen/Qwen3-Coder-WebDev"&gt;WebDev&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;💬 &lt;a href="https://github.com/QwenLM/Qwen/raw/main/assets/wechat.png"&gt;WeChat (微信)&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🫨 &lt;a href="https://discord.gg/CV4E9rpNSD"&gt; Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 📄 &lt;a href="https://arxiv.org/abs/2505.09388"&gt;Arxiv&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 👽 &lt;a href="https://github.com/QwenLM/qwen-code"&gt;Qwen Code&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Visit our Hugging Face or ModelScope organization (click links above), search checkpoints with names starting with &lt;code&gt;Qwen3-Coder-&lt;/code&gt;, and you will find all you need! Enjoy!&lt;/p&gt; 
&lt;h1&gt;Latest News&lt;/h1&gt; 
&lt;p&gt;🔥🔥🔥 Qwen3-Coder-30B-A3B-Instruct has been released, for more information &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct/tree/main"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Qwen3-Coder: Agentic Coding in the World.&lt;/h1&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Today, we're announcing Qwen3-Coder, our most agentic code model to date. &lt;strong&gt;Qwen3-Coder&lt;/strong&gt; is available in multiple sizes, but we're excited to introduce its most powerful variant first: &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt; — a 480B-parameter Mixture-of-Experts model with 35B active parameters, offering exceptional performance in both coding and agentic tasks. &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt; sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet.&lt;/p&gt; 
&lt;p&gt;💻 &lt;strong&gt;Significant Performance&lt;/strong&gt;: among open models on &lt;strong&gt;Agentic Coding&lt;/strong&gt;, &lt;strong&gt;Agentic Browser-Use&lt;/strong&gt;, and other foundational coding tasks, achieving results comparable to Claude Sonnet;&lt;/p&gt; 
&lt;p&gt;📚 &lt;strong&gt;Long-context Capabilities&lt;/strong&gt;: with native support for &lt;strong&gt;256K&lt;/strong&gt; tokens, extendable up to &lt;strong&gt;1M&lt;/strong&gt; tokens using Yarn, optimized for repository-scale understanding;&lt;/p&gt; 
&lt;p&gt;🛠 &lt;strong&gt;Agentic Coding&lt;/strong&gt;: supporting for most platform such as &lt;strong&gt;Qwen Code&lt;/strong&gt;, &lt;strong&gt;CLINE&lt;/strong&gt;, featuring a specially designed function call format;&lt;/p&gt; 
&lt;h2&gt;Basic information&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;✨ Supporting long context understanding and generation with the context length of 256K tokens;&lt;/li&gt; 
 &lt;li&gt;✨ Supporting 358 coding languages;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;['ABAP', 'ActionScript', 'Ada', 'Agda', 'Alloy', 'ApacheConf', 'AppleScript', 'Arc', 'Arduino', 'AsciiDoc', 'AspectJ', 'Assembly', 'Augeas', 'AutoHotkey', 'AutoIt', 'Awk', 'Batchfile', 'Befunge', 'Bison', 'BitBake', 'BlitzBasic', 'BlitzMax', 'Bluespec', 'Boo', 'Brainfuck', 'Brightscript', 'Bro', 'C', 'C#', 'C++', 'C2hs Haskell', 'CLIPS', 'CMake', 'COBOL', 'CSS', 'CSV', "Cap'n Proto", 'CartoCSS', 'Ceylon', 'Chapel', 'ChucK', 'Cirru', 'Clarion', 'Clean', 'Click', 'Clojure', 'CoffeeScript', 'ColdFusion', 'ColdFusion CFC', 'Common Lisp', 'Component Pascal', 'Coq', 'Creole', 'Crystal', 'Csound', 'Cucumber', 'Cuda', 'Cycript', 'Cython', 'D', 'DIGITAL Command Language', 'DM', 'DNS Zone', 'Darcs Patch', 'Dart', 'Diff', 'Dockerfile', 'Dogescript', 'Dylan', 'E', 'ECL', 'Eagle', 'Ecere Projects', 'Eiffel', 'Elixir', 'Elm', 'Emacs Lisp', 'EmberScript', 'Erlang', 'F#', 'FLUX', 'FORTRAN', 'Factor', 'Fancy', 'Fantom', 'Forth', 'FreeMarker', 'G-code', 'GAMS', 'GAP', 'GAS', 'GDScript', 'GLSL', 'Genshi', 'Gentoo Ebuild', 'Gentoo Eclass', 'Gettext Catalog', 'Glyph', 'Gnuplot', 'Go', 'Golo', 'Gosu', 'Grace', 'Gradle', 'Grammatical Framework', 'GraphQL', 'Graphviz (DOT)', 'Groff', 'Groovy', 'Groovy Server Pages', 'HCL', 'HLSL', 'HTML', 'HTML+Django', 'HTML+EEX', 'HTML+ERB', 'HTML+PHP', 'HTTP', 'Haml', 'Handlebars', 'Harbour', 'Haskell', 'Haxe', 'Hy', 'IDL', 'IGOR Pro', 'INI', 'IRC log', 'Idris', 'Inform 7', 'Inno Setup', 'Io', 'Ioke', 'Isabelle', 'J', 'JFlex', 'JSON', 'JSON5', 'JSONLD', 'JSONiq', 'JSX', 'Jade', 'Jasmin', 'Java', 'Java Server Pages', 'JavaScript', 'Julia', 'Jupyter Notebook', 'KRL', 'KiCad', 'Kit', 'Kotlin', 'LFE', 'LLVM', 'LOLCODE', 'LSL', 'LabVIEW', 'Lasso', 'Latte', 'Lean', 'Less', 'Lex', 'LilyPond', 'Linker Script', 'Liquid', 'Literate Agda', 'Literate CoffeeScript', 'Literate Haskell', 'LiveScript', 'Logos', 'Logtalk', 'LookML', 'Lua', 'M', 'M4', 'MAXScript', 'MTML', 'MUF', 'Makefile', 'Mako', 'Maple', 'Markdown', 'Mask', 'Mathematica', 'Matlab', 'Max', 'MediaWiki', 'Metal', 'MiniD', 'Mirah', 'Modelica', 'Module Management System', 'Monkey', 'MoonScript', 'Myghty', 'NSIS', 'NetLinx', 'NetLogo', 'Nginx', 'Nimrod', 'Ninja', 'Nit', 'Nix', 'Nu', 'NumPy', 'OCaml', 'ObjDump', 'Objective-C++', 'Objective-J', 'Octave', 'Omgrofl', 'Opa', 'Opal', 'OpenCL', 'OpenEdge ABL', 'OpenSCAD', 'Org', 'Ox', 'Oxygene', 'Oz', 'PAWN', 'PHP', 'POV-Ray SDL', 'Pan', 'Papyrus', 'Parrot', 'Parrot Assembly', 'Parrot Internal Representation', 'Pascal', 'Perl', 'Perl6', 'Pickle', 'PigLatin', 'Pike', 'Pod', 'PogoScript', 'Pony', 'PostScript', 'PowerShell', 'Processing', 'Prolog', 'Propeller Spin', 'Protocol Buffer', 'Public Key', 'Pure Data', 'PureBasic', 'PureScript', 'Python', 'Python traceback', 'QML', 'QMake', 'R', 'RAML', 'RDoc', 'REALbasic', 'RHTML', 'RMarkdown', 'Racket', 'Ragel in Ruby Host', 'Raw token data', 'Rebol', 'Red', 'Redcode', "Ren'Py", 'RenderScript', 'RobotFramework', 'Rouge', 'Ruby', 'Rust', 'SAS', 'SCSS', 'SMT', 'SPARQL', 'SQF', 'SQL', 'STON', 'SVG', 'Sage', 'SaltStack', 'Sass', 'Scala', 'Scaml', 'Scheme', 'Scilab', 'Self', 'Shell', 'ShellSession', 'Shen', 'Slash', 'Slim', 'Smali', 'Smalltalk', 'Smarty', 'Solidity', 'SourcePawn', 'Squirrel', 'Stan', 'Standard ML', 'Stata', 'Stylus', 'SuperCollider', 'Swift', 'SystemVerilog', 'TOML', 'TXL', 'Tcl', 'Tcsh', 'TeX', 'Tea', 'Text', 'Textile', 'Thrift', 'Turing', 'Turtle', 'Twig', 'TypeScript', 'Unified Parallel C', 'Unity3D Asset', 'Uno', 'UnrealScript', 'UrWeb', 'VCL', 'VHDL', 'Vala', 'Verilog', 'VimL', 'Visual Basic', 'Volt', 'Vue', 'Web Ontology Language', 'WebAssembly', 'WebIDL', 'X10', 'XC', 'XML', 'XPages', 'XProc', 'XQuery', 'XS', 'XSLT', 'Xojo', 'Xtend', 'YAML', 'YANG', 'Yacc', 'Zephir', 'Zig', 'Zimpl', 'desktop', 'eC', 'edn', 'fish', 'mupad', 'nesC', 'ooc', 'reStructuredText', 'wisp', 'xBase']
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;✨ Retain strengths in math and general capabilities from base model.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important]&lt;/p&gt; 
 &lt;p&gt;Qwen3-coder function calling relies on our new tool parser &lt;code&gt;qwen3coder_tool_parser.py&lt;/code&gt; &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct/blob/main/qwen3coder_tool_parser.py"&gt;here&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;We updated both the special tokens and their corresponding token ids, in order to maintain consistency with Qwen3. Please make sure to use the new tokenizer.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;model name&lt;/th&gt; 
   &lt;th&gt;type&lt;/th&gt; 
   &lt;th&gt;length&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/td&gt; 
   &lt;td&gt;instruct&lt;/td&gt; 
   &lt;td&gt;256k&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct"&gt;Hugging Face&lt;/a&gt; • 🤖 &lt;a href="https://modelscope.cn/models/Qwen/Qwen3-Coder-480B-A35B-Instruct"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qwen3-Coder-480B-A35B-Instruct-FP8&lt;/td&gt; 
   &lt;td&gt;instruct&lt;/td&gt; 
   &lt;td&gt;256k&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"&gt;Hugging Face&lt;/a&gt; • 🤖 &lt;a href="https://modelscope.cn/models/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qwen3-Coder-30B-A3B-Instruct&lt;/td&gt; 
   &lt;td&gt;instruct&lt;/td&gt; 
   &lt;td&gt;256k&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"&gt;Hugging Face&lt;/a&gt; • 🤖 &lt;a href="https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qwen3-Coder-30B-A3B-Instruct-FP8&lt;/td&gt; 
   &lt;td&gt;instruct&lt;/td&gt; 
   &lt;td&gt;256k&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8"&gt;Hugging Face&lt;/a&gt; • 🤖 &lt;a href="https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Detailed performance and introduction are shown in this &lt;a href="https://qwenlm.github.io/blog/qwen3-coder"&gt; 📑 blog&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt; are instruction models for chatting;&lt;/p&gt; 
 &lt;p&gt;This model supports only non-thinking mode and does not generate &lt;code&gt;&amp;lt;think&amp;gt;&amp;lt;/think&amp;gt;&lt;/code&gt; blocks in its output. Meanwhile, specifying &lt;code&gt;enable_thinking=False&lt;/code&gt; is no longer required.**&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;👉🏻 Chat with Qwen3-Coder&lt;/h3&gt; 
&lt;p&gt;You can just write several lines of code with &lt;code&gt;transformers&lt;/code&gt; to chat with Qwen3-Coder-480B-A35B-Instruct. Essentially, we build the tokenizer and the model with &lt;code&gt;from_pretrained&lt;/code&gt; method, and we use generate method to perform chatting with the help of chat template provided by the tokenizer. Below is an example of how to chat with &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen3-Coder-480B-A35B-Instruct"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = "write a quick sort algorithm."
messages = [
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=65536
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;apply_chat_template()&lt;/code&gt; function is used to convert the messages into a format that the model can understand. The &lt;code&gt;add_generation_prompt&lt;/code&gt; argument is used to add a generation prompt, which refers to &lt;code&gt;&amp;lt;|im_start|&amp;gt;assistant\n&lt;/code&gt; to the input. Notably, we apply ChatML template for chat models following our previous practice. The &lt;code&gt;max_new_tokens&lt;/code&gt; argument is used to set the maximum length of the response. The &lt;code&gt;tokenizer.batch_decode()&lt;/code&gt; function is used to decode the response. In terms of the input, the above messages is an example to show how to format your dialog history and system prompt. You can use the other size of instruct model in the same way.&lt;/p&gt; 
&lt;h4&gt;Fill in the middle with Qwen3-Coder&lt;/h4&gt; 
&lt;p&gt;The code insertion task, also referred to as the "fill-in-the-middle" challenge, requires the insertion of code segments in a manner that bridges the gaps within a given code context. For an approach aligned with best practices, we recommend adhering to the formatting guidelines outlined in the paper "Efficient Training of Language Models to Fill in the Middle"[&lt;a href="https://arxiv.org/abs/2207.14255"&gt;arxiv&lt;/a&gt;].&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] It should be noted that FIM is supported in every version of Qwen3-Coder. Qwen3-Coder-480B-A35B-Instruct is shown here as an example.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The prompt should be structured as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;prompt = '&amp;lt;|fim_prefix|&amp;gt;' + prefix_code + '&amp;lt;|fim_suffix|&amp;gt;' + suffix_code + '&amp;lt;|fim_middle|&amp;gt;'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Following the approach mentioned, an example would be structured in this manner:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from transformers import AutoTokenizer, AutoModelForCausalLM
# load model
device = "cuda" # the device to load the model onto

TOKENIZER = AutoTokenizer.from_pretrained("Qwen/Qwen3-Coder-480B-A35B-Instruct")
MODEL = AutoModelForCausalLM.from_pretrained("Qwen/Qwen3-Coder-480B-A35B-Instruct", device_map="auto").eval()


input_text = """&amp;lt;|fim_prefix|&amp;gt;def quicksort(arr):
    if len(arr) &amp;lt;= 1:
        return arr
    pivot = arr[len(arr) // 2]
    &amp;lt;|fim_suffix|&amp;gt;
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x &amp;gt; pivot]
    return quicksort(left) + middle + quicksort(right)&amp;lt;|fim_middle|&amp;gt;"""
            
messages = [
    {"role": "system", "content": "You are a code completion assistant."},
    {"role": "user", "content": input_text}
]


text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = TOKENIZER([text], return_tensors="pt").to(model.device)

# Use `max_new_tokens` to control the maximum output length.
eos_token_ids = [151659, 151661, 151662, 151663, 151664, 151643, 151645]
generated_ids = MODEL.generate(model_inputs.input_ids, max_new_tokens=512, do_sample=False, eos_token_id=eos_token_ids)[0]
# The generated_ids include prompt_ids, we only need to decode the tokens after prompt_ids.
output_text = TOKENIZER.decode(generated_ids[len(model_inputs.input_ids[0]):], skip_special_tokens=True)

print(f"Prompt: {input_text}\n\nGenerated text: {output_text}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Use Cases&lt;/h2&gt; 
&lt;h3&gt;Example: Physics-Based Chimney Demolition Simulation with Controlled Explosion&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Prompt with Qwen Chat Web Dev &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;使用 three.js, cannon-es.js 生成一个震撼的3D建筑拆除演示。

## 场景设置：
- 地面是一个深灰色混凝土平面，尺寸80*80，
- 所有物体严格遵循现实物理规则，包括重力、摩擦力、碰撞检测和动量守恒

## 建筑结构：
- 一座圆形高层建筑，周长对应20个方块
- 建筑总高度60个方块
- 每层采用砖砌结构，方块与砖结构建筑一致, 错开50%排列，增强结构稳定性
- 建筑外墙使用米色方块
- **重要：方块初始排列时必须确保紧密贴合，无间隙，可以通过轻微重叠或调整半径来实现**
- **重要：建筑初始化完成后，所有方块应该处于物理"睡眠"状态，确保建筑在爆炸前保持完美的静止状态，不会因重力而下沉或松散**
- 建筑砖块之间使用粘性材料填充（不可见），通过高摩擦力（0.8+）和低弹性（0.05以下）来模拟粘合效果
- 砖块在建筑倒塌瞬间不会散掉，而是建筑作为一个整体倒在地面的时候才因受力过大而散掉

## 定向爆破系统：
- 在建筑的第1层的最右侧方块附近安装爆炸装置（不可见）
- 提供操作按钮点击爆炸
- **爆炸时唤醒所有相关方块的物理状态**
- 爆炸点产生半径2的强力冲击波，冲击波影响到的方块, 受到2-5单位的冲击力

## 建筑稳定性要求：
- **确保建筑在未爆炸时完全静止，无任何晃动或下沉**
- **物理世界初始化后给建筑几个物理步骤来自然稳定，或使用睡眠机制**
- **方块间的接触材料应具有高摩擦力和极低弹性，模拟砖块间的砂浆粘合**

## 震撼的倒塌效果：
- 方块在爆炸冲击下不仅飞散，还会在空中翻滚和碰撞
- 烟尘会随着建筑倒塌逐渐扩散，营造真实的拆除现场氛围

## 增强的视觉效果：
- 添加环境光照变化：爆炸瞬间亮度激增，然后被烟尘遮挡变暗
- 粒子系统包括：烟雾、灰尘

## 技术要求：
- 粒子系统用于烟雾和灰尘效果
- 所有代码集成在单个HTML文件中，包含必要的CSS样式
- 添加简单的UI控制：重置按钮、相机角度切换, 爆炸按钮, 鼠标左键控制摄像机角度，右键控制摄像机位置，滚轮控制摄像机焦距
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo1.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example1.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: Multicolor and Interactive Animation&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Prompt with Cline [act mode] &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;Create an amazing animation multicolor and interactive using p5js

use this cdn:
https://cdn.jsdelivr.net/npm/p5@1.7.0/lib/p5.min.js
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo2.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example2.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: 3D Google Earth&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Prompt with Qwen Chat Web Dev &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;To create a 3D Google Earth, you need to load the terrain map correctly. You can use any online resource. The code is written into an HTML file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo3.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example3.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: Testing Your WPM with a Famous Quote&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt with Qwen-Code CLI &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;Create an interesting typing game with a keyboard in the lower middle of the screen and some famous articles in the upper middle. When the user types a word correctly, a cool reaction should be given to encourage him. Design a modern soft color scheme inspired by macarons. Come up with a very creative solution first, and then start writing code.
The game should be able to support typing, and you need to neglect upcase and lowercase.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo4.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example4.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: Bouncing Ball in Rotation Hypercube&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt with Qwen Chat Web Dev &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;Make a page in HTML that shows an animation of a ball bouncing in a rotating hypercube
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo5.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example5.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: Solar System Simulation&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt with Cline [act mode] &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;write a web page to show the solar system simulation
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo6.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example6.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;Example: DUET Game&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt with Cline [act mode] &lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;Create a complete, single-file HTML game with CSS and JavaScript. The game is inspired by "Duet".

Gameplay:

There are two balls, one red and one blue, rotating around a central point.
The player uses the 'A' and 'D' keys to rotate them counter-clockwise and clockwise.
White rectangular obstacles move down from the top of the screen.
The player must rotate the balls to avoid hitting the obstacles.
If a ball hits an obstacle, the game is over.
Visuals:

Make the visual effects amazing.
Use a dark background with neon glowing effects for the balls and obstacles.
Animations should be very smooth.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p align="center"&gt; &lt;a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo7.mp4"&gt; &lt;img src="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/assets/usage_demo_example7.png" width="400"&gt; &lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#QwenLM/Qwen3-Coder&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=QwenLM/Qwen3-Coder&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our work helpful, feel free to give us a cite.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{qwen3technicalreport,
      title={Qwen3 Technical Report}, 
      author={Qwen Team},
      year={2025},
      eprint={2505.09388},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.09388},
}
@article{hui2024qwen2,
  title={Qwen2. 5-Coder Technical Report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},
  journal={arXiv preprint arXiv:2409.12186},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;p&gt;If you are interested to leave a message to either our research team or product team, join our &lt;a href="https://discord.gg/z3GAxXZ9Ce"&gt;Discord&lt;/a&gt; or &lt;a href="https://github.com/QwenLM/Qwen/raw/main/assets/wechat.png"&gt;WeChat groups&lt;/a&gt;!&lt;/p&gt; 
&lt;p align="right" style="font-size: 14px; color: #555; margin-top: 20px;"&gt; &lt;a href="https://raw.githubusercontent.com/QwenLM/Qwen3-Coder/main/#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;"&gt; ↑ Back to Top ↑ &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rustdesk/rustdesk</title>
      <link>https://github.com/rustdesk/rustdesk</link>
      <description>&lt;p&gt;An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/rustdesk/rustdesk/master/res/logo-header.svg?sanitize=true" alt="RustDesk - Your remote desktop"&gt;&lt;br&gt; &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#raw-steps-to-build"&gt;Build&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#how-to-build-with-docker"&gt;Docker&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#file-structure"&gt;Structure&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#snapshot"&gt;Snapshot&lt;/a&gt;&lt;br&gt; [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-UA.md"&gt;Українська&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-CS.md"&gt;česky&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ZH.md"&gt;中文&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-HU.md"&gt;Magyar&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ES.md"&gt;Español&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FA.md"&gt;فارسی&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FR.md"&gt;Français&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DE.md"&gt;Deutsch&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PL.md"&gt;Polski&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ID.md"&gt;Indonesian&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FI.md"&gt;Suomi&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ML.md"&gt;മലയാളം&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-JP.md"&gt;日本語&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NL.md"&gt;Nederlands&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-IT.md"&gt;Italiano&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-RU.md"&gt;Русский&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PTBR.md"&gt;Português (Brasil)&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-EO.md"&gt;Esperanto&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-KR.md"&gt;한국어&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-AR.md"&gt;العربي&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-VN.md"&gt;Tiếng Việt&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DA.md"&gt;Dansk&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-GR.md"&gt;Ελληνικά&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-TR.md"&gt;Türkçe&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NO.md"&gt;Norsk&lt;/a&gt;]&lt;br&gt; &lt;b&gt;We need your help to translate this README, &lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/lang"&gt;RustDesk UI&lt;/a&gt; and &lt;a href="https://github.com/rustdesk/doc.rustdesk.com"&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Caution] &lt;strong&gt;Misuse Disclaimer:&lt;/strong&gt; &lt;br&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Chat with us: &lt;a href="https://discord.gg/nDceKgxnkV"&gt;Discord&lt;/a&gt; | &lt;a href="https://twitter.com/rustdesk"&gt;Twitter&lt;/a&gt; | &lt;a href="https://www.reddit.com/r/rustdesk"&gt;Reddit&lt;/a&gt; | &lt;a href="https://www.youtube.com/@rustdesk"&gt;YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ko-fi.com/I2I04VU09"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" alt="ko-fi"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, &lt;a href="https://rustdesk.com/server"&gt;set up your own&lt;/a&gt;, or &lt;a href="https://github.com/rustdesk/rustdesk-server-demo"&gt;write your own rendezvous/relay server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png" alt="image"&gt;&lt;/p&gt; 
&lt;p&gt;RustDesk welcomes contribution from everyone. See &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for help getting started.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/wiki/FAQ"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases"&gt;&lt;strong&gt;BINARY DOWNLOAD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases/tag/nightly"&gt;&lt;strong&gt;NIGHTLY BUILD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://f-droid.org/en/packages/com.carriez.flutter_hbb"&gt;&lt;img src="https://f-droid.org/badge/get-it-on.png" alt="Get it on F-Droid" height="80"&gt;&lt;/a&gt; &lt;a href="https://flathub.org/apps/com.rustdesk.RustDesk"&gt;&lt;img src="https://flathub.org/api/badge?svg&amp;amp;locale=en" alt="Get it on Flathub" height="80"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;p&gt;Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our &lt;a href="https://github.com/rustdesk/rustdesk/raw/master/.github/workflows/flutter-build.yml"&gt;CI&lt;/a&gt; for building Flutter version.&lt;/p&gt; 
&lt;p&gt;Please download Sciter dynamic library yourself.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll"&gt;Windows&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so"&gt;Linux&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib"&gt;macOS&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Raw Steps to build&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Prepare your Rust development env and C++ build env&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://github.com/microsoft/vcpkg"&gt;vcpkg&lt;/a&gt;, and set &lt;code&gt;VCPKG_ROOT&lt;/code&gt; env variable correctly&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static&lt;/li&gt; 
   &lt;li&gt;Linux/macOS: vcpkg install libvpx libyuv opus aom&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;run &lt;code&gt;cargo run&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://rustdesk.com/docs/en/dev/build/"&gt;Build&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;How to Build on Linux&lt;/h2&gt; 
&lt;h3&gt;Ubuntu 18 (Debian 10)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;openSUSE Tumbleweed&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fedora 28 (CentOS 8)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Arch (Manjaro)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install vcpkg&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fix libvpx (For Fedora)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i 's/CFLAGS+=-I/CFLAGS+=-fPIC -I/g' Makefile
sed -i 's/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g' Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How to build with Docker&lt;/h2&gt; 
&lt;p&gt;Begin by cloning the repository and building the Docker container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t "rustdesk-builder" .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, each time you need to build the application, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID="$(id -u)" -e PGID="$(id -g)" rustdesk-builder
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the &lt;code&gt;&amp;lt;OPTIONAL-ARGS&amp;gt;&lt;/code&gt; position. For instance, if you wanted to build an optimized release version, you would run the command above followed by &lt;code&gt;--release&lt;/code&gt;. The resulting executable will be available in the target folder on your system, and can be run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/debug/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you're running a release executable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/release/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as &lt;code&gt;install&lt;/code&gt; or &lt;code&gt;run&lt;/code&gt; are not currently supported via this method as they would install or run the program inside the container instead of the host.&lt;/p&gt; 
&lt;h2&gt;File Structure&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common"&gt;libs/hbb_common&lt;/a&gt;&lt;/strong&gt;: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/scrap"&gt;libs/scrap&lt;/a&gt;&lt;/strong&gt;: screen capture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/enigo"&gt;libs/enigo&lt;/a&gt;&lt;/strong&gt;: platform specific keyboard/mouse control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard"&gt;libs/clipboard&lt;/a&gt;&lt;/strong&gt;: file copy and paste implementation for Windows, Linux, macOS.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/ui"&gt;src/ui&lt;/a&gt;&lt;/strong&gt;: obsolete Sciter UI (deprecated)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/server"&gt;src/server&lt;/a&gt;&lt;/strong&gt;: audio/clipboard/input/video services, and network connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/client.rs"&gt;src/client.rs&lt;/a&gt;&lt;/strong&gt;: start a peer connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs"&gt;src/rendezvous_mediator.rs&lt;/a&gt;&lt;/strong&gt;: Communicate with &lt;a href="https://github.com/rustdesk/rustdesk-server"&gt;rustdesk-server&lt;/a&gt;, wait for remote direct (TCP hole punching) or relayed connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/platform"&gt;src/platform&lt;/a&gt;&lt;/strong&gt;: platform specific code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter"&gt;flutter&lt;/a&gt;&lt;/strong&gt;: Flutter code for desktop and mobile&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js"&gt;flutter/web/js&lt;/a&gt;&lt;/strong&gt;: JavaScript for Flutter web client&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651" alt="Connection Manager"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea" alt="Connected to a Windows PC"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad" alt="File Transfer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5" alt="TCP Tunneling"&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Genesis-Embodied-AI/Genesis</title>
      <link>https://github.com/Genesis-Embodied-AI/Genesis</link>
      <description>&lt;p&gt;A generative world for general-purpose robotics &amp; embodied AI learning.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/imgs/big_text.png" alt="Genesis"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/imgs/teaser.png" alt="Teaser"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/genesis-world/"&gt;&lt;img src="https://img.shields.io/pypi/v/genesis-world" alt="PyPI - Version"&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/genesis-world"&gt;&lt;img src="https://static.pepy.tech/badge/genesis-world" alt="PyPI Downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/issues"&gt;&lt;img src="https://img.shields.io/github/issues/Genesis-Embodied-AI/Genesis" alt="GitHub Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/Genesis-Embodied-AI/Genesis" alt="GitHub Discussions"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/nukCuhB47p"&gt;&lt;img src="https://img.shields.io/discord/1322086972302430269?logo=discord" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://drive.google.com/uc?export=view&amp;amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white" height="20" style="display:inline"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/English-d9d9d9" alt="README in English"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_FR.md"&gt;&lt;img src="https://img.shields.io/badge/Francais-d9d9d9" alt="README en Français"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_KR.md"&gt;&lt;img src="https://img.shields.io/badge/%ED%95%9C%EA%B5%AD%EC%96%B4-d9d9d9" alt="한국어 README"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_CN.md"&gt;&lt;img src="https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-d9d9d9" alt="简体中文版自述文件"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_JA.md"&gt;&lt;img src="https://img.shields.io/badge/%E6%97%A5%E6%9C%AC%E8%AA%9E-d9d9d9" alt="日本語版 README"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Genesis&lt;/h1&gt; 
&lt;h2&gt;🔥 News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025-07-02] The development of Genesis is now officially supported by &lt;a href="https://genesis-ai.company/"&gt;Genesis AI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025-01-09] We released a &lt;a href="https://github.com/zhouxian/genesis-speed-benchmark"&gt;detailed performance benchmarking and comparison report&lt;/a&gt; on Genesis, together with all the test scripts.&lt;/li&gt; 
 &lt;li&gt;[2025-01-08] Released v0.2.1 🎊 🎉&lt;/li&gt; 
 &lt;li&gt;[2025-01-08] Created &lt;a href="https://discord.gg/nukCuhB47p"&gt;Discord&lt;/a&gt; and &lt;a href="https://drive.google.com/uc?export=view&amp;amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ"&gt;Wechat&lt;/a&gt; group.&lt;/li&gt; 
 &lt;li&gt;[2024-12-25] Added a &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#docker"&gt;docker&lt;/a&gt; including support for the ray-tracing renderer&lt;/li&gt; 
 &lt;li&gt;[2024-12-24] Added guidelines for &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/raw/main/.github/CONTRIBUTING.md"&gt;contributing to Genesis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#what-is-genesis"&gt;What is Genesis?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#quick-installation"&gt;Quick Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#contributing-to-genesis"&gt;Contributing to Genesis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#support"&gt;Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#license-and-acknowledgments"&gt;License and Acknowledgments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#associated-papers"&gt;Associated Papers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;What is Genesis?&lt;/h2&gt; 
&lt;p&gt;Genesis is a physics platform designed for general-purpose &lt;em&gt;Robotics/Embodied AI/Physical AI&lt;/em&gt; applications. It is simultaneously multiple things:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A &lt;strong&gt;universal physics engine&lt;/strong&gt; re-built from the ground up, capable of simulating a wide range of materials and physical phenomena.&lt;/li&gt; 
 &lt;li&gt;A &lt;strong&gt;lightweight&lt;/strong&gt;, &lt;strong&gt;ultra-fast&lt;/strong&gt;, &lt;strong&gt;pythonic&lt;/strong&gt;, and &lt;strong&gt;user-friendly&lt;/strong&gt; robotics simulation platform.&lt;/li&gt; 
 &lt;li&gt;A powerful and fast &lt;strong&gt;photo-realistic rendering system&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;A &lt;strong&gt;generative data engine&lt;/strong&gt; that transforms user-prompted natural language description into various modalities of data.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Powered by a universal physics engine re-designed and re-built from the ground up, Genesis integrates various physics solvers and their coupling into a unified framework. This core physics engine is further enhanced by a generative agent framework that operates at an upper level, aiming towards fully automated data generation for robotics and beyond.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Currently, we are open-sourcing the &lt;em&gt;underlying physics engine&lt;/em&gt; and the &lt;em&gt;simulation platform&lt;/em&gt;. Our &lt;em&gt;generative framework&lt;/em&gt; is a modular system that incorporates many different generative modules, each handling a certain range of data modalities, routed by a high level agent. Some of the modules integrated existing papers and some are still under submission. Access to our generative feature will be gradually rolled out in the near future. If you are interested, feel free to explore more in the &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#associated-papers"&gt;paper list&lt;/a&gt; below.&lt;/p&gt; 
&lt;p&gt;Genesis aims to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lower the barrier&lt;/strong&gt; to using physics simulations, making robotics research accessible to everyone. See our &lt;a href="https://genesis-world.readthedocs.io/en/latest/user_guide/overview/mission.html"&gt;mission statement&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unify diverse physics solvers&lt;/strong&gt; into a single framework to recreate the physical world with the highest fidelity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automate data generation&lt;/strong&gt;, reducing human effort and letting the data flywheel spin on its own.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Project Page: &lt;a href="https://genesis-embodied-ai.github.io/"&gt;https://genesis-embodied-ai.github.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Over 43 million FPS when simulating a Franka robotic arm with a single RTX 4090 (430,000 times faster than real-time).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-platform&lt;/strong&gt;: Runs on Linux, macOS, Windows, and supports multiple compute backends (CPU, Nvidia/AMD GPUs, Apple Metal).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integration of diverse physics solvers&lt;/strong&gt;: Rigid body, MPM, SPH, FEM, PBD, Stable Fluid.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wide range of material models&lt;/strong&gt;: Simulation and coupling of rigid bodies, liquids, gases, deformable objects, thin-shell objects, and granular materials.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compatibility with various robots&lt;/strong&gt;: Robotic arms, legged robots, drones, &lt;em&gt;soft robots&lt;/em&gt;, and support for loading &lt;code&gt;MJCF (.xml)&lt;/code&gt;, &lt;code&gt;URDF&lt;/code&gt;, &lt;code&gt;.obj&lt;/code&gt;, &lt;code&gt;.glb&lt;/code&gt;, &lt;code&gt;.ply&lt;/code&gt;, &lt;code&gt;.stl&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Photo-realistic rendering&lt;/strong&gt;: Native ray-tracing-based rendering.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Differentiability&lt;/strong&gt;: Genesis is designed to be fully differentiable. Currently, our MPM solver and Tool Solver support differentiability, with other solvers planned for future versions (starting with rigid &amp;amp; articulated body solver).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Physics-based tactile simulation&lt;/strong&gt;: Differentiable &lt;a href="https://github.com/Genesis-Embodied-AI/DiffTactile"&gt;tactile sensor simulation&lt;/a&gt; coming soon (expected in version 0.3.0).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User-friendliness&lt;/strong&gt;: Designed for simplicity, with intuitive installation and APIs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Installation&lt;/h2&gt; 
&lt;p&gt;Install &lt;strong&gt;PyTorch&lt;/strong&gt; first following the &lt;a href="https://pytorch.org/get-started/locally/"&gt;official instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Then, install Genesis via PyPI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install genesis-world  # Requires Python&amp;gt;=3.10,&amp;lt;3.14;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the latest version to date, make sure that &lt;code&gt;pip&lt;/code&gt; is up-to-date via &lt;code&gt;pip install --upgrade pip&lt;/code&gt;, then run command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/Genesis-Embodied-AI/Genesis.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the package must still be updated manually to sync with main branch.&lt;/p&gt; 
&lt;p&gt;Users seeking to edit the source code of Genesis are encourage to install Genesis in editable mode. First, make sure that &lt;code&gt;genesis-world&lt;/code&gt; has been uninstalled, then clone the repository and install locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Genesis-Embodied-AI/Genesis.git
cd Genesis
pip install -e ".[dev]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;If you want to use Genesis from Docker, you can first build the Docker image as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t genesis -f docker/Dockerfile docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the examples inside the docker image (mounted to &lt;code&gt;/workspace/examples&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;xhost +local:root # Allow the container to access the display

docker run --gpus all --rm -it \
-e DISPLAY=$DISPLAY \
-v /dev/dri:/dev/dri \
-v /tmp/.X11-unix/:/tmp/.X11-unix \
-v $PWD:/workspace \
genesis
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AMD users&lt;/h3&gt; 
&lt;p&gt;AMD users can use Genesis using the &lt;code&gt;docker/Dockerfile.amdgpu&lt;/code&gt; file, which is built by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker build -t genesis-amd -f docker/Dockerfile.amdgpu docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and can then be used by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xhost"&gt;docker run -it --network=host \
 --device=/dev/kfd \
 --device=/dev/dri \
 --group-add=video \
 --ipc=host \
 --cap-add=SYS_PTRACE \
 --security-opt seccomp=unconfined \
 --shm-size 8G \
 -v $PWD:/workspace \
 -e DISPLAY=$DISPLAY \
 genesis-amd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The examples will be accessible from &lt;code&gt;/workspace/examples&lt;/code&gt;. Note: AMD users should use the vulkan backend. This means you will need to call &lt;code&gt;gs.init(vulkan)&lt;/code&gt; to initialise Genesis.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Comprehensive documentation is available in &lt;a href="https://genesis-world.readthedocs.io/en/latest/user_guide/index.html"&gt;English&lt;/a&gt;, &lt;a href="https://genesis-world.readthedocs.io/zh-cn/latest/user_guide/index.html"&gt;Chinese&lt;/a&gt;, and &lt;a href="https://genesis-world.readthedocs.io/ja/latest/user_guide/index.html"&gt;Japanese&lt;/a&gt;. This includes detailed installation steps, tutorials, and API references.&lt;/p&gt; 
&lt;h2&gt;Contributing to Genesis&lt;/h2&gt; 
&lt;p&gt;The Genesis project is an open and collaborative effort. We welcome all forms of contributions from the community, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pull requests&lt;/strong&gt; for new features or bug fixes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug reports&lt;/strong&gt; through GitHub Issues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Suggestions&lt;/strong&gt; to improve Genesis's usability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Refer to our &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/raw/main/.github/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Report bugs or request features via GitHub &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/issues"&gt;Issues&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join discussions or ask questions on GitHub &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/discussions"&gt;Discussions&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License and Acknowledgments&lt;/h2&gt; 
&lt;p&gt;The Genesis source code is licensed under Apache 2.0.&lt;/p&gt; 
&lt;p&gt;Genesis's development has been made possible thanks to these open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taichi-dev/taichi"&gt;Taichi&lt;/a&gt;: High-performance cross-platform compute backend. Kudos to the Taichi team for their technical support!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zhouxian/FluidLab"&gt;FluidLab&lt;/a&gt;: Reference MPM solver implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/erizmr/SPH_Taichi"&gt;SPH_Taichi&lt;/a&gt;: Reference SPH solver implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://matthias-research.github.io/pages/tenMinutePhysics/index.html"&gt;Ten Minute Physics&lt;/a&gt; and &lt;a href="https://github.com/WASD4959/PBF3D"&gt;PBF3D&lt;/a&gt;: Reference PBD solver implementations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google-deepmind/mujoco"&gt;MuJoCo&lt;/a&gt;: Reference for rigid body dynamics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danfis/libccd"&gt;libccd&lt;/a&gt;: Reference for collision detection.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmatl/pyrender"&gt;PyRender&lt;/a&gt;: Rasterization-based renderer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuisaGroup/LuisaCompute"&gt;LuisaCompute&lt;/a&gt; and &lt;a href="https://github.com/LuisaGroup/LuisaRender"&gt;LuisaRender&lt;/a&gt;: Ray-tracing DSL.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shacklettbp/madrona"&gt;Madrona&lt;/a&gt; and &lt;a href="https://github.com/shacklettbp/madrona_mjx"&gt;Madrona-mjx&lt;/a&gt;: Batch renderer backend&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Associated Papers&lt;/h2&gt; 
&lt;p&gt;Genesis is a large scale effort that integrates state-of-the-art technologies of various existing and on-going research work into a single system. Here we include a non-exhaustive list of all the papers that contributed to the Genesis project in one way or another:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Xian, Zhou, et al. "Fluidlab: A differentiable environment for benchmarking complex fluid manipulation." arXiv preprint arXiv:2303.02346 (2023).&lt;/li&gt; 
 &lt;li&gt;Xu, Zhenjia, et al. "Roboninja: Learning an adaptive cutting policy for multi-material objects." arXiv preprint arXiv:2302.11553 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Yufei, et al. "Robogen: Towards unleashing infinite data for automated robot learning via generative simulation." arXiv preprint arXiv:2311.01455 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Tsun-Hsuan, et al. "Softzoo: A soft robot co-design benchmark for locomotion in diverse environments." arXiv preprint arXiv:2303.09555 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Tsun-Hsuan Johnson, et al. "Diffusebot: Breeding soft robots with physics-augmented generative diffusion models." Advances in Neural Information Processing Systems 36 (2023): 44398-44423.&lt;/li&gt; 
 &lt;li&gt;Katara, Pushkal, Zhou Xian, and Katerina Fragkiadaki. "Gen2sim: Scaling up robot learning in simulation with generative models." 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024.&lt;/li&gt; 
 &lt;li&gt;Si, Zilin, et al. "DiffTactile: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation." arXiv preprint arXiv:2403.08716 (2024).&lt;/li&gt; 
 &lt;li&gt;Wang, Yian, et al. "Thin-Shell Object Manipulations With Differentiable Physics Simulations." arXiv preprint arXiv:2404.00451 (2024).&lt;/li&gt; 
 &lt;li&gt;Lin, Chunru, et al. "UBSoft: A Simulation Platform for Robotic Skill Learning in Unbounded Soft Environments." arXiv preprint arXiv:2411.12711 (2024).&lt;/li&gt; 
 &lt;li&gt;Zhou, Wenyang, et al. "EMDM: Efficient motion diffusion model for fast and high-quality motion generation." European Conference on Computer Vision. Springer, Cham, 2025.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. "Scalable differentiable physics for learning and control." International Conference on Machine Learning. PMLR, 2020.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. "Efficient differentiable simulation of articulated bodies." In International Conference on Machine Learning, PMLR, 2021.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming Lin. "Differentiable simulation of soft multi-body systems." Advances in Neural Information Processing Systems 34 (2021).&lt;/li&gt; 
 &lt;li&gt;Wan, Weilin, et al. "Tlcontrol: Trajectory and language control for human motion synthesis." arXiv preprint arXiv:2311.17135 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Yian, et al. "Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical 2D Inpainting." arXiv preprint arXiv:2411.09823 (2024).&lt;/li&gt; 
 &lt;li&gt;Zheng, Shaokun, et al. "LuisaRender: A high-performance rendering framework with layered and unified interfaces on stream architectures." ACM Transactions on Graphics (TOG) 41.6 (2022): 1-19.&lt;/li&gt; 
 &lt;li&gt;Fan, Yingruo, et al. "Faceformer: Speech-driven 3d facial animation with transformers." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.&lt;/li&gt; 
 &lt;li&gt;Wu, Sichun, Kazi Injamamul Haque, and Zerrin Yumak. "ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE." Proceedings of the 17th ACM SIGGRAPH Conference on Motion, Interaction, and Games. 2024.&lt;/li&gt; 
 &lt;li&gt;Dou, Zhiyang, et al. "C· ase: Learning conditional adversarial skill embeddings for physics-based characters." SIGGRAPH Asia 2023 Conference Papers. 2023.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;... and many more on-going work.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use Genesis in your research, please consider citing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{Genesis,
  author = {Genesis Authors},
  title = {Genesis: A Generative and Universal Physics Engine for Robotics and Beyond},
  month = {December},
  year = {2024},
  url = {https://github.com/Genesis-Embodied-AI/Genesis}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>outline/outline</title>
      <link>https://github.com/outline/outline</link>
      <description>&lt;p&gt;The fastest knowledge base for growing teams. Beautiful, realtime collaborative, feature packed, and markdown compatible.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://user-images.githubusercontent.com/31465/34380645-bd67f474-eb0b-11e7-8d03-0151c1730654.png" height="29"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;A fast, collaborative, knowledge base for your team built using React and Node.js.&lt;br&gt;Try out Outline using our hosted version at &lt;a href="https://www.getoutline.com"&gt;www.getoutline.com&lt;/a&gt;.&lt;/i&gt; &lt;br&gt; &lt;img width="1640" alt="screenshot" src="https://user-images.githubusercontent.com/380914/110356468-26374600-7fef-11eb-9f6a-f2cc2c8c6590.png"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://circleci.com/gh/outline/outline" rel="nofollow"&gt;&lt;img src="https://circleci.com/gh/outline/outline.svg?style=shield"&gt;&lt;/a&gt; &lt;a href="http://www.typescriptlang.org" rel="nofollow"&gt;&lt;img src="https://img.shields.io/badge/%3C%2F%3E-TypeScript-%230074c1.svg?sanitize=true" alt="TypeScript"&gt;&lt;/a&gt; &lt;a href="https://github.com/prettier/prettier"&gt;&lt;img src="https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat" alt="Prettier"&gt;&lt;/a&gt; &lt;a href="https://github.com/styled-components/styled-components"&gt;&lt;img src="https://img.shields.io/badge/style-%F0%9F%92%85%20styled--components-orange.svg?sanitize=true" alt="Styled Components"&gt;&lt;/a&gt; &lt;a href="https://translate.getoutline.com/project/outline" alt="Localized"&gt;&lt;img src="https://badges.crowdin.net/outline/localized.svg?sanitize=true"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;This is the source code that runs &lt;a href="https://www.getoutline.com"&gt;&lt;strong&gt;Outline&lt;/strong&gt;&lt;/a&gt; and all the associated services. If you want to use Outline then you don't need to run this code, we offer a hosted version of the app at &lt;a href="https://www.getoutline.com"&gt;getoutline.com&lt;/a&gt;. You can also find documentation on using Outline in &lt;a href="https://docs.getoutline.com/s/guide"&gt;our guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you'd like to run your own copy of Outline or contribute to development then this is the place for you.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;Please see the &lt;a href="https://docs.getoutline.com/s/hosting/"&gt;documentation&lt;/a&gt; for running your own copy of Outline in a production configuration.&lt;/p&gt; 
&lt;p&gt;If you have questions or improvements for the docs please create a thread in &lt;a href="https://github.com/outline/outline/discussions"&gt;GitHub discussions&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Development&lt;/h1&gt; 
&lt;p&gt;There is a short guide for &lt;a href="https://docs.getoutline.com/s/hosting/doc/local-development-5hEhFRXow7"&gt;setting up a development environment&lt;/a&gt; if you wish to contribute changes, fixes, and improvements to Outline.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Outline is built and maintained by a small team – we'd love your help to fix bugs and add features!&lt;/p&gt; 
&lt;p&gt;Before submitting a pull request &lt;em&gt;please&lt;/em&gt; discuss with the core team by creating or commenting in an issue on &lt;a href="https://www.github.com/outline/outline/issues"&gt;GitHub&lt;/a&gt; – we'd also love to hear from you in the &lt;a href="https://www.github.com/outline/outline/discussions"&gt;discussions&lt;/a&gt;. This way we can ensure that an approach is agreed on before code is written. This will result in a much higher likelihood of your code being accepted.&lt;/p&gt; 
&lt;p&gt;If you’re looking for ways to get started, here's a list of ways to help us improve Outline:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/outline/outline/main/docs/TRANSLATION.md"&gt;Translation&lt;/a&gt; into other languages&lt;/li&gt; 
 &lt;li&gt;Issues with &lt;a href="https://github.com/outline/outline/labels/good%20first%20issue"&gt;&lt;code&gt;good first issue&lt;/code&gt;&lt;/a&gt; label&lt;/li&gt; 
 &lt;li&gt;Performance improvements, both on server and frontend&lt;/li&gt; 
 &lt;li&gt;Developer happiness and documentation&lt;/li&gt; 
 &lt;li&gt;Bugs and other issues listed on GitHub&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;If you're interested in contributing or learning more about the Outline codebase please refer to the &lt;a href="https://raw.githubusercontent.com/outline/outline/main/docs/ARCHITECTURE.md"&gt;architecture document&lt;/a&gt; first for a high level overview of how the application is put together.&lt;/p&gt; 
&lt;h2&gt;Debugging&lt;/h2&gt; 
&lt;p&gt;In development Outline outputs simple logging to the console, prefixed by categories. In production it outputs JSON logs, these can be easily parsed by your preferred log ingestion pipeline.&lt;/p&gt; 
&lt;p&gt;HTTP logging is disabled by default, but can be enabled by setting the &lt;code&gt;DEBUG=http&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h2&gt;Tests&lt;/h2&gt; 
&lt;p&gt;We aim to have sufficient test coverage for critical parts of the application and aren't aiming for 100% unit test coverage. All API endpoints and anything authentication related should be thoroughly tested.&lt;/p&gt; 
&lt;p&gt;To add new tests, write your tests with &lt;a href="https://facebook.github.io/jest/"&gt;Jest&lt;/a&gt; and add a file with &lt;code&gt;.test.js&lt;/code&gt; extension next to the tested code.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# To run all tests
make test

# To run backend tests in watch mode
make watch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once the test database is created with &lt;code&gt;make test&lt;/code&gt; you may individually run frontend and backend tests directly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# To run backend tests
yarn test:server

# To run a specific backend test
yarn test:server myTestFile

# To run frontend tests
yarn test:app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Migrations&lt;/h2&gt; 
&lt;p&gt;Sequelize is used to create and run migrations, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;yarn sequelize migration:generate --name my-migration
yarn sequelize db:migrate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or to run migrations on test database:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;yarn sequelize db:migrate --env test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Activity&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/ff2e4e6918afff1acf9deb72d1ba6b071d586178.svg?sanitize=true" alt="Alt" title="Repobeats analytics image"&gt;&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Outline is &lt;a href="https://raw.githubusercontent.com/outline/outline/main/LICENSE"&gt;BSL 1.1 licensed&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>