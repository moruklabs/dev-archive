<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Sun, 03 Aug 2025 01:35:40 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>karpathy/build-nanogpt</title>
      <link>https://github.com/karpathy/build-nanogpt</link>
      <description>&lt;p&gt;Video+code lecture on building nanoGPT from scratch&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;build nanoGPT&lt;/h1&gt; 
&lt;p&gt;This repo holds the from-scratch reproduction of &lt;a href="https://github.com/karpathy/nanoGPT/tree/master"&gt;nanoGPT&lt;/a&gt;. The git commits were specifically kept step by step and clean so that one can easily walk through the git commit history to see it built slowly. Additionally, there is an accompanying &lt;a href="https://youtu.be/l8pRSuU81PU"&gt;video lecture on YouTube&lt;/a&gt; where you can see me introduce each commit and explain the pieces along the way.&lt;/p&gt; 
&lt;p&gt;We basically start from an empty file and work our way to a reproduction of the &lt;a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"&gt;GPT-2&lt;/a&gt; (124M) model. If you have more patience or money, the code can also reproduce the &lt;a href="https://arxiv.org/pdf/2005.14165"&gt;GPT-3&lt;/a&gt; models. While the GPT-2 (124M) model probably trained for quite some time back in the day (2019, ~5 years ago), today, reproducing it is a matter of ~1hr and ~$10. You'll need a cloud GPU box if you don't have enough, for that I recommend &lt;a href="https://lambdalabs.com"&gt;Lambda&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Note that GPT-2 and GPT-3 and both simple language models, trained on internet documents, and all they do is "dream" internet documents. So this repo/video this does not cover Chat finetuning, and you can't talk to it like you can talk to ChatGPT. The finetuning process (while quite simple conceptually - SFT is just about swapping out the dataset and continuing the training) comes after this part and will be covered at a later time. For now this is the kind of stuff that the 124M model says if you prompt it with "Hello, I'm a language model," after 10B tokens of training:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Hello, I'm a language model, and my goal is to make English as easy and fun as possible for everyone, and to find out the different grammar rules
Hello, I'm a language model, so the next time I go, I'll just say, I like this stuff.
Hello, I'm a language model, and the question is, what should I do if I want to be a teacher?
Hello, I'm a language model, and I'm an English person. In languages, "speak" is really speaking. Because for most people, there's
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And after 40B tokens of training:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Hello, I'm a language model, a model of computer science, and it's a way (in mathematics) to program computer programs to do things like write
Hello, I'm a language model, not a human. This means that I believe in my language model, as I have no experience with it yet.
Hello, I'm a language model, but I'm talking about data. You've got to create an array of data: you've got to create that.
Hello, I'm a language model, and all of this is about modeling and learning Python. I'm very good in syntax, however I struggle with Python due
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Lol. Anyway, once the video comes out, this will also be a place for FAQ, and a place for fixes and errata, of which I am sure there will be a number :)&lt;/p&gt; 
&lt;p&gt;For discussions and questions, please use &lt;a href="https://github.com/karpathy/build-nanogpt/discussions"&gt;Discussions tab&lt;/a&gt;, and for faster communication, have a look at my &lt;a href="https://discord.gg/3zy8kqD9Cp"&gt;Zero To Hero Discord&lt;/a&gt;, channel &lt;strong&gt;#nanoGPT&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/3zy8kqD9Cp"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/3zy8kqD9Cp?compact=true&amp;amp;style=flat" alt=""&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Video&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/l8pRSuU81PU"&gt;Let's reproduce GPT-2 (124M) YouTube lecture&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Errata&lt;/h2&gt; 
&lt;p&gt;Minor cleanup, we forgot to delete &lt;code&gt;register_buffer&lt;/code&gt; of the bias once we switched to flash attention, fixed with a recent PR.&lt;/p&gt; 
&lt;p&gt;Earlier version of PyTorch may have difficulty converting from uint16 to long. Inside &lt;code&gt;load_tokens&lt;/code&gt;, we added &lt;code&gt;npt = npt.astype(np.int32)&lt;/code&gt; to use numpy to convert uint16 to int32 before converting to torch tensor and then converting to long.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;torch.autocast&lt;/code&gt; function takes an arg &lt;code&gt;device_type&lt;/code&gt;, to which I tried to stubbornly just pass &lt;code&gt;device&lt;/code&gt; hoping it works ok, but PyTorch actually really wants just the type and creates errors in some version of PyTorch. So we want e.g. the device &lt;code&gt;cuda:3&lt;/code&gt; to get stripped to &lt;code&gt;cuda&lt;/code&gt;. Currently, device &lt;code&gt;mps&lt;/code&gt; (Apple Silicon) would become &lt;code&gt;device_type&lt;/code&gt; CPU, I'm not 100% sure this is the intended PyTorch way.&lt;/p&gt; 
&lt;p&gt;Confusingly, &lt;code&gt;model.require_backward_grad_sync&lt;/code&gt; is actually used by both the forward and backward pass. Moved up the line so that it also gets applied to the forward pass.&lt;/p&gt; 
&lt;h2&gt;Prod&lt;/h2&gt; 
&lt;p&gt;For more production-grade runs that are very similar to nanoGPT, I recommend looking at the following repos:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Lightning-AI/litgpt"&gt;litGPT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;TinyLlama&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TideDra/zotero-arxiv-daily</title>
      <link>https://github.com/TideDra/zotero-arxiv-daily</link>
      <description>&lt;p&gt;Recommend new arxiv papers of your interest daily according to your Zotero libarary.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="" rel="noopener"&gt; &lt;img width="200px" height="200px" src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/logo.svg?sanitize=true" alt="logo"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt;Zotero-arXiv-Daily&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href=""&gt;&lt;img src="https://img.shields.io/badge/status-active-success.svg?sanitize=true" alt="Status"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/TideDra/zotero-arxiv-daily?style=flat" alt="Stars"&gt; &lt;a href="https://github.com/TideDra/zotero-arxiv-daily/issues"&gt;&lt;img src="https://img.shields.io/github/issues/TideDra/zotero-arxiv-daily" alt="GitHub Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/TideDra/zotero-arxiv-daily/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/TideDra/zotero-arxiv-daily" alt="GitHub Pull Requests"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/TideDra/zotero-arxiv-daily" alt="License"&gt;&lt;/a&gt; &lt;a href="https://api.gitsponsors.com/api/badge/link?p=PKMtRut1dWWuC1oFdJweyDSvJg454/GkdIx4IinvBblaX2AY4rQ7FYKAK1ZjApoiNhYEeduIEhfeZVIwoIVlvcwdJXVFD2nV2EE5j6lYXaT/RHrcsQbFl3aKe1F3hliP26OMayXOoZVDidl05wj+yg=="&gt;&lt;img src="https://api.gitsponsors.com/api/badge/img?id=893025857" height="20"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p align="center"&gt; Recommend new arxiv papers of your interest daily according to your Zotero library. &lt;br&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Please keep an eye on this repo, and merge your forked repo in time when there is any update of this upstream, in order to enjoy new features and fix found bugs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üßê About &lt;a name="about"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Track new scientific researches of your interest by just forking (and staring) this repo!üòä&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;Zotero-arXiv-Daily&lt;/em&gt; finds arxiv papers that may attract you based on the context of your Zotero library, and then sends the result to your mailboxüìÆ. It can be deployed as Github Action Workflow with &lt;strong&gt;zero cost&lt;/strong&gt;, &lt;strong&gt;no installation&lt;/strong&gt;, and &lt;strong&gt;few configuration&lt;/strong&gt; of Github Action environment variables for daily &lt;strong&gt;automatic&lt;/strong&gt; delivery.&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Totally free! All the calculation can be done in the Github Action runner locally within its quota (for public repo).&lt;/li&gt; 
 &lt;li&gt;AI-generated TL;DR for you to quickly pick up target papers.&lt;/li&gt; 
 &lt;li&gt;Affiliations of the paper are resolved and presented.&lt;/li&gt; 
 &lt;li&gt;Links of PDF and code implementation (if any) presented in the e-mail.&lt;/li&gt; 
 &lt;li&gt;List of papers sorted by relevance with your recent research interest.&lt;/li&gt; 
 &lt;li&gt;Fast deployment via fork this repo and set environment variables in the Github Action Page.&lt;/li&gt; 
 &lt;li&gt;Support LLM API for generating TL;DR of papers.&lt;/li&gt; 
 &lt;li&gt;Ignore unwanted Zotero papers using gitignore-style pattern.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì∑ Screenshot&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/screenshot.png" alt="screenshot"&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Usage&lt;/h2&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Fork (and starüòò) this repo. &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/fork.png" alt="fork"&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set Github Action environment variables. &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/secrets.png" alt="secrets"&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Below are all the secrets you need to set. They are invisible to anyone including you once they are set, for security.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Key&lt;/th&gt; 
   &lt;th align="center"&gt;Required&lt;/th&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ZOTERO_ID&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;User ID of your Zotero account. &lt;strong&gt;User ID is not your username, but a sequence of numbers&lt;/strong&gt;Get your ID from &lt;a href="https://www.zotero.org/settings/security"&gt;here&lt;/a&gt;. You can find it at the position shown in this &lt;a href="https://github.com/TideDra/zotero-arxiv-daily/raw/main/assets/userid.png"&gt;screenshot&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;12345678&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ZOTERO_KEY&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;An Zotero API key with read access. Get a key from &lt;a href="https://www.zotero.org/settings/security"&gt;here&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;AB5tZ877P2j7Sm2Mragq041H&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ARXIV_QUERY&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The categories of target arxiv papers. Use &lt;code&gt;+&lt;/code&gt; to concatenate multiple categories. The example retrieves papers about AI, CV, NLP, ML. Find the abbr of your research area from &lt;a href="https://arxiv.org/category_taxonomy"&gt;here&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;cs.AI+cs.CV+cs.LG+cs.CL&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SMTP_SERVER&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The SMTP server that sends the email. I recommend to utilize a seldom-used email for this. Ask your email provider (Gmail, QQ, Outlook, ...) for its SMTP server&lt;/td&gt; 
   &lt;td align="left"&gt;smtp.qq.com&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SMTP_PORT&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;int&lt;/td&gt; 
   &lt;td align="left"&gt;The port of SMTP server.&lt;/td&gt; 
   &lt;td align="left"&gt;465&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SENDER&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The email account of the SMTP server that sends you email.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="mailto:abc@qq.com"&gt;abc@qq.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SENDER_PASSWORD&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The password of the sender account. Note that it's not necessarily the password for logging in the e-mail client, but the authentication code for SMTP service. Ask your email provider for this.&lt;/td&gt; 
   &lt;td align="left"&gt;abcdefghijklmn&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;RECEIVER&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The e-mail address that receives the paper list.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="mailto:abc@outlook.com"&gt;abc@outlook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MAX_PAPER_NUM&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;int&lt;/td&gt; 
   &lt;td align="left"&gt;The maximum number of the papers presented in the email. This value directly affects the execution time of this workflow, because it takes about 70s to generate TL;DR for one paper. &lt;code&gt;-1&lt;/code&gt; means to present all the papers retrieved.&lt;/td&gt; 
   &lt;td align="left"&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SEND_EMPTY&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;bool&lt;/td&gt; 
   &lt;td align="left"&gt;Whether to send an empty email even if no new papers today.&lt;/td&gt; 
   &lt;td align="left"&gt;False&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;USE_LLM_API&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;bool&lt;/td&gt; 
   &lt;td align="left"&gt;Whether to use the LLM API in the cloud or to use local LLM. If set to &lt;code&gt;1&lt;/code&gt;, the API is used. Else if set to &lt;code&gt;0&lt;/code&gt;, the workflow will download and deploy an open-source LLM. Default to &lt;code&gt;0&lt;/code&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;OPENAI_API_KEY&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;API Key when using the API to access LLMs. You can get FREE API for using advanced open source LLMs in &lt;a href="https://cloud.siliconflow.cn/i/b3XhBRAm"&gt;SiliconFlow&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;sk-xxx&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;OPENAI_API_BASE&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;API URL when using the API to access LLMs. If not filled in, the default is the OpenAI URL.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.siliconflow.cn/v1"&gt;https://api.siliconflow.cn/v1&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MODEL_NAME&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;Model name when using the API to access LLMs. If not filled in, the default is gpt-4o. Qwen/Qwen2.5-7B-Instruct is recommended when using &lt;a href="https://cloud.siliconflow.cn/i/b3XhBRAm"&gt;SiliconFlow&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;Qwen/Qwen2.5-7B-Instruct&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;There are also some public variables (Repository Variables) you can set, which are easy to edit. &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/repo_var.png" alt="vars"&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Key&lt;/th&gt; 
   &lt;th align="left"&gt;Required&lt;/th&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ZOTERO_IGNORE&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;Gitignore-style patterns marking the Zotero collections that should be ignored. One rule one line. Learn more about &lt;a href="https://git-scm.com/docs/gitignore"&gt;gitignore&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="left"&gt;AI Agent/&lt;br&gt;**/survey&lt;br&gt;!LLM/survey&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;REPOSITORY&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The repository that provides the workflow. If set, the value can only be &lt;code&gt;TideDra/zotero-arxiv-daily&lt;/code&gt;, in which case, the workflow always pulls the latest code from this upstream repo, so that you don't need to sync your forked repo upon each update, unless the workflow file is changed.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TideDra/zotero-arxiv-daily&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;REF&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The specified ref of the workflow to run. Only valid when REPOSITORY is set to &lt;code&gt;TideDra/zotero-arxiv-daily&lt;/code&gt;. Currently supported values include &lt;code&gt;main&lt;/code&gt; for stable version, &lt;code&gt;dev&lt;/code&gt; for development version which has new features and potential bugs.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;main&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;LANGUAGE&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;str&lt;/td&gt; 
   &lt;td align="left"&gt;The language of TLDR; Its value is directly embeded in the prompt passed to LLM&lt;/td&gt; 
   &lt;td align="left"&gt;Chinese&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;That's all! Now you can test the workflow by manually triggering it: &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/test.png" alt="test"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The Test-Workflow Action is the debug version of the main workflow (Send-emails-daily), which always retrieve 5 arxiv papers regardless of the date. While the main workflow will be automatically triggered everyday and retrieve new papers released yesterday. There is no new arxiv paper at weekends and holiday, in which case you may see "No new papers found" in the log of main workflow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Then check the log and the receiver email after it finishes.&lt;/p&gt; 
&lt;p&gt;By default, the main workflow runs on 22:00 UTC everyday. You can change this time by editting the workflow config &lt;code&gt;.github/workflows/main.yml&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Local Running&lt;/h3&gt; 
&lt;p&gt;Supported by &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt;, this workflow can easily run on your local device if uv is installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# set all the environment variables
# export ZOTERO_ID=xxxx
# ...
cd zotero-arxiv-daily
uv run main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The workflow will download and run an LLM (Qwen2.5-3B, the file size of which is about 3G). Make sure your network and hardware can handle it.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Other package managers like pip or conda are not tested. You can still use them to install this workflow because there is a &lt;code&gt;pyproject.toml&lt;/code&gt;, while potential problems exist.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üöÄ Sync with the latest version&lt;/h2&gt; 
&lt;p&gt;This project is in active development. You can subscribe this repo via &lt;code&gt;Watch&lt;/code&gt; so that you can be notified once we publish new release.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/subscribe_release.png" alt="Watch"&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ How it works&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Zotero-arXiv-Daily&lt;/em&gt; firstly retrieves all the papers in your Zotero library and all the papers released in the previous day, via corresponding API. Then it calculates the embedding of each paper's abstract via an embedding model. The score of a paper is its weighted average similarity over all your Zotero papers (newer paper added to the library has higher weight).&lt;/p&gt; 
&lt;p&gt;The TLDR of each paper is generated by a lightweight LLM (Qwen2.5-3b-instruct-q4_k_m), given its title, abstract, introduction, and conclusion (if any). The introduction and conclusion are extracted from the source latex file of the paper.&lt;/p&gt; 
&lt;h2&gt;üìå Limitations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The recommendation algorithm is very simple, it may not accurately reflect your interest. Welcome better ideas for improving the algorithm!&lt;/li&gt; 
 &lt;li&gt;This workflow deploys an LLM on the cpu of Github Action runner, and it takes about 70s to generate a TLDR for one paper. High &lt;code&gt;MAX_PAPER_NUM&lt;/code&gt; can lead the execution time exceed the limitation of Github Action runner (6h per execution for public repo, and 2000 mins per month for private repo). Commonly, the quota given to public repo is definitely enough for individual use. If you have special requirements, you can deploy the workflow in your own server, or use a self-hosted Github Action runner, or pay for the exceeded execution time.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üëØ‚Äç‚ôÇÔ∏è Contribution&lt;/h2&gt; 
&lt;p&gt;Any issue and PR are welcomed! But remember that &lt;strong&gt;each PR should merge to the &lt;code&gt;dev&lt;/code&gt; branch&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;üìÉ License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;code&gt;LICENSE&lt;/code&gt; for detail.&lt;/p&gt; 
&lt;h2&gt;‚ù§Ô∏è Acknowledgement&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/urschrei/pyzotero"&gt;pyzotero&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lukasschwab/arxiv.py"&gt;arxiv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/UKPLab/sentence-transformers"&gt;sentence_transformers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abetlen/llama-cpp-python"&gt;llama-cpp-python&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚òï Buy Me A Coffee&lt;/h2&gt; 
&lt;p&gt;If you find this project helpful, welcome to sponsor me via WeChat or via &lt;a href="https://ko-fi.com/tidedra"&gt;ko-fi&lt;/a&gt;. &lt;img src="https://raw.githubusercontent.com/TideDra/zotero-arxiv-daily/main/assets/wechat_sponsor.JPG" alt="wechat_qr"&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#TideDra/zotero-arxiv-daily&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=TideDra/zotero-arxiv-daily&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kijai/ComfyUI-WanVideoWrapper</title>
      <link>https://github.com/kijai/ComfyUI-WanVideoWrapper</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI wrapper nodes for &lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;WanVideo&lt;/a&gt; and related models.&lt;/h1&gt; 
&lt;h1&gt;WORK IN PROGRESS (perpetually)&lt;/h1&gt; 
&lt;h1&gt;Why should I use custom nodes when WanVideo works natively?&lt;/h1&gt; 
&lt;p&gt;Short answer: Unless it's a model/feature not available yet on native, you shouldn't.&lt;/p&gt; 
&lt;p&gt;Long answer: Due to the complexity of ComfyUI core code, and my lack of coding experience, in many cases it's far easier and faster to implement new models and features to a standalone wrapper, so this is a way to test things relatively quickly. I consider this my personal sandbox (which is obviously open for everyone) to play with without having to worry about compability issues etc, but as such this code is always work in progress and prone to have issues. Also not all new models end up being worth the trouble to implement in core Comfy, though I've also made some patcher nodes to allow using them in native workflows, such as the &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;ATI&lt;/a&gt; node available in this wrapper. This is also the end goal, idea isn't to compete or even offer alternatives to everything available in native workflows. All that said (this is clearly not a sales pitch) I do appreciate everyone using these nodes to explore new releases and possibilities with WanVideo.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repo into &lt;code&gt;custom_nodes&lt;/code&gt; folder.&lt;/li&gt; 
 &lt;li&gt;Install dependencies: &lt;code&gt;pip install -r requirements.txt&lt;/code&gt; or if you use the portable install, run this in ComfyUI_windows_portable -folder:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-WanVideoWrapper\requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Models&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy/tree/main"&gt;https://huggingface.co/Kijai/WanVideo_comfy/tree/main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;fp8 scaled models (personal recommendation):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled"&gt;https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Text encoders to &lt;code&gt;ComfyUI/models/text_encoders&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Clip vision to &lt;code&gt;ComfyUI/models/clip_vision&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Transformer (main video model) to &lt;code&gt;ComfyUI/models/diffusion_models&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Vae to &lt;code&gt;ComfyUI/models/vae&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can also use the native ComfyUI text encoding and clip vision loader with the wrapper instead of the original models:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/6a2fd9a5-8163-4c93-b362-92ef34dbd3a4" alt="image"&gt;&lt;/p&gt; 
&lt;p&gt;GGUF models can now be loaded in the main model loader as well.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Supported extra models:&lt;/p&gt; 
&lt;p&gt;SkyReels: &lt;a href="https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9"&gt;https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WanVideoFun: &lt;a href="https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17"&gt;https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ReCamMaster: &lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;https://github.com/KwaiVGI/ReCamMaster&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;VACE: &lt;a href="https://github.com/ali-vilab/VACE"&gt;https://github.com/ali-vilab/VACE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Phantom: &lt;a href="https://huggingface.co/bytedance-research/Phantom"&gt;https://huggingface.co/bytedance-research/Phantom&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ATI: &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;https://huggingface.co/bytedance-research/ATI&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Uni3C: &lt;a href="https://github.com/alibaba-damo-academy/Uni3C"&gt;https://github.com/alibaba-damo-academy/Uni3C&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MiniMaxRemover: &lt;a href="https://huggingface.co/zibojia/minimax-remover"&gt;https://huggingface.co/zibojia/minimax-remover&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MAGREF: &lt;a href="https://huggingface.co/MAGREF-Video/MAGREF"&gt;https://huggingface.co/MAGREF-Video/MAGREF&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;FantasyTalking: &lt;a href="https://github.com/Fantasy-AMAP/fantasy-talking"&gt;https://github.com/Fantasy-AMAP/fantasy-talking&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MultiTalk: &lt;a href="https://github.com/MeiGen-AI/MultiTalk"&gt;https://github.com/MeiGen-AI/MultiTalk&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;EchoShot: &lt;a href="https://github.com/D2I-ai/EchoShot"&gt;https://github.com/D2I-ai/EchoShot&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Examples:&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;ReCamMaster&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e"&gt;https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;TeaCache (with the old temporary WIP naive version, I2V):&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that with the new version the threshold values should be 10x higher&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Range of 0.25-0.30 seems good when using the coefficients, start step can be 0, with more aggressive threshold values it may make sense to start later to avoid any potential step skips early on, that generally ruin the motion.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46"&gt;https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Context window test:&lt;/p&gt; 
&lt;p&gt;1025 frames using window size of 81 frames, with 16 overlap. With the 1.3B T2V model this used under 5GB VRAM and took 10 minutes to gen on a 5090:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e"&gt;https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;This very first test was 512x512x81&lt;/p&gt; 
&lt;p&gt;~16GB used with 20/40 blocks offloaded&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f"&gt;https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Vid2vid example:&lt;/p&gt; 
&lt;p&gt;with 14B T2V model:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8"&gt;https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;with 1.3B T2V model&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e"&gt;https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenPipe/ART</title>
      <link>https://github.com/OpenPipe/ART</link>
      <description>&lt;p&gt;Agent Reinforcement Trainer: train multi-step agents for real-world tasks using GRPO. Give your agents on-the-job training. Reinforcement learning for Qwen2.5, Qwen3, Llama, Kimi, and more!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://art.openpipe.ai"&gt;
   &lt;picture&gt; 
    &lt;img alt="ART logo" src="https://github.com/openpipe/art/raw/main/assets/ART_logo.png" width="160px"&gt; 
   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;h1&gt;Agent Reinforcement Trainer&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt; Train multi-step agents for real-world tasks using GRPO. &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/openpipe/art/raw/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-blue.svg?sanitize=true" alt="PRs-Welcome"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/openpipe-art/"&gt;&lt;img src="https://img.shields.io/pypi/dm/openpipe-art?color=364fc7&amp;amp;logoColor=364fc7" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Train Agent"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/zbBHRUpwf4"&gt;&lt;img src="https://img.shields.io/badge/Join%20Discord-5865F2?style=plastic&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Join Discord"&gt;&lt;/a&gt; &lt;a href="https://art.openpipe.ai"&gt;&lt;img src="https://img.shields.io/badge/Documentation-orange?style=plastic&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Documentation"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìè RULER: Zero-Shot Agent Rewards&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;RULER&lt;/strong&gt; (Relative Universal LLM-Elicited Rewards) eliminates the need for hand-crafted reward functions by using an LLM-as-judge to automatically score agent trajectories. Simply define your task in the system prompt, and RULER handles the rest‚Äî&lt;strong&gt;no labeled data, expert feedback, or reward engineering required&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;‚ú® &lt;strong&gt;Key Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2-3x faster development&lt;/strong&gt; - Skip reward function engineering entirely&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General-purpose&lt;/strong&gt; - Works across any task without modification&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strong performance&lt;/strong&gt; - Matches or exceeds hand-crafted rewards in 3/4 benchmarks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy integration&lt;/strong&gt; - Drop-in replacement for manual reward functions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Before: Hours of reward engineering
def complex_reward_function(trajectory):
    # 50+ lines of careful scoring logic...
    pass

# After: One line with RULER
judged_group = await ruler_score_group(group, "openai/o3")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://art.openpipe.ai/fundamentals/ruler"&gt;üìñ Learn more about RULER ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ART Overview&lt;/h2&gt; 
&lt;p&gt;ART is an open-source RL framework that improves agent reliability by allowing LLMs to &lt;strong&gt;learn from experience&lt;/strong&gt;. ART provides an ergonomic harness for integrating GRPO into any python application. For a quick hands-on introduction, run one of the notebooks below. When you're ready to learn more, check out the &lt;a href="https://art.openpipe.ai"&gt;docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìí Notebooks&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent Task&lt;/th&gt; 
   &lt;th&gt;Example Notebook&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Comparative Performance&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ART‚Ä¢E [RULER]&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/art-e/art-e.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 7B learns to search emails using RULER&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/email_agent/accuracy-training-progress.svg?sanitize=true" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/art-e/art_e/evaluate/display_benchmarks.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;2048&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play 2048&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/2048/accuracy-training-progress.svg?sanitize=true" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/2048/benchmark_2048.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Clue&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/temporal_clue/temporal-clue.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 7B learns to solve Temporal Clue&lt;/td&gt; 
   &lt;td&gt;[Link coming soon]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Tic Tac Toe&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/tic_tac_toe/tic-tac-toe.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play Tic Tac Toe&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/tic-tac-toe-local/accuracy-training-progress.svg?sanitize=true" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/tic_tac_toe/benchmark_tic_tac_toe.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Codenames&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/codenames/Codenames_RL.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play Codenames&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/codenames/win_rate_over_time.png" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/codenames/Codenames_RL.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AutoRL [RULER]&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/auto_rl.ipynb"&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Train Qwen 2.5 7B to master any task&lt;/td&gt; 
   &lt;td&gt;[Link coming soon]&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üì∞ ART News&lt;/h2&gt; 
&lt;p&gt;Explore our latest research and updates on building SOTA agents.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href="https://x.com/mattshumer_/status/1950572449025650733"&gt;AutoRL: Zero-Data Training for Any Task&lt;/a&gt;&lt;/strong&gt; - Train custom AI models without labeled data using automatic input generation and RULER evaluation.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href="https://openpipe.ai/blog/ruler-easy-mode-for-rl-rewards"&gt;RULER: Easy Mode for RL Rewards&lt;/a&gt;&lt;/strong&gt; is now available for automatic reward generation in reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href="https://openpipe.ai/blog/art-e-mail-agent"&gt;ART¬∑E: How We Built an Email Research Agent That Beats o3&lt;/a&gt;&lt;/strong&gt; demonstrates a Qwen 2.5 14B email agent outperforming OpenAI's o3.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href="https://openpipe.ai/blog/art-trainer"&gt;ART Trainer: A New RL Trainer for Agents&lt;/a&gt;&lt;/strong&gt; enables easy training of LLM-based agents using GRPO.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://openpipe.ai/blog"&gt;üìñ See all blog posts ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why ART?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ART provides convenient wrappers for introducing RL training into &lt;strong&gt;existing applications&lt;/strong&gt;. We abstract the training server into a modular service that your code doesn't need to interface with.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Train from anywhere.&lt;/strong&gt; Run the ART client on your laptop and let the ART server kick off an ephemeral GPU-enabled environment, or run on a local GPU.&lt;/li&gt; 
 &lt;li&gt;Integrations with hosted platforms like W&amp;amp;B, Langfuse, and OpenPipe provide flexible observability and &lt;strong&gt;simplify debugging&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;ART is customizable with &lt;strong&gt;intelligent defaults&lt;/strong&gt;. You can configure training parameters and inference engine configurations to meet specific needs, or take advantage of the defaults, which have been optimized for training efficiency and stability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;ART agents can be trained from any client machine that runs python. To add to an existing project, run this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install openpipe-art
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ñ ART‚Ä¢E Agent&lt;/h2&gt; 
&lt;p&gt;Curious about how to use ART for a real-world task? Check out the &lt;a href="https://openpipe.ai/blog/art-e-mail-agent"&gt;ART‚Ä¢E Agent&lt;/a&gt; blog post, where we detail how we trained Qwen 2.5 14B to beat o3 at email retrieval!&lt;/p&gt; 
&lt;img src="https://github.com/openpipe/art/raw/main/assets/ART_E_graphs.png" width="700"&gt; 
&lt;h2&gt;üîÅ Training Loop Overview&lt;/h2&gt; 
&lt;p&gt;ART's functionality is divided into a &lt;strong&gt;client&lt;/strong&gt; and a &lt;strong&gt;server&lt;/strong&gt;. The OpenAI-compatible client is responsible for interfacing between ART and your codebase. Using the client, you can pass messages and get completions from your LLM as it improves. The server runs independently on any machine with a GPU. It abstracts away the complexity of the inference and training portions of the RL loop while allowing for some custom configuration. An outline of the training loop is shown below:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inference&lt;/strong&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;Your code uses the ART client to perform an agentic workflow (usually executing several rollouts in parallel to gather data faster).&lt;/li&gt; 
   &lt;li&gt;Completion requests are routed to the ART server, which runs the model's latest LoRA in vLLM.&lt;/li&gt; 
   &lt;li&gt;As the agent executes, each &lt;code&gt;system&lt;/code&gt;, &lt;code&gt;user&lt;/code&gt;, and &lt;code&gt;assistant&lt;/code&gt; message is stored in a Trajectory.&lt;/li&gt; 
   &lt;li&gt;When a rollout finishes, your code assigns a &lt;code&gt;reward&lt;/code&gt; to its Trajectory, indicating the performance of the LLM.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;When each rollout has finished, Trajectories are grouped and sent to the server. Inference is blocked while training executes.&lt;/li&gt; 
   &lt;li&gt;The server trains your model using GRPO, initializing from the latest checkpoint (or an empty LoRA on the first iteration).&lt;/li&gt; 
   &lt;li&gt;The server saves the newly trained LoRA to a local directory and loads it into vLLM.&lt;/li&gt; 
   &lt;li&gt;Inference is unblocked and the loop resumes at step 1.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This training loop runs until a specified number of inference and training iterations have completed.&lt;/p&gt; 
&lt;h2&gt;üß© Supported Models&lt;/h2&gt; 
&lt;p&gt;ART should work with most vLLM/HuggingFace-transformers compatible causal language models, or at least the ones supported by &lt;a href="https://docs.unsloth.ai/get-started/all-our-models"&gt;Unsloth&lt;/a&gt;. Gemma 3 does not appear to be supported for the time being. If any other model isn't working for you, please let us know on &lt;a href="https://discord.gg/zbBHRUpwf4"&gt;Discord&lt;/a&gt; or open an issue on &lt;a href="https://github.com/openpipe/art/issues"&gt;GitHub&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;ART is in active development, and contributions are most welcome! Please see the &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file for more information.&lt;/p&gt; 
&lt;h2&gt;üìñ Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{hilton2025art,
  author = {Brad Hilton and Kyle Corbitt and David Corbitt and Saumya Gandhi and Angky William and Bohdan Kovalenskyi and Andie Jones},
  title = {ART: Agent Reinforcement Trainer},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openpipe/art}}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; 
&lt;p&gt;This repository's source code is available under the &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üôè Credits&lt;/h2&gt; 
&lt;p&gt;ART stands on the shoulders of giants. While we owe many of the ideas and early experiments that led to ART's development to the open source RL community at large, we're especially grateful to the authors of the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unslothai/unsloth"&gt;Unsloth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/trl"&gt;trl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/torchtune"&gt;torchtune&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/skypilot-org/skypilot"&gt;SkyPilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, thank you to our partners who've helped us test ART in the wild! We're excited to see what you all build with it.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GongRzhe/Office-PowerPoint-MCP-Server</title>
      <link>https://github.com/GongRzhe/Office-PowerPoint-MCP-Server</link>
      <description>&lt;p&gt;A MCP (Model Context Protocol) server for PowerPoint manipulation using python-pptx. This server provides tools for creating, editing, and manipulating PowerPoint presentations through the MCP protocol.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Office-PowerPoint-MCP-Server&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://smithery.ai/server/@GongRzhe/Office-PowerPoint-MCP-Server"&gt;&lt;img src="https://smithery.ai/badge/@GongRzhe/Office-PowerPoint-MCP-Server" alt="smithery badge"&gt;&lt;/a&gt; &lt;img src="https://badge.mcpx.dev?type=server" alt="" title="MCP Server"&gt;&lt;/p&gt; 
&lt;p&gt;A comprehensive MCP (Model Context Protocol) server for PowerPoint manipulation using python-pptx. &lt;strong&gt;Version 2.0&lt;/strong&gt; provides 32 powerful tools organized into 11 specialized modules, offering complete PowerPoint creation, management, and professional design capabilities. The server features a modular architecture with enhanced parameter handling, intelligent operation selection, and comprehensive error handling.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h1&gt;&lt;strong&gt;Not so ugly anymore with new slide_layout_templates&lt;/strong&gt;&lt;/h1&gt; 
&lt;img width="1509" alt="Êà™Â±è2025-06-20 15 53 45" src="https://github.com/user-attachments/assets/197d82cb-017a-4c00-b969-6e40440ffa36"&gt; 
&lt;hr&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;h4&gt;Pormpt&lt;/h4&gt; 
&lt;img width="1280" alt="650f4cc5d0f1ea4f3b1580800cb0deb" src="https://github.com/user-attachments/assets/90633c97-f373-4c85-bc9c-a1d7b891c344"&gt; 
&lt;h4&gt;Output&lt;/h4&gt; 
&lt;img width="1640" alt="084f1cf4bc7e4fcd4890c8f94f536c1" src="https://github.com/user-attachments/assets/420e63a0-15a4-46d8-b149-1408d23af038"&gt; 
&lt;h4&gt;Demo's GIF -&amp;gt; (./public/demo.mp4)&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/GongRzhe/Office-PowerPoint-MCP-Server/main/public/demo.gif" alt="demo"&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Core PowerPoint Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Round-trip support&lt;/strong&gt; for any Open XML presentation (.pptx file) including all elements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Template support&lt;/strong&gt; with automatic theme and layout preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-presentation management&lt;/strong&gt; with global state tracking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Core document properties&lt;/strong&gt; management (title, subject, author, keywords, comments)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Content Creation &amp;amp; Management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Slide management&lt;/strong&gt; with flexible layout selection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text manipulation&lt;/strong&gt; with placeholder population and bullet point creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced text formatting&lt;/strong&gt; with font, color, alignment, and style controls&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text validation&lt;/strong&gt; with automatic fit checking and optimization suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Visual Elements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Image handling&lt;/strong&gt; with file and base64 input support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image enhancement&lt;/strong&gt; using Pillow with brightness, contrast, saturation, and filter controls&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional image effects&lt;/strong&gt; including shadows, reflections, glows, and soft edges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shape creation&lt;/strong&gt; with 20+ auto shape types (rectangles, ovals, flowchart elements, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Table creation&lt;/strong&gt; with advanced cell formatting and styling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Charts &amp;amp; Data Visualization&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chart support&lt;/strong&gt; for column, bar, line, and pie charts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data series management&lt;/strong&gt; with categories and multiple series support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chart formatting&lt;/strong&gt; with legends, data labels, and titles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Professional Design Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;4 professional color schemes&lt;/strong&gt; (Modern Blue, Corporate Gray, Elegant Green, Warm Red)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional typography&lt;/strong&gt; with Segoe UI font family and size presets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Theme application&lt;/strong&gt; with automatic styling across presentations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gradient backgrounds&lt;/strong&gt; with customizable directions and color schemes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Slide enhancement&lt;/strong&gt; tools for existing content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;25 built-in slide templates&lt;/strong&gt; with dynamic sizing and visual effects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced template features&lt;/strong&gt; including auto-wrapping, dynamic font sizing, and professional animations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Font analysis and optimization&lt;/strong&gt; using FontTools&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Picture effects&lt;/strong&gt; with 9 different visual effects (shadow, reflection, glow, bevel, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive validation&lt;/strong&gt; with automatic error fixing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Template search&lt;/strong&gt; with configurable directory paths&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional layout calculations&lt;/strong&gt; with margin and spacing management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Installing via Smithery&lt;/h3&gt; 
&lt;p&gt;To install PowerPoint Manipulation Server for Claude Desktop automatically via &lt;a href="https://smithery.ai/server/@GongRzhe/Office-PowerPoint-MCP-Server"&gt;Smithery&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx -y @smithery/cli install @GongRzhe/Office-PowerPoint-MCP-Server --client claude
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.6 or higher (as specified in pyproject.toml)&lt;/li&gt; 
 &lt;li&gt;pip package manager&lt;/li&gt; 
 &lt;li&gt;Optional: uvx for package execution without local installation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation Options&lt;/h3&gt; 
&lt;h4&gt;Option 1: Using the Setup Script (Recommended)&lt;/h4&gt; 
&lt;p&gt;The easiest way to set up the PowerPoint MCP Server is using the provided setup script, which automates the installation process:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python setup_mcp.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This script will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check prerequisites&lt;/li&gt; 
 &lt;li&gt;Offer installation options: 
  &lt;ul&gt; 
   &lt;li&gt;Install from PyPI (recommended for most users)&lt;/li&gt; 
   &lt;li&gt;Set up local development environment&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Install required dependencies&lt;/li&gt; 
 &lt;li&gt;Generate the appropriate MCP configuration file&lt;/li&gt; 
 &lt;li&gt;Provide instructions for integrating with Claude Desktop&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The script offers different paths based on your environment:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have &lt;code&gt;uvx&lt;/code&gt; installed, it will configure using UVX (recommended)&lt;/li&gt; 
 &lt;li&gt;If the server is already installed, it provides configuration options&lt;/li&gt; 
 &lt;li&gt;If the server is not installed, it offers installation methods&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Option 2: Manual Installation&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/GongRzhe/Office-PowerPoint-MCP-Server.git
cd Office-PowerPoint-MCP-Server
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Make the server executable:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;chmod +x ppt_mcp_server.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Display help text:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python ppt_mcp_server.py -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Starting the Stdio Server&lt;/h3&gt; 
&lt;p&gt;Run the stdio server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python ppt_mcp_server.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Starting the Streamable-Http Server&lt;/h3&gt; 
&lt;p&gt;Run the streamable-http server on port 8000:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python ppt_mcp_server.py --transport http --port 8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run in Docker&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t ppt_mcp_server .
docker run -d --rm -p 8000:8000 ppt_mcp_server -t http
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCP Configuration&lt;/h3&gt; 
&lt;h4&gt;Option 1: Local Python Server&lt;/h4&gt; 
&lt;p&gt;Add the server to your MCP settings configuration file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "ppt": {
      "command": "python",
      "args": ["/path/to/ppt_mcp_server.py"],
      "env": {}
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option 2: Using UVX (No Local Installation Required)&lt;/h4&gt; 
&lt;p&gt;If you have &lt;code&gt;uvx&lt;/code&gt; installed, you can run the server directly from PyPI without local installation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "ppt": {
      "command": "uvx",
      "args": [
        "--from", "office-powerpoint-mcp-server", "ppt_mcp_server"
      ],
      "env": {}
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ What's New in v2.0&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;Comprehensive Tool Suite (32 Tools)&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complete PowerPoint manipulation&lt;/strong&gt; with 34 specialized tools&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;11 organized modules&lt;/strong&gt; covering all aspects of presentation creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced parameter handling&lt;/strong&gt; with comprehensive validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent defaults&lt;/strong&gt; and operation-based interfaces&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Built-in Slide Templates&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;25+ professional slide templates&lt;/strong&gt; with dynamic features built-in&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced template system&lt;/strong&gt; with auto-generation capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto-sizing text&lt;/strong&gt; that adapts to content length and container size&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional visual effects&lt;/strong&gt; including shadows, glows, and gradients&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complete presentation generation&lt;/strong&gt; from template sequences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Modular Architecture&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;11 specialized modules&lt;/strong&gt;: presentation, content, structural, professional, template, hyperlink, chart, connector, master, and transition tools&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better maintainability&lt;/strong&gt; with separated concerns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easier extensibility&lt;/strong&gt; for adding new features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cleaner code structure&lt;/strong&gt; with shared utilities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Available Tools&lt;/h2&gt; 
&lt;p&gt;The server provides &lt;strong&gt;34 specialized tools&lt;/strong&gt; organized into the following categories:&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Presentation Management (7 tools)&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;create_presentation&lt;/strong&gt; - Create new presentations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;create_presentation_from_template&lt;/strong&gt; - Create from templates with theme preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;open_presentation&lt;/strong&gt; - Open existing presentations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;save_presentation&lt;/strong&gt; - Save presentations to files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;get_presentation_info&lt;/strong&gt; - Get comprehensive presentation information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;get_template_file_info&lt;/strong&gt; - Analyze template files and layouts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;set_core_properties&lt;/strong&gt; - Set document properties&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;Content Management (8 tools)&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol start="8"&gt; 
 &lt;li&gt;&lt;strong&gt;add_slide&lt;/strong&gt; - Add slides with optional background styling&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;get_slide_info&lt;/strong&gt; - Get detailed slide information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;extract_slide_text&lt;/strong&gt; - ‚ú® &lt;strong&gt;NEW&lt;/strong&gt; Extract all text content from a specific slide&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;extract_presentation_text&lt;/strong&gt; - ‚ú® &lt;strong&gt;NEW&lt;/strong&gt; Extract text content from all slides in presentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;populate_placeholder&lt;/strong&gt; - Populate placeholders with text&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;add_bullet_points&lt;/strong&gt; - Add formatted bullet points&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;manage_text&lt;/strong&gt; - ‚ú® &lt;strong&gt;Unified text tool&lt;/strong&gt; (add/format/validate/format_runs)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;manage_image&lt;/strong&gt; - ‚ú® &lt;strong&gt;Unified image tool&lt;/strong&gt; (add/enhance)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;Template Operations (7 tools)&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol start="16"&gt; 
 &lt;li&gt;&lt;strong&gt;list_slide_templates&lt;/strong&gt; - Browse available slide layout templates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;apply_slide_template&lt;/strong&gt; - Apply structured layout templates to existing slides&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;create_slide_from_template&lt;/strong&gt; - Create new slides using layout templates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;create_presentation_from_templates&lt;/strong&gt; - Create complete presentations from template sequences&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;get_template_info&lt;/strong&gt; - Get detailed information about specific templates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;auto_generate_presentation&lt;/strong&gt; - Automatically generate presentations based on topic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;optimize_slide_text&lt;/strong&gt; - Optimize text elements for better readability and fit&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;Structural Elements (4 tools)&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol start="23"&gt; 
 &lt;li&gt;&lt;strong&gt;add_table&lt;/strong&gt; - Create tables with enhanced formatting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;format_table_cell&lt;/strong&gt; - Format individual table cells&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;add_shape&lt;/strong&gt; - Add shapes with text and formatting options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;add_chart&lt;/strong&gt; - Create charts with comprehensive customization&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;Professional Design (3 tools)&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol start="27"&gt; 
 &lt;li&gt;&lt;strong&gt;apply_professional_design&lt;/strong&gt; - ‚ú® &lt;strong&gt;Unified design tool&lt;/strong&gt; (themes/slides/enhancement)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;apply_picture_effects&lt;/strong&gt; - ‚ú® &lt;strong&gt;Unified effects tool&lt;/strong&gt; (9+ effects combined)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;manage_fonts&lt;/strong&gt; - ‚ú® &lt;strong&gt;Unified font tool&lt;/strong&gt; (analyze/optimize/recommend)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;Specialized Features (5 tools)&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol start="30"&gt; 
 &lt;li&gt;&lt;strong&gt;manage_hyperlinks&lt;/strong&gt; - Complete hyperlink management (add/remove/list/update)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;manage_slide_masters&lt;/strong&gt; - Access and manage slide master properties and layouts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;add_connector&lt;/strong&gt; - Add connector lines/arrows between points on slides&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;update_chart_data&lt;/strong&gt; - Replace existing chart data with new categories and series&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;manage_slide_transitions&lt;/strong&gt; - Basic slide transition management&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üåü Key Unified Tools&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;code&gt;manage_text&lt;/code&gt;&lt;/strong&gt; - All-in-One Text Management&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Add text box
manage_text(slide_index=0, operation="add", text="Hello World", font_size=24)

# Format existing text
manage_text(slide_index=0, operation="format", shape_index=0, bold=True, color=[255,0,0])

# Validate text fit with auto-fix
manage_text(slide_index=0, operation="validate", shape_index=0, validation_only=False)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;code&gt;manage_image&lt;/code&gt;&lt;/strong&gt; - Complete Image Handling&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Add image with enhancement
manage_image(slide_index=0, operation="add", image_source="logo.png", 
            enhancement_style="presentation")

# Enhance existing image
manage_image(slide_index=0, operation="enhance", image_source="photo.jpg",
            brightness=1.2, contrast=1.1, saturation=1.3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;code&gt;apply_picture_effects&lt;/code&gt;&lt;/strong&gt; - Multiple Effects in One Call&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Apply combined effects
apply_picture_effects(slide_index=0, shape_index=0, effects={
    "shadow": {"blur_radius": 4.0, "color": [128,128,128]},
    "glow": {"size": 5.0, "color": [0,176,240]},
    "rotation": {"rotation": 15.0}
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;code&gt;apply_professional_design&lt;/code&gt;&lt;/strong&gt; - Theme &amp;amp; Design Management&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Add professional slide
apply_professional_design(operation="slide", slide_type="title_content", 
                         color_scheme="modern_blue", title="My Presentation")

# Apply theme to entire presentation  
apply_professional_design(operation="theme", color_scheme="corporate_gray")

# Enhance existing slide
apply_professional_design(operation="enhance", slide_index=0, color_scheme="elegant_green")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;h3&gt;Creating a New Presentation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Create a new presentation
result = use_mcp_tool(
    server_name="ppt",
    tool_name="create_presentation",
    arguments={}
)
presentation_id = result["presentation_id"]

# Add a title slide
result = use_mcp_tool(
    server_name="ppt",
    tool_name="add_slide",
    arguments={
        "layout_index": 0,  # Title slide layout
        "title": "My Presentation",
        "presentation_id": presentation_id
    }
)
slide_index = result["slide_index"]

# Populate subtitle placeholder
result = use_mcp_tool(
    server_name="ppt",
    tool_name="populate_placeholder",
    arguments={
        "slide_index": slide_index,
        "placeholder_idx": 1,  # Subtitle placeholder
        "text": "Created with PowerPoint MCP Server",
        "presentation_id": presentation_id
    }
)

# Save the presentation
result = use_mcp_tool(
    server_name="ppt",
    tool_name="save_presentation",
    arguments={
        "file_path": "my_presentation.pptx",
        "presentation_id": presentation_id
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Creating a Professional Presentation with v2.0&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Create a professional slide with modern styling - CONSOLIDATED TOOL
result = use_mcp_tool(
    server_name="ppt",
    tool_name="apply_professional_design",
    arguments={
        "operation": "slide",
        "slide_type": "title_content",
        "color_scheme": "modern_blue",
        "title": "Quarterly Business Review",
        "content": [
            "Revenue increased by 15% compared to last quarter",
            "Customer satisfaction scores reached all-time high of 94%",
            "Successfully launched 3 new product features",
            "Expanded team by 12 new talented professionals"
        ]
    }
)

# Apply professional theme to entire presentation - SAME TOOL, DIFFERENT OPERATION
result = use_mcp_tool(
    server_name="ppt",
    tool_name="apply_professional_design",
    arguments={
        "operation": "theme",
        "color_scheme": "modern_blue",
        "apply_to_existing": True
    }
)

# Add slide with gradient background - ENHANCED ADD_SLIDE
result = use_mcp_tool(
    server_name="ppt",
    tool_name="add_slide",
    arguments={
        "layout_index": 0,
        "background_type": "professional_gradient",
        "color_scheme": "modern_blue",
        "gradient_direction": "diagonal"
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Working with Built-in Slide Templates (New in v2.0)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# List all available slide templates with their features
result = use_mcp_tool(
    server_name="ppt",
    tool_name="list_slide_templates",
    arguments={}
)

# Apply a professional template to an existing slide
result = use_mcp_tool(
    server_name="ppt",
    tool_name="apply_slide_template",
    arguments={
        "slide_index": 0,
        "template_id": "title_slide",
        "color_scheme": "modern_blue",
        "content_mapping": {
            "title": "Quarterly Business Review",
            "subtitle": "Q4 2024 Results",
            "author": "Leadership Team"
        }
    }
)

# Create a new slide using a template
result = use_mcp_tool(
    server_name="ppt",
    tool_name="create_slide_from_template",
    arguments={
        "template_id": "text_with_image",
        "color_scheme": "elegant_green",
        "content_mapping": {
            "title": "Our Revolutionary Solution",
            "content": "‚Ä¢ 250% increase in efficiency\n‚Ä¢ 98% customer satisfaction\n‚Ä¢ Industry-leading performance"
        },
        "image_paths": {
            "supporting": "path/to/product_image.jpg"
        }
    }
)

# Generate a complete presentation from multiple templates
result = use_mcp_tool(
    server_name="ppt",
    tool_name="create_presentation_from_templates",
    arguments={
        "template_sequence": [
            {
                "template_id": "title_slide",
                "content": {
                    "title": "2024 Annual Report",
                    "subtitle": "Growth and Innovation",
                    "author": "Executive Team"
                }
            },
            {
                "template_id": "key_metrics_dashboard",
                "content": {
                    "metric_1_value": "94%",
                    "metric_2_value": "$2.4M",
                    "metric_3_value": "247"
                }
            },
            {
                "template_id": "before_after_comparison",
                "content": {
                    "content_left": "Manual processes taking hours",
                    "content_right": "Automated workflows in minutes"
                }
            }
        ],
        "color_scheme": "modern_blue"
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Enhanced Image Management with v2.0&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Add image with automatic enhancement - CONSOLIDATED TOOL
result = use_mcp_tool(
    server_name="ppt",
    tool_name="manage_image",
    arguments={
        "slide_index": 1,
        "operation": "add",
        "image_source": "company_logo.png",
        "left": 1.0,
        "top": 1.0,
        "width": 3.0,
        "height": 2.0,
        "enhancement_style": "presentation"
    }
)

# Apply multiple picture effects at once - CONSOLIDATED TOOL
result = use_mcp_tool(
    server_name="ppt",
    tool_name="apply_picture_effects",
    arguments={
        "slide_index": 1,
        "shape_index": 0,
        "effects": {
            "shadow": {
                "shadow_type": "outer",
                "blur_radius": 4.0,
                "distance": 3.0,
                "direction": 315.0,
                "color": [128, 128, 128],
                "transparency": 0.6
            },
            "glow": {
                "size": 5.0,
                "color": [0, 176, 240],
                "transparency": 0.4
            }
        }
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Text Management with v2.0&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Add and format text in one operation - CONSOLIDATED TOOL
result = use_mcp_tool(
    server_name="ppt",
    tool_name="manage_text",
    arguments={
        "slide_index": 0,
        "operation": "add",
        "left": 1.0,
        "top": 2.0,
        "width": 8.0,
        "height": 1.5,
        "text": "Welcome to Our Quarterly Review",
        "font_size": 32,
        "font_name": "Segoe UI",
        "bold": True,
        "color": [0, 120, 215],
        "alignment": "center",
        "auto_fit": True
    }
)

# Validate and fix text fit issues - SAME TOOL, DIFFERENT OPERATION
result = use_mcp_tool(
    server_name="ppt",
    tool_name="manage_text",
    arguments={
        "slide_index": 0,
        "operation": "validate",
        "shape_index": 0,
        "validation_only": False,  # Auto-fix enabled
        "min_font_size": 10,
        "max_font_size": 48
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Creating a Presentation from Template&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# First, inspect a template to see its layouts and properties
result = use_mcp_tool(
    server_name="ppt",
    tool_name="get_template_info",
    arguments={
        "template_path": "company_template.pptx"
    }
)
template_info = result

# Create a new presentation from the template
result = use_mcp_tool(
    server_name="ppt",
    tool_name="create_presentation_from_template",
    arguments={
        "template_path": "company_template.pptx"
    }
)
presentation_id = result["presentation_id"]

# Add a slide using one of the template's layouts
result = use_mcp_tool(
    server_name="ppt",
    tool_name="add_slide",
    arguments={
        "layout_index": 1,  # Use layout from template
        "title": "Quarterly Report",
        "presentation_id": presentation_id
    }
)

# Save the presentation
result = use_mcp_tool(
    server_name="ppt",
    tool_name="save_presentation",
    arguments={
        "file_path": "quarterly_report.pptx",
        "presentation_id": presentation_id
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Adding Advanced Charts and Data Visualization&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Add a chart slide
result = use_mcp_tool(
    server_name="ppt",
    tool_name="add_slide",
    arguments={
        "layout_index": 1,  # Content slide layout
        "title": "Sales Data",
        "presentation_id": presentation_id
    }
)
slide_index = result["slide_index"]

# Add a column chart with comprehensive customization
result = use_mcp_tool(
    server_name="ppt",
    tool_name="add_chart",
    arguments={
        "slide_index": slide_index,
        "chart_type": "column",
        "left": 1.0,
        "top": 2.0,
        "width": 8.0,
        "height": 4.5,
        "categories": ["Q1", "Q2", "Q3", "Q4"],
        "series_names": ["2023", "2024"],
        "series_values": [
            [100, 120, 140, 160],
            [110, 130, 150, 170]
        ],
        "has_legend": True,
        "legend_position": "bottom",
        "has_data_labels": True,
        "title": "Quarterly Sales Performance",
        "presentation_id": presentation_id
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Text Validation and Optimization with v2.0&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Validate text fit and get optimization suggestions - USING CONSOLIDATED TOOL
result = use_mcp_tool(
    server_name="ppt",
    tool_name="manage_text",
    arguments={
        "slide_index": 0,
        "operation": "validate",
        "shape_index": 0,
        "text": "This is a very long title that might not fit properly in the designated text box area",
        "font_size": 24,
        "validation_only": True
    }
)

# Comprehensive slide validation with automatic fixes - SAME TOOL, AUTO-FIX ENABLED
result = use_mcp_tool(
    server_name="ppt",
    tool_name="manage_text",
    arguments={
        "slide_index": 0,
        "operation": "validate",
        "shape_index": 0,
        "validation_only": False,  # Auto-fix enabled
        "min_font_size": 10,
        "max_font_size": 48
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reading Slide Content with New Text Extraction Tools (v2.1)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Extract text content from a specific slide - NEW TOOL
result = use_mcp_tool(
    server_name="ppt",
    tool_name="extract_slide_text",
    arguments={
        "slide_index": 0,
        "presentation_id": presentation_id
    }
)

# The result includes:
{
    "success": True,
    "slide_index": 0,
    "text_content": {
        "slide_title": "Quarterly Business Review",
        "placeholders": [
            {
                "shape_index": 1,
                "shape_name": "Subtitle Placeholder 2",
                "text": "Q4 2024 Results",
                "placeholder_type": "SUBTITLE",
                "placeholder_idx": 1
            }
        ],
        "text_shapes": [
            {
                "shape_index": 3,
                "shape_name": "TextBox 4",
                "text": "Revenue increased by 15%"
            }
        ],
        "table_text": [],
        "all_text_combined": "Quarterly Business Review\nQ4 2024 Results\nRevenue increased by 15%"
    },
    "total_text_shapes": 2,
    "has_title": True,
    "has_tables": False
}

# Extract text from all slides in the presentation - NEW TOOL
result = use_mcp_tool(
    server_name="ppt",
    tool_name="extract_presentation_text",
    arguments={
        "presentation_id": presentation_id,
        "include_slide_info": True
    }
)

# The result includes comprehensive text extraction:
{
    "success": True,
    "presentation_id": "pres_123",
    "total_slides": 5,
    "slides_with_text": 4,
    "total_text_shapes": 12,
    "slides_with_titles": 3,
    "slides_with_tables": 1,
    "slides_text": [...],  # Detailed per-slide text content
    "all_presentation_text_combined": "=== SLIDE 1 ===\nTitle Here\nContent here..."
}

# Extract text without additional slide metadata for cleaner output
result = use_mcp_tool(
    server_name="ppt",
    tool_name="extract_presentation_text",
    arguments={
        "presentation_id": presentation_id,
        "include_slide_info": False
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Template Support&lt;/h2&gt; 
&lt;h3&gt;Working with Templates&lt;/h3&gt; 
&lt;p&gt;The PowerPoint MCP Server provides comprehensive template support for creating presentations from existing template files. This feature enables:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Corporate branding&lt;/strong&gt; with predefined themes, layouts, and styles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistent presentations&lt;/strong&gt; across teams and projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom slide masters&lt;/strong&gt; and specialized layouts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-configured properties&lt;/strong&gt; and document settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible template discovery&lt;/strong&gt; with configurable search paths&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Template File Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Supported formats&lt;/strong&gt;: &lt;code&gt;.pptx&lt;/code&gt; and &lt;code&gt;.potx&lt;/code&gt; files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Existing content&lt;/strong&gt;: Templates can contain existing slides (preserved during creation)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Layout availability&lt;/strong&gt;: All custom layouts and slide masters are accessible&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search locations&lt;/strong&gt;: Configurable via &lt;code&gt;PPT_TEMPLATE_PATH&lt;/code&gt; environment variable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Default search paths&lt;/strong&gt;: Current directory, &lt;code&gt;./templates&lt;/code&gt;, &lt;code&gt;./assets&lt;/code&gt;, &lt;code&gt;./resources&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Template Configuration&lt;/h3&gt; 
&lt;p&gt;Set the &lt;code&gt;PPT_TEMPLATE_PATH&lt;/code&gt; environment variable to specify custom template directories:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Unix/Linux/macOS
export PPT_TEMPLATE_PATH="/path/to/templates:/another/path"

# Windows  
set PPT_TEMPLATE_PATH="C:\templates;C:\company_templates"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Template Workflow&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Inspect Template&lt;/strong&gt;: Use &lt;code&gt;get_template_info&lt;/code&gt; to analyze available layouts and properties&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create from Template&lt;/strong&gt;: Use &lt;code&gt;create_presentation_from_template&lt;/code&gt; with automatic theme preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Template Layouts&lt;/strong&gt;: Reference layout indices from template analysis when adding slides&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Maintain Branding&lt;/strong&gt;: Template themes, fonts, and colors are automatically applied to new content&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Professional Color Schemes&lt;/h3&gt; 
&lt;p&gt;The server includes 4 built-in professional color schemes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Modern Blue&lt;/strong&gt;: Microsoft-inspired blue theme with complementary colors&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Corporate Gray&lt;/strong&gt;: Professional grayscale theme with blue accents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Elegant Green&lt;/strong&gt;: Forest green theme with cream and light green accents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Warm Red&lt;/strong&gt;: Deep red theme with orange and yellow accents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each scheme includes primary, secondary, accent, light, and text colors optimized for business presentations.&lt;/p&gt; 
&lt;h2&gt;üé® Built-in Slide Templates (New in v2.0)&lt;/h2&gt; 
&lt;p&gt;The PowerPoint MCP Server now includes &lt;strong&gt;25 professional slide templates&lt;/strong&gt; with advanced dynamic features. All templates support:&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Dynamic Features&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic text sizing&lt;/strong&gt; based on content length and container dimensions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent text wrapping&lt;/strong&gt; to fit within specified areas&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Visual effects&lt;/strong&gt; including shadows, glows, and outlines&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gradient backgrounds&lt;/strong&gt; with multi-layer compositions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional animations&lt;/strong&gt; ready for presentation delivery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive hover effects&lt;/strong&gt; for enhanced user experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart content overflow handling&lt;/strong&gt; with automatic adjustments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Available Template Categories&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;Title &amp;amp; Introduction Slides&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;title_slide&lt;/code&gt; - Dynamic title slide with gradient background and text effects&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_intro&lt;/code&gt; - Section divider with chapter numbering and styling&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;thank_you_slide&lt;/code&gt; - Closing slide with contact information and effects&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Content Layout Slides&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;text_with_image&lt;/code&gt; - Text content with stylized image and interactive elements&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;two_column_text&lt;/code&gt; - Two equal columns of text with dynamic sizing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;two_column_text_images&lt;/code&gt; - Two columns with text and corresponding images&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;three_column_layout&lt;/code&gt; - Three equal columns with text and images&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;full_image_slide&lt;/code&gt; - Large background image with text overlay&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Business &amp;amp; Analytics Slides&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;key_metrics_dashboard&lt;/code&gt; - Interactive metrics dashboard with animated counters&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;before_after_comparison&lt;/code&gt; - Dynamic comparison layout with visual dividers&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chart_comparison&lt;/code&gt; - Two charts side by side for performance comparison&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data_table_slide&lt;/code&gt; - Slide focused on tabular data with professional styling&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;timeline_slide&lt;/code&gt; - Horizontal timeline with milestones and effects&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Process &amp;amp; Flow Slides&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;process_flow&lt;/code&gt; - Step-by-step process visualization with enhanced effects&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;agenda_slide&lt;/code&gt; - Table of contents or agenda overview with styling&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;quote_testimonial&lt;/code&gt; - Featured quote or customer testimonial with effects&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Team &amp;amp; Organization Slides&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;team_introduction&lt;/code&gt; - Team member showcase with photos and roles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Template Usage Examples&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Browse all available templates
templates = use_mcp_tool("ppt", "list_slide_templates", {})

# Key templates with their features:
{
  "title_slide": {
    "features": ["Dynamic text sizing", "Gradient backgrounds", "Text effects"],
    "elements": ["title", "subtitle", "author", "decorative_accent"]
  },
  "key_metrics_dashboard": {
    "features": ["Animated counters", "Gradient containers", "Trend visualization"],
    "elements": ["3 metric containers", "trend chart", "insights callout"]
  },
  "before_after_comparison": {
    "features": ["Split gradient background", "VS divider", "Improvement arrow"],
    "elements": ["before/after headers", "comparison content", "improvement metrics"]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;Color Scheme Integration&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;All templates work seamlessly with the 4 professional color schemes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;modern_blue&lt;/strong&gt;: Microsoft-inspired theme with dynamic gradients&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;corporate_gray&lt;/strong&gt;: Professional grayscale with blue accents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;elegant_green&lt;/strong&gt;: Forest green with cream and light accents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;warm_red&lt;/strong&gt;: Deep red with orange and yellow highlights&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Dynamic Content Adaptation&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Templates automatically adjust to content:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Font sizes&lt;/strong&gt; scale based on text length (8pt - 44pt range)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Line spacing&lt;/strong&gt; adjusts for readability (1.0x - 1.4x)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text wrapping&lt;/strong&gt; intelligently breaks lines at optimal points&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Container sizing&lt;/strong&gt; adapts to content overflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Visual effects&lt;/strong&gt; scale appropriately with element sizes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÅ File Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Office-PowerPoint-MCP-Server/
‚îú‚îÄ‚îÄ ppt_mcp_server.py          # Main consolidated server (v2.0)
‚îú‚îÄ‚îÄ slide_layout_templates.json # 25+ professional slide templates with dynamic features
‚îú‚îÄ‚îÄ tools/                     # 11 specialized tool modules (32 tools total)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ presentation_tools.py  # Presentation management (7 tools)
‚îÇ   ‚îú‚îÄ‚îÄ content_tools.py       # Content &amp;amp; slides (6 tools)
‚îÇ   ‚îú‚îÄ‚îÄ template_tools.py      # Template operations (7 tools)
‚îÇ   ‚îú‚îÄ‚îÄ structural_tools.py    # Tables, shapes, charts (4 tools)
‚îÇ   ‚îú‚îÄ‚îÄ professional_tools.py  # Themes, effects, fonts (3 tools)
‚îÇ   ‚îú‚îÄ‚îÄ hyperlink_tools.py     # Hyperlink management (1 tool)
‚îÇ   ‚îú‚îÄ‚îÄ chart_tools.py         # Advanced chart operations (1 tool)
‚îÇ   ‚îú‚îÄ‚îÄ connector_tools.py     # Connector lines/arrows (1 tool)
‚îÇ   ‚îú‚îÄ‚îÄ master_tools.py        # Slide master management (1 tool)
‚îÇ   ‚îî‚îÄ‚îÄ transition_tools.py    # Slide transitions (1 tool)
‚îú‚îÄ‚îÄ utils/                     # 7 organized utility modules (68+ functions)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ core_utils.py          # Error handling &amp;amp; safe operations
‚îÇ   ‚îú‚îÄ‚îÄ presentation_utils.py  # Presentation management utilities
‚îÇ   ‚îú‚îÄ‚îÄ content_utils.py       # Content &amp;amp; slide operations
‚îÇ   ‚îú‚îÄ‚îÄ design_utils.py        # Themes, colors, effects &amp;amp; fonts
‚îÇ   ‚îú‚îÄ‚îÄ template_utils.py      # Template management &amp;amp; dynamic features
‚îÇ   ‚îî‚îÄ‚îÄ validation_utils.py    # Text &amp;amp; layout validation
‚îú‚îÄ‚îÄ setup_mcp.py              # Interactive setup script
‚îú‚îÄ‚îÄ pyproject.toml            # Updated for v2.0
‚îî‚îÄ‚îÄ README.md                 # This documentation
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üèóÔ∏è Architecture Benefits&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;Modular Design&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;7 focused utility modules&lt;/strong&gt; with clear responsibilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;11 organized tool modules&lt;/strong&gt; for comprehensive coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;68+ utility functions&lt;/strong&gt; organized by functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;32 MCP tools&lt;/strong&gt; covering all PowerPoint manipulation needs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clear separation of concerns&lt;/strong&gt; for easier development&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Code Organization&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Logical grouping&lt;/strong&gt; of related functionality across modules&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better discoverability&lt;/strong&gt; with organized tool categories&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Improved testability&lt;/strong&gt; with isolated modules&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Future extensibility&lt;/strong&gt; through modular structure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Comprehensive Coverage&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complete PowerPoint lifecycle&lt;/strong&gt; from creation to presentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced template system&lt;/strong&gt; with auto-generation capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional design tools&lt;/strong&gt; with multiple effects and styling options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Specialized features&lt;/strong&gt; including hyperlinks, connectors, and slide masters&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Developer Experience&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Clear responsibility boundaries&lt;/strong&gt; between modules&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easier debugging&lt;/strong&gt; with smaller, focused files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simpler testing&lt;/strong&gt; with isolated functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced maintainability&lt;/strong&gt; through separation of concerns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîÑ What's New in Version 2.0&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Enhanced functionality with comprehensive tool coverage!&lt;/strong&gt; The updated server provides:&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;New Specialized Tools Added:&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;manage_hyperlinks&lt;/code&gt;&lt;/strong&gt; - Complete hyperlink management for text elements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;update_chart_data&lt;/code&gt;&lt;/strong&gt; - Advanced chart data replacement and updating&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;add_connector&lt;/code&gt;&lt;/strong&gt; - Connector lines and arrows between slide elements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;manage_slide_masters&lt;/code&gt;&lt;/strong&gt; - Access to slide master properties and layouts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;manage_slide_transitions&lt;/code&gt;&lt;/strong&gt; - Basic slide transition management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;auto_generate_presentation&lt;/code&gt;&lt;/strong&gt; - AI-powered presentation generation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;optimize_slide_text&lt;/code&gt;&lt;/strong&gt; - Text optimization for better readability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Enhanced Existing Tools:&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;manage_text&lt;/code&gt;&lt;/strong&gt; - Now supports text run formatting with &lt;code&gt;format_runs&lt;/code&gt; operation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;create_presentation_from_templates&lt;/code&gt;&lt;/strong&gt; - Enhanced template sequence processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;apply_picture_effects&lt;/code&gt;&lt;/strong&gt; - Expanded effect combinations and options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîÑ What's New in Version 2.1&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Text extraction capabilities added!&lt;/strong&gt; Now you can read content from existing presentations:&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;New Text Extraction Tools Added:&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;extract_slide_text&lt;/code&gt;&lt;/strong&gt; - Extract all text content from a specific slide including titles, placeholders, text shapes, and tables&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;extract_presentation_text&lt;/code&gt;&lt;/strong&gt; - Extract text content from all slides in a presentation with comprehensive statistics and combined output&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Key Features of Text Extraction:&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complete text coverage&lt;/strong&gt; - Extracts from titles, placeholders, text boxes, and table cells&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Structured output&lt;/strong&gt; - Organized by content type (titles, placeholders, shapes, tables)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Presentation-wide analysis&lt;/strong&gt; - Statistics on text distribution across slides&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible output options&lt;/strong&gt; - Individual slide content or combined presentation text&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error handling&lt;/strong&gt; - Graceful handling of slides that cannot be processed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pathwaycom/pathway</title>
      <link>https://github.com/pathwaycom/pathway</link>
      <description>&lt;p&gt;Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://pathway.com/"&gt; &lt;img src="https://pathway.com/logo-light.svg?sanitize=true"&gt; &lt;/a&gt; 
 &lt;br&gt;
 &lt;br&gt; 
 &lt;a href="https://trendshift.io/repositories/10388" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10388" alt="pathwaycom%2Fpathway | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
 &lt;br&gt;
 &lt;br&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg?sanitize=true" alt="ubuntu"&gt; &lt;br&gt; &lt;/a&gt;&lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/release.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg?sanitize=true" alt="Last release"&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://badge.fury.io/py/pathway.svg?sanitize=true" alt="PyPI version" height="18"&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://static.pepy.tech/badge/pathway" alt="PyPI downloads" height="18"&gt;&lt;/a&gt; &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt; &lt;img src="https://img.shields.io/badge/license-BSL-green" alt="License: BSL"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://discord.gg/pathway"&gt; &lt;img src="https://img.shields.io/discord/1042405378304004156?logo=discord" alt="chat on Discord"&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=pathway_com"&gt; &lt;img src="https://img.shields.io/twitter/follow/pathwaycom" alt="follow on Twitter"&gt;&lt;/a&gt; &lt;a href="https://linkedin.com/company/pathway"&gt; &lt;img src="https://img.shields.io/badge/pathway-0077B5?style=social&amp;amp;logo=linkedin" alt="follow on LinkedIn"&gt;&lt;/a&gt; &lt;a href="https://github.com/dylanhogg/awesome-python/raw/main/README.md"&gt; &lt;img src="https://awesome.re/badge.svg?sanitize=true" alt="Awesome Python"&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/pathway"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF" alt="Pathway Guru"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#deployment"&gt;Deployment&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#resources"&gt;Documentation and Support&lt;/a&gt; | &lt;a href="https://pathway.com/blog/"&gt;Blog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Pathway&lt;a id="pathway"&gt; Live Data Framework&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pathway.com"&gt;Pathway&lt;/a&gt; is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt; 
&lt;p&gt;Pathway comes with an &lt;strong&gt;easy-to-use Python API&lt;/strong&gt;, allowing you to seamlessly integrate your favorite Python ML libraries. Pathway code is versatile and robust: &lt;strong&gt;you can use it in both development and production environments, handling both batch and streaming data effectively&lt;/strong&gt;. The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.&lt;/p&gt; 
&lt;p&gt;Pathway is powered by a &lt;strong&gt;scalable Rust engine&lt;/strong&gt; based on Differential Dataflow and performs incremental computation. Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations. All the pipeline is kept in memory and can be easily deployed with &lt;strong&gt;Docker and Kubernetes&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;You can install Pathway with pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For any questions, you will find the community and team behind the project &lt;a href="https://discord.com/invite/pathway"&gt;on Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Use-cases and templates&lt;/h2&gt; 
&lt;p&gt;Ready to see what Pathway can do?&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pathway.com/developers/templates"&gt;Try one of our easy-to-run examples&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!&lt;/p&gt; 
&lt;h3&gt;Event processing and real-time analytics pipelines&lt;/h3&gt; 
&lt;p&gt;With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/kafka-etl"&gt;Showcase: Real-time ETL.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/realtime-log-monitoring"&gt;Showcase: Event-driven pipelines with alerting.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/linear_regression_with_kafka/"&gt;Showcase: Realtime analytics.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming"&gt;Docs: Switch from batch to streaming.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;AI Pipelines&lt;/h3&gt; 
&lt;p&gt;Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/overview"&gt;LLM xpack documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Don't hesitate to try one of our runnable examples featuring LLM tooling. You can find such examples &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/llm-examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/unstructured-to-structured/"&gt;Template: Unstructured data to SQL on-the-fly.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/private-rag-ollama-mistral"&gt;Template: Private RAG with Ollama and Mistral AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/adaptive-rag"&gt;Template: Adaptive RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/multimodal-rag"&gt;Template: Multimodal RAG with gpt-4o&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A wide range of connectors&lt;/strong&gt;: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stateless and stateful transformations&lt;/strong&gt;: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistence&lt;/strong&gt;: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the "at least once" consistency while the enterprise version provides the "exactly once" consistency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Rust engine&lt;/strong&gt;: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM helpers&lt;/strong&gt;: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;a id="getting-started"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;a id="installation"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Pathway requires Python 3.10 or above.&lt;/p&gt; 
&lt;p&gt;You can install the current release of Pathway using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚ö†Ô∏è Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.&lt;/p&gt; 
&lt;h3&gt;Example: computing the sum of positive values in real time.&lt;a id="example"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  "./input/",
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&amp;gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, "output.jsonl")

# Run the computation
pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run Pathway &lt;a href="https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing"&gt;in Google Colab&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find more examples &lt;a href="https://github.com/pathwaycom/pathway/tree/main/examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deployment&lt;a id="deployment"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Locally&lt;a id="running-pathway-locally"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;To use Pathway, you only need to import it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then run your Pathway project (say, &lt;code&gt;main.py&lt;/code&gt;) just like a normal Python script: &lt;code&gt;$ python main.py&lt;/code&gt;. Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages.&lt;/p&gt; 
&lt;img src="https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png" width="1326" alt="Pathway dashboard"&gt; 
&lt;p&gt;Alternatively, you can use the pathway'ish version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pathway natively supports multithreading. To launch your application with 3 threads, you can do as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn --threads 3 python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To jumpstart a Pathway project, you can use our &lt;a href="https://github.com/pathwaycom/cookiecutter-pathway"&gt;cookiecutter template&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;a id="docker"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;You can easily run Pathway using docker.&lt;/p&gt; 
&lt;h4&gt;Pathway image&lt;/h4&gt; 
&lt;p&gt;You can use the &lt;a href="https://hub.docker.com/r/pathwaycom/pathway"&gt;Pathway docker image&lt;/a&gt;, using a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ "python", "./your-script.py" ]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then build and run the Docker image:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run a single Python script&lt;/h4&gt; 
&lt;p&gt;When dealing with single-file projects, creating a full-fledged &lt;code&gt;Dockerfile&lt;/code&gt; might seem unnecessary. In such scenarios, you can execute a Python script directly using the Pathway Docker image. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker run -it --rm --name my-pathway-app -v "$PWD":/app pathwaycom/pathway:latest python my-pathway-app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python docker image&lt;/h4&gt; 
&lt;p&gt;You can also use a standard Python image and install Pathway using pip with a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD ["python", "-u", "pathway-script.py"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Kubernetes and cloud&lt;a id="k8s"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Docker containers are ideally suited for deployment on the cloud with Kubernetes. If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise. Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics. It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.&lt;/p&gt; 
&lt;p&gt;You can easily deploy Pathway using services like Render: see &lt;a href="https://pathway.com/developers/user-guide/deployment/render-deploy/"&gt;how to deploy Pathway in a few clicks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested, don't hesitate to &lt;a href="mailto:contact@pathway.com"&gt;contact us&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;a id="performance"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).&lt;/p&gt; 
&lt;p&gt;If you are curious, here are &lt;a href="https://github.com/pathwaycom/pathway-benchmarks"&gt;some benchmarks to play with&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png" width="1326" alt="WordCount Graph"&gt; 
&lt;h2&gt;Documentation and Support&lt;a id="resources"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The entire documentation of Pathway is available at &lt;a href="https://pathway.com/developers/user-guide/introduction/welcome"&gt;pathway.com/developers/&lt;/a&gt;, including the &lt;a href="https://pathway.com/developers/api-docs/pathway"&gt;API Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have any question, don't hesitate to &lt;a href="https://github.com/pathwaycom/pathway/issues"&gt;open an issue on GitHub&lt;/a&gt;, join us on &lt;a href="https://discord.com/invite/pathway"&gt;Discord&lt;/a&gt;, or send us an email at &lt;a href="mailto:contact@pathway.com"&gt;contact@pathway.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;a id="license"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is distributed on a &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt;BSL 1.1 License&lt;/a&gt; which allows for unlimited non-commercial use, as well as use of the Pathway package &lt;a href="https://pathway.com/license/"&gt;for most commercial purposes&lt;/a&gt;, free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some &lt;a href="https://github.com/pathwaycom"&gt;public repos&lt;/a&gt; which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.&lt;/p&gt; 
&lt;h2&gt;Contribution guidelines&lt;a id="contribution-guidelines"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license.&lt;/p&gt; 
&lt;p&gt;For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don't hesitate to engage with Pathway's &lt;a href="https://discord.gg/pathway"&gt;Discord community&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gradio-app/gradio</title>
      <link>https://github.com/gradio-app/gradio</link>
      <description>&lt;p&gt;Build and share delightful machine learning apps, all in Python. üåü Star to support our work!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://gradio.app"&gt; &lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/gradio.svg?sanitize=true" alt="gradio" width="350"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;span&gt; &lt;a href="https://www.producthunt.com/posts/gradio-5-0?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-gradio-5-0" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=501906&amp;amp;theme=light" alt="Gradio 5.0 - the easiest way to build AI web apps | Product Hunt" style="width: 150px; height: 54px;" width="150" height="54"&gt;&lt;/a&gt; &lt;a href="https://trendshift.io/repositories/2145" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/2145" alt="gradio-app%2Fgradio | Trendshift" style="width: 150px; height: 55px;" width="150" height="55"&gt;&lt;/a&gt; &lt;/span&gt; 
 &lt;p&gt;&lt;a href="https://github.com/gradio-app/gradio/actions/workflows/test-python.yml"&gt;&lt;img src="https://github.com/gradio-app/gradio/actions/workflows/test-python.yml/badge.svg?sanitize=true" alt="gradio-backend"&gt;&lt;/a&gt; &lt;a href="https://github.com/gradio-app/gradio/actions/workflows/tests-js.yml"&gt;&lt;img src="https://github.com/gradio-app/gradio/actions/workflows/tests-js.yml/badge.svg?sanitize=true" alt="gradio-ui"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/gradio/"&gt;&lt;img src="https://img.shields.io/pypi/v/gradio" alt="PyPI"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/gradio/"&gt;&lt;img src="https://img.shields.io/pypi/dm/gradio" alt="PyPI downloads"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/python-3.10+-important" alt="Python version"&gt; &lt;a href="https://twitter.com/gradio"&gt;&lt;img src="https://img.shields.io/twitter/follow/gradio?style=social&amp;amp;label=follow" alt="Twitter follow"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://gradio.app"&gt;Website&lt;/a&gt; | &lt;a href="https://gradio.app/docs/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://gradio.app/guides/"&gt;Guides&lt;/a&gt; | &lt;a href="https://gradio.app/getting_started/"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/gradio-app/gradio/main/demo/"&gt;Examples&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/zh-cn#readme"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;Gradio: Build Machine Learning Web Apps ‚Äî in Python&lt;/h1&gt; 
&lt;p&gt;Gradio is an open-source Python package that allows you to quickly &lt;strong&gt;build&lt;/strong&gt; a demo or web application for your machine learning model, API, or any arbitrary Python function. You can then &lt;strong&gt;share&lt;/strong&gt; a link to your demo or web application in just a few seconds using Gradio's built-in sharing features. &lt;em&gt;No JavaScript, CSS, or web hosting experience needed!&lt;/em&gt;&lt;/p&gt; 
&lt;img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/gif-version.gif" style="padding-bottom: 10px"&gt; 
&lt;p&gt;It just takes a few lines of Python to create your own demo, so let's get started üí´&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisite&lt;/strong&gt;: Gradio requires &lt;a href="https://www.python.org/downloads/"&gt;Python 3.10 or higher&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We recommend installing Gradio using &lt;code&gt;pip&lt;/code&gt;, which is included by default in Python. Run this in your terminal or command prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade gradio
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] It is best to install Gradio in a virtual environment. Detailed installation instructions for all common operating systems &lt;a href="https://www.gradio.app/main/guides/installing-gradio-in-a-virtual-environment"&gt;are provided here&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Building Your First Demo&lt;/h3&gt; 
&lt;p&gt;You can run Gradio in your favorite code editor, Jupyter notebook, Google Colab, or anywhere else you write Python. Let's write your first Gradio app:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import gradio as gr

def greet(name, intensity):
    return "Hello, " + name + "!" * int(intensity)

demo = gr.Interface(
    fn=greet,
    inputs=["text", "slider"],
    outputs=["text"],
)

demo.launch()
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] We shorten the imported name from &lt;code&gt;gradio&lt;/code&gt; to &lt;code&gt;gr&lt;/code&gt;. This is a widely adopted convention for better readability of code.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Now, run your code. If you've written the Python code in a file named &lt;code&gt;app.py&lt;/code&gt;, then you would run &lt;code&gt;python app.py&lt;/code&gt; from the terminal.&lt;/p&gt; 
&lt;p&gt;The demo below will open in a browser on &lt;a href="http://localhost:7860"&gt;http://localhost:7860&lt;/a&gt; if running from a file. If you are running within a notebook, the demo will appear embedded within the notebook.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/demo/hello_world_4/screenshot.gif" alt="hello_world_4 demo"&gt;&lt;/p&gt; 
&lt;p&gt;Type your name in the textbox on the left, drag the slider, and then press the Submit button. You should see a friendly greeting on the right.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] When developing locally, you can run your Gradio app in &lt;strong&gt;hot reload mode&lt;/strong&gt;, which automatically reloads the Gradio app whenever you make changes to the file. To do this, simply type in &lt;code&gt;gradio&lt;/code&gt; before the name of the file instead of &lt;code&gt;python&lt;/code&gt;. In the example above, you would type: &lt;code&gt;gradio app.py&lt;/code&gt; in your terminal. Learn more in the &lt;a href="https://www.gradio.app/guides/developing-faster-with-reload-mode"&gt;Hot Reloading Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Understanding the &lt;code&gt;Interface&lt;/code&gt; Class&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You'll notice that in order to make your first demo, you created an instance of the &lt;code&gt;gr.Interface&lt;/code&gt; class. The &lt;code&gt;Interface&lt;/code&gt; class is designed to create demos for machine learning models which accept one or more inputs, and return one or more outputs.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;Interface&lt;/code&gt; class has three core arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;fn&lt;/code&gt;: the function to wrap a user interface (UI) around&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;inputs&lt;/code&gt;: the Gradio component(s) to use for the input. The number of components should match the number of arguments in your function.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;outputs&lt;/code&gt;: the Gradio component(s) to use for the output. The number of components should match the number of return values from your function.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;fn&lt;/code&gt; argument is very flexible -- you can pass &lt;em&gt;any&lt;/em&gt; Python function that you want to wrap with a UI. In the example above, we saw a relatively simple function, but the function could be anything from a music generator to a tax calculator to the prediction function of a pretrained machine learning model.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; arguments take one or more Gradio components. As we'll see, Gradio includes more than &lt;a href="https://www.gradio.app/docs/gradio/introduction"&gt;30 built-in components&lt;/a&gt; (such as the &lt;code&gt;gr.Textbox()&lt;/code&gt;, &lt;code&gt;gr.Image()&lt;/code&gt;, and &lt;code&gt;gr.HTML()&lt;/code&gt; components) that are designed for machine learning applications.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] For the &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; arguments, you can pass in the name of these components as a string (&lt;code&gt;"textbox"&lt;/code&gt;) or an instance of the class (&lt;code&gt;gr.Textbox()&lt;/code&gt;).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If your function accepts more than one argument, as is the case above, pass a list of input components to &lt;code&gt;inputs&lt;/code&gt;, with each input component corresponding to one of the arguments of the function, in order. The same holds true if your function returns more than one value: simply pass in a list of components to &lt;code&gt;outputs&lt;/code&gt;. This flexibility makes the &lt;code&gt;Interface&lt;/code&gt; class a very powerful way to create demos.&lt;/p&gt; 
&lt;p&gt;We'll dive deeper into the &lt;code&gt;gr.Interface&lt;/code&gt; on our series on &lt;a href="https://www.gradio.app/main/guides/the-interface-class"&gt;building Interfaces&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Sharing Your Demo&lt;/h3&gt; 
&lt;p&gt;What good is a beautiful demo if you can't share it? Gradio lets you easily share a machine learning demo without having to worry about the hassle of hosting on a web server. Simply set &lt;code&gt;share=True&lt;/code&gt; in &lt;code&gt;launch()&lt;/code&gt;, and a publicly accessible URL will be created for your demo. Let's revisit our example demo, but change the last line as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import gradio as gr

def greet(name):
    return "Hello " + name + "!"

demo = gr.Interface(fn=greet, inputs="textbox", outputs="textbox")
    
demo.launch(share=True)  # Share your demo with just 1 extra parameter üöÄ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When you run this code, a public URL will be generated for your demo in a matter of seconds, something like:&lt;/p&gt; 
&lt;p&gt;üëâ &amp;nbsp; &lt;code&gt;https://a23dsf231adb.gradio.live&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Now, anyone around the world can try your Gradio demo from their browser, while the machine learning model and all computation continues to run locally on your computer.&lt;/p&gt; 
&lt;p&gt;To learn more about sharing your demo, read our dedicated guide on &lt;a href="https://www.gradio.app/guides/sharing-your-app"&gt;sharing your Gradio application&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;An Overview of Gradio&lt;/h3&gt; 
&lt;p&gt;So far, we've been discussing the &lt;code&gt;Interface&lt;/code&gt; class, which is a high-level class that lets to build demos quickly with Gradio. But what else does Gradio include?&lt;/p&gt; 
&lt;h4&gt;Custom Demos with &lt;code&gt;gr.Blocks&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Gradio offers a low-level approach for designing web apps with more customizable layouts and data flows with the &lt;code&gt;gr.Blocks&lt;/code&gt; class. Blocks supports things like controlling where components appear on the page, handling multiple data flows and more complex interactions (e.g. outputs can serve as inputs to other functions), and updating properties/visibility of components based on user interaction ‚Äî still all in Python.&lt;/p&gt; 
&lt;p&gt;You can build very custom and complex applications using &lt;code&gt;gr.Blocks()&lt;/code&gt;. For example, the popular image generation &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;Automatic1111 Web UI&lt;/a&gt; is built using Gradio Blocks. We dive deeper into the &lt;code&gt;gr.Blocks&lt;/code&gt; on our series on &lt;a href="https://www.gradio.app/guides/blocks-and-event-listeners"&gt;building with Blocks&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Chatbots with &lt;code&gt;gr.ChatInterface&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Gradio includes another high-level class, &lt;code&gt;gr.ChatInterface&lt;/code&gt;, which is specifically designed to create Chatbot UIs. Similar to &lt;code&gt;Interface&lt;/code&gt;, you supply a function and Gradio creates a fully working Chatbot UI. If you're interested in creating a chatbot, you can jump straight to &lt;a href="https://www.gradio.app/guides/creating-a-chatbot-fast"&gt;our dedicated guide on &lt;code&gt;gr.ChatInterface&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;The Gradio Python &amp;amp; JavaScript Ecosystem&lt;/h4&gt; 
&lt;p&gt;That's the gist of the core &lt;code&gt;gradio&lt;/code&gt; Python library, but Gradio is actually so much more! It's an entire ecosystem of Python and JavaScript libraries that let you build machine learning applications, or query them programmatically, in Python or JavaScript. Here are other related parts of the Gradio ecosystem:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.gradio.app/guides/getting-started-with-the-python-client"&gt;Gradio Python Client&lt;/a&gt; (&lt;code&gt;gradio_client&lt;/code&gt;): query any Gradio app programmatically in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.gradio.app/guides/getting-started-with-the-js-client"&gt;Gradio JavaScript Client&lt;/a&gt; (&lt;code&gt;@gradio/client&lt;/code&gt;): query any Gradio app programmatically in JavaScript.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.gradio.app/guides/gradio-lite"&gt;Gradio-Lite&lt;/a&gt; (&lt;code&gt;@gradio/lite&lt;/code&gt;): write Gradio apps in Python that run entirely in the browser (no server needed!), thanks to Pyodide.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces"&gt;Hugging Face Spaces&lt;/a&gt;: the most popular place to host Gradio applications ‚Äî for free!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What's Next?&lt;/h3&gt; 
&lt;p&gt;Keep learning about Gradio sequentially using the Gradio Guides, which include explanations as well as example code and embedded interactive demos. Next up: &lt;a href="https://www.gradio.app/guides/the-interface-class"&gt;let's dive deeper into the Interface class&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Or, if you already know the basics and are looking for something specific, you can search the more &lt;a href="https://www.gradio.app/docs/"&gt;technical API documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Gradio Sketch&lt;/h3&gt; 
&lt;p&gt;You can also build Gradio applications without writing any code. Simply type &lt;code&gt;gradio sketch&lt;/code&gt; into your terminal to open up an editor that lets you define and modify Gradio components, adjust their layouts, add events, all through a web editor. Or &lt;a href="https://huggingface.co/spaces/aliabid94/Sketch"&gt;use this hosted version of Gradio Sketch, running on Hugging Face Spaces&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Questions?&lt;/h2&gt; 
&lt;p&gt;If you'd like to report a bug or have a feature request, please create an &lt;a href="https://github.com/gradio-app/gradio/issues/new/choose"&gt;issue on GitHub&lt;/a&gt;. For general questions about usage, we are available on &lt;a href="https://discord.com/invite/feTf9x3ZSB"&gt;our Discord server&lt;/a&gt; and happy to help.&lt;/p&gt; 
&lt;p&gt;If you like Gradio, please leave us a ‚≠ê on GitHub!&lt;/p&gt; 
&lt;h2&gt;Open Source Stack&lt;/h2&gt; 
&lt;p&gt;Gradio is built on top of many wonderful open-source libraries!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/huggingface_mini.svg?sanitize=true" alt="huggingface" height="40"&gt;&lt;/a&gt; &lt;a href="https://www.python.org"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/python.svg?sanitize=true" alt="python" height="40"&gt;&lt;/a&gt; &lt;a href="https://fastapi.tiangolo.com"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/fastapi.svg?sanitize=true" alt="fastapi" height="40"&gt;&lt;/a&gt; &lt;a href="https://www.encode.io"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/encode.svg?sanitize=true" alt="encode" height="40"&gt;&lt;/a&gt; &lt;a href="https://svelte.dev"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/svelte.svg?sanitize=true" alt="svelte" height="40"&gt;&lt;/a&gt; &lt;a href="https://vitejs.dev"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/vite.svg?sanitize=true" alt="vite" height="40"&gt;&lt;/a&gt; &lt;a href="https://pnpm.io"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/pnpm.svg?sanitize=true" alt="pnpm" height="40"&gt;&lt;/a&gt; &lt;a href="https://tailwindcss.com"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/tailwind.svg?sanitize=true" alt="tailwind" height="40"&gt;&lt;/a&gt; &lt;a href="https://storybook.js.org/"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/storybook.svg?sanitize=true" alt="storybook" height="40"&gt;&lt;/a&gt; &lt;a href="https://www.chromatic.com/"&gt;&lt;img src="https://raw.githubusercontent.com/gradio-app/gradio/main/readme_files/chromatic.svg?sanitize=true" alt="chromatic" height="40"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Gradio is licensed under the Apache License 2.0 found in the &lt;a href="https://raw.githubusercontent.com/gradio-app/gradio/main/LICENSE"&gt;LICENSE&lt;/a&gt; file in the root directory of this repository.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Also check out the paper &lt;em&gt;&lt;a href="https://arxiv.org/abs/1906.02569"&gt;Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild&lt;/a&gt;, ICML HILL 2019&lt;/em&gt;, and please cite it if you use Gradio in your work.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@article{abid2019gradio,
  title = {Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild},
  author = {Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},
  journal = {arXiv preprint arXiv:1906.02569},
  year = {2019},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>paperless-ngx/paperless-ngx</title>
      <link>https://github.com/paperless-ngx/paperless-ngx</link>
      <description>&lt;p&gt;A community-supported supercharged document management system: scan, index and archive all your documents&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/paperless-ngx/paperless-ngx/actions"&gt;&lt;img src="https://github.com/paperless-ngx/paperless-ngx/workflows/ci/badge.svg?sanitize=true" alt="ci"&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/paperless-ngx"&gt;&lt;img src="https://badges.crowdin.net/paperless-ngx/localized.svg?sanitize=true" alt="Crowdin"&gt;&lt;/a&gt; &lt;a href="https://docs.paperless-ngx.com"&gt;&lt;img src="https://img.shields.io/github/deployments/paperless-ngx/paperless-ngx/github-pages?label=docs" alt="Documentation Status"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/paperless-ngx/paperless-ngx"&gt;&lt;img src="https://codecov.io/gh/paperless-ngx/paperless-ngx/branch/main/graph/badge.svg?token=VK6OUPJ3TY" alt="codecov"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23paperlessngx%3Amatrix.org"&gt;&lt;img src="https://matrix.to/img/matrix-badge.svg?sanitize=true" alt="Chat on Matrix"&gt;&lt;/a&gt; &lt;a href="https://demo.paperless-ngx.com"&gt;&lt;img src="https://cronitor.io/badges/ve7ItY/production/W5E_B9jkelG9ZbDiNHUPQEVH3MY.svg?sanitize=true" alt="demo"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/paperless-ngx/paperless-ngx/blob/main/resources/logo/web/png/White%20logo%20-%20no%20background.png" width="50%"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png" width="50%"&gt; 
  &lt;img src="https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png" width="50%"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;!-- omit in toc --&gt; 
&lt;h1&gt;Paperless-ngx&lt;/h1&gt; 
&lt;p&gt;Paperless-ngx is a document management system that transforms your physical documents into a searchable online archive so you can keep, well, &lt;em&gt;less paper&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;Paperless-ngx is the official successor to the original &lt;a href="https://github.com/the-paperless-project/paperless"&gt;Paperless&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/jonaswinkler/paperless-ng"&gt;Paperless-ng&lt;/a&gt; projects and is designed to distribute the responsibility of advancing and supporting the project among a team of people. &lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#community-support"&gt;Consider joining us!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Thanks to the generous folks at &lt;a href="https://m.do.co/c/8d70b916d462"&gt;DigitalOcean&lt;/a&gt;, a demo is available at &lt;a href="https://demo.paperless-ngx.com"&gt;demo.paperless-ngx.com&lt;/a&gt; using login &lt;code&gt;demo&lt;/code&gt; / &lt;code&gt;demo&lt;/code&gt;. &lt;em&gt;Note: demo content is reset frequently and confidential information should not be uploaded.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#getting-started"&gt;Getting started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#contributing"&gt;Contributing&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#community-support"&gt;Community Support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#translation"&gt;Translation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#feature-requests"&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#bugs"&gt;Bugs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#related-projects"&gt;Related Projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#important-note"&gt;Important Note&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;This project is supported by:&lt;br&gt; &lt;a href="https://m.do.co/c/8d70b916d462" style="padding-top: 4px; display: block;"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_white.svg" width="140px"&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg" width="140px"&gt; 
   &lt;img src="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_black_.svg?sanitize=true" width="140px"&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards-dark.png"&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png"&gt; 
&lt;/picture&gt; 
&lt;p&gt;A full list of &lt;a href="https://docs.paperless-ngx.com/#features"&gt;features&lt;/a&gt; and &lt;a href="https://docs.paperless-ngx.com/#screenshots"&gt;screenshots&lt;/a&gt; are available in the &lt;a href="https://docs.paperless-ngx.com/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Getting started&lt;/h1&gt; 
&lt;p&gt;The easiest way to deploy paperless is &lt;code&gt;docker compose&lt;/code&gt;. The files in the &lt;a href="https://github.com/paperless-ngx/paperless-ngx/tree/main/docker/compose"&gt;&lt;code&gt;/docker/compose&lt;/code&gt; directory&lt;/a&gt; are configured to pull the image from the GitHub container registry.&lt;/p&gt; 
&lt;p&gt;If you'd like to jump right in, you can configure a &lt;code&gt;docker compose&lt;/code&gt; environment with our install script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash -c "$(curl -L https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/install-paperless-ngx.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details and step-by-step guides for alternative installation methods can be found in &lt;a href="https://docs.paperless-ngx.com/setup/#installation"&gt;the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Migrating from Paperless-ng is easy, just drop in the new docker image! See the &lt;a href="https://docs.paperless-ngx.com/setup/#migrating-to-paperless-ngx"&gt;documentation on migrating&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;!-- omit in toc --&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;The documentation for Paperless-ngx is available at &lt;a href="https://docs.paperless-ngx.com/"&gt;https://docs.paperless-ngx.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;If you feel like contributing to the project, please do! Bug fixes, enhancements, visual fixes etc. are always welcome. If you want to implement something big: Please start a discussion about that! The &lt;a href="https://docs.paperless-ngx.com/development/"&gt;documentation&lt;/a&gt; has some basic information on how to get started.&lt;/p&gt; 
&lt;h2&gt;Community Support&lt;/h2&gt; 
&lt;p&gt;People interested in continuing the work on paperless-ngx are encouraged to reach out here on github and in the &lt;a href="https://matrix.to/#/%23paperless:matrix.org"&gt;Matrix Room&lt;/a&gt;. If you would like to contribute to the project on an ongoing basis there are multiple &lt;a href="https://github.com/orgs/paperless-ngx/people"&gt;teams&lt;/a&gt; (frontend, ci/cd, etc) that could use your help so please reach out!&lt;/p&gt; 
&lt;h2&gt;Translation&lt;/h2&gt; 
&lt;p&gt;Paperless-ngx is available in many languages that are coordinated on Crowdin. If you want to help out by translating paperless-ngx into your language, please head over to &lt;a href="https://crowdin.com/project/paperless-ngx"&gt;https://crowdin.com/project/paperless-ngx&lt;/a&gt;, and thank you! More details can be found in &lt;a href="https://github.com/paperless-ngx/paperless-ngx/raw/main/CONTRIBUTING.md#translating-paperless-ngx"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;Feature requests can be submitted via &lt;a href="https://github.com/paperless-ngx/paperless-ngx/discussions/categories/feature-requests"&gt;GitHub Discussions&lt;/a&gt;, you can search for existing ideas, add your own and vote for the ones you care about.&lt;/p&gt; 
&lt;h2&gt;Bugs&lt;/h2&gt; 
&lt;p&gt;For bugs please &lt;a href="https://github.com/paperless-ngx/paperless-ngx/issues"&gt;open an issue&lt;/a&gt; or &lt;a href="https://github.com/paperless-ngx/paperless-ngx/discussions"&gt;start a discussion&lt;/a&gt; if you have questions.&lt;/p&gt; 
&lt;h1&gt;Related Projects&lt;/h1&gt; 
&lt;p&gt;Please see &lt;a href="https://github.com/paperless-ngx/paperless-ngx/wiki/Related-Projects"&gt;the wiki&lt;/a&gt; for a user-maintained list of related projects and software that is compatible with Paperless-ngx.&lt;/p&gt; 
&lt;h1&gt;Important Note&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Document scanners are typically used to scan sensitive documents like your social insurance number, tax records, invoices, etc. &lt;strong&gt;Paperless-ngx should never be run on an untrusted host&lt;/strong&gt; because information is stored in clear text without encryption. No guarantees are made regarding security (but we do try!) and you use the app at your own risk. &lt;strong&gt;The safest way to run Paperless-ngx is on a local server in your own home with backups in place&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Huanshere/VideoLingo</title>
      <link>https://github.com/Huanshere/VideoLingo</link>
      <description>&lt;p&gt;Netflix-level subtitle cutting, translation, alignment, and even dubbing - one-click fully automated AI video subtitle team | NetflixÁ∫ßÂ≠óÂπïÂàáÂâ≤„ÄÅÁøªËØë„ÄÅÂØπÈΩê„ÄÅÁîöËá≥Âä†‰∏äÈÖçÈü≥Ôºå‰∏ÄÈîÆÂÖ®Ëá™Âä®ËßÜÈ¢ëÊê¨ËøêAIÂ≠óÂπïÁªÑ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/docs/logo.png" alt="VideoLingo Logo" height="140"&gt; 
 &lt;h1&gt;Connect the World, Frame by Frame&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12200" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12200" alt="Huanshere%2FVideoLingo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/README.md"&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.zh.md"&gt;&lt;strong&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.zh-TW.md"&gt;&lt;strong&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.ja.md"&gt;&lt;strong&gt;Êó•Êú¨Ë™û&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.es.md"&gt;&lt;strong&gt;Espa√±ol&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.ru.md"&gt;&lt;strong&gt;–†—É—Å—Å–∫–∏–π&lt;/strong&gt;&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/translations/README.fr.md"&gt;&lt;strong&gt;Fran√ßais&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü Overview (&lt;a href="https://videolingo.io"&gt;Try VL Now!&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;VideoLingo is an all-in-one video translation, localization, and dubbing tool aimed at generating Netflix-quality subtitles. It eliminates stiff machine translations and multi-line subtitles while adding high-quality dubbing, enabling global knowledge sharing across language barriers.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üé• YouTube video download via yt-dlp&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéôÔ∏è Word-level and Low-illusion subtitle recognition with WhisperX&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù NLP and AI-powered subtitle segmentation&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìö Custom + AI-generated terminology for coherent translation&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîÑ 3-step Translate-Reflect-Adaptation for cinematic quality&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚úÖ Netflix-standard, Single-line subtitles Only&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üó£Ô∏è Dubbing with GPT-SoVITS, Azure, OpenAI, and more&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üöÄ One-click startup and processing in Streamlit&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üåç Multi-language support in Streamlit UI&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìù Detailed logging with progress resumption&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Difference from similar projects: &lt;strong&gt;Single-line subtitles only, superior translation quality, seamless dubbing experience&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üé• Demo&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%"&gt; &lt;h3&gt;Dual Subtitles&lt;/h3&gt; 
    &lt;hr&gt; &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/a5c3d8d1-2b29-4ba9-b0d0-25896829d951"&gt;https://github.com/user-attachments/assets/a5c3d8d1-2b29-4ba9-b0d0-25896829d951&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;h3&gt;Cosy2 Voice Clone&lt;/h3&gt; 
    &lt;hr&gt; &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/e065fe4c-3694-477f-b4d6-316917df7c0a"&gt;https://github.com/user-attachments/assets/e065fe4c-3694-477f-b4d6-316917df7c0a&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;h3&gt;GPT-SoVITS with my voice&lt;/h3&gt; 
    &lt;hr&gt; &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/47d965b2-b4ab-4a0b-9d08-b49a7bf3508c"&gt;https://github.com/user-attachments/assets/47d965b2-b4ab-4a0b-9d08-b49a7bf3508c&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Language Support&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Input Language Support(more to come):&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;üá∫üá∏ English ü§© | üá∑üá∫ Russian üòä | üá´üá∑ French ü§© | üá©üá™ German ü§© | üáÆüáπ Italian ü§© | üá™üá∏ Spanish ü§© | üáØüáµ Japanese üòê | üá®üá≥ Chinese* üòä&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;*Chinese uses a separate punctuation-enhanced whisper model, for now...&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Translation supports all languages, while dubbing language depends on the chosen TTS method.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Meet any problem? Chat with our free online AI agent &lt;a href="https://share.fastgpt.in/chat/share?shareId=066w11n3r9aq6879r4z0v9rh"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; to help you.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For Windows users with NVIDIA GPU, follow these steps before installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda_12.6.0_560.76_windows.exe"&gt;CUDA Toolkit 12.6&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/cudnn_9.3.0_windows.exe"&gt;CUDNN 9.3.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Add &lt;code&gt;C:\Program Files\NVIDIA\CUDNN\v9.3\bin\12.6&lt;/code&gt; to your system PATH&lt;/li&gt; 
  &lt;li&gt;Restart your computer&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; FFmpeg is required. Please install it via package managers:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Windows: &lt;code&gt;choco install ffmpeg&lt;/code&gt; (via &lt;a href="https://chocolatey.org/"&gt;Chocolatey&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;macOS: &lt;code&gt;brew install ffmpeg&lt;/code&gt; (via &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;Linux: &lt;code&gt;sudo apt install ffmpeg&lt;/code&gt; (Debian/Ubuntu)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Huanshere/VideoLingo.git
cd VideoLingo
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies(requires &lt;code&gt;python=3.10&lt;/code&gt;)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n videolingo python=3.10.0 -y
conda activate videolingo
python install.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Start the application&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;streamlit run st.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Alternatively, you can use Docker (requires CUDA 12.4 and NVIDIA Driver version &amp;gt;550), see &lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/docs/pages/docs/docker.en-US.md"&gt;Docker docs&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t videolingo .
docker run -d -p 8501:8501 --gpus all videolingo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;APIs&lt;/h2&gt; 
&lt;p&gt;VideoLingo supports OpenAI-Like API format and various TTS interfaces:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLM: &lt;code&gt;claude-3-5-sonnet&lt;/code&gt;, &lt;code&gt;gpt-4.1&lt;/code&gt;, &lt;code&gt;deepseek-v3&lt;/code&gt;, &lt;code&gt;gemini-2.0-flash&lt;/code&gt;, ... (sorted by performance, be cautious with gemini-2.5-flash...)&lt;/li&gt; 
 &lt;li&gt;WhisperX: Run whisperX (large-v3) locally or use 302.ai API&lt;/li&gt; 
 &lt;li&gt;TTS: &lt;code&gt;azure-tts&lt;/code&gt;, &lt;code&gt;openai-tts&lt;/code&gt;, &lt;code&gt;siliconflow-fishtts&lt;/code&gt;, &lt;strong&gt;&lt;code&gt;fish-tts&lt;/code&gt;&lt;/strong&gt;, &lt;code&gt;GPT-SoVITS&lt;/code&gt;, &lt;code&gt;edge-tts&lt;/code&gt;, &lt;code&gt;*custom-tts&lt;/code&gt;(You can modify your own TTS in custom_tts.py!)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; VideoLingo works with &lt;strong&gt;&lt;a href="https://gpt302.saaslink.net/C2oHR9"&gt;302.ai&lt;/a&gt;&lt;/strong&gt; - one API key for all services (LLM, WhisperX, TTS). Or run locally with Ollama and Edge-TTS for free, no API needed!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For detailed installation, API configuration, and batch mode instructions, please refer to the documentation: &lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/docs/pages/docs/start.en-US.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Huanshere/VideoLingo/main/docs/pages/docs/start.zh-CN.md"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Current Limitations&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;WhisperX transcription performance may be affected by video background noise, as it uses wav2vac model for alignment. For videos with loud background music, please enable Voice Separation Enhancement. Additionally, subtitles ending with numbers or special characters may be truncated early due to wav2vac's inability to map numeric characters (e.g., "1") to their spoken form ("one").&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Using weaker models can lead to errors during processes due to strict JSON format requirements for responses (tried my best to prompt llmüòä). If this error occurs, please delete the &lt;code&gt;output&lt;/code&gt; folder and retry with a different LLM, otherwise repeated execution will read the previous erroneous response causing the same error.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The dubbing feature may not be 100% perfect due to differences in speech rates and intonation between languages, as well as the impact of the translation step. However, this project has implemented extensive engineering processing for speech rates to ensure the best possible dubbing results.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multilingual video transcription recognition will only retain the main language&lt;/strong&gt;. This is because whisperX uses a specialized model for a single language when forcibly aligning word-level subtitles, and will delete unrecognized languages.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;For now, cannot dub multiple characters separately&lt;/strong&gt;, as whisperX's speaker distinction capability is not sufficiently reliable.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License. Special thanks to the following open source projects for their contributions:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/m-bain/whisperX"&gt;whisperX&lt;/a&gt;, &lt;a href="https://github.com/yt-dlp/yt-dlp"&gt;yt-dlp&lt;/a&gt;, &lt;a href="https://github.com/mangiucugna/json_repair"&gt;json_repair&lt;/a&gt;, &lt;a href="https://github.com/LianjiaTech/BELLE"&gt;BELLE&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì¨ Contact Me&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Submit &lt;a href="https://github.com/Huanshere/VideoLingo/issues"&gt;Issues&lt;/a&gt; or &lt;a href="https://github.com/Huanshere/VideoLingo/pulls"&gt;Pull Requests&lt;/a&gt; on GitHub&lt;/li&gt; 
 &lt;li&gt;DM me on Twitter: &lt;a href="https://twitter.com/Huanshere"&gt;@Huanshere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Email me at: &lt;a href="mailto:team@videolingo.io"&gt;team@videolingo.io&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Huanshere/VideoLingo&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=Huanshere/VideoLingo&amp;amp;type=Timeline" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p align="center"&gt;If you find VideoLingo helpful, please give me a ‚≠êÔ∏è!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>comet-ml/opik</title>
      <link>https://github.com/comet-ml/opik</link>
      <description>&lt;p&gt;Debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt;
 &lt;b&gt;&lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/readme_CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/readme_JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/readme_KO.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/b&gt;
&lt;/div&gt; 
&lt;h1 align="center" style="border-bottom: none"&gt; 
 &lt;div&gt; 
  &lt;a href="https://www.comet.com/site/products/opik/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=header_img&amp;amp;utm_campaign=opik"&gt;
   &lt;picture&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/comet-ml/opik/refs/heads/main/apps/opik-documentation/documentation/static/img/logo-dark-mode.svg"&gt; 
    &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/comet-ml/opik/refs/heads/main/apps/opik-documentation/documentation/static/img/opik-logo.svg"&gt; 
    &lt;img alt="Comet Opik logo" src="https://raw.githubusercontent.com/comet-ml/opik/refs/heads/main/apps/opik-documentation/documentation/static/img/opik-logo.svg?sanitize=true" width="200"&gt; 
   &lt;/picture&gt;&lt;/a&gt; 
  &lt;br&gt; Opik 
 &lt;/div&gt; &lt;/h1&gt; 
&lt;h2 align="center" style="border-bottom: none"&gt;Open-source LLM evaluation platform&lt;/h2&gt; 
&lt;p align="center"&gt; Opik helps you build, evaluate, and optimize LLM systems that run better, faster, and cheaper. From RAG chatbots to code assistants to complex agentic pipelines, Opik provides comprehensive tracing, evaluations, dashboards, and powerful features like &lt;b&gt;Opik Agent Optimizer&lt;/b&gt; and &lt;b&gt;Opik Guardrails&lt;/b&gt; to improve and secure your LLM powered applications in production. &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/opik/"&gt;&lt;img src="https://img.shields.io/pypi/v/opik" alt="Python SDK"&gt;&lt;/a&gt; &lt;a href="https://github.com/comet-ml/opik/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/comet-ml/opik" alt="License"&gt;&lt;/a&gt; &lt;a href="https://github.com/comet-ml/opik/actions/workflows/build_apps.yml"&gt;&lt;img src="https://github.com/comet-ml/opik/actions/workflows/build_apps.yml/badge.svg?sanitize=true" alt="Build"&gt;&lt;/a&gt; &lt;a href="https://algora.io/comet-ml/bounties?status=open"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Falgora.io%2Fapi%2Fshields%2Fcomet-ml%2Fbounties%3Fstatus%3Dopen" alt="Bounties"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- [![Quick Start](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/opik_quickstart.ipynb) --&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.comet.com/site/products/opik/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=website_button&amp;amp;utm_campaign=opik"&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://chat.comet.com"&gt;&lt;b&gt;Slack Community&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://x.com/Cometml"&gt;&lt;b&gt;Twitter&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.comet.com/docs/opik/changelog"&gt;&lt;b&gt;Changelog&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.comet.com/docs/opik/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=docs_button&amp;amp;utm_campaign=opik"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center" style="margin-top: 1em; margin-bottom: 1em;"&gt; 
 &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/#-what-is-opik"&gt;üöÄ What is Opik?&lt;/a&gt; ‚Ä¢ 
 &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/#%EF%B8%8F-opik-server-installation"&gt;üõ†Ô∏è Opik Server Installation&lt;/a&gt; ‚Ä¢ 
 &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/#-opik-client-sdk"&gt;üíª Opik Client SDK&lt;/a&gt; ‚Ä¢ 
 &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/#-logging-traces-with-integrations"&gt;üìù Logging Traces&lt;/a&gt;
 &lt;br&gt; 
 &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/#-llm-as-a-judge-metrics"&gt;üßë‚Äç‚öñÔ∏è LLM as a Judge&lt;/a&gt; ‚Ä¢ 
 &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/#-evaluating-your-llm-application"&gt;üîç Evaluating your Application&lt;/a&gt; ‚Ä¢ 
 &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/#-star-us-on-github"&gt;‚≠ê Star Us&lt;/a&gt; ‚Ä¢ 
 &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/#-contributing"&gt;ü§ù Contributing&lt;/a&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://www.comet.com/signup?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=readme_banner&amp;amp;utm_campaign=opik"&gt;&lt;img src="https://raw.githubusercontent.com/comet-ml/opik/main/readme-thumbnail-new.png" alt="Opik platform screenshot (thumbnail)"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ What is Opik?&lt;/h2&gt; 
&lt;p&gt;Opik (built by &lt;a href="https://www.comet.com?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=what_is_opik_link&amp;amp;utm_campaign=opik"&gt;Comet&lt;/a&gt;) is an open-source platform designed to streamline the entire lifecycle of LLM applications. It empowers developers to evaluate, test, monitor, and optimize their models and agentic systems. Key offerings include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Observability&lt;/strong&gt;: Deep tracing of LLM calls, conversation logging, and agent activity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Evaluation&lt;/strong&gt;: Robust prompt evaluation, LLM-as-a-judge, and experiment management.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production-Ready&lt;/strong&gt;: Scalable monitoring dashboards and online evaluation rules for production.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Opik Agent Optimizer&lt;/strong&gt;: Dedicated SDK and set of optimizers to enhance prompts and agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Opik Guardrails&lt;/strong&gt;: Features to help you implement safe and responsible AI practices.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;p&gt;Key capabilities include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Development &amp;amp; Tracing:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Track all LLM calls and traces with detailed context during development and in production (&lt;a href="https://www.comet.com/docs/opik/quickstart/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=quickstart_link&amp;amp;utm_campaign=opik"&gt;Quickstart&lt;/a&gt;).&lt;/li&gt; 
   &lt;li&gt;Extensive 3rd-party integrations for easy observability: Seamlessly integrate with a growing list of frameworks, supporting many of the largest and most popular ones natively (including recent additions like &lt;strong&gt;Google ADK&lt;/strong&gt;, &lt;strong&gt;Autogen&lt;/strong&gt;, and &lt;strong&gt;Flowise AI&lt;/strong&gt;). (&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/overview/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=integrations_link&amp;amp;utm_campaign=opik"&gt;Integrations&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;Annotate traces and spans with feedback scores via the &lt;a href="https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-and-spans-using-the-sdk?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=sdk_link&amp;amp;utm_campaign=opik"&gt;Python SDK&lt;/a&gt; or the &lt;a href="https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-through-the-ui?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=ui_link&amp;amp;utm_campaign=opik"&gt;UI&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Experiment with prompts and models in the &lt;a href="https://www.comet.com/docs/opik/prompt_engineering/playground"&gt;Prompt Playground&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Evaluation &amp;amp; Testing&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Automate your LLM application evaluation with &lt;a href="https://www.comet.com/docs/opik/evaluation/manage_datasets/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=datasets_link&amp;amp;utm_campaign=opik"&gt;Datasets&lt;/a&gt; and &lt;a href="https://www.comet.com/docs/opik/evaluation/evaluate_your_llm/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=eval_link&amp;amp;utm_campaign=opik"&gt;Experiments&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Leverage powerful LLM-as-a-judge metrics for complex tasks like &lt;a href="https://www.comet.com/docs/opik/evaluation/metrics/hallucination/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=hallucination_link&amp;amp;utm_campaign=opik"&gt;hallucination detection&lt;/a&gt;, &lt;a href="https://www.comet.com/docs/opik/evaluation/metrics/moderation/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=moderation_link&amp;amp;utm_campaign=opik"&gt;moderation&lt;/a&gt;, and RAG assessment (&lt;a href="https://www.comet.com/docs/opik/evaluation/metrics/answer_relevance/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=alex_link&amp;amp;utm_campaign=opik"&gt;Answer Relevance&lt;/a&gt;, &lt;a href="https://www.comet.com/docs/opik/evaluation/metrics/context_precision/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=context_link&amp;amp;utm_campaign=opik"&gt;Context Precision&lt;/a&gt;).&lt;/li&gt; 
   &lt;li&gt;Integrate evaluations into your CI/CD pipeline with our &lt;a href="https://www.comet.com/docs/opik/testing/pytest_integration/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=pytest_link&amp;amp;utm_campaign=opik"&gt;PyTest integration&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Production Monitoring &amp;amp; Optimization&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Log high volumes of production traces: Opik is designed for scale (40M+ traces/day).&lt;/li&gt; 
   &lt;li&gt;Monitor feedback scores, trace counts, and token usage over time in the &lt;a href="https://www.comet.com/docs/opik/production/production_monitoring/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=dashboard_link&amp;amp;utm_campaign=opik"&gt;Opik Dashboard&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Utilize &lt;a href="https://www.comet.com/docs/opik/production/rules/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=dashboard_link&amp;amp;utm_campaign=opik"&gt;Online Evaluation Rules&lt;/a&gt; with LLM-as-a-Judge metrics to identify production issues.&lt;/li&gt; 
   &lt;li&gt;Leverage &lt;strong&gt;Opik Agent Optimizer&lt;/strong&gt; and &lt;strong&gt;Opik Guardrails&lt;/strong&gt; to continuously improve and secure your LLM applications in production.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you are looking for features that Opik doesn't have today, please raise a new &lt;a href="https://github.com/comet-ml/opik/issues/new/choose"&gt;Feature request&lt;/a&gt; üöÄ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br&gt; 
&lt;h2&gt;üõ†Ô∏è Opik Server Installation&lt;/h2&gt; 
&lt;p&gt;Get your Opik server running in minutes. Choose the option that best suits your needs:&lt;/p&gt; 
&lt;h3&gt;Option 1: Comet.com Cloud (Easiest &amp;amp; Recommended)&lt;/h3&gt; 
&lt;p&gt;Access Opik instantly without any setup. Ideal for quick starts and hassle-free maintenance.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://www.comet.com/signup?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=install_create_link&amp;amp;utm_campaign=opik"&gt;Create your free Comet account&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Option 2: Self-Host Opik for Full Control&lt;/h3&gt; 
&lt;p&gt;Deploy Opik in your own environment. Choose between Docker for local setups or Kubernetes for scalability.&lt;/p&gt; 
&lt;h4&gt;Self-Hosting with Docker Compose (for Local Development &amp;amp; Testing)&lt;/h4&gt; 
&lt;p&gt;This is the simplest way to get a local Opik instance running. Note the new &lt;code&gt;.opik.sh&lt;/code&gt; installation script:&lt;/p&gt; 
&lt;p&gt;On Linux or Mac Enviroment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the Opik repository
git clone https://github.com/comet-ml/opik.git

# Navigate to the repository
cd opik

# Start the Opik platform
./opik.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Windows Enviroment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# Clone the Opik repository
git clone https://github.com/comet-ml/opik.git

# Navigate to the repository
cd opik

# Start the Opik platform
powershell -ExecutionPolicy ByPass -c ".\\opik.ps1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use the &lt;code&gt;--help&lt;/code&gt; or &lt;code&gt;--info&lt;/code&gt; options to troubleshoot issues. Dockerfiles now ensure containers run as non-root users for enhanced security. Once all is up and running, you can now visit &lt;a href="http://localhost:5173"&gt;localhost:5173&lt;/a&gt; on your browser! For detailed instructions, see the &lt;a href="https://www.comet.com/docs/opik/self-host/local_deployment?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=self_host_link&amp;amp;utm_campaign=opik"&gt;Local Deployment Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Self-Hosting with Kubernetes &amp;amp; Helm (for Scalable Deployments)&lt;/h4&gt; 
&lt;p&gt;For production or larger-scale self-hosted deployments, Opik can be installed on a Kubernetes cluster using our Helm chart. Click the badge for the full &lt;a href="https://www.comet.com/docs/opik/self-host/kubernetes/#kubernetes-installation?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=kubernetes_link&amp;amp;utm_campaign=opik"&gt;Kubernetes Installation Guide using Helm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.comet.com/docs/opik/self-host/kubernetes/#kubernetes-installation?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=kubernetes_link&amp;amp;utm_campaign=opik"&gt;&lt;img src="https://img.shields.io/badge/Kubernetes-%23326ce5.svg?&amp;amp;logo=kubernetes&amp;amp;logoColor=white" alt="Kubernetes"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;Version 1.7.0 Changes&lt;/strong&gt;: Please check the &lt;a href="https://github.com/comet-ml/opik/raw/main/CHANGELOG.md"&gt;changelog&lt;/a&gt; for important updates and breaking changes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üíª Opik Client SDK&lt;/h2&gt; 
&lt;p&gt;Opik provides a suite of client libraries and a REST API to interact with the Opik server. This includes SDKs for Python, TypeScript, and Ruby (via OpenTelemetry), allowing for seamless integration into your workflows. For detailed API and SDK references, see the &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/docs/reference/overview.mdx"&gt;Opik Client Reference Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Python SDK Quick Start&lt;/h3&gt; 
&lt;p&gt;To get started with the Python SDK:&lt;/p&gt; 
&lt;p&gt;Install the package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# install using pip
pip install opik

# or install with uv
uv pip install opik
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Configure the python SDK by running the &lt;code&gt;opik configure&lt;/code&gt; command, which will prompt you for your Opik server address (for self-hosted instances) or your API key and workspace (for Comet.com):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;opik configure
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] You can also call &lt;code&gt;opik.configure(use_local=True)&lt;/code&gt; from your Python code to configure the SDK to run on a local self-hosted installation, or provide API key and workspace details directly for Comet.com. Refer to the &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/docs/reference/python-sdk/"&gt;Python SDK documentation&lt;/a&gt; for more configuration options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You are now ready to start logging traces using the &lt;a href="https://www.comet.com/docs/opik/python-sdk-reference/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=sdk_link2&amp;amp;utm_campaign=opik"&gt;Python SDK&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;üìù Logging Traces with Integrations&lt;/h3&gt; 
&lt;p&gt;The easiest way to log traces is to use one of our direct integrations. Opik supports a wide array of frameworks, including recent additions like &lt;strong&gt;Google ADK&lt;/strong&gt;, &lt;strong&gt;Autogen&lt;/strong&gt;, and &lt;strong&gt;Flowise AI&lt;/strong&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Integration&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Documentation&lt;/th&gt; 
   &lt;th&gt;Try in Colab&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AG2&lt;/td&gt; 
   &lt;td&gt;Log traces for AG2 LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/ag2?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=anthropic_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;aisuite&lt;/td&gt; 
   &lt;td&gt;Log traces for aisuite LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/aisuite?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=anthropic_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/aisuite.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;Log traces for Anthropic LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/anthropic?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=anthropic_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/anthropic.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Autogen&lt;/td&gt; 
   &lt;td&gt;Log traces for Autogen agentic workflows&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/autogen?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=autogen_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Bedrock&lt;/td&gt; 
   &lt;td&gt;Log traces for Amazon Bedrock LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/bedrock?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=bedrock_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/bedrock.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CrewAI&lt;/td&gt; 
   &lt;td&gt;Log traces for CrewAI calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/crewai?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=crewai_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/crewai.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek&lt;/td&gt; 
   &lt;td&gt;Log traces for DeepSeek LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/deepseek?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=deepseek_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dify&lt;/td&gt; 
   &lt;td&gt;Log traces for Dify agent runs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/dify?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=dspy_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DSPy&lt;/td&gt; 
   &lt;td&gt;Log traces for DSPy runs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/dspy?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=dspy_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/dspy.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Flowise AI&lt;/td&gt; 
   &lt;td&gt;Log traces for Flowise AI visual LLM builder&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/flowise?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=flowise_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Native UI intergration, see documentation&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemini&lt;/td&gt; 
   &lt;td&gt;Log traces for Google Gemini LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/gemini?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=gemini_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/gemini.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google ADK&lt;/td&gt; 
   &lt;td&gt;Log traces for Google Agent Development Kit (ADK)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/google_adk?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=google_adk_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Groq&lt;/td&gt; 
   &lt;td&gt;Log traces for Groq LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/groq?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=groq_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/groq.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Guardrails&lt;/td&gt; 
   &lt;td&gt;Log traces for Guardrails AI validations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/guardrails/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=guardrails_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/guardrails-ai.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Haystack&lt;/td&gt; 
   &lt;td&gt;Log traces for Haystack calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/haystack/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=haystack_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/haystack.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Instructor&lt;/td&gt; 
   &lt;td&gt;Log traces for LLM calls made with Instructor&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/instructor/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=instructor_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/instructor.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LangChain&lt;/td&gt; 
   &lt;td&gt;Log traces for LangChain LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/langchain/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=langchain_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/langchain.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LangChain JS&lt;/td&gt; 
   &lt;td&gt;Log traces for LangChain JS LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/langchainjs/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=langchain_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Log traces for LangGraph executions&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/langgraph/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=langchain_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/langgraph.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LiteLLM&lt;/td&gt; 
   &lt;td&gt;Log traces for LiteLLM model calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/litellm/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=openai_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/litellm.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LlamaIndex&lt;/td&gt; 
   &lt;td&gt;Log traces for LlamaIndex LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/llama_index?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=llama_index_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/llama-index.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;Log traces for Ollama LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/ollama?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=ollama_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/ollama.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;Log traces for OpenAI LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/openai/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=openai_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/openai.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI Agents&lt;/td&gt; 
   &lt;td&gt;Log traces for OpenAI Agents SDK calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/openai_agents/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=openai_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/openai-agents.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;Log traces for OpenRouter LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/openrouter/overview//?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=openai_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenTelemetry&lt;/td&gt; 
   &lt;td&gt;Log traces for OpenTelemetry supported calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/opentelemetry/overview//?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=openai_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Predibase&lt;/td&gt; 
   &lt;td&gt;Log traces for Predibase LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/predibase?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=predibase_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/predibase.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pydantic AI&lt;/td&gt; 
   &lt;td&gt;Log traces for PydanticAI agent calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/pydantic-ai?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=predibase_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/pydantic-ai.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ragas&lt;/td&gt; 
   &lt;td&gt;Log traces for Ragas evaluations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/ragas?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=pydantic_ai_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/ragas.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Smolagents&lt;/td&gt; 
   &lt;td&gt;Log traces for Smolagents agents&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/smolagents?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=smolagents_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/smolagents.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Strands Agents&lt;/td&gt; 
   &lt;td&gt;Log traces for Strands agents calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/strands-agents/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=langchain_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vercel AI&lt;/td&gt; 
   &lt;td&gt;Log traces for Vercel AI SDK calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/vercel-ai-sdk/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=langchain_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;(&lt;em&gt;Coming Soon&lt;/em&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;watsonx&lt;/td&gt; 
   &lt;td&gt;Log traces for IBM watsonx LLM calls&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/docs/opik/tracing/integrations/watsonx?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=watsonx_link&amp;amp;utm_campaign=opik"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/watsonx.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Quickstart In Colab"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If the framework you are using is not listed above, feel free to &lt;a href="https://github.com/comet-ml/opik/issues"&gt;open an issue&lt;/a&gt; or submit a PR with the integration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you are not using any of the frameworks above, you can also use the &lt;code&gt;track&lt;/code&gt; function decorator to &lt;a href="https://www.comet.com/docs/opik/tracing/log_traces/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=traces_link&amp;amp;utm_campaign=opik"&gt;log traces&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import opik

opik.configure(use_local=True) # Run locally

@opik.track
def my_llm_function(user_question: str) -&amp;gt; str:
    # Your LLM code here

    return "Hello"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The track decorator can be used in conjunction with any of our integrations and can also be used to track nested function calls.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üßë‚Äç‚öñÔ∏è LLM as a Judge metrics&lt;/h3&gt; 
&lt;p&gt;The Python Opik SDK includes a number of LLM as a judge metrics to help you evaluate your LLM application. Learn more about it in the &lt;a href="https://www.comet.com/docs/opik/evaluation/metrics/overview/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=metrics_2_link&amp;amp;utm_campaign=opik"&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use them, simply import the relevant metric and use the &lt;code&gt;score&lt;/code&gt; function:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from opik.evaluation.metrics import Hallucination

metric = Hallucination()
score = metric.score(
    input="What is the capital of France?",
    output="Paris",
    context=["France is a country in Europe."]
)
print(score)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Opik also includes a number of pre-built heuristic metrics as well as the ability to create your own. Learn more about it in the &lt;a href="https://www.comet.com/docs/opik/evaluation/metrics/overview?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=metrics_3_link&amp;amp;utm_campaign=opik"&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;üîç Evaluating your LLM Application&lt;/h3&gt; 
&lt;p&gt;Opik allows you to evaluate your LLM application during development through &lt;a href="https://www.comet.com/docs/opik/evaluation/manage_datasets/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=datasets_2_link&amp;amp;utm_campaign=opik"&gt;Datasets&lt;/a&gt; and &lt;a href="https://www.comet.com/docs/opik/evaluation/evaluate_your_llm/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=experiments_link&amp;amp;utm_campaign=opik"&gt;Experiments&lt;/a&gt;. The Opik Dashboard offers enhanced charts for experiments and better handling of large traces. You can also run evaluations as part of your CI/CD pipeline using our &lt;a href="https://www.comet.com/docs/opik/testing/pytest_integration/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=pytest_2_link&amp;amp;utm_campaign=opik"&gt;PyTest integration&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚≠ê Star Us on GitHub&lt;/h2&gt; 
&lt;p&gt;If you find Opik useful, please consider giving us a star! Your support helps us grow our community and continue improving the product.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/comet-ml/opik"&gt;&lt;img src="https://api.star-history.com/svg?repos=comet-ml/opik&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;There are many ways to contribute to Opik:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Submit &lt;a href="https://github.com/comet-ml/opik/issues"&gt;bug reports&lt;/a&gt; and &lt;a href="https://github.com/comet-ml/opik/issues"&gt;feature requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Review the documentation and submit &lt;a href="https://github.com/comet-ml/opik/pulls"&gt;Pull Requests&lt;/a&gt; to improve it&lt;/li&gt; 
 &lt;li&gt;Speaking or writing about Opik and &lt;a href="https://chat.comet.com"&gt;letting us know&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Upvoting &lt;a href="https://github.com/comet-ml/opik/issues?q=is%3Aissue+is%3Aopen+label%3A%22enhancement%22"&gt;popular feature requests&lt;/a&gt; to show your support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To learn more about how to contribute to Opik, please see our &lt;a href="https://raw.githubusercontent.com/comet-ml/opik/main/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Shubhamsaboo/awesome-llm-apps</title>
      <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
      <description>&lt;p&gt;Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="http://www.theunwindai.com"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/unwind_black.png" width="900px" alt="Unwind AI"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/in/shubhamsaboo/"&gt; &lt;img src="https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;amp;style=flat-square" alt="LinkedIn"&gt; &lt;/a&gt; &lt;a href="https://twitter.com/Saboo_Shubham_"&gt; &lt;img src="https://img.shields.io/twitter/follow/Shubham_Saboo" alt="Twitter"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;h1&gt;üåü Awesome LLM Apps&lt;/h1&gt; 
&lt;p&gt;A curated collection of &lt;strong&gt;Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.&lt;/strong&gt; This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/9876" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/9876" alt="Shubhamsaboo%2Fawesome-llm-apps | Trendshift" style="width: 250px; height: 55px;"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;ü§î Why Awesome LLM Apps?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí° Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.&lt;/li&gt; 
 &lt;li&gt;üî• Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp;amp; RAG.&lt;/li&gt; 
 &lt;li&gt;üéì Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÇ Featured AI Projects&lt;/h2&gt; 
&lt;h3&gt;AI Agents&lt;/h3&gt; 
&lt;h3&gt;üå± Starter AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_blog_to_podcast_agent/"&gt;üéôÔ∏è AI Blog to Podcast Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_breakup_recovery_agent/"&gt;‚ù§Ô∏è‚Äçü©π AI Breakup Recovery Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_data_analysis_agent/"&gt;üìä AI Data Analysis Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_medical_imaging_agent/"&gt;ü©ª AI Medical Imaging Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_meme_generator_agent_browseruse/"&gt;üòÇ AI Meme Generator Agent (Browser)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_music_generator_agent/"&gt;üéµ AI Music Generator Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_travel_agent/"&gt;üõ´ AI Travel Agent (Local &amp;amp; Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/gemini_multimodal_agent_demo/"&gt;‚ú® Gemini Multimodal Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/local_news_agent_openai_swarm/"&gt;üåê Local News Agent (OpenAI Swarm)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/mixture_of_agents/"&gt;üîÑ Mixture of Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/xai_finance_agent/"&gt;üìä xAI Finance Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/opeani_research_agent/"&gt;üîç OpenAI Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/web_scrapping_ai_agent/"&gt;üï∏Ô∏è Web Scrapping AI Agent (Local &amp;amp; Cloud)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üöÄ Advanced AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_deep_research_agent/"&gt;üîç AI Deep Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_consultant_agent"&gt;ü§ù AI Consultant Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_system_architect_r1/"&gt;üèóÔ∏è AI System Architect Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/"&gt;üéØ AI Lead Generation Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/"&gt;üí∞ AI Financial Coach Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_movie_production_agent/"&gt;üé¨ AI Movie Production Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_investment_agent/"&gt;üìà AI Investment Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/"&gt;üèãÔ∏è‚Äç‚ôÇÔ∏è AI Health &amp;amp; Fitness Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent"&gt;üöÄ AI Product Launch Intelligence Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_journalist_agent/"&gt;üóûÔ∏è AI Journalist Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/"&gt;üß† AI Mental Wellbeing Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_meeting_agent/"&gt;üìë AI Meeting Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/"&gt;üß¨ AI Self-Evolving Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/"&gt;üéß AI Social Media News and Podcast Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéÆ Autonomous Game Playing Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/"&gt;üéÆ AI 3D Pygame Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/"&gt;‚ôú AI Chess Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/"&gt;üé≤ AI Tic-Tac-Toe Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ü§ù Multi-agent Teams&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/"&gt;üß≤ AI Competitor Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/"&gt;üí≤ AI Finance Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/"&gt;üé® AI Game Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/"&gt;üë®‚Äç‚öñÔ∏è AI Legal Agent Team (Cloud &amp;amp; Local)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/"&gt;üíº AI Recruitment Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/"&gt;üë®‚Äçüíº AI Services Agency (CrewAI)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/"&gt;üë®‚Äçüè´ AI Teaching Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/"&gt;üíª Multimodal Coding Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/"&gt;‚ú® Multimodal Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/"&gt;üåè AI Travel Planner Agent Team&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üó£Ô∏è Voice AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/ai_audio_tour_agent/"&gt;üó£Ô∏è AI Audio Tour Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/customer_support_voice_agent/"&gt;üìû Customer Support Voice Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/voice_rag_openaisdk/"&gt;üîä Voice RAG Agent (OpenAI SDK)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üåê MCP AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/browser_mcp_agent/"&gt;‚ôæÔ∏è Browser MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/github_mcp_agent/"&gt;üêô GitHub MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/notion_mcp_agent"&gt;üìë Notion MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/ai_travel_planner_mcp_agent_team"&gt;üåç AI Travel Planner MCP Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìÄ RAG (Retrieval Augmented Generation)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag/"&gt;üîó Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag_with_reasoning/"&gt;üßê Agentic RAG with Reasoning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/ai_blog_search/"&gt;üì∞ AI Blog Search (RAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/autonomous_rag/"&gt;üîç Autonomous RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/corrective_rag/"&gt;üîÑ Corrective RAG (CRAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/deepseek_local_rag_agent/"&gt;üêã Deepseek Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/gemini_agentic_rag/"&gt;ü§î Gemini Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/hybrid_search_rag/"&gt;üëÄ Hybrid Search RAG (Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/llama3.1_local_rag/"&gt;üîÑ Llama 3.1 Local RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_hybrid_search_rag/"&gt;üñ•Ô∏è Local Hybrid Search RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_rag_agent/"&gt;ü¶ô Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag-as-a-service/"&gt;üß© RAG-as-a-Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_agent_cohere/"&gt;‚ú® RAG Agent with Cohere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_chain/"&gt;‚õìÔ∏è Basic RAG Chain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_database_routing/"&gt;üì† RAG with Database Routing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/vision_rag/"&gt;üñºÔ∏è Vision RAG&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üíæ LLM Apps with Memory Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/"&gt;üíæ AI ArXiv Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/"&gt;üõ©Ô∏è AI Travel Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/"&gt;üí¨ Llama3 Stateful Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/"&gt;üìù LLM App with Personalized Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/"&gt;üóÑÔ∏è Local ChatGPT Clone with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/"&gt;üß† Multi-LLM Application with Shared Memory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üí¨ Chat with X Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_github/"&gt;üí¨ Chat with GitHub (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/"&gt;üì® Chat with Gmail&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/"&gt;üìÑ Chat with PDF (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/"&gt;üìö Chat with Research Papers (ArXiv) (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/"&gt;üìù Chat with Substack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/"&gt;üìΩÔ∏è Chat with YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîß LLM Fine-tuning Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/"&gt;üîß Llama 3.2 Fine-tuning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Navigate to the desired project directory&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the required dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Follow the project-specific instructions&lt;/strong&gt; in each project's &lt;code&gt;README.md&lt;/code&gt; file to set up and run the app.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ü§ù Contributing to Open Source&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new &lt;a href="https://github.com/Shubhamsaboo/awesome-llm-apps/issues"&gt;GitHub Issue&lt;/a&gt; or submit a pull request. Make sure to follow the existing project structure and include a detailed &lt;code&gt;README.md&lt;/code&gt; for each new app.&lt;/p&gt; 
&lt;h3&gt;Thank You, Community, for the Support! üôè&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üåü &lt;strong&gt;Don‚Äôt miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PrefectHQ/prefect</title>
      <link>https://github.com/PrefectHQ/prefect</link>
      <description>&lt;p&gt;Prefect is a workflow orchestration framework for building resilient data pipelines in Python.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://github.com/PrefectHQ/prefect/assets/3407835/c654cbc6-63e8-4ada-a92a-efd2f8f24b85" width="1000"&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://pypi.org/project/prefect/" alt="PyPI version"&gt; &lt;img alt="PyPI" src="https://img.shields.io/pypi/v/prefect?color=0052FF&amp;amp;labelColor=090422"&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/prefect/" alt="PyPI downloads/month"&gt; &lt;img alt="Downloads" src="https://img.shields.io/pypi/dm/prefect?color=0052FF&amp;amp;labelColor=090422"&gt; &lt;/a&gt; &lt;a href="https://github.com/prefecthq/prefect/" alt="Stars"&gt; &lt;img src="https://img.shields.io/github/stars/prefecthq/prefect?color=0052FF&amp;amp;labelColor=090422"&gt; &lt;/a&gt; &lt;a href="https://github.com/prefecthq/prefect/pulse" alt="Activity"&gt; &lt;img src="https://img.shields.io/github/commit-activity/m/prefecthq/prefect?color=0052FF&amp;amp;labelColor=090422"&gt; &lt;/a&gt; &lt;br&gt; &lt;a href="https://prefect.io/slack" alt="Slack"&gt; &lt;img src="https://img.shields.io/badge/slack-join_community-red.svg?color=0052FF&amp;amp;labelColor=090422&amp;amp;logo=slack"&gt; &lt;/a&gt; &lt;a href="https://www.youtube.com/c/PrefectIO/" alt="YouTube"&gt; &lt;img src="https://img.shields.io/badge/youtube-watch_videos-red.svg?color=0052FF&amp;amp;labelColor=090422&amp;amp;logo=youtube"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://docs.prefect.io/v3/get-started/index?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt; Installation &lt;/a&gt; ¬∑ &lt;a href="https://docs.prefect.io/v3/get-started/quickstart?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt; Quickstart &lt;/a&gt; ¬∑ &lt;a href="https://docs.prefect.io/v3/how-to-guides/workflows/write-and-run?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt; Build workflows &lt;/a&gt; ¬∑ &lt;a href="https://docs.prefect.io/v3/concepts/deployments?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt; Deploy workflows &lt;/a&gt; ¬∑ &lt;a href="https://app.prefect.cloud/?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt; Prefect Cloud &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Prefect&lt;/h1&gt; 
&lt;p&gt;Prefect is a workflow orchestration framework for building data pipelines in Python. It's the simplest way to elevate a script into a production workflow. With Prefect, you can build resilient, dynamic data pipelines that react to the world around them and recover from unexpected changes.&lt;/p&gt; 
&lt;p&gt;With just a few lines of code, data teams can confidently automate any data process with features such as scheduling, caching, retries, and event-based automations.&lt;/p&gt; 
&lt;p&gt;Workflow activity is tracked and can be monitored with a self-hosted &lt;a href="https://docs.prefect.io/latest/manage/self-host/?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;Prefect server&lt;/a&gt; instance or managed &lt;a href="https://www.prefect.io/cloud-vs-oss?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;Prefect Cloud&lt;/a&gt; dashboard.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Prefect flows can handle retries, dependencies, and even complex branching logic&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://docs.prefect.io/v3/get-started/index?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;Check our docs&lt;/a&gt; or see the example below to learn more!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Prefect requires Python 3.9+. To &lt;a href="https://docs.prefect.io/v3/get-started/install"&gt;install the latest version of Prefect&lt;/a&gt;, run one of the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U prefect
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add prefect
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then create and run a Python file that uses Prefect &lt;code&gt;flow&lt;/code&gt; and &lt;code&gt;task&lt;/code&gt; decorators to orchestrate and observe your workflow - in this case, a simple script that fetches the number of GitHub stars from a repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from prefect import flow, task
import httpx


@task(log_prints=True)
def get_stars(repo: str):
    url = f"https://api.github.com/repos/{repo}"
    count = httpx.get(url).json()["stargazers_count"]
    print(f"{repo} has {count} stars!")


@flow(name="GitHub Stars")
def github_stars(repos: list[str]):
    for repo in repos:
        get_stars(repo)


# run the flow!
if __name__ == "__main__":
    github_stars(["PrefectHQ/Prefect"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Fire up a Prefect server and open the UI at &lt;a href="http://localhost:4200"&gt;http://localhost:4200&lt;/a&gt; to see what happened:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;prefect server start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run your workflow on a schedule, turn it into a deployment and schedule it to run every minute by changing the last line of your script to the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;if __name__ == "__main__":
    github_stars.serve(
        name="first-deployment",
        cron="* * * * *",
        parameters={"repos": ["PrefectHQ/prefect"]}
    )
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You now have a process running locally that is looking for scheduled deployments! Additionally you can run your workflow manually from the UI or CLI. You can even run deployments in response to &lt;a href="https://docs.prefect.io/latest/automate/?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;events&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Where to go next - check out our &lt;a href="https://docs.prefect.io/v3/get-started/index?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;documentation&lt;/a&gt; to learn more about:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.prefect.io/v3/deploy?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;Deploying flows to production environments&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.prefect.io/v3/develop/write-tasks#retries?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;Adding error handling and retries&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.prefect.io/integrations/integrations?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;Integrating with your existing tools&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.prefect.io/v3/manage/cloud/manage-users/manage-teams#manage-teams?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;Setting up team collaboration features&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Prefect Cloud&lt;/h2&gt; 
&lt;p&gt;Prefect Cloud provides workflow orchestration for the modern data enterprise. By automating over 200 million data tasks monthly, Prefect empowers diverse organizations ‚Äî from Fortune 50 leaders such as Progressive Insurance to innovative disruptors such as Cash App ‚Äî to increase engineering productivity, reduce pipeline errors, and cut data workflow compute costs.&lt;/p&gt; 
&lt;p&gt;Read more about Prefect Cloud &lt;a href="https://www.prefect.io/cloud-vs-oss?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;here&lt;/a&gt; or sign up to &lt;a href="https://app.prefect.cloud?utm_source=oss&amp;amp;utm_medium=oss&amp;amp;utm_campaign=oss_gh_repo&amp;amp;utm_term=none&amp;amp;utm_content=none"&gt;try it for yourself&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;prefect-client&lt;/h2&gt; 
&lt;p&gt;If your use case is geared towards communicating with Prefect Cloud or a remote Prefect server, check out our &lt;a href="https://pypi.org/project/prefect-client/"&gt;prefect-client&lt;/a&gt;. It is a lighter-weight option for accessing client-side functionality in the Prefect SDK and is ideal for use in ephemeral execution environments.&lt;/p&gt; 
&lt;h2&gt;Connect &amp;amp; Contribute&lt;/h2&gt; 
&lt;p&gt;Join a thriving community of over 25,000 practitioners who solve data challenges with Prefect. Prefect's community is built on collaboration, technical innovation, and continuous improvement.&lt;/p&gt; 
&lt;h3&gt;Community Resources&lt;/h3&gt; 
&lt;p&gt;üåê &lt;strong&gt;&lt;a href="https://docs.prefect.io"&gt;Explore the Documentation&lt;/a&gt;&lt;/strong&gt; - Comprehensive guides and API references&lt;br&gt; üí¨ &lt;strong&gt;&lt;a href="https://prefect.io/slack"&gt;Join the Slack Community&lt;/a&gt;&lt;/strong&gt; - Connect with thousands of practitioners&lt;br&gt; ü§ù &lt;strong&gt;&lt;a href="https://docs.prefect.io/contribute/"&gt;Contribute to Prefect&lt;/a&gt;&lt;/strong&gt; - Help shape the future of the project&lt;br&gt; üîå &lt;strong&gt;&lt;a href="https://docs.prefect.io/contribute/contribute-integrations"&gt;Support or create a new Prefect integration&lt;/a&gt;&lt;/strong&gt; - Extend Prefect's capabilities&lt;/p&gt; 
&lt;h3&gt;Stay Informed&lt;/h3&gt; 
&lt;p&gt;üì• &lt;strong&gt;&lt;a href="https://prefect.io/newsletter"&gt;Subscribe to our Newsletter&lt;/a&gt;&lt;/strong&gt; - Get the latest Prefect news and updates&lt;br&gt; üì£ &lt;strong&gt;&lt;a href="https://x.com/PrefectIO"&gt;Twitter/X&lt;/a&gt;&lt;/strong&gt; - Latest updates and announcements&lt;br&gt; üì∫ &lt;strong&gt;&lt;a href="https://www.youtube.com/@PrefectIO"&gt;YouTube&lt;/a&gt;&lt;/strong&gt; - Video tutorials and webinars&lt;br&gt; üì± &lt;strong&gt;&lt;a href="https://www.linkedin.com/company/prefect"&gt;LinkedIn&lt;/a&gt;&lt;/strong&gt; - Professional networking and company news&lt;/p&gt; 
&lt;p&gt;Your contributions, questions, and ideas make Prefect better every day. Whether you're reporting bugs, suggesting features, or improving documentation, your input is invaluable to the Prefect community.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>odoo/odoo</title>
      <link>https://github.com/odoo/odoo</link>
      <description>&lt;p&gt;Odoo. Open Source Apps To Grow Your Business.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Odoo&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://runbot.odoo.com/runbot"&gt;&lt;img src="https://runbot.odoo.com/runbot/badge/flat/1/master.svg?sanitize=true" alt="Build Status"&gt;&lt;/a&gt; &lt;a href="https://www.odoo.com/documentation/master"&gt;&lt;img src="https://img.shields.io/badge/master-docs-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F" alt="Tech Doc"&gt;&lt;/a&gt; &lt;a href="https://www.odoo.com/forum/help-1"&gt;&lt;img src="https://img.shields.io/badge/master-help-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F" alt="Help"&gt;&lt;/a&gt; &lt;a href="https://nightly.odoo.com/"&gt;&lt;img src="https://img.shields.io/badge/master-nightly-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F" alt="Nightly Builds"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Odoo is a suite of web based open source business apps.&lt;/p&gt; 
&lt;p&gt;The main Odoo Apps include an &lt;a href="https://www.odoo.com/page/crm"&gt;Open Source CRM&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/website"&gt;Website Builder&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/ecommerce"&gt;eCommerce&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/inventory"&gt;Warehouse Management&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/project"&gt;Project Management&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/accounting"&gt;Billing &amp;amp; Accounting&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/point-of-sale-shop"&gt;Point of Sale&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/employees"&gt;Human Resources&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/social-marketing"&gt;Marketing&lt;/a&gt;, &lt;a href="https://www.odoo.com/app/manufacturing"&gt;Manufacturing&lt;/a&gt;, &lt;a href="https://www.odoo.com/"&gt;...&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Odoo Apps can be used as stand-alone applications, but they also integrate seamlessly so you get a full-featured &lt;a href="https://www.odoo.com"&gt;Open Source ERP&lt;/a&gt; when you install several Apps.&lt;/p&gt; 
&lt;h2&gt;Getting started with Odoo&lt;/h2&gt; 
&lt;p&gt;For a standard installation please follow the &lt;a href="https://www.odoo.com/documentation/master/administration/install/install.html"&gt;Setup instructions&lt;/a&gt; from the documentation.&lt;/p&gt; 
&lt;p&gt;To learn the software, we recommend the &lt;a href="https://www.odoo.com/slides"&gt;Odoo eLearning&lt;/a&gt;, or &lt;a href="https://www.odoo.com/page/scale-up-business-game"&gt;Scale-up, the business game&lt;/a&gt;. Developers can start with &lt;a href="https://www.odoo.com/documentation/master/developer/howtos.html"&gt;the developer tutorials&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you believe you have found a security issue, check our &lt;a href="https://www.odoo.com/security-report"&gt;Responsible Disclosure page&lt;/a&gt; for details and get in touch with us via email.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>getsentry/sentry</title>
      <link>https://github.com/getsentry/sentry</link>
      <description>&lt;p&gt;Developer-first error tracking and performance monitoring&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://sentry.io/?utm_source=github&amp;amp;utm_medium=logo" target="_blank"&gt; &lt;img src="https://sentry-brand.storage.googleapis.com/sentry-wordmark-dark-280x84.png" alt="Sentry" width="280" height="84"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Users and logs provide clues. Sentry provides answers. &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;What's Sentry?&lt;/h1&gt; 
&lt;p&gt;Sentry is the debugging platform that helps every developer detect, trace, and fix issues. Code breaks, fix it faster.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/issue-details.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/seer.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/traces.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/trace-explorer.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/replays.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/logs.png" width="270"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/uptime.png" width="270"&gt; &lt;/p&gt; 
&lt;h2&gt;Official Sentry SDKs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-javascript"&gt;JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-electron/"&gt;Electron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-react-native"&gt;React-Native&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-ruby"&gt;Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-php"&gt;PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-laravel"&gt;Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-rust"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-java"&gt;Java/Kotlin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-cocoa"&gt;Objective-C/Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-dotnet"&gt;C#/F#&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-native"&gt;C/C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-dart"&gt;Dart/Flutter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/perl-raven"&gt;Perl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-clj/"&gt;Clojure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-elixir"&gt;Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-unity"&gt;Unity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-unreal"&gt;Unreal Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-godot"&gt;Godot Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-powershell"&gt;PowerShell&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Resources&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.sentry.io/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry/discussions"&gt;Discussions&lt;/a&gt; (Bugs, feature requests, general questions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/PXa5Apfe7K"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.sentry.io/internal/contributing/"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry/issues"&gt;Bug Tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry"&gt;Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.transifex.com/getsentry/sentry/"&gt;Transifex&lt;/a&gt; (Translate Sentry!)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>nerfstudio-project/viser</title>
      <link>https://github.com/nerfstudio-project/viser</link>
      <description>&lt;p&gt;Web-based 3D visualization + Python&lt;/p&gt;&lt;hr&gt;&lt;h1 align="left"&gt; &lt;img alt="viser logo" src="https://viser.studio/main/_static/logo.svg?sanitize=true" width="30" height="auto"&gt; Viser &lt;img alt="viser logo" src="https://viser.studio/main/_static/logo.svg?sanitize=true" width="30" height="auto"&gt; &lt;/h1&gt; 
&lt;p align="left"&gt; &lt;img alt="pyright" src="https://github.com/nerfstudio-project/viser/actions/workflows/pyright.yml/badge.svg?sanitize=true"&gt; &lt;img alt="typescript-compile" src="https://github.com/nerfstudio-project/viser/actions/workflows/typescript-compile.yml/badge.svg?sanitize=true"&gt; &lt;a href="https://pypi.org/project/viser/"&gt; &lt;img alt="codecov" src="https://img.shields.io/pypi/pyversions/viser"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Viser is a 3D visualization library for computer vision and robotics in Python.&lt;/p&gt; 
&lt;p&gt;Features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;API for visualizing 3D primitives.&lt;/li&gt; 
 &lt;li&gt;GUI building blocks: buttons, checkboxes, text inputs, sliders, etc.&lt;/li&gt; 
 &lt;li&gt;Scene interaction tools (clicks, selection, transform gizmos).&lt;/li&gt; 
 &lt;li&gt;Programmatic camera control and rendering.&lt;/li&gt; 
 &lt;li&gt;An entirely web-based client, for easy use over SSH!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The goal is to provide primitives that are (1) easy for simple visualization tasks, but (2) can be composed into more elaborate interfaces. For more about design goals, see the &lt;a href="https://arxiv.org/abs/2507.22885"&gt;technical report&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Examples and documentation: &lt;a href="https://viser.studio"&gt;https://viser.studio&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can install &lt;code&gt;viser&lt;/code&gt; with &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install viser            # Core dependencies only.
pip install viser[examples]  # To include example dependencies.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! To learn more, we recommend looking at the examples in the &lt;a href="https://viser.studio/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;To cite Viser in your work, you can use the BibTeX for our &lt;a href="https://arxiv.org/abs/2507.22885"&gt;technical report&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{yi2025viser,
      title={Viser: Imperative, Web-based 3D Visualization in Python},
      author={Brent Yi and Chung Min Kim and Justin Kerr and Gina Wu and Rebecca Feng and Anthony Zhang and Jonas Kulhanek and Hongsuk Choi and Yi Ma and Matthew Tancik and Angjoo Kanazawa},
      year={2025},
      eprint={2507.22885},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.22885},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;viser&lt;/code&gt; is heavily inspired by packages like &lt;a href="https://github.com/stevenlovegrove/Pangolin"&gt;Pangolin&lt;/a&gt;, &lt;a href="https://github.com/ocornut/imgui"&gt;Dear ImGui&lt;/a&gt;, &lt;a href="https://wiki.ros.org/rviz/"&gt;rviz&lt;/a&gt;, &lt;a href="https://github.com/rdeits/meshcat"&gt;meshcat&lt;/a&gt;, and &lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The web client is implemented using &lt;a href="https://react.dev/"&gt;React&lt;/a&gt;, with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://vitejs.dev/"&gt;Vite&lt;/a&gt; / &lt;a href="https://rollupjs.org/"&gt;Rollup&lt;/a&gt; for bundling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://threejs.org/"&gt;three.js&lt;/a&gt; via &lt;a href="https://github.com/pmndrs/react-three-fiber"&gt;react-three-fiber&lt;/a&gt; and &lt;a href="https://github.com/pmndrs/drei"&gt;drei&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mantine.dev/"&gt;Mantine&lt;/a&gt; for UI components&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pmndrs/zustand"&gt;zustand&lt;/a&gt; for state management&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vanilla-extract.style/"&gt;vanilla-extract&lt;/a&gt; for stylesheets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Thanks to the authors of these projects for open-sourcing their work!&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>