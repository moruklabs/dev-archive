<rss version="2.0">
  <channel>
    <title>GitHub Python Monthly Trending</title>
    <description>Monthly Trending of Python in GitHub</description>
    <pubDate>Sun, 03 Aug 2025 01:56:04 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>hummingbot/hummingbot</title>
      <link>https://github.com/hummingbot/hummingbot</link>
      <description>&lt;p&gt;Open source software that helps you create and deploy high-frequency crypto trading bots&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3213d7f8-414b-4df8-8c1b-a0cd142a82d8" alt="Hummingbot"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;a href="https://github.com/hummingbot/hummingbot/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-informational.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;a href="https://twitter.com/_hummingbot"&gt;&lt;img src="https://img.shields.io/twitter/url?url=https://twitter.com/_hummingbot?style=social&amp;amp;label=_hummingbot" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/@hummingbot"&gt;&lt;img src="https://img.shields.io/youtube/channel/subscribers/UCxzzdEnDRbylLMWmaMjywOA" alt="Youtube"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/hummingbot"&gt;&lt;img src="https://img.shields.io/discord/530578568154054663?logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Hummingbot is an open-source framework that helps you design and deploy automated trading strategies, or &lt;strong&gt;bots&lt;/strong&gt;, that can run on many centralized or decentralized exchanges. Over the past year, Hummingbot users have generated over $34 billion in trading volume across 140+ unique trading venues.&lt;/p&gt; 
&lt;p&gt;The Hummingbot codebase is free and publicly available under the Apache 2.0 open-source license. Our mission is to &lt;strong&gt;democratize high-frequency trading&lt;/strong&gt; by creating a global community of algorithmic traders and developers that share knowledge and contribute to the codebase.&lt;/p&gt; 
&lt;h2&gt;Quick Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hummingbot.org"&gt;Website and Docs&lt;/a&gt;: Official Hummingbot website and documeniuntation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hummingbot.org/installation/docker/"&gt;Installation&lt;/a&gt;: Install Hummingbot on various platforms&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/hummingbot"&gt;Discord&lt;/a&gt;: The main gathering spot for the global Hummingbot community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/c/hummingbot"&gt;YouTube&lt;/a&gt;: Videos that teach you how to get the most of of Hummingbot&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/_hummingbot"&gt;Twitter&lt;/a&gt;: Get the latest announcements about Hummingbot&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://p.datadoghq.com/sb/a96a744f5-a15479d77992ccba0d23aecfd4c87a52"&gt;Reported Volumes&lt;/a&gt;: Reported trading volumes across all Hummingbot instances&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hummingbot.substack.com"&gt;Newsletter&lt;/a&gt;: Get our newsletter whenever we ship a new release&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Exchange Connectors&lt;/h2&gt; 
&lt;p&gt;Hummingbot connectors standardize REST and WebSocket API interfaces to different types of exchanges, enabling you to build sophisticated trading strategies that can be deployed across many exchanges with minimal changes. We classify exchanges into the following categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CEX&lt;/strong&gt;: Centralized exchanges that take custody of your funds. Use API keys to connect with Hummingbot.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DEX&lt;/strong&gt;: Decentralized, non-custodial exchanges that operate on a blockchain. Use wallet keys to connect with Hummingbot.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition, connectors differ based on the type of market supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CLOB Spot&lt;/strong&gt;: Connectors to spot markets on central limit order book (CLOB) exchanges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CLOB Perp&lt;/strong&gt;: Connectors to perpetual futures markets on CLOB exchanges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AMM&lt;/strong&gt;: Connectors to spot markets on Automatic Market Maker (AMM) decentralized exchanges&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Exchange Sponsors&lt;/h3&gt; 
&lt;p&gt;We are grateful for the following exchanges that support the development and maintenance of Hummingbot via broker partnerships and sponsorships.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connector ID&lt;/th&gt; 
   &lt;th&gt;Exchange&lt;/th&gt; 
   &lt;th&gt;CEX/DEX&lt;/th&gt; 
   &lt;th&gt;Market Type&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
   &lt;th&gt;Discount&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;binance&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://accounts.binance.com/register?ref=CBWO4LU6"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/binance/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://accounts.binance.com/register?ref=CBWO4LU6"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d10%25&amp;amp;color=orange" alt="Sign up for Binance using Hummingbot's referral link for a 10% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;binance_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://accounts.binance.com/register?ref=CBWO4LU6"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/binance/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://accounts.binance.com/register?ref=CBWO4LU6"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d10%25&amp;amp;color=orange" alt="Sign up for Binance using Hummingbot's referral link for a 10% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;gate_io&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gate.io/referral/invite/HBOTGATE_0_103"&gt;Gate.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/gate-io/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gate.io/referral/invite/HBOTGATE_0_103"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Gate.io using Hummingbot's referral link for a 10% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;gate_io_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gate.io/referral/invite/HBOTGATE_0_103"&gt;Gate.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/gate-io/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gate.io/referral/invite/HBOTGATE_0_103"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Gate.io using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;htx&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.htx.com.pk/invite/en-us/1h?invite_code=re4w9223"&gt;HTX (Huobi)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/huobi/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.htx.com.pk/invite/en-us/1h?invite_code=re4w9223"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for HTX using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kucoin&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.kucoin.com/r/af/hummingbot"&gt;KuCoin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/kucoin/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.kucoin.com/r/af/hummingbot"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Kucoin using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kucoin_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.kucoin.com/r/af/hummingbot"&gt;KuCoin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/kucoin/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.kucoin.com/r/af/hummingbot"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Kucoin using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;okx&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.okx.com/join/1931920269"&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/okx/okx/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.okx.com/join/1931920269"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Kucoin using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;okx_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.okx.com/join/1931920269"&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/okx/okx/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.okx.com/join/1931920269"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Kucoin using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dydx_v4_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.dydx.exchange/"&gt;dYdX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/dydx/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;hyperliquid_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hyperliquid.io/"&gt;Hyperliquid&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/hyperliquid/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;xrpl&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://xrpl.org/"&gt;XRP Ledger&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/xrpl/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Other Exchange Connectors&lt;/h3&gt; 
&lt;p&gt;Currently, the master branch of Hummingbot also includes the following exchange connectors, which are maintained and updated through the Hummingbot Foundation governance process. See &lt;a href="https://hummingbot.org/governance/"&gt;Governance&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connector ID&lt;/th&gt; 
   &lt;th&gt;Exchange&lt;/th&gt; 
   &lt;th&gt;CEX/DEX&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
   &lt;th&gt;Discount&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ascend_ex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;AscendEx&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/ascendex/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;balancer&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Balancer&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/balancer/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bing_x&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;BingX&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bing_x/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitget_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bitget&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bitget-perpetual/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitmart&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;BitMart&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bitmart/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitrue&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bitrue&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bitrue/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitstamp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bitstamp&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bitstamp/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;btc_markets&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;BTC Markets&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/btc-markets/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bybit&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bybit&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bybit/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bybit_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bybit&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bybit/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;carbon&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Carbon&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/carbon/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;coinbase_advanced_trade&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Coinbase&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/coinbase/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;cube&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cube&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/cube/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;curve&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Curve&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/curve/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dexalot&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dexalot&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/dexalot/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;injective_v2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Injective Helix&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/injective/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;injective_v2_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Injective Helix&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/injective/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kraken&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Kraken&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/kraken/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mad_meerkat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Mad Meerkat&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/mad-meerkat/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mexc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;MEXC&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/mexc/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openocean&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenOcean&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/openocean/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pancakeswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;PancakeSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/pancakeswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pangolin&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pangolin&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/pangolin/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;quickswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;QuickSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/quickswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;sushiswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;SushiSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/sushiswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tinyman&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Tinyman&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/tinyman/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;traderjoe&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Trader Joe&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/traderjoe/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;uniswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Uniswap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/gateway/uniswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vertex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Vertex&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/vertex/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vvs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;VVS&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/vvs/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;xsswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;XSSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/xswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Other Hummingbot Repos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/deploy"&gt;Deploy&lt;/a&gt;: Deploy Hummingbot in various configurations with Docker&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/dashboard"&gt;Dashboard&lt;/a&gt;: Web app that help you create, backtest, deploy, and manage Hummingbot instances&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/quants-lab"&gt;Quants Lab&lt;/a&gt;: Juypter notebooks that enable you to fetch data and perform research using Hummingbot&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/gateway"&gt;Gateway&lt;/a&gt;: Typescript based API client for DEX connectors&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/hummingbot-site"&gt;Hummingbot Site&lt;/a&gt;: Official documentation for Hummingbot - we welcome contributions here too!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;The Hummingbot architecture features modular components that can be maintained and extended by individual community members.&lt;/p&gt; 
&lt;p&gt;We welcome contributions from the community! Please review these &lt;a href="https://raw.githubusercontent.com/hummingbot/hummingbot/master/CONTRIBUTING.md"&gt;guidelines&lt;/a&gt; before submitting a pull request.&lt;/p&gt; 
&lt;p&gt;To have your exchange connector or other pull request merged into the codebase, please submit a New Connector Proposal or Pull Request Proposal, following these &lt;a href="https://hummingbot.org/governance/proposals/"&gt;guidelines&lt;/a&gt;. Note that you will need some amount of &lt;a href="https://etherscan.io/token/0xe5097d9baeafb89f9bcb78c9290d545db5f9e9cb"&gt;HBOT tokens&lt;/a&gt; in your Ethereum wallet to submit a proposal.&lt;/p&gt; 
&lt;h2&gt;Legal&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;License&lt;/strong&gt;: Hummingbot is open source and licensed under &lt;a href="https://raw.githubusercontent.com/hummingbot/hummingbot/master/LICENSE"&gt;Apache 2.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data collection&lt;/strong&gt;: See &lt;a href="https://hummingbot.org/reporting/"&gt;Reporting&lt;/a&gt; for information on anonymous data collection and reporting in Hummingbot.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>hesreallyhim/awesome-claude-code</title>
      <link>https://github.com/hesreallyhim/awesome-claude-code</link>
      <description>&lt;p&gt;A curated list of awesome commands, files, and workflows for Claude Code&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;/h1&gt; 
&lt;!-- [![Awesome](https://awesome.re/badge-flat2.svg)](https://awesome.re) --&gt; 
&lt;pre style="display: inline-block; text-align: left;"&gt;
 █████┐ ██┐    ██┐███████┐███████┐ ██████┐ ███┐   ███┐███████┐
██┌──██┐██│    ██│██┌────┘██┌────┘██┌───██┐████┐ ████│██┌────┘
███████│██│ █┐ ██│█████┐  ███████┐██│   ██│██┌████┌██│█████┐
██┌──██│██│███┐██│██┌──┘  └────██│██│   ██│██│└██┌┘██│██┌──┘
██│  ██│└███┌███┌┘███████┐███████│└██████┌┘██│ └─┘ ██│███████┐
└─┘  └─┘ └──┘└──┘ └──────┘└──────┘ └─────┘ └─┘     └─┘└──────┘

 ────────────────────────────────────────────────────────────────────────────────────

 ██████┐██┐      █████┐ ██┐   ██┐██████┐ ███████┐     ██████┐ ██████┐ ██████┐ ███████┐
██┌────┘██│     ██┌──██┐██│   ██│██┌──██┐██┌────┘    ██┌────┘██┌───██┐██┌──██┐██┌────┘
██│     ██│     ███████│██│   ██│██│  ██│█████┐      ██│     ██│   ██│██│  ██│█████┐
██│     ██│     ██┌──██│██│   ██│██│  ██│██┌──┘      ██│     ██│   ██│██│  ██│██┌──┘
└██████┐███████┐██│  ██│└██████┌┘██████┌┘███████┐    └██████┐└██████┌┘██████┌┘███████┐
 └─────┘└──────┘└─┘  └─┘ └─────┘ └─────┘ └──────┘     └─────┘ └─────┘ └─────┘ └──────┘
&lt;/pre&gt; 
&lt;!--lint enable remark-lint:awesome-badge--&gt; 
&lt;p&gt;&lt;a href="https://awesome.re"&gt;&lt;img src="https://awesome.re/badge-flat2.svg?sanitize=true" alt="Awesome"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;a href="https://github.com/hesreallyhim/awesome-claude-code"&gt;Awesome Claude Code&lt;/a&gt; 🤝 &lt;a href="https://github.com/hesreallyhim/awesome-claude-code-agents"&gt;Awesome Claude Code Agents&lt;/a&gt;&lt;/h1&gt; 
&lt;!--lint enable remark-lint:awesome-badge--&gt; 
&lt;!--lint disable double-link--&gt; 
&lt;p&gt;This is a curated list of slash-commands, &lt;code&gt;CLAUDE.md&lt;/code&gt; files, CLI tools, and other resources and guides for enhancing your &lt;a href="https://docs.anthropic.com/en/docs/claude-code"&gt;Claude Code&lt;/a&gt; workflow, productivity, and vibes.&lt;/p&gt; 
&lt;!--lint enable double-link--&gt; 
&lt;p&gt;Claude Code is a cutting-edge CLI-based coding assistant and agent that you can access in your terminal or IDE. It is a rapidly evolving tool that offers a number of powerful capabilities, and allows for a lot of configuration, in a lot of different ways. Users are actively working out best practices and workflows. It is the hope that this repo will help the community share knowledge and understand how to get the most out of Claude Code.&lt;/p&gt; 
&lt;h3&gt;Announcements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025-07-30 - Quick Update: Still trying to iron out the submission flow (sorry for anyone that received duplicate "Congratulations!" issues). If you end up fighting any of the programmatic submission tools, just submit something that has all the necessary data, and I'll take it from there once approved. Other notes: (i) I think it would be really cool/fun to set up a "Claude Code Leaderboard", so feel free to weigh in on the &lt;a href="https://github.com/hesreallyhim/awesome-claude-code/discussions/81"&gt;Discussion&lt;/a&gt;; (ii) I'm still trying to figure out what to do about &lt;strong&gt;SUB AGENTS&lt;/strong&gt;, and I've reached out to some of the other folks who have started similar repo's; (iii) Added a small section that will be updated with new submissions as they roll in.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;New Additions&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dazuiba/CCNotify"&gt;&lt;code&gt;CC Notify&lt;/code&gt;&lt;/a&gt; by &lt;a href="https://github.com/dazuiba"&gt;dazuiba&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Piebald-AI/tweakcc"&gt;&lt;code&gt;tweakcc&lt;/code&gt;&lt;/a&gt; by &lt;a href="https://github.com/Piebald-AI"&gt;Piebald-AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GowayLee/cchooks"&gt;&lt;code&gt;cchooks&lt;/code&gt;&lt;/a&gt; by &lt;a href="https://github.com/GowayLee"&gt;GowayLee&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;h2&gt;Contents&lt;/h2&gt; 
&lt;p&gt;▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#workflows--knowledge-guides-"&gt;Workflows &amp;amp; Knowledge Guides&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#tooling-"&gt;Tooling&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ide-integrations"&gt;IDE Integrations&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#hooks-"&gt;Hooks&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#slash-commands-"&gt;Slash-Commands&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#version-control--git"&gt;Version Control &amp;amp; Git&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#code-analysis--testing"&gt;Code Analysis &amp;amp; Testing&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#context-loading--priming"&gt;Context Loading &amp;amp; Priming&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#documentation--changelogs"&gt;Documentation &amp;amp; Changelogs&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ci--deployment"&gt;CI / Deployment&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project--task-management"&gt;Project &amp;amp; Task Management&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#miscellaneous"&gt;Miscellaneous&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#claudemd-files-"&gt;CLAUDE.md Files&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#language-specific"&gt;Language-Specific&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#domain-specific"&gt;Domain-Specific&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project-scaffolding--mcp"&gt;Project Scaffolding &amp;amp; MCP&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#official-documentation-"&gt;Official Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Workflows &amp;amp; Knowledge Guides 🧠&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A &lt;strong&gt;workflow&lt;/strong&gt; is a tightly coupled set of Claude Code-native resources that facilitate specific projects&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/cloudartisan/cloudartisan.github.io/tree/main/.claude/commands"&gt;&lt;code&gt;Blogging Platform Instructions&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/cloudartisan"&gt;cloudartisan&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;CC-BY-SA-4.0&lt;br&gt; Provides a well-structured set of commands for publishing and maintaining a blogging platform, including commands for creating posts, managing categories, and handling media files.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://claudelog.com"&gt;&lt;code&gt;ClaudeLog&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://www.reddit.com/user/inventor_black/"&gt;InventorBlack&lt;/a&gt;&lt;br&gt; A comprehensive knowledge base with detailed breakdowns of advanced &lt;a href="https://claudelog.com/mechanics/you-are-the-main-thread/"&gt;mechanics&lt;/a&gt; including &lt;a href="https://claudelog.com/mechanics/claude-md-supremacy"&gt;CLAUDE.md best practices&lt;/a&gt;, practical technique guides like &lt;a href="https://claudelog.com/mechanics/plan-mode"&gt;plan mode&lt;/a&gt;, &lt;a href="https://claudelog.com/faqs/what-is-ultrathink/"&gt;ultrathink&lt;/a&gt;, &lt;a href="https://claudelog.com/mechanics/task-agent-tools/"&gt;sub-agents&lt;/a&gt;, &lt;a href="https://claudelog.com/mechanics/agent-first-design/"&gt;agent-first design&lt;/a&gt; and &lt;a href="https://claudelog.com/configuration"&gt;configuration guides&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/disler/just-prompt/tree/main/.claude/commands"&gt;&lt;code&gt;Context Priming&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/disler"&gt;disler&lt;/a&gt;&lt;br&gt; Provides a systematic approach to priming Claude Code with comprehensive project context through specialized commands for different project scenarios and development contexts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kingler/n8n_agent/tree/main/.claude/commands"&gt;&lt;code&gt;n8n_agent&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/kingler"&gt;kingler&lt;/a&gt;&lt;br&gt; Amazing comprehensive set of comments for code analysis, QA, design, documentation, project structure, project management, optimization, and many more.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steadycursor/steadystart/tree/main/.claude/commands"&gt;&lt;code&gt;Project Bootstrapping and Task Management&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt;&lt;br&gt; Provides a structured set of commands for bootstrapping and managing a new project, including meta-commands for creating and editing custom slash-commands.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/scopecraft/command/tree/main/.claude/commands"&gt;&lt;code&gt;Project Management, Implementation, Planning, and Release&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/scopecraft"&gt;scopecraft&lt;/a&gt;&lt;br&gt; Really comprehensive set of commands for all aspects of SDLC.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/harperreed/dotfiles/tree/master/.claude/commands"&gt;&lt;code&gt;Project Workflow System&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/harperreed"&gt;harperreed&lt;/a&gt;&lt;br&gt; A set of commands that provide a comprehensive workflow system for managing projects, including task management, code review, and deployment processes.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://diwank.space/field-notes-from-shipping-real-code-with-claude"&gt;&lt;code&gt;Shipping Real Code w/ Claude&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/creatorrr"&gt;Diwank&lt;/a&gt;&lt;br&gt; A detailed blog post explaining the author's process for shipping a product with Claude Code, including CLAUDE.md files and other interesting resources.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Helmi/claude-simone"&gt;&lt;code&gt;Simone&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Helmi"&gt;Helmi&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A broader project management workflow for Claude Code that encompasses not just a set of commands, but a system of documents, guidelines, and processes to facilitate project planning and execution.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/wcygan/dotfiles/tree/d8ab6b9f5a7a81007b7f5fa3025d4f83ce12cc02/claude/commands"&gt;&lt;code&gt;Slash-commands megalist&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/wcygan"&gt;wcygan&lt;/a&gt;&lt;br&gt; A pretty stunning list (88 at the time of this post!) of slash-commands ranging from agent orchestration, code review, project management, security, documentation, self-assessment, almost anything you can dream of.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Tooling 🧰&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tooling&lt;/strong&gt; denotes applications that are built on top of Claude Code and consist of more components than slash-commands and &lt;code&gt;CLAUDE.md&lt;/code&gt; files&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/ryoppippi/ccusage"&gt;&lt;code&gt;CC Usage&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ryoppippi"&gt;ryoppippi&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Handy CLI tool for managing and analyzing Claude Code usage, based on analyzing local Claude Code logs. Presents a nice dashboard regarding cost information, token consumption, etc.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/nyatinte/ccexp"&gt;&lt;code&gt;ccexp&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/nyatinte"&gt;nyatinte&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Interactive CLI tool for discovering and managing Claude Code configuration files and slash commands with a beautiful terminal UI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ruvnet/claude-code-flow"&gt;&lt;code&gt;Claude Code Flow&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ruvnet"&gt;ruvnet&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; This mode serves as a code-first orchestration layer, enabling Claude to write, edit, test, and optimize code autonomously across recursive agent cycles.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor"&gt;&lt;code&gt;Claude Code Usage Monitor&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Maciek-roboblog"&gt;Maciek-roboblog&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A real-time terminal-based tool for monitoring Claude Code token usage. It shows live token consumption, burn rate, and predictions for token depletion. Features include visual progress bars, session-aware analytics, and support for multiple subscription plans.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/possibilities/claude-composer"&gt;&lt;code&gt;Claude Composer&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/possibilities"&gt;Mike Bannister&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Unlicense&lt;br&gt; A tool that adds small enhancements to Claude Code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/claude-did-this/claude-hub"&gt;&lt;code&gt;Claude Hub&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/claude-did-this"&gt;Claude Did This&lt;/a&gt;&lt;br&gt; A webhook service that connects Claude Code to GitHub repositories, enabling AI-powered code assistance directly through pull requests and issues. This integration allows Claude to analyze repositories, answer technical questions, and help developers understand and improve their codebase through simple @mentions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/smtg-ai/claude-squad"&gt;&lt;code&gt;Claude Squad&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/smtg-ai"&gt;smtg-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br&gt; Claude Squad is a terminal app that manages multiple Claude Code, Codex (and other local agents including Aider) in separate workspaces, allowing you to work on multiple tasks simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/parruda/claude-swarm"&gt;&lt;code&gt;Claude Swarm&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/parruda"&gt;parruda&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Launch Claude Code session that is connected to a swarm of Claude Code Agents.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/eyaltoledano/claude-task-master"&gt;&lt;code&gt;Claude Task Master&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/eyaltoledano"&gt;eyaltoledano&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/grahama1970/claude-task-runner"&gt;&lt;code&gt;Claude Task Runner&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/grahama1970"&gt;grahama1970&lt;/a&gt;&lt;br&gt; A specialized tool to manage context isolation and focused task execution with Claude Code, solving the critical challenge of context length limitations and task focus when working with Claude on complex, multi-step projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dagger/container-use"&gt;&lt;code&gt;Container Use&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/dagger"&gt;dagger&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Development environments for coding agents. Enable multiple agents to work safely and independently with your preferred stack.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Piebald-AI/tweakcc"&gt;&lt;code&gt;tweakcc&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Piebald-AI"&gt;Piebald-AI&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Command-line tool to customize your Claude Code styling.&lt;/p&gt; 
&lt;h3&gt;IDE Integrations&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=AndrePimenta.claude-code-chat"&gt;&lt;code&gt;Claude Code Chat&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/andrepimenta"&gt;andrepimenta&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;©&lt;br&gt; An elegant and user-friendly Claude Code chat interface for VS Code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/stevemolitor/claude-code.el"&gt;&lt;code&gt;claude-code.el&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/stevemolitor"&gt;stevemolitor&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; An Emacs interface for Claude Code CLI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/greggh/claude-code.nvim"&gt;&lt;code&gt;claude-code.nvim&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/greggh"&gt;greggh&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A seamless integration between Claude Code AI assistant and Neovim.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/stravu/crystal"&gt;&lt;code&gt;crystal&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/stravu"&gt;stravu&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A full-fledged desktop application for orchestrating, monitoring, and interacting with Claude Code agents.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Hooks 🪝&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Hooks&lt;/strong&gt; are a brand new API for Claude Code that allows users to activate commands and run scripts at different points in Claude's agentic lifecycle.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;[Experimental]&lt;/strong&gt; - The resources listed in this section have not been fully vetted and may not work as expected, given the bleeding-edge nature of Claude Code hooks. Nevertheless, I wished to include them at least as a source of inspiration and to explore this unknown terrain. YMMV!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dazuiba/CCNotify"&gt;&lt;code&gt;CC Notify&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/dazuiba"&gt;dazuiba&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; CCNotify provides desktop notifications for Claude Code, alerting you to input needs or task completion, with one-click jumps back to VS Code and task duration display.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/GowayLee/cchooks"&gt;&lt;code&gt;cchooks&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/GowayLee"&gt;GowayLee&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A lightweight Python SDK with a clean API and good documentation; simplifies the process of writing hooks and integrating them into your codebase, providing a nice abstraction over the JSON configuration files.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/beyondcode/claude-hooks-sdk"&gt;&lt;code&gt;claude-code-hooks-sdk&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/beyondcode"&gt;beyondcode&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A Laravel-inspired PHP SDK for building Claude Code hook responses with a clean, fluent API. This SDK makes it easy to create structured JSON responses for Claude Code hooks using an expressive, chainable interface.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/johnlindquist/claude-hooks"&gt;&lt;code&gt;claude-hooks&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/johnlindquist"&gt;John Lindquist&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A TypeScript-based system for configuring and customizing Claude Code hooks with a powerful and flexible interface.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Veraticus/nix-config/tree/main/home-manager/claude-code/hooks"&gt;&lt;code&gt;Linting, testing, and notifications (in go)&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Veraticus"&gt;Josh Symonds&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Nice set of hooks for enforcing code quality (linting, testing, notifications), with a nice configuration setup as well.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/nizos/tdd-guard"&gt;&lt;code&gt;TDD Guard&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/nizos"&gt;Nizar Selander&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A hooks-driven system that monitors file operations in real-time and blocks changes that violate TDD principles.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Slash-Commands 🔪&lt;/h2&gt; 
&lt;h3&gt;Version Control &amp;amp; Git&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/danielscholl/mvn-mcp-server/raw/main/.claude/commands/bug-fix.md"&gt;&lt;code&gt;/bug-fix&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/danielscholl"&gt;danielscholl&lt;/a&gt;&lt;br&gt; Streamlines bug fixing by creating a GitHub issue first, then a feature branch for implementing and thoroughly testing the solution before merging.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/commit.md"&gt;&lt;code&gt;/commit&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Creates git commits using conventional commit format with appropriate emojis, following project standards and creating descriptive messages that explain the purpose of changes.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steadycursor/steadystart/raw/main/.claude/commands/2-commit-fast.md"&gt;&lt;code&gt;/commit-fast&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt;&lt;br&gt; Automates git commit process by selecting the first suggested message, generating structured commits with consistent formatting while skipping manual confirmation and removing Claude co-Contributorship footer&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/toyamarinyon/giselle/raw/main/.claude/commands/create-pr.md"&gt;&lt;code&gt;/create-pr&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/toyamarinyon"&gt;toyamarinyon&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Streamlines pull request creation by handling the entire workflow: creating a new branch, committing changes, formatting modified files with Biome, and submitting the PR.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/liam-hq/liam/raw/main/.claude/commands/create-pull-request.md"&gt;&lt;code&gt;/create-pull-request&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/liam-hq"&gt;liam-hq&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Provides comprehensive PR creation guidance with GitHub CLI, enforcing title conventions, following template structure, and offering concrete command examples with best practices.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/create-worktrees.md"&gt;&lt;code&gt;/create-worktrees&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Creates git worktrees for all open PRs or specific branches, handling branches with slashes, cleaning up stale worktrees, and supporting custom branch creation for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jeremymailen/kotlinter-gradle/raw/master/.claude/commands/fix-github-issue.md"&gt;&lt;code&gt;/fix-github-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/jeremymailen"&gt;jeremymailen&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Analyzes and fixes GitHub issues using a structured approach with GitHub CLI for issue details, implementing necessary code changes, running tests, and creating proper commit messages.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/.claude/commands/fix-issue.md"&gt;&lt;code&gt;/fix-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Addresses GitHub issues by taking issue number as parameter, analyzing context, implementing solution, and testing/validating the fix for proper integration.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/.claude/commands/fix-pr.md"&gt;&lt;code&gt;/fix-pr&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Fetches and fixes unresolved PR comments by automatically retrieving feedback, addressing reviewer concerns, making targeted code improvements, and streamlining the review process.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/husky.md"&gt;&lt;code&gt;/husky&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Sets up and manages Husky Git hooks by configuring pre-commit hooks, establishing commit message standards, integrating with linting tools, and ensuring code quality on commits.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/arkavo-org/opentdf-rs/raw/main/.claude/commands/pr-review.md"&gt;&lt;code&gt;/pr-review&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/arkavo-org"&gt;arkavo-org&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Reviews pull request changes to provide feedback, check for issues, and suggest improvements before merging into the main codebase.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/giselles-ai/giselle/raw/main/.claude/commands/update-branch-name.md"&gt;&lt;code&gt;/update-branch-name&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/giselles-ai"&gt;giselles-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Updates branch names with proper prefixes and formats, enforcing naming conventions, supporting semantic prefixes, and managing remote branch updates.&lt;/p&gt; 
&lt;h3&gt;Code Analysis &amp;amp; Testing&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/rygwdn/slack-tools/raw/main/.claude/commands/check.md"&gt;&lt;code&gt;/check&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/rygwdn"&gt;rygwdn&lt;/a&gt;&lt;br&gt; Performs comprehensive code quality and security checks, featuring static analysis integration, security vulnerability scanning, code style enforcement, and detailed reporting.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Graphlet-AI/eridu/raw/main/.claude/commands/clean.md"&gt;&lt;code&gt;/clean&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Graphlet-AI"&gt;Graphlet-AI&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Addresses code formatting and quality issues by fixing black formatting problems, organizing imports with isort, resolving flake8 linting issues, and correcting mypy type errors.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kingler/n8n_agent/raw/main/.claude/commands/code_analysis.md"&gt;&lt;code&gt;/code_analysis&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/kingler"&gt;kingler&lt;/a&gt;&lt;br&gt; Provides a menu of advanced code analysis commands for deep inspection, including knowledge graph generation, optimization suggestions, and quality evaluation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/to4iki/ai-project-rules/raw/main/.claude/commands/optimize.md"&gt;&lt;code&gt;/optimize&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/to4iki"&gt;to4iki&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Analyzes code performance to identify bottlenecks, proposing concrete optimizations with implementation guidance for improved application performance.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rzykov/metabase/raw/master/.claude/commands/repro-issue.md"&gt;&lt;code&gt;/repro-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/rzykov"&gt;rzykov&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Creates reproducible test cases for GitHub issues, ensuring tests fail reliably and documenting clear reproduction steps for developers.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/zscott/pane/raw/main/.claude/commands/tdd.md"&gt;&lt;code&gt;/tdd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/zscott"&gt;zscott&lt;/a&gt;&lt;br&gt; Guides development using Test-Driven Development principles, enforcing Red-Green-Refactor discipline, integrating with git workflow, and managing PR creation.&lt;/p&gt; 
&lt;h3&gt;Context Loading &amp;amp; Priming&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/elizaOS/elizaos.github.io/raw/main/.claude/commands/context-prime.md"&gt;&lt;code&gt;/context-prime&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/elizaOS"&gt;elizaOS&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Primes Claude with comprehensive project understanding by loading repository structure, setting development context, establishing project goals, and defining collaboration parameters.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/okuvshynov/cubestat/raw/main/.claude/commands/initref.md"&gt;&lt;code&gt;/initref&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/okuvshynov"&gt;okuvshynov&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Initializes reference documentation structure with standard doc templates, API reference setup, documentation conventions, and placeholder content generation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ethpandaops/xatu-data/raw/master/.claude/commands/load-llms-txt.md"&gt;&lt;code&gt;/load-llms-txt&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ethpandaops"&gt;ethpandaops&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Loads LLM configuration files to context, importing specific terminology, model configurations, and establishing baseline terminology for AI discussions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_coo_context.md"&gt;&lt;code&gt;/load_coo_context&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br&gt; References specific files for sparse matrix operations, explains transform usage, compares with previous approaches, and sets data formatting context for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_dango_pipeline.md"&gt;&lt;code&gt;/load_dango_pipeline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br&gt; Sets context for model training by referencing pipeline files, establishing working context, and preparing for pipeline work with relevant documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/yzyydev/AI-Engineering-Structure/raw/main/.claude/commands/prime.md"&gt;&lt;code&gt;/prime&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/yzyydev"&gt;yzyydev&lt;/a&gt;&lt;br&gt; Sets up initial project context by viewing directory structure and reading key files, creating standardized context with directory visualization and key documentation focus.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ddisisto/si/raw/main/.claude/commands/rsi.md"&gt;&lt;code&gt;/rsi&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ddisisto"&gt;ddisisto&lt;/a&gt;&lt;br&gt; Reads all commands and key project files to optimize AI-assisted development by streamlining the process, loading command context, and setting up for better development workflow.&lt;/p&gt; 
&lt;h3&gt;Documentation &amp;amp; Changelogs&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/berrydev-ai/blockdoc-python/raw/main/.claude/commands/add-to-changelog.md"&gt;&lt;code&gt;/add-to-changelog&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/berrydev-ai"&gt;berrydev-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Adds new entries to changelog files while maintaining format consistency, properly documenting changes, and following established project standards for version tracking.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jerseycheese/Narraitor/tree/feature/issue-227-ai-suggestions/.claude/commands/analyze-issue.md"&gt;&lt;code&gt;/create-docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/jerseycheese"&gt;jerseycheese&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Analyzes code structure and purpose to create comprehensive documentation detailing inputs/outputs, behavior, user interaction flows, and edge cases with error handling.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/slunsford/coffee-analytics/raw/main/.claude/commands/docs.md"&gt;&lt;code&gt;/docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/slunsford"&gt;slunsford&lt;/a&gt;&lt;br&gt; Generates comprehensive documentation that follows project structure, documenting APIs and usage patterns with consistent formatting for better user understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/explain-issue-fix.md"&gt;&lt;code&gt;/explain-issue-fix&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/hackdays-io"&gt;hackdays-io&lt;/a&gt;&lt;br&gt; Documents solution approaches for GitHub issues, explaining technical decisions, detailing challenges overcome, and providing implementation context for better understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Consiliency/Flutter-Structurizr/raw/main/.claude/commands/update-docs.md"&gt;&lt;code&gt;/update-docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Consiliency"&gt;Consiliency&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Reviews current documentation status, updates implementation progress, reviews phase documents, and maintains documentation consistency across the project.&lt;/p&gt; 
&lt;h3&gt;CI / Deployment&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/kelp/webdown/raw/main/.claude/commands/release.md"&gt;&lt;code&gt;/release&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/kelp"&gt;kelp&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Manages software releases by updating changelogs, reviewing README changes, evaluating version increments, and documenting release changes for better version tracking.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/run-ci.md"&gt;&lt;code&gt;/run-ci&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/hackdays-io"&gt;hackdays-io&lt;/a&gt;&lt;br&gt; Activates virtual environments, runs CI-compatible check scripts, iteratively fixes errors, and ensures all tests pass before completion.&lt;/p&gt; 
&lt;h3&gt;Project &amp;amp; Task Management&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/scopecraft/command/raw/main/.claude/commands/create-command.md"&gt;&lt;code&gt;/create-command&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/scopecraft"&gt;scopecraft&lt;/a&gt;&lt;br&gt; Guides Claude through creating new custom commands with proper structure by analyzing requirements, templating commands by category, enforcing command standards, and creating supporting documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-jtbd.md"&gt;&lt;code&gt;/create-jtbd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/taddyorg"&gt;taddyorg&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br&gt; Creates Jobs-to-be-Done frameworks that outline user needs with structured format, focusing on specific user problems and organizing by job categories for product development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-prd.md"&gt;&lt;code&gt;/create-prd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/taddyorg"&gt;taddyorg&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br&gt; Generates comprehensive product requirement documents outlining detailed specifications, requirements, and features following standardized document structure and format.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Wirasm/claudecode-utils/raw/main/.claude/commands/create-prp.md"&gt;&lt;code&gt;/create-prp&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Wirasm"&gt;Wirasm&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Creates product requirement plans by reading PRP methodology, following template structure, creating comprehensive requirements, and structuring product definitions for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/disler/just-prompt/raw/main/.claude/commands/project_hello_w_name.md"&gt;&lt;code&gt;/project_hello_w_name&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/disler"&gt;disler&lt;/a&gt;&lt;br&gt; Creates customizable greeting components with name input, demonstrating argument passing, component reusability, state management, and user input handling.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/chrisleyva/todo-slash-command/raw/main/todo.md"&gt;&lt;code&gt;/todo&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/chrisleyva"&gt;chrisleyva&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A convenient command to quickly manage project todo items without leaving the Claude Code interface, featuring due dates, sorting, task prioritization, and comprehensive todo list management.&lt;/p&gt; 
&lt;h3&gt;Miscellaneous&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/TuckerTucker/tkr-portfolio/raw/main/.claude/commands/five.md"&gt;&lt;code&gt;/five&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/TuckerTucker"&gt;TuckerTucker&lt;/a&gt;&lt;br&gt; Applies the "five whys" methodology to perform root cause analysis, identify underlying issues, and create solution approaches for complex problems.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/fixing_go_in_graph.md"&gt;&lt;code&gt;/fixing_go_in_graph&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br&gt; Focuses on Gene Ontology annotation integration in graph databases, handling multiple data sources, addressing graph representation issues, and ensuring correct data incorporation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/GaloyMoney/lana-bank/raw/main/.claude/commands/mermaid.md"&gt;&lt;code&gt;/mermaid&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/GaloyMoney"&gt;GaloyMoney&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Generates Mermaid diagrams from SQL schema files, creating entity relationship diagrams with table properties, validating diagram compilation, and ensuring complete entity coverage.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/review_dcell_model.md"&gt;&lt;code&gt;/review_dcell_model&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br&gt; Reviews old Dcell implementation files, comparing with newer Dango model, noting changes over time, and analyzing refactoring approaches for better code organization.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/zuplo/docs/raw/main/.claude/commands/use-stepper.md"&gt;&lt;code&gt;/use-stepper&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/zuplo"&gt;zuplo&lt;/a&gt;&lt;br&gt; Reformats documentation to use React Stepper component, transforming heading formats, applying proper indentation, and maintaining markdown compatibility with admonition formatting.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;CLAUDE.md Files 📂&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt; files&lt;/strong&gt; are files that contain important guidelines and context-specfic information or instructions that help Claude Code to better understand your project and your coding standards&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Language-Specific&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/didalgolab/ai-intellij-plugin/raw/main/CLAUDE.md"&gt;&lt;code&gt;AI IntelliJ Plugin&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/didalgolab"&gt;didalgolab&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Provides comprehensive Gradle commands for IntelliJ plugin development with platform-specific coding patterns, detailed package structure guidelines, and clear internationalization standards.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/alexei-led/aws-mcp-server/raw/main/CLAUDE.md"&gt;&lt;code&gt;AWS MCP Server&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/alexei-led"&gt;alexei-led&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Features multiple Python environment setup options with detailed code style guidelines, comprehensive error handling recommendations, and security considerations for AWS CLI interactions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/touchlab/DroidconKotlin/raw/main/CLAUDE.md"&gt;&lt;code&gt;DroidconKotlin&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/touchlab"&gt;touchlab&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Delivers comprehensive Gradle commands for cross-platform Kotlin Multiplatform development with clear module structure and practical guidance for dependency injection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/expectedparrot/edsl/raw/main/CLAUDE.md"&gt;&lt;code&gt;EDSL&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/expectedparrot"&gt;expectedparrot&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Offers detailed build and test commands with strict code style enforcement, comprehensive testing requirements, and standardized development workflow using Black and mypy.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/giselles-ai/giselle/raw/main/CLAUDE.md"&gt;&lt;code&gt;Giselle&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/giselles-ai"&gt;giselles-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Provides detailed build and test commands using pnpm and Vitest with strict code formatting requirements and comprehensive naming conventions for code consistency.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hashintel/hash/raw/main/CLAUDE.md"&gt;&lt;code&gt;HASH&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/hashintel"&gt;hashintel&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Features comprehensive repository structure breakdown with strong emphasis on coding standards, detailed Rust documentation guidelines, and systematic PR review process.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/inkline/inkline/raw/main/CLAUDE.md"&gt;&lt;code&gt;Inkline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/inkline"&gt;inkline&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Structures development workflow using pnpm with emphasis on TypeScript and Vue 3 Composition API, detailed component creation process, and comprehensive testing recommendations.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/mattgodbolt/jsbeeb/raw/main/CLAUDE.md"&gt;&lt;code&gt;JSBeeb&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/mattgodbolt"&gt;mattgodbolt&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br&gt; Provides development guide for JavaScript BBC Micro emulator with build and testing instructions, architecture documentation, and debugging workflows.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/LamoomAI/lamoom-python/raw/main/CLAUDE.md"&gt;&lt;code&gt;Lamoom Python&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/LamoomAI"&gt;LamoomAI&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Serves as reference for production prompt engineering library with load balancing of AI Models, API documentation, and usage patterns with examples.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langgraphjs/raw/main/CLAUDE.md"&gt;&lt;code&gt;LangGraphJS&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/langchain-ai"&gt;langchain-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Offers comprehensive build and test commands with detailed TypeScript style guidelines, layered library architecture, and monorepo structure using yarn workspaces.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/CLAUDE.md"&gt;&lt;code&gt;Metabase&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Details workflow for REPL-driven development in Clojure/ClojureScript with emphasis on incremental development, testing, and step-by-step approach for feature implementation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sgcarstrends/backend/raw/main/CLAUDE.md"&gt;&lt;code&gt;SG Cars Trends Backend&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/sgcarstrends"&gt;sgcarstrends&lt;/a&gt;&lt;br&gt; Provides comprehensive structure for TypeScript monorepo projects with detailed commands for development, testing, deployment, and AWS/Cloudflare integration.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/spylang/spy/raw/main/CLAUDE.md"&gt;&lt;code&gt;SPy&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/spylang"&gt;spylang&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Enforces strict coding conventions with comprehensive testing guidelines, multiple code compilation options, and backend-specific test decorators for targeted filtering.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/KarpelesLab/tpl/raw/master/CLAUDE.md"&gt;&lt;code&gt;TPL&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/KarpelesLab"&gt;KarpelesLab&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Details Go project conventions with comprehensive error handling recommendations, table-driven testing approach guidelines, and modernization suggestions for latest Go features.&lt;/p&gt; 
&lt;h3&gt;Domain-Specific&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/Layr-Labs/avs-vibe-developer-guide/raw/master/CLAUDE.md"&gt;&lt;code&gt;AVS Vibe Developer Guide&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Layr-Labs"&gt;Layr-Labs&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Structures AI-assisted EigenLayer AVS development workflow with consistent naming conventions for prompt files and established terminology standards for blockchain concepts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/CommE2E/comm/raw/master/CLAUDE.md"&gt;&lt;code&gt;Comm&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/CommE2E"&gt;CommE2E&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;BSD-3-Clause&lt;br&gt; Serves as a development reference for E2E-encrypted messaging applications with code organization architecture, security implementation details, and testing procedures.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/badass-courses/course-builder/raw/main/CLAUDE.md"&gt;&lt;code&gt;Course Builder&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/badass-courses"&gt;badass-courses&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Enables real-time multiplayer capabilities for collaborative course creation with diverse tech stack integration and monorepo architecture using Turborepo.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/eastlondoner/cursor-tools/raw/main/CLAUDE.md"&gt;&lt;code&gt;Cursor Tools&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/eastlondoner"&gt;eastlondoner&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Creates a versatile AI command interface supporting multiple providers and models with flexible command options and browser automation through "Stagehand" feature.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/soramimi/Guitar/raw/master/CLAUDE.md"&gt;&lt;code&gt;Guitar&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/soramimi"&gt;soramimi&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;GPL-2.0&lt;br&gt; Serves as development guide for Guitar Git GUI Client with build commands for various platforms, code style guidelines for contributing, and project structure explanation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Fimeg/NetworkChronicles/raw/legacy-v1/CLAUDE.md"&gt;&lt;code&gt;Network Chronicles&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Fimeg"&gt;Fimeg&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Presents detailed implementation plan for AI-driven game characters with technical specifications for LLM integration, character guidelines, and service discovery mechanics.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/different-ai/note-companion/raw/master/CLAUDE.md"&gt;&lt;code&gt;Note Companion&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/different-ai"&gt;different-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Provides detailed styling isolation techniques for Obsidian plugins using Tailwind with custom prefix to prevent style conflicts and practical troubleshooting steps.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ParetoSecurity/pareto-mac/raw/main/CLAUDE.md"&gt;&lt;code&gt;Pareto Mac&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ParetoSecurity"&gt;ParetoSecurity&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br&gt; Serves as development guide for Mac security audit tool with build instructions, contribution guidelines, testing procedures, and workflow documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steadycursor/steadystart/raw/main/CLAUDE.md"&gt;&lt;code&gt;SteadyStart&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt;&lt;br&gt; Clear and direct instructives about style, permissions, Claude's "role", communications, and documentation of Claude Code sessions for other team members to stay abreast.&lt;/p&gt; 
&lt;h3&gt;Project Scaffolding &amp;amp; MCP&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/basicmachines-co/basic-memory/raw/main/CLAUDE.md"&gt;&lt;code&gt;Basic Memory&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/basicmachines-co"&gt;basicmachines-co&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br&gt; Presents an innovative AI-human collaboration framework with Model Context Protocol for bidirectional LLM-markdown communication and flexible knowledge structure for complex projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/grahama1970/claude-code-mcp-enhanced/raw/main/CLAUDE.md"&gt;&lt;code&gt;claude-code-mcp-enhanced&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/grahama1970"&gt;grahama1970&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Provides detailed and emphatic instructions for Claude to follow as a coding agent, with testing guidance, code examples, and compliance checks.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Family-IT-Guy/perplexity-mcp/raw/main/CLAUDE.md"&gt;&lt;code&gt;Perplexity MCP&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Family-IT-Guy"&gt;Family-IT-Guy&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;ISC&lt;br&gt; Offers clear step-by-step installation instructions with multiple configuration options, detailed troubleshooting guidance, and concise architecture overview of the MCP protocol.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Official Documentation 🏛️&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Links to some of Anthropic's terrific documentation and resources regarding Claude Code&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!--lint disable double-link--&gt; 
&lt;p&gt;&lt;a href="https://docs.anthropic.com/en/docs/claude-code"&gt;&lt;code&gt;Anthropic Documentation&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;©&lt;br&gt; The official documentation for Claude Code, including installation instructions, usage guidelines, API references, tutorials, examples, loads of information that I won't list individually. Like Claude Code, the documentation is frequently updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/anthropics/anthropic-quickstarts/raw/main/CLAUDE.md"&gt;&lt;code&gt;Anthropic Quickstarts&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Offers comprehensive development guides for three distinct AI-powered demo projects with standardized workflows, strict code style guidelines, and containerization instructions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/anthropics/claude-code-action/tree/main/examples"&gt;&lt;code&gt;Claude Code GitHub Actions&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Official GitHub Actions integration for Claude Code with examples and documentation for automating AI-powered workflows in CI/CD pipelines.&lt;/p&gt; 
&lt;h2&gt;Contributing 🌻&lt;/h2&gt; 
&lt;p&gt;Please note that this project is released with a &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/code-of-conduct.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project you agree to abide by its terms.&lt;/p&gt; 
&lt;p&gt;Regarding content, we especially welcome:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Proven, effective resources that follow best practices and may even be in use in production.&lt;/li&gt; 
 &lt;li&gt;Innovative, creative, or experimental workflows that perhaps are still being iterated upon, but have high potential value, and push the boundaries of Claude Code's documented capabilities and use cases.&lt;/li&gt; 
 &lt;li&gt;Additional libraries and tooling that are built on top of Claude Code and offer enhanced functionality.&lt;/li&gt; 
 &lt;li&gt;Applications of Claude Code outside of the traditional "coding assistant" context, e.g., CI/CD integration, testing, documentation, dev-ops, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more information on how to contribute to this project. Or, fire up Claude Code and invoke the &lt;code&gt;/project:add-new-resource&lt;/code&gt; command and let Claude walk you through it!&lt;/p&gt; 
&lt;p&gt;If you have any suggestions or thoughts on how to improve the repo, or how to best organize the list, feel free to start a Discussion topic. This is meant to be for the Claude Code community, and in general I prefer not to act on sole authority.&lt;/p&gt; 
&lt;h3&gt;A note about licenses&lt;/h3&gt; 
&lt;p&gt;Because simply listing a hyperlink does not qualify as redistribution, the license of the original source is not relevant to its inclusion. However, for posterity and convenience, we do host copies of all resources whose license permits it. Therefore, please include information about the resource's license. Additionally, take note: &lt;em&gt;if you do not include a LICENSE in your GitHub repo, then by default it is fully copyrighted and redistribution is not allowed&lt;/em&gt;. So, if you are intending to make an open source project, it's critical to pick from one of the many available open source licenses. This is just a reminder that without a LICENSE, your project is not open source (it's merely source-code-available) - it may of course still be included on this list, but this notice is to inform readers about the default rules regarding GitHub and LICENSE files. See &lt;a href="https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/licensing-a-repository"&gt;here&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>KellerJordan/modded-nanogpt</title>
      <link>https://github.com/KellerJordan/modded-nanogpt</link>
      <description>&lt;p&gt;NanoGPT (124M) in 3 minutes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Modded-NanoGPT&lt;/h1&gt; 
&lt;p&gt;This repository hosts the &lt;em&gt;NanoGPT speedrun&lt;/em&gt;, in which we (collaboratively|competitively) search for the fastest algorithm to use 8 NVIDIA H100 GPUs to train a language model that attains 3.28 cross-entropy loss on the &lt;a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb"&gt;FineWeb&lt;/a&gt; validation set.&lt;/p&gt; 
&lt;p&gt;The target (3.28 validation loss on FineWeb) follows Andrej Karpathy's &lt;a href="https://github.com/karpathy/llm.c/discussions/481#:~:text=By%20the%20end%20of%20the%20optimization%20we%27ll%20get%20to%20about%203.29"&gt;GPT-2 replication in llm.c, which attains that loss after running for 45 minutes&lt;/a&gt;. The speedrun code also descends from llm.c's &lt;a href="https://github.com/karpathy/llm.c/raw/master/train_gpt2.py"&gt;PyTorch trainer&lt;/a&gt;, which itself descends from NanoGPT, hence the name of the repo. Thanks to the efforts of many contributors, this repo now contains a training algorithm which attains the target performance in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;3 minutes on 8xH100 (the llm.c GPT-2 replication needed 45)&lt;/li&gt; 
 &lt;li&gt;0.73B tokens (the llm.c GPT-2 replication needed 10B)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This improvement in training speed has been brought about by the following techniques:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modernized architecture: Rotary embeddings, QK-Norm, and ReLU²&lt;/li&gt; 
 &lt;li&gt;The Muon optimizer [&lt;a href="https://kellerjordan.github.io/posts/muon/"&gt;writeup&lt;/a&gt;] [&lt;a href="https://github.com/KellerJordan/Muon"&gt;repo&lt;/a&gt;]&lt;/li&gt; 
 &lt;li&gt;Untie head from embedding, use FP8 matmul for head, and softcap logits (the latter following Gemma 2)&lt;/li&gt; 
 &lt;li&gt;Initialization of projection and classification layers to zero (muP-like)&lt;/li&gt; 
 &lt;li&gt;Skip connections from embedding to every block as well as between blocks in U-net pattern&lt;/li&gt; 
 &lt;li&gt;Extra embeddings which are mixed into the values in attention layers (inspired by Zhou et al. 2024)&lt;/li&gt; 
 &lt;li&gt;FlexAttention with long-short sliding window attention pattern (inspired by Gemma 2) and window size warmup&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As well as many systems optimizations.&lt;/p&gt; 
&lt;p&gt;Contributors list (growing with each new record): &lt;a href="https://x.com/bozavlado"&gt;@bozavlado&lt;/a&gt;; &lt;a href="https://x.com/brendanh0gan"&gt;@brendanh0gan&lt;/a&gt;; &lt;a href="https://bsky.app/profile/fernbear.bsky.social"&gt;@fernbear.bsky.social&lt;/a&gt;; &lt;a href="https://x.com/Grad62304977"&gt;@Grad62304977&lt;/a&gt;; &lt;a href="https://x.com/jxbz"&gt;@jxbz&lt;/a&gt;; &lt;a href="https://x.com/kellerjordan0"&gt;@kellerjordan0&lt;/a&gt;; &lt;a href="https://x.com/KoszarskyB"&gt;@KoszarskyB&lt;/a&gt;; &lt;a href="https://x.com/@leloykun"&gt;@leloykun&lt;/a&gt;; &lt;a href="https://x.com/YouJiacheng"&gt;@YouJiacheng&lt;/a&gt;; &lt;a href="https://x.com/jadenj3o"&gt;@jadenj3o&lt;/a&gt;; &lt;a href="https://github.com/KonstantinWilleke"&gt;@KonstantinWilleke&lt;/a&gt;, &lt;a href="https://github.com/alexrgilbert"&gt;@alexrgilbert&lt;/a&gt;, &lt;a href="https://github.com/adricarda"&gt;@adricarda&lt;/a&gt;, &lt;a href="https://github.com/tuttyfrutyee"&gt;@tuttyfrutyee&lt;/a&gt;, &lt;a href="https://github.com/vdlad"&gt;@vdlad&lt;/a&gt;; &lt;a href="https://x.com/ryanyang0"&gt;@ryanyang0&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Running the current record&lt;/h2&gt; 
&lt;p&gt;To run the current record, run the following commands.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/KellerJordan/modded-nanogpt.git &amp;amp;&amp;amp; cd modded-nanogpt
pip install -r requirements.txt
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126 --upgrade
# downloads only the first 800M training tokens to save time
python data/cached_fineweb10B.py 8
./run.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note: torch.compile will add around 5 minutes of latency the first time you run the code.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Alternative: Running with Docker (recommended for precise timing)&lt;/h2&gt; 
&lt;p&gt;For cases where CUDA or NCCL versions aren't compatible with your current system setup, Docker can be a helpful alternative. This approach standardizes versions for CUDA, NCCL, CUDNN, and Python, reducing dependency issues and simplifying setup. Note: an NVIDIA driver must already be installed on the system (useful if only the NVIDIA driver and Docker are available).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/KellerJordan/modded-nanogpt.git &amp;amp;&amp;amp; cd modded-nanogpt
sudo docker build -t modded-nanogpt .
sudo docker run -it --rm --gpus all -v $(pwd):/modded-nanogpt modded-nanogpt python data/cached_fineweb10B.py 8
sudo docker run -it --rm --gpus all -v $(pwd):/modded-nanogpt modded-nanogpt sh run.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To get an interactive docker, you can use&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo docker run -it --rm --gpus all -v $(pwd):/modded-nanogpt modded-nanogpt bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;h2&gt;World record history&lt;/h2&gt; 
&lt;p&gt;The following is the historical progression of world speed records for the following competitive task:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Train a neural network to ≤3.28 validation loss on FineWeb using 8x NVIDIA H100s.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Note: The 3.28 target was selected to match &lt;a href="https://github.com/karpathy/llm.c/discussions/481"&gt;Andrej Karpathy's GPT-2 (small) reproduction&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Record time&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Date&lt;/th&gt; 
   &lt;th&gt;Log&lt;/th&gt; 
   &lt;th&gt;Contributors&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;45 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/karpathy/llm.c/discussions/481"&gt;llm.c baseline&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;05/28/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/101324_llmc/main.log"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@karpathy, llm.c contributors&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;31.4 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1798863559243513937"&gt;Tuned learning rate &amp;amp; rotary embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;06/06/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/060624_AdamW/f66d43d7-e449-4029-8adf-e8537bab49ea.log"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;24.9 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1842300916864844014"&gt;Introduced the Muon optimizer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/04/24&lt;/td&gt; 
   &lt;td&gt;none&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0, @jxbz&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;22.3 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1844820919061287009"&gt;Muon improvements&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/11/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/101024_Muon/eb5659d0-fb6a-49e5-a311-f1f89412f726.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0, @bozavlado&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;15.2 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1845865698532450646"&gt;Pad embeddings, ReLU², zero-init projections, QK-norm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/14/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/101424_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@Grad62304977, @kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;13.1 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1847291684016783746"&gt;Distributed the overhead of Muon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/18/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/101724_DistributedMuon/22d24867-eb5a-4fcc-ae2c-263d0277dfd1.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;12.0 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1847358578686152764"&gt;Upgraded PyTorch 2.5.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/18/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/101824_PyTorch25/d4bfb25f-688d-4da5-8743-33926fad4842.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;10.8 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1853188916704387239"&gt;Untied embedding and head&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/03/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/110324_UntieEmbed/d6b50d71-f419-4d26-bb39-a60d55ae7a04.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@Grad62304977, @kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9&lt;/td&gt; 
   &lt;td&gt;8.2 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1854296101303800108"&gt;Value and embedding skip connections, momentum warmup, logit softcap&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/06/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/110624_ShortcutsTweaks/dd7304a6-cc43-4d5e-adb8-c070111464a1.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@Grad62304977, @kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;7.8 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1855267054774865980"&gt;Bfloat16 activations&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/08/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/110824_CastBf16/a833bed8-2fa8-4cfe-af05-58c1cc48bc30.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;7.2 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1856053121103093922"&gt;U-net pattern skip connections &amp;amp; double lr&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/10/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/111024_UNetDoubleLr/c87bb826-797b-4f37-98c7-d3a5dad2de74.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@brendanh0gan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;5.03 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1859331370268623321"&gt;1024-ctx dense causal attention → 64K-ctx FlexAttention&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/19/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/111924_FlexAttention/8384493d-dba9-4991-b16b-8696953f5e6d.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@KoszarskyB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td&gt;4.66 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/hi_tysam/status/1860851011797053450"&gt;Attention window warmup&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/24/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/112424_WindowWarmup/cf9e4571-c5fc-4323-abf3-a98d862ec6c8.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@fernbear.bsky.social&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;4.41 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/KoszarskyB/status/1864746625572257852"&gt;Value Embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/04/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/120424_ValueEmbed"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@KoszarskyB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;3.95 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1865761473886347747"&gt;U-net pattern value embeddings, assorted code optimizations&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/08/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/120824_UNetValueEmbedsTweaks"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@leloykun, @YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;3.80 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1866734331559071981"&gt;Split value embeddings, block sliding window, separate block mask&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/10/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/121024_MFUTweaks"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;3.57 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1868938024731787640"&gt;Sparsify value embeddings, improve rotary embeddings, drop an attn layer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/17/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/121724_SparsifyEmbeds"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;3.4 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1876048851158880624"&gt;Lower logit softcap from 30 to 15&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/04/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/010425_SoftCap/31d6c427-f1f7-4d8a-91be-a67b5dcd13fd.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@KoszarskyB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;3.142 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1878827972519772241"&gt;FP8 head, offset logits, lr decay to 0.1 instead of 0.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/13/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/011325_Fp8LmHead/c51969c2-d04c-40a7-bcea-c092c3c2d11a.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;2.992 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/leloykun/status/1880301753213809016"&gt;Merged QKV weights, long-short attention, attention scale, lower Adam epsilon, batched Muon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/16/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/011625_Sub3Min/1d3bd93b-a69e-4118-aeb8-8184239d7566.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@leloykun, @fernbear.bsky.social, @YouJiacheng, @brendanh0gan, @scottjmaddox, @Grad62304977&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;2.933 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/leloykun/status/1885640350368420160"&gt;Reduced batch size&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/26/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/012625_BatchSize/c44090cc-1b99-4c95-8624-38fb4b5834f9.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@leloykun&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;2.997 minutes&lt;/td&gt; 
   &lt;td&gt;21st record with new timing&lt;/td&gt; 
   &lt;td&gt;02/01/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/020125_RuleTweak/eff63a8c-2f7e-4fc5-97ce-7f600dae0bc7.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;not a new record, just re-timing #21 with the &lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/#timing-change-after-record-21"&gt;updated rules&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;3.014 minutes&lt;/td&gt; 
   &lt;td&gt;21st record with latest torch&lt;/td&gt; 
   &lt;td&gt;05/24/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/052425_StableTorch/89d9f224-3b01-4581-966e-358d692335e0.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;not a new record, just re-timing #21 with latest torch&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;2.990 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/KonstantinWille/status/1927137223238909969"&gt;Faster gradient all-reduce&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;05/24/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/052425_FasterReduce/23f40b75-06fb-4c3f-87a8-743524769a35.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@KonstantinWilleke, @alexrgilbert, @adricarda, @tuttyfrutyee, @vdlad; The Enigma project&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;2.979 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1927460573098262616"&gt;Overlap computation and gradient communication&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;05/25/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/052525_EvenFasterReduce/6ae86d05-5cb2-4e40-a512-63246fd08e45.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@ryanyang0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;2.966 minutes&lt;/td&gt; 
   &lt;td&gt;Replace gradient all_reduce with reduce_scatter&lt;/td&gt; 
   &lt;td&gt;05/30/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/053025_noallreduce/8054c239-3a18-499e-b0c8-dbd27cb4b3ab.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@vagrawal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;2.896 minutes&lt;/td&gt; 
   &lt;td&gt;Upgrade PyTorch to 2.9.0.dev20250713+cu126&lt;/td&gt; 
   &lt;td&gt;07/13/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/071325_UpgradeTorch190/692f80e0-5e64-4819-97d4-0dc83b7106b9.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;2.863 minutes&lt;/td&gt; 
   &lt;td&gt;Align training batch starts with EoS, increase cooldown frac to .45&lt;/td&gt; 
   &lt;td&gt;07/13/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/071225_BosAlign/c1fd8a38-bb9f-45c4-8af0-d37f70c993f3.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@ClassicLarry&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Rules&lt;/h2&gt; 
&lt;p&gt;The only rules are that new records must:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Not modify the train or validation data pipelines. (You can change the batch size, sequence length, attention structure etc.; just don't change the underlying streams of tokens.)&lt;/li&gt; 
 &lt;li&gt;Attain ≤3.28 mean val loss. (Due to inter-run variance, submissions must provide enough run logs to attain a statistical significance level of p&amp;lt;0.01 that their mean val loss is ≤3.28. Example code to compute p-value can be found &lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/010425_SoftCap#softer-softcap"&gt;here&lt;/a&gt;. For submissions which improve speed by optimizing the systems performance, without touching the ML, this requirement is waived.)&lt;/li&gt; 
 &lt;li&gt;Not use any extra &lt;code&gt;torch._inductor.config&lt;/code&gt; or &lt;code&gt;torch.compile&lt;/code&gt; flags. (These can save a few seconds, but they can also make compilation take &amp;gt;30min. This rule was introduced after the 21st record.)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: &lt;code&gt;torch._inductor.config.coordinate_descent_tuning&lt;/code&gt; is allowed for GPT-2 Medium track (a.k.a. 2.92 track).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Other than that, anything and everything is fair game!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/KellerJordan/modded-nanogpt/discussions/23?sort=new#discussioncomment-12109560"&gt;further clarifications&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;Comment on the target metric&lt;/h3&gt; 
&lt;p&gt;The target metric is &lt;em&gt;cross-entropy loss on the FineWeb val set&lt;/em&gt;. To speak mathematically, the goal of the speedrun is *to obtain a probability model of language which assigns a probability of at least &lt;code&gt;math.exp(-3.28 * 10485760)&lt;/code&gt; to the first 10,485,760 tokens of the FineWeb valset. Hence, e.g., we allow evaluation at any sequence length, so long as we still have a valid probability model of language.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;Timing change after record 21&lt;/h3&gt; 
&lt;p&gt;After the 21st record, we made two changes to the timing. First, there used to be an initial "grace period" of 10 untimed steps to allow kernel warmup. We replaced this with an explicit kernel-warmup section which is untimed and uses dummy data. This results in an extra runtime of 850ms from the 10 extra timed steps. Second, we banned the use of &lt;code&gt;torch._inductor.config.coordinate_descent_tuning&lt;/code&gt;. This saves ~25min of untimed pre-run compilation, but results in an extra runtime of ~3s.&lt;/p&gt; 
&lt;!--Note: The original llm.c baseline is intended to be closer to a replication of GPT-2 than to an optimized LLM training.
So it's no surprise that there is room to improve; as @karpathy has said, 'llm.c still has a lot of pending optimizations.'
In addition, many of the techniques used in these records are completely standard, such as rotary embeddings.
The goal of this benchmark/speedrun is simply to find out which techniques actually work, and maybe come up with some new ones.--&gt; 
&lt;!--The goal of this benchmark is simply to find out all the techniques which actually work, because I'm going crazy reading all these
LLM training papers
which claim a huge benefit but then use their own idiosyncratic non-competitive benchmark and therefore no one in the community has any idea if it's legit for months.--&gt; 
&lt;!--[LLM](https://arxiv.org/abs/2305.14342) [training](https://arxiv.org/abs/2402.17764) [papers](https://arxiv.org/abs/2410.01131)--&gt; 
&lt;!--I mean hello??? We're in a completely empirical field; it is insane to not have a benchmark. Ideally everyone uses the same LLM training benchmark,
and then reviewing LLM training papers becomes as simple as checking if they beat the benchmark. It's not like this would be unprecedented, that's how things
were in the ImageNet days.
The only possible 'benefit' I can think of for any empirical field to abandon benchmarks is that it would make it easier to publish false results. Oh, I guess that's why it happened.
Hilarious to think about how, in the often-commented-upon and ongoing collapse of the peer review system, people blame the *reviewers* --
yeah, those guys doing free labor who everyone constantly musters all of their intelligence to lie to, it's *their* fault! My bad, you caught me monologuing.--&gt; 
&lt;hr&gt; 
&lt;h3&gt;Important note about records 22-25&lt;/h3&gt; 
&lt;p&gt;Thanks to the statistical testing of &lt;a href="https://www.github.com/agrawal"&gt;@agrawal&lt;/a&gt; (holder of the 24th record), we have learned that records 23, 24, and in all likelihood 22 and 25, actually attain a mean loss of 3.281, which is slightly above the 3.28 target. Therefore if we were to completely adhere to the speedrun rules, we would have to deny that these are valid records. However, we have decided to leave them in place as valid, because of the following two reasons: (a) the extra loss is most likely my (@kellerjordan0) own fault rather than that of the records, and (b) it is most likely easily addressable.&lt;/p&gt; 
&lt;p&gt;Here's what happened: Records #22 to #25 each change only the systems/implementation of the speedrun. Therefore, the requirement to do statistical testing to confirm they hit the target was waived, since in theory they should have hit it automatically, by virtue of the fact that they didn't touch the ML (i.e., they didn't change the architecture, learning rate, etc.).&lt;/p&gt; 
&lt;p&gt;So if these records shouldn't have changed the ML, what explains the regression in val loss? We think that most likely, the answer is that this regression was indeed not introduced by any of these records. Instead, it was probably caused by my own non-record in which I retimed record #21 with newest torch, because in this non-record I also changed the constants used to cast the lm_head to fp8. I thought that this change should cause only a (small) strict improvement, but apparently that was not the case.&lt;/p&gt; 
&lt;p&gt;Therefore, it is probable that each of records #22-25 could be easily made fully valid by simply reverting the change I made to those constants. Therefore they shall be upheld as valid records.&lt;/p&gt; 
&lt;p&gt;For the future, fortunately record #26 brought the speedrun back into the green in terms of &amp;lt;3.28 loss, so (with high p-value) it should be in a good state now.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;Notable attempts &amp;amp; forks&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Notable runs:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://x.com/alexjc/status/1881410039639863622"&gt;@alexjc's 01/20/2025 2.77-minute TokenMonster-based record&lt;/a&gt;. This record is technically outside the rules of the speedrun, since we specified that the train/val tokens must be kept fixed. However, it's very interesting, and worth including. The run is not more data-efficient; rather, the speedup comes from the improved tokenizer allowing the vocabulary size to be reduced (nearly halved!) while preserving the same bytes-per-token, which saves lots of parameters and FLOPs in the head and embeddings.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Notable forks:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BlinkDL/modded-nanogpt-rwkv"&gt;https://github.com/BlinkDL/modded-nanogpt-rwkv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nikhilvyas/modded-nanogpt-SOAP"&gt;https://github.com/nikhilvyas/modded-nanogpt-SOAP&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;Speedrun track 2: GPT-2 Medium&lt;/h2&gt; 
&lt;p&gt;The target loss for this track is lowered from 3.28 to 2.92, as per Andrej Karpathy's 350M-parameter llm.c baseline. This baseline generates a model with performance similar to the original GPT-2 Medium, whereas the first track's baseline generates a model on par with GPT-2 Small. All other rules remain the same.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: &lt;code&gt;torch._inductor.config.coordinate_descent_tuning&lt;/code&gt; is turned on after the record 6 (*).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Record time&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Date&lt;/th&gt; 
   &lt;th&gt;Log&lt;/th&gt; 
   &lt;th&gt;Contributors&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;5.8 hours&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/karpathy/llm.c/discussions/481"&gt;llm.c baseline (350M parameters)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;05/28/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/011825_GPT2Medium/main.log"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@karpathy, llm.c contributors&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;29.3 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1881959719012847703"&gt;Initial record based on scaling up the GPT-2 small track speedrun&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/18/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/011825_GPT2Medium/241dd7a7-3d76-4dce-85a4-7df60387f32a.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;28.1 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1888320690543284449"&gt;Added standard weight decay&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;02/08/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/020825_GPT2MediumWeightDecay/b01743db-605c-4326-b5b1-d388ee5bebc5.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;27.7 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/leloykun/status/1892793848163946799"&gt;Tuned Muon Newton-Schulz coefficients&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;02/14/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/021425_GPT2MediumOptCoeffs/1baa66b2-bff7-4850-aced-d63885ffb4b6.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@leloykun&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;27.2 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/030625_GPT2MediumLongerCooldown/779c041a-2a37-45d2-a18b-ec0f223c2bb7.txt"&gt;Increased learning rate cooldown phase duration&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;03/06/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/030625_GPT2MediumLongerCooldown/779c041a-2a37-45d2-a18b-ec0f223c2bb7.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;25.95 minutes*&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1905861218138804534"&gt;2x MLP wd, qkv norm, all_reduce/opt.step() overlap, optimized skip pattern&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;03/25/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/032525_GPT2MediumArchOptTweaks/train_gpt-20250329.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;25.29 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1912570883878842527"&gt;Remove FP8 head; ISRU logits softcap; New sharded mixed precision Muon; merge weights&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;04/16/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/041625_GPT2Medium_Record7/223_3310d0b1-b24d-48ee-899f-d5c2a254a195.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;24.50 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/jadenj3o/status/1914893086276169754"&gt;Cubic sliding window size schedule, 2× max window size (24.84 minutes)&lt;/a&gt; &lt;a href="https://x.com/YouJiacheng/status/1915667616913645985"&gt;24.5min repro&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;04/22/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/042225_GPT2Medium_Record8/075_640429f2-e726-4e83-aa27-684626239ffc.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@jadenj3o&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h3&gt;Q: What is the point of NanoGPT speedrunning?&lt;/h3&gt; 
&lt;p&gt;A: The officially stated goal of NanoGPT speedrunning is as follows: &lt;code&gt;gotta go fast&lt;/code&gt;. But for something a little more verbose involving an argument for good benchmarking, here's some kind of manifesto, adorned with a blessing from the master. &lt;a href="https://x.com/karpathy/status/1846790537262571739"&gt;https://x.com/karpathy/status/1846790537262571739&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Q: What makes "NanoGPT speedrunning" not just another idiosyncratic benchmark?&lt;/h3&gt; 
&lt;p&gt;A: Because it is a &lt;em&gt;competitive&lt;/em&gt; benchmark. In particular, if you attain a new speed record (using whatever method you want), there is an open invitation for you to post that record (on arXiv or X) and thereby vacuum up all the clout for yourself. I will even help you do it by reposting you as much as I can.&lt;/p&gt; 
&lt;!--On the contrary, for example, the benchmark used in the [Sophia](https://arxiv.org/abs/2305.14342) paper does *not* have this property.
There is no such open invitation for anyone to compete on the benchmark they used. In particular, if, for a random and definitely not weirdly specific example, you happen to find better AdamW hyperparameters for their training setup than
the ones they used which significantly close the gap between AdamW and their proposed optimizer,
then there is no clear path for you to publish that result in *any* form.
You could try posting it on X.com, but then you would be risking being perceived as aggressive/confrontational, which is *not a good look* in this racket.
So if you're rational, the result probably just dies with you and no one else learns anything
(unless you're in a frontier lab, in which case you can do a nice internal writeup. Boy I'd love to get my hands on those writeups).--&gt; 
&lt;p&gt;&lt;a href="https://www.argmin.net/p/too-much-information"&gt;"Artificial intelligence advances by inventing games and gloating to goad others to play" - Professor Ben Recht&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Q: NanoGPT speedrunning is cool and all, but meh it probably won't scale and is just overfitting to val loss&lt;/h3&gt; 
&lt;p&gt;A: This is hard to refute, since "at scale" is an infinite category (what if the methods stop working only for &amp;gt;100T models?), making it impossible to fully prove. Also, I would agree that some of the methods used in the speedrun are unlikely to scale, particularly those which &lt;em&gt;impose additional structure&lt;/em&gt; on the network, such as logit softcapping. But if the reader cares about 1.5B models, they might be convinced by this result:&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Straightforwardly scaling up the speedrun (10/18/24 version) to 1.5B parameters yields a model with GPT-2 (1.5B)-level HellaSwag performance 2.5x more cheaply than &lt;a href="https://github.com/karpathy/llm.c/discussions/677"&gt;@karpathy's baseline&lt;/a&gt; ($233 instead of $576):&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/img/nanogpt_speedrun51.png" alt=""&gt; [&lt;a href="https://github.com/KellerJordan/modded-nanogpt/raw/master/records/102024_ScaleUp1B/ad8d7ae5-7b2d-4ee9-bc52-f912e9174d7a.txt"&gt;reproducible log&lt;/a&gt;] &lt;img src="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/img/nanogpt_speedrun52.png" alt=""&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;a href="https://github.com/KellerJordan/Muon"&gt;Muon optimizer&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Muon is defined as follows:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/img/algo_optimizer.png" alt=""&gt;&lt;/p&gt; 
&lt;p&gt;Where NewtonSchulz5 is the following Newton-Schulz iteration [2, 3], which approximately replaces &lt;code&gt;G&lt;/code&gt; with &lt;code&gt;U @ V.T&lt;/code&gt; where &lt;code&gt;U, S, V = G.svd()&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@torch.compile
def zeroth_power_via_newtonschulz5(G, steps=5, eps=1e-7):
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16() / (G.norm() + eps)
    if G.size(0) &amp;gt; G.size(1):
        X = X.T 
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A
        X = a * X + B @ X
    if G.size(0) &amp;gt; G.size(1):
        X = X.T 
    return X.to(G.dtype)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For this training scenario, Muon has the following favorable properties:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Lower memory usage than Adam&lt;/li&gt; 
 &lt;li&gt;~1.5x better sample-efficiency&lt;/li&gt; 
 &lt;li&gt;&amp;lt;2% wallclock overhead&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provenance&lt;/h3&gt; 
&lt;p&gt;Many of the choices made to generate this optimizer were obtained experimentally by our pursuit of &lt;a href="https://github.com/KellerJordan/cifar10-airbench"&gt;CIFAR-10 speedrunning&lt;/a&gt;. In particular, we experimentally obtained the following practices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Using Nesterov momentum inside the update, with orthogonalization applied after momentum.&lt;/li&gt; 
 &lt;li&gt;Using a specifically quintic Newton-Schulz iteration as the method of orthogonalization.&lt;/li&gt; 
 &lt;li&gt;Using non-convergent coefficients for the quintic polynomial in order to maximize slope at zero, and thereby minimize the number of necessary Newton-Schulz iterations. It turns out that the variance doesn't actually matter that much, so we end up with a quintic that rapidly converges to the range 0.68, 1.13 upon repeated application, rather than converging more slowly to 1.&lt;/li&gt; 
 &lt;li&gt;Running the Newton-Schulz iteration in bfloat16 (whereas Shampoo implementations often depend on inverse-pth-roots run in fp32 or fp64).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Our use of a Newton-Schulz iteration for orthogonalization traces to &lt;a href="https://arxiv.org/abs/2409.20325"&gt;Bernstein &amp;amp; Newhouse (2024)&lt;/a&gt;, who suggested it as a way to compute Shampoo [5, 6] preconditioners, and theoretically explored Shampoo without preconditioner accumulation. In particular, Jeremy Bernstein @jxbz sent us the draft, which caused us to experiment with various Newton-Schulz iterations as the orthogonalization method for this optimizer. If we had used SVD instead of a Newton-Schulz iteration, this optimizer would have been too slow to be useful. Bernstein &amp;amp; Newhouse also pointed out that Shampoo without preconditioner accumulation is equivalent to steepest descent in the spectral norm, and therefore Shampoo can be thought of as a way to smooth out spectral steepest descent. The proposed optimizer can be thought of as a second way of smoothing spectral steepest descent, with a different set of memory and runtime tradeoffs compared to Shampoo.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Running on fewer GPUs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;To run experiments on fewer GPUs, simply modify &lt;code&gt;run.sh&lt;/code&gt; to have a different &lt;code&gt;--nproc_per_node&lt;/code&gt;. This should not change the behavior of the training.&lt;/li&gt; 
 &lt;li&gt;If you're running out of memory, you may need to reduce the sequence length for FlexAttention (which does change the training. see &lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/38"&gt;here&lt;/a&gt; for a guide)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;References&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2406.17557"&gt;Guilherme Penedo et al. "The fineweb datasets: Decanting the web for the finest text data at scale." arXiv preprint arXiv:2406.17557 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Nicholas J. Higham. Functions of Matrices. Society for Industrial and Applied Mathematics (2008). Equation 5.22.&lt;/li&gt; 
 &lt;li&gt;GÃ¼nther Schulz. Iterative Berechnung der reziproken Matrix. Z. Angew. Math. Mech., 13:57â59 (1933).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2409.20325"&gt;Jeremy Bernstein and Laker Newhouse. "Old Optimizer, New Norm: An Anthology." arxiv preprint arXiv:2409.20325 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/1802.09568"&gt;Vineet Gupta, Tomer Koren, and Yoram Singer. "Shampoo: Preconditioned stochastic tensor optimization." International Conference on Machine Learning. PMLR, 2018.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2002.09018"&gt;Rohan Anil et al. "Scalable second order optimization for deep learning." arXiv preprint arXiv:2002.09018 (2020).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2405.18392"&gt;Alexander HÃ¤gele et al. "Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations." arXiv preprint arXiv:2405.18392 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2410.17897"&gt;Zhanchao Zhou et al. "Value Residual Learning For Alleviating Attention Concentration In Transformers." arXiv preprint arXiv:2410.17897 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2408.00118"&gt;Team, Gemma, et al. "Gemma 2: Improving open language models at a practical size." arXiv preprint arXiv:2408.00118 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"&gt;Alec Radford et al. "Language models are unsupervised multitask learners." OpenAI blog 1.8 (2019).&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@misc{modded_nanogpt_2024,
  author       = {Keller Jordan and Jeremy Bernstein and Brendan Rappazzo and
                  @fernbear.bsky.social and Boza Vlado and You Jiacheng and
                  Franz Cesista and Braden Koszarsky and @Grad62304977},
  title        = {modded-nanogpt: Speedrunning the NanoGPT baseline},
  year         = {2024},
  url          = {https://github.com/KellerJordan/modded-nanogpt}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;img src="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/img/dofa.jpg" alt="itsover_wereback" style="width:100%;"&gt;</description>
    </item>
    
    <item>
      <title>microsoft/markitdown</title>
      <link>https://github.com/microsoft/markitdown</link>
      <description>&lt;p&gt;Python tool for converting files and office documents to Markdown.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MarkItDown&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/markitdown/"&gt;&lt;img src="https://img.shields.io/pypi/v/markitdown.svg?sanitize=true" alt="PyPI"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/dd/markitdown" alt="PyPI - Downloads"&gt; &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue" alt="Built by AutoGen Team"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See &lt;a href="https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp"&gt;markitdown-mcp&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Breaking changes between 0.0.1 to 0.1.0:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dependencies are now organized into optional feature-groups (further details below). Use &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt; to have backward-compatible behavior.&lt;/li&gt; 
  &lt;li&gt;convert_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.&lt;/li&gt; 
  &lt;li&gt;The DocumentConverter class interface has changed to read from file-like streams rather than file paths. &lt;em&gt;No temporary files are created anymore&lt;/em&gt;. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to &lt;a href="https://github.com/deanmalmgren/textract"&gt;textract&lt;/a&gt;, but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.&lt;/p&gt; 
&lt;p&gt;MarkItDown currently supports the conversion from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDF&lt;/li&gt; 
 &lt;li&gt;PowerPoint&lt;/li&gt; 
 &lt;li&gt;Word&lt;/li&gt; 
 &lt;li&gt;Excel&lt;/li&gt; 
 &lt;li&gt;Images (EXIF metadata and OCR)&lt;/li&gt; 
 &lt;li&gt;Audio (EXIF metadata and speech transcription)&lt;/li&gt; 
 &lt;li&gt;HTML&lt;/li&gt; 
 &lt;li&gt;Text-based formats (CSV, JSON, XML)&lt;/li&gt; 
 &lt;li&gt;ZIP files (iterates over contents)&lt;/li&gt; 
 &lt;li&gt;Youtube URLs&lt;/li&gt; 
 &lt;li&gt;EPubs&lt;/li&gt; 
 &lt;li&gt;... and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Markdown?&lt;/h2&gt; 
&lt;p&gt;Markdown is extremely close to plain text, with minimal markup or formatting, but still provides a way to represent important document structure. Mainstream LLMs, such as OpenAI's GPT-4o, natively "&lt;em&gt;speak&lt;/em&gt;" Markdown, and often incorporate Markdown into their responses unprompted. This suggests that they have been trained on vast amounts of Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions are also highly token-efficient.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;MarkItDown requires Python 3.10 or higher. It is recommended to use a virtual environment to avoid dependency conflicts.&lt;/p&gt; 
&lt;p&gt;With the standard Python installation, you can create and activate a virtual environment using the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If using &lt;code&gt;uv&lt;/code&gt;, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv --python=3.12 .venv
source .venv/bin/activate
# NOTE: Be sure to use 'uv pip install' rather than just 'pip install' to install packages in this virtual environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using Anaconda, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n markitdown python=3.12
conda activate markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install MarkItDown, use pip: &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt;. Alternatively, you can install it from the source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e 'packages/markitdown[all]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Command-Line&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf &amp;gt; document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;code&gt;-o&lt;/code&gt; to specify the output file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pipe content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat path-to-file.pdf | markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Dependencies&lt;/h3&gt; 
&lt;p&gt;MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the &lt;code&gt;[all]&lt;/code&gt; option. However, you can also install them individually for more control. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'markitdown[pdf, docx, pptx]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will install only the dependencies for PDF, DOCX, and PPTX files.&lt;/p&gt; 
&lt;p&gt;At the moment, the following optional dependencies are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[all]&lt;/code&gt; Installs all optional dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pptx]&lt;/code&gt; Installs dependencies for PowerPoint files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[docx]&lt;/code&gt; Installs dependencies for Word files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xlsx]&lt;/code&gt; Installs dependencies for Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xls]&lt;/code&gt; Installs dependencies for older Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pdf]&lt;/code&gt; Installs dependencies for PDF files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[outlook]&lt;/code&gt; Installs dependencies for Outlook messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[az-doc-intel]&lt;/code&gt; Installs dependencies for Azure Document Intelligence&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[audio-transcription]&lt;/code&gt; Installs dependencies for audio transcription of wav and mp3 files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[youtube-transcription]&lt;/code&gt; Installs dependencies for fetching YouTube video transcription&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Plugins&lt;/h3&gt; 
&lt;p&gt;MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --list-plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To enable plugins use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --use-plugins path-to-file.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find available plugins, search GitHub for the hashtag &lt;code&gt;#markitdown-plugin&lt;/code&gt;. To develop a plugin, see &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Azure Document Intelligence&lt;/h3&gt; 
&lt;p&gt;To use Microsoft Document Intelligence for conversion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md -d -e "&amp;lt;document_intelligence_endpoint&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More information about how to set up an Azure Document Intelligence Resource can be found &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Python API&lt;/h3&gt; 
&lt;p&gt;Basic usage in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert("test.xlsx")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Document Intelligence conversion in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint="&amp;lt;document_intelligence_endpoint&amp;gt;")
result = md.convert("test.pdf")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use Large Language Models for image descriptions, provide &lt;code&gt;llm_client&lt;/code&gt; and &lt;code&gt;llm_model&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model="gpt-4o")
result = md.convert("example.jpg")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &amp;lt; ~/your-file.pdf &amp;gt; output.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;p&gt;You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are ofcourse just suggestions and you are welcome to contribute in any way you like.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;All&lt;/th&gt; 
    &lt;th&gt;Especially Needs Help from Community&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues"&gt;All Issues&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22"&gt;Issues open for contribution&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;PRs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls"&gt;All PRs&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22"&gt;PRs open for reviewing&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;Running Tests and Checks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to the MarkItDown package:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;cd packages/markitdown
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;code&gt;hatch&lt;/code&gt; in your environment and run tests:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
hatch shell
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(Alternative) Use the Devcontainer which has all the dependencies installed:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;# Reopen the project in Devcontainer and run:
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run pre-commit checks before submitting a PR: &lt;code&gt;pre-commit run --all-files&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing 3rd-party Plugins&lt;/h3&gt; 
&lt;p&gt;You can also contribute by creating and sharing 3rd party plugins. See &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/open_deep_research</title>
      <link>https://github.com/langchain-ai/open_deep_research</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open Deep Research&lt;/h1&gt; 
&lt;img width="1388" height="298" alt="full_diagram" src="https://github.com/user-attachments/assets/12a2371b-8be2-4219-9b48-90503eb43c69"&gt; 
&lt;p&gt;Deep research has broken out as one of the most popular agent applications. This is a simple, configurable, fully open source deep research agent that works across many model providers, search tools, and MCP servers.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read more in our &lt;a href="https://blog.langchain.com/open-deep-research/"&gt;blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See our &lt;a href="https://www.youtube.com/watch?v=agGiWUpxkhg"&gt;video&lt;/a&gt; for a quick overview&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🚀 Quickstart&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository and activate a virtual environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install -r pyproject.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up your &lt;code&gt;.env&lt;/code&gt; file to customize the environment variables (for model selection, search tools, and other configuration settings):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Launch the assistant with the LangGraph server locally to open LangGraph Studio in your browser:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies and start the LangGraph server
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev --allow-blocking
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use this to open the Studio UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;- 🚀 API: http://127.0.0.1:2024
- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- 📚 API Docs: http://127.0.0.1:2024/docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;img width="817" height="666" alt="Screenshot 2025-07-13 at 11 21 12 PM" src="https://github.com/user-attachments/assets/052f2ed3-c664-4a4f-8ec2-074349dcaa3f"&gt; 
&lt;p&gt;Ask a question in the &lt;code&gt;messages&lt;/code&gt; input field and click &lt;code&gt;Submit&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Configurations&lt;/h3&gt; 
&lt;p&gt;Open Deep Research offers extensive configuration options to customize the research process and model behavior. All configurations can be set via the web UI, environment variables, or by modifying the configuration directly.&lt;/p&gt; 
&lt;h4&gt;General Settings&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Max Structured Output Retries&lt;/strong&gt; (default: 3): Maximum number of retries for structured output calls from models when parsing fails&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Allow Clarification&lt;/strong&gt; (default: true): Whether to allow the researcher to ask clarifying questions before starting research&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Max Concurrent Research Units&lt;/strong&gt; (default: 5): Maximum number of research units to run concurrently using sub-agents. Higher values enable faster research but may hit rate limits&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Research Configuration&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Search API&lt;/strong&gt; (default: Tavily): Choose from Tavily (works with all models), OpenAI Native Web Search, Anthropic Native Web Search, or None&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Max Researcher Iterations&lt;/strong&gt; (default: 3): Number of times the Research Supervisor will reflect on research and ask follow-up questions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Max React Tool Calls&lt;/strong&gt; (default: 5): Maximum number of tool calling iterations in a single researcher step&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Models&lt;/h4&gt; 
&lt;p&gt;Open Deep Research uses multiple specialized models for different research tasks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Summarization Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1-nano&lt;/code&gt;): Summarizes research results from search APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Conducts research and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1-mini&lt;/code&gt;): Compresses research findings from sub-agents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Final Report Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Writes the final comprehensive report&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All models are configured using &lt;a href="https://python.langchain.com/docs/how_to/chat_models_universal_init/"&gt;init_chat_model() API&lt;/a&gt; which supports providers like OpenAI, Anthropic, Google Vertex AI, and others.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important Model Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Structured Outputs&lt;/strong&gt;: All models must support structured outputs. Check support &lt;a href="https://python.langchain.com/docs/integrations/chat/"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Search API Compatibility&lt;/strong&gt;: Research and Compression models must support your selected search API:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Anthropic search requires Anthropic models with web search capability&lt;/li&gt; 
   &lt;li&gt;OpenAI search requires OpenAI models with web search capability&lt;/li&gt; 
   &lt;li&gt;Tavily works with all models&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tool Calling&lt;/strong&gt;: All models must support tool calling functionality&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Special Configurations&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;For OpenRouter: Follow &lt;a href="https://github.com/langchain-ai/open_deep_research/issues/75#issuecomment-2811472408"&gt;this guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;For local models via Ollama: See &lt;a href="https://github.com/langchain-ai/open_deep_research/issues/65#issuecomment-2743586318"&gt;setup instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Example MCP (Model Context Protocol) Servers&lt;/h4&gt; 
&lt;p&gt;Open Deep Research supports MCP servers to extend research capabilities.&lt;/p&gt; 
&lt;h4&gt;Local MCP Servers&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Filesystem MCP Server&lt;/strong&gt; provides secure file system operations with robust access control:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read, write, and manage files and directories&lt;/li&gt; 
 &lt;li&gt;Perform operations like reading file contents, creating directories, moving files, and searching&lt;/li&gt; 
 &lt;li&gt;Restrict operations to predefined directories for security&lt;/li&gt; 
 &lt;li&gt;Support for both command-line configuration and dynamic MCP roots&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mcp-server-filesystem /path/to/allowed/dir1 /path/to/allowed/dir2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Remote MCP Servers&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Remote MCP servers&lt;/strong&gt; enable distributed agent coordination and support streamable HTTP requests. Unlike local servers, they can be multi-tenant and require more complex authentication.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Arcade MCP Server Example&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "url": "https://api.arcade.dev/v1/mcps/ms_0ujssxh0cECutqzMgbtXSGnjorm",
  "tools": ["Search_SearchHotels", "Search_SearchOneWayFlights", "Search_SearchRoundtripFlights"]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Remote servers can be configured as authenticated or unauthenticated and support JWT-based authentication through OAuth endpoints.&lt;/p&gt; 
&lt;h3&gt;Evaluation&lt;/h3&gt; 
&lt;p&gt;A comprehensive batch evaluation system designed for detailed analysis and comparative studies.&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-dimensional Scoring&lt;/strong&gt;: Specialized evaluators with 0-1 scale ratings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dataset-driven Evaluation&lt;/strong&gt;: Batch processing across multiple test cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Usage:&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run comprehensive evaluation on LangSmith datasets
python tests/run_evaluate.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;Key Files:&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tests/run_evaluate.py&lt;/code&gt;: Main evaluation script&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tests/evaluators.py&lt;/code&gt;: Specialized evaluator functions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tests/prompts.py&lt;/code&gt;: Evaluation prompts for each dimension&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deployments and Usages&lt;/h3&gt; 
&lt;h4&gt;LangGraph Studio&lt;/h4&gt; 
&lt;p&gt;Follow the &lt;a href="https://raw.githubusercontent.com/langchain-ai/open_deep_research/main/#-quickstart"&gt;quickstart&lt;/a&gt; to start LangGraph server locally and test the agent out on LangGraph Studio.&lt;/p&gt; 
&lt;h4&gt;Hosted deployment&lt;/h4&gt; 
&lt;p&gt;You can easily deploy to &lt;a href="https://langchain-ai.github.io/langgraph/concepts/#deployment-options"&gt;LangGraph Platform&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Open Agent Platform&lt;/h4&gt; 
&lt;p&gt;Open Agent Platform (OAP) is a UI from which non-technical users can build and configure their own agents. OAP is great for allowing users to configure the Deep Researcher with different MCP tools and search APIs that are best suited to their needs and the problems that they want to solve.&lt;/p&gt; 
&lt;p&gt;We've deployed Open Deep Research to our public demo instance of OAP. All you need to do is add your API Keys, and you can test out the Deep Researcher for yourself! Try it out &lt;a href="https://oap.langchain.com"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also deploy your own instance of OAP, and make your own custom agents (like Deep Researcher) available on it to your users.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.oap.langchain.com/quickstart"&gt;Deploy Open Agent Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.oap.langchain.com/setup/agents"&gt;Add Deep Researcher to OAP&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Updates 🔥&lt;/h3&gt; 
&lt;h3&gt;Legacy Implementations 🏛️&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;src/legacy/&lt;/code&gt; folder contains two earlier implementations that provide alternative approaches to automated research:&lt;/p&gt; 
&lt;h4&gt;1. Workflow Implementation (&lt;code&gt;legacy/graph.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Plan-and-Execute&lt;/strong&gt;: Structured workflow with human-in-the-loop planning&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sequential Processing&lt;/strong&gt;: Creates sections one by one with reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Control&lt;/strong&gt;: Allows feedback and approval of report plans&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality Focused&lt;/strong&gt;: Emphasizes accuracy through iterative refinement&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. Multi-Agent Implementation (&lt;code&gt;legacy/multi_agent.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Supervisor-Researcher Architecture&lt;/strong&gt;: Coordinated multi-agent system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Processing&lt;/strong&gt;: Multiple researchers work simultaneously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Speed Optimized&lt;/strong&gt;: Faster report generation through concurrency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Support&lt;/strong&gt;: Extensive Model Context Protocol integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;code&gt;src/legacy/legacy.md&lt;/code&gt; for detailed documentation, configuration options, and usage examples for both legacy implementations.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Investment Research for Everyone, Everywhere.&lt;/p&gt;&lt;hr&gt;&lt;br&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://x.com/openbb_finance"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/xPHTuHCmuV"&gt;&lt;img src="https://img.shields.io/discord/831165782750789672" alt="Discord Shield"&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers"&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/OpenBB-finance/OpenBB"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" height="20"&gt; &lt;/a&gt; &lt;a target="_blank" href="https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/openbb/"&gt;&lt;img src="https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package" alt="PyPI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The first financial Platform that is open source.&lt;/p&gt; 
&lt;p&gt;The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.&lt;/p&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openbb import obb
output = obb.equity.price.historical("AAPL")
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can sign up to the &lt;a href="https://my.openbb.co/login"&gt;OpenBB Hub&lt;/a&gt; to get the most out of the OpenBB ecosystem.&lt;/p&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href="https://docs.openbb.co/platform/reference"&gt;https://docs.openbb.co/platform/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.&lt;/p&gt; 
&lt;p&gt;If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;a href="https://pro.openbb.co"&gt;https://pro.openbb.co&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png" alt="Logo" width="1000"&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href="https://docs.openbb.co/workspace"&gt;docs&lt;/a&gt; or &lt;a href="https://github.com/OpenBB-finance/backends-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href="https://github.com/OpenBB-finance/agents-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating OpenBB Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run OpenBB Platform backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "openbb[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate OpenBB Platform backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href="https://pro.openbb.co/"&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069" alt="CleanShot 2025-05-17 at 09 51 56@2x"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the "Apps" tab&lt;/li&gt; 
 &lt;li&gt;Click on "Connect backend"&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: OpenBB Platform URL: &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on "Test". You should get a "Test successful" with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on "Add".&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it.&lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed="closed"&gt; 
 &lt;summary&gt;&lt;h2 style="display: inline-block"&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts"&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The OpenBB Platform can be installed as a &lt;a href="https://pypi.org/project/openbb/"&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href="https://docs.openbb.co/platform/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenBB Platform CLI installation&lt;/h3&gt; 
&lt;p&gt;The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href="https://docs.openbb.co/cli/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now ⭐️)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href="https://docs.openbb.co/platform/developer_guide/misc/contributing"&gt;Contributing Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn't exist already &lt;a href="https://github.com/OpenBB-finance/OpenBB/issues"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D"&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D"&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href="https://openbb.co/discord"&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href="https://openbb.co/links"&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the OpenBB Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href="https://openbb.co/links"&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href="https://openbb.co/open"&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB" width="800"&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>NanmiCoder/MediaCrawler</title>
      <link>https://github.com/NanmiCoder/MediaCrawler</link>
      <description>&lt;p&gt;小红书笔记 | 评论爬虫、抖音视频 | 评论爬虫、快手视频 | 评论爬虫、B 站视频 ｜ 评论爬虫、微博帖子 ｜ 评论爬虫、百度贴吧帖子 ｜ 百度贴吧评论回复爬虫 | 知乎问答文章｜评论爬虫&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🔥 MediaCrawler - 自媒体平台爬虫 🕷️&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/8291" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/8291" alt="NanmiCoder%2FMediaCrawler | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;a href="https://github.com/NanmiCoder/MediaCrawler/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/NanmiCoder/MediaCrawler?style=social" alt="GitHub Stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/NanmiCoder/MediaCrawler?style=social" alt="GitHub Forks"&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/issues"&gt;&lt;img src="https://img.shields.io/github/issues/NanmiCoder/MediaCrawler" alt="GitHub Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/NanmiCoder/MediaCrawler" alt="GitHub Pull Requests"&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/NanmiCoder/MediaCrawler" alt="License"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%87%A8%F0%9F%87%B3_%E4%B8%AD%E6%96%87-%E5%BD%93%E5%89%8D-blue" alt="中文"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README_en.md"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%87%BA%F0%9F%87%B8_English-Available-green" alt="English"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README_es.md"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%87%AA%F0%9F%87%B8_Espa%C3%B1ol-Available-green" alt="Español"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;免责声明：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;大家请以学习为目的使用本仓库⚠️⚠️⚠️⚠️，&lt;a href="https://github.com/HiddenStrawberry/Crawler_Illegal_Cases_In_China"&gt;爬虫违法违规的案件&lt;/a&gt; &lt;br&gt;&lt;/p&gt; 
 &lt;p&gt;本仓库的所有内容仅供学习和参考之用，禁止用于商业用途。任何人或组织不得将本仓库的内容用于非法用途或侵犯他人合法权益。本仓库所涉及的爬虫技术仅用于学习和研究，不得用于对其他平台进行大规模爬虫或其他非法行为。对于因使用本仓库内容而引起的任何法律责任，本仓库不承担任何责任。使用本仓库的内容即表示您同意本免责声明的所有条款和条件。&lt;/p&gt; 
 &lt;p&gt;点击查看更为详细的免责声明。&lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/#disclaimer"&gt;点击跳转&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;📖 项目简介&lt;/h2&gt; 
&lt;p&gt;一个功能强大的&lt;strong&gt;多平台自媒体数据采集工具&lt;/strong&gt;，支持小红书、抖音、快手、B站、微博、贴吧、知乎等主流平台的公开信息抓取。&lt;/p&gt; 
&lt;h3&gt;🔧 技术原理&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;核心技术&lt;/strong&gt;：基于 &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt; 浏览器自动化框架登录保存登录态&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;无需JS逆向&lt;/strong&gt;：利用保留登录态的浏览器上下文环境，通过 JS 表达式获取签名参数&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;优势特点&lt;/strong&gt;：无需逆向复杂的加密算法，大幅降低技术门槛&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;✨ 功能特性&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;平台&lt;/th&gt; 
   &lt;th&gt;关键词搜索&lt;/th&gt; 
   &lt;th&gt;指定帖子ID爬取&lt;/th&gt; 
   &lt;th&gt;二级评论&lt;/th&gt; 
   &lt;th&gt;指定创作者主页&lt;/th&gt; 
   &lt;th&gt;登录态缓存&lt;/th&gt; 
   &lt;th&gt;IP代理池&lt;/th&gt; 
   &lt;th&gt;生成评论词云图&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;小红书&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;抖音&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;快手&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;B 站&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;微博&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;贴吧&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;知乎&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details id="pro-version"&gt; 
 &lt;summary&gt;🔗 &lt;strong&gt;🚀 MediaCrawlerPro 重磅发布！更多的功能，更好的架构设计！&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;🚀 MediaCrawlerPro 重磅发布！&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;专注于学习成熟项目的架构设计，不仅仅是爬虫技术，Pro 版本的代码设计思路同样值得深入学习！&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/MediaCrawlerPro"&gt;MediaCrawlerPro&lt;/a&gt; 相较于开源版本的核心优势：&lt;/p&gt; 
 &lt;h4&gt;🎯 核心功能升级&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;✅ &lt;strong&gt;断点续爬功能&lt;/strong&gt;（重点特性）&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;多账号 + IP代理池支持&lt;/strong&gt;（重点特性）&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;去除 Playwright 依赖&lt;/strong&gt;，使用更简单&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;完整 Linux 环境支持&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;🏗️ 架构设计优化&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;✅ &lt;strong&gt;代码重构优化&lt;/strong&gt;，更易读易维护（解耦 JS 签名逻辑）&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;企业级代码质量&lt;/strong&gt;，适合构建大型爬虫项目&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;完美架构设计&lt;/strong&gt;，高扩展性，源码学习价值更大&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;🎁 额外功能&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;✅ &lt;strong&gt;自媒体视频下载器桌面端&lt;/strong&gt;（适合学习全栈开发）&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;多平台首页信息流推荐&lt;/strong&gt;（HomeFeed）&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; &lt;strong&gt;基于自媒体平台的AI Agent正在开发中 🚀🚀&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;点击查看：&lt;a href="https://github.com/MediaCrawlerPro"&gt;MediaCrawlerPro 项目主页&lt;/a&gt; 更多介绍&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;🚀 快速开始&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💡 &lt;strong&gt;开源不易，如果这个项目对您有帮助，请给个 ⭐ Star 支持一下！&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;📋 前置依赖&lt;/h2&gt; 
&lt;h3&gt;🚀 uv 安装（推荐）&lt;/h3&gt; 
&lt;p&gt;在进行下一步操作之前，请确保电脑上已经安装了 uv：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安装地址&lt;/strong&gt;：&lt;a href="https://docs.astral.sh/uv/getting-started/installation"&gt;uv 官方安装指南&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;验证安装&lt;/strong&gt;：终端输入命令 &lt;code&gt;uv --version&lt;/code&gt;，如果正常显示版本号，证明已经安装成功&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;推荐理由&lt;/strong&gt;：uv 是目前最强的 Python 包管理工具，速度快、依赖解析准确&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🟢 Node.js 安装&lt;/h3&gt; 
&lt;p&gt;项目依赖 Node.js，请前往官网下载安装：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;下载地址&lt;/strong&gt;：&lt;a href="https://nodejs.org/en/download/"&gt;https://nodejs.org/en/download/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;版本要求&lt;/strong&gt;：&amp;gt;= 16.0.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📦 Python 包安装&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 进入项目目录
cd MediaCrawler

# 使用 uv sync 命令来保证 python 版本和相关依赖包的一致性
uv sync
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;🌐 浏览器驱动安装&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 安装浏览器驱动
uv run playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;💡 提示&lt;/strong&gt;：MediaCrawler 目前已经支持使用 playwright 连接你本地的 Chrome 浏览器了，一些因为 Webdriver 导致的问题迎刃而解了。&lt;/p&gt; 
 &lt;p&gt;目前开放了 &lt;code&gt;xhs&lt;/code&gt; 和 &lt;code&gt;dy&lt;/code&gt; 这两个使用 CDP 的方式连接本地浏览器，如有需要，查看 &lt;code&gt;config/base_config.py&lt;/code&gt; 中的配置项。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;🚀 运行爬虫程序&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 项目默认是没有开启评论爬取模式，如需评论请在 config/base_config.py 中的 ENABLE_GET_COMMENTS 变量修改
# 一些其他支持项，也可以在 config/base_config.py 查看功能，写的有中文注释

# 从配置文件中读取关键词搜索相关的帖子并爬取帖子信息与评论
uv run main.py --platform xhs --lt qrcode --type search

# 从配置文件中读取指定的帖子ID列表获取指定帖子的信息与评论信息
uv run main.py --platform xhs --lt qrcode --type detail

# 打开对应APP扫二维码登录

# 其他平台爬虫使用示例，执行下面的命令查看
uv run main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;🔗 &lt;strong&gt;使用 Python 原生 venv 管理环境（不推荐）&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;创建并激活 Python 虚拟环境&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;如果是爬取抖音和知乎，需要提前安装 nodejs 环境，版本大于等于：&lt;code&gt;16&lt;/code&gt; 即可&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# 进入项目根目录
cd MediaCrawler

# 创建虚拟环境
# 我的 python 版本是：3.9.6，requirements.txt 中的库是基于这个版本的
# 如果是其他 python 版本，可能 requirements.txt 中的库不兼容，需自行解决
python -m venv venv

# macOS &amp;amp; Linux 激活虚拟环境
source venv/bin/activate

# Windows 激活虚拟环境
venv\Scripts\activate
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;安装依赖库&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;安装 playwright 浏览器驱动&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;playwright install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;运行爬虫程序（原生环境）&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# 项目默认是没有开启评论爬取模式，如需评论请在 config/base_config.py 中的 ENABLE_GET_COMMENTS 变量修改
# 一些其他支持项，也可以在 config/base_config.py 查看功能，写的有中文注释

# 从配置文件中读取关键词搜索相关的帖子并爬取帖子信息与评论
python main.py --platform xhs --lt qrcode --type search

# 从配置文件中读取指定的帖子ID列表获取指定帖子的信息与评论信息
python main.py --platform xhs --lt qrcode --type detail

# 打开对应APP扫二维码登录

# 其他平台爬虫使用示例，执行下面的命令查看
python main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;💾 数据保存&lt;/h2&gt; 
&lt;p&gt;支持多种数据存储方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite 数据库&lt;/strong&gt;：轻量级数据库，无需服务器，适合个人使用（推荐） 
  &lt;ul&gt; 
   &lt;li&gt;参数：&lt;code&gt;--save_data_option sqlite&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;自动创建数据库文件&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MySQL 数据库&lt;/strong&gt;：支持关系型数据库 MySQL 中保存（需要提前创建数据库） 
  &lt;ul&gt; 
   &lt;li&gt;执行 &lt;code&gt;python db.py&lt;/code&gt; 初始化数据库表结构（只在首次执行）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CSV 文件&lt;/strong&gt;：支持保存到 CSV 中（&lt;code&gt;data/&lt;/code&gt; 目录下）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON 文件&lt;/strong&gt;：支持保存到 JSON 中（&lt;code&gt;data/&lt;/code&gt; 目录下）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;使用示例：&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 使用 SQLite（推荐个人用户使用）
uv run main.py --platform xhs --lt qrcode --type search --save_data_option sqlite

# 使用 MySQL
uv run main.py --platform xhs --lt qrcode --type search --save_data_option db
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;a href="https://github.com/MediaCrawlerPro"&gt;🚀 MediaCrawlerPro 重磅发布 🚀！更多的功能，更好的架构设计！&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🤝 社区与支持&lt;/h2&gt; 
&lt;h3&gt;💬 交流群组&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;微信交流群&lt;/strong&gt;：&lt;a href="https://nanmicoder.github.io/MediaCrawler/%E5%BE%AE%E4%BF%A1%E4%BA%A4%E6%B5%81%E7%BE%A4.html"&gt;点击加入&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📚 文档与教程&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;在线文档&lt;/strong&gt;：&lt;a href="https://nanmicoder.github.io/MediaCrawler/"&gt;MediaCrawler 完整文档&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;爬虫教程&lt;/strong&gt;：&lt;a href="https://github.com/NanmiCoder/CrawlerTutorial"&gt;CrawlerTutorial 免费教程&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;其他常见问题可以查看在线文档&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在线文档包含使用方法、常见问题、加入项目交流群等。 &lt;a href="https://nanmicoder.github.io/MediaCrawler/"&gt;MediaCrawler在线文档&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;作者提供的知识服务&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果想快速入门和学习该项目的使用、源码架构设计等、学习编程技术、亦或者想了解MediaCrawlerPro的源代码设计可以看下我的知识付费栏目。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://nanmicoder.github.io/MediaCrawler/%E7%9F%A5%E8%AF%86%E4%BB%98%E8%B4%B9%E4%BB%8B%E7%BB%8D.html"&gt;作者的知识付费栏目介绍&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;⭐ Star 趋势图&lt;/h2&gt; 
&lt;p&gt;如果这个项目对您有帮助，请给个 ⭐ Star 支持一下，让更多的人看到 MediaCrawler！&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#NanmiCoder/MediaCrawler&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=NanmiCoder/MediaCrawler&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;💰 赞助商展示&lt;/h3&gt; 
&lt;a href="https://www.swiftproxy.net/?ref=nanmi"&gt; &lt;img src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_5.png"&gt; &lt;br&gt; Swiftproxy - 90M+ 全球高质量纯净住宅IP，注册可领免费 500MB 测试流量，动态流量不过期！ &amp;gt; 专属折扣码：**GHB5** 立享九折优惠！ &lt;/a&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;a href="https://www.tkyds.com/?=MediaCrawler"&gt; &lt;img src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_6.png"&gt; &lt;br&gt; TK云大师,专业的TikTok矩阵系统,AI赋能自动化,单人轻松管理上万账号！ &lt;/a&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;a href="https://www.thordata.com/?ls=github&amp;amp;lk=Crawler"&gt; &lt;img src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_7.png"&gt; &lt;br&gt; Thordata是全球代理IP解决方案提供商，支持大规模采集公共网络数据，提供 195+ 国家城市、6000 万住宅IP，价格低至 $0.65/GB，支持不限流量、不限IP、不限并发；还包括本土独享ISP静态代理和高性能数据中心代理（均为 $0.75/IP，弹性定价）。点击图片注册后联系中文客服即可免费试用，现在首充还有赠送同额金额活动。可与EasySpider工具配合使用，高效采集网络数据。 &lt;/a&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;a href="https://h.wandouip.com"&gt; &lt;img src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_8.jpg"&gt; &lt;br&gt; 豌豆HTTP自营千万级IP资源池，IP纯净度≥99.8%，每日保持IP高频更新，快速响应，稳定连接，满足多种业务场景，支持按需定制，注册免费提取10000ip。 &lt;/a&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://sider.ai/ad-land-redirect?source=github&amp;amp;p1=mi&amp;amp;p2=kk"&gt;&lt;strong&gt;Sider&lt;/strong&gt; - 全网最火的 ChatGPT 插件，体验拉满！&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;🤝 成为赞助者&lt;/h3&gt; 
&lt;p&gt;成为赞助者，可以将您的产品展示在这里，每天获得大量曝光！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;联系方式&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;微信：&lt;code&gt;yzglan&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;邮箱：&lt;code&gt;relakkes@gmail.com&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📚 参考&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;小红书客户端&lt;/strong&gt;：&lt;a href="https://github.com/ReaJason/xhs"&gt;ReaJason 的 xhs 仓库&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;短信转发&lt;/strong&gt;：&lt;a href="https://github.com/pppscn/SmsForwarder"&gt;SmsForwarder 参考仓库&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;内网穿透工具&lt;/strong&gt;：&lt;a href="https://ngrok.com/docs/"&gt;ngrok 官方文档&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;免责声明&lt;/h1&gt; 
&lt;div id="disclaimer"&gt; 
 &lt;h2&gt;1. 项目目的与性质&lt;/h2&gt; 
 &lt;p&gt;本项目（以下简称“本项目”）是作为一个技术研究与学习工具而创建的，旨在探索和学习网络数据采集技术。本项目专注于自媒体平台的数据爬取技术研究，旨在提供给学习者和研究者作为技术交流之用。&lt;/p&gt; 
 &lt;h2&gt;2. 法律合规性声明&lt;/h2&gt; 
 &lt;p&gt;本项目开发者（以下简称“开发者”）郑重提醒用户在下载、安装和使用本项目时，严格遵守中华人民共和国相关法律法规，包括但不限于《中华人民共和国网络安全法》、《中华人民共和国反间谍法》等所有适用的国家法律和政策。用户应自行承担一切因使用本项目而可能引起的法律责任。&lt;/p&gt; 
 &lt;h2&gt;3. 使用目的限制&lt;/h2&gt; 
 &lt;p&gt;本项目严禁用于任何非法目的或非学习、非研究的商业行为。本项目不得用于任何形式的非法侵入他人计算机系统，不得用于任何侵犯他人知识产权或其他合法权益的行为。用户应保证其使用本项目的目的纯属个人学习和技术研究，不得用于任何形式的非法活动。&lt;/p&gt; 
 &lt;h2&gt;4. 免责声明&lt;/h2&gt; 
 &lt;p&gt;开发者已尽最大努力确保本项目的正当性及安全性，但不对用户使用本项目可能引起的任何形式的直接或间接损失承担责任。包括但不限于由于使用本项目而导致的任何数据丢失、设备损坏、法律诉讼等。&lt;/p&gt; 
 &lt;h2&gt;5. 知识产权声明&lt;/h2&gt; 
 &lt;p&gt;本项目的知识产权归开发者所有。本项目受到著作权法和国际著作权条约以及其他知识产权法律和条约的保护。用户在遵守本声明及相关法律法规的前提下，可以下载和使用本项目。&lt;/p&gt; 
 &lt;h2&gt;6. 最终解释权&lt;/h2&gt; 
 &lt;p&gt;关于本项目的最终解释权归开发者所有。开发者保留随时更改或更新本免责声明的权利，恕不另行通知。&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🙏 致谢&lt;/h2&gt; 
&lt;h3&gt;JetBrains 开源许可证支持&lt;/h3&gt; 
&lt;p&gt;感谢 JetBrains 为本项目提供免费的开源许可证支持！&lt;/p&gt; 
&lt;a href="https://www.jetbrains.com/?from=MediaCrawler"&gt; &lt;img src="https://www.jetbrains.com/company/brand/img/jetbrains_logo.png" width="100" alt="JetBrains"&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>ihmily/DouyinLiveRecorder</title>
      <link>https://github.com/ihmily/DouyinLiveRecorder</link>
      <description>&lt;p&gt;可循环值守和多人录制的直播录制软件，支持抖音、TikTok、Youtube、快手、虎牙、斗鱼、B站、小红书、pandatv、sooplive、flextv、popkontv、twitcasting、winktv、百度、微博、酷狗、17Live、Twitch、Acfun、CHZZK、shopee等40+平台直播录制&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://socialify.git.ci/ihmily/DouyinLiveRecorder/image?font=Inter&amp;amp;forks=1&amp;amp;language=1&amp;amp;owner=1&amp;amp;pattern=Circuit%20Board&amp;amp;stargazers=1&amp;amp;theme=Light" alt="video_spider"&gt;&lt;/p&gt; 
&lt;h2&gt;💡简介&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/downloads/release/python-3116/"&gt;&lt;img src="https://img.shields.io/badge/python-3.11.6-blue.svg?sanitize=true" alt="Python Version"&gt;&lt;/a&gt; &lt;a href="https://github.com/ihmily/DouyinLiveRecorder"&gt;&lt;img src="https://img.shields.io/badge/platforms-Windows%20%7C%20Linux-blue.svg?sanitize=true" alt="Supported Platforms"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/ihmily/douyin-live-recorder/tags"&gt;&lt;img src="https://img.shields.io/docker/pulls/ihmily/douyin-live-recorder?label=Docker%20Pulls&amp;amp;color=blue&amp;amp;logo=docker" alt="Docker Pulls"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/issues/ihmily/DouyinLiveRecorder.svg?sanitize=true" alt="GitHub issues"&gt; &lt;a href="https://github.com/ihmily/DouyinLiveRecorder/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/ihmily/DouyinLiveRecorder" alt="Latest Release"&gt;&lt;/a&gt; &lt;a href="https://github.com/ihmily/DouyinLiveRecorder/releases/latest"&gt;&lt;img src="https://img.shields.io/github/downloads/ihmily/DouyinLiveRecorder/total" alt="Downloads"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;一款&lt;strong&gt;简易&lt;/strong&gt;的可循环值守的直播录制工具，基于FFmpeg实现多平台直播源录制，支持自定义配置录制以及直播状态推送。&lt;/p&gt;  
&lt;h2&gt;😺已支持平台&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 抖音&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; TikTok&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 快手&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 虎牙&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 斗鱼&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; YY&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; B站&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 小红书&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; bigo&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; blued&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; SOOP(原AfreecaTV)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 网易cc&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 千度热播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; PandaTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 猫耳FM&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Look直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; WinkTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; FlexTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; PopkonTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; TwitCasting&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 百度直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 微博直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 酷狗直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; TwitchTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; LiveMe&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 花椒直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 流星直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; ShowRoom&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Acfun&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 映客直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 音播直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 知乎直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; CHZZK&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 嗨秀直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; vv星球直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 17Live&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 浪Live&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 畅聊直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 飘飘直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 六间房直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 乐嗨直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 花猫直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Shopee&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Youtube&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 淘宝&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 京东&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Faceit&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; 更多平台正在更新中&lt;/li&gt; 
&lt;/ul&gt;  
&lt;h2&gt;🎈项目结构&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;.
└── DouyinLiveRecorder/
    ├── /config -&amp;gt; (config record)
    ├── /logs -&amp;gt; (save runing log file)
    ├── /backup_config -&amp;gt; (backup file)
    ├── /douyinliverecorder -&amp;gt; (package)
        ├── initializer.py-&amp;gt; (check and install nodejs)
    	├── spider.py-&amp;gt; (get live data)
    	├── stream.py-&amp;gt; (get live stream address)
    	├── utils.py -&amp;gt; (contains utility functions)
    	├── logger.py -&amp;gt; (logger handdle)
    	├── room.py -&amp;gt; (get room info)
    	├── /javascript -&amp;gt; (some decrypt code)
    ├── main.py -&amp;gt; (main file)
    ├── ffmpeg_install.py -&amp;gt; (ffmpeg install script)
    ├── demo.py -&amp;gt; (call package test demo)
    ├── msg_push.py -&amp;gt; (send live status update message)
    ├── ffmpeg.exe -&amp;gt; (record video)
    ├── index.html -&amp;gt; (play m3u8 and flv video)
    ├── requirements.txt -&amp;gt; (library dependencies)
    ├── docker-compose.yaml -&amp;gt; (Container Orchestration File)
    ├── Dockerfile -&amp;gt; (Application Build Recipe)
    ├── StopRecording.vbs -&amp;gt; (stop recording script on Windows)
    ...
&lt;/code&gt;&lt;/pre&gt;  
&lt;h2&gt;🌱使用说明&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;对于只想使用录制软件的小白用户，进入&lt;a href="https://github.com/ihmily/DouyinLiveRecorder/releases"&gt;Releases&lt;/a&gt; 中下载最新发布的 zip压缩包即可，里面有打包好的录制软件。（有些电脑可能会报毒，直接忽略即可，如果下载时被浏览器屏蔽，请更换浏览器下载）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;压缩包解压后，在 &lt;code&gt;config&lt;/code&gt; 文件夹内的 &lt;code&gt;URL_config.ini&lt;/code&gt; 中添加录制直播间地址，一行一个直播间地址。如果要自定义配置录制，可以修改&lt;code&gt;config.ini&lt;/code&gt; 文件，推荐将录制格式修改为&lt;code&gt;ts&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;以上步骤都做好后，就可以运行&lt;code&gt;DouyinLiveRecorder.exe&lt;/code&gt; 程序进行录制了。录制的视频文件保存在同目录下的 &lt;code&gt;downloads&lt;/code&gt; 文件夹内。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;另外，如果需要录制TikTok、AfreecaTV等海外平台，请在配置文件中设置开启代理并添加proxy_addr链接 如：&lt;code&gt;127.0.0.1:7890&lt;/code&gt; （这只是示例地址，具体根据实际填写）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;假如&lt;code&gt;URL_config.ini&lt;/code&gt;文件中添加的直播间地址，有个别直播间暂时不想录制又不想移除链接，可以在对应直播间的链接开头加上&lt;code&gt;#&lt;/code&gt;，那么将停止该直播间的监测以及录制。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;软件默认录制清晰度为 &lt;code&gt;原画&lt;/code&gt; ，如果要单独设置某个直播间的录制画质，可以在添加直播间地址时前面加上画质即可，如&lt;code&gt;超清，https://live.douyin.com/745964462470&lt;/code&gt; 记得中间要有&lt;code&gt;,&lt;/code&gt; 分隔。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果要长时间挂着软件循环监测直播，最好循环时间设置长一点（咱也不差没录制到的那几分钟），避免因请求频繁导致被官方封禁IP 。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;要停止直播录制，Windows平台可执行StopRecording.vbs脚本文件，或者在录制界面使用 &lt;code&gt;Ctrl+C &lt;/code&gt; 组合键中断录制，若要停止其中某个直播间的录制，可在&lt;code&gt;URL_config.ini&lt;/code&gt;文件中的地址前加#，会自动停止对应直播间的录制并正常保存已录制的视频。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最后，欢迎右上角给本项目一个star，同时也非常乐意大家提交pr。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt; &lt;/p&gt; 
&lt;p&gt;直播间链接示例：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;抖音:
https://live.douyin.com/745964462470
https://v.douyin.com/iQFeBnt/
https://live.douyin.com/yall1102  （链接+抖音号）
https://v.douyin.com/CeiU5cbX  （主播主页地址）

TikTok:
https://www.tiktok.com/@pearlgaga88/live

快手:
https://live.kuaishou.com/u/yall1102

虎牙:
https://www.huya.com/52333

斗鱼:
https://www.douyu.com/3637778?dyshid=
https://www.douyu.com/topic/wzDBLS6?rid=4921614&amp;amp;dyshid=

YY:
https://www.yy.com/22490906/22490906

B站:
https://live.bilibili.com/320

小红书（直播间分享地址):
http://xhslink.com/xpJpfM

bigo直播:
https://www.bigo.tv/cn/716418802

buled直播:
https://app.blued.cn/live?id=Mp6G2R

SOOP:
https://play.sooplive.co.kr/sw7love

网易cc:
https://cc.163.com/583946984

千度热播:
https://qiandurebo.com/web/video.php?roomnumber=33333

PandaTV:
https://www.pandalive.co.kr/live/play/bara0109

猫耳FM:
https://fm.missevan.com/live/868895007

Look直播:
https://look.163.com/live?id=65108820&amp;amp;position=3

WinkTV:
https://www.winktv.co.kr/live/play/anjer1004

FlexTV:
https://www.flextv.co.kr/channels/593127/live

PopkonTV:
https://www.popkontv.com/live/view?castId=wjfal007&amp;amp;partnerCode=P-00117
https://www.popkontv.com/channel/notices?mcid=wjfal007&amp;amp;mcPartnerCode=P-00117

TwitCasting:
https://twitcasting.tv/c:uonq

百度直播:
https://live.baidu.com/m/media/pclive/pchome/live.html?room_id=9175031377&amp;amp;tab_category

微博直播:
https://weibo.com/l/wblive/p/show/1022:2321325026370190442592

酷狗直播:
https://fanxing2.kugou.com/50428671?refer=2177&amp;amp;sourceFrom=

TwitchTV:
https://www.twitch.tv/gamerbee

LiveMe:
https://www.liveme.com/zh/v/17141543493018047815/index.html

花椒直播:
https://www.huajiao.com/l/345096174

流星直播:
https://www.7u66.com/100960

ShowRoom:
https://www.showroom-live.com/room/profile?room_id=480206  （主播主页地址）

Acfun:
https://live.acfun.cn/live/179922

映客直播:
https://www.inke.cn/liveroom/index.html?uid=22954469&amp;amp;id=1720860391070904

音播直播:
https://live.ybw1666.com/800002949

知乎直播:
https://www.zhihu.com/people/ac3a467005c5d20381a82230101308e9 (主播主页地址)

CHZZK:
https://chzzk.naver.com/live/458f6ec20b034f49e0fc6d03921646d2

嗨秀直播:
https://www.haixiutv.com/6095106

VV星球直播:
https://h5webcdn-pro.vvxqiu.com//activity/videoShare/videoShare.html?h5Server=https://h5p.vvxqiu.com&amp;amp;roomId=LP115924473&amp;amp;platformId=vvstar

17Live:
https://17.live/en/live/6302408

浪Live:
https://www.lang.live/en-US/room/3349463

畅聊直播:
https://live.tlclw.com/106188

飘飘直播:
https://m.pp.weimipopo.com/live/preview.html?uid=91648673&amp;amp;anchorUid=91625862&amp;amp;app=plpl

六间房直播:
https://v.6.cn/634435

乐嗨直播:
https://www.lehaitv.com/8059096

花猫直播:
https://h.catshow168.com/live/preview.html?uid=19066357&amp;amp;anchorUid=18895331

Shopee:
https://sg.shp.ee/GmpXeuf?uid=1006401066&amp;amp;session=802458

Youtube:
https://www.youtube.com/watch?v=cS6zS5hi1w0

淘宝(需cookie):
https://m.tb.cn/h.TWp0HTd

京东:
https://3.cn/28MLBy-E

Faceit:
https://www.faceit.com/zh/players/Compl1/stream
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt; &lt;/p&gt; 
&lt;h2&gt;🎃源码运行&lt;/h2&gt; 
&lt;p&gt;使用源码运行，前提要有&lt;strong&gt;Python&amp;gt;=3.10&lt;/strong&gt;环境，如果没有请先自行安装Python，再执行下面步骤。&lt;/p&gt; 
&lt;p&gt;1.首先拉取或手动下载本仓库项目代码&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ihmily/DouyinLiveRecorder.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2.进入项目文件夹，安装依赖&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd DouyinLiveRecorder
pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3.安装&lt;a href="https://ffmpeg.org/download.html#build-linux"&gt;FFmpeg&lt;/a&gt;，如果是Windows系统，这一步可跳过。对于Linux系统，执行以下命令安装&lt;/p&gt; 
&lt;p&gt;CentOS执行&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yum install epel-release
yum install ffmpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ubuntu则执行&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;apt update
apt install ffmpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;macOS 执行&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如果已经安装 Homebrew 请跳过这一步&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install ffmpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;4.运行程序&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中Linux系统请使用&lt;code&gt;python3 main.py&lt;/code&gt; 运行。&lt;/p&gt; 
&lt;p&gt; &lt;/p&gt; 
&lt;h2&gt;🐋容器运行&lt;/h2&gt; 
&lt;p&gt;在运行命令之前，请确保您的机器上安装了 &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt; 和 &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;1.快速启动&lt;/p&gt; 
&lt;p&gt;最简单方法是运行项目中的 &lt;a href="https://github.com/ihmily/DouyinLiveRecorder/raw/main/docker-compose.yaml"&gt;docker-compose.yaml&lt;/a&gt; 文件，只需简单执行以下命令：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可选 &lt;code&gt;-d&lt;/code&gt; 在后台运行。&lt;/p&gt; 
&lt;p&gt;2.构建镜像(可选)&lt;/p&gt; 
&lt;p&gt;如果你只想简单的运行程序，则不需要做这一步。Docker镜像仓库中代码版本可能不是最新的，如果要运行本仓库主分支最新代码，可以本地自定义构建，通过修改 &lt;a href="https://github.com/ihmily/DouyinLiveRecorder/raw/main/docker-compose.yaml"&gt;docker-compose.yaml&lt;/a&gt; 文件，如将镜像名修改为 &lt;code&gt;douyin-live-recorder:latest&lt;/code&gt;，并取消 &lt;code&gt;# build: .&lt;/code&gt; 注释，然后再执行&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t douyin-live-recorder:latest .
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;或者直接使用下面命令进行构建并启动&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose -f docker-compose.yaml up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3.停止容器实例&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;4.注意事项&lt;/p&gt; 
&lt;p&gt;①在docker容器内运行本程序之前，请先在配置文件中添加要录制的直播间地址。&lt;/p&gt; 
&lt;p&gt;②在容器内时，如果手动中断容器运行停止录制，会导致正在录制的视频文件损坏！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;无论哪种运行方式，为避免手动中断或者异常中断导致录制的视频文件损坏的情况，推荐使用 &lt;code&gt;ts&lt;/code&gt; 格式保存&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt; &lt;/p&gt; 
&lt;h2&gt;❤️贡献者&lt;/h2&gt; 
&lt;p&gt;   &lt;a href="https://github.com/ihmily"&gt;&lt;img src="https://github.com/ihmily.png?size=50" alt="Hmily"&gt;&lt;/a&gt; &lt;a href="https://github.com/iridescentGray"&gt;&lt;img src="https://github.com/iridescentGray.png?size=50" alt="iridescentGray"&gt;&lt;/a&gt; &lt;a href="https://github.com/annidy"&gt;&lt;img src="https://github.com/annidy.png?size=50" alt="annidy"&gt;&lt;/a&gt; &lt;a href="https://github.com/wwkk2580"&gt;&lt;img src="https://github.com/wwkk2580.png?size=50" alt="wwkk2580"&gt;&lt;/a&gt; &lt;a href="https://github.com/missuo"&gt;&lt;img src="https://github.com/missuo.png?size=50" alt="missuo"&gt;&lt;/a&gt; &lt;a href="https://github.com/xueli12" target="_blank"&gt;&lt;img src="https://github.com/xueli12.png?size=50" alt="xueli12" style="width:53px; height:51px;"&gt;&lt;/a&gt; &lt;a href="https://github.com/kaine1973" target="_blank"&gt;&lt;img src="https://github.com/kaine1973.png?size=50" alt="kaine1973" style="width:53px; height:51px;"&gt;&lt;/a&gt; &lt;a href="https://github.com/yinruiqing" target="_blank"&gt;&lt;img src="https://github.com/yinruiqing.png?size=50" alt="yinruiqing" style="width:53px; height:51px;"&gt;&lt;/a&gt; &lt;a href="https://github.com/Max-Tortoise" target="_blank"&gt;&lt;img src="https://github.com/Max-Tortoise.png?size=50" alt="Max-Tortoise" style="width:53px; height:51px;"&gt;&lt;/a&gt; &lt;a href="https://github.com/justdoiting"&gt;&lt;img src="https://github.com/justdoiting.png?size=50" alt="justdoiting"&gt;&lt;/a&gt; &lt;a href="https://github.com/dhbxs"&gt;&lt;img src="https://github.com/dhbxs.png?size=50" alt="dhbxs"&gt;&lt;/a&gt; &lt;a href="https://github.com/wujiyu115"&gt;&lt;img src="https://github.com/wujiyu115.png?size=50" alt="wujiyu115"&gt;&lt;/a&gt; &lt;a href="https://github.com/zhanghao333"&gt;&lt;img src="https://github.com/zhanghao333.png?size=50" alt="zhanghao333"&gt;&lt;/a&gt; &lt;a href="https://github.com/gyc0123" target="_blank"&gt;&lt;img src="https://github.com/gyc0123.png?size=50" alt="gyc0123" style="width:53px; height:51px;"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;   &lt;a href="https://github.com/HoratioShaw"&gt;&lt;img src="https://github.com/HoratioShaw.png?size=50" alt="HoratioShaw"&gt;&lt;/a&gt; &lt;a href="https://github.com/nov30th"&gt;&lt;img src="https://github.com/nov30th.png?size=50" alt="nov30th"&gt;&lt;/a&gt;  &lt;/p&gt; 
&lt;h2&gt;⏳提交日志&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;20250127&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增淘宝、京东、faceit直播录制&lt;/li&gt; 
   &lt;li&gt;修复小红书直播流录制以及转码问题&lt;/li&gt; 
   &lt;li&gt;修复畅聊、VV星球、flexTV直播录制&lt;/li&gt; 
   &lt;li&gt;修复批量微信直播推送&lt;/li&gt; 
   &lt;li&gt;新增email发送ssl和port配置&lt;/li&gt; 
   &lt;li&gt;新增强制转h264配置&lt;/li&gt; 
   &lt;li&gt;更新ffmpeg版本&lt;/li&gt; 
   &lt;li&gt;重构包为异步函数！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20241130&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增shopee、youtube直播录制&lt;/li&gt; 
   &lt;li&gt;新增支持自定义m3u8、flv地址录制&lt;/li&gt; 
   &lt;li&gt;新增自定义执行脚本，支持python、bat、bash等&lt;/li&gt; 
   &lt;li&gt;修复YY直播、花椒直播和小红书直播录制&lt;/li&gt; 
   &lt;li&gt;修复b站标题获取错误&lt;/li&gt; 
   &lt;li&gt;修复log日志错误&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20241030&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增嗨秀直播、vv星球直播、17Live、浪Live、SOOP、畅聊直播(原时光直播)、飘飘直播、六间房直播、乐嗨直播、花猫直播等10个平台直播录制&lt;/li&gt; 
   &lt;li&gt;修复小红书直播录制，支持小红书作者主页地址录制直播&lt;/li&gt; 
   &lt;li&gt;新增支持ntfy消息推送，以及新增支持批量推送多个地址（逗号分隔多个推送地址)&lt;/li&gt; 
   &lt;li&gt;修复Liveme直播录制、twitch直播录制&lt;/li&gt; 
   &lt;li&gt;新增Windows平台一键停止录制VB脚本程序&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20241005&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增邮箱和Bark推送&lt;/li&gt; 
   &lt;li&gt;新增直播注释停止录制&lt;/li&gt; 
   &lt;li&gt;优化分段录制&lt;/li&gt; 
   &lt;li&gt;重构部分代码&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240928&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增知乎直播、CHZZK直播录制&lt;/li&gt; 
   &lt;li&gt;修复音播直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240903&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增抖音双屏录制、音播直播录制&lt;/li&gt; 
   &lt;li&gt;修复PandaTV、bigo直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240713&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增映客直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240705&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增时光直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240701&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复虎牙直播录制2分钟断流问题&lt;/li&gt; 
   &lt;li&gt;新增自定义直播推送内容&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240621&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增Acfun、ShowRoom直播录制&lt;/li&gt; 
   &lt;li&gt;修复微博录制、新增直播源线路&lt;/li&gt; 
   &lt;li&gt;修复斗鱼直播60帧录制&lt;/li&gt; 
   &lt;li&gt;修复酷狗直播录制&lt;/li&gt; 
   &lt;li&gt;修复TikTok部分无法解析直播源&lt;/li&gt; 
   &lt;li&gt;修复抖音无法录制连麦直播&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240510&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复部分虎牙直播间录制错误&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240508&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复花椒直播录制&lt;/li&gt; 
   &lt;li&gt;更改文件路径解析方式 &lt;a href="https://github.com/kaine1973"&gt;@kaine1973&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240506&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复抖音录制画质解析bug&lt;/li&gt; 
   &lt;li&gt;修复虎牙录制 60帧最高画质问题&lt;/li&gt; 
   &lt;li&gt;新增流星直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240427&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增LiveMe、花椒直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240425&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增TwitchTV直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240424&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增酷狗直播录制、优化PopkonTV直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240423&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增百度直播录制、微博直播录制&lt;/li&gt; 
   &lt;li&gt;修复斗鱼录制直播回放的问题&lt;/li&gt; 
   &lt;li&gt;新增直播源地址显示以及输出到日志文件设置&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240311&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复海外平台录制bug，增加画质选择，增强录制稳定性&lt;/li&gt; 
   &lt;li&gt;修复虎牙录制bug (虎牙&lt;code&gt;一起看&lt;/code&gt;频道 有特殊限制，有时无法录制)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240309&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复虎牙直播、小红书直播和B站直播录制&lt;/li&gt; 
   &lt;li&gt;新增5个直播平台录制，包括winktv、flextv、look、popkontv、twitcasting&lt;/li&gt; 
   &lt;li&gt;新增部分海外平台账号密码配置，实现自动登录并更新配置文件中的cookie&lt;/li&gt; 
   &lt;li&gt;新增自定义配置需要使用代理录制的平台&lt;/li&gt; 
   &lt;li&gt;新增只推送开播消息不进行录制设置&lt;/li&gt; 
   &lt;li&gt;修复了一些bug&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240209&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;优化AfreecaTV录制，新增账号密码登录获取cookie以及持久保存&lt;/li&gt; 
   &lt;li&gt;修复了小红书直播因官方更新直播域名，导致无法录制直播的问题&lt;/li&gt; 
   &lt;li&gt;修复了更新URL配置文件的bug&lt;/li&gt; 
   &lt;li&gt;最后，祝大家新年快乐！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt;
 &lt;summary&gt;点击展开更多提交日志&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;20240129 
   &lt;ul&gt; 
    &lt;li&gt;新增猫耳FM直播录制&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20240127 
   &lt;ul&gt; 
    &lt;li&gt;新增千度热播直播录制、新增pandaTV(韩国)直播录制&lt;/li&gt; 
    &lt;li&gt;新增telegram直播状态消息推送，修复了某些bug&lt;/li&gt; 
    &lt;li&gt;新增自定义设置不同直播间的录制画质(即每个直播间录制画质可不同)&lt;/li&gt; 
    &lt;li&gt;修改录制视频保存路径为 &lt;code&gt;downloads&lt;/code&gt; 文件夹，并且分平台进行保存。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20240114 
   &lt;ul&gt; 
    &lt;li&gt;新增网易cc直播录制，优化ffmpeg参数，修改AfreecaTV输入直播地址格式&lt;/li&gt; 
    &lt;li&gt;修改日志记录器 @&lt;a href="https://github.com/iridescentGray"&gt;iridescentGray&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20240102 
   &lt;ul&gt; 
    &lt;li&gt;修复Linux上运行，新增docker配置文件&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231210 
   &lt;ul&gt; 
    &lt;li&gt;修复录制分段bug，修复bigo录制检测bug&lt;/li&gt; 
    &lt;li&gt;新增自定义修改录制主播名&lt;/li&gt; 
    &lt;li&gt;新增AfreecaTV直播录制，修复某些可能会发生的bug&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231207 
   &lt;ul&gt; 
    &lt;li&gt;新增blued直播录制，修复YY直播录制，新增直播结束消息推送&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231206 
   &lt;ul&gt; 
    &lt;li&gt;新增bigo直播录制&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231203 
   &lt;ul&gt; 
    &lt;li&gt;新增小红书直播录制（全网首发），目前小红书官方没有切换清晰度功能，因此直播录制也只有默认画质&lt;/li&gt; 
    &lt;li&gt;小红书录制暂时无法循环监测，每次主播开启直播，都要重新获取一次链接&lt;/li&gt; 
    &lt;li&gt;获取链接的方式为 将直播间转发到微信，在微信中打开后，复制页面的链接。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231030 
   &lt;ul&gt; 
    &lt;li&gt;本次更新只是进行修复，没时间新增功能。&lt;/li&gt; 
    &lt;li&gt;欢迎各位大佬提pr 帮忙更新维护&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230930 
   &lt;ul&gt; 
    &lt;li&gt;新增抖音从接口获取直播流，增强稳定性&lt;/li&gt; 
    &lt;li&gt;修改快手获取直播流的方式，改用从官方接口获取&lt;/li&gt; 
    &lt;li&gt;祝大家中秋节快乐！&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230919 
   &lt;ul&gt; 
    &lt;li&gt;修复了快手版本更新后录制出错的问题，增加了其自动获取cookie(&lt;del&gt;稳定性未知&lt;/del&gt;)&lt;/li&gt; 
    &lt;li&gt;修复了TikTok显示正在直播但不进行录制的问题&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230907 
   &lt;ul&gt; 
    &lt;li&gt;修复了因抖音官方更新了版本导致的录制出错以及短链接转换出错&lt;/li&gt; 
    &lt;li&gt;修复B站无法录制原画视频的bug&lt;/li&gt; 
    &lt;li&gt;修改了配置文件字段，新增各平台自定义设置Cookie&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230903 
   &lt;ul&gt; 
    &lt;li&gt;修复了TikTok录制时报644无法录制的问题&lt;/li&gt; 
    &lt;li&gt;新增直播状态推送到钉钉和微信的功能，如有需要请看 &lt;a href="https://d04vqdiqwr3.feishu.cn/docx/XFPwdDDvfobbzlxhmMYcvouynDh?from=from_copylink"&gt;设置推送教程&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;最近比较忙，其他问题有时间再更新&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230816 
   &lt;ul&gt; 
    &lt;li&gt;修复斗鱼直播（官方更新了字段）和快手直播录制出错的问题&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230814 
   &lt;ul&gt; 
    &lt;li&gt;新增B站直播录制&lt;/li&gt; 
    &lt;li&gt;写了一个在线播放M3U8和FLV视频的网页源码，打开即可食用&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230812 
   &lt;ul&gt; 
    &lt;li&gt;新增YY直播录制&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230808 
   &lt;ul&gt; 
    &lt;li&gt;修复主播重新开播无法再次录制的问题&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230807 
   &lt;ul&gt; 
    &lt;li&gt;新增了斗鱼直播录制&lt;/li&gt; 
    &lt;li&gt;修复显示录制完成之后会重新开始录制的问题&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230805 
   &lt;ul&gt; 
    &lt;li&gt;新增了虎牙直播录制，其暂时只能用flv视频流进行录制&lt;/li&gt; 
    &lt;li&gt;Web API 新增了快手和虎牙这两个平台的直播流解析（TikTok要代理）&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230804 
   &lt;ul&gt; 
    &lt;li&gt;新增了快手直播录制，优化了部分代码&lt;/li&gt; 
    &lt;li&gt;上传了一个自动化获取抖音直播间页面Cookie的代码，可以用于录制&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230803 
   &lt;ul&gt; 
    &lt;li&gt;通宵更新&lt;/li&gt; 
    &lt;li&gt;新增了国际版抖音TikTok的直播录制，去除冗余 简化了部分代码&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230724 
   &lt;ul&gt; 
    &lt;li&gt;新增了一个通过抖音直播间地址获取直播视频流链接的API接口，上传即可用&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt;
 &lt;/ul&gt;
&lt;/details&gt;     
&lt;h2&gt;有问题可以提issue, 我会在这里持续添加更多直播平台的录制 欢迎Star&lt;/h2&gt; 
&lt;h4&gt;&lt;/h4&gt;</description>
    </item>
    
    <item>
      <title>Alibaba-NLP/WebAgent</title>
      <link>https://github.com/Alibaba-NLP/WebAgent</link>
      <description>&lt;p&gt;🌐 WebAgent for Information Seeking built by Tongyi Lab: WebWalker &amp; WebDancer &amp; WebSailor &amp; WebShaper https://arxiv.org/abs/2507.15061 https://arxiv.org/pdf/2507.02592&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h2&gt;WebAgent for Information Seeking built by Tongyi Lab, Alibaba Group &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="30px" style="display:inline;"&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14217" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14217" alt="Alibaba-NLP%2FWebAgent | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 🤗 &lt;a href="https://huggingface.co/datasets/Alibaba-NLP/WebShaper" target="_blank"&gt;WebShaperQA&lt;/a&gt; ｜ &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="14px" style="display:inline;"&gt; &lt;a href="https://modelscope.cn/datasets/iic/WebShaper" target="_blank"&gt;WebShaperQA&lt;/a&gt; ｜ 🤗 &lt;a href="https://huggingface.co/Alibaba-NLP/WebSailor-3B" target="_blank"&gt;WebSailor-3B&lt;/a&gt; ｜ &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="14px" style="display:inline;"&gt; &lt;a href="https://modelscope.cn/models/iic/WebSailor-3B" target="_blank"&gt;ModelScope WebSailor-3B&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; 🤗 &lt;a href="https://huggingface.co/Alibaba-NLP/WebDancer-32B" target="_blank"&gt;WebDancer-QwQ-32B&lt;/a&gt; | &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="14px" style="display:inline;"&gt; &lt;a href="https://modelscope.cn/models/iic/WebDancer-32B" target="_blank"&gt;ModelScope WebDancer-QwQ-32B&lt;/a&gt; | 🤗 &lt;a href="https://huggingface.co/datasets/callanwu/WebWalkerQA" target="_blank"&gt;WebWalkerQA&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/roadmap.png" width="100%" height="400%"&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You can check the paper of &lt;a href="https://arxiv.org/pdf/2505.22648"&gt;WebDancer&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2501.07572"&gt;WebWalker&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2507.02592"&gt;WebSailor&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2507.15061"&gt;WebShaper&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💥 💥 💥 Stay tuned for more updates! We are working on building native agentic model based on the Browser and more open-domain environments!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebShaper"&gt;&lt;strong&gt;WebShaper&lt;/strong&gt;&lt;/a&gt; (Preprint 2025) - WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebSailor"&gt;&lt;strong&gt;WebSailor&lt;/strong&gt;&lt;/a&gt; (Preprint 2025) - WebSailor: Navigating Super-human Reasoning for Web Agent&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebDancer"&gt;&lt;strong&gt;WebDancer&lt;/strong&gt;&lt;/a&gt; (Preprint 2025) - WebDancer: Towards Autonomous Information Seeking Agency&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebWalker"&gt;&lt;strong&gt;WebWalker&lt;/strong&gt;&lt;/a&gt; (ACL 2025) - WebWalker: Benchmarking LLMs in Web Traversal&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📰 News and Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;2025.07.22&lt;/code&gt; 🔥🔥🔥We release &lt;strong&gt;WebShaper&lt;/strong&gt;: Agentically Data Synthesizing via Information-Seeking Formalization.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.07.11&lt;/code&gt; 🔥🔥🔥&lt;strong&gt;WebSailor-3B&lt;/strong&gt; is &lt;a href="https://huggingface.co/Alibaba-NLP/WebSailor-3B"&gt;released&lt;/a&gt;. You can deploy it with one click using &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/aliyun.png" width="14px" style="display:inline;"&gt; &lt;a href="https://functionai.console.aliyun.com/template-detail?template=Alibaba-NLP-WebSailor-3B"&gt;Alibaba Cloud's FunctionAI&lt;/a&gt; in ten minutes!&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.07.03&lt;/code&gt; 🔥🔥🔥We release &lt;strong&gt;WebSailor&lt;/strong&gt;, an agentic search model specialized in performing extremely complex information seeking tasks, achieving open-source SOTA on some of the most difficult browsing benchmarks. &lt;strong&gt;WebSailor&lt;/strong&gt; topped the HuggingFace &lt;a href="https://huggingface.co/papers/2507.02592"&gt;daily papers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.06.23&lt;/code&gt; 🔥🔥🔥The model, interactive demo, and some of the data of &lt;strong&gt;WebDancer&lt;/strong&gt; have been open-sourced. You're welcome to try them out!&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.05.29&lt;/code&gt; 🔥🔥🔥We release &lt;strong&gt;WebDancer&lt;/strong&gt;, a native agentic search model towards autonomous information seeking agency and &lt;em&gt;Deep Research&lt;/em&gt;-like model.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.05.15&lt;/code&gt; &lt;strong&gt;WebWalker&lt;/strong&gt; is accepted by ACL 2025 main conference.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.01.14&lt;/code&gt; We release &lt;strong&gt;WebWalker&lt;/strong&gt;, a benchmark for LLMs in web traversal and a multi-agent framework for information seeking.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;💎 Results Showcase&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/webagent-gaia.png" width="800%" height="400%"&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/webagent-bc.png" width="800%" height="400%"&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;💡 Features for WebShaper&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A &lt;strong&gt;&lt;code&gt;formalization-driven&lt;/code&gt;&lt;/strong&gt; data synthesis method for information-seeking agents, grounded in our proposed task formalization. Leveraging this method, we construct the &lt;strong&gt;WebShaper&lt;/strong&gt; dataset, which enables systematic generation of IS instances.&lt;/li&gt; 
 &lt;li&gt;We propose an agentic Expander that iteratively generates and validates questions in alignment with the formalization.&lt;/li&gt; 
 &lt;li&gt;We conduct extensive experiments across multiple benchmarks to evaluate the effectiveness of WebShaper. We achieve new state-of-the-art results on &lt;strong&gt;GAIA&lt;/strong&gt; (&lt;strong&gt;60.19&lt;/strong&gt;) and &lt;strong&gt;WebWalkerQA&lt;/strong&gt; (&lt;strong&gt;52.50&lt;/strong&gt;) benchmarks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;⛵️ Features for WebSailor&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A complete post-training methodology enabling models to engage in extended thinking and information seeking, ultimately allowing them to successfully complete extremely complex tasks previously considered unsolvable.&lt;/li&gt; 
 &lt;li&gt;Introduces &lt;strong&gt;SailorFog-QA&lt;/strong&gt;, a scalable QA benchmark with high uncertainty and difficulty, curated with a novel data synthesis method through graph sampling and information obfuscation. Example SailorFog-QA data samples can be found at: &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebSailor/dataset/sailorfog-QA.jsonl"&gt;&lt;code&gt;WebSailor/dataset/sailorfog-QA.jsonl&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Effective post-training pipeline consisting of (1) high-quality reconstruction of concise reasoning from expert trajectories for clean supervision, (2) a two-stage training process involving an RFT cold start stage, followed by &lt;strong&gt;Duplicating Sampling Policy Optimization (DUPO)&lt;/strong&gt;, an efficient agentic RL algorithm excelling in effectiveness and efficiency.&lt;/li&gt; 
 &lt;li&gt;WebSailor-72B significantly outperforms all open-source agents and frameworks while closing the performance gap with leading proprietary systems, achieving a score of &lt;strong&gt;12.0%&lt;/strong&gt; on BrowseComp-en, &lt;strong&gt;30.1%&lt;/strong&gt; on BrowseComp-zh, and &lt;strong&gt;55.4%&lt;/strong&gt; on GAIA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The checkpoint is coming soon.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🌐 Features for WebDancer&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Native agentic search reasoning model using ReAct framework towards autonomous information seeking agency and &lt;em&gt;Deep Research&lt;/em&gt;-like model.&lt;/li&gt; 
 &lt;li&gt;We introduce a four-stage training paradigm comprising &lt;strong&gt;browsing data construction, trajectory sampling, supervised fine-tuning for effective cold start, and reinforcement learning for improved generalization&lt;/strong&gt;, enabling the agent to autonomously acquire autonomous search and reasoning skills.&lt;/li&gt; 
 &lt;li&gt;Our data-centric approach integrates trajectory-level supervision fine-tuning and reinforcement learning (DAPO) to develop a scalable pipeline for &lt;strong&gt;training agentic systems&lt;/strong&gt; via SFT or RL.&lt;/li&gt; 
 &lt;li&gt;WebDancer achieves a Pass@3 score of 64.1% on GAIA and 62.0% on WebWalkerQA.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;p&gt;You need to enter the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebDancer"&gt;&lt;code&gt;WebDancer&lt;/code&gt;&lt;/a&gt; folder for the following commands.&lt;/p&gt; 
&lt;h3&gt;Step 0: Set Up the Environment&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n webdancer python=3.12
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 1: Deploy the Model&lt;/h3&gt; 
&lt;p&gt;Download the WebDancer model from &lt;a href="https://huggingface.co/Alibaba-NLP/WebDancer-32B"&gt;🤗 HuggingFace&lt;/a&gt; and deploy it using the provided scripts with &lt;a href="https://github.com/sgl-project/sglang"&gt;sglang&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd scripts
bash deploy_model.sh WebDancer_PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Replace &lt;code&gt;WebDancer_PATH&lt;/code&gt; with the actual path to the downloaded model.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Step 2: Run the Demo&lt;/h3&gt; 
&lt;p&gt;Edit the following keys in &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebDancer/scripts/run_demo.sh"&gt;&lt;code&gt;WebDancer/scripts/run_demo.sh&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GOOGLE_SEARCH_KEY&lt;/code&gt;, you can get it from &lt;a href="https://serper.dev/"&gt;serper&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;JINA_API_KEY&lt;/code&gt;, you can get it from &lt;a href="https://jina.ai/api-dashboard/"&gt;jina&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DASHSCOPE_API_KEY&lt;/code&gt;, you can get it from &lt;a href="https://dashscope.aliyun.com/"&gt;dashscope&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, launch the demo with Gradio to interact with the WebDancer model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd scripts
bash run_demo.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🎥 WebSailor Demos&lt;/h2&gt; 
&lt;p&gt;We provide demos for BrowseComp-en, BrowseComp-zh and Daily Use. Our model can complete highly difficult and uncertain tasks requiring massive information acquisition and complex reasoning.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;BrowseComp-en&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/2dc0b03a-c241-4f70-bf11-92fda28020fa"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;BrowseComp-zh&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/f9aed746-ffc8-4b76-b135-715ec0eab544"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;Daily Use&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/1299c5a8-cee3-4a70-b68b-c5d227cf8055"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;h2&gt;🎥 WebDancer Demos&lt;/h2&gt; 
&lt;p&gt;We provide demos for WebWalkerQA, GAIA and Daily Use. Our model can execute the long-horizon tasks with &lt;strong&gt;multiple steps&lt;/strong&gt; and &lt;strong&gt;complex reasoning&lt;/strong&gt;, such as web traversal, information seeking and question answering.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;WebWalkerQA&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/0bbaf55b-897e-4c57-967d-a6e8bbd2167e"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;GAIA&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/935c668e-6169-4712-9c04-ac80f0531872"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;Daily Use&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/d1d5b533-4009-478b-bd87-96b86389327d"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;h2&gt;📃 License&lt;/h2&gt; 
&lt;p&gt;The content of this project itself is licensed under &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🚩 Citation&lt;/h2&gt; 
&lt;p&gt;If this work is helpful, please kindly cite as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bigquery"&gt;@misc{tao2025webshaper,
      title={WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization},
      author={Zhengwei Tao and Jialong Wu and Wenbiao Yin and Junkai Zhang and Baixuan Li and Haiyang Shen and Kuan Li and Liwen Zhang and Xinyu Wang and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2507.15061},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.15061},
}
@misc{li2025websailor,
      title={WebSailor: Navigating Super-human Reasoning for Web Agent},
      author={Kuan Li and Zhongwang Zhang and Huifeng Yin and Liwen Zhang and Litu Ou and Jialong Wu and Wenbiao Yin and Baixuan Li and Zhengwei Tao and Xinyu Wang and Weizhou Shen and Junkai Zhang and Dingchu Zhang and Xixi Wu and Yong Jiang and Ming Yan and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2507.02592},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.02592},
}
@misc{wu2025webdancer,
      title={WebDancer: Towards Autonomous Information Seeking Agency},
      author={Jialong Wu and Baixuan Li and Runnan Fang and Wenbiao Yin and Liwen Zhang and Zhengwei Tao and Dingchu Zhang and Zekun Xi and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2505.22648},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.22648},
}
@misc{wu2025webwalker,
      title={WebWalker: Benchmarking LLMs in Web Traversal},
      author={Jialong Wu and Wenbiao Yin and Yong Jiang and Zhenglin Wang and Zekun Xi and Runnan Fang and Deyu Zhou and Pengjun Xie and Fei Huang},
      year={2025},
      eprint={2501.07572},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.07572},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🌟 Misc&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#Alibaba-NLP/WebAgent&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Alibaba-NLP/WebAgent&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🚩 Talent Recruitment&lt;/h2&gt; 
&lt;p&gt;🔥🔥🔥 We are hiring! Research intern positions are open (based in Hangzhou、Beijing、Shanghai)&lt;/p&gt; 
&lt;p&gt;📚 &lt;strong&gt;Research Area&lt;/strong&gt;：Web Agent, Search Agent, Agent RL, MultiAgent RL, Agentic RAG&lt;/p&gt; 
&lt;p&gt;☎️ &lt;strong&gt;Contact&lt;/strong&gt;：&lt;a href=""&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contact Information&lt;/h2&gt; 
&lt;p&gt;For communications, please contact Yong Jiang (&lt;a href="mailto:yongjiang.jy@alibaba-inc.com"&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>snailyp/gemini-balance</title>
      <link>https://github.com/snailyp/gemini-balance</link>
      <description>&lt;p&gt;Gemini polling proxy service （gemini轮询代理服务）&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/snailyp/gemini-balance/main/README_ZH.md"&gt;Read this document in Chinese&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Gemini Balance - Gemini API Proxy and Load Balancer&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/13692" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/13692" alt="snailyp%2Fgemini-balance | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Python-3.9%2B-blue.svg?sanitize=true" alt="Python"&gt;&lt;/a&gt; &lt;a href="https://fastapi.tiangolo.com/"&gt;&lt;img src="https://img.shields.io/badge/FastAPI-0.100%2B-green.svg?sanitize=true" alt="FastAPI"&gt;&lt;/a&gt; &lt;a href="https://www.uvicorn.org/"&gt;&lt;img src="https://img.shields.io/badge/Uvicorn-running-purple.svg?sanitize=true" alt="Uvicorn"&gt;&lt;/a&gt; &lt;a href="https://t.me/+soaHax5lyI0wZDVl"&gt;&lt;img src="https://img.shields.io/badge/Telegram-Group-blue.svg?logo=telegram" alt="Telegram Group"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⚠️ &lt;strong&gt;Important&lt;/strong&gt;: This project is licensed under the &lt;a href="https://raw.githubusercontent.com/snailyp/gemini-balance/main/LICENSE"&gt;CC BY-NC 4.0&lt;/a&gt; license. &lt;strong&gt;Any form of commercial resale service is prohibited&lt;/strong&gt;. I have never sold this service on any platform. If you encounter someone selling this service, they are a reseller. Please do not be deceived.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;h2&gt;📖 Project Introduction&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Gemini Balance&lt;/strong&gt; is an application built with Python FastAPI, designed to provide proxy and load balancing functions for the Google Gemini API. It allows you to manage multiple Gemini API Keys and implement key rotation, authentication, model filtering, and status monitoring through simple configuration. Additionally, the project integrates image generation and multiple image hosting upload functions, and supports proxying in the OpenAI API format.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;📂 View Project Structure&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-plaintext"&gt;app/
├── config/       # Configuration management
├── core/         # Core application logic (FastAPI instance creation, middleware, etc.)
├── database/     # Database models and connections
├── domain/       # Business domain objects
├── exception/    # Custom exceptions
├── handler/      # Request handlers
├── log/          # Logging configuration
├── main.py       # Application entry point
├── middleware/   # FastAPI middleware
├── router/       # API routes (Gemini, OpenAI, status page, etc.)
├── scheduler/    # Scheduled tasks (e.g., Key status check)
├── service/      # Business logic services (chat, Key management, statistics, etc.)
├── static/       # Static files (CSS, JS)
├── templates/    # HTML templates (e.g., Key status page)
└── utils/        # Utility functions
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;✨ Feature Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Key Load Balancing&lt;/strong&gt;: Supports configuring multiple Gemini API Keys (&lt;code&gt;API_KEYS&lt;/code&gt;) for automatic sequential polling.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Visual Configuration&lt;/strong&gt;: Configurations modified through the admin backend take effect immediately without restarting. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image4.png" alt="Configuration Panel"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dual Protocol API Compatibility&lt;/strong&gt;: Supports both Gemini and OpenAI CHAT API formats. 
  &lt;ul&gt; 
   &lt;li&gt;OpenAI Base URL: &lt;code&gt;http://localhost:8000(/hf)/v1&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Gemini Base URL: &lt;code&gt;http://localhost:8000(/gemini)/v1beta&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image-Text Chat &amp;amp; Modification&lt;/strong&gt;: Configure models with &lt;code&gt;IMAGE_MODELS&lt;/code&gt; to support image-text chat and editing. Use the &lt;code&gt;configured_model-image&lt;/code&gt; model name to invoke. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image6.png" alt="Chat with Image Generation"&gt; &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image7.png" alt="Modify Image"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web Search&lt;/strong&gt;: Configure models with &lt;code&gt;SEARCH_MODELS&lt;/code&gt; to support web search. Use the &lt;code&gt;configured_model-search&lt;/code&gt; model name to invoke. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image8.png" alt="Web Search"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Key Status Monitoring&lt;/strong&gt;: Provides a &lt;code&gt;/keys_status&lt;/code&gt; page (authentication required) for real-time monitoring. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image.png" alt="Monitoring Panel"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Detailed Logging&lt;/strong&gt;: Provides detailed error logs for easy troubleshooting. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image1.png" alt="Call Details"&gt; &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image2.png" alt="Log List"&gt; &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image3.png" alt="Log Details"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Key Addition&lt;/strong&gt;: Add keys in batches using the &lt;code&gt;gemini_key&lt;/code&gt; regex, with automatic deduplication. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image5.png" alt="Add Key"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Failure Retry &amp;amp; Auto-Disable&lt;/strong&gt;: Automatically retries failed API requests (&lt;code&gt;MAX_RETRIES&lt;/code&gt;) and disables keys after excessive failures (&lt;code&gt;MAX_FAILURES&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive API Compatibility&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Embeddings API&lt;/strong&gt;: Fully compatible with the OpenAI &lt;code&gt;embeddings&lt;/code&gt; API format.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Image Generation API&lt;/strong&gt;: Adapts the &lt;code&gt;imagen-3.0-generate-002&lt;/code&gt; model to the OpenAI image generation API format.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Model List Maintenance&lt;/strong&gt;: Automatically fetches and syncs the latest model lists from Gemini and OpenAI.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proxy Support&lt;/strong&gt;: Supports HTTP/SOCKS5 proxies (&lt;code&gt;PROXIES&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Support&lt;/strong&gt;: Provides Docker images for both AMD and ARM architectures. 
  &lt;ul&gt; 
   &lt;li&gt;Image Address: &lt;code&gt;ghcr.io/snailyp/gemini-balance:latest&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;h3&gt;Option 1: Docker Compose (Recommended)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Get &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/strong&gt;: Download the &lt;code&gt;docker-compose.yml&lt;/code&gt; file from the project repository.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prepare &lt;code&gt;.env&lt;/code&gt; file&lt;/strong&gt;: Copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; and configure it. Ensure &lt;code&gt;DATABASE_TYPE&lt;/code&gt; is set to &lt;code&gt;mysql&lt;/code&gt; and fill in the &lt;code&gt;MYSQL_*&lt;/code&gt; details.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start Services&lt;/strong&gt;: In the directory containing &lt;code&gt;docker-compose.yml&lt;/code&gt; and &lt;code&gt;.env&lt;/code&gt;, run: &lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Option 2: Docker Command&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Pull Image&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/snailyp/gemini-balance:latest
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prepare &lt;code&gt;.env&lt;/code&gt; file&lt;/strong&gt;: Copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; and configure it.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Run Container&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 8000:8000 --name gemini-balance \
-v ./data:/app/data \
--env-file .env \
ghcr.io/snailyp/gemini-balance:latest
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;-d&lt;/code&gt;: Detached mode.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-p 8000:8000&lt;/code&gt;: Map container port 8000 to host.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-v ./data:/app/data&lt;/code&gt;: Mount volume for persistent data.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--env-file .env&lt;/code&gt;: Load environment variables.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Option 3: Local Development&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Clone and Install&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/snailyp/gemini-balance.git
cd gemini-balance
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configure Environment&lt;/strong&gt;: Copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; and configure it.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start Application&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
&lt;/code&gt;&lt;/pre&gt; Access the application at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h2&gt;⚙️ API Endpoints&lt;/h2&gt; 
&lt;h3&gt;Gemini API Format (&lt;code&gt;/gemini/v1beta&lt;/code&gt;)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /models&lt;/code&gt;: List available Gemini models.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /models/{model_name}:generateContent&lt;/code&gt;: Generate content.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /models/{model_name}:streamGenerateContent&lt;/code&gt;: Stream content generation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;OpenAI API Format&lt;/h3&gt; 
&lt;h4&gt;Hugging Face (HF) Compatible&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /hf/v1/models&lt;/code&gt;: List models.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /hf/v1/chat/completions&lt;/code&gt;: Chat completion.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /hf/v1/embeddings&lt;/code&gt;: Create text embeddings.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /hf/v1/images/generations&lt;/code&gt;: Generate images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Standard OpenAI&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /openai/v1/models&lt;/code&gt;: List models.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /openai/v1/chat/completions&lt;/code&gt;: Chat completion (Recommended).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /openai/v1/embeddings&lt;/code&gt;: Create text embeddings.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /openai/v1/images/generations&lt;/code&gt;: Generate images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;details&gt; 
 &lt;summary&gt;📋 View Full Configuration List&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Configuration Item&lt;/th&gt; 
    &lt;th align="left"&gt;Description&lt;/th&gt; 
    &lt;th align="left"&gt;Default Value&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Database&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;DATABASE_TYPE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;mysql&lt;/code&gt; or &lt;code&gt;sqlite&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;mysql&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SQLITE_DATABASE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Path for SQLite database file&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;default_db&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_HOST&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL host address&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;localhost&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_SOCKET&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL socket address&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;/var/run/mysqld/mysqld.sock&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_PORT&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL port&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;3306&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_USER&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL username&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your_db_user&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_PASSWORD&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL password&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your_db_password&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_DATABASE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL database name&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;defaultdb&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;API&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;API_KEYS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Required&lt;/strong&gt;, list of Gemini API keys&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;ALLOWED_TOKENS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Required&lt;/strong&gt;, list of access tokens&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTH_TOKEN&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Super admin token, defaults to the first of &lt;code&gt;ALLOWED_TOKENS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;sk-123456&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;ADMIN_SESSION_EXPIRE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Admin session expiration time in seconds (5 minutes to 24 hours)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;3600&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TEST_MODEL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Model for testing key validity&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;gemini-1.5-flash&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;IMAGE_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Models supporting image generation&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;["gemini-2.0-flash-exp"]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SEARCH_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Models supporting web search&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;["gemini-2.0-flash-exp"]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;FILTERED_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Disabled models&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TOOLS_CODE_EXECUTION_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable code execution tool&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SHOW_SEARCH_LINK&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Display search result links in response&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SHOW_THINKING_PROCESS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Display model's thinking process&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;THINKING_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Models supporting thinking process&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;THINKING_BUDGET_MAP&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Budget map for thinking function (model:budget)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;{}&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;URL_NORMALIZATION_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable smart URL routing&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;URL_CONTEXT_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable URL context understanding&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;URL_CONTEXT_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Models supporting URL context&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;BASE_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Gemini API base URL&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;https://generativelanguage.googleapis.com/v1beta&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MAX_FAILURES&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Max failures allowed per key&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MAX_RETRIES&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Max retries for failed API requests&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CHECK_INTERVAL_HOURS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Interval (hours) to re-check disabled keys&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TIMEZONE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Application timezone&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;Asia/Shanghai&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TIME_OUT&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Request timeout (seconds)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;300&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;PROXIES&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;List of proxy servers&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Logging &amp;amp; Security&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;LOG_LEVEL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Log level: &lt;code&gt;DEBUG&lt;/code&gt;, &lt;code&gt;INFO&lt;/code&gt;, &lt;code&gt;WARNING&lt;/code&gt;, &lt;code&gt;ERROR&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;INFO&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTO_DELETE_ERROR_LOGS_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Auto-delete error logs&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTO_DELETE_ERROR_LOGS_DAYS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Error log retention period (days)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;7&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTO_DELETE_REQUEST_LOGS_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Auto-delete request logs&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTO_DELETE_REQUEST_LOGS_DAYS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Request log retention period (days)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SAFETY_SETTINGS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Content safety thresholds (JSON string)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[{"category": "HARM_CATEGORY_HARASSMENT", "threshold": "OFF"}, ...]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;TTS&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TTS_MODEL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;TTS model name&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;gemini-2.5-flash-preview-tts&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TTS_VOICE_NAME&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;TTS voice name&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;Zephyr&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TTS_SPEED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;TTS speed&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;normal&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Image Generation&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;PAID_KEY&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Paid API Key for advanced features&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your-paid-api-key&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CREATE_IMAGE_MODEL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Image generation model&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;imagen-3.0-generate-002&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;UPLOAD_PROVIDER&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Image upload provider: &lt;code&gt;smms&lt;/code&gt;, &lt;code&gt;picgo&lt;/code&gt;, &lt;code&gt;cloudflare_imgbed&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;smms&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SMMS_SECRET_TOKEN&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;SM.MS API Token&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your-smms-token&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;PICGO_API_KEY&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;PicoGo API Key&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your-picogo-apikey&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CLOUDFLARE_IMGBED_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;CloudFlare ImgBed upload URL&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;https://xxxxxxx.pages.dev/upload&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CLOUDFLARE_IMGBED_AUTH_CODE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;CloudFlare ImgBed auth key&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your-cloudflare-imgber-auth-code&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CLOUDFLARE_IMGBED_UPLOAD_FOLDER&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;CloudFlare ImgBed upload folder&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;""&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Stream Optimizer&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_OPTIMIZER_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable stream output optimization&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_MIN_DELAY&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Minimum stream output delay&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;0.016&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_MAX_DELAY&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Maximum stream output delay&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;0.024&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_SHORT_TEXT_THRESHOLD&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Short text threshold&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_LONG_TEXT_THRESHOLD&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Long text threshold&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;50&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_CHUNK_SIZE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Stream output chunk size&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;5&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Fake Stream&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;FAKE_STREAM_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable fake streaming&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;FAKE_STREAM_EMPTY_DATA_INTERVAL_SECONDS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Heartbeat interval for fake streaming (seconds)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;5&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;Pull Requests or Issues are welcome.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/snailyp/gemini-balance/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=snailyp/gemini-balance" alt="Contributors"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;⭐ Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#snailyp/gemini-balance&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=snailyp/gemini-balance&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🎉 Special Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.picgo.net/"&gt;PicGo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smms.app/"&gt;SM.MS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MarSeventh/CloudFlare-ImgBed"&gt;CloudFlare-ImgBed&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🙏 Our Supporters&lt;/h2&gt; 
&lt;p&gt;A special shout-out to &lt;a href="https://m.do.co/c/b249dd7f3b4c"&gt;DigitalOcean&lt;/a&gt; for providing the rock-solid and dependable cloud infrastructure that keeps this project humming!&lt;/p&gt; 
&lt;a href="https://m.do.co/c/b249dd7f3b4c"&gt; &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/dataocean.svg?sanitize=true" alt="DigitalOcean Logo" width="200"&gt; &lt;/a&gt; 
&lt;p&gt;CDN acceleration and security protection for this project are sponsored by &lt;a href="https://edgeone.ai/?from=github"&gt;Tencent EdgeOne&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://edgeone.ai/?from=github"&gt; &lt;img src="https://edgeone.ai/media/34fe3a45-492d-4ea4-ae5d-ea1087ca7b4b.png" alt="EdgeOne Logo" width="200"&gt; &lt;/a&gt; 
&lt;h2&gt;💖 Friendly Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/chengtx809/OneLine"&gt;OneLine&lt;/a&gt;&lt;/strong&gt; by &lt;a href="https://github.com/chengtx809"&gt;chengtx809&lt;/a&gt; - AI-driven hot event timeline generation tool.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎁 Project Support&lt;/h2&gt; 
&lt;p&gt;If you find this project helpful, consider supporting me via &lt;a href="https://afdian.com/a/snaily"&gt;Afdian&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/snailyp/gemini-balance/main/LICENSE"&gt;CC BY-NC 4.0&lt;/a&gt; (Attribution-NonCommercial) license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>frappe/hrms</title>
      <link>https://github.com/frappe/hrms</link>
      <description>&lt;p&gt;Open Source HR and Payroll Software&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt; &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/frappe-hr-logo.png" height="80px" width="80px" alt="Frappe HR Logo"&gt; &lt;/a&gt; 
 &lt;h2&gt;Frappe HR&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;Open Source, modern, and easy-to-use HR and Payroll Software&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/frappe/hrms/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/frappe/hrms/actions/workflows/ci.yml/badge.svg?branch=develop" alt="CI"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/frappe/hrms"&gt;&lt;img src="https://codecov.io/gh/frappe/hrms/branch/develop/graph/badge.svg?token=0TwvyUg3I5" alt="codecov"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/10972" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10972" alt="frappe%2Fhrms | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-hero.png"&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt;Website&lt;/a&gt; - 
 &lt;a href="https://docs.frappe.io/hr/introduction"&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Frappe HR&lt;/h2&gt; 
&lt;p&gt;Frappe HR has everything you need to drive excellence within the company. It's a complete HRMS solution with over 13 different modules right from Employee Management, Onboarding, Leaves, to Payroll, Taxation, and more!&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;When Frappe team started growing in terms of size, we needed an open-source HR and Payroll software. We didn't find any "true" open-source HR software out there and so decided to build one ourselves. Initially, it was a set of modules within ERPNext but version 14 onwards, as the modules became more mature, Frappe HR was created as a separate product.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Employee Lifecycle&lt;/strong&gt;: From onboarding employees, managing promotions and transfers, all the way to documenting feedback with exit interviews, make life easier for employees throughout their life cycle.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leave and Attendance&lt;/strong&gt;: Configure leave policies, pull regional holidays with a click, check-in and check-out with geolocation capturing, track leave balances and attendance with reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expense Claims and Advances&lt;/strong&gt;: Manage employee advances, claim expenses, configure multi-level approval workflows, all this with seamless integration with ERPNext accounting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Management&lt;/strong&gt;: Track goals, align goals with key result areas (KRAs), enable employees to evaluate themselves, make managing appraisal cycles easy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Payroll &amp;amp; Taxation&lt;/strong&gt;: Create salary structures, configure income tax slabs, run standard payroll, accomodate additional salaries and off cycle payments, view income breakup on salary slips and so much more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frappe HR Mobile App&lt;/strong&gt;: Apply for and approve leaves on the go, check-in and check-out, access employee profile right from the mobile app.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;View Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-appraisal.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-requisition.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-attendance.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-salary.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-pwa.png"&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe"&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe-ui"&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href="https://frappecloud.com"&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href="https://github.com/frappe/press"&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://frappecloud.com/hrms/signup" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/try-on-fc-white.png"&gt; 
   &lt;img src="https://frappe.io/files/try-on-fc-black.png" alt="Try on Frappe Cloud" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Development setup&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;You need Docker, docker-compose and git setup on your machine. Refer &lt;a href="https://docs.docker.com/"&gt;Docker documentation&lt;/a&gt;. After that, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/hrms
cd hrms/docker
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for some time until the setup script creates a site. After that you can access &lt;code&gt;http://localhost:8000&lt;/code&gt; in your browser and the login screen for HR should show up.&lt;/p&gt; 
&lt;p&gt;Use the following credentials to log in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: &lt;code&gt;Administrator&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Password: &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Set up bench by following the &lt;a href="https://frappeframework.com/docs/user/en/installation"&gt;Installation Steps&lt;/a&gt; and start the server and keep it running &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;In a separate terminal window, run the following commands &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench new-site hrms.local
$ bench get-app erpnext
$ bench get-app hrms
$ bench --site hrms.local install-app hrms
$ bench --site hrms.local add-to-hosts
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;You can access the site at &lt;code&gt;http://hrms.local:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and Community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://frappe.school"&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.frappe.io/hr"&gt;Documentation&lt;/a&gt; - Extensive documentation for Frappe HR.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.erpnext.com/"&gt;User Forum&lt;/a&gt; - Engage with the community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/frappehr"&gt;Telegram Group&lt;/a&gt; - Get instant help from the community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines"&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext.com/security"&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/frappe/hrms/develop/TRADEMARK_POLICY.md"&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;div align="center" style="padding-top: 0.75rem;"&gt; 
 &lt;a href="https://frappe.io" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/Frappe-white.png"&gt; 
   &lt;img src="https://frappe.io/files/Frappe-black.png" alt="Frappe Technologies" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>ostris/ai-toolkit</title>
      <link>https://github.com/ostris/ai-toolkit</link>
      <description>&lt;p&gt;The ultimate training toolkit for finetuning diffusion models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Toolkit by Ostris&lt;/h1&gt; 
&lt;p&gt;AI Toolkit is an all in one training suite for diffusion models. I try to support all the latest models on consumer grade hardware. Image and video models. It can be run as a GUI or CLI. It is designed to be easy to use but still have every feature imaginable.&lt;/p&gt; 
&lt;h2&gt;Support My Work&lt;/h2&gt; 
&lt;p&gt;If you enjoy my projects or use them commercially, please consider sponsoring me. Every bit helps! 💖&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/orgs/ostris"&gt;Sponsor on GitHub&lt;/a&gt; | &lt;a href="https://www.patreon.com/ostris"&gt;Support on Patreon&lt;/a&gt; | &lt;a href="https://www.paypal.com/donate/?hosted_button_id=9GEFUKC8T9R9W"&gt;Donate on PayPal&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Current Sponsors&lt;/h3&gt; 
&lt;p&gt;All of these people / organizations are the ones who selflessly make this project possible. Thank you!!&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Last updated: 2025-06-28 15:58 UTC&lt;/em&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://x.com/NuxZoe" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1919488160125616128/QAZXTMEj_400x400.png" alt="a16z" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;"&gt;&lt;/a&gt; &lt;a href="https://github.com/replicate" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/60410876?v=4" alt="Replicate" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;"&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/25720743?v=4" alt="Hugging Face" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;"&gt;&lt;/a&gt; &lt;a href="https://github.com/josephrocca" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1167575?u=92d92921b4cb5c8c7e225663fed53c4b41897736&amp;amp;v=4" alt="josephrocca" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;"&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/162524101/81a72689c3754ac5b9e38612ce5ce914/eyJ3IjoyMDB9/1.png?token-hash=JHRjAxd2XxV1aXIUijj-l65pfTnLoefYSvgNPAsw2lI%3D" alt="Prasanth Veerina" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;"&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/weights-ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/185568492?v=4" alt="Weights" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;"&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/93304/J" alt="Joseph Rocca" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/161471720/dd330b4036d44a5985ed5985c12a5def/eyJ3IjoyMDB9/1.jpeg?token-hash=k1f4Vv7TevzYa9tqlzAjsogYmkZs8nrXQohPCDGJGkc%3D" alt="Vladimir Sotnikov" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/33158543/C" alt="clement Delangue" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/8654302/b0f5ebedc62a47c4b56222693e1254e9/eyJ3IjoyMDB9/2.jpeg?token-hash=suI7_QjKUgWpdPuJPaIkElkTrXfItHlL8ZHLPT-w_d4%3D" alt="Misch Strotz" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/120239481/49b1ce70d3d24704b8ec34de24ec8f55/eyJ3IjoyMDB9/1.jpeg?token-hash=o0y1JqSXqtGvVXnxb06HMXjQXs6OII9yMMx5WyyUqT4%3D" alt="nitish PNR" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;"&gt; 
&lt;p align="center"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/2298192/1228b69bd7d7481baf3103315183250d/eyJ3IjoyMDB9/1.jpg?token-hash=opN1e4r4Nnvqbtr8R9HI8eyf9m5F50CiHDOdHzb4UcA%3D" alt="Mohamed Oumoumad" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/548524/S" alt="Steve Hanff" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/152118848/3b15a43d71714552b5ed1c9f84e66adf/eyJ3IjoyMDB9/1.png?token-hash=MKf3sWHz0MFPm_OAFjdsNvxoBfN5B5l54mn1ORdlRy8%3D" alt="Kristjan Retter" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/83319230/M" alt="Miguel Lara" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;a href="https://x.com/NuxZoe" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1916482710069014528/RDLnPRSg_400x400.jpg" alt="tungsten" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/8449560/P" alt="Patron" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/131773947/eda3405aa582437db4582fce908c8739/eyJ3IjoyMDB9/1.png?token-hash=hjsbCT71DRw44twCVNugBaOTY61N4-pQ8INOOoYOVxs%3D" alt="Jodh Singh" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/169502989/220069e79ce745b29237e94c22a729df/eyJ3IjoyMDB9/1.png?token-hash=E8E2JOqx66k2zMtYUw8Gy57dw-gVqA6OPpdCmWFFSFw%3D" alt="Timothy Bielec" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/2410522/G" alt="George Gostyshev" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/16287560/78130de30950410ca528d8a888997081/eyJ3IjoyMDB9/1.png?token-hash=J_ryHbLQQ1NpJIJORmT5jdrA6wgxvjMXrjbGoHikglc%3D" alt="Vitaly Golubenko" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;"&gt; 
&lt;p align="center"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/27288932/6c35d2d961ee4e14a7a368c990791315/eyJ3IjoyMDB9/1.jpeg?token-hash=TGIto_PGEG2NEKNyqwzEnRStOkhrjb3QlMhHA3raKJY%3D" alt="David Garrido" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/34200989/58ae95ebda0640c8b7a91b4fa31357aa/eyJ3IjoyMDB9/1.jpeg?token-hash=4mVDM1kCYGauYa33zLG14_g0oj9_UjDK_-Qp4zk42GE%3D" alt="Noah Miller" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/81275465/1e4148fe9c47452b838949d02dd9a70f/eyJ3IjoyMDB9/1.jpeg?token-hash=YAX1ucxybpCIujUCXfdwzUQkttIn3c7pfi59uaFPSwM%3D" alt="Aaron Amortegui" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/338551/e8f257d8d3dd46c38272b391a5785948/eyJ3IjoyMDB9/1.jpg?token-hash=eZ_9Do55OaQYOmiYxFGv-YUKKJiOV6qdv3Hhv-ecouk%3D" alt="Plaidam" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/570742/4ceb33453a5a4745b430a216aba9280f/eyJ3IjoyMDB9/1.jpg?token-hash=nPcJ2zj3sloND9jvbnbYnob2vMXRnXdRuujthqDLWlU%3D" alt="Al H" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/82763/f99cc484361d4b9d94fe4f0814ada303/eyJ3IjoyMDB9/1.jpeg?token-hash=A3JWlBNL0b24FFWb-FCRDAyhs-OAxg-zrhfBXP_axuU%3D" alt="Doron Adler" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/99036356/7ae9c4d80e604e739b68cca12ee2ed01/eyJ3IjoyMDB9/3.png?token-hash=ZhsBMoTOZjJ-Y6h5NOmU5MT-vDb2fjK46JDlpEehkVQ%3D" alt="Noctre" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/141098579/1a9f0a1249d447a7a0df718a57343912/eyJ3IjoyMDB9/2.png?token-hash=_n-AQmPgY0FP9zCGTIEsr5ka4Y7YuaMkt3qL26ZqGg8%3D" alt="The Local Lab" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/98811435/3a3632d1795b4c2b9f8f0270f2f6a650/eyJ3IjoyMDB9/1.jpeg?token-hash=657rzuJ0bZavMRZW3XZ-xQGqm3Vk6FkMZgFJVMCOPdk%3D" alt="EmmanuelMr18" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/27791680/J" alt="Jean-Tristan Marin" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/4105384/J" alt="Jack Blakely" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/103077711/bb215761cc004e80bd9cec7d4bcd636d/eyJ3IjoyMDB9/2.jpeg?token-hash=3U8kdZSUpnmeYIDVK4zK9TTXFpnAud_zOwBRXx18018%3D" alt="John Dopamine" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/93348210/5c650f32a0bc481d80900d2674528777/eyJ3IjoyMDB9/1.jpeg?token-hash=0jiknRw3jXqYWW6En8bNfuHgVDj4LI_rL7lSS4-_xlo%3D" alt="Armin Behjati" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/155963250/6f8fd7075c3b4247bfeb054ba49172d6/eyJ3IjoyMDB9/1.png?token-hash=z81EHmdU2cqSrwa9vJmZTV3h0LG-z9Qakhxq34FrYT4%3D" alt="Un Defined" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/45562978/0de33cf52ec642ae8a2f612cddec4ca6/eyJ3IjoyMDB9/1.jpeg?token-hash=aD4debMD5ZQjqTII6s4zYSgVK2-bdQt9p3eipi0bENs%3D" alt="Jack English" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/60995694/92e0e8f336eb4a5bb8d99b940247d1d1/eyJ3IjoyMDB9/1.png?token-hash=5ea18PFzxMl94hHv_luaZYFqhCCvEa_hzbHnPsagcrQ%3D" alt="Abraham Irawan" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/44568304/a9d83a0e786b41b4bdada150f7c9271c/eyJ3IjoyMDB9/1.jpeg?token-hash=FtxnwrSrknQUQKvDRv2rqPceX2EF23eLq4pNQYM_fmw%3D" alt="Albert Bukoski" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/134129880/680c7e14cd1a4d1a9face921fb010f88/eyJ3IjoyMDB9/1.png?token-hash=5fqqHE6DCTbt7gDQL7VRcWkV71jF7FvWcLhpYl5aMXA%3D" alt="Bharat Prabhakar" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/70218846/C" alt="Cosmosis" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/83054970/13de6cb103ad41a5841edf549e66cd51/eyJ3IjoyMDB9/1.jpeg?token-hash=V3rXc47rrrjpoMb94tEHxXIaUB2RnWkXLmXak1d-lNc%3D" alt="Gili Ben Shahar" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/30931983/54ab4e4ceab946e79a6418d205f9ed51/eyJ3IjoyMDB9/1.png?token-hash=j2phDrgd6IWuqKqNIDbq9fR2B3fMF-GUCQSdETS1w5Y%3D" alt="HestoySeghuro ." width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/494309/J" alt="Julian Tsependa" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/24653779/R" alt="RayHell" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/4541423/S" alt="Sören " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/31950857/c567dc648f6144be9f6234946df05da2/eyJ3IjoyMDB9/1.jpeg?token-hash=FPYLcxwaL-B1-wvNMAqTYGYzi0ZlTwe5-nNJkb7znE8%3D" alt="Trent Hunter" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/110407414/30f9e9d88ef945ddb0f47fd23a8cbac2/eyJ3IjoyMDB9/1.jpeg?token-hash=H6yJ1pzUahBymaHrUuY6grqJAsGilPtpQpK5pGsi8xE%3D" alt="Wesley Reitzfeld" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/32633822/1ab5612efe80417cbebfe91e871fc052/eyJ3IjoyMDB9/1.png?token-hash=pOS_IU3b3RL5-iL96A3Xqoj2bQ-dDo4RUkBylcMED_s%3D" alt="Zack Abrams" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/97985240/3d1d0e6905d045aba713e8132cab4a30/eyJ3IjoyMDB9/1.png?token-hash=fRavvbO_yqWKA_OsJb5DzjfKZ1Yt-TG-ihMoeVBvlcM%3D" alt="עומר מכלוף" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/5048649/B" alt="Ben Ward" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/111904990/08b1cf65be6a4de091c9b73b693b3468/eyJ3IjoyMDB9/1.png?token-hash=_Odz6RD3CxtubEHbUxYujcjw6zAajbo3w8TRz249VBA%3D" alt="Brian Smith" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/113207022/d4a67cc113e84fb69032bef71d068720/eyJ3IjoyMDB9/1.png?token-hash=eoIz9jCEVuvH088o-chrr7YuIBvdpYG7QO65lBnlPbw%3D" alt="Fagem X" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/5602036/K" alt="Kelevra" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/159203973/36c817f941ac4fa18103a4b8c0cb9cae/eyJ3IjoyMDB9/1.png?token-hash=zkt72HW3EoiIEAn3LSk9gJPBsXfuTVcc4rRBS3CeR8w%3D" alt="Marko jak" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/11198131/e696d9647feb4318bcf16243c2425805/eyJ3IjoyMDB9/1.jpeg?token-hash=c2c2p1SaiX86iXAigvGRvzm4jDHvIFCg298A49nIfUM%3D" alt="Nicholas Agranoff" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/785333/bdb9ede5765d42e5a2021a86eebf0d8f/eyJ3IjoyMDB9/2.jpg?token-hash=l_rajMhxTm6wFFPn7YdoKBxeUqhdRXKdy6_8SGCuNsE%3D" alt="Sapjes " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/2446176/S" alt="Scott VanKirk" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/76566911/6485eaf5ec6249a7b524ee0b979372f0/eyJ3IjoyMDB9/1.jpeg?token-hash=mwCSkTelDBaengG32NkN0lVl5mRjB-cwo6-a47wnOsU%3D" alt="the biitz" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/83034/W" alt="william tatum" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/138787189/2b5662dcb638466282ac758e3ac651b4/eyJ3IjoyMDB9/1.png?token-hash=zwj7MScO18vhDxhKt6s5q4gdeNJM3xCLuhSt8zlqlZs%3D" alt="Антон Антонио" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/25209707/36ae876d662d4d85aaf162b6d67d31e7/eyJ3IjoyMDB9/1.png?token-hash=Zows_A6uqlY5jClhfr4Y3QfMnDKVkS3mbxNHUDkVejo%3D" alt="fjioq8" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/53077895/M" alt="Marc" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/157407541/bb9d80cffdab4334ad78366060561520/eyJ3IjoyMDB9/2.png?token-hash=WYz-U_9zabhHstOT5UIa5jBaoFwrwwqyWxWEzIR2m_c%3D" alt="Tokio Studio srl IT10640050968" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/46680573/ee3d99c04a674dd5a8e1ecfb926db6a2/eyJ3IjoyMDB9/1.jpeg?token-hash=cgD4EXyfZMPnXIrcqWQ5jGqzRUfqjPafb9yWfZUPB4Q%3D" alt="Neil Murray" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;a href="https://github.com/julien-blanchon" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/11278197?v=4" alt="Blanchon" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/88567307/E" alt="el Chavo" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/117569999/55f75c57f95343e58402529cec852b26/eyJ3IjoyMDB9/1.jpeg?token-hash=squblHZH4-eMs3gI46Uqu1oTOK9sQ-0gcsFdZcB9xQg%3D" alt="James Thompson" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/66157709/6fe70df085e24464995a1a9293a53760/eyJ3IjoyMDB9/1.jpeg?token-hash=eqe0wvg6JfbRUGMKpL_x3YPI5Ppf18aUUJe2EzADU-g%3D" alt="Joey Santana" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/30530914/T" alt="Techer " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c8.patreon.com/4/200/63510241/A" alt="Andrew Park" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/103916378/d7850a1901a14497b36945d58b095f2a/eyJ3IjoyMDB9/1.jpeg?token-hash=m8Am6GWUGsTWbTrTm6ntot9iYhQ07WdkHZw74qi4B2E%3D" alt="B. Elliott Baker" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;a href="https://github.com/Spikhalskiy" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/532108?u=2464983638afea8caf4cd9f0e4a7bc3e6a63bb0a&amp;amp;v=4" alt="Dmitry Spikhalsky" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/28533016/e8f6044ccfa7483f87eeaa01c894a773/eyJ3IjoyMDB9/2.png?token-hash=ak-h3JWB50hyenCavcs32AAPw6nNhmH2nBFKpdk5hvM%3D" alt="William Tatum" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;"&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;python &amp;gt;3.10&lt;/li&gt; 
 &lt;li&gt;Nvidia GPU with enough ram to do what you need&lt;/li&gt; 
 &lt;li&gt;python venv&lt;/li&gt; 
 &lt;li&gt;git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Linux:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
python3 -m venv venv
source venv/bin/activate
# install torch first
pip3 install --no-cache-dir torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126
pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Windows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
python -m venv venv
.\venv\Scripts\activate
pip install --no-cache-dir torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;AI Toolkit UI&lt;/h1&gt; 
&lt;img src="https://ostris.com/wp-content/uploads/2025/02/toolkit-ui.jpg" alt="AI Toolkit UI" width="100%"&gt; 
&lt;p&gt;The AI Toolkit UI is a web interface for the AI Toolkit. It allows you to easily start, stop, and monitor jobs. It also allows you to easily train models with a few clicks. It also allows you to set a token for the UI to prevent unauthorized access so it is mostly safe to run on an exposed server.&lt;/p&gt; 
&lt;h2&gt;Running the UI&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Node.js &amp;gt; 18&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The UI does not need to be kept running for the jobs to run. It is only needed to start/stop/monitor jobs. The commands below will install / update the UI and it's dependencies and start the UI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ui
npm run build_and_start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can now access the UI at &lt;code&gt;http://localhost:8675&lt;/code&gt; or &lt;code&gt;http://&amp;lt;your-ip&amp;gt;:8675&lt;/code&gt; if you are running it on a server.&lt;/p&gt; 
&lt;h2&gt;Securing the UI&lt;/h2&gt; 
&lt;p&gt;If you are hosting the UI on a cloud provider or any network that is not secure, I highly recommend securing it with an auth token. You can do this by setting the environment variable &lt;code&gt;AI_TOOLKIT_AUTH&lt;/code&gt; to super secure password. This token will be required to access the UI. You can set this when starting the UI like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Linux
AI_TOOLKIT_AUTH=super_secure_password npm run build_and_start

# Windows
set AI_TOOLKIT_AUTH=super_secure_password &amp;amp;&amp;amp; npm run build_and_start

# Windows Powershell
$env:AI_TOOLKIT_AUTH="super_secure_password"; npm run build_and_start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FLUX.1 Training&lt;/h2&gt; 
&lt;h3&gt;Tutorial&lt;/h3&gt; 
&lt;p&gt;To get started quickly, check out &lt;a href="https://x.com/araminta_k"&gt;@araminta_k&lt;/a&gt; tutorial on &lt;a href="https://www.youtube.com/watch?v=HzGW_Kyermg"&gt;Finetuning Flux Dev on a 3090&lt;/a&gt; with 24GB VRAM.&lt;/p&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;You currently need a GPU with &lt;strong&gt;at least 24GB of VRAM&lt;/strong&gt; to train FLUX.1. If you are using it as your GPU to control your monitors, you probably need to set the flag &lt;code&gt;low_vram: true&lt;/code&gt; in the config file under &lt;code&gt;model:&lt;/code&gt;. This will quantize the model on CPU and should allow it to train with monitors attached. Users have gotten it to work on Windows with WSL, but there are some reports of a bug when running on windows natively. I have only tested on linux for now. This is still extremely experimental and a lot of quantizing and tricks had to happen to get it to fit on 24GB at all.&lt;/p&gt; 
&lt;h3&gt;FLUX.1-dev&lt;/h3&gt; 
&lt;p&gt;FLUX.1-dev has a non-commercial license. Which means anything you train will inherit the non-commercial license. It is also a gated model, so you need to accept the license on HF before using it. Otherwise, this will fail. Here are the required steps to setup a license.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Sign into HF and accept the model access here &lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-dev"&gt;black-forest-labs/FLUX.1-dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Make a file named &lt;code&gt;.env&lt;/code&gt; in the root on this folder&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/settings/tokens/new?"&gt;Get a READ key from huggingface&lt;/a&gt; and add it to the &lt;code&gt;.env&lt;/code&gt; file like so &lt;code&gt;HF_TOKEN=your_key_here&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;FLUX.1-schnell&lt;/h3&gt; 
&lt;p&gt;FLUX.1-schnell is Apache 2.0. Anything trained on it can be licensed however you want and it does not require a HF_TOKEN to train. However, it does require a special adapter to train with it, &lt;a href="https://huggingface.co/ostris/FLUX.1-schnell-training-adapter"&gt;ostris/FLUX.1-schnell-training-adapter&lt;/a&gt;. It is also highly experimental. For best overall quality, training on FLUX.1-dev is recommended.&lt;/p&gt; 
&lt;p&gt;To use it, You just need to add the assistant to the &lt;code&gt;model&lt;/code&gt; section of your config file like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      model:
        name_or_path: "black-forest-labs/FLUX.1-schnell"
        assistant_lora_path: "ostris/FLUX.1-schnell-training-adapter"
        is_flux: true
        quantize: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You also need to adjust your sample steps since schnell does not require as many&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      sample:
        guidance_scale: 1  # schnell does not do guidance
        sample_steps: 4  # 1 - 4 works well
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Training&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Copy the example config file located at &lt;code&gt;config/examples/train_lora_flux_24gb.yaml&lt;/code&gt; (&lt;code&gt;config/examples/train_lora_flux_schnell_24gb.yaml&lt;/code&gt; for schnell) to the &lt;code&gt;config&lt;/code&gt; folder and rename it to &lt;code&gt;whatever_you_want.yml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Edit the file following the comments in the file&lt;/li&gt; 
 &lt;li&gt;Run the file like so &lt;code&gt;python run.py config/whatever_you_want.yml&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A folder with the name and the training folder from the config file will be created when you start. It will have all checkpoints and images in it. You can stop the training at any time using ctrl+c and when you resume, it will pick back up from the last checkpoint.&lt;/p&gt; 
&lt;p&gt;IMPORTANT. If you press crtl+c while it is saving, it will likely corrupt that checkpoint. So wait until it is done saving&lt;/p&gt; 
&lt;h3&gt;Need help?&lt;/h3&gt; 
&lt;p&gt;Please do not open a bug report unless it is a bug in the code. You are welcome to &lt;a href="https://discord.gg/VXmU2f5WEU"&gt;Join my Discord&lt;/a&gt; and ask for help there. However, please refrain from PMing me directly with general question or support. Ask in the discord and I will answer when I can.&lt;/p&gt; 
&lt;h2&gt;Gradio UI&lt;/h2&gt; 
&lt;p&gt;To get started training locally with a with a custom UI, once you followed the steps above and &lt;code&gt;ai-toolkit&lt;/code&gt; is installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai-toolkit #in case you are not yet in the ai-toolkit folder
huggingface-cli login #provide a `write` token to publish your LoRA at the end
python flux_train_ui.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will instantiate a UI that will let you upload your images, caption them, train and publish your LoRA &lt;img src="https://raw.githubusercontent.com/ostris/ai-toolkit/main/assets/lora_ease_ui.png" alt="image"&gt;&lt;/p&gt; 
&lt;h2&gt;Training in RunPod&lt;/h2&gt; 
&lt;p&gt;Example RunPod template: &lt;strong&gt;runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You need a minimum of 24GB VRAM, pick a GPU by your preference.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Example config ($0.5/hr):&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;1x A40 (48 GB VRAM)&lt;/li&gt; 
 &lt;li&gt;19 vCPU 100 GB RAM&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Custom overrides (you need some storage to clone FLUX.1, store datasets, store trained models and samples):&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;~120 GB Disk&lt;/li&gt; 
 &lt;li&gt;~120 GB Pod Volume&lt;/li&gt; 
 &lt;li&gt;Start Jupyter Notebook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
git submodule update --init --recursive
python -m venv venv
source venv/bin/activate
pip install torch
pip install -r requirements.txt
pip install --upgrade accelerate transformers diffusers huggingface_hub #Optional, run it if you run into issues
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Upload your dataset&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a new folder in the root, name it &lt;code&gt;dataset&lt;/code&gt; or whatever you like.&lt;/li&gt; 
 &lt;li&gt;Drag and drop your .jpg, .jpeg, or .png images and .txt files inside the newly created dataset folder.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Login into Hugging Face with an Access Token&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Get a READ token from &lt;a href="https://huggingface.co/settings/tokens"&gt;here&lt;/a&gt; and request access to Flux.1-dev model from &lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-dev"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;huggingface-cli login&lt;/code&gt; and paste your token.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Training&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Copy an example config file located at &lt;code&gt;config/examples&lt;/code&gt; to the config folder and rename it to &lt;code&gt;whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Edit the config following the comments in the file.&lt;/li&gt; 
 &lt;li&gt;Change &lt;code&gt;folder_path: "/path/to/images/folder"&lt;/code&gt; to your dataset path like &lt;code&gt;folder_path: "/workspace/ai-toolkit/your-dataset"&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run the file: &lt;code&gt;python run.py config/whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Screenshot from RunPod&lt;/h3&gt; 
&lt;img width="1728" alt="RunPod Training Screenshot" src="https://github.com/user-attachments/assets/53a1b8ef-92fa-4481-81a7-bde45a14a7b5"&gt; 
&lt;h2&gt;Training in Modal&lt;/h2&gt; 
&lt;h3&gt;1. Setup&lt;/h3&gt; 
&lt;h4&gt;ai-toolkit:&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
git submodule update --init --recursive
python -m venv venv
source venv/bin/activate
pip install torch
pip install -r requirements.txt
pip install --upgrade accelerate transformers diffusers huggingface_hub #Optional, run it if you run into issues
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Modal:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run &lt;code&gt;pip install modal&lt;/code&gt; to install the modal Python package.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;modal setup&lt;/code&gt; to authenticate (if this doesn’t work, try &lt;code&gt;python -m modal setup&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Hugging Face:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Get a READ token from &lt;a href="https://huggingface.co/settings/tokens"&gt;here&lt;/a&gt; and request access to Flux.1-dev model from &lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-dev"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;huggingface-cli login&lt;/code&gt; and paste your token.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. Upload your dataset&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Drag and drop your dataset folder containing the .jpg, .jpeg, or .png images and .txt files in &lt;code&gt;ai-toolkit&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Configs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Copy an example config file located at &lt;code&gt;config/examples/modal&lt;/code&gt; to the &lt;code&gt;config&lt;/code&gt; folder and rename it to &lt;code&gt;whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Edit the config following the comments in the file, &lt;strong&gt;&lt;ins&gt;be careful and follow the example &lt;code&gt;/root/ai-toolkit&lt;/code&gt; paths&lt;/ins&gt;&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Edit run_modal.py&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Set your entire local &lt;code&gt;ai-toolkit&lt;/code&gt; path at &lt;code&gt;code_mount = modal.Mount.from_local_dir&lt;/code&gt; like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;code_mount = modal.Mount.from_local_dir("/Users/username/ai-toolkit", remote_path="/root/ai-toolkit")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Choose a &lt;code&gt;GPU&lt;/code&gt; and &lt;code&gt;Timeout&lt;/code&gt; in &lt;code&gt;@app.function&lt;/code&gt; &lt;em&gt;(default is A100 40GB and 2 hour timeout)&lt;/em&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. Training&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run the config file in your terminal: &lt;code&gt;modal run run_modal.py --config-file-list-str=/root/ai-toolkit/config/whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;You can monitor your training in your local terminal, or on &lt;a href="https://modal.com/"&gt;modal.com&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Models, samples and optimizer will be stored in &lt;code&gt;Storage &amp;gt; flux-lora-models&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;6. Saving the model&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check contents of the volume by running &lt;code&gt;modal volume ls flux-lora-models&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Download the content by running &lt;code&gt;modal volume get flux-lora-models your-model-name&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Example: &lt;code&gt;modal volume get flux-lora-models my_first_flux_lora_v1&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Screenshot from Modal&lt;/h3&gt; 
&lt;img width="1728" alt="Modal Traning Screenshot" src="https://github.com/user-attachments/assets/7497eb38-0090-49d6-8ad9-9c8ea7b5388b"&gt; 
&lt;hr&gt; 
&lt;h2&gt;Dataset Preparation&lt;/h2&gt; 
&lt;p&gt;Datasets generally need to be a folder containing images and associated text files. Currently, the only supported formats are jpg, jpeg, and png. Webp currently has issues. The text files should be named the same as the images but with a &lt;code&gt;.txt&lt;/code&gt; extension. For example &lt;code&gt;image2.jpg&lt;/code&gt; and &lt;code&gt;image2.txt&lt;/code&gt;. The text file should contain only the caption. You can add the word &lt;code&gt;[trigger]&lt;/code&gt; in the caption file and if you have &lt;code&gt;trigger_word&lt;/code&gt; in your config, it will be automatically replaced.&lt;/p&gt; 
&lt;p&gt;Images are never upscaled but they are downscaled and placed in buckets for batching. &lt;strong&gt;You do not need to crop/resize your images&lt;/strong&gt;. The loader will automatically resize them and can handle varying aspect ratios.&lt;/p&gt; 
&lt;h2&gt;Training Specific Layers&lt;/h2&gt; 
&lt;p&gt;To train specific layers with LoRA, you can use the &lt;code&gt;only_if_contains&lt;/code&gt; network kwargs. For instance, if you want to train only the 2 layers used by The Last Ben, &lt;a href="https://x.com/__TheBen/status/1829554120270987740"&gt;mentioned in this post&lt;/a&gt;, you can adjust your network kwargs like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lora"
        linear: 128
        linear_alpha: 128
        network_kwargs:
          only_if_contains:
            - "transformer.single_transformer_blocks.7.proj_out"
            - "transformer.single_transformer_blocks.20.proj_out"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The naming conventions of the layers are in diffusers format, so checking the state dict of a model will reveal the suffix of the name of the layers you want to train. You can also use this method to only train specific groups of weights. For instance to only train the &lt;code&gt;single_transformer&lt;/code&gt; for FLUX.1, you can use the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lora"
        linear: 128
        linear_alpha: 128
        network_kwargs:
          only_if_contains:
            - "transformer.single_transformer_blocks."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also exclude layers by their names by using &lt;code&gt;ignore_if_contains&lt;/code&gt; network kwarg. So to exclude all the single transformer blocks,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lora"
        linear: 128
        linear_alpha: 128
        network_kwargs:
          ignore_if_contains:
            - "transformer.single_transformer_blocks."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;ignore_if_contains&lt;/code&gt; takes priority over &lt;code&gt;only_if_contains&lt;/code&gt;. So if a weight is covered by both, if will be ignored.&lt;/p&gt; 
&lt;h2&gt;LoKr Training&lt;/h2&gt; 
&lt;p&gt;To learn more about LoKr, read more about it at &lt;a href="https://github.com/KohakuBlueleaf/LyCORIS/raw/main/docs/Guidelines.md"&gt;KohakuBlueleaf/LyCORIS&lt;/a&gt;. To train a LoKr model, you can adjust the network type in the config file like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lokr"
        lokr_full_rank: true
        lokr_factor: 8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Everything else should work the same including layer targeting.&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;Only larger updates are listed here. There are usually smaller daily updated that are omitted.&lt;/p&gt; 
&lt;h3&gt;Jul 17, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Make it easy to add control images to the samples in the ui&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Jul 11, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added better video config settings to the UI for video models.&lt;/li&gt; 
 &lt;li&gt;Added Wan I2V training to the UI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 29, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed issue where Kontext forced sizes on sampling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 26, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added support for FLUX.1 Kontext training&lt;/li&gt; 
 &lt;li&gt;added support for instruction dataset training&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 25, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added support for OmniGen2 training&lt;/li&gt; 
 &lt;li&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 17, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Performance optimizations for batch preparation&lt;/li&gt; 
 &lt;li&gt;Added some docs via a popup for items in the simple ui explaining what settings do. Still a WIP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 16, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hide control images in the UI when viewing datasets&lt;/li&gt; 
 &lt;li&gt;WIP on mean flow loss&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 12, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed issue that resulted in blank captions in the dataloader&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 10, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Decided to keep track up updates in the readme&lt;/li&gt; 
 &lt;li&gt;Added support for SDXL in the UI&lt;/li&gt; 
 &lt;li&gt;Added support for SD 1.5 in the UI&lt;/li&gt; 
 &lt;li&gt;Fixed UI Wan 2.1 14b name bug&lt;/li&gt; 
 &lt;li&gt;Added support for for conv training in the UI for models that support it&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Genesis-Embodied-AI/Genesis</title>
      <link>https://github.com/Genesis-Embodied-AI/Genesis</link>
      <description>&lt;p&gt;A generative world for general-purpose robotics &amp; embodied AI learning.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/imgs/big_text.png" alt="Genesis"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/imgs/teaser.png" alt="Teaser"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/genesis-world/"&gt;&lt;img src="https://img.shields.io/pypi/v/genesis-world" alt="PyPI - Version"&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/genesis-world"&gt;&lt;img src="https://static.pepy.tech/badge/genesis-world" alt="PyPI Downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/issues"&gt;&lt;img src="https://img.shields.io/github/issues/Genesis-Embodied-AI/Genesis" alt="GitHub Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/Genesis-Embodied-AI/Genesis" alt="GitHub Discussions"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/nukCuhB47p"&gt;&lt;img src="https://img.shields.io/discord/1322086972302430269?logo=discord" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://drive.google.com/uc?export=view&amp;amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white" height="20" style="display:inline"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/English-d9d9d9" alt="README in English"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_FR.md"&gt;&lt;img src="https://img.shields.io/badge/Francais-d9d9d9" alt="README en Français"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_KR.md"&gt;&lt;img src="https://img.shields.io/badge/%ED%95%9C%EA%B5%AD%EC%96%B4-d9d9d9" alt="한국어 README"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_CN.md"&gt;&lt;img src="https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-d9d9d9" alt="简体中文版自述文件"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_JA.md"&gt;&lt;img src="https://img.shields.io/badge/%E6%97%A5%E6%9C%AC%E8%AA%9E-d9d9d9" alt="日本語版 README"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Genesis&lt;/h1&gt; 
&lt;h2&gt;🔥 News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025-07-02] The development of Genesis is now officially supported by &lt;a href="https://genesis-ai.company/"&gt;Genesis AI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025-01-09] We released a &lt;a href="https://github.com/zhouxian/genesis-speed-benchmark"&gt;detailed performance benchmarking and comparison report&lt;/a&gt; on Genesis, together with all the test scripts.&lt;/li&gt; 
 &lt;li&gt;[2025-01-08] Released v0.2.1 🎊 🎉&lt;/li&gt; 
 &lt;li&gt;[2025-01-08] Created &lt;a href="https://discord.gg/nukCuhB47p"&gt;Discord&lt;/a&gt; and &lt;a href="https://drive.google.com/uc?export=view&amp;amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ"&gt;Wechat&lt;/a&gt; group.&lt;/li&gt; 
 &lt;li&gt;[2024-12-25] Added a &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#docker"&gt;docker&lt;/a&gt; including support for the ray-tracing renderer&lt;/li&gt; 
 &lt;li&gt;[2024-12-24] Added guidelines for &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/raw/main/.github/CONTRIBUTING.md"&gt;contributing to Genesis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#what-is-genesis"&gt;What is Genesis?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#quick-installation"&gt;Quick Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#contributing-to-genesis"&gt;Contributing to Genesis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#support"&gt;Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#license-and-acknowledgments"&gt;License and Acknowledgments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#associated-papers"&gt;Associated Papers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;What is Genesis?&lt;/h2&gt; 
&lt;p&gt;Genesis is a physics platform designed for general-purpose &lt;em&gt;Robotics/Embodied AI/Physical AI&lt;/em&gt; applications. It is simultaneously multiple things:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A &lt;strong&gt;universal physics engine&lt;/strong&gt; re-built from the ground up, capable of simulating a wide range of materials and physical phenomena.&lt;/li&gt; 
 &lt;li&gt;A &lt;strong&gt;lightweight&lt;/strong&gt;, &lt;strong&gt;ultra-fast&lt;/strong&gt;, &lt;strong&gt;pythonic&lt;/strong&gt;, and &lt;strong&gt;user-friendly&lt;/strong&gt; robotics simulation platform.&lt;/li&gt; 
 &lt;li&gt;A powerful and fast &lt;strong&gt;photo-realistic rendering system&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;A &lt;strong&gt;generative data engine&lt;/strong&gt; that transforms user-prompted natural language description into various modalities of data.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Powered by a universal physics engine re-designed and re-built from the ground up, Genesis integrates various physics solvers and their coupling into a unified framework. This core physics engine is further enhanced by a generative agent framework that operates at an upper level, aiming towards fully automated data generation for robotics and beyond.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Currently, we are open-sourcing the &lt;em&gt;underlying physics engine&lt;/em&gt; and the &lt;em&gt;simulation platform&lt;/em&gt;. Our &lt;em&gt;generative framework&lt;/em&gt; is a modular system that incorporates many different generative modules, each handling a certain range of data modalities, routed by a high level agent. Some of the modules integrated existing papers and some are still under submission. Access to our generative feature will be gradually rolled out in the near future. If you are interested, feel free to explore more in the &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#associated-papers"&gt;paper list&lt;/a&gt; below.&lt;/p&gt; 
&lt;p&gt;Genesis aims to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lower the barrier&lt;/strong&gt; to using physics simulations, making robotics research accessible to everyone. See our &lt;a href="https://genesis-world.readthedocs.io/en/latest/user_guide/overview/mission.html"&gt;mission statement&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unify diverse physics solvers&lt;/strong&gt; into a single framework to recreate the physical world with the highest fidelity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automate data generation&lt;/strong&gt;, reducing human effort and letting the data flywheel spin on its own.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Project Page: &lt;a href="https://genesis-embodied-ai.github.io/"&gt;https://genesis-embodied-ai.github.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Over 43 million FPS when simulating a Franka robotic arm with a single RTX 4090 (430,000 times faster than real-time).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-platform&lt;/strong&gt;: Runs on Linux, macOS, Windows, and supports multiple compute backends (CPU, Nvidia/AMD GPUs, Apple Metal).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integration of diverse physics solvers&lt;/strong&gt;: Rigid body, MPM, SPH, FEM, PBD, Stable Fluid.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wide range of material models&lt;/strong&gt;: Simulation and coupling of rigid bodies, liquids, gases, deformable objects, thin-shell objects, and granular materials.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compatibility with various robots&lt;/strong&gt;: Robotic arms, legged robots, drones, &lt;em&gt;soft robots&lt;/em&gt;, and support for loading &lt;code&gt;MJCF (.xml)&lt;/code&gt;, &lt;code&gt;URDF&lt;/code&gt;, &lt;code&gt;.obj&lt;/code&gt;, &lt;code&gt;.glb&lt;/code&gt;, &lt;code&gt;.ply&lt;/code&gt;, &lt;code&gt;.stl&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Photo-realistic rendering&lt;/strong&gt;: Native ray-tracing-based rendering.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Differentiability&lt;/strong&gt;: Genesis is designed to be fully differentiable. Currently, our MPM solver and Tool Solver support differentiability, with other solvers planned for future versions (starting with rigid &amp;amp; articulated body solver).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Physics-based tactile simulation&lt;/strong&gt;: Differentiable &lt;a href="https://github.com/Genesis-Embodied-AI/DiffTactile"&gt;tactile sensor simulation&lt;/a&gt; coming soon (expected in version 0.3.0).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User-friendliness&lt;/strong&gt;: Designed for simplicity, with intuitive installation and APIs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Installation&lt;/h2&gt; 
&lt;p&gt;Install &lt;strong&gt;PyTorch&lt;/strong&gt; first following the &lt;a href="https://pytorch.org/get-started/locally/"&gt;official instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Then, install Genesis via PyPI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install genesis-world  # Requires Python&amp;gt;=3.10,&amp;lt;3.14;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the latest version to date, make sure that &lt;code&gt;pip&lt;/code&gt; is up-to-date via &lt;code&gt;pip install --upgrade pip&lt;/code&gt;, then run command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/Genesis-Embodied-AI/Genesis.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the package must still be updated manually to sync with main branch.&lt;/p&gt; 
&lt;p&gt;Users seeking to edit the source code of Genesis are encourage to install Genesis in editable mode. First, make sure that &lt;code&gt;genesis-world&lt;/code&gt; has been uninstalled, then clone the repository and install locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Genesis-Embodied-AI/Genesis.git
cd Genesis
pip install -e ".[dev]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;If you want to use Genesis from Docker, you can first build the Docker image as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t genesis -f docker/Dockerfile docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the examples inside the docker image (mounted to &lt;code&gt;/workspace/examples&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;xhost +local:root # Allow the container to access the display

docker run --gpus all --rm -it \
-e DISPLAY=$DISPLAY \
-v /dev/dri:/dev/dri \
-v /tmp/.X11-unix/:/tmp/.X11-unix \
-v $PWD:/workspace \
genesis
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AMD users&lt;/h3&gt; 
&lt;p&gt;AMD users can use Genesis using the &lt;code&gt;docker/Dockerfile.amdgpu&lt;/code&gt; file, which is built by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker build -t genesis-amd -f docker/Dockerfile.amdgpu docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and can then be used by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xhost"&gt;docker run -it --network=host \
 --device=/dev/kfd \
 --device=/dev/dri \
 --group-add=video \
 --ipc=host \
 --cap-add=SYS_PTRACE \
 --security-opt seccomp=unconfined \
 --shm-size 8G \
 -v $PWD:/workspace \
 -e DISPLAY=$DISPLAY \
 genesis-amd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The examples will be accessible from &lt;code&gt;/workspace/examples&lt;/code&gt;. Note: AMD users should use the vulkan backend. This means you will need to call &lt;code&gt;gs.init(vulkan)&lt;/code&gt; to initialise Genesis.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Comprehensive documentation is available in &lt;a href="https://genesis-world.readthedocs.io/en/latest/user_guide/index.html"&gt;English&lt;/a&gt;, &lt;a href="https://genesis-world.readthedocs.io/zh-cn/latest/user_guide/index.html"&gt;Chinese&lt;/a&gt;, and &lt;a href="https://genesis-world.readthedocs.io/ja/latest/user_guide/index.html"&gt;Japanese&lt;/a&gt;. This includes detailed installation steps, tutorials, and API references.&lt;/p&gt; 
&lt;h2&gt;Contributing to Genesis&lt;/h2&gt; 
&lt;p&gt;The Genesis project is an open and collaborative effort. We welcome all forms of contributions from the community, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pull requests&lt;/strong&gt; for new features or bug fixes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug reports&lt;/strong&gt; through GitHub Issues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Suggestions&lt;/strong&gt; to improve Genesis's usability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Refer to our &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/raw/main/.github/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Report bugs or request features via GitHub &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/issues"&gt;Issues&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join discussions or ask questions on GitHub &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/discussions"&gt;Discussions&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License and Acknowledgments&lt;/h2&gt; 
&lt;p&gt;The Genesis source code is licensed under Apache 2.0.&lt;/p&gt; 
&lt;p&gt;Genesis's development has been made possible thanks to these open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taichi-dev/taichi"&gt;Taichi&lt;/a&gt;: High-performance cross-platform compute backend. Kudos to the Taichi team for their technical support!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zhouxian/FluidLab"&gt;FluidLab&lt;/a&gt;: Reference MPM solver implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/erizmr/SPH_Taichi"&gt;SPH_Taichi&lt;/a&gt;: Reference SPH solver implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://matthias-research.github.io/pages/tenMinutePhysics/index.html"&gt;Ten Minute Physics&lt;/a&gt; and &lt;a href="https://github.com/WASD4959/PBF3D"&gt;PBF3D&lt;/a&gt;: Reference PBD solver implementations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google-deepmind/mujoco"&gt;MuJoCo&lt;/a&gt;: Reference for rigid body dynamics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danfis/libccd"&gt;libccd&lt;/a&gt;: Reference for collision detection.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmatl/pyrender"&gt;PyRender&lt;/a&gt;: Rasterization-based renderer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuisaGroup/LuisaCompute"&gt;LuisaCompute&lt;/a&gt; and &lt;a href="https://github.com/LuisaGroup/LuisaRender"&gt;LuisaRender&lt;/a&gt;: Ray-tracing DSL.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shacklettbp/madrona"&gt;Madrona&lt;/a&gt; and &lt;a href="https://github.com/shacklettbp/madrona_mjx"&gt;Madrona-mjx&lt;/a&gt;: Batch renderer backend&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Associated Papers&lt;/h2&gt; 
&lt;p&gt;Genesis is a large scale effort that integrates state-of-the-art technologies of various existing and on-going research work into a single system. Here we include a non-exhaustive list of all the papers that contributed to the Genesis project in one way or another:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Xian, Zhou, et al. "Fluidlab: A differentiable environment for benchmarking complex fluid manipulation." arXiv preprint arXiv:2303.02346 (2023).&lt;/li&gt; 
 &lt;li&gt;Xu, Zhenjia, et al. "Roboninja: Learning an adaptive cutting policy for multi-material objects." arXiv preprint arXiv:2302.11553 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Yufei, et al. "Robogen: Towards unleashing infinite data for automated robot learning via generative simulation." arXiv preprint arXiv:2311.01455 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Tsun-Hsuan, et al. "Softzoo: A soft robot co-design benchmark for locomotion in diverse environments." arXiv preprint arXiv:2303.09555 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Tsun-Hsuan Johnson, et al. "Diffusebot: Breeding soft robots with physics-augmented generative diffusion models." Advances in Neural Information Processing Systems 36 (2023): 44398-44423.&lt;/li&gt; 
 &lt;li&gt;Katara, Pushkal, Zhou Xian, and Katerina Fragkiadaki. "Gen2sim: Scaling up robot learning in simulation with generative models." 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024.&lt;/li&gt; 
 &lt;li&gt;Si, Zilin, et al. "DiffTactile: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation." arXiv preprint arXiv:2403.08716 (2024).&lt;/li&gt; 
 &lt;li&gt;Wang, Yian, et al. "Thin-Shell Object Manipulations With Differentiable Physics Simulations." arXiv preprint arXiv:2404.00451 (2024).&lt;/li&gt; 
 &lt;li&gt;Lin, Chunru, et al. "UBSoft: A Simulation Platform for Robotic Skill Learning in Unbounded Soft Environments." arXiv preprint arXiv:2411.12711 (2024).&lt;/li&gt; 
 &lt;li&gt;Zhou, Wenyang, et al. "EMDM: Efficient motion diffusion model for fast and high-quality motion generation." European Conference on Computer Vision. Springer, Cham, 2025.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. "Scalable differentiable physics for learning and control." International Conference on Machine Learning. PMLR, 2020.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. "Efficient differentiable simulation of articulated bodies." In International Conference on Machine Learning, PMLR, 2021.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming Lin. "Differentiable simulation of soft multi-body systems." Advances in Neural Information Processing Systems 34 (2021).&lt;/li&gt; 
 &lt;li&gt;Wan, Weilin, et al. "Tlcontrol: Trajectory and language control for human motion synthesis." arXiv preprint arXiv:2311.17135 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Yian, et al. "Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical 2D Inpainting." arXiv preprint arXiv:2411.09823 (2024).&lt;/li&gt; 
 &lt;li&gt;Zheng, Shaokun, et al. "LuisaRender: A high-performance rendering framework with layered and unified interfaces on stream architectures." ACM Transactions on Graphics (TOG) 41.6 (2022): 1-19.&lt;/li&gt; 
 &lt;li&gt;Fan, Yingruo, et al. "Faceformer: Speech-driven 3d facial animation with transformers." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.&lt;/li&gt; 
 &lt;li&gt;Wu, Sichun, Kazi Injamamul Haque, and Zerrin Yumak. "ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE." Proceedings of the 17th ACM SIGGRAPH Conference on Motion, Interaction, and Games. 2024.&lt;/li&gt; 
 &lt;li&gt;Dou, Zhiyang, et al. "C· ase: Learning conditional adversarial skill embeddings for physics-based characters." SIGGRAPH Asia 2023 Conference Papers. 2023.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;... and many more on-going work.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use Genesis in your research, please consider citing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{Genesis,
  author = {Genesis Authors},
  title = {Genesis: A Generative and Universal Physics Engine for Robotics and Beyond},
  month = {December},
  year = {2024},
  url = {https://github.com/Genesis-Embodied-AI/Genesis}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Netflix/metaflow</title>
      <link>https://github.com/Netflix/metaflow</link>
      <description>&lt;p&gt;Build, Manage and Deploy AI/ML Systems&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/763451/89453116-96a57e00-d713-11ea-9fa6-82b29d4d6eff.png" alt="Metaflow_Logo_Horizontal_FullColor_Ribbon_Dark_RGB"&gt;&lt;/p&gt; 
&lt;h1&gt;Metaflow&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://metaflow.org"&gt;Metaflow&lt;/a&gt; is a human-centric framework designed to help scientists and engineers &lt;strong&gt;build and manage real-life AI and ML systems&lt;/strong&gt;. Serving teams of all sizes and scale, Metaflow streamlines the entire development lifecycle—from rapid prototyping in notebooks to reliable, maintainable production deployments—enabling teams to iterate quickly and deliver robust systems efficiently.&lt;/p&gt; 
&lt;p&gt;Originally developed at &lt;a href="https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9"&gt;Netflix&lt;/a&gt; and now supported by &lt;a href="https://outerbounds.com"&gt;Outerbounds&lt;/a&gt;, Metaflow is designed to boost the productivity for research and engineering teams working on &lt;a href="https://netflixtechblog.com/supporting-diverse-ml-systems-at-netflix-2d2e6b6d205d"&gt;a wide variety of projects&lt;/a&gt;, from classical statistics to state-of-the-art deep learning and foundation models. By unifying code, data, and compute at every stage, Metaflow ensures seamless, end-to-end management of real-world AI and ML systems.&lt;/p&gt; 
&lt;p&gt;Today, Metaflow powers thousands of AI and ML experiences across a diverse array of companies, large and small, including Amazon, Doordash, Dyson, Goldman Sachs, Ramp, and &lt;a href="https://raw.githubusercontent.com/Netflix/metaflow/master/ADOPTERS.md"&gt;many others&lt;/a&gt;. At Netflix alone, Metaflow supports over 3000 AI and ML projects, executes hundreds of millions of data-intensive high-performance compute jobs processing petabytes of data and manages tens of petabytes of models and artifacts for hundreds of users across its AI, ML, data science, and engineering teams.&lt;/p&gt; 
&lt;h2&gt;From prototype to production (and back)&lt;/h2&gt; 
&lt;p&gt;Metaflow provides a simple and friendly pythonic &lt;a href="https://docs.metaflow.org"&gt;API&lt;/a&gt; that covers foundational needs of AI and ML systems: &lt;img src="https://raw.githubusercontent.com/Netflix/metaflow/master/docs/prototype-to-prod.png" width="800px"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/metaflow/basics"&gt;Rapid local prototyping&lt;/a&gt;, &lt;a href="https://docs.metaflow.org/metaflow/managing-flows/notebook-runs"&gt;support for notebooks&lt;/a&gt;, and built-in support for &lt;a href="https://docs.metaflow.org/metaflow/client"&gt;experiment tracking, versioning&lt;/a&gt; and &lt;a href="https://docs.metaflow.org/metaflow/visualizing-results"&gt;visualization&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/scaling/remote-tasks/introduction"&gt;Effortlessly scale horizontally and vertically in your cloud&lt;/a&gt;, utilizing both CPUs and GPUs, with &lt;a href="https://docs.metaflow.org/scaling/data"&gt;fast data access&lt;/a&gt; for running &lt;a href="https://docs.metaflow.org/metaflow/basics#foreach"&gt;massive embarrassingly parallel&lt;/a&gt; as well as &lt;a href="https://docs.metaflow.org/scaling/remote-tasks/distributed-computing"&gt;gang-scheduled&lt;/a&gt; compute workloads &lt;a href="https://docs.metaflow.org/scaling/failures"&gt;reliably&lt;/a&gt; and &lt;a href="https://docs.metaflow.org/scaling/checkpoint/introduction"&gt;efficiently&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/scaling/dependencies"&gt;Easily manage dependencies&lt;/a&gt; and &lt;a href="https://docs.metaflow.org/production/introduction"&gt;deploy with one-click&lt;/a&gt; to highly available production orchestrators with built in support for &lt;a href="https://docs.metaflow.org/production/event-triggering"&gt;reactive orchestration&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For full documentation, check out our &lt;a href="https://docs.metaflow.org/api"&gt;API Reference&lt;/a&gt; or see our &lt;a href="https://github.com/Netflix/metaflow/releases"&gt;Release Notes&lt;/a&gt; for the latest features and improvements.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Getting up and running is easy. If you don't know where to start, &lt;a href="https://outerbounds.com/sandbox"&gt;Metaflow sandbox&lt;/a&gt; will have you running and exploring in seconds.&lt;/p&gt; 
&lt;h3&gt;Installing Metaflow&lt;/h3&gt; 
&lt;p&gt;To install Metaflow in your Python environment from &lt;a href="https://pypi.org/project/metaflow/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install metaflow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, using &lt;a href="https://anaconda.org/conda-forge/metaflow"&gt;conda-forge&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;conda install -c conda-forge metaflow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once installed, a great way to get started is by following our &lt;a href="https://docs.metaflow.org/getting-started/tutorials"&gt;tutorial&lt;/a&gt;. It walks you through creating and running your first Metaflow flow step by step.&lt;/p&gt; 
&lt;p&gt;For more details on Metaflow’s features and best practices, check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/metaflow/basics"&gt;How Metaflow works&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/introduction/metaflow-resources"&gt;Additional resources&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need help, don’t hesitate to reach out on our &lt;a href="http://slack.outerbounds.co/"&gt;Slack community&lt;/a&gt;!&lt;/p&gt; 
&lt;h3&gt;Deploying infrastructure for Metaflow in your cloud&lt;/h3&gt; 
&lt;img src="https://raw.githubusercontent.com/Netflix/metaflow/master/docs/multicloud.png" width="800px"&gt; 
&lt;p&gt;While you can get started with Metaflow easily on your laptop, the main benefits of Metaflow lie in its ability to &lt;a href="https://docs.metaflow.org/scaling/remote-tasks/introduction"&gt;scale out to external compute clusters&lt;/a&gt; and to &lt;a href="https://docs.metaflow.org/production/introduction"&gt;deploy to production-grade workflow orchestrators&lt;/a&gt;. To benefit from these features, follow this &lt;a href="https://outerbounds.com/engineering/welcome/"&gt;guide&lt;/a&gt; to configure Metaflow and the infrastructure behind it appropriately.&lt;/p&gt; 
&lt;h2&gt;Get in touch&lt;/h2&gt; 
&lt;p&gt;We'd love to hear from you. Join our community &lt;a href="http://slack.outerbounds.co/"&gt;Slack workspace&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to Metaflow. Please see our &lt;a href="https://docs.metaflow.org/introduction/contributing-to-metaflow"&gt;contribution guide&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>getzep/graphiti</title>
      <link>https://github.com/getzep/graphiti</link>
      <description>&lt;p&gt;Build Real-Time Knowledge Graphs for AI Agents&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.getzep.com/"&gt; &lt;img src="https://github.com/user-attachments/assets/119c5682-9654-4257-8922-56b7cb8ffd73" width="150" alt="Zep Logo"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Graphiti &lt;/h1&gt; 
&lt;h2 align="center"&gt; Build Real-Time Knowledge Graphs for AI Agents&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/getzep/Graphiti/actions/workflows/lint.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/lint.yml/badge.svg?style=flat" alt="Lint"&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml/badge.svg?sanitize=true" alt="Unit Tests"&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml/badge.svg?sanitize=true" alt="MyPy Check"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/getzep/graphiti" alt="GitHub Repo stars"&gt; &lt;a href="https://discord.com/invite/W8Kw6bsgXQ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2501.13956"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2501.13956-b31b1b.svg?style=flat" alt="arXiv"&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/graphiti/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/getzep/graphiti?style=flat&amp;amp;label=Release&amp;amp;color=limegreen" alt="Release"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12986" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12986" alt="getzep%2Fgraphiti | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;⭐&lt;/span&gt; &lt;em&gt;Help us reach more developers and grow the Graphiti community. Star this repo!&lt;/em&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Check out the new &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md"&gt;MCP server for Graphiti&lt;/a&gt;! Give Claude, Cursor, and other MCP clients powerful Knowledge Graph-based memory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Graphiti is a framework for building and querying temporally-aware knowledge graphs, specifically tailored for AI agents operating in dynamic environments. Unlike traditional retrieval-augmented generation (RAG) methods, Graphiti continuously integrates user interactions, structured and unstructured enterprise data, and external information into a coherent, queryable graph. The framework supports incremental data updates, efficient retrieval, and precise historical queries without requiring complete graph recomputation, making it suitable for developing interactive, context-aware AI applications.&lt;/p&gt; 
&lt;p&gt;Use Graphiti to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Integrate and maintain dynamic user interactions and business data.&lt;/li&gt; 
 &lt;li&gt;Facilitate state-based reasoning and task automation for agents.&lt;/li&gt; 
 &lt;li&gt;Query complex, evolving data with semantic, keyword, and graph-based search methods.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-graph-intro.gif" alt="Graphiti temporal walkthrough" width="700px"&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;A knowledge graph is a network of interconnected facts, such as &lt;em&gt;"Kendra loves Adidas shoes."&lt;/em&gt; Each fact is a "triplet" represented by two entities, or nodes ("Kendra", "Adidas shoes"), and their relationship, or edge ("loves"). Knowledge Graphs have been explored extensively for information retrieval. What makes Graphiti unique is its ability to autonomously build a knowledge graph while handling changing relationships and maintaining historical context.&lt;/p&gt; 
&lt;h2&gt;Graphiti and Zep's Context Engineering Platform.&lt;/h2&gt; 
&lt;p&gt;Graphiti powers the core of &lt;a href="https://www.getzep.com"&gt;Zep&lt;/a&gt;, a turn-key context engineering platform for AI Agents. Zep offers agent memory, Graph RAG for dynamic data, and context retrieval and assembly.&lt;/p&gt; 
&lt;p&gt;Using Graphiti, we've demonstrated Zep is the &lt;a href="https://blog.getzep.com/state-of-the-art-agent-memory/"&gt;State of the Art in Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Read our paper: &lt;a href="https://arxiv.org/abs/2501.13956"&gt;Zep: A Temporal Knowledge Graph Architecture for Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We're excited to open-source Graphiti, believing its potential reaches far beyond AI memory applications.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://arxiv.org/abs/2501.13956"&gt;&lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/arxiv-screenshot.png" alt="Zep: A Temporal Knowledge Graph Architecture for Agent Memory" width="700px"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Why Graphiti?&lt;/h2&gt; 
&lt;p&gt;Traditional RAG approaches often rely on batch processing and static data summarization, making them inefficient for frequently changing data. Graphiti addresses these challenges by providing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Incremental Updates:&lt;/strong&gt; Immediate integration of new data episodes without batch recomputation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bi-Temporal Data Model:&lt;/strong&gt; Explicit tracking of event occurrence and ingestion times, allowing accurate point-in-time queries.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Hybrid Retrieval:&lt;/strong&gt; Combines semantic embeddings, keyword (BM25), and graph traversal to achieve low-latency queries without reliance on LLM summarization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Entity Definitions:&lt;/strong&gt; Flexible ontology creation and support for developer-defined entities through straightforward Pydantic models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; Efficiently manages large datasets with parallel processing, suitable for enterprise environments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-intro-slides-stock-2.gif" alt="Graphiti structured + unstructured demo" width="700px"&gt; &lt;/p&gt; 
&lt;h2&gt;Graphiti vs. GraphRAG&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;GraphRAG&lt;/th&gt; 
   &lt;th&gt;Graphiti&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Primary Use&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Static document summarization&lt;/td&gt; 
   &lt;td&gt;Dynamic data management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Batch-oriented processing&lt;/td&gt; 
   &lt;td&gt;Continuous, incremental updates&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Knowledge Structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Entity clusters &amp;amp; community summaries&lt;/td&gt; 
   &lt;td&gt;Episodic data, semantic entities, communities&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Retrieval Method&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Sequential LLM summarization&lt;/td&gt; 
   &lt;td&gt;Hybrid semantic, keyword, and graph-based search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Adaptability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Low&lt;/td&gt; 
   &lt;td&gt;High&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Basic timestamp tracking&lt;/td&gt; 
   &lt;td&gt;Explicit bi-temporal tracking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Contradiction Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM-driven summarization judgments&lt;/td&gt; 
   &lt;td&gt;Temporal edge invalidation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Query Latency&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Seconds to tens of seconds&lt;/td&gt; 
   &lt;td&gt;Typically sub-second latency&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Custom Entity Types&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes, customizable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Moderate&lt;/td&gt; 
   &lt;td&gt;High, optimized for large datasets&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Graphiti is specifically designed to address the challenges of dynamic and frequently updated datasets, making it particularly suitable for applications requiring real-time interaction and precise historical queries.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or higher&lt;/li&gt; 
 &lt;li&gt;Neo4j 5.26 / FalkorDB 1.1.2 or higher (serves as the embeddings storage backend)&lt;/li&gt; 
 &lt;li&gt;OpenAI API key (Graphiti defaults to OpenAI for LLM inference and embedding)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti works best with LLM services that support Structured Output (such as OpenAI and Gemini). Using other services may result in incorrect output schemas and ingestion failures. This is particularly problematic when using smaller models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Optional:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Google Gemini, Anthropic, or Groq API key (for alternative LLM providers)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The simplest way to install Neo4j is via &lt;a href="https://neo4j.com/download/"&gt;Neo4j Desktop&lt;/a&gt;. It provides a user-friendly interface to manage Neo4j instances and databases. Alternatively, you can use FalkorDB on-premises via Docker and instantly start with the quickstart example:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing with FalkorDB Support&lt;/h3&gt; 
&lt;p&gt;If you plan to use FalkorDB as your graph database backend, install with the FalkorDB extra:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core[falkordb]

# or with uv
uv add graphiti-core[falkordb]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;You can also install optional LLM providers as extras:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install with Anthropic support
pip install graphiti-core[anthropic]

# Install with Groq support
pip install graphiti-core[groq]

# Install with Google Gemini support
pip install graphiti-core[google-genai]

# Install with multiple providers
pip install graphiti-core[anthropic,groq,google-genai]

# Install with FalkorDB and LLM providers
pip install graphiti-core[falkordb,anthropic,google-genai]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Default to Low Concurrency; LLM Provider 429 Rate Limit Errors&lt;/h2&gt; 
&lt;p&gt;Graphiti's ingestion pipelines are designed for high concurrency. By default, concurrency is set low to avoid LLM Provider 429 Rate Limit Errors. If you find Graphiti slow, please increase concurrency as described below.&lt;/p&gt; 
&lt;p&gt;Concurrency controlled by the &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; environment variable. By default, &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; is set to &lt;code&gt;10&lt;/code&gt; concurrent operations to help prevent &lt;code&gt;429&lt;/code&gt; rate limit errors from your LLM provider. If you encounter such errors, try lowering this value.&lt;/p&gt; 
&lt;p&gt;If your LLM provider allows higher throughput, you can increase &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; to boost episode ingestion performance.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti defaults to using OpenAI for LLM inference and embedding. Ensure that an &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is set in your environment. Support for Anthropic and Groq LLM inferences is available, too. Other LLM providers may be supported via OpenAI compatible APIs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For a complete working example, see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/examples/quickstart/README.md"&gt;Quickstart Example&lt;/a&gt; in the examples directory. The quickstart demonstrates:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Connecting to a Neo4j or FalkorDB database&lt;/li&gt; 
 &lt;li&gt;Initializing Graphiti indices and constraints&lt;/li&gt; 
 &lt;li&gt;Adding episodes to the graph (both text and structured JSON)&lt;/li&gt; 
 &lt;li&gt;Searching for relationships (edges) using hybrid search&lt;/li&gt; 
 &lt;li&gt;Reranking search results using graph distance&lt;/li&gt; 
 &lt;li&gt;Searching for nodes using predefined search recipes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The example is fully documented with clear explanations of each functionality and includes a comprehensive README with setup instructions and next steps.&lt;/p&gt; 
&lt;h2&gt;MCP Server&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;mcp_server&lt;/code&gt; directory contains a Model Context Protocol (MCP) server implementation for Graphiti. This server allows AI assistants to interact with Graphiti's knowledge graph capabilities through the MCP protocol.&lt;/p&gt; 
&lt;p&gt;Key features of the MCP server include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Episode management (add, retrieve, delete)&lt;/li&gt; 
 &lt;li&gt;Entity management and relationship handling&lt;/li&gt; 
 &lt;li&gt;Semantic and hybrid search capabilities&lt;/li&gt; 
 &lt;li&gt;Group management for organizing related data&lt;/li&gt; 
 &lt;li&gt;Graph maintenance operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The MCP server can be deployed using Docker with Neo4j, making it easy to integrate Graphiti into your AI assistant workflows.&lt;/p&gt; 
&lt;p&gt;For detailed setup instructions and usage examples, see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md"&gt;MCP server README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;REST Service&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;server&lt;/code&gt; directory contains an API service for interacting with the Graphiti API. It is built using FastAPI.&lt;/p&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/server/README.md"&gt;server README&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Optional Environment Variables&lt;/h2&gt; 
&lt;p&gt;In addition to the Neo4j and OpenAi-compatible credentials, Graphiti also has a few optional environment variables. If you are using one of our supported models, such as Anthropic or Voyage models, the necessary environment variables must be set.&lt;/p&gt; 
&lt;h3&gt;Database Configuration&lt;/h3&gt; 
&lt;p&gt;Database names are configured directly in the driver constructors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Neo4j&lt;/strong&gt;: Database name defaults to &lt;code&gt;neo4j&lt;/code&gt; (hardcoded in Neo4jDriver)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FalkorDB&lt;/strong&gt;: Database name defaults to &lt;code&gt;default_db&lt;/code&gt; (hardcoded in FalkorDriver)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As of v0.17.0, if you need to customize your database configuration, you can instantiate a database driver and pass it to the Graphiti constructor using the &lt;code&gt;graph_driver&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;h4&gt;Neo4j with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.neo4j_driver import Neo4jDriver

# Create a Neo4j driver with custom database name
driver = Neo4jDriver(
    uri="bolt://localhost:7687",
    user="neo4j",
    password="password",
    database="my_custom_database"  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;FalkorDB with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.falkordb_driver import FalkorDriver

# Create a FalkorDB driver with custom database name
driver = FalkorDriver(
    host="localhost",
    port=6379,
    username="falkor_user",  # Optional
    password="falkor_password",  # Optional
    database="my_custom_graph"  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Performance Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;USE_PARALLEL_RUNTIME&lt;/code&gt; is an optional boolean variable that can be set to true if you wish to enable Neo4j's parallel runtime feature for several of our search queries. Note that this feature is not supported for Neo4j Community edition or for smaller AuraDB instances, as such this feature is off by default.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Azure OpenAI&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Azure OpenAI for both LLM inference and embeddings. Azure deployments often require different endpoints for LLM and embedding services, and separate deployments for default and small models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import AsyncAzureOpenAI
from graphiti_core import Graphiti
from graphiti_core.llm_client import LLMConfig, OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Azure OpenAI configuration - use separate endpoints for different services
api_key = "&amp;lt;your-api-key&amp;gt;"
api_version = "&amp;lt;your-api-version&amp;gt;"
llm_endpoint = "&amp;lt;your-llm-endpoint&amp;gt;"  # e.g., "https://your-llm-resource.openai.azure.com/"
embedding_endpoint = "&amp;lt;your-embedding-endpoint&amp;gt;"  # e.g., "https://your-embedding-resource.openai.azure.com/"

# Create separate Azure OpenAI clients for different services
llm_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=llm_endpoint
)

embedding_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=embedding_endpoint
)

# Create LLM Config with your Azure deployment names
azure_llm_config = LLMConfig(
    small_model="gpt-4.1-nano",
    model="gpt-4.1-mini",
)

# Initialize Graphiti with Azure OpenAI clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=OpenAIClient(
        llm_config=azure_llm_config,
        client=llm_client_azure
    ),
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            embedding_model="text-embedding-3-small-deployment"  # Your Azure embedding deployment name
        ),
        client=embedding_client_azure
    ),
    cross_encoder=OpenAIRerankerClient(
        llm_config=LLMConfig(
            model=azure_llm_config.small_model  # Use small model for reranking
        ),
        client=llm_client_azure
    )
)

# Now you can use Graphiti with Azure OpenAI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure to replace the placeholder values with your actual Azure OpenAI credentials and deployment names that match your Azure OpenAI service configuration.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Google Gemini&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Google's Gemini models for LLM inference, embeddings, and cross-encoding/reranking. To use Gemini, you'll need to configure the LLM client, embedder, and the cross-encoder with your Google API key.&lt;/p&gt; 
&lt;p&gt;Install Graphiti:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add "graphiti-core[google-genai]"

# or

pip install "graphiti-core[google-genai]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig
from graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig
from graphiti_core.cross_encoder.gemini_reranker_client import GeminiRerankerClient

# Google API key configuration
api_key = "&amp;lt;your-google-api-key&amp;gt;"

# Initialize Graphiti with Gemini clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=GeminiClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.0-flash"
        )
    ),
    embedder=GeminiEmbedder(
        config=GeminiEmbedderConfig(
            api_key=api_key,
            embedding_model="embedding-001"
        )
    ),
    cross_encoder=GeminiRerankerClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.5-flash-lite-preview-06-17"
        )
    )
)

# Now you can use Graphiti with Google Gemini for all components
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Gemini reranker uses the &lt;code&gt;gemini-2.5-flash-lite-preview-06-17&lt;/code&gt; model by default, which is optimized for cost-effective and low-latency classification tasks. It uses the same boolean classification approach as the OpenAI reranker, leveraging Gemini's log probabilities feature to rank passage relevance.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Ollama (Local LLM)&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Ollama for running local LLMs and embedding models via Ollama's OpenAI-compatible API. This is ideal for privacy-focused applications or when you want to avoid API costs.&lt;/p&gt; 
&lt;p&gt;Install the models: ollama pull deepseek-r1:7b # LLM ollama pull nomic-embed-text # embeddings&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.config import LLMConfig
from graphiti_core.llm_client.openai_client import OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Configure Ollama LLM client
llm_config = LLMConfig(
    api_key="abc",  # Ollama doesn't require a real API key
    model="deepseek-r1:7b",
    small_model="deepseek-r1:7b",
    base_url="http://localhost:11434/v1", # Ollama provides this port
)

llm_client = OpenAIClient(config=llm_config)

# Initialize Graphiti with Ollama clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=llm_client,
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            api_key="abc",
            embedding_model="nomic-embed-text",
            embedding_dim=768,
            base_url="http://localhost:11434/v1",
        )
    ),
    cross_encoder=OpenAIRerankerClient(client=llm_client, config=llm_config),
)

# Now you can use Graphiti with local Ollama models
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure Ollama is running (&lt;code&gt;ollama serve&lt;/code&gt;) and that you have pulled the models you want to use.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti"&gt;Guides and API documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti/graphiti/quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti/graphiti/lang-graph-agent"&gt;Building an agent with LangChain's LangGraph and Graphiti&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;Graphiti collects anonymous usage statistics to help us understand how the framework is being used and improve it for everyone. We believe transparency is important, so here's exactly what we collect and why.&lt;/p&gt; 
&lt;h3&gt;What We Collect&lt;/h3&gt; 
&lt;p&gt;When you initialize a Graphiti instance, we collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anonymous identifier&lt;/strong&gt;: A randomly generated UUID stored locally in &lt;code&gt;~/.cache/graphiti/telemetry_anon_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System information&lt;/strong&gt;: Operating system, Python version, and system architecture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Graphiti version&lt;/strong&gt;: The version you're using&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configuration choices&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;LLM provider type (OpenAI, Azure, Anthropic, etc.)&lt;/li&gt; 
   &lt;li&gt;Database backend (Neo4j, FalkorDB)&lt;/li&gt; 
   &lt;li&gt;Embedder provider (OpenAI, Azure, Voyage, etc.)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What We Don't Collect&lt;/h3&gt; 
&lt;p&gt;We are committed to protecting your privacy. We &lt;strong&gt;never&lt;/strong&gt; collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Personal information or identifiers&lt;/li&gt; 
 &lt;li&gt;API keys or credentials&lt;/li&gt; 
 &lt;li&gt;Your actual data, queries, or graph content&lt;/li&gt; 
 &lt;li&gt;IP addresses or hostnames&lt;/li&gt; 
 &lt;li&gt;File paths or system-specific information&lt;/li&gt; 
 &lt;li&gt;Any content from your episodes, nodes, or edges&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Why We Collect This Data&lt;/h3&gt; 
&lt;p&gt;This information helps us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Understand which configurations are most popular to prioritize support and testing&lt;/li&gt; 
 &lt;li&gt;Identify which LLM and database providers to focus development efforts on&lt;/li&gt; 
 &lt;li&gt;Track adoption patterns to guide our roadmap&lt;/li&gt; 
 &lt;li&gt;Ensure compatibility across different Python versions and operating systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By sharing this anonymous information, you help us make Graphiti better for everyone in the community.&lt;/p&gt; 
&lt;h3&gt;View the Telemetry Code&lt;/h3&gt; 
&lt;p&gt;The Telemetry code &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/graphiti_core/telemetry/telemetry.py"&gt;may be found here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;How to Disable Telemetry&lt;/h3&gt; 
&lt;p&gt;Telemetry is &lt;strong&gt;opt-out&lt;/strong&gt; and can be disabled at any time. To disable telemetry collection:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Environment Variable&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export GRAPHITI_TELEMETRY_ENABLED=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Set in your shell profile&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For bash users (~/.bashrc or ~/.bash_profile)
echo 'export GRAPHITI_TELEMETRY_ENABLED=false' &amp;gt;&amp;gt; ~/.bashrc

# For zsh users (~/.zshrc)
echo 'export GRAPHITI_TELEMETRY_ENABLED=false' &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 3: Set for a specific Python session&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ['GRAPHITI_TELEMETRY_ENABLED'] = 'false'

# Then initialize Graphiti as usual
from graphiti_core import Graphiti
graphiti = Graphiti(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Telemetry is automatically disabled during test runs (when &lt;code&gt;pytest&lt;/code&gt; is detected).&lt;/p&gt; 
&lt;h3&gt;Technical Details&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Telemetry uses PostHog for anonymous analytics collection&lt;/li&gt; 
 &lt;li&gt;All telemetry operations are designed to fail silently - they will never interrupt your application or affect Graphiti functionality&lt;/li&gt; 
 &lt;li&gt;The anonymous ID is stored locally and is not tied to any personal information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status and Roadmap&lt;/h2&gt; 
&lt;p&gt;Graphiti is under active development. We aim to maintain API stability while working on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Supporting custom graph schemas: 
  &lt;ul&gt; 
   &lt;li&gt;Allow developers to provide their own defined node and edge classes when ingesting episodes&lt;/li&gt; 
   &lt;li&gt;Enable more flexible knowledge representation tailored to specific use cases&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Enhancing retrieval capabilities with more robust and configurable options&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Graphiti MCP Server&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Expanding test coverage to ensure reliability and catch edge cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We encourage and appreciate all forms of contributions, whether it's code, documentation, addressing GitHub Issues, or answering questions in the Graphiti Discord channel. For detailed guidelines on code contributions, please refer to &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.com/invite/W8Kw6bsgXQ"&gt;Zep Discord server&lt;/a&gt; and make your way to the &lt;strong&gt;#Graphiti&lt;/strong&gt; channel!&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>