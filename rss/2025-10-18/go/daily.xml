<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Fri, 17 Oct 2025 01:34:27 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>SagerNet/sing-box</title>
      <link>https://github.com/SagerNet/sing-box</link>
      <description>&lt;p&gt;The universal proxy platform&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;Sponsored by &lt;a href="https://go.warp.dev/sing-box"&gt;Warp&lt;/a&gt;, built for coding with multiple AI agents&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a href="https://go.warp.dev/sing-box"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/warpdotdev/brand-assets/raw/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;h1&gt;sing-box&lt;/h1&gt; 
&lt;p&gt;The universal proxy platform.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/sing-box/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/sing-box.svg?sanitize=true" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://sing-box.sagernet.org"&gt;https://sing-box.sagernet.org&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (C) 2022 by nekohasekai &amp;lt;contact-sagernet@sekai.icu&amp;gt;

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see &amp;lt;http://www.gnu.org/licenses/&amp;gt;.

In addition, no derivative work may use the name or imply association
with this application without prior consent.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>DataDog/datadog-agent</title>
      <link>https://github.com/DataDog/datadog-agent</link>
      <description>&lt;p&gt;Main repository for Datadog Agent&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Datadog Agent&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/v/release/DataDog/datadog-agent?style=flat&amp;amp;logo=datadog&amp;amp;logoColor=%23632CA6&amp;amp;labelColor=%23FFF&amp;amp;color=%23632CA6" alt="GitHub Release" /&gt; &lt;a href="https://codecov.io/github/DataDog/datadog-agent?branch=main"&gt;&lt;img src="https://codecov.io/github/DataDog/datadog-agent/coverage.svg?branch=main" alt="Coverage status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/DataDog/datadog-agent"&gt;&lt;img src="https://godoc.org/github.com/DataDog/datadog-agent?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repository contains the source code of the Datadog Agent version 7 and version 6. Please refer to the &lt;a href="https://docs.datadoghq.com/agent/"&gt;Agent user documentation&lt;/a&gt; for information about differences between Agent v5, Agent v6 and Agent v7. Additionally, we provide a list of prepackaged binaries for an easy install process &lt;a href="https://app.datadoghq.com/fleet/install-agent/latest?platform=overview"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://datadoghq.dev/datadog-agent/setup/"&gt;developer docs site&lt;/a&gt; contains information about how to develop the Datadog Agent itself.&lt;/p&gt; 
&lt;p&gt;The source of the content is located under &lt;a href="https://raw.githubusercontent.com/DataDog/datadog-agent/main/docs"&gt;the docs directory&lt;/a&gt; and may contain pages that are not yet published.&lt;/p&gt; 
&lt;h2&gt;Contributing code&lt;/h2&gt; 
&lt;p&gt;You'll find information and help on how to contribute code to this project under &lt;a href="https://raw.githubusercontent.com/DataDog/datadog-agent/main/docs/dev"&gt;the &lt;code&gt;docs/dev&lt;/code&gt; directory&lt;/a&gt; of the present repo.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The Datadog Agent user space components are licensed under the &lt;a href="https://raw.githubusercontent.com/DataDog/datadog-agent/main/LICENSE"&gt;Apache License, Version 2.0&lt;/a&gt;. The BPF code is licensed under the &lt;a href="https://raw.githubusercontent.com/DataDog/datadog-agent/main/pkg/ebpf/c/COPYING"&gt;General Public License, Version 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>golangci/golangci-lint</title>
      <link>https://github.com/golangci/golangci-lint</link>
      <description>&lt;p&gt;Fast linters runner for Go&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img alt="golangci-lint logo" src="https://raw.githubusercontent.com/golangci/golangci-lint/main/assets/go.png" height="150" /&gt; &lt;/p&gt;
&lt;h3 align="center"&gt;golangci-lint&lt;/h3&gt; 
&lt;p align="center"&gt;Fast linters runner for Go&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;code&gt;golangci-lint&lt;/code&gt; is a fast Go linters runner.&lt;/p&gt; 
&lt;p&gt;It runs linters in parallel, uses caching, supports YAML configuration, integrates with all major IDEs, and includes over a hundred linters.&lt;/p&gt; 
&lt;h2&gt;Install &lt;code&gt;golangci-lint&lt;/code&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://golangci-lint.run/docs/welcome/install/#local-installation"&gt;On my machine&lt;/a&gt;;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://golangci-lint.run/docs/welcome/install/#ci-installation"&gt;On CI/CD systems&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Documentation is hosted at &lt;a href="https://golangci-lint.run"&gt;https://golangci-lint.run&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Social Networks&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://gophers.slack.com/archives/CS0TBRKPC"&gt;&lt;img src="https://img.shields.io/badge/Slack-4285F4?logo=slack&amp;amp;logoColor=white" alt="Join Slack" /&gt;&lt;/a&gt; &lt;a href="https://fosstodon.org/@golangcilint"&gt;&lt;img src="https://img.shields.io/badge/Mastodon-6364FF?logo=mastodon&amp;amp;logoColor=white" alt="Follow on Mastodon" /&gt;&lt;/a&gt; &lt;a href="https://bsky.app/profile/golangci-lint.run"&gt;&lt;img src="https://img.shields.io/badge/Bluesky-0a7aff?logo=bluesky&amp;amp;logoColor=white" alt="Follow on Bluesky" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/golangci"&gt;&lt;img src="https://img.shields.io/badge/Twitter-1DA1F2?logo=x&amp;amp;logoColor=white" alt="Follow on Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support Us&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;golangci-lint&lt;/code&gt; is a free and open-source project built by volunteers.&lt;/p&gt; 
&lt;p&gt;If you value it, consider supporting us, we appreciate it! &lt;span&gt;❤️&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://donate.golangci.org"&gt;&lt;img src="https://img.shields.io/badge/Support-golangci_lint-blue?style=for-the-badge" alt="Golangci-lint" /&gt;&lt;/a&gt; &lt;a href="https://golangci-lint.run/docs/product/thanks/"&gt;&lt;img src="https://img.shields.io/badge/Support-Linter_Authors-blue?style=for-the-badge" alt="Linter Authors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Badges&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/golangci/golangci-lint/workflows/CI/badge.svg?sanitize=true" alt="Build Status" /&gt; &lt;a href="https://raw.githubusercontent.com/golangci/golangci-lint/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/golangci/golangci-lint" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/golangci/golangci-lint/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/golangci/golangci-lint.svg?sanitize=true" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/golangci/golangci-lint"&gt;&lt;img src="https://img.shields.io/docker/pulls/golangci/golangci-lint" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://somsubhra.github.io/github-release-stats/?username=golangci&amp;amp;repository=golangci-lint"&gt;&lt;img src="https://img.shields.io/github/downloads/golangci/golangci-lint/total.svg?logo=github" alt="GitHub Releases Stats of golangci-lint" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;This project exists thanks to all the people who contribute. &lt;a href="https://golangci-lint.run/docs/contributing/"&gt;How to contribute&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://github.com/golangci/golangci-lint/graphs/contributors"&gt; &lt;img src="https://opencollective.com/golangci-lint/contributors.svg?width=890&amp;amp;button=false&amp;amp;skip=golangcidev,CLAassistant,renovate,fossabot,golangcibot,kortschak,golangci-releaser,dependabot%5Bbot%5D" /&gt; &lt;/a&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p float="left"&gt; &lt;a href="https://www.jetbrains.com/go/?utm_source=OSS&amp;amp;utm_medium=referral&amp;amp;utm_campaign=golangci" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="assets/goland-white.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="assets/goland.svg" /&gt; 
   &lt;img alt="The complete IDE crafted for professional Go developers." src="https://raw.githubusercontent.com/golangci/golangci-lint/main/assets/goland.svg?sanitize=true" width="150" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/golangci/golangci-lint"&gt;&lt;img src="https://starchart.cc/golangci/golangci-lint.svg?variant=adaptive" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;S3 API Compatible – Seamless integration with existing S3 tools&lt;/li&gt; 
 &lt;li&gt;Built for AI &amp;amp; Analytics – Optimized for large-scale data pipelines&lt;/li&gt; 
 &lt;li&gt;High Performance – Ideal for demanding storage workloads.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This README provides instructions for building MinIO from source and deploying onto baremetal hardware. Use the &lt;a href="https://github.com/minio/docs"&gt;MinIO Documentation&lt;/a&gt; project to build and host a local copy of the documentation.&lt;/p&gt; 
&lt;h2&gt;MinIO is Open Source Software&lt;/h2&gt; 
&lt;p&gt;We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.&lt;/p&gt; 
&lt;p&gt;All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.&lt;/p&gt; 
&lt;p&gt;The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work. All support is provided on a best-effort basis through Github and our &lt;a href="https://raw.githubusercontent.com/minio/minio/master/https//slack.min.io"&gt;Slack&lt;/a&gt; channel, and any member of the community is welcome to contribute and assist others in their usage of the software.&lt;/p&gt; 
&lt;p&gt;MinIO &lt;a href="https://www.min.io/product/aistor"&gt;AIStor&lt;/a&gt; includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, &lt;a href="https://min.io/pricing"&gt;reach out for a quote&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source-Only Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.&lt;/p&gt; 
&lt;h3&gt;Installing Latest MinIO Community Edition&lt;/h3&gt; 
&lt;p&gt;To use MinIO community edition, you have two options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from source&lt;/strong&gt; using &lt;code&gt;go install github.com/minio/minio@latest&lt;/code&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Docker image&lt;/strong&gt; from the provided Dockerfile&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the sections below for detailed instructions on each method.&lt;/p&gt; 
&lt;h3&gt;Legacy Binary Releases&lt;/h3&gt; 
&lt;p&gt;Historical pre-compiled binary releases remain available for reference but are no longer maintained:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Releases: &lt;a href="https://github.com/minio/minio/releases"&gt;https://github.com/minio/minio/releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Direct downloads: &lt;a href="https://dl.min.io/server/minio/release/"&gt;https://dl.min.io/server/minio/release/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;These legacy binaries will not receive updates.&lt;/strong&gt; We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.&lt;/p&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can alternatively run &lt;code&gt;go build&lt;/code&gt; and use the &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables to control the OS and architecture target. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GOOS=linux GOARCh=arm64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start MinIO by running &lt;code&gt;minio server PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; is any empty folder on your local filesystem.&lt;/p&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://docs.min.io/community/minio-object-store/developers/minio-drivers.html"&gt;https://docs.min.io/community/minio-object-store/developers/minio-drivers.html&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Production environments using compiled-from-source MinIO binaries do so at their own risk. The AGPLv3 license provides no warranties nor liabilites for any such usage.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Build Docker Image&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;docker build .&lt;/code&gt; command to build a Docker image on your local host machine. You must first &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#install-from-source"&gt;build MinIO&lt;/a&gt; and ensure the &lt;code&gt;minio&lt;/code&gt; binary exists in the project root.&lt;/p&gt; 
&lt;p&gt;The following command builds the Docker image using the default &lt;code&gt;Dockerfile&lt;/code&gt; in the root project directory with the repository and image tag &lt;code&gt;myminio:minio&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t myminio:minio .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;docker image ls&lt;/code&gt; to confirm the image exists in your local repository. You can run the server using standard Docker invocation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation. You can modify the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;dockerscripts/socker-entrypoint.sh&lt;/code&gt; as-needed to reflect your specific image requirements.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container"&gt;MinIO Container&lt;/a&gt; documentation for more guidance on running MinIO within a Container image.&lt;/p&gt; 
&lt;h2&gt;Install using Helm Charts&lt;/h2&gt; 
&lt;p&gt;There are two paths for installing MinIO onto Kubernetes infrastructure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/minio/operator"&gt;MinIO Operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the community-maintained &lt;a href="https://github.com/minio/minio/tree/master/helm/minio"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html"&gt;MinIO Documentation&lt;/a&gt; for guidance on deploying using the Operator. The Community Helm chart has instructions in the folder-level README.&lt;/p&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.&lt;/p&gt; 
&lt;p&gt;The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the MinIO Client &lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/developers/go/minio-go.html"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; for guidance on making new contributions to the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>tulir/whatsmeow</title>
      <link>https://github.com/tulir/whatsmeow</link>
      <description>&lt;p&gt;Go library for the WhatsApp web multidevice API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;whatsmeow&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/go.mau.fi/whatsmeow"&gt;&lt;img src="https://pkg.go.dev/badge/go.mau.fi/whatsmeow.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;whatsmeow is a Go library for the WhatsApp web multidevice API.&lt;/p&gt; 
&lt;h2&gt;Discussion&lt;/h2&gt; 
&lt;p&gt;Matrix room: &lt;a href="https://matrix.to/#/#whatsmeow:maunium.net"&gt;#whatsmeow:maunium.net&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For questions about the WhatsApp protocol (like how to send a specific type of message), you can also use the &lt;a href="https://github.com/tulir/whatsmeow/discussions/categories/whatsapp-protocol-q-a"&gt;WhatsApp protocol Q&amp;amp;A&lt;/a&gt; section on GitHub discussions.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://pkg.go.dev/go.mau.fi/whatsmeow"&gt;godoc&lt;/a&gt; includes docs for all methods and event types. There's also a &lt;a href="https://pkg.go.dev/go.mau.fi/whatsmeow#example-package"&gt;simple example&lt;/a&gt; at the top.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;Most core features are already present:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sending messages to private chats and groups (both text and media)&lt;/li&gt; 
 &lt;li&gt;Receiving all messages&lt;/li&gt; 
 &lt;li&gt;Managing groups and receiving group change events&lt;/li&gt; 
 &lt;li&gt;Joining via invite messages, using and creating invite links&lt;/li&gt; 
 &lt;li&gt;Sending and receiving typing notifications&lt;/li&gt; 
 &lt;li&gt;Sending and receiving delivery and read receipts&lt;/li&gt; 
 &lt;li&gt;Reading and writing app state (contact list, chat pin/mute status, etc)&lt;/li&gt; 
 &lt;li&gt;Sending and handling retry receipts if message decryption fails&lt;/li&gt; 
 &lt;li&gt;Sending status messages (experimental, may not work for large contact lists)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Things that are not yet implemented:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sending broadcast list messages (this is not supported on WhatsApp web either)&lt;/li&gt; 
 &lt;li&gt;Calls&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>argoproj/argo-workflows</title>
      <link>https://github.com/argoproj/argo-workflows</link>
      <description>&lt;p&gt;Workflow Engine for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml?query=branch%3Amain"&gt;&lt;img src="https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml/badge.svg?branch=main" alt="Security Status" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/3830"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/3830/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows.svg?type=shield" alt="FOSSA License Status" /&gt;&lt;/a&gt; &lt;a href="https://argoproj.github.io/community/join-slack"&gt;&lt;img src="https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://x.com/argoproj"&gt;&lt;img src="https://img.shields.io/twitter/follow/argoproj?style=social" alt="X Follow" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/argoproj/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin" alt="LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://github.com/argoproj/argo-workflows/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/argoproj/argo-workflows?label=argo-workflows" alt="Release Version" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/helm/argo/argo-workflows"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-workflows" alt="Artifact HUB" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What is Argo Workflows?&lt;/h2&gt; 
&lt;p&gt;Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Define workflows where each step is a container.&lt;/li&gt; 
 &lt;li&gt;Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a directed acyclic graph (DAG).&lt;/li&gt; 
 &lt;li&gt;Easily run compute intensive jobs for machine learning or data processing in a fraction of the time using Argo Workflows on Kubernetes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Argo is a &lt;a href="https://cncf.io/"&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt; graduated project.&lt;/p&gt; 
&lt;h2&gt;Use Cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://argo-workflows.readthedocs.io/en/latest/use-cases/machine-learning/"&gt;Machine Learning pipelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://argo-workflows.readthedocs.io/en/latest/use-cases/data-processing/"&gt;Data and batch processing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://argo-workflows.readthedocs.io/en/latest/use-cases/infrastructure-automation/"&gt;Infrastructure automation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://argo-workflows.readthedocs.io/en/latest/use-cases/ci-cd/"&gt;CI/CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://argo-workflows.readthedocs.io/en/latest/use-cases/other/"&gt;Other use cases&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Argo Workflows?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Argo Workflows is the most popular workflow execution engine for Kubernetes.&lt;/li&gt; 
 &lt;li&gt;Light-weight, scalable, and easier to use. 
  &lt;ul&gt; 
   &lt;li&gt;Including for Python users through &lt;a href="https://hera.readthedocs.io/en/stable/"&gt;the Hera Python SDK for Argo Workflows&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Designed from the ground up for containers without the overhead and limitations of legacy VM and server-based environments.&lt;/li&gt; 
 &lt;li&gt;Cloud agnostic and can run on any Kubernetes cluster.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://blog.argoproj.io/argo-workflows-events-2023-user-survey-results-82c53bc30543"&gt;Read what people said in our latest survey&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Try Argo Workflows&lt;/h2&gt; 
&lt;p&gt;You can try Argo Workflows via one of the following:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://killercoda.com/argoproj/course/argo-workflows/"&gt;Interactive Training Material&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://workflows.apps.argoproj.io/workflows/argo"&gt;Access the demo environment&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/argoproj/argo-workflows/main/docs/assets/screenshot.png" alt="Screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Who uses Argo Workflows?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/argoproj/argo-workflows/main/USERS.md"&gt;About 200+ organizations are officially using Argo Workflows&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;p&gt;Just some of the projects that use or rely on Argo Workflows (complete list &lt;a href="https://github.com/akuity/awesome-argo#ecosystem-projects"&gt;here&lt;/a&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/argoproj/argo-events"&gt;Argo Events&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/couler-proj/couler"&gt;Couler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/argoproj-labs/hera-workflows"&gt;Hera&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubeflow/katib"&gt;Katib&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kedro.readthedocs.io/en/stable/"&gt;Kedro&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubeflow/pipelines"&gt;Kubeflow Pipelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://metaflow.org"&gt;Netflix Metaflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/onepanelio/onepanel"&gt;Onepanel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orchest/orchest/"&gt;Orchest&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quickube/piper"&gt;Piper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ploomber/ploomber"&gt;Ploomber&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SeldonIO/seldon-core"&gt;Seldon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sql-machine-learning/sqlflow"&gt;SQLFlow&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Client Libraries&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href="https://raw.githubusercontent.com/argoproj/argo-workflows/main/docs/client-libraries.md"&gt;Java, Golang and Python clients&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://argo-workflows.readthedocs.io/en/latest/quick-start/"&gt;Get started here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://argo-workflows.readthedocs.io/en/latest/walk-through/"&gt;Walk-through examples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://argo-workflows.readthedocs.io/en/latest/"&gt;View the docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;An incomplete list of features Argo Workflows provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;UI to visualize and manage Workflows&lt;/li&gt; 
 &lt;li&gt;Artifact support (S3, Artifactory, Alibaba Cloud OSS, Azure Blob Storage, HTTP, Git, GCS, raw)&lt;/li&gt; 
 &lt;li&gt;Workflow templating to store commonly used Workflows in the cluster&lt;/li&gt; 
 &lt;li&gt;Archiving Workflows after executing for later access&lt;/li&gt; 
 &lt;li&gt;Scheduled workflows using cron&lt;/li&gt; 
 &lt;li&gt;Server interface with REST API (HTTP and GRPC)&lt;/li&gt; 
 &lt;li&gt;DAG or Steps based declaration of workflows&lt;/li&gt; 
 &lt;li&gt;Step level input &amp;amp; outputs (artifacts/parameters)&lt;/li&gt; 
 &lt;li&gt;Loops&lt;/li&gt; 
 &lt;li&gt;Parameterization&lt;/li&gt; 
 &lt;li&gt;Conditionals&lt;/li&gt; 
 &lt;li&gt;Timeouts (step &amp;amp; workflow level)&lt;/li&gt; 
 &lt;li&gt;Retry (step &amp;amp; workflow level)&lt;/li&gt; 
 &lt;li&gt;Resubmit (memoized)&lt;/li&gt; 
 &lt;li&gt;Suspend &amp;amp; Resume&lt;/li&gt; 
 &lt;li&gt;Cancellation&lt;/li&gt; 
 &lt;li&gt;K8s resource orchestration&lt;/li&gt; 
 &lt;li&gt;Exit Hooks (notifications, cleanup)&lt;/li&gt; 
 &lt;li&gt;Garbage collection of completed workflow&lt;/li&gt; 
 &lt;li&gt;Scheduling (affinity/tolerations/node selectors)&lt;/li&gt; 
 &lt;li&gt;Volumes (ephemeral/existing)&lt;/li&gt; 
 &lt;li&gt;Parallelism limits&lt;/li&gt; 
 &lt;li&gt;Daemoned steps&lt;/li&gt; 
 &lt;li&gt;DinD (docker-in-docker)&lt;/li&gt; 
 &lt;li&gt;Script steps&lt;/li&gt; 
 &lt;li&gt;Event emission&lt;/li&gt; 
 &lt;li&gt;Prometheus metrics&lt;/li&gt; 
 &lt;li&gt;Multiple executors&lt;/li&gt; 
 &lt;li&gt;Multiple pod and workflow garbage collection strategies&lt;/li&gt; 
 &lt;li&gt;Automatically calculated resource usage per step&lt;/li&gt; 
 &lt;li&gt;Java/Golang/Python SDKs&lt;/li&gt; 
 &lt;li&gt;Pod Disruption Budget support&lt;/li&gt; 
 &lt;li&gt;Single-sign on (OAuth2/OIDC)&lt;/li&gt; 
 &lt;li&gt;Webhook triggering&lt;/li&gt; 
 &lt;li&gt;CLI&lt;/li&gt; 
 &lt;li&gt;Out-of-the box and custom Prometheus metrics&lt;/li&gt; 
 &lt;li&gt;Windows container support&lt;/li&gt; 
 &lt;li&gt;Embedded widgets&lt;/li&gt; 
 &lt;li&gt;Multiplex log viewer&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community Meetings&lt;/h2&gt; 
&lt;p&gt;We host monthly community meetings where we and the community showcase demos and discuss the current and future state of the project. Feel free to join us! For Community Meeting information, minutes and recordings, please &lt;a href="https://bit.ly/argo-wf-cmty-mtng"&gt;see here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Participation in Argo Workflows is governed by the &lt;a href="https://github.com/cncf/foundation/raw/master/code-of-conduct.md"&gt;CNCF Code of Conduct&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community Blogs and Presentations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/terrytangyuan/awesome-argo"&gt;Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/XNXJtxkUKeY"&gt;Automation of Everything - How To Combine Argo Events, Workflows &amp;amp; Pipelines, CD, and Rollouts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/UMaivwrAyTA"&gt;Argo Workflows and Pipelines - CI/CD, Machine Learning, and Other Kubernetes Workflows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@marekermk/provisioning-argo-on-openshift-with-ansible-and-kustomize-340a1fda8b50"&gt;Argo Ansible role: Provisioning Argo Workflows on OpenShift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://bit.ly/30YNIvT"&gt;Argo Workflows vs Apache Airflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-na-2023-metaflow-argo"&gt;Beyond Prototypes: Production-Ready ML Systems with Metaflow and Argo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@bouwe.ceunen/ci-cd-with-argo-on-kubernetes-28c1a99616a9"&gt;CI/CD with Argo on Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://haque-zubair.medium.com/define-your-ci-cd-pipeline-with-argo-workflows-25aefb02fa63"&gt;Define Your CI/CD Pipeline with Argo Workflows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/terrytangyuan/distributed-ml-patterns"&gt;Distributed Machine Learning Patterns from Manning Publication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/terrytangyuan/public-talks/tree/main/talks/platform-con-2024-engineering-cloud-native-ai-platform"&gt;Engineering Cloud Native AI Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/terrytangyuan/public-talks/raw/main/talks/argocon-automl-experiments-2022"&gt;Managing Thousands of Automatic Machine Learning Experiments with Argo and Katib&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BYVf7GhfiRg"&gt;Revolutionizing Scientific Simulations with Argo Workflows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://admiralty.io/blog/running-argo-workflows-across-multiple-kubernetes-clusters/"&gt;Running Argo Workflows Across Multiple Kubernetes Clusters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=KqEKRPjy4aE"&gt;Scaling Kubernetes: Best Practices for Managing Large-Scale Batch Jobs with Spark and Argo Workflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.anaconda.com/blog/developer-blog/open-source-model-management-roundup-polyaxon-argo-and-seldon/"&gt;Open Source Model Management Roundup: Polyaxon, Argo, and Seldon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.interline.io/blog/scaling-openstreetmap-data-workflows/"&gt;Producing 200 OpenStreetMap extracts in 35 minutes using a scalable data workflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-europe-2024-production-ai-platform-on-k8s"&gt;Production-Ready AI Platform on Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://dev.matt.hillsdon.net/2018/03/24/argo-integration-review.html"&gt;Argo integration review&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;TGI Kubernetes with Joe Beda: &lt;a href="https://www.youtube.com/watch?v=M_rxPPLG8pU&amp;amp;start=859"&gt;Argo workflow system&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Project Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/argoproj"&gt;Argo Project GitHub organization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://argoproj.github.io/"&gt;Argo Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://argoproj.github.io/community/join-slack"&gt;Argo Slack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/argoproj/argo-workflows/main/SECURITY.md"&gt;SECURITY.md&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vxcontrol/pentagi</title>
      <link>https://github.com/vxcontrol/pentagi</link>
      <description>&lt;p&gt;✨ Fully autonomous AI Agents system capable of performing complex penetration testing tasks&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PentAGI&lt;/h1&gt; 
&lt;div align="center" style="font-size: 1.5em; margin: 20px 0;"&gt; 
 &lt;strong&gt;P&lt;/strong&gt;enetration testing 
 &lt;strong&gt;A&lt;/strong&gt;rtificial 
 &lt;strong&gt;G&lt;/strong&gt;eneral 
 &lt;strong&gt;I&lt;/strong&gt;ntelligence 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;🚀 &lt;strong&gt;Join the Community!&lt;/strong&gt; Connect with security researchers, AI enthusiasts, and fellow ethical hackers. Get support, share insights, and stay updated with the latest PentAGI developments.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/2xrMh7qX6m"&gt;&lt;img src="https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;⠀&lt;a href="https://t.me/+Ka9i6CNwe71hMWQy"&gt;&lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?logo=telegram&amp;amp;logoColor=white" alt="Telegram" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;📖 Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-advanced-setup"&gt;Advanced Setup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-development"&gt;Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-testing-llm-agents"&gt;Testing LLM Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-embedding-configuration-and-testing"&gt;Embedding Configuration and Testing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-function-testing-with-ftester"&gt;Function Testing with ftester&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#%EF%B8%8F-building"&gt;Building&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-credits"&gt;Credits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎯 Overview&lt;/h2&gt; 
&lt;p&gt;PentAGI is an innovative tool for automated security testing that leverages cutting-edge artificial intelligence technologies. The project is designed for information security professionals, researchers, and enthusiasts who need a powerful and flexible solution for conducting penetration tests.&lt;/p&gt; 
&lt;p&gt;You can watch the video &lt;strong&gt;PentAGI overview&lt;/strong&gt;: &lt;a href="https://youtu.be/R70x5Ddzs1o"&gt;&lt;img src="https://github.com/user-attachments/assets/0828dc3e-15f1-4a1d-858e-9696a146e478" alt="PentAGI Overview Video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🛡️ Secure &amp;amp; Isolated. All operations are performed in a sandboxed Docker environment with complete isolation.&lt;/li&gt; 
 &lt;li&gt;🤖 Fully Autonomous. AI-powered agent that automatically determines and executes penetration testing steps.&lt;/li&gt; 
 &lt;li&gt;🔬 Professional Pentesting Tools. Built-in suite of 20+ professional security tools including nmap, metasploit, sqlmap, and more.&lt;/li&gt; 
 &lt;li&gt;🧠 Smart Memory System. Long-term storage of research results and successful approaches for future use.&lt;/li&gt; 
 &lt;li&gt;🔍 Web Intelligence. Built-in browser via &lt;a href="https://hub.docker.com/r/vxcontrol/scraper"&gt;scraper&lt;/a&gt; for gathering latest information from web sources.&lt;/li&gt; 
 &lt;li&gt;🔎 External Search Systems. Integration with advanced search APIs including &lt;a href="https://tavily.com"&gt;Tavily&lt;/a&gt;, &lt;a href="https://traversaal.ai"&gt;Traversaal&lt;/a&gt;, &lt;a href="https://www.perplexity.ai"&gt;Perplexity&lt;/a&gt;, &lt;a href="https://duckduckgo.com/"&gt;DuckDuckGo&lt;/a&gt;, &lt;a href="https://programmablesearchengine.google.com/"&gt;Google Custom Search&lt;/a&gt;, and &lt;a href="https://searxng.org"&gt;Searxng&lt;/a&gt; for comprehensive information gathering.&lt;/li&gt; 
 &lt;li&gt;👥 Team of Specialists. Delegation system with specialized AI agents for research, development, and infrastructure tasks.&lt;/li&gt; 
 &lt;li&gt;📊 Comprehensive Monitoring. Detailed logging and integration with Grafana/Prometheus for real-time system observation.&lt;/li&gt; 
 &lt;li&gt;📝 Detailed Reporting. Generation of thorough vulnerability reports with exploitation guides.&lt;/li&gt; 
 &lt;li&gt;📦 Smart Container Management. Automatic Docker image selection based on specific task requirements.&lt;/li&gt; 
 &lt;li&gt;📱 Modern Interface. Clean and intuitive web UI for system management and monitoring.&lt;/li&gt; 
 &lt;li&gt;🔌 API Integration. Support for REST and GraphQL APIs for seamless external system integration.&lt;/li&gt; 
 &lt;li&gt;💾 Persistent Storage. All commands and outputs are stored in PostgreSQL with &lt;a href="https://hub.docker.com/r/vxcontrol/pgvector"&gt;pgvector&lt;/a&gt; extension.&lt;/li&gt; 
 &lt;li&gt;🎯 Scalable Architecture. Microservices-based design supporting horizontal scaling.&lt;/li&gt; 
 &lt;li&gt;🏠 Self-Hosted Solution. Complete control over your deployment and data.&lt;/li&gt; 
 &lt;li&gt;🔑 Flexible Authentication. Support for various LLM providers (&lt;a href="https://platform.openai.com/"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt;, &lt;a href="https://ollama.com/"&gt;Ollama&lt;/a&gt;, &lt;a href="https://aws.amazon.com/bedrock/"&gt;AWS Bedrock&lt;/a&gt;, &lt;a href="https://ai.google.dev/"&gt;Google AI/Gemini&lt;/a&gt;, &lt;a href="https://deepinfra.com/"&gt;Deep Infra&lt;/a&gt;, &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;, &lt;a href="https://www.deepseek.com/en"&gt;DeepSeek&lt;/a&gt;) and custom configurations.&lt;/li&gt; 
 &lt;li&gt;⚡ Quick Deployment. Easy setup through &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt; with comprehensive environment configuration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🏗️ Architecture&lt;/h2&gt; 
&lt;h3&gt;System Context&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TB
    classDef person fill:#08427B,stroke:#073B6F,color:#fff
    classDef system fill:#1168BD,stroke:#0B4884,color:#fff
    classDef external fill:#666666,stroke:#0B4884,color:#fff

    pentester["👤 Security Engineer
    (User of the system)"]

    pentagi["✨ PentAGI
    (Autonomous penetration testing system)"]

    target["🎯 target-system
    (System under test)"]
    llm["🧠 llm-provider
    (OpenAI/Anthropic/Ollama/Bedrock/Gemini/Custom)"]
    search["🔍 search-systems
    (Google/DuckDuckGo/Tavily/Traversaal/Perplexity/Searxng)"]
    langfuse["📊 langfuse-ui
    (LLM Observability Dashboard)"]
    grafana["📈 grafana
    (System Monitoring Dashboard)"]

    pentester --&amp;gt; |Uses HTTPS| pentagi
    pentester --&amp;gt; |Monitors AI HTTPS| langfuse
    pentester --&amp;gt; |Monitors System HTTPS| grafana
    pentagi --&amp;gt; |Tests Various protocols| target
    pentagi --&amp;gt; |Queries HTTPS| llm
    pentagi --&amp;gt; |Searches HTTPS| search
    pentagi --&amp;gt; |Reports HTTPS| langfuse
    pentagi --&amp;gt; |Reports HTTPS| grafana

    class pentester person
    class pentagi system
    class target,llm,search,langfuse,grafana external

    linkStyle default stroke:#ffffff,color:#ffffff
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;🔄 Container Architecture&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;graph TB
    subgraph Core Services
        UI[Frontend UI&amp;lt;br/&amp;gt;React + TypeScript]
        API[Backend API&amp;lt;br/&amp;gt;Go + GraphQL]
        DB[(Vector Store&amp;lt;br/&amp;gt;PostgreSQL + pgvector)]
        MQ[Task Queue&amp;lt;br/&amp;gt;Async Processing]
        Agent[AI Agents&amp;lt;br/&amp;gt;Multi-Agent System]
    end

    subgraph Monitoring
        Grafana[Grafana&amp;lt;br/&amp;gt;Dashboards]
        VictoriaMetrics[VictoriaMetrics&amp;lt;br/&amp;gt;Time-series DB]
        Jaeger[Jaeger&amp;lt;br/&amp;gt;Distributed Tracing]
        Loki[Loki&amp;lt;br/&amp;gt;Log Aggregation]
        OTEL[OpenTelemetry&amp;lt;br/&amp;gt;Data Collection]
    end

    subgraph Analytics
        Langfuse[Langfuse&amp;lt;br/&amp;gt;LLM Analytics]
        ClickHouse[ClickHouse&amp;lt;br/&amp;gt;Analytics DB]
        Redis[Redis&amp;lt;br/&amp;gt;Cache + Rate Limiter]
        MinIO[MinIO&amp;lt;br/&amp;gt;S3 Storage]
    end

    subgraph Security Tools
        Scraper[Web Scraper&amp;lt;br/&amp;gt;Isolated Browser]
        PenTest[Security Tools&amp;lt;br/&amp;gt;20+ Pro Tools&amp;lt;br/&amp;gt;Sandboxed Execution]
    end

    UI --&amp;gt; |HTTP/WS| API
    API --&amp;gt; |SQL| DB
    API --&amp;gt; |Events| MQ
    MQ --&amp;gt; |Tasks| Agent
    Agent --&amp;gt; |Commands| Tools
    Agent --&amp;gt; |Queries| DB

    API --&amp;gt; |Telemetry| OTEL
    OTEL --&amp;gt; |Metrics| VictoriaMetrics
    OTEL --&amp;gt; |Traces| Jaeger
    OTEL --&amp;gt; |Logs| Loki

    Grafana --&amp;gt; |Query| VictoriaMetrics
    Grafana --&amp;gt; |Query| Jaeger
    Grafana --&amp;gt; |Query| Loki

    API --&amp;gt; |Analytics| Langfuse
    Langfuse --&amp;gt; |Store| ClickHouse
    Langfuse --&amp;gt; |Cache| Redis
    Langfuse --&amp;gt; |Files| MinIO

    classDef core fill:#f9f,stroke:#333,stroke-width:2px,color:#000
    classDef monitoring fill:#bbf,stroke:#333,stroke-width:2px,color:#000
    classDef analytics fill:#bfb,stroke:#333,stroke-width:2px,color:#000
    classDef tools fill:#fbb,stroke:#333,stroke-width:2px,color:#000

    class UI,API,DB,MQ,Agent core
    class Grafana,VictoriaMetrics,Jaeger,Loki,OTEL monitoring
    class Langfuse,ClickHouse,Redis,MinIO analytics
    class Scraper,PenTest tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;📊 Entity Relationship&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;erDiagram
    Flow ||--o{ Task : contains
    Task ||--o{ SubTask : contains
    SubTask ||--o{ Action : contains
    Action ||--o{ Artifact : produces
    Action ||--o{ Memory : stores

    Flow {
        string id PK
        string name "Flow name"
        string description "Flow description"
        string status "active/completed/failed"
        json parameters "Flow parameters"
        timestamp created_at
        timestamp updated_at
    }

    Task {
        string id PK
        string flow_id FK
        string name "Task name"
        string description "Task description"
        string status "pending/running/done/failed"
        json result "Task results"
        timestamp created_at
        timestamp updated_at
    }

    SubTask {
        string id PK
        string task_id FK
        string name "Subtask name"
        string description "Subtask description"
        string status "queued/running/completed/failed"
        string agent_type "researcher/developer/executor"
        json context "Agent context"
        timestamp created_at
        timestamp updated_at
    }

    Action {
        string id PK
        string subtask_id FK
        string type "command/search/analyze/etc"
        string status "success/failure"
        json parameters "Action parameters"
        json result "Action results"
        timestamp created_at
    }

    Artifact {
        string id PK
        string action_id FK
        string type "file/report/log"
        string path "Storage path"
        json metadata "Additional info"
        timestamp created_at
    }

    Memory {
        string id PK
        string action_id FK
        string type "observation/conclusion"
        vector embedding "Vector representation"
        text content "Memory content"
        timestamp created_at
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;🤖 Agent Interaction&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;sequenceDiagram
    participant O as Orchestrator
    participant R as Researcher
    participant D as Developer
    participant E as Executor
    participant VS as Vector Store
    participant KB as Knowledge Base

    Note over O,KB: Flow Initialization
    O-&amp;gt;&amp;gt;VS: Query similar tasks
    VS--&amp;gt;&amp;gt;O: Return experiences
    O-&amp;gt;&amp;gt;KB: Load relevant knowledge
    KB--&amp;gt;&amp;gt;O: Return context

    Note over O,R: Research Phase
    O-&amp;gt;&amp;gt;R: Analyze target
    R-&amp;gt;&amp;gt;VS: Search similar cases
    VS--&amp;gt;&amp;gt;R: Return patterns
    R-&amp;gt;&amp;gt;KB: Query vulnerabilities
    KB--&amp;gt;&amp;gt;R: Return known issues
    R-&amp;gt;&amp;gt;VS: Store findings
    R--&amp;gt;&amp;gt;O: Research results

    Note over O,D: Planning Phase
    O-&amp;gt;&amp;gt;D: Plan attack
    D-&amp;gt;&amp;gt;VS: Query exploits
    VS--&amp;gt;&amp;gt;D: Return techniques
    D-&amp;gt;&amp;gt;KB: Load tools info
    KB--&amp;gt;&amp;gt;D: Return capabilities
    D--&amp;gt;&amp;gt;O: Attack plan

    Note over O,E: Execution Phase
    O-&amp;gt;&amp;gt;E: Execute plan
    E-&amp;gt;&amp;gt;KB: Load tool guides
    KB--&amp;gt;&amp;gt;E: Return procedures
    E-&amp;gt;&amp;gt;VS: Store results
    E--&amp;gt;&amp;gt;O: Execution status
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;🧠 Memory System&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;graph TB
    subgraph "Long-term Memory"
        VS[(Vector Store&amp;lt;br/&amp;gt;Embeddings DB)]
        KB[Knowledge Base&amp;lt;br/&amp;gt;Domain Expertise]
        Tools[Tools Knowledge&amp;lt;br/&amp;gt;Usage Patterns]
    end

    subgraph "Working Memory"
        Context[Current Context&amp;lt;br/&amp;gt;Task State]
        Goals[Active Goals&amp;lt;br/&amp;gt;Objectives]
        State[System State&amp;lt;br/&amp;gt;Resources]
    end

    subgraph "Episodic Memory"
        Actions[Past Actions&amp;lt;br/&amp;gt;Commands History]
        Results[Action Results&amp;lt;br/&amp;gt;Outcomes]
        Patterns[Success Patterns&amp;lt;br/&amp;gt;Best Practices]
    end

    Context --&amp;gt; |Query| VS
    VS --&amp;gt; |Retrieve| Context

    Goals --&amp;gt; |Consult| KB
    KB --&amp;gt; |Guide| Goals

    State --&amp;gt; |Record| Actions
    Actions --&amp;gt; |Learn| Patterns
    Patterns --&amp;gt; |Store| VS

    Tools --&amp;gt; |Inform| State
    Results --&amp;gt; |Update| Tools

    VS --&amp;gt; |Enhance| KB
    KB --&amp;gt; |Index| VS

    classDef ltm fill:#f9f,stroke:#333,stroke-width:2px,color:#000
    classDef wm fill:#bbf,stroke:#333,stroke-width:2px,color:#000
    classDef em fill:#bfb,stroke:#333,stroke-width:2px,color:#000

    class VS,KB,Tools ltm
    class Context,Goals,State wm
    class Actions,Results,Patterns em
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;🔄 Chain Summarization&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;p&gt;The chain summarization system manages conversation context growth by selectively summarizing older messages. This is critical for preventing token limits from being exceeded while maintaining conversation coherence.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TD
    A[Input Chain] --&amp;gt; B{Needs Summarization?}
    B --&amp;gt;|No| C[Return Original Chain]
    B --&amp;gt;|Yes| D[Convert to ChainAST]
    D --&amp;gt; E[Apply Section Summarization]
    E --&amp;gt; F[Process Oversized Pairs]
    F --&amp;gt; G[Manage Last Section Size]
    G --&amp;gt; H[Apply QA Summarization]
    H --&amp;gt; I[Rebuild Chain with Summaries]
    I --&amp;gt; J{Is New Chain Smaller?}
    J --&amp;gt;|Yes| K[Return Optimized Chain]
    J --&amp;gt;|No| C

    classDef process fill:#bbf,stroke:#333,stroke-width:2px,color:#000
    classDef decision fill:#bfb,stroke:#333,stroke-width:2px,color:#000
    classDef output fill:#fbb,stroke:#333,stroke-width:2px,color:#000

    class A,D,E,F,G,H,I process
    class B,J decision
    class C,K output
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The algorithm operates on a structured representation of conversation chains (ChainAST) that preserves message types including tool calls and their responses. All summarization operations maintain critical conversation flow while reducing context size.&lt;/p&gt; 
 &lt;h3&gt;Global Summarizer Configuration Options&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Parameter&lt;/th&gt; 
    &lt;th&gt;Environment Variable&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Preserve Last&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;SUMMARIZER_PRESERVE_LAST&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Whether to keep all messages in the last section intact&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Use QA Pairs&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;SUMMARIZER_USE_QA&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Whether to use QA pair summarization strategy&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Summarize Human in QA&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;SUMMARIZER_SUM_MSG_HUMAN_IN_QA&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Whether to summarize human messages in QA pairs&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Last Section Size&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;SUMMARIZER_LAST_SEC_BYTES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;51200&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum byte size for last section (50KB)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Max Body Pair Size&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;SUMMARIZER_MAX_BP_BYTES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;16384&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum byte size for a single body pair (16KB)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Max QA Sections&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;SUMMARIZER_MAX_QA_SECTIONS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum QA pair sections to preserve&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Max QA Size&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;SUMMARIZER_MAX_QA_BYTES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;65536&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum byte size for QA pair sections (64KB)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Keep QA Sections&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;SUMMARIZER_KEEP_QA_SECTIONS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Number of recent QA sections to keep without summarization&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;Assistant Summarizer Configuration Options&lt;/h3&gt; 
 &lt;p&gt;Assistant instances can use customized summarization settings to fine-tune context management behavior:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Parameter&lt;/th&gt; 
    &lt;th&gt;Environment Variable&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Preserve Last&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ASSISTANT_SUMMARIZER_PRESERVE_LAST&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Whether to preserve all messages in the assistant's last section&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Last Section Size&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ASSISTANT_SUMMARIZER_LAST_SEC_BYTES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;76800&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum byte size for assistant's last section (75KB)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Max Body Pair Size&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ASSISTANT_SUMMARIZER_MAX_BP_BYTES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;16384&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum byte size for a single body pair in assistant context (16KB)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Max QA Sections&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ASSISTANT_SUMMARIZER_MAX_QA_SECTIONS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;7&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum QA sections to preserve in assistant context&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Max QA Size&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ASSISTANT_SUMMARIZER_MAX_QA_BYTES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;76800&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum byte size for assistant's QA sections (75KB)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Keep QA Sections&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ASSISTANT_SUMMARIZER_KEEP_QA_SECTIONS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Number of recent QA sections to preserve without summarization&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;The assistant summarizer configuration provides more memory for context retention compared to the global settings, preserving more recent conversation history while still ensuring efficient token usage.&lt;/p&gt; 
 &lt;h3&gt;Summarizer Environment Configuration&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Default values for global summarizer logic
SUMMARIZER_PRESERVE_LAST=true
SUMMARIZER_USE_QA=true
SUMMARIZER_SUM_MSG_HUMAN_IN_QA=false
SUMMARIZER_LAST_SEC_BYTES=51200
SUMMARIZER_MAX_BP_BYTES=16384
SUMMARIZER_MAX_QA_SECTIONS=10
SUMMARIZER_MAX_QA_BYTES=65536
SUMMARIZER_KEEP_QA_SECTIONS=1

# Default values for assistant summarizer logic
ASSISTANT_SUMMARIZER_PRESERVE_LAST=true
ASSISTANT_SUMMARIZER_LAST_SEC_BYTES=76800
ASSISTANT_SUMMARIZER_MAX_BP_BYTES=16384
ASSISTANT_SUMMARIZER_MAX_QA_SECTIONS=7
ASSISTANT_SUMMARIZER_MAX_QA_BYTES=76800
ASSISTANT_SUMMARIZER_KEEP_QA_SECTIONS=3
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;The architecture of PentAGI is designed to be modular, scalable, and secure. Here are the key components:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Core Services&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Frontend UI: React-based web interface with TypeScript for type safety&lt;/li&gt; 
   &lt;li&gt;Backend API: Go-based REST and GraphQL APIs for flexible integration&lt;/li&gt; 
   &lt;li&gt;Vector Store: PostgreSQL with pgvector for semantic search and memory storage&lt;/li&gt; 
   &lt;li&gt;Task Queue: Async task processing system for reliable operation&lt;/li&gt; 
   &lt;li&gt;AI Agent: Multi-agent system with specialized roles for efficient testing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Monitoring Stack&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;OpenTelemetry: Unified observability data collection and correlation&lt;/li&gt; 
   &lt;li&gt;Grafana: Real-time visualization and alerting dashboards&lt;/li&gt; 
   &lt;li&gt;VictoriaMetrics: High-performance time-series metrics storage&lt;/li&gt; 
   &lt;li&gt;Jaeger: End-to-end distributed tracing for debugging&lt;/li&gt; 
   &lt;li&gt;Loki: Scalable log aggregation and analysis&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Analytics Platform&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Langfuse: Advanced LLM observability and performance analytics&lt;/li&gt; 
   &lt;li&gt;ClickHouse: Column-oriented analytics data warehouse&lt;/li&gt; 
   &lt;li&gt;Redis: High-speed caching and rate limiting&lt;/li&gt; 
   &lt;li&gt;MinIO: S3-compatible object storage for artifacts&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Security Tools&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Web Scraper: Isolated browser environment for safe web interaction&lt;/li&gt; 
   &lt;li&gt;Pentesting Tools: Comprehensive suite of 20+ professional security tools&lt;/li&gt; 
   &lt;li&gt;Sandboxed Execution: All operations run in isolated containers&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Memory Systems&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Long-term Memory: Persistent storage of knowledge and experiences&lt;/li&gt; 
   &lt;li&gt;Working Memory: Active context and goals for current operations&lt;/li&gt; 
   &lt;li&gt;Episodic Memory: Historical actions and success patterns&lt;/li&gt; 
   &lt;li&gt;Knowledge Base: Structured domain expertise and tool capabilities&lt;/li&gt; 
   &lt;li&gt;Context Management: Intelligently manages growing LLM context windows using chain summarization&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The system uses Docker containers for isolation and easy deployment, with separate networks for core services, monitoring, and analytics to ensure proper security boundaries. Each component is designed to scale horizontally and can be configured for high availability in production environments.&lt;/p&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;h3&gt;System Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker and Docker Compose&lt;/li&gt; 
 &lt;li&gt;Minimum 4GB RAM&lt;/li&gt; 
 &lt;li&gt;10GB free disk space&lt;/li&gt; 
 &lt;li&gt;Internet access for downloading images and updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Using Installer (Recommended)&lt;/h3&gt; 
&lt;p&gt;PentAGI provides an interactive installer with a terminal-based UI for streamlined configuration and deployment. The installer guides you through system checks, LLM provider setup, search engine configuration, and security hardening.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Supported Platforms:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: amd64 (&lt;a href="https://pentagi.com/downloads/linux/amd64/installer-latest.zip"&gt;download&lt;/a&gt;) | arm64 (&lt;a href="https://pentagi.com/downloads/linux/arm64/installer-latest.zip"&gt;download&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: amd64&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: amd64 (Intel) | arm64 (M-series)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Installation (Linux amd64):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create installation directory
mkdir -p pentagi &amp;amp;&amp;amp; cd pentagi

# Download installer
wget -O installer.zip https://pentagi.com/downloads/linux/amd64/installer-latest.zip

# Extract
unzip installer.zip

# Run interactive installer
./installer
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The installer will:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;System Checks&lt;/strong&gt;: Verify Docker, network connectivity, and system requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Environment Setup&lt;/strong&gt;: Create and configure &lt;code&gt;.env&lt;/code&gt; file with optimal defaults&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Provider Configuration&lt;/strong&gt;: Set up LLM providers (OpenAI, Anthropic, Gemini, Bedrock, Ollama, Custom)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search Engines&lt;/strong&gt;: Configure DuckDuckGo, Google, Tavily, Traversaal, Perplexity, Searxng&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security Hardening&lt;/strong&gt;: Generate secure credentials and configure SSL certificates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Start PentAGI with docker-compose&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;For Production &amp;amp; Enhanced Security:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;For production deployments or security-sensitive environments, we &lt;strong&gt;strongly recommend&lt;/strong&gt; using a distributed two-node architecture where worker operations are isolated on a separate server. This prevents untrusted code execution and network access issues on your main system.&lt;/p&gt; 
&lt;p&gt;👉 &lt;strong&gt;See detailed guide&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/examples/guides/worker_node.md"&gt;Worker Node Setup&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The two-node setup provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Isolated Execution&lt;/strong&gt;: Worker containers run on dedicated hardware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network Isolation&lt;/strong&gt;: Separate network boundaries for penetration testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security Boundaries&lt;/strong&gt;: Docker-in-Docker with TLS authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OOB Attack Support&lt;/strong&gt;: Dedicated port ranges for out-of-band techniques&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Manual Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a working directory or clone the repository:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir pentagi &amp;amp;&amp;amp; cd pentagi
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; or download it:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -o .env https://raw.githubusercontent.com/vxcontrol/pentagi/master/.env.example
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Fill in the required API keys in &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Required: At least one of these LLM providers
OPEN_AI_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
GEMINI_API_KEY=your_gemini_key

# Optional: AWS Bedrock provider (enterprise-grade models)
BEDROCK_REGION=us-east-1
BEDROCK_ACCESS_KEY_ID=your_aws_access_key
BEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key

# Optional: Local LLM provider (zero-cost inference)
OLLAMA_SERVER_URL=http://localhost:11434

# Optional: Additional search capabilities
DUCKDUCKGO_ENABLED=true
GOOGLE_API_KEY=your_google_key
GOOGLE_CX_KEY=your_google_cx
TAVILY_API_KEY=your_tavily_key
TRAVERSAAL_API_KEY=your_traversaal_key
PERPLEXITY_API_KEY=your_perplexity_key
PERPLEXITY_MODEL=sonar-pro
PERPLEXITY_CONTEXT_SIZE=medium

# Searxng meta search engine (aggregates results from multiple sources)
SEARXNG_URL=http://your-searxng-instance:8080
SEARXNG_CATEGORIES=general
SEARXNG_LANGUAGE=
SEARXNG_SAFESEARCH=0
SEARXNG_TIME_RANGE=

# Assistant configuration
ASSISTANT_USE_AGENTS=false         # Default value for agent usage when creating new assistants
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Change all security related environment variables in &lt;code&gt;.env&lt;/code&gt; file to improve security.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;details&gt; 
 &lt;summary&gt;Security related environment variables&lt;/summary&gt; 
 &lt;h3&gt;Main Security Settings&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;COOKIE_SIGNING_SALT&lt;/code&gt; - Salt for cookie signing, change to random value&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;PUBLIC_URL&lt;/code&gt; - Public URL of your server (eg. &lt;code&gt;https://pentagi.example.com&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;SERVER_SSL_CRT&lt;/code&gt; and &lt;code&gt;SERVER_SSL_KEY&lt;/code&gt; - Custom paths to your existing SSL certificate and key for HTTPS (these paths should be used in the docker-compose.yml file to mount as volumes)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Scraper Access&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;SCRAPER_PUBLIC_URL&lt;/code&gt; - Public URL for scraper if you want to use different scraper server for public URLs&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;SCRAPER_PRIVATE_URL&lt;/code&gt; - Private URL for scraper (local scraper server in docker-compose.yml file to access it to local URLs)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Access Credentials&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;PENTAGI_POSTGRES_USER&lt;/code&gt; and &lt;code&gt;PENTAGI_POSTGRES_PASSWORD&lt;/code&gt; - PostgreSQL credentials&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Remove all inline comments from &lt;code&gt;.env&lt;/code&gt; file if you want to use it in VSCode or other IDEs as a envFile option:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;perl -i -pe 's/\s+#.*$//' .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;Run the PentAGI stack:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -O https://raw.githubusercontent.com/vxcontrol/pentagi/master/docker-compose.yml
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit &lt;a href="https://localhost:8443"&gt;localhost:8443&lt;/a&gt; to access PentAGI Web UI (default is &lt;code&gt;admin@pentagi.com&lt;/code&gt; / &lt;code&gt;admin&lt;/code&gt;)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you caught an error about &lt;code&gt;pentagi-network&lt;/code&gt; or &lt;code&gt;observability-network&lt;/code&gt; or &lt;code&gt;langfuse-network&lt;/code&gt; you need to run &lt;code&gt;docker-compose.yml&lt;/code&gt; firstly to create these networks and after that run &lt;code&gt;docker-compose-langfuse.yml&lt;/code&gt; and &lt;code&gt;docker-compose-observability.yml&lt;/code&gt; to use Langfuse and Observability services.&lt;/p&gt; 
 &lt;p&gt;You have to set at least one Language Model provider (OpenAI, Anthropic, Gemini, AWS Bedrock, or Ollama) to use PentAGI. AWS Bedrock provides enterprise-grade access to multiple foundation models from leading AI companies, while Ollama provides zero-cost local inference if you have sufficient computational resources. Additional API keys for search engines are optional but recommended for better results.&lt;/p&gt; 
 &lt;p&gt;&lt;code&gt;LLM_SERVER_*&lt;/code&gt; environment variables are experimental feature and will be changed in the future. Right now you can use them to specify custom LLM server URL and one model for all agent types.&lt;/p&gt; 
 &lt;p&gt;&lt;code&gt;PROXY_URL&lt;/code&gt; is a global proxy URL for all LLM providers and external search systems. You can use it for isolation from external networks.&lt;/p&gt; 
 &lt;p&gt;The &lt;code&gt;docker-compose.yml&lt;/code&gt; file runs the PentAGI service as root user because it needs access to docker.sock for container management. If you're using TCP/IP network connection to Docker instead of socket file, you can remove root privileges and use the default &lt;code&gt;pentagi&lt;/code&gt; user for better security.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Assistant Configuration&lt;/h3&gt; 
&lt;p&gt;PentAGI allows you to configure default behavior for assistants:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ASSISTANT_USE_AGENTS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Controls the default value for agent usage when creating new assistants&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The &lt;code&gt;ASSISTANT_USE_AGENTS&lt;/code&gt; setting affects the initial state of the "Use Agents" toggle when creating a new assistant in the UI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;false&lt;/code&gt; (default): New assistants are created with agent delegation disabled by default&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;true&lt;/code&gt;: New assistants are created with agent delegation enabled by default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that users can always override this setting by toggling the "Use Agents" button in the UI when creating or editing an assistant. This environment variable only controls the initial default state.&lt;/p&gt; 
&lt;h3&gt;Custom LLM Provider Configuration&lt;/h3&gt; 
&lt;p&gt;When using custom LLM providers with the &lt;code&gt;LLM_SERVER_*&lt;/code&gt; variables, you can fine-tune the reasoning format used in requests:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Base URL for the custom LLM API endpoint&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_SERVER_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;API key for the custom LLM provider&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_SERVER_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Default model to use (can be overridden in provider config)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_SERVER_CONFIG_PATH&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Path to the YAML configuration file for agent-specific models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_SERVER_LEGACY_REASONING&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Controls reasoning format in API requests&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The &lt;code&gt;LLM_SERVER_LEGACY_REASONING&lt;/code&gt; setting affects how reasoning parameters are sent to the LLM:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;false&lt;/code&gt; (default): Uses modern format where reasoning is sent as a structured object with &lt;code&gt;max_tokens&lt;/code&gt; parameter&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;true&lt;/code&gt;: Uses legacy format with string-based &lt;code&gt;reasoning_effort&lt;/code&gt; parameter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This setting is important when working with different LLM providers as they may expect different reasoning formats in their API requests. If you encounter reasoning-related errors with custom providers, try changing this setting.&lt;/p&gt; 
&lt;h3&gt;Local LLM Provider Configuration&lt;/h3&gt; 
&lt;p&gt;PentAGI supports Ollama for local LLM inference, providing zero-cost operation and enhanced privacy:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;URL of your Ollama server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_SERVER_CONFIG_PATH&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Path to custom agent configuration file&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Configuration examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic Ollama setup
OLLAMA_SERVER_URL=http://localhost:11434

# Remote Ollama server
OLLAMA_SERVER_URL=http://ollama-server:11434

# Custom configuration with agent-specific models
OLLAMA_SERVER_CONFIG_PATH=/path/to/ollama-config.yml

# Default configuration file inside the docker container (just for example)
OLLAMA_SERVER_CONFIG_PATH=/opt/pentagi/conf/ollama-llama318b.provider.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The system automatically discovers available models from your Ollama server and provides zero-cost inference for penetration testing workflows.&lt;/p&gt; 
&lt;h4&gt;Creating Custom Ollama Models with Extended Context&lt;/h4&gt; 
&lt;p&gt;PentAGI requires models with larger context windows than the default Ollama configurations. You need to create custom models with increased &lt;code&gt;num_ctx&lt;/code&gt; parameter through Modelfiles. While typical agent workflows consume around 64K tokens, PentAGI uses 110K context size for safety margin and handling complex penetration testing scenarios.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: The &lt;code&gt;num_ctx&lt;/code&gt; parameter can only be set during model creation via Modelfile - it cannot be changed after model creation or overridden at runtime.&lt;/p&gt; 
&lt;h5&gt;Example: Qwen3 32B FP16 with Extended Context&lt;/h5&gt; 
&lt;p&gt;Create a Modelfile named &lt;code&gt;Modelfile_qwen3_32b_fp16_tc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM qwen3:32b-fp16
PARAMETER num_ctx 110000
PARAMETER temperature 0.3
PARAMETER top_p 0.8
PARAMETER min_p 0.0
PARAMETER top_k 20
PARAMETER repeat_penalty 1.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build the custom model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama create qwen3:32b-fp16-tc -f Modelfile_qwen3_32b_fp16_tc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Example: QwQ 32B FP16 with Extended Context&lt;/h5&gt; 
&lt;p&gt;Create a Modelfile named &lt;code&gt;Modelfile_qwq_32b_fp16_tc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM qwq:32b-fp16
PARAMETER num_ctx 110000
PARAMETER temperature 0.2
PARAMETER top_p 0.7
PARAMETER min_p 0.0
PARAMETER top_k 40
PARAMETER repeat_penalty 1.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build the custom model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama create qwq:32b-fp16-tc -f Modelfile_qwq_32b_fp16_tc
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The QwQ 32B FP16 model requires approximately &lt;strong&gt;71.3 GB VRAM&lt;/strong&gt; for inference. Ensure your system has sufficient GPU memory before attempting to use this model.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;These custom models are referenced in the pre-built provider configuration files (&lt;code&gt;ollama-qwen332b-fp16-tc.provider.yml&lt;/code&gt; and &lt;code&gt;ollama-qwq32b-fp16-tc.provider.yml&lt;/code&gt;) that are included in the Docker image at &lt;code&gt;/opt/pentagi/conf/&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenAI Provider Configuration&lt;/h3&gt; 
&lt;p&gt;PentAGI supports OpenAI's advanced language models, including the latest reasoning-capable o-series models designed for complex analytical tasks:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPEN_AI_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;API key for OpenAI services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPEN_AI_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.openai.com/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API endpoint&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Configuration examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic OpenAI setup
OPEN_AI_KEY=your_openai_api_key
OPEN_AI_SERVER_URL=https://api.openai.com/v1

# Using with proxy for enhanced security
OPEN_AI_KEY=your_openai_api_key
PROXY_URL=http://your-proxy:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The OpenAI provider offers cutting-edge capabilities including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Reasoning Models&lt;/strong&gt;: Advanced o-series models (o1, o3, o4-mini) with step-by-step analytical thinking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Latest GPT-4.1 Series&lt;/strong&gt;: Flagship models optimized for complex security research and exploit development&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost-Effective Options&lt;/strong&gt;: From nano models for high-volume scanning to powerful reasoning models for deep analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versatile Performance&lt;/strong&gt;: Fast, intelligent models perfect for multi-step security analysis and penetration testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proven Reliability&lt;/strong&gt;: Industry-leading models with consistent performance across diverse security scenarios&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The system automatically selects appropriate OpenAI models based on task complexity, optimizing for both performance and cost-effectiveness.&lt;/p&gt; 
&lt;h3&gt;Anthropic Provider Configuration&lt;/h3&gt; 
&lt;p&gt;PentAGI integrates with Anthropic's Claude models, known for their exceptional safety, reasoning capabilities, and sophisticated understanding of complex security contexts:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;API key for Anthropic services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.anthropic.com/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic API endpoint&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Configuration examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic Anthropic setup
ANTHROPIC_API_KEY=your_anthropic_api_key
ANTHROPIC_SERVER_URL=https://api.anthropic.com/v1

# Using with proxy for secure environments
ANTHROPIC_API_KEY=your_anthropic_api_key
PROXY_URL=http://your-proxy:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Anthropic provider delivers superior capabilities including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Reasoning&lt;/strong&gt;: Claude 4 series with exceptional reasoning for sophisticated penetration testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extended Thinking&lt;/strong&gt;: Claude 3.7 with step-by-step thinking capabilities for methodical security research&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High-Speed Performance&lt;/strong&gt;: Claude 3.5 Haiku for blazing-fast vulnerability scans and real-time monitoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Analysis&lt;/strong&gt;: Claude Sonnet models for complex security analysis and threat hunting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Safety-First Design&lt;/strong&gt;: Built-in safety mechanisms ensuring responsible security testing practices&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The system leverages Claude's advanced understanding of security contexts to provide thorough and responsible penetration testing guidance.&lt;/p&gt; 
&lt;h3&gt;Google AI (Gemini) Provider Configuration&lt;/h3&gt; 
&lt;p&gt;PentAGI supports Google's Gemini models through the Google AI API, offering state-of-the-art reasoning capabilities and multimodal features:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;API key for Google AI services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://generativelanguage.googleapis.com&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google AI API endpoint&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Configuration examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic Gemini setup
GEMINI_API_KEY=your_gemini_api_key
GEMINI_SERVER_URL=https://generativelanguage.googleapis.com

# Using with proxy
GEMINI_API_KEY=your_gemini_api_key
PROXY_URL=http://your-proxy:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Gemini provider offers advanced features including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Thinking Capabilities&lt;/strong&gt;: Advanced reasoning models (Gemini 2.5 series) with step-by-step analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multimodal Support&lt;/strong&gt;: Text and image processing for comprehensive security assessments&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Large Context Windows&lt;/strong&gt;: Up to 2M tokens for analyzing extensive codebases and documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost-Effective Options&lt;/strong&gt;: From high-performance pro models to economical flash variants&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security-Focused Models&lt;/strong&gt;: Specialized configurations optimized for penetration testing workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The system automatically selects appropriate Gemini models based on agent requirements, balancing performance, capabilities, and cost-effectiveness.&lt;/p&gt; 
&lt;h3&gt;AWS Bedrock Provider Configuration&lt;/h3&gt; 
&lt;p&gt;PentAGI integrates with Amazon Bedrock, offering access to a wide range of foundation models from leading AI companies including Anthropic, AI21, Cohere, Meta, and Amazon's own models:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BEDROCK_REGION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;us-east-1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;AWS region for Bedrock service&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BEDROCK_ACCESS_KEY_ID&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;AWS access key ID for authentication&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BEDROCK_SECRET_ACCESS_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;AWS secret access key for authentication&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BEDROCK_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Optional custom Bedrock endpoint URL&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Configuration examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic AWS Bedrock setup with credentials
BEDROCK_REGION=us-east-1
BEDROCK_ACCESS_KEY_ID=your_aws_access_key
BEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key

# Using with proxy for enhanced security
BEDROCK_REGION=us-east-1
BEDROCK_ACCESS_KEY_ID=your_aws_access_key
BEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key
PROXY_URL=http://your-proxy:8080

# Using custom endpoint (for VPC endpoints or testing)
BEDROCK_REGION=us-east-1
BEDROCK_ACCESS_KEY_ID=your_aws_access_key
BEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key
BEDROCK_SERVER_URL=https://bedrock-runtime.us-east-1.amazonaws.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;AWS Bedrock Rate Limits Warning&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The default PentAGI configuration for AWS Bedrock uses two primary models:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;us.anthropic.claude-sonnet-4-20250514-v1:0&lt;/code&gt; (for most agents) - &lt;strong&gt;2 requests per minute&lt;/strong&gt; for new AWS accounts&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;us.anthropic.claude-3-5-haiku-20241022-v1:0&lt;/code&gt; (for simple tasks) - &lt;strong&gt;20 requests per minute&lt;/strong&gt; for new AWS accounts&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;These default rate limits are &lt;strong&gt;extremely restrictive&lt;/strong&gt; for comfortable penetration testing scenarios and will significantly impact your workflow. We &lt;strong&gt;strongly recommend&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Request quota increases&lt;/strong&gt; for your AWS Bedrock models through the AWS Service Quotas console&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Use provisioned throughput models&lt;/strong&gt; with hourly billing for higher throughput requirements&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Switch to alternative models&lt;/strong&gt; with higher default quotas (e.g., Amazon Nova series, Meta Llama models)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Consider using a different LLM provider&lt;/strong&gt; (OpenAI, Anthropic, Gemini) if you need immediate high-throughput access&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Without adequate rate limits, you may experience frequent delays, timeouts, and degraded testing performance.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The AWS Bedrock provider delivers comprehensive capabilities including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Provider Access&lt;/strong&gt;: Access to models from Anthropic (Claude), AI21 (Jamba), Cohere (Command), Meta (Llama), Amazon (Nova, Titan), and DeepSeek (R1) through a single interface&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Reasoning&lt;/strong&gt;: Support for Claude 4 and other reasoning-capable models with step-by-step thinking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multimodal Models&lt;/strong&gt;: Amazon Nova series supporting text, image, and video processing for comprehensive security analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Security&lt;/strong&gt;: AWS-native security controls, VPC integration, and compliance certifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost Optimization&lt;/strong&gt;: Wide range of model sizes and capabilities for cost-effective penetration testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Regional Availability&lt;/strong&gt;: Deploy models in your preferred AWS region for data residency and performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Low-latency inference through AWS's global infrastructure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The system automatically selects appropriate Bedrock models based on task complexity and requirements, leveraging the full spectrum of available foundation models for optimal security testing results.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;Converse API Requirements&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;PentAGI uses the &lt;strong&gt;Amazon Bedrock Converse API&lt;/strong&gt; for model interactions, which requires models to support the following features:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;✅ &lt;strong&gt;Converse&lt;/strong&gt; - Basic conversation API support&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;ConverseStream&lt;/strong&gt; - Streaming response support&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;Tool use&lt;/strong&gt; - Function calling capabilities for penetration testing tools&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;Streaming tool use&lt;/strong&gt; - Real-time tool execution feedback&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Before selecting models&lt;/strong&gt;, verify their feature support at: &lt;a href="https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-supported-models-features.html"&gt;Supported models and model features&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;⚠️ &lt;strong&gt;Important&lt;/strong&gt;: Some models like AI21 Jurassic-2 and Cohere Command (Text) have &lt;strong&gt;limited chat support&lt;/strong&gt; and may not work properly with PentAGI's multi-turn conversation workflows.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: AWS credentials can also be provided through IAM roles, environment variables, or AWS credential files following standard AWS SDK authentication patterns. Ensure your AWS account has appropriate permissions for Amazon Bedrock service access.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For advanced configuration options and detailed setup instructions, please visit our &lt;a href="https://docs.pentagi.com"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🔧 Advanced Setup&lt;/h2&gt; 
&lt;h3&gt;Langfuse Integration&lt;/h3&gt; 
&lt;p&gt;Langfuse provides advanced capabilities for monitoring and analyzing AI agent operations.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Configure Langfuse environment variables in existing &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;details&gt; 
 &lt;summary&gt;Langfuse valuable environment variables&lt;/summary&gt; 
 &lt;h3&gt;Database Credentials&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_POSTGRES_USER&lt;/code&gt; and &lt;code&gt;LANGFUSE_POSTGRES_PASSWORD&lt;/code&gt; - Langfuse PostgreSQL credentials&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_CLICKHOUSE_USER&lt;/code&gt; and &lt;code&gt;LANGFUSE_CLICKHOUSE_PASSWORD&lt;/code&gt; - ClickHouse credentials&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_REDIS_AUTH&lt;/code&gt; - Redis password&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Encryption and Security Keys&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_SALT&lt;/code&gt; - Salt for hashing in Langfuse Web UI&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_ENCRYPTION_KEY&lt;/code&gt; - Encryption key (32 bytes in hex)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_NEXTAUTH_SECRET&lt;/code&gt; - Secret key for NextAuth&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Admin Credentials&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_INIT_USER_EMAIL&lt;/code&gt; - Admin email&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_INIT_USER_PASSWORD&lt;/code&gt; - Admin password&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_INIT_USER_NAME&lt;/code&gt; - Admin username&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;API Keys and Tokens&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_INIT_PROJECT_PUBLIC_KEY&lt;/code&gt; - Project public key (used from PentAGI side too)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_INIT_PROJECT_SECRET_KEY&lt;/code&gt; - Project secret key (used from PentAGI side too)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;S3 Storage&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_S3_ACCESS_KEY_ID&lt;/code&gt; - S3 access key ID&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LANGFUSE_S3_SECRET_ACCESS_KEY&lt;/code&gt; - S3 secret access key&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Enable integration with Langfuse for PentAGI service in &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;LANGFUSE_BASE_URL=http://langfuse-web:3000
LANGFUSE_PROJECT_ID= # default: value from ${LANGFUSE_INIT_PROJECT_ID}
LANGFUSE_PUBLIC_KEY= # default: value from ${LANGFUSE_INIT_PROJECT_PUBLIC_KEY}
LANGFUSE_SECRET_KEY= # default: value from ${LANGFUSE_INIT_PROJECT_SECRET_KEY}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Run the Langfuse stack:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -O https://raw.githubusercontent.com/vxcontrol/pentagi/master/docker-compose-langfuse.yml
docker compose -f docker-compose.yml -f docker-compose-langfuse.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit &lt;a href="http://localhost:4000"&gt;localhost:4000&lt;/a&gt; to access Langfuse Web UI with credentials from &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;LANGFUSE_INIT_USER_EMAIL&lt;/code&gt; - Admin email&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;LANGFUSE_INIT_USER_PASSWORD&lt;/code&gt; - Admin password&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Monitoring and Observability&lt;/h3&gt; 
&lt;p&gt;For detailed system operation tracking, integration with monitoring tools is available.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable integration with OpenTelemetry and all observability services for PentAGI in &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OTEL_HOST=otelcol:8148
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run the observability stack:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -O https://raw.githubusercontent.com/vxcontrol/pentagi/master/docker-compose-observability.yml
docker compose -f docker-compose.yml -f docker-compose-observability.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit &lt;a href="http://localhost:3000"&gt;localhost:3000&lt;/a&gt; to access Grafana Web UI.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you want to use Observability stack with Langfuse, you need to enable integration in &lt;code&gt;.env&lt;/code&gt; file to set &lt;code&gt;LANGFUSE_OTEL_EXPORTER_OTLP_ENDPOINT&lt;/code&gt; to &lt;code&gt;http://otelcol:4318&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;And you need to run both stacks &lt;code&gt;docker compose -f docker-compose.yml -f docker-compose-langfuse.yml -f docker-compose-observability.yml up -d&lt;/code&gt; to have all services running.&lt;/p&gt; 
 &lt;p&gt;Also you can register aliases for these commands in your shell to run it faster:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;alias pentagi="docker compose -f docker-compose.yml -f docker-compose-langfuse.yml -f docker-compose-observability.yml"
alias pentagi-up="docker compose -f docker-compose.yml -f docker-compose-langfuse.yml -f docker-compose-observability.yml up -d"
alias pentagi-down="docker compose -f docker-compose.yml -f docker-compose-langfuse.yml -f docker-compose-observability.yml down"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;GitHub and Google OAuth Integration&lt;/h3&gt; 
&lt;p&gt;OAuth integration with GitHub and Google allows users to authenticate using their existing accounts on these platforms. This provides several benefits:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Simplified login process without need to create separate credentials&lt;/li&gt; 
 &lt;li&gt;Enhanced security through trusted identity providers&lt;/li&gt; 
 &lt;li&gt;Access to user profile information from GitHub/Google accounts&lt;/li&gt; 
 &lt;li&gt;Seamless integration with existing development workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For using GitHub OAuth you need to create a new OAuth application in your GitHub account and set the &lt;code&gt;GITHUB_CLIENT_ID&lt;/code&gt; and &lt;code&gt;GITHUB_CLIENT_SECRET&lt;/code&gt; in &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; 
&lt;p&gt;For using Google OAuth you need to create a new OAuth application in your Google account and set the &lt;code&gt;GOOGLE_CLIENT_ID&lt;/code&gt; and &lt;code&gt;GOOGLE_CLIENT_SECRET&lt;/code&gt; in &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; 
&lt;h3&gt;Docker Image Configuration&lt;/h3&gt; 
&lt;p&gt;PentAGI allows you to configure Docker image selection for executing various tasks. The system automatically chooses the most appropriate image based on the task type, but you can constrain this selection by specifying your preferred images:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DOCKER_DEFAULT_IMAGE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;debian:latest&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Default Docker image for general tasks and ambiguous cases&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DOCKER_DEFAULT_IMAGE_FOR_PENTEST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;vxcontrol/kali-linux&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Default Docker image for security/penetration testing tasks&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;When these environment variables are set, AI agents will be limited to the image choices you specify. This is particularly useful for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Security Enforcement&lt;/strong&gt;: Restricting usage to only verified and trusted images&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Environment Standardization&lt;/strong&gt;: Using corporate or customized images across all operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Optimization&lt;/strong&gt;: Utilizing pre-built images with necessary tools already installed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Configuration examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using a custom image for general tasks
DOCKER_DEFAULT_IMAGE=mycompany/custom-debian:latest

# Using a specialized image for penetration testing
DOCKER_DEFAULT_IMAGE_FOR_PENTEST=mycompany/pentest-tools:v2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If a user explicitly specifies a particular Docker image in their task, the system will try to use that exact image, ignoring these settings. These variables only affect the system's automatic image selection process.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;💻 Development&lt;/h2&gt; 
&lt;h3&gt;Development Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;golang&lt;/li&gt; 
 &lt;li&gt;nodejs&lt;/li&gt; 
 &lt;li&gt;docker&lt;/li&gt; 
 &lt;li&gt;postgres&lt;/li&gt; 
 &lt;li&gt;commitlint&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Environment Setup&lt;/h3&gt; 
&lt;h4&gt;Backend Setup&lt;/h4&gt; 
&lt;p&gt;Run once &lt;code&gt;cd backend &amp;amp;&amp;amp; go mod download&lt;/code&gt; to install needed packages.&lt;/p&gt; 
&lt;p&gt;For generating swagger files have to run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;swag init -g ../../pkg/server/router.go -o pkg/server/docs/ --parseDependency --parseInternal --parseDepth 2 -d cmd/pentagi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;before installing &lt;code&gt;swag&lt;/code&gt; package via&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/swaggo/swag/cmd/swag@v1.8.7
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For generating graphql resolver files have to run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go run github.com/99designs/gqlgen --config ./gqlgen/gqlgen.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;after that you can see the generated files in &lt;code&gt;pkg/graph&lt;/code&gt; folder.&lt;/p&gt; 
&lt;p&gt;For generating ORM methods (database package) from sqlc configuration&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -v $(pwd):/src -w /src --network pentagi-network -e DATABASE_URL="{URL}" sqlc/sqlc generate -f sqlc/sqlc.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For generating Langfuse SDK from OpenAPI specification&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fern generate --local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and to install fern-cli&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g fern-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Testing&lt;/h4&gt; 
&lt;p&gt;For running tests &lt;code&gt;cd backend &amp;amp;&amp;amp; go test -v ./...&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Frontend Setup&lt;/h4&gt; 
&lt;p&gt;Run once &lt;code&gt;cd frontend &amp;amp;&amp;amp; npm install&lt;/code&gt; to install needed packages.&lt;/p&gt; 
&lt;p&gt;For generating graphql files have to run &lt;code&gt;npm run graphql:generate&lt;/code&gt; which using &lt;code&gt;graphql-codegen.ts&lt;/code&gt; file.&lt;/p&gt; 
&lt;p&gt;Be sure that you have &lt;code&gt;graphql-codegen&lt;/code&gt; installed globally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g graphql-codegen
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After that you can run:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;npm run prettier&lt;/code&gt; to check if your code is formatted correctly&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run prettier:fix&lt;/code&gt; to fix it&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run lint&lt;/code&gt; to check if your code is linted correctly&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run lint:fix&lt;/code&gt; to fix it&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For generating SSL certificates you need to run &lt;code&gt;npm run ssl:generate&lt;/code&gt; which using &lt;code&gt;generate-ssl.ts&lt;/code&gt; file or it will be generated automatically when you run &lt;code&gt;npm run dev&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Backend Configuration&lt;/h4&gt; 
&lt;p&gt;Edit the configuration for &lt;code&gt;backend&lt;/code&gt; in &lt;code&gt;.vscode/launch.json&lt;/code&gt; file:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DATABASE_URL&lt;/code&gt; - PostgreSQL database URL (eg. &lt;code&gt;postgres://postgres:postgres@localhost:5432/pentagidb?sslmode=disable&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DOCKER_HOST&lt;/code&gt; - Docker SDK API (eg. for macOS &lt;code&gt;DOCKER_HOST=unix:///Users/&amp;lt;my-user&amp;gt;/Library/Containers/com.docker.docker/Data/docker.raw.sock&lt;/code&gt;) &lt;a href="https://stackoverflow.com/a/62757128/5922857"&gt;more info&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Optional:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;SERVER_PORT&lt;/code&gt; - Port to run the server (default: &lt;code&gt;8443&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SERVER_USE_SSL&lt;/code&gt; - Enable SSL for the server (default: &lt;code&gt;false&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Frontend Configuration&lt;/h4&gt; 
&lt;p&gt;Edit the configuration for &lt;code&gt;frontend&lt;/code&gt; in &lt;code&gt;.vscode/launch.json&lt;/code&gt; file:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;VITE_API_URL&lt;/code&gt; - Backend API URL. &lt;em&gt;Omit&lt;/em&gt; the URL scheme (e.g., &lt;code&gt;localhost:8080&lt;/code&gt; &lt;em&gt;NOT&lt;/em&gt; &lt;code&gt;http://localhost:8080&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;VITE_USE_HTTPS&lt;/code&gt; - Enable SSL for the server (default: &lt;code&gt;false&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;VITE_PORT&lt;/code&gt; - Port to run the server (default: &lt;code&gt;8000&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;VITE_HOST&lt;/code&gt; - Host to run the server (default: &lt;code&gt;0.0.0.0&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Running the Application&lt;/h3&gt; 
&lt;h4&gt;Backend&lt;/h4&gt; 
&lt;p&gt;Run the command(s) in &lt;code&gt;backend&lt;/code&gt; folder:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;.env&lt;/code&gt; file to set environment variables like a &lt;code&gt;source .env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;go run cmd/pentagi/main.go&lt;/code&gt; to start the server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The first run can take a while as dependencies and docker images need to be downloaded to setup the backend environment.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Frontend&lt;/h4&gt; 
&lt;p&gt;Run the command(s) in &lt;code&gt;frontend&lt;/code&gt; folder:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run &lt;code&gt;npm install&lt;/code&gt; to install the dependencies&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm run dev&lt;/code&gt; to run the web app&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm run build&lt;/code&gt; to build the web app&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Open your browser and visit the web app URL.&lt;/p&gt; 
&lt;h2&gt;🧪 Testing LLM Agents&lt;/h2&gt; 
&lt;p&gt;PentAGI includes a powerful utility called &lt;code&gt;ctester&lt;/code&gt; for testing and validating LLM agent capabilities. This tool helps ensure your LLM provider configurations work correctly with different agent types, allowing you to optimize model selection for each specific agent role.&lt;/p&gt; 
&lt;p&gt;The utility features parallel testing of multiple agents, detailed reporting, and flexible configuration options.&lt;/p&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Testing&lt;/strong&gt;: Tests multiple agents simultaneously for faster results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Test Suite&lt;/strong&gt;: Evaluates basic completion, JSON responses, function calling, and penetration testing knowledge&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Detailed Reporting&lt;/strong&gt;: Generates markdown reports with success rates and performance metrics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Configuration&lt;/strong&gt;: Test specific agents or test groups as needed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Specialized Test Groups&lt;/strong&gt;: Includes domain-specific tests for cybersecurity and penetration testing scenarios&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Usage Scenarios&lt;/h3&gt; 
&lt;h4&gt;For Developers (with local Go environment)&lt;/h4&gt; 
&lt;p&gt;If you've cloned the repository and have Go installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Default configuration with .env file
cd backend
go run cmd/ctester/*.go -verbose

# Custom provider configuration
go run cmd/ctester/*.go -config ../examples/configs/openrouter.provider.yml -verbose

# Generate a report file
go run cmd/ctester/*.go -config ../examples/configs/deepinfra.provider.yml -report ../test-report.md

# Test specific agent types only
go run cmd/ctester/*.go -agents simple,simple_json,primary_agent -verbose

# Test specific test groups only
go run cmd/ctester/*.go -groups basic,advanced -verbose
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;For Users (using Docker image)&lt;/h4&gt; 
&lt;p&gt;If you prefer to use the pre-built Docker image without setting up a development environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using Docker to test with default environment
docker run --rm -v $(pwd)/.env:/opt/pentagi/.env vxcontrol/pentagi /opt/pentagi/bin/ctester -verbose

# Test with your custom provider configuration
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  -v $(pwd)/my-config.yml:/opt/pentagi/config.yml \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/config.yml -agents simple,primary_agent,coder -verbose

# Generate a detailed report
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  -v $(pwd):/opt/pentagi/output \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -report /opt/pentagi/output/report.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Pre-configured Providers&lt;/h4&gt; 
&lt;p&gt;The Docker image comes with built-in support for major providers (OpenAI, Anthropic, Gemini, Ollama) and pre-configured provider files for additional services (OpenRouter, DeepInfra, DeepSeek):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test with OpenRouter configuration
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/openrouter.provider.yml

# Test with DeepInfra configuration
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/deepinfra.provider.yml

# Test with DeepSeek configuration
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/deepseek.provider.yml

# Test with OpenAI configuration
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -type openai

# Test with Anthropic configuration
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -type anthropic

# Test with Gemini configuration
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -type gemini

# Test with AWS Bedrock configuration
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -type bedrock

# Test with Custom OpenAI configuration
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/custom-openai.provider.yml

# Test with Ollama configuration (local inference)
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/ollama-llama318b.provider.yml

# Test with Ollama Qwen3 32B configuration (requires custom model creation)
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/ollama-qwen332b-fp16-tc.provider.yml

# Test with Ollama QwQ 32B configuration (requires custom model creation and 71.3GB VRAM)
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/ollama-qwq32b-fp16-tc.provider.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use these configurations, your &lt;code&gt;.env&lt;/code&gt; file only needs to contain:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;LLM_SERVER_URL=https://openrouter.ai/api/v1      # or https://api.deepinfra.com/v1/openai or https://api.deepseek.com or https://api.openai.com/v1
LLM_SERVER_KEY=your_api_key
LLM_SERVER_MODEL=                                # Leave empty, as models are specified in the config
LLM_SERVER_CONFIG_PATH=/opt/pentagi/conf/openrouter.provider.yml  # or deepinfra.provider.yml or deepseek.provider.yml or custom-openai.provider.yml
LLM_SERVER_LEGACY_REASONING=false                # Controls reasoning format, for OpenAI must be true (default: false)

# For OpenAI (official API)
OPEN_AI_KEY=your_openai_api_key                  # Your OpenAI API key
OPEN_AI_SERVER_URL=https://api.openai.com/v1     # OpenAI API endpoint

# For Anthropic (Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key         # Your Anthropic API key
ANTHROPIC_SERVER_URL=https://api.anthropic.com/v1  # Anthropic API endpoint

# For Gemini (Google AI)
GEMINI_API_KEY=your_gemini_api_key               # Your Google AI API key
GEMINI_SERVER_URL=https://generativelanguage.googleapis.com  # Google AI API endpoint

# For AWS Bedrock (enterprise foundation models)
BEDROCK_REGION=us-east-1                         # AWS region for Bedrock service
BEDROCK_ACCESS_KEY_ID=your_aws_access_key        # AWS access key ID
BEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key    # AWS secret access key
BEDROCK_SERVER_URL=                              # Optional custom Bedrock endpoint

# For Ollama (local inference)
OLLAMA_SERVER_URL=http://localhost:11434         # Your Ollama server URL (only for test run)
OLLAMA_SERVER_CONFIG_PATH=/opt/pentagi/conf/ollama-llama318b.provider.yml  # or ollama-qwen332b-fp16-tc.provider.yml or ollama-qwq32b-fp16-tc.provider.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using OpenAI with Unverified Organizations&lt;/h4&gt; 
&lt;p&gt;For OpenAI accounts with unverified organizations that don't have access to the latest reasoning models (o1, o3, o4-mini), you need to use a custom configuration.&lt;/p&gt; 
&lt;p&gt;To use OpenAI with unverified organization accounts, configure your &lt;code&gt;.env&lt;/code&gt; file as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;LLM_SERVER_URL=https://api.openai.com/v1
LLM_SERVER_KEY=your_openai_api_key
LLM_SERVER_MODEL=                                # Leave empty, models are specified in config
LLM_SERVER_CONFIG_PATH=/opt/pentagi/conf/custom-openai.provider.yml
LLM_SERVER_LEGACY_REASONING=true                 # Required for OpenAI reasoning format
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This configuration uses the pre-built &lt;code&gt;custom-openai.provider.yml&lt;/code&gt; file that maps all agent types to models available for unverified organizations, using &lt;code&gt;o3-mini&lt;/code&gt; instead of models like &lt;code&gt;o1&lt;/code&gt;, &lt;code&gt;o3&lt;/code&gt;, and &lt;code&gt;o4-mini&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can test this configuration using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test with custom OpenAI configuration for unverified accounts
docker run --rm \
  -v $(pwd)/.env:/opt/pentagi/.env \
  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/custom-openai.provider.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The &lt;code&gt;LLM_SERVER_LEGACY_REASONING=true&lt;/code&gt; setting is crucial for OpenAI compatibility as it ensures reasoning parameters are sent in the format expected by OpenAI's API.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Running Tests in a Production Environment&lt;/h4&gt; 
&lt;p&gt;If you already have a running PentAGI container and want to test the current configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run ctester in an existing container using current environment variables
docker exec -it pentagi /opt/pentagi/bin/ctester -verbose

# Test specific agent types with deterministic ordering
docker exec -it pentagi /opt/pentagi/bin/ctester -agents simple,primary_agent,pentester -groups basic,knowledge -verbose

# Generate a report file inside the container
docker exec -it pentagi /opt/pentagi/bin/ctester -report /opt/pentagi/data/agent-test-report.md

# Access the report from the host
docker cp pentagi:/opt/pentagi/data/agent-test-report.md ./
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Command-line Options&lt;/h3&gt; 
&lt;p&gt;The utility accepts several options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-env &amp;lt;path&amp;gt;&lt;/code&gt; - Path to environment file (default: &lt;code&gt;.env&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-type &amp;lt;provider&amp;gt;&lt;/code&gt; - Provider type: &lt;code&gt;custom&lt;/code&gt;, &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;anthropic&lt;/code&gt;, &lt;code&gt;ollama&lt;/code&gt;, &lt;code&gt;bedrock&lt;/code&gt;, &lt;code&gt;gemini&lt;/code&gt; (default: &lt;code&gt;custom&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-config &amp;lt;path&amp;gt;&lt;/code&gt; - Path to custom provider config (default: from &lt;code&gt;LLM_SERVER_CONFIG_PATH&lt;/code&gt; env variable)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-tests &amp;lt;path&amp;gt;&lt;/code&gt; - Path to custom tests YAML file (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-report &amp;lt;path&amp;gt;&lt;/code&gt; - Path to write the report file (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-agents &amp;lt;list&amp;gt;&lt;/code&gt; - Comma-separated list of agent types to test (default: &lt;code&gt;all&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-groups &amp;lt;list&amp;gt;&lt;/code&gt; - Comma-separated list of test groups to run (default: &lt;code&gt;all&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-verbose&lt;/code&gt; - Enable verbose output with detailed test results for each agent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Available Agent Types&lt;/h3&gt; 
&lt;p&gt;Agents are tested in the following deterministic order:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;simple&lt;/strong&gt; - Basic completion tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;simple_json&lt;/strong&gt; - JSON-structured responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;primary_agent&lt;/strong&gt; - Main reasoning agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;assistant&lt;/strong&gt; - Interactive assistant mode&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;generator&lt;/strong&gt; - Content generation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;refiner&lt;/strong&gt; - Content refinement and improvement&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;adviser&lt;/strong&gt; - Expert advice and consultation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;reflector&lt;/strong&gt; - Self-reflection and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;searcher&lt;/strong&gt; - Information gathering and search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;enricher&lt;/strong&gt; - Data enrichment and expansion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;coder&lt;/strong&gt; - Code generation and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;installer&lt;/strong&gt; - Installation and setup tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;pentester&lt;/strong&gt; - Penetration testing and security assessment&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Available Test Groups&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;basic&lt;/strong&gt; - Fundamental completion and prompt response tests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;advanced&lt;/strong&gt; - Complex reasoning and function calling tests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;json&lt;/strong&gt; - JSON format validation and structure tests (specifically designed for &lt;code&gt;simple_json&lt;/code&gt; agent)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;knowledge&lt;/strong&gt; - Domain-specific cybersecurity and penetration testing knowledge tests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;json&lt;/code&gt; test group is specifically designed for the &lt;code&gt;simple_json&lt;/code&gt; agent type, while all other agents are tested with &lt;code&gt;basic&lt;/code&gt;, &lt;code&gt;advanced&lt;/code&gt;, and &lt;code&gt;knowledge&lt;/code&gt; groups. This specialization ensures optimal testing coverage for each agent's intended purpose.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Example Provider Configuration&lt;/h3&gt; 
&lt;p&gt;Provider configuration defines which models to use for different agent types:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;simple:
  model: "provider/model-name"
  temperature: 0.7
  top_p: 0.95
  n: 1
  max_tokens: 4000

simple_json:
  model: "provider/model-name"
  temperature: 0.7
  top_p: 1.0
  n: 1
  max_tokens: 4000
  json: true

# ... other agent types ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optimization Workflow&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Create a baseline&lt;/strong&gt;: Run tests with default configuration to establish benchmark performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Analyze agent-specific performance&lt;/strong&gt;: Review the deterministic agent ordering to identify underperforming agents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test specialized configurations&lt;/strong&gt;: Experiment with different models for each agent type using provider-specific configs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Focus on domain knowledge&lt;/strong&gt;: Pay special attention to knowledge group tests for cybersecurity expertise&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Validate function calling&lt;/strong&gt;: Ensure tool-based tests pass consistently for critical agent types&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compare results&lt;/strong&gt;: Look for the best success rate and performance across all test groups&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deploy optimal configuration&lt;/strong&gt;: Use in production with your optimized setup&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This tool helps ensure your AI agents are using the most effective models for their specific tasks, improving reliability while optimizing costs.&lt;/p&gt; 
&lt;h2&gt;🧮 Embedding Configuration and Testing&lt;/h2&gt; 
&lt;p&gt;PentAGI uses vector embeddings for semantic search, knowledge storage, and memory management. The system supports multiple embedding providers that can be configured according to your needs and preferences.&lt;/p&gt; 
&lt;h3&gt;Supported Embedding Providers&lt;/h3&gt; 
&lt;p&gt;PentAGI supports the following embedding providers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI&lt;/strong&gt; (default): Uses OpenAI's text embedding models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: Local embedding model through Ollama&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mistral&lt;/strong&gt;: Mistral AI's embedding models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jina&lt;/strong&gt;: Jina AI's embedding service&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HuggingFace&lt;/strong&gt;: Models from HuggingFace&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GoogleAI&lt;/strong&gt;: Google's embedding models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;VoyageAI&lt;/strong&gt;: VoyageAI's embedding models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Embedding Provider Configuration&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;h3&gt;Environment Variables&lt;/h3&gt; 
 &lt;p&gt;To configure the embedding provider, set the following environment variables in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Primary embedding configuration
EMBEDDING_PROVIDER=openai       # Provider type (openai, ollama, mistral, jina, huggingface, googleai, voyageai)
EMBEDDING_MODEL=text-embedding-3-small  # Model name to use
EMBEDDING_URL=                  # Optional custom API endpoint
EMBEDDING_KEY=                  # API key for the provider (if required)
EMBEDDING_BATCH_SIZE=100        # Number of documents to process in a batch
EMBEDDING_STRIP_NEW_LINES=true  # Whether to remove new lines from text before embedding

# Advanced settings
PROXY_URL=                      # Optional proxy for all API calls
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Provider-Specific Limitations&lt;/h3&gt; 
 &lt;p&gt;Each provider has specific limitations and supported features:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;: Supports all configuration options&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: Does not support &lt;code&gt;EMBEDDING_KEY&lt;/code&gt; as it uses local models&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Mistral&lt;/strong&gt;: Does not support &lt;code&gt;EMBEDDING_MODEL&lt;/code&gt; or custom HTTP client&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Jina&lt;/strong&gt;: Does not support custom HTTP client&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HuggingFace&lt;/strong&gt;: Requires &lt;code&gt;EMBEDDING_KEY&lt;/code&gt; and supports all other options&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GoogleAI&lt;/strong&gt;: Does not support &lt;code&gt;EMBEDDING_URL&lt;/code&gt;, requires &lt;code&gt;EMBEDDING_KEY&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;VoyageAI&lt;/strong&gt;: Supports all configuration options&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If &lt;code&gt;EMBEDDING_URL&lt;/code&gt; and &lt;code&gt;EMBEDDING_KEY&lt;/code&gt; are not specified, the system will attempt to use the corresponding LLM provider settings (e.g., &lt;code&gt;OPEN_AI_KEY&lt;/code&gt; when &lt;code&gt;EMBEDDING_PROVIDER=openai&lt;/code&gt;).&lt;/p&gt; 
 &lt;h3&gt;Why Consistent Embedding Providers Matter&lt;/h3&gt; 
 &lt;p&gt;It's crucial to use the same embedding provider consistently because:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Vector Compatibility&lt;/strong&gt;: Different providers produce vectors with different dimensions and mathematical properties&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Semantic Consistency&lt;/strong&gt;: Changing providers can break semantic similarity between previously embedded documents&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Memory Corruption&lt;/strong&gt;: Mixed embeddings can lead to poor search results and broken knowledge base functionality&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;If you change your embedding provider, you should flush and reindex your entire knowledge base (see &lt;code&gt;etester&lt;/code&gt; utility below).&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Embedding Tester Utility (etester)&lt;/h3&gt; 
&lt;p&gt;PentAGI includes a specialized &lt;code&gt;etester&lt;/code&gt; utility for testing, managing, and debugging embedding functionality. This tool is essential for diagnosing and resolving issues related to vector embeddings and knowledge storage.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Etester Commands&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Test embedding provider and database connection
cd backend
go run cmd/etester/main.go test -verbose

# Show statistics about the embedding database
go run cmd/etester/main.go info

# Delete all documents from the embedding database (use with caution!)
go run cmd/etester/main.go flush

# Recalculate embeddings for all documents (after changing provider)
go run cmd/etester/main.go reindex

# Search for documents in the embedding database
go run cmd/etester/main.go search -query "How to install PostgreSQL" -limit 5
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Using Docker&lt;/h3&gt; 
 &lt;p&gt;If you're running PentAGI in Docker, you can use etester from within the container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Test embedding provider
docker exec -it pentagi /opt/pentagi/bin/etester test

# Show detailed database information
docker exec -it pentagi /opt/pentagi/bin/etester info -verbose
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Advanced Search Options&lt;/h3&gt; 
 &lt;p&gt;The &lt;code&gt;search&lt;/code&gt; command supports various filters to narrow down results:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Filter by document type
docker exec -it pentagi /opt/pentagi/bin/etester search -query "Security vulnerability" -doc_type guide -threshold 0.8

# Filter by flow ID
docker exec -it pentagi /opt/pentagi/bin/etester search -query "Code examples" -doc_type code -flow_id 42

# All available search options
docker exec -it pentagi /opt/pentagi/bin/etester search -help
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Available search parameters:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;-query STRING&lt;/code&gt;: Search query text (required)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;-doc_type STRING&lt;/code&gt;: Filter by document type (answer, memory, guide, code)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;-flow_id NUMBER&lt;/code&gt;: Filter by flow ID (positive number)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;-answer_type STRING&lt;/code&gt;: Filter by answer type (guide, vulnerability, code, tool, other)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;-guide_type STRING&lt;/code&gt;: Filter by guide type (install, configure, use, pentest, development, other)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;-limit NUMBER&lt;/code&gt;: Maximum number of results (default: 3)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;-threshold NUMBER&lt;/code&gt;: Similarity threshold (0.0-1.0, default: 0.7)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Common Troubleshooting Scenarios&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;After changing embedding provider&lt;/strong&gt;: Always run &lt;code&gt;flush&lt;/code&gt; or &lt;code&gt;reindex&lt;/code&gt; to ensure consistency&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Poor search results&lt;/strong&gt;: Try adjusting the similarity threshold or check if embeddings are correctly generated&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Database connection issues&lt;/strong&gt;: Verify PostgreSQL is running with pgvector extension installed&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Missing API keys&lt;/strong&gt;: Check environment variables for your chosen embedding provider&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;🔍 Function Testing with ftester&lt;/h2&gt; 
&lt;p&gt;PentAGI includes a versatile utility called &lt;code&gt;ftester&lt;/code&gt; for debugging, testing, and developing specific functions and AI agent behaviors. While &lt;code&gt;ctester&lt;/code&gt; focuses on testing LLM model capabilities, &lt;code&gt;ftester&lt;/code&gt; allows you to directly invoke individual system functions and AI agent components with precise control over execution context.&lt;/p&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Direct Function Access&lt;/strong&gt;: Test individual functions without running the entire system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mock Mode&lt;/strong&gt;: Test functions without a live PentAGI deployment using built-in mocks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Input&lt;/strong&gt;: Fill function arguments interactively for exploratory testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Detailed Output&lt;/strong&gt;: Color-coded terminal output with formatted responses and errors&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Context-Aware Testing&lt;/strong&gt;: Debug AI agents within the context of specific flows, tasks, and subtasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability Integration&lt;/strong&gt;: All function calls are logged to Langfuse and Observability stack&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Usage Modes&lt;/h3&gt; 
&lt;h4&gt;Command Line Arguments&lt;/h4&gt; 
&lt;p&gt;Run ftester with specific function and arguments directly from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage with mock mode
cd backend
go run cmd/ftester/main.go [function_name] -[arg1] [value1] -[arg2] [value2]

# Example: Test terminal command in mock mode
go run cmd/ftester/main.go terminal -command "ls -la" -message "List files"

# Using a real flow context
go run cmd/ftester/main.go -flow 123 terminal -command "whoami" -message "Check user"

# Testing AI agent in specific task/subtask context
go run cmd/ftester/main.go -flow 123 -task 456 -subtask 789 pentester -message "Find vulnerabilities"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Interactive Mode&lt;/h4&gt; 
&lt;p&gt;Run ftester without arguments for a guided interactive experience:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start interactive mode
go run cmd/ftester/main.go [function_name]

# For example, to interactively fill browser tool arguments
go run cmd/ftester/main.go browser
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Available Functions&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;h3&gt;Environment Functions&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;terminal&lt;/strong&gt;: Execute commands in a container and return the output&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;file&lt;/strong&gt;: Perform file operations (read, write, list) in a container&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Search Functions&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;browser&lt;/strong&gt;: Access websites and capture screenshots&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;google&lt;/strong&gt;: Search the web using Google Custom Search&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;duckduckgo&lt;/strong&gt;: Search the web using DuckDuckGo&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;tavily&lt;/strong&gt;: Search using Tavily AI search engine&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;traversaal&lt;/strong&gt;: Search using Traversaal AI search engine&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;perplexity&lt;/strong&gt;: Search using Perplexity AI&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;searxng&lt;/strong&gt;: Search using Searxng meta search engine (aggregates results from multiple engines)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Vector Database Functions&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;search_in_memory&lt;/strong&gt;: Search for information in vector database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;search_guide&lt;/strong&gt;: Find guidance documents in vector database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;search_answer&lt;/strong&gt;: Find answers to questions in vector database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;search_code&lt;/strong&gt;: Find code examples in vector database&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;AI Agent Functions&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;advice&lt;/strong&gt;: Get expert advice from an AI agent&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;coder&lt;/strong&gt;: Request code generation or modification&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;maintenance&lt;/strong&gt;: Run system maintenance tasks&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;memorist&lt;/strong&gt;: Store and organize information in vector database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;pentester&lt;/strong&gt;: Perform security tests and vulnerability analysis&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;search&lt;/strong&gt;: Complex search across multiple sources&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Utility Functions&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;describe&lt;/strong&gt;: Show information about flows, tasks, and subtasks&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Debugging Flow Context&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;p&gt;The &lt;code&gt;describe&lt;/code&gt; function provides detailed information about tasks and subtasks within a flow. This is particularly useful for diagnosing issues when PentAGI encounters problems or gets stuck.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# List all flows in the system
go run cmd/ftester/main.go describe

# Show all tasks and subtasks for a specific flow
go run cmd/ftester/main.go -flow 123 describe

# Show detailed information for a specific task
go run cmd/ftester/main.go -flow 123 -task 456 describe

# Show detailed information for a specific subtask
go run cmd/ftester/main.go -flow 123 -task 456 -subtask 789 describe

# Show verbose output with full descriptions and results
go run cmd/ftester/main.go -flow 123 describe -verbose
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This function allows you to identify the exact point where a flow might be stuck and resume processing by directly invoking the appropriate agent function.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Function Help and Discovery&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;p&gt;Each function has a help mode that shows available parameters:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Get help for a specific function
go run cmd/ftester/main.go [function_name] -help

# Examples:
go run cmd/ftester/main.go terminal -help
go run cmd/ftester/main.go browser -help
go run cmd/ftester/main.go describe -help
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You can also run ftester without arguments to see a list of all available functions:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;go run cmd/ftester/main.go
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Output Format&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;p&gt;The &lt;code&gt;ftester&lt;/code&gt; utility uses color-coded output to make interpretation easier:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Blue headers&lt;/strong&gt;: Section titles and key names&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Cyan [INFO]&lt;/strong&gt;: General information messages&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Green [SUCCESS]&lt;/strong&gt;: Successful operations&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Red [ERROR]&lt;/strong&gt;: Error messages&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Yellow [WARNING]&lt;/strong&gt;: Warning messages&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Yellow [MOCK]&lt;/strong&gt;: Indicates mock mode operation&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Magenta values&lt;/strong&gt;: Function arguments and results&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;JSON and Markdown responses are automatically formatted for readability.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Advanced Usage Scenarios&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;h3&gt;Debugging Stuck AI Flows&lt;/h3&gt; 
 &lt;p&gt;When PentAGI gets stuck in a flow:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Pause the flow through the UI&lt;/li&gt; 
  &lt;li&gt;Use &lt;code&gt;describe&lt;/code&gt; to identify the current task and subtask&lt;/li&gt; 
  &lt;li&gt;Directly invoke the agent function with the same task/subtask IDs&lt;/li&gt; 
  &lt;li&gt;Examine the detailed output to identify the issue&lt;/li&gt; 
  &lt;li&gt;Resume the flow or manually intervene as needed&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Testing Environment Variables&lt;/h3&gt; 
 &lt;p&gt;Verify that API keys and external services are configured correctly:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Test Google search API configuration
go run cmd/ftester/main.go google -query "pentesting tools"

# Test browser access to external websites
go run cmd/ftester/main.go browser -url "https://example.com"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Developing New AI Agent Behaviors&lt;/h3&gt; 
 &lt;p&gt;When developing new prompt templates or agent behaviors:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Create a test flow in the UI&lt;/li&gt; 
  &lt;li&gt;Use ftester to directly invoke the agent with different prompts&lt;/li&gt; 
  &lt;li&gt;Observe responses and adjust prompts accordingly&lt;/li&gt; 
  &lt;li&gt;Check Langfuse for detailed traces of all function calls&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Verifying Docker Container Setup&lt;/h3&gt; 
 &lt;p&gt;Ensure containers are properly configured:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;go run cmd/ftester/main.go -flow 123 terminal -command "env | grep -i proxy" -message "Check proxy settings"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Docker Container Usage&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;p&gt;If you have PentAGI running in Docker, you can use ftester from within the container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Run ftester inside the running PentAGI container
docker exec -it pentagi /opt/pentagi/bin/ftester [arguments]

# Examples:
docker exec -it pentagi /opt/pentagi/bin/ftester -flow 123 describe
docker exec -it pentagi /opt/pentagi/bin/ftester -flow 123 terminal -command "ps aux" -message "List processes"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This is particularly useful for production deployments where you don't have a local development environment.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Integration with Observability Tools&lt;/b&gt; (click to expand)&lt;/summary&gt; 
 &lt;p&gt;All function calls made through ftester are logged to:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Langfuse&lt;/strong&gt;: Captures the entire AI agent interaction chain, including prompts, responses, and function calls&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;OpenTelemetry&lt;/strong&gt;: Records metrics, traces, and logs for system performance analysis&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Terminal Output&lt;/strong&gt;: Provides immediate feedback on function execution&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;To access detailed logs:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Check Langfuse UI for AI agent traces (typically at &lt;code&gt;http://localhost:4000&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;Use Grafana dashboards for system metrics (typically at &lt;code&gt;http://localhost:3000&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;Examine terminal output for immediate function results and errors&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Command-line Options&lt;/h3&gt; 
&lt;p&gt;The main utility accepts several options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-env &amp;lt;path&amp;gt;&lt;/code&gt; - Path to environment file (optional, default: &lt;code&gt;.env&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-provider &amp;lt;type&amp;gt;&lt;/code&gt; - Provider type to use (default: &lt;code&gt;custom&lt;/code&gt;, options: &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;anthropic&lt;/code&gt;, &lt;code&gt;ollama&lt;/code&gt;, &lt;code&gt;bedrock&lt;/code&gt;, &lt;code&gt;gemini&lt;/code&gt;, &lt;code&gt;custom&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-flow &amp;lt;id&amp;gt;&lt;/code&gt; - Flow ID for testing (0 means using mocks, default: &lt;code&gt;0&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-task &amp;lt;id&amp;gt;&lt;/code&gt; - Task ID for agent context (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-subtask &amp;lt;id&amp;gt;&lt;/code&gt; - Subtask ID for agent context (optional)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Function-specific arguments are passed after the function name using &lt;code&gt;-name value&lt;/code&gt; format.&lt;/p&gt; 
&lt;h2&gt;🏗️ Building&lt;/h2&gt; 
&lt;h3&gt;Building Docker Image&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t local/pentagi:latest .
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You can use &lt;code&gt;docker buildx&lt;/code&gt; to build the image for different platforms like a &lt;code&gt;docker buildx build --platform linux/amd64 -t local/pentagi:latest .&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;You need to change image name in docker-compose.yml file to &lt;code&gt;local/pentagi:latest&lt;/code&gt; and run &lt;code&gt;docker compose up -d&lt;/code&gt; to start the server or use &lt;code&gt;build&lt;/code&gt; key option in &lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt; file.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;👏 Credits&lt;/h2&gt; 
&lt;p&gt;This project is made possible thanks to the following research and developments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://lilianweng.github.io/posts/2023-06-23-agent"&gt;Emerging Architectures for LLM Applications&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2403.08299"&gt;A Survey of Autonomous LLM Agents&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;h3&gt;PentAGI Core License&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;PentAGI Core&lt;/strong&gt;: Licensed under &lt;a href="https://raw.githubusercontent.com/vxcontrol/pentagi/master/LICENSE"&gt;MIT License&lt;/a&gt;&lt;br /&gt; Copyright (c) 2025 PentAGI Development Team&lt;/p&gt; 
&lt;h3&gt;VXControl Cloud SDK Integration&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;VXControl Cloud SDK Integration&lt;/strong&gt;: This repository integrates &lt;a href="https://github.com/vxcontrol/cloud"&gt;VXControl Cloud SDK&lt;/a&gt; under a &lt;strong&gt;special licensing exception&lt;/strong&gt; that applies &lt;strong&gt;ONLY&lt;/strong&gt; to the official PentAGI project.&lt;/p&gt; 
&lt;h4&gt;✅ Official PentAGI Project&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;This official repository: &lt;code&gt;https://github.com/vxcontrol/pentagi&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Official releases distributed by VXControl LLC&lt;/li&gt; 
 &lt;li&gt;Code used under direct authorization from VXControl LLC&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;⚠️ Important for Forks and Third-Party Use&lt;/h4&gt; 
&lt;p&gt;If you fork this project or create derivative works, the VXControl SDK components are subject to &lt;strong&gt;AGPL-3.0&lt;/strong&gt; license terms. You must either:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Remove VXControl SDK integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open source your entire application&lt;/strong&gt; (comply with AGPL-3.0 copyleft terms)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Obtain a commercial license&lt;/strong&gt; from VXControl LLC&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Commercial Licensing&lt;/h4&gt; 
&lt;p&gt;For commercial use of VXControl Cloud SDK in proprietary applications, contact:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Email&lt;/strong&gt;: &lt;a href="mailto:info@vxcontrol.com"&gt;info@vxcontrol.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Subject&lt;/strong&gt;: "VXControl Cloud SDK Commercial License"&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>opentofu/opentofu</title>
      <link>https://github.com/opentofu/opentofu</link>
      <description>&lt;p&gt;OpenTofu lets you declaratively manage your cloud infrastructure.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenTofu&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://opentofu.org/"&gt;HomePage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opentofu.org/docs/intro/install"&gt;How to install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opentofu.org/slack"&gt;Join our Slack community!&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-dark.svg#gh-dark-mode-only" alt="" /&gt; &lt;img src="https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-light.svg#gh-light-mode-only" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bestpractices.dev/projects/10508"&gt;&lt;img src="https://www.bestpractices.dev/projects/10508/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OpenTofu is an OSS tool for building, changing, and versioning infrastructure safely and efficiently. OpenTofu can manage existing and popular service providers as well as custom in-house solutions.&lt;/p&gt; 
&lt;p&gt;The key features of OpenTofu are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Infrastructure as Code&lt;/strong&gt;: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Execution Plans&lt;/strong&gt;: OpenTofu has a "planning" step where it generates an execution plan. The execution plan shows what OpenTofu will do when you call apply. This lets you avoid any surprises when OpenTofu manipulates infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Resource Graph&lt;/strong&gt;: OpenTofu builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, OpenTofu builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Change Automation&lt;/strong&gt;: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what OpenTofu will change and in what order, avoiding many possible human errors.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting help and contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have a question? 
  &lt;ul&gt; 
   &lt;li&gt;Post it in &lt;a href="https://github.com/orgs/opentofu/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Open a &lt;a href="https://github.com/opentofu/opentofu/issues/new/choose"&gt;GitHub issue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Join the &lt;a href="https://opentofu.org/slack/"&gt;OpenTofu Slack&lt;/a&gt;!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Want to contribute? 
  &lt;ul&gt; 
   &lt;li&gt;Please read the &lt;a href="https://raw.githubusercontent.com/opentofu/opentofu/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Recurring Events 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://meet.google.com/xfm-cgms-has"&gt;Community Meetings&lt;/a&gt; on Wednesdays at 12:30 UTC at this link: &lt;a href="https://meet.google.com/xfm-cgms-has"&gt;https://meet.google.com/xfm-cgms-has&lt;/a&gt; (&lt;a href="https://calendar.google.com/calendar/event?eid=NDg0aWl2Y3U1aHFva3N0bGhyMHBhNzdpZmsgY18zZjJkZDNjMWZlMGVmNGU5M2VmM2ZjNDU2Y2EyZGQyMTlhMmU4ZmQ4NWY2YjQwNzUwYWYxNmMzZGYzNzBiZjkzQGc"&gt;📅 calendar link&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://meet.google.com/cry-houa-qbk"&gt;Technical Steering Committee Meetings&lt;/a&gt; every other Tuesday at 4pm UTC at this link: &lt;a href="https://meet.google.com/cry-houa-qbk"&gt;https://meet.google.com/cry-houa-qbk&lt;/a&gt; (&lt;a href="https://calendar.google.com/calendar/u/0/event?eid=M3JyMWtuYWptdXI0Zms4ZnJpNmppcDczb3RfMjAyNTA1MjdUMTYwMDAwWiBjXzNmMmRkM2MxZmUwZWY0ZTkzZWYzZmM0NTZjYTJkZDIxOWEyZThmZDg1ZjZiNDA3NTBhZjE2YzNkZjM3MGJmOTNAZw"&gt;📅 calendar link&lt;/a&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] For more OpenTofu events, subscribe to the &lt;a href="https://calendar.google.com/calendar/embed?src=c_3f2dd3c1fe0ef4e93ef3fc456ca2dd219a2e8fd85f6b40750af16c3df370bf93%40group.calendar.google.com"&gt;OpenTofu Events Calendar&lt;/a&gt;!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Reporting security vulnerabilities&lt;/h2&gt; 
&lt;p&gt;If you've found a vulnerability or a potential vulnerability in OpenTofu please follow &lt;a href="https://github.com/opentofu/opentofu/security/policy"&gt;Security Policy&lt;/a&gt;. We'll send a confirmation email to acknowledge your report, and we'll send an additional email when we've identified the issue positively or negatively.&lt;/p&gt; 
&lt;h2&gt;Reporting possible copyright issues&lt;/h2&gt; 
&lt;p&gt;If you believe you have found any possible copyright or intellectual property issues, please contact &lt;a href="mailto:liaison@opentofu.org"&gt;liaison@opentofu.org&lt;/a&gt;. We'll send a confirmation email to acknowledge your report.&lt;/p&gt; 
&lt;h2&gt;Registry Access&lt;/h2&gt; 
&lt;p&gt;In an effort to comply with applicable sanctions, we block access from specific countries of origin.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/opentofu/opentofu/raw/main/LICENSE"&gt;Mozilla Public License v2.0&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zalando/postgres-operator</title>
      <link>https://github.com/zalando/postgres-operator</link>
      <description>&lt;p&gt;Postgres operator creates and manages PostgreSQL clusters running in Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Postgres Operator&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/zalando/postgres-operator/workflows/operator-tests/badge.svg?sanitize=true" alt="Tests" /&gt; &lt;img src="https://github.com/zalando/postgres-operator/workflows/operator-e2e-tests/badge.svg?sanitize=true" alt="E2E Tests" /&gt; &lt;a href="https://coveralls.io/github/zalando/postgres-operator?branch=master"&gt;&lt;img src="https://coveralls.io/repos/github/zalando/postgres-operator/badge.svg?branch=master" alt="Coverage Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/diagrams/logo.png" width="200" /&gt; 
&lt;p&gt;The Postgres Operator delivers an easy to run highly-available &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; clusters on Kubernetes (K8s) powered by &lt;a href="https://github.com/zalando/patroni"&gt;Patroni&lt;/a&gt;. It is configured only through Postgres manifests (CRDs) to ease integration into automated CI/CD pipelines with no access to Kubernetes API directly, promoting infrastructure as code vs manual operations.&lt;/p&gt; 
&lt;h3&gt;Operator features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rolling updates on Postgres cluster changes, incl. quick minor version updates&lt;/li&gt; 
 &lt;li&gt;Live volume resize without pod restarts (AWS EBS, PVC)&lt;/li&gt; 
 &lt;li&gt;Database connection pooling with PGBouncer&lt;/li&gt; 
 &lt;li&gt;Support fast in place major version upgrade. Supports global upgrade of all clusters.&lt;/li&gt; 
 &lt;li&gt;Restore and cloning Postgres clusters on AWS, GCS and Azure&lt;/li&gt; 
 &lt;li&gt;Additionally logical backups to S3 or GCS bucket can be configured&lt;/li&gt; 
 &lt;li&gt;Standby cluster from S3 or GCS WAL archive&lt;/li&gt; 
 &lt;li&gt;Configurable for non-cloud environments&lt;/li&gt; 
 &lt;li&gt;Basic credential and user management on K8s, eases application deployments&lt;/li&gt; 
 &lt;li&gt;Support for custom TLS certificates&lt;/li&gt; 
 &lt;li&gt;UI to create and edit Postgres cluster manifests&lt;/li&gt; 
 &lt;li&gt;Compatible with OpenShift&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;PostgreSQL features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports PostgreSQL 17, starting from 13+&lt;/li&gt; 
 &lt;li&gt;Streaming replication cluster via Patroni&lt;/li&gt; 
 &lt;li&gt;Point-In-Time-Recovery with &lt;a href="https://www.postgresql.org/docs/17/app-pgbasebackup.html"&gt;pg_basebackup&lt;/a&gt; / &lt;a href="https://github.com/wal-e/wal-e"&gt;WAL-E&lt;/a&gt; via &lt;a href="https://github.com/zalando/spilo"&gt;Spilo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Preload libraries: &lt;a href="https://github.com/CyberDem0n/bg_mon"&gt;bg_mon&lt;/a&gt;, &lt;a href="https://www.postgresql.org/docs/17/pgstatstatements.html"&gt;pg_stat_statements&lt;/a&gt;, &lt;a href="https://github.com/dimitri/pgextwlist"&gt;pgextwlist&lt;/a&gt;, &lt;a href="https://github.com/RafiaSabih/pg_auth_mon"&gt;pg_auth_mon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Incl. popular Postgres extensions such as &lt;a href="https://github.com/debezium/postgres-decoderbufs"&gt;decoderbufs&lt;/a&gt;, &lt;a href="https://github.com/HypoPG/hypopg"&gt;hypopg&lt;/a&gt;, &lt;a href="https://github.com/citusdata/pg_cron"&gt;pg_cron&lt;/a&gt;, &lt;a href="https://github.com/pgpartman/pg_partman"&gt;pg_partman&lt;/a&gt;, &lt;a href="https://github.com/powa-team/pg_stat_kcache"&gt;pg_stat_kcache&lt;/a&gt;, &lt;a href="https://github.com/pgq/pgq"&gt;pgq&lt;/a&gt;, &lt;a href="https://github.com/pgvector/pgvector"&gt;pgvector&lt;/a&gt;, &lt;a href="https://github.com/okbob/plpgsql_check"&gt;plpgsql_check&lt;/a&gt;, &lt;a href="https://postgis.net/"&gt;postgis&lt;/a&gt;, &lt;a href="https://github.com/pgaudit/set_user"&gt;set_user&lt;/a&gt; and &lt;a href="https://github.com/timescale/timescaledb"&gt;timescaledb&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The Postgres Operator has been developed at Zalando and is being used in production for over five years.&lt;/p&gt; 
&lt;h2&gt;Supported Postgres &amp;amp; K8s versions&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Release&lt;/th&gt; 
   &lt;th align="center"&gt;Postgres versions&lt;/th&gt; 
   &lt;th align="center"&gt;K8s versions&lt;/th&gt; 
   &lt;th align="center"&gt;Golang&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;v1.15.0&lt;/td&gt; 
   &lt;td align="center"&gt;13 → 17&lt;/td&gt; 
   &lt;td align="center"&gt;1.27+&lt;/td&gt; 
   &lt;td align="center"&gt;1.25.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;v1.14.0&lt;/td&gt; 
   &lt;td align="center"&gt;13 → 17&lt;/td&gt; 
   &lt;td align="center"&gt;1.27+&lt;/td&gt; 
   &lt;td align="center"&gt;1.23.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;v1.13.0&lt;/td&gt; 
   &lt;td align="center"&gt;12 → 16&lt;/td&gt; 
   &lt;td align="center"&gt;1.27+&lt;/td&gt; 
   &lt;td align="center"&gt;1.22.5&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;v1.12.0&lt;/td&gt; 
   &lt;td align="center"&gt;11 → 16&lt;/td&gt; 
   &lt;td align="center"&gt;1.27+&lt;/td&gt; 
   &lt;td align="center"&gt;1.22.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;v1.11.0&lt;/td&gt; 
   &lt;td align="center"&gt;11 → 16&lt;/td&gt; 
   &lt;td align="center"&gt;1.27+&lt;/td&gt; 
   &lt;td align="center"&gt;1.21.7&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;v1.10.1&lt;/td&gt; 
   &lt;td align="center"&gt;10 → 15&lt;/td&gt; 
   &lt;td align="center"&gt;1.21+&lt;/td&gt; 
   &lt;td align="center"&gt;1.19.8&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;For a quick first impression follow the instructions of this &lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/quickstart.md"&gt;tutorial&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Supported setups of Postgres and Applications&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/diagrams/neutral_operator_dark.png#gh-dark-mode-only" alt="Features" /&gt; &lt;img src="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/diagrams/neutral_operator_light.png#gh-light-mode-only" alt="Features" /&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;There is a browser-friendly version of this documentation at &lt;a href="https://postgres-operator.readthedocs.io"&gt;postgres-operator.readthedocs.io&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/index.md"&gt;How it works&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/quickstart.md#deployment-options"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/user.md"&gt;The Postgres experience on K8s&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/operator-ui.md"&gt;The Postgres Operator UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/administrator.md"&gt;DBA options - from RBAC to backup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/developer.md"&gt;Build, debug and extend the operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/reference/operator_parameters.md"&gt;Configuration options&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/reference/cluster_manifest.md"&gt;Postgres manifest reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zalando/postgres-operator/master/docs/reference/command_line_and_environment.md"&gt;Command-line options and environment variables&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>prometheus-operator/prometheus-operator</title>
      <link>https://github.com/prometheus-operator/prometheus-operator</link>
      <description>&lt;p&gt;Prometheus Operator creates/configures/manages Prometheus clusters atop Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Prometheus Operator&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/prometheus-operator/prometheus-operator/actions"&gt;&lt;img src="https://github.com/prometheus-operator/prometheus-operator/actions/workflows/checks.yaml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/prometheus-operator/prometheus-operator"&gt;&lt;img src="https://goreportcard.com/badge/prometheus-operator/prometheus-operator" alt="Go Report Card" title="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://kubernetes.slack.com"&gt;&lt;img src="https://img.shields.io/badge/join%20slack-%23prometheus--operator-brightgreen.svg?sanitize=true" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;The Prometheus Operator provides &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; native deployment and management of &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt; and related monitoring components. The purpose of this project is to simplify and automate the configuration of a Prometheus based monitoring stack for Kubernetes clusters.&lt;/p&gt; 
&lt;p&gt;The Prometheus operator includes, but is not limited to, the following features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Kubernetes Custom Resources&lt;/strong&gt;: Use Kubernetes custom resources to deploy and manage Prometheus, Alertmanager, and related components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simplified Deployment Configuration&lt;/strong&gt;: Configure the fundamentals of Prometheus like versions, persistence, retention policies, and replicas from a native Kubernetes resource.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prometheus Target Configuration&lt;/strong&gt;: Automatically generate monitoring target configurations based on familiar Kubernetes label queries; no need to learn a Prometheus specific configuration language.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For an introduction to the Prometheus Operator, see the &lt;a href="https://github.com/prometheus-operator/prometheus-operator/raw/main/Documentation/developer/getting-started.md"&gt;getting started&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h2&gt;Project Status&lt;/h2&gt; 
&lt;p&gt;The operator in itself is considered to be production ready. Please refer to the Custom Resource Definition (CRD) versions for the status of each CRD:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;monitoring.coreos.com/v1&lt;/code&gt;: &lt;strong&gt;stable&lt;/strong&gt; CRDs and API, changes are made in a backward-compatible way.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;monitoring.coreos.com/v1beta1&lt;/code&gt;: &lt;strong&gt;unstable&lt;/strong&gt; CRDs and API, changes can happen but the team is focused on avoiding them. We encourage usage in production for users that accept the risk of breaking changes.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;monitoring.coreos.com/v1alpha1&lt;/code&gt;: &lt;strong&gt;unstable&lt;/strong&gt; CRDs and API, changes can happen frequently, and we suggest avoiding its usage on mission-critical environments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Prometheus Operator vs. kube-prometheus vs. community Helm chart&lt;/h2&gt; 
&lt;h3&gt;Prometheus Operator&lt;/h3&gt; 
&lt;p&gt;The Prometheus Operator uses Kubernetes &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;custom resources&lt;/a&gt; to simplify the deployment and configuration of Prometheus, Alertmanager, and related monitoring components.&lt;/p&gt; 
&lt;h3&gt;kube-prometheus&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/prometheus-operator/kube-prometheus"&gt;kube-prometheus&lt;/a&gt; provides example configurations for a complete cluster monitoring stack based on Prometheus and the Prometheus Operator. This includes deployment of multiple Prometheus and Alertmanager instances, metrics exporters such as the node_exporter for gathering node metrics, scrape target configuration linking Prometheus to various metrics endpoints, and example alerting rules for notification of potential issues in the cluster.&lt;/p&gt; 
&lt;h3&gt;Helm chart&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack"&gt;prometheus-community/kube-prometheus-stack&lt;/a&gt; Helm chart provides a similar feature set to kube-prometheus. This chart is maintained by the Prometheus community. For more information, please see the &lt;a href="https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack#kube-prometheus-stack"&gt;chart's readme&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;The Prometheus Operator requires at least Kubernetes version &lt;code&gt;1.16.0&lt;/code&gt;. If you are just starting out with the Prometheus Operator, it is highly recommended to use the latest &lt;a href="https://github.com/prometheus-operator/prometheus-operator/releases/latest"&gt;stable release&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;CustomResourceDefinitions&lt;/h2&gt; 
&lt;p&gt;A core feature of the Prometheus Operator is to monitor the Kubernetes API server for changes to specific objects and ensure that the current Prometheus deployments match these objects. The Operator acts on the following &lt;a href="https://kubernetes.io/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/"&gt;Custom Resource Definitions (CRDs)&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;Prometheus&lt;/code&gt;&lt;/strong&gt;, which defines a desired Prometheus deployment.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;PrometheusAgent&lt;/code&gt;&lt;/strong&gt;, which defines a desired Prometheus deployment, but running in Agent mode.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;Alertmanager&lt;/code&gt;&lt;/strong&gt;, which defines a desired Alertmanager deployment.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;ThanosRuler&lt;/code&gt;&lt;/strong&gt;, which defines a desired Thanos Ruler deployment.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;ServiceMonitor&lt;/code&gt;&lt;/strong&gt;, which declaratively specifies how groups of Kubernetes services should be monitored. The Operator automatically generates Prometheus scrape configuration based on the current state of the objects in the API server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;PodMonitor&lt;/code&gt;&lt;/strong&gt;, which declaratively specifies how group of pods should be monitored. The Operator automatically generates Prometheus scrape configuration based on the current state of the objects in the API server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;Probe&lt;/code&gt;&lt;/strong&gt;, which declaratively specifies how groups of ingresses or static targets should be monitored. The Operator automatically generates Prometheus scrape configuration based on the definition.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;ScrapeConfig&lt;/code&gt;&lt;/strong&gt;, which declaratively specifies scrape configurations to be added to Prometheus. This CustomResourceDefinition helps with scraping resources outside the Kubernetes cluster.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;PrometheusRule&lt;/code&gt;&lt;/strong&gt;, which defines a desired set of Prometheus alerting and/or recording rules. The Operator generates a rule file, which can be used by Prometheus instances.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;AlertmanagerConfig&lt;/code&gt;&lt;/strong&gt;, which declaratively specifies subsections of the Alertmanager configuration, allowing routing of alerts to custom receivers, and setting inhibit rules.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The Prometheus operator automatically detects changes in the Kubernetes API server to any of the above objects, and ensures that matching deployments and configurations are kept in sync.&lt;/p&gt; 
&lt;p&gt;To learn more about the CRDs introduced by the Prometheus Operator have a look at the &lt;a href="https://prometheus-operator.dev/docs/getting-started/design/"&gt;design&lt;/a&gt; page.&lt;/p&gt; 
&lt;h2&gt;Dynamic Admission Control&lt;/h2&gt; 
&lt;p&gt;To prevent invalid Prometheus alerting and recording rules from causing failures in a deployed Prometheus instance, an &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/"&gt;admission webhook&lt;/a&gt; is provided to validate &lt;code&gt;PrometheusRule&lt;/code&gt; resources upon initial creation or update.&lt;/p&gt; 
&lt;p&gt;For more information on this feature, see the &lt;a href="https://prometheus-operator.dev/docs/platform/webhook/"&gt;user guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; this quickstart does not provision an entire monitoring stack; if that is what you are looking for, see the &lt;a href="https://github.com/prometheus-operator/kube-prometheus"&gt;kube-prometheus&lt;/a&gt; project. If you want the whole stack, but have already applied the &lt;code&gt;bundle.yaml&lt;/code&gt;, delete the bundle first (&lt;code&gt;kubectl delete -f bundle.yaml&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;To quickly try out &lt;em&gt;just&lt;/em&gt; the Prometheus Operator inside a cluster, &lt;strong&gt;choose a release&lt;/strong&gt; and run the following command which deploys the operator in the &lt;code&gt;default&lt;/code&gt; namespace:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;kubectl create -f bundle.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to deploy the Prometheus operator in a different namespace, you also need &lt;code&gt;kustomize&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;NAMESPACE=my_namespace kustomize edit set namespace $NAMESPACE &amp;amp;&amp;amp; kubectl create -k .
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: make sure to adapt the namespace in the ClusterRoleBinding if deploying in a namespace other than the default namespace.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To run the Operator outside of a cluster:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;make
scripts/run-external.sh &amp;lt;kubectl cluster name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Removal&lt;/h2&gt; 
&lt;p&gt;To remove the operator and Prometheus, first delete any custom resources you created in each namespace. The operator will automatically shut down and remove Prometheus and Alertmanager pods, and associated ConfigMaps.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;for n in $(kubectl get namespaces -o jsonpath={..metadata.name}); do
  kubectl delete --all --namespace=$n prometheus,servicemonitor,podmonitor,alertmanager
done
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After a couple of minutes you can go ahead and remove the operator itself.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;kubectl delete -f bundle.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The operator automatically creates services in each namespace where you created a Prometheus or Alertmanager resources, and defines three custom resource definitions. You can clean these up now.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;for n in $(kubectl get namespaces -o jsonpath={..metadata.name}); do
  kubectl delete --ignore-not-found --namespace=$n service prometheus-operated alertmanager-operated
done

kubectl delete --ignore-not-found customresourcedefinitions \
  prometheuses.monitoring.coreos.com \
  servicemonitors.monitoring.coreos.com \
  podmonitors.monitoring.coreos.com \
  alertmanagers.monitoring.coreos.com \
  prometheusrules.monitoring.coreos.com \
  alertmanagerconfigs.monitoring.coreos.com \
  scrapeconfigs.monitoring.coreos.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/TESTING.md"&gt;TESTING&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you find a security vulnerability related to the Prometheus Operator which isn't already publicly disclosed, please do not report it by opening a GitHub issue, but instead please send an e-mail to the maintainers of the project found in the &lt;a href="https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/MAINTAINERS.md"&gt;MAINTAINERS.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://prometheus.io/docs/operating/security/#automated-security-scanners"&gt;Prometheus documentation&lt;/a&gt; when reporting issues from automated security scanners.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/Documentation/platform/troubleshooting.md"&gt;troubleshooting documentation&lt;/a&gt; for common issues and frequently asked questions (FAQ).&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;prometheus-operator organization logo was created and contributed by &lt;a href="https://github.com/bia"&gt;Bianca Cheng Costanzo&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>stefanprodan/podinfo</title>
      <link>https://github.com/stefanprodan/podinfo</link>
      <description>&lt;p&gt;Go microservice template for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;podinfo&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/stefanprodan/podinfo/raw/master/.github/workflows/e2e.yml"&gt;&lt;img src="https://github.com/stefanprodan/podinfo/workflows/e2e/badge.svg?sanitize=true" alt="e2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/stefanprodan/podinfo/raw/master/.github/workflows/test.yml"&gt;&lt;img src="https://github.com/stefanprodan/podinfo/workflows/test/badge.svg?sanitize=true" alt="test" /&gt;&lt;/a&gt; &lt;a href="https://github.com/stefanprodan/podinfo/raw/master/.github/workflows/cve-scan.yml"&gt;&lt;img src="https://github.com/stefanprodan/podinfo/workflows/cve-scan/badge.svg?sanitize=true" alt="cve-scan" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/stefanprodan/podinfo"&gt;&lt;img src="https://goreportcard.com/badge/github.com/stefanprodan/podinfo" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/stefanprodan/podinfo"&gt;&lt;img src="https://img.shields.io/docker/pulls/stefanprodan/podinfo" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Podinfo is a tiny web application made with Go that showcases best practices of running microservices in Kubernetes. Podinfo is used by CNCF projects like &lt;a href="https://github.com/fluxcd/flux2"&gt;Flux&lt;/a&gt; and &lt;a href="https://github.com/fluxcd/flagger"&gt;Flagger&lt;/a&gt; for end-to-end testing and workshops.&lt;/p&gt; 
&lt;p&gt;Specifications:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Health checks (readiness and liveness)&lt;/li&gt; 
 &lt;li&gt;Graceful shutdown on interrupt signals&lt;/li&gt; 
 &lt;li&gt;File watcher for secrets and configmaps&lt;/li&gt; 
 &lt;li&gt;Instrumented with Prometheus and Open Telemetry&lt;/li&gt; 
 &lt;li&gt;Structured logging with zap&lt;/li&gt; 
 &lt;li&gt;12-factor app with viper&lt;/li&gt; 
 &lt;li&gt;Fault injection (random errors and latency)&lt;/li&gt; 
 &lt;li&gt;Swagger docs&lt;/li&gt; 
 &lt;li&gt;Timoni, Helm and Kustomize installers&lt;/li&gt; 
 &lt;li&gt;End-to-End testing with Kubernetes Kind and Helm&lt;/li&gt; 
 &lt;li&gt;Multi-arch container image with Docker buildx and GitHub Actions&lt;/li&gt; 
 &lt;li&gt;Container image signing with Sigstore cosign&lt;/li&gt; 
 &lt;li&gt;SBOMs and SLSA Provenance embedded in the container image&lt;/li&gt; 
 &lt;li&gt;CVE scanning with govulncheck&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Web API:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /&lt;/code&gt; prints runtime information&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /version&lt;/code&gt; prints podinfo version and git commit hash&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /metrics&lt;/code&gt; return HTTP requests duration and Go runtime metrics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /healthz&lt;/code&gt; used by Kubernetes liveness probe&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /readyz&lt;/code&gt; used by Kubernetes readiness probe&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /readyz/enable&lt;/code&gt; signals the Kubernetes LB that this instance is ready to receive traffic&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /readyz/disable&lt;/code&gt; signals the Kubernetes LB to stop sending requests to this instance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /status/{code}&lt;/code&gt; returns the status code&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /panic&lt;/code&gt; crashes the process with exit code 255&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /echo&lt;/code&gt; forwards the call to the backend service and echos the posted content&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /env&lt;/code&gt; returns the environment variables as a JSON array&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /headers&lt;/code&gt; returns a JSON with the request HTTP headers&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /delay/{seconds}&lt;/code&gt; waits for the specified period&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /token&lt;/code&gt; issues a JWT token valid for one minute &lt;code&gt;JWT=$(curl -sd 'anon' podinfo:9898/token | jq -r .token)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /token/validate&lt;/code&gt; validates the JWT token &lt;code&gt;curl -H "Authorization: Bearer $JWT" podinfo:9898/token/validate&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /configs&lt;/code&gt; returns a JSON with configmaps and/or secrets mounted in the &lt;code&gt;config&lt;/code&gt; volume&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST/PUT /cache/{key}&lt;/code&gt; saves the posted content to Redis&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /cache/{key}&lt;/code&gt; returns the content from Redis if the key exists&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DELETE /cache/{key}&lt;/code&gt; deletes the key from Redis if exists&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /store&lt;/code&gt; writes the posted content to disk at /data/hash and returns the SHA1 hash of the content&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /store/{hash}&lt;/code&gt; returns the content of the file /data/hash if exists&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /ws/echo&lt;/code&gt; echos content via websockets &lt;code&gt;podcli ws ws://localhost:9898/ws/echo&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /chunked/{seconds}&lt;/code&gt; uses &lt;code&gt;transfer-encoding&lt;/code&gt; type &lt;code&gt;chunked&lt;/code&gt; to give a partial response and then waits for the specified period&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /swagger.json&lt;/code&gt; returns the API Swagger docs, used for Linkerd service profiling and Gloo routes discovery&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;gRPC API:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.health.v1.Health/Check&lt;/code&gt; health checking&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.EchoService/Echo&lt;/code&gt; echos the received content&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.VersionService/Version&lt;/code&gt; returns podinfo version and Git commit hash&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.DelayService/Delay&lt;/code&gt; returns a successful response after the given seconds in the body of gRPC request&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.EnvService/Env&lt;/code&gt; returns environment variables as a JSON array&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.HeaderService/Header&lt;/code&gt; returns the headers present in the gRPC request. Any custom header can also be given as a part of request and that can be returned using this API&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.InfoService/Info&lt;/code&gt; returns the runtime information&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.PanicService/Panic&lt;/code&gt; crashes the process with gRPC status code as '1 CANCELLED'&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.StatusService/Status&lt;/code&gt; returns the gRPC Status code given in the request body&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.TokenService/TokenGenerate&lt;/code&gt; issues a JWT token valid for one minute&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/grpc.TokenService/TokenValidate&lt;/code&gt; validates the JWT token&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Web UI:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/stefanprodan/podinfo/gh-pages/screens/podinfo-ui-v3.png" alt="podinfo-ui" /&gt;&lt;/p&gt; 
&lt;p&gt;To access the Swagger UI open &lt;code&gt;&amp;lt;podinfo-host&amp;gt;/swagger/index.html&lt;/code&gt; in a browser.&lt;/p&gt; 
&lt;h3&gt;Guides&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://timoni.sh/quickstart/"&gt;Getting started with Timoni&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fluxcd.io/flux/get-started/"&gt;Getting started with Flux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.flagger.app/tutorials/linkerd-progressive-delivery"&gt;Progressive Deliver with Flagger and Linkerd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.flagger.app/tutorials/gatewayapi-progressive-delivery"&gt;Automated canary deployments with Kubernetes Gateway API&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;To install Podinfo on Kubernetes the minimum required version is &lt;strong&gt;Kubernetes v1.23&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Timoni&lt;/h4&gt; 
&lt;p&gt;Install with &lt;a href="https://timoni.sh"&gt;Timoni&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;timoni -n default apply podinfo oci://ghcr.io/stefanprodan/modules/podinfo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Helm&lt;/h4&gt; 
&lt;p&gt;Install from github.io:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;helm repo add podinfo https://stefanprodan.github.io/podinfo

helm upgrade --install --wait frontend \
--namespace test \
--set replicaCount=2 \
--set backend=http://backend-podinfo:9898/echo \
podinfo/podinfo

helm test frontend --namespace test

helm upgrade --install --wait backend \
--namespace test \
--set redis.enabled=true \
podinfo/podinfo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install from ghcr.io:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;helm upgrade --install --wait podinfo --namespace default \
oci://ghcr.io/stefanprodan/charts/podinfo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Kustomize&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;kubectl apply -k github.com/stefanprodan/podinfo//kustomize
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -dp 9898:9898 stefanprodan/podinfo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Continuous Delivery&lt;/h3&gt; 
&lt;p&gt;In order to install podinfo on a Kubernetes cluster and keep it up to date with the latest release in an automated manner, you can use &lt;a href="https://fluxcd.io"&gt;Flux&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Install the Flux CLI on MacOS and Linux using Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install fluxcd/tap/flux
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the Flux controllers needed for Helm operations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;flux install \
--namespace=flux-system \
--network-policy=false \
--components=source-controller,helm-controller
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add podinfo's Helm repository to your cluster and configure Flux to check for new chart releases every ten minutes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;flux create source helm podinfo \
--namespace=default \
--url=https://stefanprodan.github.io/podinfo \
--interval=10m
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a &lt;code&gt;podinfo-values.yaml&lt;/code&gt; file locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cat &amp;gt; podinfo-values.yaml &amp;lt;&amp;lt;EOL
replicaCount: 2
resources:
  limits:
    memory: 256Mi
  requests:
    cpu: 100m
    memory: 64Mi
EOL
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a Helm release for deploying podinfo in the default namespace:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;flux create helmrelease podinfo \
--namespace=default \
--source=HelmRepository/podinfo \
--release-name=podinfo \
--chart=podinfo \
--chart-version="&amp;gt;5.0.0" \
--values=podinfo-values.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Based on the above definition, Flux will upgrade the release automatically when a new version of podinfo is released. If the upgrade fails, Flux can &lt;a href="https://toolkit.fluxcd.io/components/helm/helmreleases/#configuring-failure-remediation"&gt;rollback&lt;/a&gt; to the previous working version.&lt;/p&gt; 
&lt;p&gt;You can check what version is currently deployed with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;flux get helmreleases -n default
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To delete podinfo's Helm repository and release from your cluster run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;flux -n default delete source helm podinfo
flux -n default delete helmrelease podinfo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you wish to manage the lifecycle of your applications in a &lt;strong&gt;GitOps&lt;/strong&gt; manner, check out this &lt;a href="https://github.com/fluxcd/flux2-kustomize-helm-example"&gt;workflow example&lt;/a&gt; for multi-env deployments with Flux, Kustomize and Helm.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>XTLS/Xray-core</title>
      <link>https://github.com/XTLS/Xray-core</link>
      <description>&lt;p&gt;Xray, Penetrates Everything. Also the best v2ray-core. Where the magic happens. An open platform for various uses.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Project X&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/XTLS"&gt;Project X&lt;/a&gt; originates from XTLS protocol, providing a set of network tools such as &lt;a href="https://github.com/XTLS/Xray-core"&gt;Xray-core&lt;/a&gt; and &lt;a href="https://github.com/XTLS/REALITY"&gt;REALITY&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/XTLS/Xray-core#readme"&gt;README&lt;/a&gt; is open, so feel free to submit your project &lt;a href="https://github.com/XTLS/Xray-core/pulls"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Donation &amp;amp; NFTs&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1"&gt;Collect a Project X NFT to support the development of Project X!&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1"&gt;&lt;img alt="Project X NFT" width="150px" src="https://raw2.seadn.io/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/7fa9ce900fb39b44226348db330e32/8b7fa9ce900fb39b44226348db330e32.svg?sanitize=true" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ETH/USDT/USDC: &lt;code&gt;0xDc3Fe44F0f25D13CACb1C4896CD0D321df3146Ee&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Project X NFT: &lt;a href="https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1"&gt;https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;VLESS NFT: &lt;a href="https://opensea.io/collection/vless"&gt;https://opensea.io/collection/vless&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;REALITY NFT: &lt;a href="https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/2"&gt;https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/2&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Related links: &lt;a href="https://github.com/XTLS/Xray-core/pull/5067"&gt;VLESS Post-Quantum Encryption&lt;/a&gt;, &lt;a href="https://github.com/XTLS/Xray-core/discussions/4113"&gt;XHTTP: Beyond REALITY&lt;/a&gt;, &lt;a href="https://github.com/XTLS/Xray-core/discussions/3633"&gt;Announcement of NFTs by Project X&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/XTLS/Xray-core/raw/main/LICENSE"&gt;Mozilla Public License Version 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://xtls.github.io"&gt;Project X Official Website&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Telegram&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://t.me/projectXray"&gt;Project X&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://t.me/projectXtls"&gt;Project X Channel&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://t.me/projectVless"&gt;Project VLESS&lt;/a&gt; (Русский)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://t.me/projectXhttp"&gt;Project XHTTP&lt;/a&gt; (Persian)&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Linux Script 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-install"&gt;XTLS/Xray-install&lt;/a&gt; (&lt;strong&gt;Official&lt;/strong&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/team-cloudchaser/tempest"&gt;tempest&lt;/a&gt; (supports &lt;a href="https://systemd.io"&gt;&lt;code&gt;systemd&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/OpenRC/openrc"&gt;OpenRC&lt;/a&gt;; Linux-only)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Docker 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://ghcr.io/xtls/xray-core"&gt;ghcr.io/xtls/xray-core&lt;/a&gt; (&lt;strong&gt;Official&lt;/strong&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://hub.docker.com/r/teddysun/xray"&gt;teddysun/xray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/wulabing/xray_docker"&gt;wulabing/xray_docker&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Web Panel - &lt;strong&gt;WARNING: Please DO NOT USE plain HTTP panels like 3X-UI&lt;/strong&gt;, as they are believed to be bribed by Iran GFW for supporting plain HTTP by default and refused to change (&lt;a href="https://github.com/XTLS/Xray-core/pull/3884#issuecomment-2439595331"&gt;https://github.com/XTLS/Xray-core/pull/3884#issuecomment-2439595331&lt;/a&gt;), which has already put many users' data security in danger in the past few years. &lt;strong&gt;If you are already using 3X-UI, please switch to the following panels, which are verified to support HTTPS and SSH port forwarding only:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/xeefei/X-Panel"&gt;X-Panel&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/PasarGuard/panel"&gt;PasarGuard&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/remnawave/panel"&gt;Remnawave&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Gozargah/Marzban"&gt;Marzban&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qist/xray-ui"&gt;Xray-UI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/hiddify/Hiddify-Manager"&gt;Hiddify&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;One Click 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/zxcvos/Xray-script"&gt;Xray-REALITY&lt;/a&gt;, &lt;a href="https://github.com/sajjaddg/xray-reality"&gt;xray-reality&lt;/a&gt;, &lt;a href="https://github.com/aleskxyz/reality-ezpz"&gt;reality-ezpz&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/hello-yunshu/Xray_bash_onekey"&gt;Xray_bash_onekey&lt;/a&gt;, &lt;a href="https://github.com/LordPenguin666/XTool"&gt;XTool&lt;/a&gt;, &lt;a href="https://github.com/vpainless/vpainless"&gt;VPainLess&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mack-a/v2ray-agent"&gt;v2ray-agent&lt;/a&gt;, &lt;a href="https://github.com/wulabing/Xray_onekey"&gt;Xray_onekey&lt;/a&gt;, &lt;a href="https://github.com/proxysu/ProxySU"&gt;ProxySU&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Magisk 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Asterisk4Magisk/Xray4Magisk"&gt;Xray4Magisk&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/E7KMbb/Xray_For_Magisk"&gt;Xray_For_Magisk&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Homebrew 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;brew install xray&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Example 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/REALITY#readme"&gt;VLESS-XTLS-uTLS-REALITY&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-examples/tree/main/VLESS-TCP-XTLS-Vision"&gt;VLESS-TCP-XTLS-Vision&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-examples/tree/main/All-in-One-fallbacks-Nginx"&gt;All-in-One-fallbacks-Nginx&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Xray-examples 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-examples"&gt;XTLS/Xray-examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/chika0801/Xray-examples"&gt;chika0801/Xray-examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lxhao61/integrated-examples"&gt;lxhao61/integrated-examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Tutorial 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/chika0801/Xray-install"&gt;XTLS Vision&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://cscot.pages.dev/2023/03/02/Xray-REALITY-tutorial/"&gt;REALITY (English)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/SasukeFreestyle/XTLS-Iran-Reality"&gt;XTLS-Iran-Reality (English)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://computerscot.github.io/vless-xtls-utls-reality-steal-oneself.html"&gt;Xray REALITY with 'steal oneself' (English)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://g800.pages.dev/wireguard"&gt;Xray with WireGuard inbound (English)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;GUI Clients&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenWrt 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/xiaorouji/openwrt-passwall"&gt;PassWall&lt;/a&gt;, &lt;a href="https://github.com/xiaorouji/openwrt-passwall2"&gt;PassWall 2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/fw876/helloworld"&gt;ShadowSocksR Plus+&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yichya/luci-app-xray"&gt;luci-app-xray&lt;/a&gt; (&lt;a href="https://github.com/yichya/openwrt-xray"&gt;openwrt-xray&lt;/a&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Asuswrt-Merlin 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/DanielLavrushin/asuswrt-merlin-xrayui"&gt;XRAYUI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Windows 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/2dust/v2rayN"&gt;v2rayN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/LorenEteval/Furious"&gt;Furious&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/InvisibleManVPN/InvisibleMan-XRayClient"&gt;Invisible Man - Xray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AnyPortal/AnyPortal"&gt;AnyPortal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Android 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/2dust/v2rayNG"&gt;v2rayNG&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/X-flutter"&gt;X-flutter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/SaeedDev94/Xray"&gt;SaeedDev94/Xray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lhear/SimpleXray"&gt;SimpleXray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AnyPortal/AnyPortal"&gt;AnyPortal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;iOS &amp;amp; macOS arm64 &amp;amp; tvOS 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/app/happ-proxy-utility/id6504287215"&gt;Happ&lt;/a&gt; (&lt;a href="https://apps.apple.com/us/app/happ-proxy-utility-for-tv/id6748297274"&gt;tvOS&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/app/streisand/id6450534064"&gt;Streisand&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/OneXray/OneXray"&gt;OneXray&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;macOS arm64 &amp;amp; x64 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/app/happ-proxy-utility/id6504287215"&gt;Happ&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yanue/V2rayU"&gt;V2rayU&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tzmax/V2RayXS"&gt;V2RayXS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/LorenEteval/Furious"&gt;Furious&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/OneXray/OneXray"&gt;OneXray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/goxray/desktop"&gt;GoXRay&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AnyPortal/AnyPortal"&gt;AnyPortal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Linux 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/v2rayA/v2rayA"&gt;v2rayA&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/LorenEteval/Furious"&gt;Furious&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ketetefid/GorzRay"&gt;GorzRay&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/goxray/desktop"&gt;GoXRay&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AnyPortal/AnyPortal"&gt;AnyPortal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Others that support VLESS, XTLS, REALITY, XUDP, PLUX...&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;iOS &amp;amp; macOS arm64 &amp;amp; tvOS 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/app/shadowrocket/id932747118"&gt;Shadowrocket&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/us/app/loon/id1373567447"&gt;Loon&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Xray Tools 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lilendian0x00/xray-knife"&gt;xray-knife&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/kutovoys/xray-checker"&gt;xray-checker&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Xray Wrapper 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/libXray"&gt;XTLS/libXray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/remnawave/xtls-sdk"&gt;xtls-sdk&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/hiddify/xtlsapi"&gt;xtlsapi&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/2dust/AndroidLibXrayLite"&gt;AndroidLibXrayLite&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/LorenEteval/Xray-core-python"&gt;Xray-core-python&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XVGuardian/xray-api"&gt;xray-api&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XrayR-project/XrayR"&gt;XrayR&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XrayR-project/XrayR-release"&gt;XrayR-release&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/missuo/XrayR-V2Board"&gt;XrayR-V2Board&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Cores 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/amnezia-vpn"&gt;Amnezia VPN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/MetaCubeX/mihomo"&gt;mihomo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/SagerNet/sing-box"&gt;sing-box&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/XTLS/Xray-core/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://deepwiki.com/XTLS/Xray-core"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-core/releases/tag/v1.0.0"&gt;Xray-core v1.0.0&lt;/a&gt; was forked from &lt;a href="https://github.com/v2fly/v2ray-core/commit/9a03cc5c98d04cc28320fcee26dbc236b3291256"&gt;v2fly-core 9a03cc5&lt;/a&gt;, and we have made &amp;amp; accumulated a huge number of enhancements over time, check &lt;a href="https://github.com/XTLS/Xray-core/releases"&gt;the release notes for each version&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For third-party projects used in &lt;a href="https://github.com/XTLS/Xray-core"&gt;Xray-core&lt;/a&gt;, check your local or &lt;a href="https://github.com/XTLS/Xray-core/raw/main/go.mod"&gt;the latest go.mod&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;One-line Compilation&lt;/h2&gt; 
&lt;h3&gt;Windows (PowerShell)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;$env:CGO_ENABLED=0
go build -o xray.exe -trimpath -buildvcs=false -ldflags="-s -w -buildid=" -v ./main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linux / macOS&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -ldflags="-s -w -buildid=" -v ./main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reproducible Releases&lt;/h3&gt; 
&lt;p&gt;Make sure that you are using the same Go version, and remember to set the git commit id (7 bytes):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -gcflags="all=-l=4" -ldflags="-X github.com/xtls/xray-core/core.build=REPLACE -s -w -buildid=" -v ./main
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are compiling a 32-bit MIPS/MIPSLE target, use this command instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -gcflags="-l=4" -ldflags="-X github.com/xtls/xray-core/core.build=REPLACE -s -w -buildid=" -v ./main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/XTLS/Xray-core"&gt;&lt;img src="https://starchart.cc/XTLS/Xray-core.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>influxdata/telegraf</title>
      <link>https://github.com/influxdata/telegraf</link>
      <description>&lt;p&gt;Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/influxdata/telegraf/master/assets/TelegrafTigerSmall.png" alt="tiger" title="tiger" /&gt; Telegraf&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://godoc.org/github.com/influxdata/telegraf"&gt;&lt;img src="https://img.shields.io/badge/doc-reference-00ADD8.svg?logo=go" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/_/telegraf/"&gt;&lt;img src="https://img.shields.io/docker/pulls/library/telegraf.svg?sanitize=true" alt="Docker pulls" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/influxdata/telegraf"&gt;&lt;img src="https://goreportcard.com/badge/github.com/influxdata/telegraf" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://circleci.com/gh/influxdata/telegraf"&gt;&lt;img src="https://circleci.com/gh/influxdata/telegraf.svg?style=svg" alt="Circle CI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Telegraf is an agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Offers a comprehensive suite of over 300 plugins, covering a wide range of functionalities including system monitoring, cloud services, and message passing&lt;/li&gt; 
 &lt;li&gt;Enables the integration of user-defined code to collect, transform, and transmit data efficiently&lt;/li&gt; 
 &lt;li&gt;Compiles into a standalone static binary without any external dependencies, ensuring a streamlined deployment process&lt;/li&gt; 
 &lt;li&gt;Utilizes TOML for configuration, providing a user-friendly and unambiguous setup experience&lt;/li&gt; 
 &lt;li&gt;Developed with contributions from a diverse community of over 1,200 contributors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Users can choose plugins from a wide range of topics, including but not limited to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Devices: &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opcua"&gt;OPC UA&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/modbus"&gt;Modbus&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Logs: &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/file"&gt;File&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/tail"&gt;Tail&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/directory_monitor"&gt;Directory Monitor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Messaging: &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/amqp_consumer"&gt;AMQP&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/kafka_consumer"&gt;Kafka&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mqtt_consumer"&gt;MQTT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Monitoring: &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opentelemetry"&gt;OpenTelemetry&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus"&gt;Prometheus&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Networking: &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cisco_telemetry_mdt"&gt;Cisco TelemetryMDT&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/gnmi"&gt;gNMI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;System monitoring: &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cpu"&gt;CPU&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mem"&gt;Memory&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/disk"&gt;Disk&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/net"&gt;Network&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/smartctl"&gt;SMART&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker"&gt;Docker&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nvidia_smi"&gt;Nvidia SMI&lt;/a&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;Universal: &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec"&gt;Exec&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http"&gt;HTTP&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http_listener_v2"&gt;HTTP Listener&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/snmp"&gt;SNMP&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/sql"&gt;SQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Windows: &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_eventlog"&gt;Event Log&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_wmi"&gt;Management Instrumentation&lt;/a&gt;, &lt;a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters"&gt;Performance Counters&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔨 Installation&lt;/h2&gt; 
&lt;p&gt;For binary builds, Docker images, RPM &amp;amp; DEB packages, and other builds of Telegraf, please see the &lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/docs/INSTALL_GUIDE.md"&gt;install guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/docs/RELEASES.md"&gt;releases documentation&lt;/a&gt; for details on versioning and when releases are made.&lt;/p&gt; 
&lt;h2&gt;💻 Usage&lt;/h2&gt; 
&lt;p&gt;Users define a TOML configuration with the plugins and settings they wish to use, then pass that configuration to Telegraf. The Telegraf agent then collects data from inputs at each interval and sends data to outputs at each flush interval.&lt;/p&gt; 
&lt;p&gt;For a basic walkthrough see &lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/docs/QUICK_START.md"&gt;quick start&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📖 Documentation&lt;/h2&gt; 
&lt;p&gt;For a full list of documentation including tutorials, reference and other material, start with the &lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/docs/README.md"&gt;/docs directory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, each plugin has its own README that includes details about how to configure, use, and sometimes debug or troubleshoot. Look under the &lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/plugins/"&gt;/plugins directory&lt;/a&gt; for specific plugins.&lt;/p&gt; 
&lt;p&gt;Here are some commonly used documents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/CHANGELOG.md"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/docs/CONFIGURATION.md"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/docs/FAQ.md"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/influxdata/telegraf/releases"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/SECURITY.md"&gt;Security&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;❤️ Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/influxdata/telegraf/raw/master/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/contribute-to_telegraf-blue.svg?logo=influxdb" alt="Contribute" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We love our community of over 1,200 contributors! Many of the plugins included in Telegraf were originally contributed by community members. Check out our &lt;a href="https://raw.githubusercontent.com/influxdata/telegraf/master/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; if you are interested in helping out. Also, join us on our &lt;a href="https://influxdata.com/slack"&gt;Community Slack&lt;/a&gt; or &lt;a href="https://community.influxdata.com/"&gt;Community Forums&lt;/a&gt; if you have questions or comments for our engineering teams.&lt;/p&gt; 
&lt;p&gt;If you are completely new to Telegraf and InfluxDB, you can also enroll for free at &lt;a href="https://www.influxdata.com/university/"&gt;InfluxDB university&lt;/a&gt; to take courses to learn more.&lt;/p&gt; 
&lt;h2&gt;ℹ️ Support&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.influxdata.com/slack"&gt;&lt;img src="https://img.shields.io/badge/slack-join_chat-blue.svg?logo=slack" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://community.influxdata.com/"&gt;&lt;img src="https://img.shields.io/badge/discourse-join_forums-blue.svg?logo=discourse" alt="Forums" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please use the &lt;a href="https://influxdata.com/slack"&gt;Community Slack&lt;/a&gt; or &lt;a href="https://community.influxdata.com/"&gt;Community Forums&lt;/a&gt; if you have questions or comments for our engineering teams. GitHub issues are limited to actual issues and feature requests only.&lt;/p&gt; 
&lt;h2&gt;📜 License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/influxdata/telegraf/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue" alt="MIT" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sjzar/chatlog</title>
      <link>https://github.com/sjzar/chatlog</link>
      <description>&lt;p&gt;chat log tool, easily use your own chat data. 聊天记录工具，轻松使用自己的聊天数据&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e085d3a2-e009-4463-b2fd-8bd7df2b50c3" alt="chatlog" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;聊天记录工具，帮助大家轻松使用自己的聊天数据&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://imgmcp.com"&gt;&lt;img src="https://cdn.imgmcp.com/imgmcp-logo-small.png" alt="ImgMCP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/sjzar/chatlog"&gt;&lt;img src="https://goreportcard.com/badge/github.com/sjzar/chatlog" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/sjzar/chatlog"&gt;&lt;img src="https://godoc.org/github.com/sjzar/chatlog?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sjzar/chatlog/releases"&gt;&lt;img src="https://img.shields.io/github/release/sjzar/chatlog.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sjzar/chatlog/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/sjzar/chatlog.svg?sanitize=true" alt="GitHub license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Feature&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;从本地数据库文件中获取聊天数据&lt;/li&gt; 
 &lt;li&gt;支持 Windows / macOS 系统，兼容微信 3.x / 4.x 版本&lt;/li&gt; 
 &lt;li&gt;支持获取数据与图片密钥 (Windows &amp;lt; 4.0.3.36 / macOS &amp;lt; 4.0.3.80)&lt;/li&gt; 
 &lt;li&gt;支持图片、语音等多媒体数据解密，支持 wxgf 格式解析&lt;/li&gt; 
 &lt;li&gt;支持自动解密数据库，并提供新消息 Webhook 回调&lt;/li&gt; 
 &lt;li&gt;提供 Terminal UI 界面，同时支持命令行工具和 Docker 镜像部署&lt;/li&gt; 
 &lt;li&gt;提供 HTTP API 服务，可轻松查询聊天记录、联系人、群聊、最近会话等信息&lt;/li&gt; 
 &lt;li&gt;支持 MCP Streamable HTTP 协议，可与 AI 助手无缝集成&lt;/li&gt; 
 &lt;li&gt;支持多账号管理，可在不同账号间切换&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;基本步骤&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;安装 Chatlog&lt;/strong&gt;：&lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/#%E4%B8%8B%E8%BD%BD%E9%A2%84%E7%BC%96%E8%AF%91%E7%89%88%E6%9C%AC"&gt;下载预编译版本&lt;/a&gt; 或 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/#%E4%BB%8E%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85"&gt;使用 Go 安装&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;运行程序&lt;/strong&gt;：执行 &lt;code&gt;chatlog&lt;/code&gt; 启动 Terminal UI 界面&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;解密数据&lt;/strong&gt;：选择 &lt;code&gt;解密数据&lt;/code&gt; 菜单项&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;开启 HTTP 服务&lt;/strong&gt;：选择 &lt;code&gt;开启 HTTP 服务&lt;/code&gt; 菜单项&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;访问数据&lt;/strong&gt;：通过 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/#http-api"&gt;HTTP API&lt;/a&gt; 或 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/#mcp-%E9%9B%86%E6%88%90"&gt;MCP 集成&lt;/a&gt; 访问聊天记录&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💡 &lt;strong&gt;提示&lt;/strong&gt;: 如果电脑端微信聊天记录不全，可以&lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/#%E4%BB%8E%E6%89%8B%E6%9C%BA%E8%BF%81%E7%A7%BB%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95"&gt;从手机端迁移数据&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;常见问题快速解决&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS 用户&lt;/strong&gt;：获取密钥前需&lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/#macos-%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E"&gt;临时关闭 SIP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows 用户&lt;/strong&gt;：遇到界面显示问题请&lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/#windows-%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E"&gt;使用 Windows Terminal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;集成 AI 助手&lt;/strong&gt;：查看 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/#mcp-%E9%9B%86%E6%88%90"&gt;MCP 集成指南&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;无法获取密钥&lt;/strong&gt;：查看 &lt;a href="https://github.com/sjzar/chatlog/issues/197"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;安装指南&lt;/h2&gt; 
&lt;h3&gt;从源码安装&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/sjzar/chatlog@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💡 &lt;strong&gt;提示&lt;/strong&gt;: 部分功能有 cgo 依赖，编译前需确认本地有 C 编译环境。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;下载预编译版本&lt;/h3&gt; 
&lt;p&gt;访问 &lt;a href="https://github.com/sjzar/chatlog/releases"&gt;Releases&lt;/a&gt; 页面下载适合您系统的预编译版本。&lt;/p&gt; 
&lt;h2&gt;使用指南&lt;/h2&gt; 
&lt;h3&gt;Terminal UI 模式&lt;/h3&gt; 
&lt;p&gt;最简单的使用方式是通过 Terminal UI 界面操作：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;chatlog
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;操作方法：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用 &lt;code&gt;↑&lt;/code&gt; &lt;code&gt;↓&lt;/code&gt; 键选择菜单项&lt;/li&gt; 
 &lt;li&gt;按 &lt;code&gt;Enter&lt;/code&gt; 确认选择&lt;/li&gt; 
 &lt;li&gt;按 &lt;code&gt;Esc&lt;/code&gt; 返回上级菜单&lt;/li&gt; 
 &lt;li&gt;按 &lt;code&gt;Ctrl+C&lt;/code&gt; 退出程序&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;命令行模式&lt;/h3&gt; 
&lt;p&gt;对于熟悉命令行的用户，可以直接使用以下命令：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 获取微信数据密钥
chatlog key

# 解密数据库文件
chatlog decrypt

# 启动 HTTP 服务
chatlog server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker 部署&lt;/h3&gt; 
&lt;p&gt;由于 Docker 部署时，程序运行环境与宿主机隔离，所以不支持获取密钥等操作，需要提前获取密钥数据。&lt;/p&gt; 
&lt;p&gt;一般用于 NAS 等设备部署，详细指南可参考 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/docs/docker.md"&gt;Docker 部署指南&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;0. 获取密钥信息&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 从本机运行 chatlog 获取密钥信息
$ chatlog key
Data Key: [c0163e***ac3dc6]
Image Key: [38636***653361]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;1. 拉取镜像&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;chatlog 提供了两个镜像源：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docker Hub&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker pull sjzar/chatlog:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;GitHub Container Registry (ghcr)&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker pull ghcr.io/sjzar/chatlog:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💡 &lt;strong&gt;镜像地址&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Docker Hub: &lt;a href="https://hub.docker.com/r/sjzar/chatlog"&gt;https://hub.docker.com/r/sjzar/chatlog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;GitHub Container Registry: &lt;a href="https://ghcr.io/sjzar/chatlog"&gt;https://ghcr.io/sjzar/chatlog&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;2. 运行容器&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ docker run -d \
  --name chatlog \
  -p 5030:5030 \
  -v /path/to/your/wechat/data:/app/data \
  sjzar/chatlog:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;从手机迁移聊天记录&lt;/h3&gt; 
&lt;p&gt;如果电脑端微信聊天记录不全，可以从手机端迁移数据：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;打开手机微信，进入 &lt;code&gt;我 - 设置 - 通用 - 聊天记录迁移与备份&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;选择 &lt;code&gt;迁移 - 迁移到电脑&lt;/code&gt;，按照提示操作&lt;/li&gt; 
 &lt;li&gt;完成迁移后，重新运行 &lt;code&gt;chatlog&lt;/code&gt; 获取密钥并解密数据&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;此操作不会影响手机上的聊天记录，只是将数据复制到电脑端&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;平台特定说明&lt;/h2&gt; 
&lt;h3&gt;Windows 版本说明&lt;/h3&gt; 
&lt;p&gt;如遇到界面显示异常（如花屏、乱码等），请使用 &lt;a href="https://github.com/microsoft/terminal"&gt;Windows Terminal&lt;/a&gt; 运行程序&lt;/p&gt; 
&lt;h3&gt;macOS 版本说明&lt;/h3&gt; 
&lt;p&gt;macOS 用户在获取密钥前需要临时关闭 SIP（系统完整性保护）：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;关闭 SIP&lt;/strong&gt;：&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;# 进入恢复模式
# Intel Mac: 重启时按住 Command + R
# Apple Silicon: 重启时长按电源键

# 在恢复模式中打开终端并执行
csrutil disable

# 重启系统
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;安装必要工具&lt;/strong&gt;：&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;# 安装 Xcode Command Line Tools
xcode-select --install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;获取密钥后&lt;/strong&gt;：可以重新启用 SIP（&lt;code&gt;csrutil enable&lt;/code&gt;），不影响后续使用&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Apple Silicon 用户注意：确保微信、chatlog 和终端都不在 Rosetta 模式下运行&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;HTTP API&lt;/h2&gt; 
&lt;p&gt;启动 HTTP 服务后（默认地址 &lt;code&gt;http://127.0.0.1:5030&lt;/code&gt;），可通过以下 API 访问数据：&lt;/p&gt; 
&lt;h3&gt;聊天记录查询&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;GET /api/v1/chatlog?time=2023-01-01&amp;amp;talker=wxid_xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;参数说明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;time&lt;/code&gt;: 时间范围，格式为 &lt;code&gt;YYYY-MM-DD&lt;/code&gt; 或 &lt;code&gt;YYYY-MM-DD~YYYY-MM-DD&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;talker&lt;/code&gt;: 聊天对象标识（支持 wxid、群聊 ID、备注名、昵称等）&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;limit&lt;/code&gt;: 返回记录数量&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;offset&lt;/code&gt;: 分页偏移量&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt;: 输出格式，支持 &lt;code&gt;json&lt;/code&gt;、&lt;code&gt;csv&lt;/code&gt; 或纯文本&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;其他 API 接口&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;联系人列表&lt;/strong&gt;：&lt;code&gt;GET /api/v1/contact&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;群聊列表&lt;/strong&gt;：&lt;code&gt;GET /api/v1/chatroom&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;会话列表&lt;/strong&gt;：&lt;code&gt;GET /api/v1/session&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;多媒体内容&lt;/h3&gt; 
&lt;p&gt;聊天记录中的多媒体内容会通过 HTTP 服务进行提供，可通过以下路径访问：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;图片内容&lt;/strong&gt;：&lt;code&gt;GET /image/&amp;lt;id&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;视频内容&lt;/strong&gt;：&lt;code&gt;GET /video/&amp;lt;id&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;文件内容&lt;/strong&gt;：&lt;code&gt;GET /file/&amp;lt;id&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;语音内容&lt;/strong&gt;：&lt;code&gt;GET /voice/&amp;lt;id&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多媒体内容&lt;/strong&gt;：&lt;code&gt;GET /data/&amp;lt;data dir relative path&amp;gt;&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当请求图片、视频、文件内容时，将返回 302 跳转到多媒体内容 URL。&lt;br /&gt; 当请求语音内容时，将直接返回语音内容，并对原始 SILK 语音做了实时转码 MP3 处理。&lt;br /&gt; 多媒体内容 URL 地址为基于&lt;code&gt;数据目录&lt;/code&gt;的相对地址，请求多媒体内容将直接返回对应文件，并针对加密图片做了实时解密处理。&lt;/p&gt; 
&lt;h2&gt;Webhook&lt;/h2&gt; 
&lt;p&gt;需开启自动解密功能，当收到特定新消息时，可以通过 HTTP POST 请求将消息推送到指定的 URL。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;延迟测试: 本地服务消息回调延迟约 13 秒; 远程同步消息回调延迟约 45 秒。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;0. 回调配置&lt;/h4&gt; 
&lt;p&gt;使用 TUI 模式的话，在 &lt;code&gt;$HOME/.chatlog/chatlog.json&lt;/code&gt; 配置文件中，新增 &lt;code&gt;webhook&lt;/code&gt; 配置。&lt;br /&gt; （Windows 用户的配置文件在 &lt;code&gt;%USERPROFILE%/.chatlog/chatlog.json&lt;/code&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "history": [],
  "last_account": "wxuser_x",
  "webhook": {
    "host": "localhost:5030",                   # 消息中的图片、文件等 URL host
    "items": [
      {
        "url": "http://localhost:8080/webhook", # 必填，webhook 请求的URL，可配置为 n8n 等 webhook 入口 
        "talker": "wxid_123",                   # 必填，需要监控的私聊、群聊名称
        "sender": "",                           # 选填，消息发送者
        "keyword": ""                           # 选填，关键词
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;使用 server 模式的话，可以通过 &lt;code&gt;CHATLOG_WEBHOOK&lt;/code&gt; 环境变量进行设置。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 方案 1
CHATLOG_WEBHOOK='{"host":"localhost:5030","items":[{"url":"http://localhost:8080/proxy","talker":"wxid_123","sender":"","keyword":""}]}'

# 方案 2（任选一种）
CHATLOG_WEBHOOK_HOST="localhost:5030"
CHATLOG_WEBHOOK_ITEMS='[{"url":"http://localhost:8080/proxy","talker":"wxid_123","sender":"","keyword":""}]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;1. 测试效果&lt;/h4&gt; 
&lt;p&gt;启动 chatlog 并开启自动解密功能，测试回调效果&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;POST /webhook HTTP/1.1
Host: localhost:8080
Accept-Encoding: gzip
Content-Length: 386
Content-Type: application/json
User-Agent: Go-http-client/1.1

Body:
{
  "keyword": "",
  "lastTime": "2025-08-27 00:00:00",
  "length": 1,
  "messages": [
    {
      "seq": 1756225000000,
      "time": "2025-08-27T00:00:00+08:00",
      "talker": "wxid_123",
      "talkerName": "",
      "isChatRoom": false,
      "sender": "wxid_123",
      "senderName": "Name",
      "isSelf": false,
      "type": 1,
      "subType": 0,
      "content": "测试消息",
      "contents": {
        "host": "localhost:5030"
      }
    }
  ],
  "sender": "",
  "talker": "wxid_123"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;MCP 集成&lt;/h2&gt; 
&lt;p&gt;Chatlog 支持 MCP (Model Context Protocol) 协议，可与支持 MCP 的 AI 助手无缝集成。&lt;br /&gt; 启动 HTTP 服务后，通过 Streamable HTTP Endpoint 访问服务：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;快速集成&lt;/h3&gt; 
&lt;p&gt;Chatlog 可以与多种支持 MCP 的 AI 助手集成，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ChatWise&lt;/strong&gt;: 直接支持 Streamable HTTP，在工具设置中添加 &lt;code&gt;http://127.0.0.1:5030/mcp&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cherry Studio&lt;/strong&gt;: 直接支持 Streamable HTTP，在 MCP 服务器设置中添加 &lt;code&gt;http://127.0.0.1:5030/mcp&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;对于不直接支持 Streamable HTTP 的客户端，可以使用 &lt;a href="https://github.com/sparfenyuk/mcp-proxy"&gt;mcp-proxy&lt;/a&gt; 工具转发请求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Desktop&lt;/strong&gt;: 通过 mcp-proxy 支持，需要配置 &lt;code&gt;claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monica Code&lt;/strong&gt;: 通过 mcp-proxy 支持，需要配置 VSCode 插件设置&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;详细集成指南&lt;/h3&gt; 
&lt;p&gt;查看 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/docs/mcp.md"&gt;MCP 集成指南&lt;/a&gt; 获取各平台的详细配置步骤和注意事项。&lt;/p&gt; 
&lt;h2&gt;Prompt 示例&lt;/h2&gt; 
&lt;p&gt;为了帮助大家更好地利用 Chatlog 与 AI 助手，我们整理了一些 prompt 示例。希望这些 prompt 可以启发大家更有效地查询和分析聊天记录，获取更精准的信息。&lt;/p&gt; 
&lt;p&gt;查看 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/docs/prompt.md"&gt;Prompt 指南&lt;/a&gt; 获取详细示例。&lt;/p&gt; 
&lt;p&gt;同时欢迎大家分享使用经验和 prompt！如果您有好的 prompt 示例或使用技巧，请通过 &lt;a href="https://github.com/sjzar/chatlog/discussions"&gt;Discussions&lt;/a&gt; 进行分享，共同进步。&lt;/p&gt; 
&lt;h2&gt;免责声明&lt;/h2&gt; 
&lt;p&gt;⚠️ &lt;strong&gt;重要提示：使用本项目前，请务必阅读并理解完整的 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/DISCLAIMER.md"&gt;免责声明&lt;/a&gt;。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;本项目仅供学习、研究和个人合法使用，禁止用于任何非法目的或未授权访问他人数据。下载、安装或使用本工具即表示您同意遵守免责声明中的所有条款，并自行承担使用过程中的全部风险和法律责任。&lt;/p&gt; 
&lt;h3&gt;摘要（请阅读完整免责声明）&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;仅限处理您自己合法拥有的聊天数据或已获授权的数据&lt;/li&gt; 
 &lt;li&gt;严禁用于未经授权获取、查看或分析他人聊天记录&lt;/li&gt; 
 &lt;li&gt;开发者不对使用本工具可能导致的任何损失承担责任&lt;/li&gt; 
 &lt;li&gt;使用第三方 LLM 服务时，您应遵守这些服务的使用条款和隐私政策&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;本项目完全免费开源，任何以本项目名义收费的行为均与本项目无关。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;本项目基于 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/LICENSE"&gt;Apache-2.0 许可证&lt;/a&gt; 开源。&lt;/p&gt; 
&lt;h2&gt;隐私政策&lt;/h2&gt; 
&lt;p&gt;本项目不收集任何用户数据。所有数据处理均在用户本地设备上进行。使用第三方服务时，请参阅相应服务的隐私政策。&lt;/p&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/0xlane"&gt;@0xlane&lt;/a&gt; 的 &lt;a href="https://github.com/0xlane/wechat-dump-rs"&gt;wechat-dump-rs&lt;/a&gt; 项目&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xaoyaoo"&gt;@xaoyaoo&lt;/a&gt; 的 &lt;a href="https://github.com/xaoyaoo/PyWxDump"&gt;PyWxDump&lt;/a&gt; 项目&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/git-jiadong"&gt;@git-jiadong&lt;/a&gt; 的 &lt;a href="https://github.com/git-jiadong/go-lame"&gt;go-lame&lt;/a&gt; 和 &lt;a href="https://github.com/git-jiadong/go-silk"&gt;go-silk&lt;/a&gt; 项目&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt; 的 &lt;a href="https://raw.githubusercontent.com/sjzar/chatlog/main/(https://github.com/modelcontextprotocol)"&gt;MCP&lt;/a&gt; 协议&lt;/li&gt; 
 &lt;li&gt;各个 Go 开源库的贡献者们&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>NexaAI/nexa-sdk</title>
      <link>https://github.com/NexaAI/nexa-sdk</link>
      <description>&lt;p&gt;Run the latest LLMs and VLMs across GPU, NPU, and CPU with PC (Python/C++) &amp; mobile (Android &amp; iOS) support, running quickly with OpenAI gpt-oss, Granite4, Qwen3VL, Gemma 3n and more.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/assets/banner.png" alt="Nexa AI Banner" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://docs.nexa.ai"&gt; &lt;img src="https://img.shields.io/badge/docs-website-brightgreen?logo=readthedocs" alt="Documentation" /&gt; &lt;/a&gt; &lt;a href="https://x.com/nexa_ai"&gt;&lt;img alt="X account" src="https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&amp;amp;label=Follow%20%40Nexa_AI" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/nexa-ai"&gt; &lt;img src="https://img.shields.io/discord/1192186167391682711?color=5865F2&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Join us on Discord" /&gt; &lt;/a&gt; &lt;a href="https://join.slack.com/t/nexa-ai-community/shared_invite/zt-3837k9xpe-LEty0disTTUnTUQ4O3uuNw"&gt; &lt;img src="https://img.shields.io/badge/slack-join%20chat-4A154B?logo=slack&amp;amp;logoColor=white" alt="Join us on Slack" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/os-linux%20%7C%20macOS%20%7C%20windows-purple" alt="OS" /&gt; &lt;img src="https://img.shields.io/badge/hardware-CPU%20%7C%20GPU%20%7C%20NPU-yellow" alt="Hardware" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;Nexa SDK&lt;/h1&gt; 
&lt;p&gt;Nexa SDK is an on-device inference framework that runs any model on any device, across any backend. It runs on CPUs, GPUs, NPUs with backend support for CUDA, Metal, Vulkan, and Qualcomm / Intel / AMD NPU. It handles multiple input modalities including text 📝, image 🖼️, and audio 🎧. The SDK includes an OpenAI-compatible API server with support for JSON schema-based function calling and streaming. It supports model formats such as GGUF, MLX, Nexa AI's own &lt;code&gt;.nexa&lt;/code&gt; format, enabling efficient quantized inference across diverse platforms.&lt;/p&gt; 
&lt;h2&gt;Qualcomm NPU PC Demos&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/assets/PC_demo_2_image.gif" alt="Multi-Image Reasoning Demo" /&gt; &lt;p align="center"&gt;&lt;b&gt;🖼️ Multi-Image Reasoning&lt;/b&gt;&lt;br /&gt;Spot the difference across two images in multi-round dialogue.&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/assets/PC_Demo_Agent.gif" alt="Image + Audio Function Call Demo" /&gt; &lt;p align="center"&gt;&lt;b&gt;🎤 Image + Text → Function Call&lt;/b&gt;&lt;br /&gt;Snap a poster, add a voice note, and AI agent creates a calendar event.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2" align="center"&gt; &lt;img width="50%" src="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/assets/PC_Demo_Audio.gif" alt="Multi-Audio Comparison Demo" /&gt; &lt;p align="center"&gt;&lt;b&gt;🎶 Multi-Audio Comparison&lt;/b&gt;&lt;br /&gt;Tell the difference between two music clips locally.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Recent updates&lt;/h2&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.10.14: Day-0 Support : Qwen3-VL-4B-Instruct, Qwen3-VL-4B-Thinking, Qwen3-VL-8B-Instruct, Qwen3-VL-8B-Thinking&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;We support &lt;a href="https://huggingface.co/collections/NexaAI/qwen3vl-68d46de18fdc753a7295190a"&gt;Qwen3-VL-4B series models&lt;/a&gt; with Nexa SDK on Day-0!&lt;/li&gt; 
 &lt;li&gt;We support Qualcomm NPU/GPU/CPU, Apple GPU/CPU, Intel/AMD/MediaTek/Nvidia GPU/CPUs and more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.10.04: Day-0 Support : Qwen3-VL-30B-A3B-Instruct&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;We support &lt;a href="https://huggingface.co/NexaAI/qwen3vl-30B-A3B-mlx"&gt;Qwen3-VL-30B-A3B-Instruct&lt;/a&gt; with Nexa SDK on Day-0!&lt;/li&gt; 
 &lt;li&gt;Try it on Apple GPU with &lt;code&gt;nexa infer NexaAI/qwen3vl-30B-A3B-mlx&lt;/code&gt; on MLX backend.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.10.02: Day-0 Support on NPU/GPU/CPU : IBM Granite 4.0&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;We support &lt;a href="https://sdk.nexa.ai/model/Granite-4-Micro"&gt;IBM Granite 4.0&lt;/a&gt; with Nexa SDK on Day-0!&lt;/li&gt; 
 &lt;li&gt;Try it on AMD / Intel / Qualcomm / Apple GPU with &lt;code&gt;nexa infer NexaAI/granite-4.0-micro-GGUF&lt;/code&gt; and on Qualcomm NPU with &lt;code&gt;nexa infer NexaAI/Granite-4-Micro-NPU&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.10.01: AMD NPU Support&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Image Generation with &lt;a href="https://huggingface.co/NexaAI/sdxl-turbo-amd-npu"&gt;SDXL&lt;/a&gt; on AMD NPU&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.09.23: Intel NPU Support&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLM inference with &lt;a href="https://sdk.nexa.ai/model/DeepSeek-R1-Distill-Qwen-1.5B-Intel-NPU"&gt;DeepSeek-r1-distill-Qwen-1.5B&lt;/a&gt; and &lt;a href="https://sdk.nexa.ai/model/Llama3.2-3B-Intel-NPU"&gt;Llama3.2-3B&lt;/a&gt; on Intel NPU&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.09.22: Apple Neural Engine (ANE) Support&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Real-time speech recognition with &lt;a href="https://sdk.nexa.ai/model/parakeet-v3-ane"&gt;Parakeet v3 model&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.09.15: New Models Support&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;First-ever &lt;a href="https://sdk.nexa.ai/model/Gemma3n-E4B"&gt;Gemma-3n&lt;/a&gt; &lt;strong&gt;multimodal&lt;/strong&gt; inference for GPU &amp;amp; CPU, in GGUF format.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sdk.nexa.ai/model/Prefect-illustrious-XL-v2.0p"&gt;SDXL image generation&lt;/a&gt; from Civitai for GPU&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sdk.nexa.ai/model/embeddinggemma-300m-npu"&gt;EmbeddingGemma&lt;/a&gt; for Qualcomm NPU&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sdk.nexa.ai/model/phi4-mini-npu-turbo"&gt;Phi4-mini turbo&lt;/a&gt; and &lt;a href="https://sdk.nexa.ai/model/phi3.5-mini-npu"&gt;Phi3.5-mini&lt;/a&gt; for Qualcomm NPU&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sdk.nexa.ai/model/parakeet-v3-npu"&gt;Parakeet V3 model&lt;/a&gt; for Qualcomm NPU&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.09.05: Turbo Engine &amp;amp; Unified Interface&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://nexa.ai/blogs/nexaml-turbo"&gt;Nexa ML Turbo engine&lt;/a&gt; for optimized NPU performance 
  &lt;ul&gt; 
   &lt;li&gt;Try &lt;a href="https://sdk.nexa.ai/model/phi4-mini-npu-turbo"&gt;Phi4-mini turbo&lt;/a&gt; and &lt;a href="https://sdk.nexa.ai/model/Llama3.2-3B-NPU-Turbo"&gt;Llama3.2-3B-NPU-Turbo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;80% faster at shorter contexts (&amp;lt;=2048), 33% faster at longer contexts (&amp;gt;2048) than current NPU solutions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nexa.ai/blogs/sdk-unifiedarchitecture"&gt;Unified interface&lt;/a&gt; supporting NPU/GPU/CPU backends: 
  &lt;ul&gt; 
   &lt;li&gt;Single installer architecture eliminating dependency conflicts&lt;/li&gt; 
   &lt;li&gt;Lazy loading and plugin isolation for improved performance&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.08.20: Qualcomm NPU Support with NexaML Turbo Engine&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;OmniNeural-4B: the &lt;strong&gt;first multimodal AI model built natively for NPUs&lt;/strong&gt; — handling text, images, and audio in one model&lt;/li&gt; 
 &lt;li&gt;Check the model and demos at &lt;a href="https://huggingface.co/NexaAI/OmniNeural-4B"&gt;Hugging Face repo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check our &lt;a href="https://nexa.ai/blogs/omnineural-4b"&gt;OmniNeural-4B technical blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📣 &lt;strong&gt;2025.08.12: ASR &amp;amp; TTS Support in MLX format&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Parakeet and Kokoro models support in MLX format.&lt;/li&gt; 
 &lt;li&gt;new &lt;code&gt;/mic&lt;/code&gt; mode to transcribe live speech directly in your terminal.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_macos_arm64.pkg"&gt;arm64 with Apple Neural Engine support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_macos_x86_64.pkg"&gt;x86_64&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_arm64.exe"&gt;arm64 with Qualcomm NPU support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_x86_64.exe"&gt;x86_64 with Intel / AMD NPU support&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://github.com/NexaAI/nexa-sdk/releases/latest/download/nexa-cli_linux_x86_64.sh -o install.sh &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh &amp;amp;&amp;amp; rm install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;You can run any compatible GGUF, MLX, or nexa model from 🤗 Hugging Face by using the &lt;code&gt;&amp;lt;full repo name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Qualcomm NPU models&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] You need to download the &lt;a href="https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_arm64.exe"&gt;arm64 with Qualcomm NPU support&lt;/a&gt; and make sure you have Snapdragon® X Elite chip on your laptop.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Quick Start (Windows arm64, Snapdragon X Elite)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Login &amp;amp; Get Access Token (required for Pro Models)&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Create an account at &lt;a href="https://sdk.nexa.ai"&gt;sdk.nexa.ai&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Go to &lt;strong&gt;Deployment → Create Token&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Run this once in your terminal (replace with your token): &lt;pre&gt;&lt;code class="language-bash"&gt;nexa config set license '&amp;lt;your_token_here&amp;gt;'
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run and chat with our multimodal model, OmniNeural-4B, or other models on NPU&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nexa infer omni-neural
nexa infer NexaAI/OmniNeural-4B
nexa infer NexaAI/qwen3-1.7B-npu
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;GGUF models&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] GGUF runs on macOS, Linux, and Windows.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;📝 Run and chat with LLMs, e.g. Qwen3:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nexa infer ggml-org/Qwen3-1.7B-GGUF
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;🖼️ Run and chat with Multimodal models, e.g. Qwen2.5-Omni:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nexa infer NexaAI/Qwen2.5-Omni-3B-GGUF
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MLX models&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] MLX is macOS-only (Apple Silicon). Many MLX models in the Hugging Face mlx-community organization have quality issues and may not run reliably. We recommend starting with models from our curated &lt;a href="https://huggingface.co/NexaAI/collections"&gt;NexaAI Collection&lt;/a&gt; for best results. For example&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;📝 Run and chat with LLMs, e.g. Qwen3:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nexa infer NexaAI/Qwen3-4B-4bit-MLX
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;🖼️ Run and chat with Multimodal models, e.g. Gemma3n:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nexa infer NexaAI/gemma-3n-E4B-it-4bit-MLX
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;CLI Reference&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Essential Command&lt;/th&gt; 
   &lt;th&gt;What it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nexa -h&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;show all CLI commands&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nexa pull &amp;lt;repo&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Interactive download &amp;amp; cache of a model&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nexa infer &amp;lt;repo&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Local inference&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nexa list&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show all cached models with sizes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nexa remove &amp;lt;repo&amp;gt;&lt;/code&gt; / &lt;code&gt;nexa clean&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Delete one / all cached models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nexa serve --host 127.0.0.1:8080&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Launch OpenAI‑compatible REST server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nexa run &amp;lt;repo&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Chat with a model via an existing server&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;👉 To interact with multimodal models, you can drag photos or audio clips directly into the CLI — you can even drop multiple images at once!&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://nexaai.mintlify.app/nexa-sdk-go/NexaCLI"&gt;CLI Reference&lt;/a&gt; for full commands.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We would like to thank the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ml-explore/mlx-lm"&gt;mlx-lm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Blaizzy/mlx-vlm"&gt;mlx-vlm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Blaizzy/mlx-audio"&gt;mlx-audio&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>spf13/cobra</title>
      <link>https://github.com/spf13/cobra</link>
      <description>&lt;p&gt;A Commander for modern Go CLI interactions&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://cobra.dev"&gt; &lt;img width="512" height="535" alt="cobra-logo" src="https://github.com/user-attachments/assets/c8bf9aad-b5ae-41d3-8899-d83baec10af8" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Cobra is a library for creating powerful modern CLI applications.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cobra.dev"&gt;Visit Cobra.dev for extensive documentation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Cobra is used in many Go projects such as &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt;, &lt;a href="https://gohugo.io"&gt;Hugo&lt;/a&gt;, and &lt;a href="https://github.com/cli/cli"&gt;GitHub CLI&lt;/a&gt; to name a few. &lt;a href="https://raw.githubusercontent.com/spf13/cobra/main/site/content/projects_using_cobra.md"&gt;This list&lt;/a&gt; contains a more extensive list of projects using Cobra.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/spf13/cobra/actions?query=workflow%3ATest"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/spf13/cobra/test.yml?branch=main&amp;amp;longCache=true&amp;amp;label=Test&amp;amp;logo=github%20actions&amp;amp;logoColor=fff" alt="" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/spf13/cobra"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/spf13/cobra.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/spf13/cobra"&gt;&lt;img src="https://goreportcard.com/badge/github.com/spf13/cobra" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://gophers.slack.com/archives/CD3LP1199"&gt;&lt;img src="https://img.shields.io/badge/Slack-cobra-brightgreen" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;sup&gt;Supported by:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.warp.dev/cobra"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;a href="https://www.warp.dev/cobra"&gt;Warp, the AI terminal for devs&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://www.warp.dev/cobra"&gt;Try Cobra in Warp today&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;Cobra is a library providing a simple interface to create powerful modern CLI interfaces similar to git &amp;amp; go tools.&lt;/p&gt; 
&lt;p&gt;Cobra provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easy subcommand-based CLIs: &lt;code&gt;app server&lt;/code&gt;, &lt;code&gt;app fetch&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;Fully POSIX-compliant flags (including short &amp;amp; long versions)&lt;/li&gt; 
 &lt;li&gt;Nested subcommands&lt;/li&gt; 
 &lt;li&gt;Global, local and cascading flags&lt;/li&gt; 
 &lt;li&gt;Intelligent suggestions (&lt;code&gt;app srver&lt;/code&gt;... did you mean &lt;code&gt;app server&lt;/code&gt;?)&lt;/li&gt; 
 &lt;li&gt;Automatic help generation for commands and flags&lt;/li&gt; 
 &lt;li&gt;Grouping help for subcommands&lt;/li&gt; 
 &lt;li&gt;Automatic help flag recognition of &lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;Automatically generated shell autocomplete for your application (bash, zsh, fish, powershell)&lt;/li&gt; 
 &lt;li&gt;Automatically generated man pages for your application&lt;/li&gt; 
 &lt;li&gt;Command aliases so you can change things without breaking them&lt;/li&gt; 
 &lt;li&gt;The flexibility to define your own help, usage, etc.&lt;/li&gt; 
 &lt;li&gt;Optional seamless integration with &lt;a href="https://github.com/spf13/viper"&gt;viper&lt;/a&gt; for 12-factor apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Concepts&lt;/h1&gt; 
&lt;p&gt;Cobra is built on a structure of commands, arguments &amp;amp; flags.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Commands&lt;/strong&gt; represent actions, &lt;strong&gt;Args&lt;/strong&gt; are things and &lt;strong&gt;Flags&lt;/strong&gt; are modifiers for those actions.&lt;/p&gt; 
&lt;p&gt;The best applications read like sentences when used, and as a result, users intuitively know how to interact with them.&lt;/p&gt; 
&lt;p&gt;The pattern to follow is &lt;code&gt;APPNAME VERB NOUN --ADJECTIVE&lt;/code&gt; or &lt;code&gt;APPNAME COMMAND ARG --FLAG&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;A few good real world examples may better illustrate this point.&lt;/p&gt; 
&lt;p&gt;In the following example, 'server' is a command, and 'port' is a flag:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;hugo server --port=1313
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this command we are telling Git to clone the url bare.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone URL --bare
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Commands&lt;/h2&gt; 
&lt;p&gt;Command is the central point of the application. Each interaction that the application supports will be contained in a Command. A command can have children commands and optionally run an action.&lt;/p&gt; 
&lt;p&gt;In the example above, 'server' is the command.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/spf13/cobra#Command"&gt;More about cobra.Command&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Flags&lt;/h2&gt; 
&lt;p&gt;A flag is a way to modify the behavior of a command. Cobra supports fully POSIX-compliant flags as well as the Go &lt;a href="https://golang.org/pkg/flag/"&gt;flag package&lt;/a&gt;. A Cobra command can define flags that persist through to children commands and flags that are only available to that command.&lt;/p&gt; 
&lt;p&gt;In the example above, 'port' is the flag.&lt;/p&gt; 
&lt;p&gt;Flag functionality is provided by the &lt;a href="https://github.com/spf13/pflag"&gt;pflag library&lt;/a&gt;, a fork of the flag standard library which maintains the same interface while adding POSIX compliance.&lt;/p&gt; 
&lt;h1&gt;Installing&lt;/h1&gt; 
&lt;p&gt;Using Cobra is easy. First, use &lt;code&gt;go get&lt;/code&gt; to install the latest version of the library.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go get -u github.com/spf13/cobra@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, include Cobra in your application:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "github.com/spf13/cobra"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Usage&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;cobra-cli&lt;/code&gt; is a command line program to generate cobra applications and command files. It will bootstrap your application scaffolding to rapidly develop a Cobra-based application. It is the easiest way to incorporate Cobra into your application.&lt;/p&gt; 
&lt;p&gt;It can be installed by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install github.com/spf13/cobra-cli@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For complete details on using the Cobra-CLI generator, please read &lt;a href="https://github.com/spf13/cobra-cli/raw/main/README.md"&gt;The Cobra Generator README&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For complete details on using the Cobra library, please read &lt;a href="https://raw.githubusercontent.com/spf13/cobra/main/site/content/user_guide.md"&gt;The Cobra User Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Cobra is released under the Apache 2.0 license. See &lt;a href="https://raw.githubusercontent.com/spf13/cobra/main/LICENSE.txt"&gt;LICENSE.txt&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cloudnative-pg/cloudnative-pg</title>
      <link>https://github.com/cloudnative-pg/cloudnative-pg</link>
      <description>&lt;p&gt;CloudNativePG is a comprehensive platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://landscape.cncf.io/?item=app-definition-and-development--database--cloudnativepg"&gt;&lt;img src="https://img.shields.io/badge/CNCF%20Landscape-5699C6" alt="CNCF Landscape" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudnative-pg/cloudnative-pg/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/cloudnative-pg/cloudnative-pg.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudnative-pg/cloudnative-pg?tab=Apache-2.0-1-ov-file#readme"&gt;&lt;img src="https://img.shields.io/github/license/cloudnative-pg/cloudnative-pg" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/9933"&gt;&lt;img src="https://www.bestpractices.dev/projects/9933/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/cloudnative-pg/cloudnative-pg"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/cloudnative-pg/cloudnative-pg/badge" alt="OpenSSF Scorecard Badge" /&gt;&lt;/a&gt; &lt;a href="https://cloudnative-pg.io/documentation/current/"&gt;&lt;img src="https://img.shields.io/badge/Documentation-white?logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAGN0lEQVR4nJRXXWwcVxU%2B8%2F%2BzP%2BPZtR2v7dqy07jUJUALNaiK6lZyUVVKWgGKaIv8QCMekBAVQlQICcEzVZFQVYFKQhASEBHlISJPCRJEshTFChgrIYHEiYMh69jetffHM7Mzc%2B9Bs7vjnTs7yZpZWbt37s%2F5zne%2Bc861CD0eXRkbHc3NfjeffvxNAGEAgULD2756v35%2B3qe1Nc4fnQVEXlA2LnOcXlCF8S%2B6vvVgq%2FL3M65X3e51PvfQCU4WJgZe%2B8GQ8fS7AKgjBB8KEHwjDXZSjkf0CREAaXM2eI9c65siqWxWl360Xl74ANHz%2Fy8AitxnTBfmz%2BhyYS4wGhwObQCIHSA0AigOMBzvOsXzd4pnjyL6NMmWEH8hi2b28Og3%2FqRJA0ewfQy0v1vGO2NovwPo%2FEU%2FwVgSU1PI%2BSu79v3lJAB8HM%2BTI%2FO%2FUUXzM4xHIe0xI4DdRqOAwnF%2F38ePPyzaDIDh%2FMxcWh462m08aojuGY97C0nrAEHg9BlF0fmeAPr0J15vbaKsp0BZQzEDEAlP9B209UIIVXUta%2FQEQHwxgxFjTc%2BRskAwrgVWmHtg22vMPJwLDqGUNJIAMHVAkGu3WdpZz6NAkgSXpINSycluV28er1a3rJ4M3F2%2F9AtCvXKycRrTQttrjINjxxxIL9jevxdaDHU%2FTBr6pL5ruzuLZubgUQBOY2hPij3GBUe7tBCMBRE2KrXVSz0BBI%2FtPVgtV%2F%2FxkZ5WSjI%2F%2BFIXC3sHJwgT4yFqrZFFTSlVrp3sGYLwcfxSmXCbS00j2Ms4K7qkOsFx6qdTuiHtG4AimfmM8NyvOvR2G48qXtZ2fsfrN7%2BqpcRyUp0glKiimDm4TwAcHBp%2B9WeA4ki0GMWNR9OVF8BZvn7xtI%2FF09H8jzLEgz6yLwCDuelnFXHkTZZOytCOEdqDOtGwsm%2BNj00fXt%2B6%2Bj4vcA7bwNrZwENmXwAKuZnvsNRThs5ozMPfPiHyoDF7xiduHcXb70A8dRFheHjiySQATBZk0nl9MHPkBEWUoEtYjyrPFNwGzfdlD37Zdu98KCv%2BMmD2BYpUCvcST39e0%2BS1Wr249FAAg7mPzWrS5NstEbE0xrsiA6QN1PfRFLnhr%2BspxVJTlY8Mw1DqNXeyCQFREEXz9cHB0QOev73QaNhOF4B%2B45PHFHFgDhJTqjuubJFqX1KQco7NTTuW8kq95k2G4eLEGzM7lfItnjNeTKcOfV%2FT8hOuV77A9IK0XjgMpCO0ZiuV3L%2F6njCFAOmucGB3OII5XgCXEJTDdZLElVbu3Vz0fWexvL30k0B6ggBACOmIUBAEUKX0dDTvW7RCYcdZPq6n%2FSsQnUO2RuyBRgQ9Rc5mMvJ6CNIj1nXfd9qWAsCkaZzJAk1L8UjVqY737dSjfCGrPHWqXL32Q0mB%2F2BXnke00WaEYv2aTzAbnuV5pcWkDGAAGJmhSafh6hjr%2BW2SVYHrP7bb%2BOdPW%2FUgflGlTM2gaK%2Ft7tp6%2BN6yixdN89DcIwGktIFPABfNbwoQqQWEUnDJzg1g0jDeK5p7Kp7nensXFI7uyAr%2FLyM7fYLnpa6LYScE8vDnot5hrKlslm%2BfE3nVxJgO4o3KcYu%2FF8XM8yFQ27n%2F65Te%2FzKl3Jhpjj6TCIDneRD5%2FItxr1vdkALw7p1qfeWPpjHxMtsXaPxu6FLc%2BrnbSB1r7fcrlr36nqwMzQfnplJDryQCGOh%2FbLjhcM%2FEvQ4Pdund9xRV5m1LfTXaF%2BK9gsLGB9nsgddcz8thM%2FarPzYM8%2FFazf9sMFaU%2Fi%2FwvNANwEhPvUGR8ozn7d%2BiDKXixtKpbHp81nV9E7puRy31ixKUbOe%2Fv3Ud891ghhDrL5Z975eaOvV%2BCNRp0Gfz%2BcJjDABdTwlpdfKbId0t5XYAcHz5D5ZVtWUp9%2Flog2L7PgVJqZx0HOE5Cqghemv1%2Bt%2FeGBmZ%2BdB2yNN72UEpnzXG32YADA186i3bIpPxMhuKrFK%2Fd77JUnbkKbYvRJlC8DzKSZK76Lq1he2dKy%2BZuSfesSz5a2xHDbLJ%2BJaqdv5H4EUY%2BzbG2m9HgN7mg81bfw4W1uu7AjvHaqDhqF%2FZ3Fq5XFy%2FcESSDsx5fvZ7wLEsNfXk%2BjlVHfpSCOB%2FAQAA%2F%2F8zd8orZc2N9AAAAABJRU5ErkJggg%3D%3D" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/cloudnative-pg"&gt;&lt;img src="https://img.shields.io/badge/stackoverflow-cloudnative--pg-blue?logo=stackoverflow&amp;amp;logoColor=%23F48024&amp;amp;link=https%3A%2F%2Fstackoverflow.com%2Fquestions%2Ftagged%2Fcloudnative-pg" alt="Stack Overflow" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg?ref=badge_small"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg.svg?type=small" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Welcome to the CloudNativePG Project!&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;CloudNativePG (CNPG)&lt;/strong&gt; is an open-source platform designed to seamlessly manage &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; databases in Kubernetes environments. It covers the entire operational lifecycle—from deployment to ongoing maintenance—through its core component, the CloudNativePG operator.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudnative-pg/governance/raw/main/GOVERNANCE.md"&gt;Governance Policies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/ADOPTERS.md"&gt;Adopters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudnative-pg.io/support/"&gt;Commercial Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/LICENSE"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;The best way to get started is the &lt;a href="https://cloudnative-pg.io/documentation/current/quickstart/"&gt;Quickstart Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Scope&lt;/h2&gt; 
&lt;h3&gt;Mission&lt;/h3&gt; 
&lt;p&gt;CloudNativePG aims to increase PostgreSQL adoption within Kubernetes by making it an integral part of the development process and GitOps-driven CI/CD automation.&lt;/p&gt; 
&lt;h3&gt;Core Principles &amp;amp; Features&lt;/h3&gt; 
&lt;p&gt;Designed by PostgreSQL experts for Kubernetes administrators, CloudNativePG follows a Kubernetes-native approach to PostgreSQL primary/standby cluster management. Instead of relying on external high-availability tools (like Patroni, repmgr, or Stolon), it integrates directly with the Kubernetes API to automate database operations that a skilled DBA would perform manually.&lt;/p&gt; 
&lt;p&gt;Key design decisions include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Direct integration with Kubernetes API: The PostgreSQL cluster’s status is available directly in the &lt;code&gt;Cluster&lt;/code&gt; resource, allowing users to inspect it via the Kubernetes API.&lt;/li&gt; 
 &lt;li&gt;Operator pattern: The operator ensures that the desired PostgreSQL state is reconciled automatically, following Kubernetes best practices.&lt;/li&gt; 
 &lt;li&gt;Immutable application containers: Updates follow an immutable infrastructure model, as explained in &lt;a href="https://www.enterprisedb.com/blog/why-edb-chose-immutable-application-containers"&gt;"Why EDB Chose Immutable Application Containers"&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How CloudNativePG Works&lt;/h3&gt; 
&lt;p&gt;The operator continuously monitors and updates the PostgreSQL cluster state. Examples of automated actions include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Failover management: If the primary instance fails, the operator elects a new primary, updates the cluster status, and orchestrates the transition.&lt;/li&gt; 
 &lt;li&gt;Scaling read replicas: When the number of desired replicas changes, the operator provisions or removes resources such as persistent volumes, secrets, and config maps while managing streaming replication.&lt;/li&gt; 
 &lt;li&gt;Service updates: Kubernetes remains the single source of truth, ensuring that PostgreSQL service endpoints are always up to date.&lt;/li&gt; 
 &lt;li&gt;Rolling updates: When an image is updated, the operator follows a rolling strategy—first updating replica pods before performing a controlled switchover for the primary.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CloudNativePG manages additional Kubernetes resources to enhance PostgreSQL management, including: &lt;code&gt;Backup&lt;/code&gt;, &lt;code&gt;ClusterImageCatalog&lt;/code&gt;, &lt;code&gt;Database&lt;/code&gt;, &lt;code&gt;ImageCatalog&lt;/code&gt;, &lt;code&gt;Pooler&lt;/code&gt;, &lt;code&gt;Publication&lt;/code&gt;, &lt;code&gt;ScheduledBackup&lt;/code&gt;, and &lt;code&gt;Subscription&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Out of Scope&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes only:&lt;/strong&gt; CloudNativePG is dedicated to vanilla Kubernetes maintained by the &lt;a href="https://kubernetes.io/"&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL only:&lt;/strong&gt; CloudNativePG is dedicated to vanilla PostgreSQL maintained by the &lt;a href="https://www.postgresql.org/about/"&gt;PostgreSQL Global Development Group (PGDG)&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No support for forks:&lt;/strong&gt; Features from PostgreSQL forks will only be considered if they can be integrated as extensions or pluggable frameworks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Not a general-purpose database operator:&lt;/strong&gt; CloudNativePG does not support other databases (e.g., MariaDB).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CloudNativePG can be extended via the &lt;a href="https://github.com/cloudnative-pg/cnpg-i"&gt;CNPG-I plugin interface&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Communications&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudnative-pg/cloudnative-pg/discussions"&gt;Github Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloud-native.slack.com/archives/C08MAUJ7NPM"&gt;Slack&lt;/a&gt; (join the &lt;a href="https://communityinviter.com/apps/cloud-native/cncf"&gt;CNCF Slack Workspace&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/CloudNativePg"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@CloudNativePG"&gt;Mastodon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bsky.app/profile/cloudnativepg.bsky.social"&gt;Bluesky&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/cloudnative-pg/projects/1"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudnative-pg.io"&gt;Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/docs/src/faq.md"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudnative-pg.io/blog/"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudnative-pg/cnpg-i"&gt;CloudNativePG plugin Interface (CNPG-I)&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;A list of publicly known users of the CloudNativePG operator is in &lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/ADOPTERS.md"&gt;ADOPTERS.md&lt;/a&gt;. Help us grow our community and CloudNativePG by adding yourself and your organization to this list!&lt;/p&gt; 
&lt;h3&gt;CloudNativePG at KubeCon&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;April 4 2025, KubeCon Europe in London: &lt;a href="https://sched.co/1tx8g"&gt;"Consistent Volume Group Snapshots, Unraveling the Magic"&lt;/a&gt; - Leonardo Cecchi (EDB) and Xing Yang (VMware)&lt;/li&gt; 
 &lt;li&gt;November 11 2024, Cloud Native Rejekts NA 2024: &lt;a href="https://www.youtube.com/watch?v=uBzl_stoxoc&amp;amp;ab_channel=CloudNativeRejekts"&gt;"Maximising Microservice Databases with Kubernetes, Postgres, and CloudNativePG"&lt;/a&gt; - Gabriele Bartolini (EDB) and Leonardo Cecchi (EDB)&lt;/li&gt; 
 &lt;li&gt;March 21 2024, KubeCon Europe 2024 in Paris: &lt;a href="https://kccnceu2024.sched.com/event/1YeM4/scaling-heights-mastering-postgres-database-vertical-scalability-with-kubernetes-storage-magic-gabriele-bartolini-edb-gari-singh-google"&gt;"Scaling Heights: Mastering Postgres Database Vertical Scalability with Kubernetes Storage Magic"&lt;/a&gt; - Gari Singh, Google &amp;amp; Gabriele Bartolini, EDB&lt;/li&gt; 
 &lt;li&gt;March 19 2024, Data on Kubernetes Day at KubeCon Europe 2024 in Paris: &lt;a href="https://colocatedeventseu2024.sched.com/event/1YFha/from-zero-to-hero-scaling-postgres-in-kubernetes-using-the-power-of-cloudnativepg-gabriele-bartolini-edb"&gt;"From Zero to Hero: Scaling Postgres in Kubernetes Using the Power of CloudNativePG"&lt;/a&gt; - Gabriele Bartolini, EDB&lt;/li&gt; 
 &lt;li&gt;7 November 2023, KubeCon North America 2023 in Chicago: &lt;a href="https://kccncna2023.sched.com/event/1R2ml/disaster-recovery-with-very-large-postgres-databases-gabriele-bartolini-edb-michelle-au-google"&gt;"Disaster Recovery with Very Large Postgres Databases (in Kubernetes)"&lt;/a&gt; - Michelle Au, Google &amp;amp; Gabriele Bartolini, EDB&lt;/li&gt; 
 &lt;li&gt;27 October 2022, KubeCon North America 2022 in Detroit: &lt;a href="https://kccncna2022.sched.com/event/182GB/data-on-kubernetes-deploying-and-running-postgresql-and-patterns-for-databases-in-a-kubernetes-cluster-chris-milsted-ondat-gabriele-bartolini-edb"&gt;"Data On Kubernetes, Deploying And Running PostgreSQL And Patterns For Databases In a Kubernetes Cluster"&lt;/a&gt; - Chris Milsted, Ondat &amp;amp; Gabriele Bartolini, EDB&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Useful links&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dok.community/"&gt;Data on Kubernetes (DoK) Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cncf.io/blog/2024/11/20/cloud-neutral-postgres-databases-with-kubernetes-and-cloudnativepg/"&gt;"Cloud Neutral Postgres Databases with Kubernetes and CloudNativePG" by Gabriele Bartolini&lt;/a&gt; (November 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gabrielebartolini.it/articles/2024/03/cloudnativepg-recipe-5-how-to-migrate-your-postgresql-database-in-kubernetes-with-~0-downtime-from-anywhere/"&gt;"How to migrate your PostgreSQL database in Kubernetes with ~0 downtime from anywhere" by Gabriele Bartolini&lt;/a&gt; (March 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gabrielebartolini.it/articles/2024/02/maximizing-microservice-databases-with-kubernetes-postgres-and-cloudnativepg/"&gt;"Maximizing Microservice Databases with Kubernetes, Postgres, and CloudNativePG" by Gabriele Bartolini&lt;/a&gt; (February 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cncf.io/blog/2023/09/29/recommended-architectures-for-postgresql-in-kubernetes/"&gt;"Recommended Architectures for PostgreSQL in Kubernetes" by Gabriele Bartolini&lt;/a&gt; (September 2023)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.enterprisedb.com/blog/current-state-major-postgresql-upgrades-cloudnativepg-kubernetes"&gt;"The Current State of Major PostgreSQL Upgrades with CloudNativePG" by Gabriele Bartolini&lt;/a&gt; (August 2023)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://thenewstack.io/the-rise-of-the-kubernetes-native-database/"&gt;"The Rise of the Kubernetes Native Database" by Jeff Carpenter&lt;/a&gt; (December 2022)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudnativenow.com/kubecon-cnc-eu-2022/why-run-postgres-in-kubernetes/"&gt;"Why Run Postgres in Kubernetes?" by Gabriele Bartolini&lt;/a&gt; (May 2022)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tfir.io/shift-left-security-the-path-to-postgresql-on-kubernetes/"&gt;"Shift-Left Security: The Path To PostgreSQL On Kubernetes" by Gabriele Bartolini&lt;/a&gt; (April 2021)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/"&gt;"Local Persistent Volumes and PostgreSQL usage in Kubernetes" by Gabriele Bartolini&lt;/a&gt; (June 2020)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; We are a &lt;a href="https://www.cncf.io/sandbox-projects/"&gt;Cloud Native Computing Foundation Sandbox project&lt;/a&gt;. &lt;/p&gt; 
&lt;p style="text-align:center;" align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/white/cncf-white.svg?raw=true" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/color/cncf-color.svg?raw=true" /&gt; 
  &lt;img align="center" src="https://github.com/cncf/artwork/raw/main/other/cncf/horizontal/color/cncf-color.svg?raw=true" alt="CNCF logo" width="50%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; CloudNativePG was originally built and sponsored by &lt;a href="https://www.enterprisedb.com"&gt;EDB&lt;/a&gt;. &lt;/p&gt; 
&lt;p style="text-align:center;" align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_white.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg" /&gt; 
  &lt;img align="center" src="https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg?sanitize=true" alt="EDB logo" width="25%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.postgresql.org/about/policies/trademarks/"&gt;Postgres, PostgreSQL, and the Slonik Logo&lt;/a&gt; are trademarks or registered trademarks of the PostgreSQL Community Association of Canada, and used with their permission. &lt;/p&gt; 
&lt;hr /&gt;</description>
    </item>
    
    <item>
      <title>majd/ipatool</title>
      <link>https://github.com/majd/ipatool</link>
      <description>&lt;p&gt;Command-line tool that allows searching and downloading app packages (known as ipa files) from the iOS App Store&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;IPATool&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/majd/ipatool/releases/"&gt;&lt;img src="https://img.shields.io/github/release/majd/ipatool.svg?label=Release" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/majd/ipatool/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ipatool&lt;/code&gt; is a command line tool that allows you to search for iOS apps on the &lt;a href="https://apps.apple.com"&gt;App Store&lt;/a&gt; and download a copy of the app package, known as an &lt;em&gt;ipa&lt;/em&gt; file.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/majd/ipatool/main/resources/demo.gif" alt="Demo" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/majd/ipatool/main/#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/majd/ipatool/main/#installation"&gt;Installation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/majd/ipatool/main/#manual"&gt;Manual&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/majd/ipatool/main/#package-manager-macos"&gt;Package Manager (macOS)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/majd/ipatool/main/#usage"&gt;Usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/majd/ipatool/main/#compiling"&gt;Compiling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/majd/ipatool/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/majd/ipatool/releases"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/majd/ipatool/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supported operating system (Windows, Linux or macOS).&lt;/li&gt; 
 &lt;li&gt;Apple ID set up to use the App Store.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Manual&lt;/h3&gt; 
&lt;p&gt;You can grab the latest version of &lt;code&gt;ipatool&lt;/code&gt; from &lt;a href="https://github.com/majd/ipatool/releases"&gt;GitHub releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Package Manager (macOS)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;ipatool&lt;/code&gt; using &lt;a href="https://brew.sh"&gt;Homebrew&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ brew install ipatool
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;To authenticate with the App Store, use the &lt;code&gt;auth&lt;/code&gt; command.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Authenticate with the App Store

Usage:
  ipatool auth [command]

Available Commands:
  info        Show current account info
  login       Login to the App Store
  revoke      Revoke your App Store credentials

Flags:
  -h, --help   help for auth

Global Flags:
      --format format     sets output format for command; can be 'text', 'json' (default text)
      --non-interactive   run in non-interactive session
      --verbose           enables verbose logs

Use "ipatool auth [command] --help" for more information about a command.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To search for apps on the App Store, use the &lt;code&gt;search&lt;/code&gt; command.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Search for iOS apps available on the App Store

Usage:
  ipatool search &amp;lt;term&amp;gt; [flags]

Flags:
  -h, --help        help for search
  -l, --limit int   maximum amount of search results to retrieve (default 5)

Global Flags:
      --format format     sets output format for command; can be 'text', 'json' (default text)
      --non-interactive   run in non-interactive session
      --verbose           enables verbose logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To obtain a license for an app, use the &lt;code&gt;purchase&lt;/code&gt; command.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Obtain a license for the app from the App Store

Usage:
  ipatool purchase [flags]

Flags:
  -b, --bundle-identifier string   Bundle identifier of the target iOS app (required)
  -h, --help                       help for purchase

Global Flags:
      --format format     sets output format for command; can be 'text', 'json' (default text)
      --non-interactive   run in non-interactive session
      --verbose           enables verbose logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To obtain a list of availble app versions to download, use the &lt;code&gt;list-versions&lt;/code&gt; command.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;List the available versions of an iOS app

Usage:
  ipatool list-versions [flags]

Flags:
  -i, --app-id int                 ID of the target iOS app (required)
  -b, --bundle-identifier string   The bundle identifier of the target iOS app (overrides the app ID)
  -h, --help                       help for list-versions

Global Flags:
      --format format                sets output format for command; can be 'text', 'json' (default text)
      --keychain-passphrase string   passphrase for unlocking keychain
      --non-interactive              run in non-interactive session
      --verbose                      enables verbose logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To download a copy of the ipa file, use the &lt;code&gt;download&lt;/code&gt; command.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Download (encrypted) iOS app packages from the App Store

Usage:
  ipatool download [flags]

Flags:
  -i, --app-id int                   ID of the target iOS app (required)
  -b, --bundle-identifier string     The bundle identifier of the target iOS app (overrides the app ID)
      --external-version-id string   External version identifier of the target iOS app (defaults to latest version when not specified)
  -h, --help                         help for download
  -o, --output string                The destination path of the downloaded app package
      --purchase                     Obtain a license for the app if needed

Global Flags:
      --format format                sets output format for command; can be 'text', 'json' (default text)
      --keychain-passphrase string   passphrase for unlocking keychain
      --non-interactive              run in non-interactive session
      --verbose                      enables verbose logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To resolve an external version identifier, returned by the &lt;code&gt;list-versions&lt;/code&gt; command, use the &lt;code&gt;get-version-metadata&lt;/code&gt; command.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Retrieves the metadata for a specific version of an app

Usage:
  ipatool get-version-metadata [flags]

Flags:
  -i, --app-id int                   ID of the target iOS app (required)
  -b, --bundle-identifier string     The bundle identifier of the target iOS app (overrides the app ID)
      --external-version-id string   External version identifier of the target iOS app (required)
  -h, --help                         help for get-version-metadata

Global Flags:
      --format format                sets output format for command; can be 'text', 'json' (default text)
      --keychain-passphrase string   passphrase for unlocking keychain
      --non-interactive              run in non-interactive session
      --verbose                      enables verbose logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; the tool runs in interactive mode by default. Use the &lt;code&gt;--non-interactive&lt;/code&gt; flag if running in an automated environment.&lt;/p&gt; 
&lt;h2&gt;Compiling&lt;/h2&gt; 
&lt;p&gt;The tool can be compiled using the Go toolchain.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ go build -o ipatool
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unit tests can be executed with the following commands.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ go generate github.com/majd/ipatool/...
$ go test -v github.com/majd/ipatool/...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;IPATool is released under the &lt;a href="https://github.com/majd/ipatool/raw/main/LICENSE"&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>charmbracelet/huh</title>
      <link>https://github.com/charmbracelet/huh</link>
      <description>&lt;p&gt;Build terminal forms and prompts 🤷🏻‍♀️&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Huh?&lt;/h1&gt; 
&lt;p&gt; &lt;img alt="Hey there! I’m Glenn!" title="Hey there! I’m Glenn!" src="https://stuff.charm.sh/huh/glenn.png" width="400" /&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://github.com/charmbracelet/huh/releases"&gt;&lt;img src="https://img.shields.io/github/release/charmbracelet/huh.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/charmbracelet/huh?tab=doc"&gt;&lt;img src="https://godoc.org/github.com/golang/gddo?status.svg?sanitize=true" alt="Go Docs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/charmbracelet/huh/actions"&gt;&lt;img src="https://github.com/charmbracelet/huh/actions/workflows/build.yml/badge.svg?branch=main" alt="Build Status" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;A simple, powerful library for building interactive forms and prompts in the terminal.&lt;/p&gt; 
&lt;img alt="Running a burger form" width="600" src="https://vhs.charm.sh/vhs-3J4i6HE3yBmz6SUO3HqILr.gif" /&gt; 
&lt;p&gt;&lt;code&gt;huh?&lt;/code&gt; is easy to use in a standalone fashion, can be &lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/#what-about-bubble-tea"&gt;integrated into a Bubble Tea application&lt;/a&gt;, and contains a first-class &lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/#accessibility"&gt;accessible mode&lt;/a&gt; for screen readers.&lt;/p&gt; 
&lt;p&gt;The above example is running from a single Go program (&lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/examples/burger/main.go"&gt;source&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;Tutorial&lt;/h2&gt; 
&lt;p&gt;Let’s build a form for ordering burgers. To start, we’ll import the library and define a few variables where we'll store answers.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import "github.com/charmbracelet/huh"

var (
    burger       string
    toppings     []string
    sauceLevel   int
    name         string
    instructions string
    discount     bool
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;huh?&lt;/code&gt; separates forms into groups (you can think of groups as pages). Groups are made of fields (e.g. &lt;code&gt;Select&lt;/code&gt;, &lt;code&gt;Input&lt;/code&gt;, &lt;code&gt;Text&lt;/code&gt;). We will set up three groups for the customer to fill out.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;form := huh.NewForm(
    huh.NewGroup(
        // Ask the user for a base burger and toppings.
        huh.NewSelect[string]().
            Title("Choose your burger").
            Options(
                huh.NewOption("Charmburger Classic", "classic"),
                huh.NewOption("Chickwich", "chickwich"),
                huh.NewOption("Fishburger", "fishburger"),
                huh.NewOption("Charmpossible™ Burger", "charmpossible"),
            ).
            Value(&amp;amp;burger), // store the chosen option in the "burger" variable

        // Let the user select multiple toppings.
        huh.NewMultiSelect[string]().
            Title("Toppings").
            Options(
                huh.NewOption("Lettuce", "lettuce").Selected(true),
                huh.NewOption("Tomatoes", "tomatoes").Selected(true),
                huh.NewOption("Jalapeños", "jalapeños"),
                huh.NewOption("Cheese", "cheese"),
                huh.NewOption("Vegan Cheese", "vegan cheese"),
                huh.NewOption("Nutella", "nutella"),
            ).
            Limit(4). // there’s a 4 topping limit!
            Value(&amp;amp;toppings),

        // Option values in selects and multi selects can be any type you
        // want. We’ve been recording strings above, but here we’ll store
        // answers as integers. Note the generic "[int]" directive below.
        huh.NewSelect[int]().
            Title("How much Charm Sauce do you want?").
            Options(
                huh.NewOption("None", 0),
                huh.NewOption("A little", 1),
                huh.NewOption("A lot", 2),
            ).
            Value(&amp;amp;sauceLevel),
    ),

    // Gather some final details about the order.
    huh.NewGroup(
        huh.NewInput().
            Title("What’s your name?").
            Value(&amp;amp;name).
            // Validating fields is easy. The form will mark erroneous fields
            // and display error messages accordingly.
            Validate(func(str string) error {
                if str == "Frank" {
                    return errors.New("Sorry, we don’t serve customers named Frank.")
                }
                return nil
            }),

        huh.NewText().
            Title("Special Instructions").
            CharLimit(400).
            Value(&amp;amp;instructions),

        huh.NewConfirm().
            Title("Would you like 15% off?").
            Value(&amp;amp;discount),
    ),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, run the form:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;err := form.Run()
if err != nil {
    log.Fatal(err)
}

if !discount {
    fmt.Println("What? You didn’t take the discount?!")
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And that’s it! For more info see &lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/examples/burger/main.go"&gt;the full source&lt;/a&gt; for this example as well as &lt;a href="https://pkg.go.dev/github.com/charmbracelet/huh?tab=doc"&gt;the docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you need more dynamic forms that change based on input from previous fields, check out the &lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/#dynamic-forms"&gt;dynamic forms&lt;/a&gt; example.&lt;/p&gt; 
&lt;h2&gt;Field Reference&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/#input"&gt;&lt;code&gt;Input&lt;/code&gt;&lt;/a&gt;: single line text input&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/#text"&gt;&lt;code&gt;Text&lt;/code&gt;&lt;/a&gt;: multi-line text input&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/#select"&gt;&lt;code&gt;Select&lt;/code&gt;&lt;/a&gt;: select an option from a list&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/#multiple-select"&gt;&lt;code&gt;MultiSelect&lt;/code&gt;&lt;/a&gt;: select multiple options from a list&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/#confirm"&gt;&lt;code&gt;Confirm&lt;/code&gt;&lt;/a&gt;: confirm an action (yes or no)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Just want to prompt the user with a single field? Each field has a &lt;code&gt;Run&lt;/code&gt; method that can be used as a shorthand for gathering quick and easy input.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;var name string

huh.NewInput().
    Title("What’s your name?").
    Value(&amp;amp;name).
    Run() // this is blocking...

fmt.Printf("Hey, %s!\n", name)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Input&lt;/h3&gt; 
&lt;p&gt;Prompt the user for a single line of text.&lt;/p&gt; 
&lt;img alt="Input field" width="600" src="https://vhs.charm.sh/vhs-1ULe9JbTHfwFmm3hweRVtD.gif" /&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;huh.NewInput().
    Title("What’s for lunch?").
    Prompt("?").
    Validate(isFood).
    Value(&amp;amp;lunch)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Text&lt;/h3&gt; 
&lt;p&gt;Prompt the user for multiple lines of text.&lt;/p&gt; 
&lt;img alt="Text field" width="600" src="https://vhs.charm.sh/vhs-2rrIuVSEf38bT0cwc8hfEG.gif" /&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;huh.NewText().
    Title("Tell me a story.").
    Validate(checkForPlagiarism).
    Value(&amp;amp;story)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Select&lt;/h3&gt; 
&lt;p&gt;Prompt the user to select a single option from a list.&lt;/p&gt; 
&lt;img alt="Select field" width="600" src="https://vhs.charm.sh/vhs-7wFqZlxMWgbWmOIpBqXJTi.gif" /&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;huh.NewSelect[string]().
    Title("Pick a country.").
    Options(
        huh.NewOption("United States", "US"),
        huh.NewOption("Germany", "DE"),
        huh.NewOption("Brazil", "BR"),
        huh.NewOption("Canada", "CA"),
    ).
    Value(&amp;amp;country)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiple Select&lt;/h3&gt; 
&lt;p&gt;Prompt the user to select multiple (zero or more) options from a list.&lt;/p&gt; 
&lt;img alt="Multiselect field" width="600" src="https://vhs.charm.sh/vhs-3TLImcoexOehRNLELysMpK.gif" /&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;huh.NewMultiSelect[string]().
    Options(
        huh.NewOption("Lettuce", "Lettuce").Selected(true),
        huh.NewOption("Tomatoes", "Tomatoes").Selected(true),
        huh.NewOption("Charm Sauce", "Charm Sauce"),
        huh.NewOption("Jalapeños", "Jalapeños"),
        huh.NewOption("Cheese", "Cheese"),
        huh.NewOption("Vegan Cheese", "Vegan Cheese"),
        huh.NewOption("Nutella", "Nutella"),
    ).
    Title("Toppings").
    Limit(4).
    Value(&amp;amp;toppings)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Confirm&lt;/h3&gt; 
&lt;p&gt;Prompt the user to confirm (Yes or No).&lt;/p&gt; 
&lt;img alt="Confirm field" width="600" src="https://vhs.charm.sh/vhs-2HeX5MdOxLsrWwsa0TNMIL.gif" /&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;huh.NewConfirm().
    Title("Are you sure?").
    Affirmative("Yes!").
    Negative("No.").
    Value(&amp;amp;confirm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Accessibility&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;huh?&lt;/code&gt; has a special rendering option designed specifically for screen readers. You can enable it with &lt;code&gt;form.WithAccessible(true)&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] We recommend setting this through an environment variable or configuration option to allow the user to control accessibility.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;accessibleMode := os.Getenv("ACCESSIBLE") != ""
form.WithAccessible(accessibleMode)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Accessible forms will drop TUIs in favor of standard prompts, providing better dictation and feedback of the information on screen for the visually impaired.&lt;/p&gt; 
&lt;img alt="Accessible cuisine form" width="600" src="https://vhs.charm.sh/vhs-19xEBn4LgzPZDtgzXRRJYS.gif" /&gt; 
&lt;h2&gt;Themes&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;huh?&lt;/code&gt; contains a powerful theme abstraction. Supply your own custom theme or choose from one of the five predefined themes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Charm&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Dracula&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Catppuccin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Base 16&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Default&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p&gt; &lt;img alt="Charm-themed form" width="400" src="https://stuff.charm.sh/huh/themes/charm-theme.png" /&gt; &lt;img alt="Dracula-themed form" width="400" src="https://stuff.charm.sh/huh/themes/dracula-theme.png" /&gt; &lt;img alt="Catppuccin-themed form" width="400" src="https://stuff.charm.sh/huh/themes/catppuccin-theme.png" /&gt; &lt;img alt="Base 16-themed form" width="400" src="https://stuff.charm.sh/huh/themes/basesixteen-theme.png" /&gt; &lt;img alt="Default-themed form" width="400" src="https://stuff.charm.sh/huh/themes/default-theme.png" /&gt; &lt;/p&gt; 
&lt;p&gt;Themes can take advantage of the full range of &lt;a href="https://github.com/charmbracelet/lipgloss"&gt;Lip Gloss&lt;/a&gt; style options. For a high level theme reference see &lt;a href="https://pkg.go.dev/github.com/charmbracelet/huh#Theme"&gt;the docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Dynamic Forms&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;huh?&lt;/code&gt; forms can be as dynamic as your heart desires. Simply replace properties with their equivalent &lt;code&gt;Func&lt;/code&gt; to recompute the properties value every time a different part of your form changes.&lt;/p&gt; 
&lt;p&gt;Here’s how you would build a simple country + state / province picker.&lt;/p&gt; 
&lt;p&gt;First, define some variables that we’ll use to store the user selection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;var country string
var state string
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Define your country select as you normally would:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;huh.NewSelect[string]().
    Options(huh.NewOptions("United States", "Canada", "Mexico")...).
    Value(&amp;amp;country).
    Title("Country").
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Define your state select with &lt;code&gt;TitleFunc&lt;/code&gt; and &lt;code&gt;OptionsFunc&lt;/code&gt; instead of &lt;code&gt;Title&lt;/code&gt; and &lt;code&gt;Options&lt;/code&gt;. This will allow you to change the title and options based on the selection of the previous field, i.e. &lt;code&gt;country&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To do this, we provide a &lt;code&gt;func() string&lt;/code&gt; and a &lt;code&gt;binding any&lt;/code&gt; to &lt;code&gt;TitleFunc&lt;/code&gt;. The function defines what to show for the title and the binding specifies what value needs to change for the function to recompute. So if &lt;code&gt;country&lt;/code&gt; changes (e.g. the user changes the selection) we will recompute the function.&lt;/p&gt; 
&lt;p&gt;For &lt;code&gt;OptionsFunc&lt;/code&gt;, we provide a &lt;code&gt;func() []Option[string]&lt;/code&gt; and a &lt;code&gt;binding any&lt;/code&gt;. We’ll fetch the country’s states, provinces, or territories from an API. &lt;code&gt;huh&lt;/code&gt; will automatically handle caching for you.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] We have to pass &lt;code&gt;&amp;amp;country&lt;/code&gt; as the binding to recompute the function only when &lt;code&gt;country&lt;/code&gt; changes, otherwise we will hit the API too often.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;huh.NewSelect[string]().
    Value(&amp;amp;state).
    Height(8).
    TitleFunc(func() string {
        switch country {
        case "United States":
            return "State"
        case "Canada":
            return "Province"
        default:
            return "Territory"
        }
    }, &amp;amp;country).
    OptionsFunc(func() []huh.Option[string] {
        opts := fetchStatesForCountry(country)
        return huh.NewOptions(opts...)
    }, &amp;amp;country),
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Lastly, run the &lt;code&gt;form&lt;/code&gt; with these inputs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;err := form.Run()
if err != nil {
    log.Fatal(err)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;img width="600" src="https://vhs.charm.sh/vhs-6FRmBjNi2aiRb4INPXwIjo.gif" alt="Country / State form with dynamic inputs running." /&gt; 
&lt;h2&gt;Bonus: Spinner&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;huh?&lt;/code&gt; ships with a standalone spinner package. It’s useful for indicating background activity after a form is submitted.&lt;/p&gt; 
&lt;img alt="Spinner while making a burger" width="600" src="https://vhs.charm.sh/vhs-6HvYomAFP6H8mngOYWXvwJ.gif" /&gt; 
&lt;p&gt;Create a new spinner, set a title, set the action (or provide a &lt;code&gt;Context&lt;/code&gt;), and run the spinner:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;strong&gt;Action Style&lt;/strong&gt; &lt;/td&gt;
   &lt;td&gt; &lt;strong&gt;Context Style&lt;/strong&gt; &lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;pre&gt;&lt;code class="language-go"&gt;err := spinner.New().
    Title("Making your burger...").
    Action(makeBurger).
    Run()

fmt.Println("Order up!")
&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;pre&gt;&lt;code class="language-go"&gt;go makeBurger()

err := spinner.New().
    Type(spinner.Line).
    Title("Making your burger...").
    Context(ctx).
    Run()

fmt.Println("Order up!")
&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;For more on Spinners see the &lt;a href="https://raw.githubusercontent.com/charmbracelet/huh/main/spinner/examples"&gt;spinner examples&lt;/a&gt; and &lt;a href="https://pkg.go.dev/github.com/charmbracelet/huh/spinner"&gt;the spinner docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;What about Bubble Tea?&lt;/h2&gt; 
&lt;img alt="Bubbletea + Huh?" width="174" src="https://stuff.charm.sh/huh/bubbletea-huh.png" /&gt; 
&lt;p&gt;Huh is built on &lt;a href="https://github.com/charmbracelet/bubbletea"&gt;Bubble Tea&lt;/a&gt; and, in addition to its standalone mode, &lt;code&gt;huh?&lt;/code&gt; has first-class support and can be easily integrated into Bubble Tea applications. It’s very useful in portions of your Bubble Tea application that need form-like input, and for times when you need more flexibility than &lt;code&gt;huh?&lt;/code&gt; alone can offer.&lt;/p&gt; 
&lt;img alt="Bubble Tea embedded form example" width="800" src="https://vhs.charm.sh/vhs-3wGaB7EUKWmojeaHpARMUv.gif" /&gt; 
&lt;p&gt;A &lt;code&gt;huh.Form&lt;/code&gt; is just a &lt;code&gt;tea.Model&lt;/code&gt;, so you can use it just as you would any other &lt;a href="https://github.com/charmbracelet/bubbles"&gt;Bubble&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type Model struct {
    form *huh.Form // huh.Form is just a tea.Model
}

func NewModel() Model {
    return Model{
        form: huh.NewForm(
            huh.NewGroup(
                huh.NewSelect[string]().
                    Key("class").
                    Options(huh.NewOptions("Warrior", "Mage", "Rogue")...).
                    Title("Choose your class"),

            huh.NewSelect[int]().
                Key("level").
                Options(huh.NewOptions(1, 20, 9999)...).
                Title("Choose your level"),
            ),
        )
    }
}

func (m Model) Init() tea.Cmd {
    return m.form.Init()
}

func (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
    // ...

    form, cmd := m.form.Update(msg)
    if f, ok := form.(*huh.Form); ok {
        m.form = f
    }

    return m, cmd
}

func (m Model) View() string {
    if m.form.State == huh.StateCompleted {
        class := m.form.GetString("class")
        level := m.form.GetInt("level")
        return fmt.Sprintf("You selected: %s, Lvl. %d", class, level)
    }
    return m.form.View()
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more info in using &lt;code&gt;huh?&lt;/code&gt; in Bubble Tea applications see &lt;a href="https://github.com/charmbracelet/huh/raw/main/examples/bubbletea/main.go"&gt;the full Bubble Tea example&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Huh?&lt;/code&gt; in the Wild&lt;/h2&gt; 
&lt;p&gt;For some &lt;code&gt;Huh?&lt;/code&gt; programs in production, see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/maaslalani/glyphs"&gt;glyphs&lt;/a&gt;: a unicode symbol picker&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/stefanlogue/meteor"&gt;meteor&lt;/a&gt;: a highly customisable conventional commit message tool&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/freeze"&gt;freeze&lt;/a&gt;: a tool for generating images of code and terminal output&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsavvyinc/savvy-cli"&gt;savvy&lt;/a&gt;: the easiest way to create, share, and run runbooks in the terminal&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/charmbracelet/huh/contribute"&gt;contributing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;We’d love to hear your thoughts on this project. Feel free to drop us a note!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/charmcli"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@charmcli"&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.sh/chat"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;huh?&lt;/code&gt; is inspired by the wonderful &lt;a href="https://github.com/AlecAivazis/survey"&gt;Survey&lt;/a&gt; library by Alec Aivazis.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/bubbletea/raw/master/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Part of &lt;a href="https://charm.sh"&gt;Charm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://charm.sh/"&gt;&lt;img alt="The Charm logo" src="https://stuff.charm.sh/charm-badge.jpg" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Charm热爱开源 • Charm loves open source • نحنُ نحب المصادر المفتوحة&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kubeflow/trainer</title>
      <link>https://github.com/kubeflow/trainer</link>
      <description>&lt;p&gt;Distributed AI Model Training and Fine-Tuning on Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kubeflow Trainer&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.kubeflow.org/docs/about/community/#kubeflow-slack-channels"&gt;&lt;img src="https://img.shields.io/badge/Join_Slack-blue?logo=slack" alt="Join Slack" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/kubeflow/trainer?branch=master"&gt;&lt;img src="https://coveralls.io/repos/github/kubeflow/trainer/badge.svg?branch=master" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/kubeflow/trainer"&gt;&lt;img src="https://goreportcard.com/badge/github.com/kubeflow/trainer" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/10435"&gt;&lt;img src="https://www.bestpractices.dev/projects/10435/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/kubeflow/trainer"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fkubeflow%2Ftrainer?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fkubeflow%2Ftrainer.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/kubeflow/trainer/master/docs/images/trainer-logo.svg?sanitize=true" alt="logo" width="200" /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p&gt;Latest News 🔥&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/09] Kubeflow SDK v0.1 is officially released with support for CustomTrainer, BuiltinTrainer, and local PyTorch execution. Check out &lt;a href="https://github.com/kubeflow/sdk/releases/tag/0.1.0"&gt;the GitHub release notes&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/07] PyTorch on Kubernetes: Kubeflow Trainer Joins the PyTorch Ecosystem. Find the announcement in &lt;a href="https://pytorch.org/blog/pytorch-on-kubernetes-kubeflow-trainer-joins-the-pytorch-ecosystem/"&gt;the PyTorch blog post&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/07] Kubeflow Trainer v2.0 has been officially released. Check out &lt;a href="https://blog.kubeflow.org/trainer/intro/"&gt;the blog post announcement&lt;/a&gt; and &lt;a href="https://github.com/kubeflow/trainer/releases/tag/v2.0.0"&gt;the release notes&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/04] From High Performance Computing To AI Workloads on Kubernetes: MPI Runtime in Kubeflow TrainJob. See the &lt;a href="https://youtu.be/Fnb1a5Kaxgo"&gt;KubeCon + CloudNativeCon London talk&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Kubeflow Trainer is a Kubernetes-native project designed for large language models (LLMs) fine-tuning and enabling scalable, distributed training of machine learning (ML) models across various frameworks, including PyTorch, JAX, TensorFlow, and others.&lt;/p&gt; 
&lt;p&gt;You can integrate other ML libraries such as &lt;a href="https://huggingface.co"&gt;HuggingFace&lt;/a&gt;, &lt;a href="https://github.com/microsoft/DeepSpeed"&gt;DeepSpeed&lt;/a&gt;, or &lt;a href="https://github.com/NVIDIA/Megatron-LM"&gt;Megatron-LM&lt;/a&gt; with Kubeflow Trainer to run them on Kubernetes.&lt;/p&gt; 
&lt;p&gt;Kubeflow Trainer enables you to effortlessly develop your LLMs with the &lt;a href="https://github.com/kubeflow/sdk/"&gt;Kubeflow Python SDK&lt;/a&gt;, and build Kubernetes-native Training Runtimes using Kubernetes Custom Resource APIs.&lt;/p&gt; 
&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/kubeflow/trainer/master/docs/images/trainer-tech-stack.drawio.svg?sanitize=true" alt="logo" width="500" /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h2&gt;Kubeflow Trainer Introduction&lt;/h2&gt; 
&lt;p&gt;The following KubeCon + CloudNativeCon 2024 talk provides an overview of Kubeflow Trainer capabilities:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Lgy4ir1AhYw"&gt;&lt;img src="https://img.youtube.com/vi/Lgy4ir1AhYw/0.jpg" alt="Kubeflow Trainer" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Please check &lt;a href="https://www.kubeflow.org/docs/components/trainer/getting-started"&gt;the official Kubeflow Trainer documentation&lt;/a&gt; to install and get started with Kubeflow Trainer.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The following links provide information on how to get involved in the community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join our &lt;a href="https://www.kubeflow.org/docs/about/community/#kubeflow-slack"&gt;&lt;code&gt;#kubeflow-trainer&lt;/code&gt; Slack channel&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Attend &lt;a href="https://bit.ly/2PWVCkV"&gt;the bi-weekly AutoML and Training Working Group&lt;/a&gt; community meeting.&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://raw.githubusercontent.com/kubeflow/trainer/master/ADOPTERS.md"&gt;who is using Kubeflow Trainer&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/kubeflow/trainer/master/CONTRIBUTING.md"&gt;CONTRIBUTING guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/kubeflow/trainer/master/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Kubeflow Training Operator V1&lt;/h2&gt; 
&lt;p&gt;Kubeflow Trainer project is currently in &lt;strong&gt;alpha&lt;/strong&gt; status, and APIs may change. If you are using Kubeflow Training Operator V1, please refer &lt;a href="https://www.kubeflow.org/docs/components/trainer/operator-guides/migration/"&gt;to this migration document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Kubeflow Community will maintain the Training Operator V1 source code at &lt;a href="https://github.com/kubeflow/trainer/tree/release-1.9"&gt;the &lt;code&gt;release-1.9&lt;/code&gt; branch&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find the documentation for Kubeflow Training Operator V1 in &lt;a href="https://www.kubeflow.org/docs/components/trainer/legacy-v1"&gt;these guides&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;This project was originally started as a distributed training operator for TensorFlow and later we merged efforts from other Kubeflow Training Operators to provide a unified and simplified experience for both users and developers. We are very grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions. We'd also like to thank everyone who's contributed to and maintained the original operators.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PyTorch Operator: &lt;a href="https://github.com/kubeflow/pytorch-operator/graphs/contributors"&gt;list of contributors&lt;/a&gt; and &lt;a href="https://github.com/kubeflow/pytorch-operator/raw/master/OWNERS"&gt;maintainers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MPI Operator: &lt;a href="https://github.com/kubeflow/mpi-operator/graphs/contributors"&gt;list of contributors&lt;/a&gt; and &lt;a href="https://github.com/kubeflow/mpi-operator/raw/master/OWNERS"&gt;maintainers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;XGBoost Operator: &lt;a href="https://github.com/kubeflow/xgboost-operator/graphs/contributors"&gt;list of contributors&lt;/a&gt; and &lt;a href="https://github.com/kubeflow/xgboost-operator/raw/master/OWNERS"&gt;maintainers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Common library: &lt;a href="https://github.com/kubeflow/common/graphs/contributors"&gt;list of contributors&lt;/a&gt; and &lt;a href="https://github.com/kubeflow/common/raw/master/OWNERS"&gt;maintainers&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>rancher/rancher</title>
      <link>https://github.com/rancher/rancher</link>
      <description>&lt;p&gt;Complete container management platform&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Rancher&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://store.docker.com/community/images/rancher/rancher"&gt;&lt;img src="https://img.shields.io/docker/pulls/rancher/rancher.svg?sanitize=true" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/rancher/rancher"&gt;&lt;img src="https://goreportcard.com/badge/github.com/rancher/rancher" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Rancher is an open source container management platform built for organizations that deploy containers in production. Rancher makes it easy to run Kubernetes everywhere, meet IT requirements, and empower DevOps teams.&lt;/p&gt; 
&lt;h2&gt;Stable Release&lt;/h2&gt; 
&lt;!-- stable v2.12.2 DO NOT REMOVE THIS LINE --&gt; 
&lt;ul&gt; 
 &lt;li&gt;v2.12 
  &lt;ul&gt; 
   &lt;li&gt;Stable - v2.12.2 - &lt;code&gt;rancher/rancher:v2.12.2&lt;/code&gt; / &lt;code&gt;rancher/rancher:stable&lt;/code&gt; - Read the full release &lt;a href="https://github.com/rancher/rancher/releases/tag/v2.12.2"&gt;notes&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;v2.11 
  &lt;ul&gt; 
   &lt;li&gt;Stable - v2.11.3 - &lt;code&gt;rancher/rancher:v2.11.3&lt;/code&gt; - Read the full release &lt;a href="https://github.com/rancher/rancher/releases/tag/v2.11.3"&gt;notes&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;v2.10 
  &lt;ul&gt; 
   &lt;li&gt;Stable - v2.10.3 - &lt;code&gt;rancher/rancher:v2.10.3&lt;/code&gt; - Read the full release &lt;a href="https://github.com/rancher/rancher/releases/tag/v2.10.3"&gt;notes&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To get automated notifications of our latest release, you can watch the announcements category in our &lt;a href="http://forums.rancher.com/c/announcements"&gt;forums&lt;/a&gt;, or subscribe to the RSS feed &lt;code&gt;https://forums.rancher.com/c/announcements.rss&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open your browser to &lt;a href="https://localhost"&gt;https://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-and-upgrade"&gt;Installing/Upgrading Rancher&lt;/a&gt; for all installation options.&lt;/p&gt; 
&lt;h3&gt;Minimum Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Operating Systems 
  &lt;ul&gt; 
   &lt;li&gt;Please see &lt;a href="https://rancher.com/support-matrix/"&gt;Support Matrix&lt;/a&gt; for specific OS versions for each Rancher version. Note that the link will default to the support matrix for the latest version of Rancher. Use the left navigation menu to select a different Rancher version.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Hardware &amp;amp; Software 
  &lt;ul&gt; 
   &lt;li&gt;Please see &lt;a href="https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-requirements"&gt;Installation Requirements&lt;/a&gt; for hardware and software requirements.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Using Rancher&lt;/h3&gt; 
&lt;p&gt;To learn more about using Rancher, please refer to our &lt;a href="https://ranchermanager.docs.rancher.com/v2.8"&gt;Rancher Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source Code&lt;/h2&gt; 
&lt;p&gt;This repo is a meta-repo used for packaging and contains the majority of Rancher codebase. For other Rancher projects and modules, &lt;a href="https://github.com/rancher/rancher/raw/release/v2.8/go.mod"&gt;see go.mod&lt;/a&gt; for the full list.&lt;/p&gt; 
&lt;p&gt;Rancher also includes other open source libraries and projects, &lt;a href="https://github.com/rancher/rancher/raw/release/v2.8/go.mod"&gt;see go.mod&lt;/a&gt; for the full list.&lt;/p&gt; 
&lt;h2&gt;Build configuration&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://raw.githubusercontent.com/rancher/rancher/main/docs/build.md"&gt;build docs&lt;/a&gt; on how to customize the building and packaging of Rancher.&lt;/p&gt; 
&lt;h2&gt;Support, Discussion, and Community&lt;/h2&gt; 
&lt;p&gt;If you need any help with Rancher, please join us at either our &lt;a href="http://forums.rancher.com/"&gt;Rancher forums&lt;/a&gt; or &lt;a href="https://slack.rancher.io/"&gt;Slack&lt;/a&gt; where most of our team hangs out at.&lt;/p&gt; 
&lt;p&gt;Please submit any Rancher bugs, issues, and feature requests to &lt;a href="https://github.com/rancher/rancher/issues"&gt;rancher/rancher&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For security issues, please first check our &lt;a href="https://github.com/rancher/rancher/security"&gt;security policy&lt;/a&gt; and email &lt;a href="mailto:security-rancher@suse.com"&gt;security-rancher@suse.com&lt;/a&gt; instead of posting a public issue in GitHub. You may (but are not required to) use the GPG key located on &lt;a href="https://keybase.io/rancher"&gt;Keybase&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Copyright (c) 2014-2025 &lt;a href="http://rancher.com"&gt;SUSE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;p&gt;&lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ollama/ollama</title>
      <link>https://github.com/ollama/ollama</link>
      <description>&lt;p&gt;Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt;
  &amp;nbsp; 
 &lt;a href="https://ollama.com"&gt; &lt;img alt="ollama" width="240" src="https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;Ollama&lt;/h1&gt; 
&lt;p&gt;Get up and running with large language models.&lt;/p&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/Ollama.dmg"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/OllamaSetup.exe"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl -fsSL https://ollama.com/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/ollama/ollama/raw/main/docs/linux.md"&gt;Manual install instructions&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;The official &lt;a href="https://hub.docker.com/r/ollama/ollama"&gt;Ollama Docker image&lt;/a&gt; &lt;code&gt;ollama/ollama&lt;/code&gt; is available on Docker Hub.&lt;/p&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-python"&gt;ollama-python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-js"&gt;ollama-js&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/ollama"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://reddit.com/r/ollama"&gt;Reddit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To run and chat with &lt;a href="https://ollama.com/library/gemma3"&gt;Gemma 3&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run gemma3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model library&lt;/h2&gt; 
&lt;p&gt;Ollama supports a list of models available on &lt;a href="https://ollama.com/library" title="ollama model library"&gt;ollama.com/library&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Here are some example models that can be downloaded:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Parameters&lt;/th&gt; 
   &lt;th&gt;Size&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;815MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;4B&lt;/td&gt; 
   &lt;td&gt;3.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;12B&lt;/td&gt; 
   &lt;td&gt;8.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:12b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;27B&lt;/td&gt; 
   &lt;td&gt;17GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:27b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QwQ&lt;/td&gt; 
   &lt;td&gt;32B&lt;/td&gt; 
   &lt;td&gt;20GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run qwq&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;671B&lt;/td&gt; 
   &lt;td&gt;404GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1:671b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;109B&lt;/td&gt; 
   &lt;td&gt;67GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:scout&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;400B&lt;/td&gt; 
   &lt;td&gt;245GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:maverick&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.3&lt;/td&gt; 
   &lt;td&gt;70B&lt;/td&gt; 
   &lt;td&gt;43GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;2.0GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;1.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;11B&lt;/td&gt; 
   &lt;td&gt;7.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;90B&lt;/td&gt; 
   &lt;td&gt;55GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision:90b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;405B&lt;/td&gt; 
   &lt;td&gt;231GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1:405b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4&lt;/td&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;9.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4 Mini&lt;/td&gt; 
   &lt;td&gt;3.8B&lt;/td&gt; 
   &lt;td&gt;2.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4-mini&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run mistral&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Moondream 2&lt;/td&gt; 
   &lt;td&gt;1.4B&lt;/td&gt; 
   &lt;td&gt;829MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run moondream&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Neural Chat&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run neural-chat&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Starling&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run starling-lm&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Code Llama&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run codellama&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 2 Uncensored&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama2-uncensored&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLaVA&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llava&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Granite-3.3&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run granite3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Customize a model&lt;/h2&gt; 
&lt;h3&gt;Import from GGUF&lt;/h3&gt; 
&lt;p&gt;Ollama supports importing GGUF models in the Modelfile:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a file named &lt;code&gt;Modelfile&lt;/code&gt;, with a &lt;code&gt;FROM&lt;/code&gt; instruction with the local filepath to the model you want to import.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;FROM ./vicuna-33b.Q4_0.gguf
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the model in Ollama&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama create example -f Modelfile
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the model&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama run example
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Import from Safetensors&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/ollama/ollama/main/docs/import.md"&gt;guide&lt;/a&gt; on importing models for more information.&lt;/p&gt; 
&lt;h3&gt;Customize a prompt&lt;/h3&gt; 
&lt;p&gt;Models from the Ollama library can be customized with a prompt. For example, to customize the &lt;code&gt;llama3.2&lt;/code&gt; model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a &lt;code&gt;Modelfile&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM """
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, create and run the model:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ollama create mario -f ./Modelfile
ollama run mario
&amp;gt;&amp;gt;&amp;gt; hi
Hello! It's your friend Mario.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information on working with a Modelfile, see the &lt;a href="https://raw.githubusercontent.com/ollama/ollama/main/docs/modelfile.md"&gt;Modelfile&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;CLI Reference&lt;/h2&gt; 
&lt;h3&gt;Create a model&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama create&lt;/code&gt; is used to create a model from a Modelfile.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama create mymodel -f ./Modelfile
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Pull a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This command can also be used to update a local model. Only the diff will be pulled.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Remove a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama rm llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Copy a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama cp llama3.2 my-model
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiline input&lt;/h3&gt; 
&lt;p&gt;For multiline input, you can wrap text with &lt;code&gt;"""&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; """Hello,
... world!
... """
I'm a basic program that prints the famous "Hello, world!" message to the console.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multimodal models&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ollama run llava "What's in this image? /Users/jmorgan/Desktop/smile.png"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: The image features a yellow smiley face, which is likely the central focus of the picture.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Pass the prompt as an argument&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run llama3.2 "Summarize this file: $(cat README.md)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Show model information&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama show llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List models on your computer&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List which models are currently loaded&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama ps
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Stop a model which is currently running&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama stop llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama serve&lt;/code&gt; is used when you want to start ollama without running the desktop application.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/ollama/ollama/raw/main/docs/development.md"&gt;developer guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Running local builds&lt;/h3&gt; 
&lt;p&gt;Next, start the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, in a separate shell, run a model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama run llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;REST API&lt;/h2&gt; 
&lt;p&gt;Ollama has a REST API for running and managing models.&lt;/p&gt; 
&lt;h3&gt;Generate a response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt":"Why is the sky blue?"
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chat with a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2",
  "messages": [
    { "role": "user", "content": "why is the sky blue?" }
  ]
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/ollama/ollama/main/docs/api.md"&gt;API documentation&lt;/a&gt; for all endpoints.&lt;/p&gt; 
&lt;h2&gt;Community Integrations&lt;/h2&gt; 
&lt;h3&gt;Web &amp;amp; Desktop&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/open-webui/open-webui"&gt;Open WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat (macOS with ReactNative)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted (macOS native)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fmaclen/hollama"&gt;Hollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ParisNeo/lollms-webui"&gt;Lollms-Webui&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danny-avila/LibreChat"&gt;LibreChat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bionic-gpt/bionic-gpt"&gt;Bionic GPT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rtcfirefly/ollama-ui"&gt;HTML UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jikkuatwork/saddle"&gt;Saddle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tagspaces.org"&gt;TagSpaces&lt;/a&gt; (A platform for file-based apps, &lt;a href="https://docs.tagspaces.org/ai/"&gt;utilizing Ollama&lt;/a&gt; for the generation of tags and descriptions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivanfioravanti/chatbot-ollama"&gt;Chatbot UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mckaywrigley/chatbot-ui"&gt;Chatbot UI v2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file"&gt;Typescript UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richawo/minimal-llm-ui"&gt;Minimalistic React UI for Ollama Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/Ollamac"&gt;Ollamac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enricoros/big-AGI"&gt;big-AGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cheshire-cat-ai/core"&gt;Cheshire Cat assistant framework&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/semperai/amica"&gt;Amica&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BruceMacD/chatd"&gt;chatd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kghandour/Ollama-SwiftUI"&gt;Ollama-SwiftUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify"&gt;Dify.AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mindmac.app"&gt;MindMac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakobhoeg/nextjs-ollama-llm-ui"&gt;NextJS Web Interface for Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://msty.app"&gt;Msty&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Bin-Huang/Chatbox"&gt;Chatbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tgraupmann/WinForm_Ollama_Copilot"&gt;WinForm Ollama Copilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web"&gt;NextChat&lt;/a&gt; with &lt;a href="https://docs.nextchat.dev/models/ollama"&gt;Get Started Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmo80/alpaca-webui"&gt;Alpaca WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enoch1118/ollamaGUI"&gt;OllamaGUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InternLM/OpenAOE"&gt;OpenAOE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/leonid20000/OdinRunes"&gt;Odin Runes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mrdjohnson/llm-x"&gt;LLM-X&lt;/a&gt; (Progressive Web App)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mintplex-Labs/anything-llm"&gt;AnythingLLM (Docker + MacOs/Windows/Linux native app)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_basic_chat"&gt;Ollama Basic Chat: Uses HyperDiv Reactive UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drazdra/ollama-chats"&gt;Ollama-chats RPG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://intellibar.app/"&gt;IntelliBar&lt;/a&gt; (AI-powered assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/jirapt"&gt;Jirapt&lt;/a&gt; (Jira Integration to generate issues, tasks, epics)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/ojira"&gt;ojira&lt;/a&gt; (Jira chrome plugin to easily generate descriptions for tasks)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/QA-Pilot"&gt;QA-Pilot&lt;/a&gt; (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sugarforever/chat-ollama"&gt;ChatOllama&lt;/a&gt; (Open Source Chatbot based on Ollama with Knowledge Bases)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Nagi-ovo/CRAG-Ollama-Chat"&gt;CRAG Ollama Chat&lt;/a&gt; (Simple Web Search with Corrective RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; (Open-source Retrieval-Augmented Generation engine based on deep document understanding)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold"&gt;StreamDeploy&lt;/a&gt; (LLM Application Scaffold)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/swuecho/chat"&gt;chat&lt;/a&gt; (chat web app for teams)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/lobe-chat"&gt;Lobe Chat&lt;/a&gt; with &lt;a href="https://lobehub.com/docs/self-hosting/examples/ollama"&gt;Integrating Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/datvodinh/rag-chatbot.git"&gt;Ollama RAG Chatbot&lt;/a&gt; (Local Chat with multiple PDFs using Ollama and RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;BrainSoup&lt;/a&gt; (Flexible native client with RAG &amp;amp; multi-agent automation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Renset/macai"&gt;macai&lt;/a&gt; (macOS client for Ollama, ChatGPT, and other compatible API back-ends)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/RWKV-Runner"&gt;RWKV-Runner&lt;/a&gt; (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dezoito/ollama-grid-search"&gt;Ollama Grid Search&lt;/a&gt; (app to evaluate and compare models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Otacon/olpaka"&gt;Olpaka&lt;/a&gt; (User-friendly Flutter Web App for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://casibase.org"&gt;Casibase&lt;/a&gt; (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CrazyNeil/OllamaSpring"&gt;OllamaSpring&lt;/a&gt; (Ollama Client for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kartikm7/llocal"&gt;LLocal.in&lt;/a&gt; (Easy to use Electron Desktop Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dcSpark/shinkai-apps"&gt;Shinkai Desktop&lt;/a&gt; (Two click install Local AI using Ollama + Files + RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeyoyt/ailama"&gt;AiLama&lt;/a&gt; (A Discord User App that allows you to interact with Ollama anywhere in Discord)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_mesop/"&gt;Ollama with Google Mesop&lt;/a&gt; (Mesop Chat Client implementation with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SciPhi-AI/R2R"&gt;R2R&lt;/a&gt; (Open-source RAG engine)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/elearningshow/ollama-kis"&gt;Ollama-Kis&lt;/a&gt; (A simple easy-to-use GUI with sample custom LLM for Drivers Education)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opengpa.org"&gt;OpenGPA&lt;/a&gt; (Open-source offline-first Enterprise Agentic Application)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mateuszmigas/painting-droid"&gt;Painting Droid&lt;/a&gt; (Painting app with AI integrations)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.kerlig.com/"&gt;Kerlig AI&lt;/a&gt; (AI writing assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MindWorkAI/AI-Studio"&gt;AI Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gyopak/sidellama"&gt;Sidellama&lt;/a&gt; (browser-based LLM client)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trypromptly/LLMStack"&gt;LLMStack&lt;/a&gt; (No-code multi-agent framework to build LLM agents and workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://boltai.com"&gt;BoltAI for Mac&lt;/a&gt; (AI Chat Client for Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/av/harbor"&gt;Harbor&lt;/a&gt; (Containerized LLM Toolkit with Ollama as default backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/szczyglis-dev/py-gpt"&gt;PyGPT&lt;/a&gt; (AI desktop assistant for Linux, Windows, and Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jeffser/Alpaca"&gt;Alpaca&lt;/a&gt; (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Significant-Gravitas/AutoGPT/raw/master/docs/content/platform/ollama.md"&gt;AutoGPT&lt;/a&gt; (AutoGPT Ollama integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.jonathanhecl.com/go-crew/"&gt;Go-CREW&lt;/a&gt; (Powerful Offline RAG in Golang)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvmp/partcad/"&gt;PartCAD&lt;/a&gt; (CAD model generation with OpenSCAD and CadQuery)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j-web-ui"&gt;Ollama4j Web UI&lt;/a&gt; - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kspviswa/pyOllaMx"&gt;PyOllaMx&lt;/a&gt; - macOS application capable of chatting with both Ollama and Apple MLX models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cline/cline"&gt;Cline&lt;/a&gt; - Formerly known as Claude Dev is a VSCode extension for multi-file/whole-repo coding&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kangfenmao/cherry-studio"&gt;Cherry Studio&lt;/a&gt; (Desktop client with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nickthecook/archyve"&gt;Archyve&lt;/a&gt; (RAG-enabling document library)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama-crew-mesop"&gt;crewAI with Mesop&lt;/a&gt; (Mesop Web Interface to run crewAI with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chyok/ollama-gui"&gt;Tkinter-based client&lt;/a&gt; (Python tkinter-based Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trendy-design/llmchat"&gt;LLMChat&lt;/a&gt; (Privacy focused, 100% local, intuitive all-in-one chat interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Leon-Sander/Local-Multimodal-AI-Chat"&gt;Local Multimodal AI Chat&lt;/a&gt; (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xark-argo/argo"&gt;ARGO&lt;/a&gt; (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EliasPereirah/OrionChat"&gt;OrionChat&lt;/a&gt; - OrionChat is a web interface for chatting with different AI providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bklieger-groq/g1"&gt;G1&lt;/a&gt; (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lemonit-eric-mao/ollama-web-management"&gt;Web management&lt;/a&gt; (Web management page)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/promptery/promptery"&gt;Promptery&lt;/a&gt; (desktop client for Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/annilq/chat-ollama"&gt;chat-ollama&lt;/a&gt; (a React Native client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/spacellama"&gt;SpaceLlama&lt;/a&gt; (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/youlama"&gt;YouLama&lt;/a&gt; (Webapp to quickly summarize any YouTube video, supporting Invidious as well)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/dualmind"&gt;DualMind&lt;/a&gt; (Experimental app allowing two models to talk to each other in the terminal or in a web interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/h1ddenpr0cess20/ollamarama-matrix"&gt;ollamarama-matrix&lt;/a&gt; (Ollama chatbot for the Matrix chat protocol)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anan1213095357/ollama-chat-app"&gt;ollama-chat-app&lt;/a&gt; (Flutter-based chat app)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.perfectmemory.ai/"&gt;Perfect Memory AI&lt;/a&gt; (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hexastack/hexabot"&gt;Hexabot&lt;/a&gt; (A conversational AI builder)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/reddit_analyzer"&gt;Reddit Rate&lt;/a&gt; (Search and Rate Reddit topics with a weighted summation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/OpenTalkGpt"&gt;OpenTalkGpt&lt;/a&gt; (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vinhnx/vt.ai"&gt;VT&lt;/a&gt; (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nosia-ai/nosia"&gt;Nosia&lt;/a&gt; (Easy to install and use RAG platform based on Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/witsy"&gt;Witsy&lt;/a&gt; (An AI Desktop application available for Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/US-Artificial-Intelligence/abbey"&gt;Abbey&lt;/a&gt; (A configurable AI interface server with notebooks, document storage, and YouTube support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmayboroda/minima"&gt;Minima&lt;/a&gt; (RAG with on-premises or fully local workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AidfulAI/aidful-ollama-model-delete"&gt;aidful-ollama-model-delete&lt;/a&gt; (User interface for simplified model cleanup)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ItzCrazyKns/Perplexica"&gt;Perplexica&lt;/a&gt; (An AI-powered search engine &amp;amp; an open-source alternative to Perplexity AI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oslook/ollama-webui"&gt;Ollama Chat WebUI for Docker &lt;/a&gt; (Support for local docker deployment, lightweight ollama webui)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-tooklit/ollama-docs"&gt;AI Toolkit for Visual Studio Code&lt;/a&gt; (Microsoft-official VSCode extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anilkay/MinimalNextOllamaChat"&gt;MinimalNextOllamaChat&lt;/a&gt; (Minimal Web UI for Chat and Model Control)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TilmanGriesel/chipper"&gt;Chipper&lt;/a&gt; AI interface for tinkerers (Ollama, Haystack RAG, Python)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CosmicEventHorizon/ChibiChat"&gt;ChibiChat&lt;/a&gt; (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qusaismael/localllm"&gt;LocalLLM&lt;/a&gt; (Minimal Web-App to run ollama models on it with a GUI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/buiducnhat/ollamazing"&gt;Ollamazing&lt;/a&gt; (Web extension to run Ollama models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/benhaotang/OpenDeepResearcher-via-searxng"&gt;OpenDeepResearcher-via-searxng&lt;/a&gt; (A Deep Research equivalent endpoint with Ollama support for running locally)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AIDotNet/AntSK"&gt;AntSK&lt;/a&gt; (Out-of-the-box &amp;amp; Adaptable RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; (Ready-to-use &amp;amp; flexible RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danielekp/yla"&gt;yla&lt;/a&gt; (Web interface to freely interact with your customized models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RockChinQ/LangBot"&gt;LangBot&lt;/a&gt; (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/1Panel/"&gt;1Panel&lt;/a&gt; (Web-based Linux Server Management Tool)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Soulter/AstrBot/"&gt;AstrBot&lt;/a&gt; (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aharon-Bensadoun/Flufy"&gt;Flufy&lt;/a&gt; (A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeozeozeo/ellama"&gt;Ellama&lt;/a&gt; (Friendly native app to chat with an Ollama instance)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mediar-ai/screenpipe"&gt;screenpipe&lt;/a&gt; Build agents powered by your screen history&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hengkysteen/ollamb"&gt;Ollamb&lt;/a&gt; (Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the &lt;a href="https://hengkysteen.github.io/demo/ollamb/"&gt;web demo&lt;/a&gt;.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Writeopia/Writeopia"&gt;Writeopia&lt;/a&gt; (Text editor with integration with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AppFlowy-IO/AppFlowy"&gt;AppFlowy&lt;/a&gt; (AI collaborative workspace with Ollama, cross-platform and self-hostable)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cushydigit/lumina.git"&gt;Lumina&lt;/a&gt; (A lightweight, minimal React.js frontend for interacting with Ollama servers)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/tiny-notepad"&gt;Tiny Notepad&lt;/a&gt; (A lightweight, notepad-like interface to chat with ollama available on PyPI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hellotunamayo/macLlama"&gt;macLlama (macOS native)&lt;/a&gt; (A native macOS GUI application for interacting with Ollama models, featuring a chat interface.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philberndt/GPTranslate"&gt;GPTranslate&lt;/a&gt; (A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NGC13009/ollama-launcher"&gt;ollama launcher&lt;/a&gt; (A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aj-Seven/ai-hub"&gt;ai-hub&lt;/a&gt; (AI Hub supports multiple models via API keys and Chat support via Ollama API.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/mayan-edms/mayan-edms"&gt;Mayan EDMS&lt;/a&gt; (Open source document management system to organize, tag, search, and automate your files with powerful Ollama driven workflows.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/doolijb/serene-pub"&gt;Serene Pub&lt;/a&gt; (Beginner friendly, open source AI Roleplaying App for Windows, Mac OS and Linux. Search, download and use models with Ollama all inside the app.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aqerd/andes"&gt;Andes&lt;/a&gt; (A Visual Studio Code extension that provides a local UI interface for Ollama models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KashyapTan/clueless"&gt;Clueless&lt;/a&gt; (Open Source &amp;amp; Local Cluely: A desktop application LLM assistant to help you talk to anything on your screen using locally served Ollama models. Also undetectable to screenshare)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/carbonatedWaterOrg/ollama-co2"&gt;ollama-co2&lt;/a&gt; (FastAPI web interface for monitoring and managing local and remote Ollama servers with real-time model monitoring and concurrent downloads)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama"&gt;Google Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fly.io/docs/python/do-more/add-ollama/"&gt;Fly.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.koyeb.com/deploy/ollama"&gt;Koyeb&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Terminal&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggozad/oterm"&gt;oterm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/s-kostyaev/ellama"&gt;Ellama Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zweifisch/ollama"&gt;Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paradoxical-dev/neollama"&gt;neollama&lt;/a&gt; UI client for interacting with models from within Neovim&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/David-Kunz/gen.nvim"&gt;gen.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nomnivore/ollama.nvim"&gt;ollama.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marco-souza/ollero.nvim"&gt;ollero.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gerazov/ollama-chat.nvim"&gt;ollama-chat.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huynle/ogpt.nvim"&gt;ogpt.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karthink/gptel"&gt;gptel Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dustinblackman/oatmeal"&gt;Oatmeal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pgibler/cmdh"&gt;cmdh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/npahlfer/ooo"&gt;ooo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/shell-pilot"&gt;shell-pilot&lt;/a&gt;(Interact with models via pure shell scripts on Linux or macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pythops/tenere"&gt;tenere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taketwo/llm-ollama"&gt;llm-ollama&lt;/a&gt; for &lt;a href="https://llm.datasette.io/en/stable/"&gt;Datasette's LLM CLI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anaisbetts/typechat-cli"&gt;typechat-cli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djcopley/ShellOracle"&gt;ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yusufcanb/tlm"&gt;tlm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ericcurtin/podman-ollama"&gt;podman-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/gollama"&gt;gollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paulrobello/parllama"&gt;ParLlama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cognitivetech/ollama-ebook-summary/"&gt;Ollama eBook Summary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_moe"&gt;Ollama Mixture of Experts (MOE) in 50 lines of code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepo-ec/vim-intelligence-bridge"&gt;vim-intelligence-bridge&lt;/a&gt; Simple interaction of "Ollama" with the Vim editor&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x-cmd.com/mod/ollama"&gt;x-cmd ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drunkwcodes/bb7"&gt;bb7&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcusziade/Swollama"&gt;SwollamaCLI&lt;/a&gt; bundled with the Swollama Swift package. &lt;a href="https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sigoden/aichat"&gt;aichat&lt;/a&gt; All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools &amp;amp; agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rrg92/powershai"&gt;PowershAI&lt;/a&gt; PowerShell module that brings AI to terminal on Windows, including support for Ollama&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abyss-c0re/deepshell"&gt;DeepShell&lt;/a&gt; Your self-hosted AI assistant. Interactive Shell, Files and Folders analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/orbiton"&gt;orbiton&lt;/a&gt; Configuration-free text editor and IDE with support for tab completion with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/molbal/orca-cli"&gt;orca-cli&lt;/a&gt; Ollama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gguf-to-ollama"&gt;GGUF-to-Ollama&lt;/a&gt; - Importing GGUF to Ollama made easy (multiplatform)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_strands"&gt;AWS-Strands-With-Ollama&lt;/a&gt; - AWS Strands Agents with Ollama Examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-multirun"&gt;ollama-multirun&lt;/a&gt; - A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. (&lt;a href="https://attogram.github.io/ai_test_zone/"&gt;Demo&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-bash-toolshed"&gt;ollama-bash-toolshed&lt;/a&gt; - Bash scripts to chat with tool using models. Add new tools to your shed with ease. Runs on Ollama.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Apple Vision Pro&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Cross-platform AI chat app supporting Apple Vision Pro via "Designed for iPad")&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/timescale/pgai"&gt;pgai&lt;/a&gt; - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/timescale/pgai/raw/main/docs/vectorizer-quick-start.md"&gt;Get started guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mindsdb/mindsdb/raw/staging/mindsdb/integrations/handlers/ollama_handler/README.md"&gt;MindsDB&lt;/a&gt; (Connects Ollama models with nearly 200 data platforms and apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philippgille/chromem-go/raw/v0.5.0/embed_ollama.go"&gt;chromem-go&lt;/a&gt; with &lt;a href="https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbkangaroo/kangaroo"&gt;Kangaroo&lt;/a&gt; (AI-powered SQL client and admin tool for popular databases)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Package managers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://archlinux.org/packages/extra/x86_64/ollama/"&gt;Pacman&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gentoo/guru/tree/master/app-misc/ollama"&gt;Gentoo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://formulae.brew.sh/formula/ollama"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://artifacthub.io/packages/helm/ollama-helm/ollama"&gt;Helm Chart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeberg.org/tusharhero/ollama-guix"&gt;Guix channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://search.nixos.org/packages?show=ollama&amp;amp;from=0&amp;amp;size=50&amp;amp;sort=relevance&amp;amp;type=packages&amp;amp;query=ollama"&gt;Nix package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://flox.dev/blog/ollama-part-one"&gt;Flox&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain&lt;/a&gt; and &lt;a href="https://js.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain.js&lt;/a&gt; with &lt;a href="https://js.langchain.com/docs/tutorials/local_rag/"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://firebase.google.com/docs/genkit/plugins/ollama"&gt;Firebase Genkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI"&gt;crewAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://remembersoftwares.github.io/yacana/"&gt;Yacana&lt;/a&gt; (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/spring-projects/spring-ai"&gt;Spring AI&lt;/a&gt; with &lt;a href="https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html"&gt;reference&lt;/a&gt; and &lt;a href="https://github.com/tzolov/ollama-tools"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tmc/langchaingo/"&gt;LangChainGo&lt;/a&gt; with &lt;a href="https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain4j/langchain4j"&gt;LangChain4j&lt;/a&gt; with &lt;a href="https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abraxas-365/langchain-rust"&gt;LangChainRust&lt;/a&gt; with &lt;a href="https://github.com/Abraxas-365/langchain-rust/raw/main/examples/llm_ollama.rs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tryAGI/LangChain"&gt;LangChain for .NET&lt;/a&gt; with &lt;a href="https://github.com/tryAGI/LangChain/raw/main/examples/LangChain.Samples.OpenAI/Program.cs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama"&gt;LLPhant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.llamaindex.ai/en/stable/examples/llm/ollama/"&gt;LlamaIndex&lt;/a&gt; and &lt;a href="https://ts.llamaindex.ai/modules/llms/available_llms/ollama"&gt;LlamaIndexTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BerriAI/litellm"&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/presbrey/ollamafarm"&gt;OllamaFarm for Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/awaescher/OllamaSharp"&gt;OllamaSharp for .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gbaptista/ollama-ai"&gt;Ollama for Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepperoni21/ollama-rs"&gt;Ollama-rs for Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jmont-dev/ollama-hpp"&gt;Ollama-hpp for C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j"&gt;Ollama4j for Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://modelfusion.dev/integration/model-provider/ollama"&gt;ModelFusion Typescript Library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/OllamaKit"&gt;OllamaKit for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/breitburg/dart-ollama"&gt;Ollama for Dart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudstudio/ollama-laravel"&gt;Ollama for Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/davidmigloz/langchain_dart"&gt;LangChainDart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama"&gt;Semantic Kernel - Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepset-ai/haystack-integrations/raw/main/integrations/ollama.md"&gt;Haystack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brainlid/langchain"&gt;Elixir LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JBGruber/rollama"&gt;Ollama for R - rollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hauselin/ollama-r"&gt;Ollama for R - ollama-r&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lebrunel/ollama-ex"&gt;Ollama-ex for Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/b-tocs/abap_btocs_ollama"&gt;Ollama Connector for SAP ABAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://testcontainers.com/modules/ollama/"&gt;Testcontainers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://portkey.ai/docs/welcome/integration-guides/ollama"&gt;Portkey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/svilupp/PromptingTools.jl"&gt;PromptingTools.jl&lt;/a&gt; with an &lt;a href="https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Project-Llama/llamascript"&gt;LlamaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/emirsahin1/llm-axe"&gt;llm-axe&lt;/a&gt; (Python Toolkit for Building LLM Powered Apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.gollm.co/examples/ollama-example"&gt;Gollm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gollama"&gt;Gollama for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/ollamaclient"&gt;Ollamaclient for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/tozd/go/fun"&gt;High-level function abstraction in Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArdaGnsrn/ollama-php"&gt;Ollama PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/agents-flex/agents-flex"&gt;Agents-Flex for Java&lt;/a&gt; with &lt;a href="https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/parakeet-nest/parakeet"&gt;Parakeet&lt;/a&gt; is a GoLang library, made to simplify the development of small generative AI applications with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andygill/haverscript"&gt;Haverscript&lt;/a&gt; with &lt;a href="https://github.com/andygill/haverscript/tree/main/examples"&gt;examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mattt/ollama-swift"&gt;Ollama for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcusziade/Swollama"&gt;Swollama for Swift&lt;/a&gt; with &lt;a href="https://marcusziade.github.io/Swollama/documentation/swollama/"&gt;DocC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/prasad89/golamify"&gt;GoLamify&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharad/ollama-haskell"&gt;Ollama for Haskell&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/multi-llm-ts"&gt;multi-llm-ts&lt;/a&gt; (A Typescript/JavaScript library allowing access to different LLM in a unified API)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lofcz/llmtornado"&gt;LlmTornado&lt;/a&gt; (C# library providing a unified interface for major FOSS &amp;amp; Commercial inference APIs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dravenk/ollama-zig"&gt;Ollama for Zig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lunary-ai/abso"&gt;Abso&lt;/a&gt; (OpenAI-compatible TypeScript SDK for any LLM provider)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/goodreasonai/nichey"&gt;Nichey&lt;/a&gt; is a Python package for generating custom wikis for your research topic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kassane/ollama-d"&gt;Ollama for D&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/OllamaPlusPlus"&gt;OllamaPlusPlus&lt;/a&gt; (Very simple C++ library for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mozilla-ai/any-llm"&gt;any-llm&lt;/a&gt; (A single interface to use different llm providers by &lt;a href="https://www.mozilla.ai/"&gt;mozilla.ai&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mozilla-ai/any-agent"&gt;any-agent&lt;/a&gt; (A single interface to use and evaluate different agent frameworks by &lt;a href="https://www.mozilla.ai/"&gt;mozilla.ai&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cognizant-ai-lab/neuro-san-studio"&gt;Neuro SAN&lt;/a&gt; (Data-driven multi-agent orchestration framework) with &lt;a href="https://github.com/cognizant-ai-lab/neuro-san-studio/raw/main/docs/user_guide.md#ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ai-bot-pro/achatbot-go"&gt;achatbot-go&lt;/a&gt; a multimodal(text/audio/image) chatbot.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mobile&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mobile-Artificial-Intelligence/maid"&gt;Maid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sunshine0523/OllamaServer"&gt;Ollama Android Chat&lt;/a&gt; (No need for Termux, start the Ollama service with one click on an Android device)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extensions &amp;amp; Plugins&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MassimilianoPasquini97/raycast_ollama"&gt;Raycast extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mxyng/discollama"&gt;Discollama&lt;/a&gt; (Discord bot inside the Ollama discord channel)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/continuedev/continue"&gt;Continue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thewh1teagle/vibe"&gt;Vibe&lt;/a&gt; (Transcribe and analyze meetings with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hinterdupfinger/obsidian-ollama"&gt;Obsidian Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/omagdy7/ollama-logseq"&gt;Logseq Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andersrex/notesollama"&gt;NotesOllama&lt;/a&gt; (Apple Notes Ollama plugin)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/samalba/dagger-chatbot"&gt;Dagger Chatbot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mekb-turtle/discord-ai-bot"&gt;Discord AI Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ruecat/ollama-telegram"&gt;Ollama Telegram Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ej52/hass-ollama-conversation"&gt;Hass Ollama Conversation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abrenneke/rivet-plugin-ollama"&gt;Rivet plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/longy2k/obsidian-bmo-chatbot"&gt;Obsidian BMO Chatbot plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/herval/cliobot"&gt;Cliobot&lt;/a&gt; (Telegram bot with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/logancyang/obsidian-copilot"&gt;Copilot for Obsidian plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pfrankov/obsidian-local-gpt"&gt;Obsidian Local GPT plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openinterpreter.com/language-model-setup/local-models/ollama"&gt;Open Interpreter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ex3ndr/llama-coder"&gt;Llama Coder&lt;/a&gt; (Copilot alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bernardo-bruning/ollama-copilot"&gt;Ollama Copilot&lt;/a&gt; (Proxy that allows you to use Ollama as a copilot like GitHub Copilot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rjmacarthy/twinny"&gt;twinny&lt;/a&gt; (Copilot and Copilot chat alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RussellCanfield/wingman-ai"&gt;Wingman-AI&lt;/a&gt; (Copilot code and chat alternative using Ollama and Hugging Face)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n4ze3m/page-assist"&gt;Page Assist&lt;/a&gt; (Chrome Extension)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imoize/plasmoid-ollamacontrol"&gt;Plasmoid Ollama Control&lt;/a&gt; (KDE Plasma extension that allows you to quickly manage/control Ollama model)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharhero/aitelegrambot"&gt;AI Telegram Bot&lt;/a&gt; (Telegram bot using Ollama in backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yaroslavyaroslav/OpenAI-sublime-text"&gt;AI ST Completion&lt;/a&gt; (Sublime Text 4 AI assistant plugin with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinthedang/discord-ollama"&gt;Discord-Ollama Chat Bot&lt;/a&gt; (Generalized TypeScript Discord Bot w/ Tuning Documentation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/chatGPTBox"&gt;ChatGPTBox: All in one browser extension&lt;/a&gt; with &lt;a href="https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467"&gt;Integrating Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapmd73/Companion"&gt;Discord AI chat/moderation bot&lt;/a&gt; Chat/moderation bot written in python. Uses Ollama to create personalities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nischalj10/headless-ollama"&gt;Headless Ollama&lt;/a&gt; (Scripts to automatically install ollama client &amp;amp; models on any OS for apps that depend on ollama server)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xuyangbocn/terraform-aws-self-host-llm"&gt;Terraform AWS Ollama &amp;amp; Open WebUI&lt;/a&gt; (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakubburkiewicz/node-red-contrib-ollama"&gt;node-red-contrib-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivostoykov/localAI"&gt;Local AI Helper&lt;/a&gt; (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jake83741/vnc-lm"&gt;vnc-lm&lt;/a&gt; (Discord bot for messaging with LLMs through Ollama and LiteLLM. Seamlessly move between local and flagship models.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SilasMarvin/lsp-ai"&gt;LSP-AI&lt;/a&gt; (Open-source language server for AI-powered functionality)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Palm1r/QodeAssist"&gt;QodeAssist&lt;/a&gt; (AI-powered coding assistant plugin for Qt Creator)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ECuiDev/obsidian-quiz-generator"&gt;Obsidian Quiz Generator plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philffm/ai-summary-helper"&gt;AI Summmary Helper plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/suncloudsmoon/TextCraft"&gt;TextCraft&lt;/a&gt; (Copilot in Word alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeitlings/alfred-ollama"&gt;Alfred Ollama&lt;/a&gt; (Alfred Workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/TextLLaMA"&gt;TextLLaMA&lt;/a&gt; A Chrome Extension that helps you write emails, correct grammar, and translate into any language&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zyphixor/simple-discord-ai"&gt;Simple-Discord-AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/innightwolfsleep/llm_telegram_bot"&gt;LLM Telegram Bot&lt;/a&gt; (telegram bot, primary for RP. Oobabooga-like buttons, &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;A1111&lt;/a&gt; API integration e.t.c)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/mcp-llm"&gt;mcp-llm&lt;/a&gt; (MCP Server to allow LLMs to call other LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/SimpleOllamaUnity"&gt;SimpleOllamaUnity&lt;/a&gt; (Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/UnityCodeLama"&gt;UnityCodeLama&lt;/a&gt; (Unity Edtior tool to analyze scripts via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NativeMindBrowser/NativeMindExtension"&gt;NativeMind&lt;/a&gt; (Private, on-device AI Assistant, no cloud dependencies)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gmai.premex.se/"&gt;GMAI - Gradle Managed AI&lt;/a&gt; (Gradle plugin for automated Ollama lifecycle management during build phases)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nomyo-ai/nomyo-router"&gt;NOMYO Router&lt;/a&gt; (A transparent Ollama proxy with model deployment aware routing which auto-manages multiple Ollama instances in a given network)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported backends&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp&lt;/a&gt; project founded by Georgi Gerganov.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Observability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.comet.com/docs/opik/cookbook/ollama"&gt;Opik&lt;/a&gt; is an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native intergration to Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lunary.ai/docs/integrations/ollama"&gt;Lunary&lt;/a&gt; is the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openlit/openlit"&gt;OpenLIT&lt;/a&gt; is an OpenTelemetry-native tool for monitoring Ollama Applications &amp;amp; GPUs using traces and metrics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.honeyhive.ai/integrations/ollama"&gt;HoneyHive&lt;/a&gt; is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://langfuse.com/docs/integrations/ollama"&gt;Langfuse&lt;/a&gt; is an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing"&gt;MLflow Tracing&lt;/a&gt; is an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>jesseduffield/lazygit</title>
      <link>https://github.com/jesseduffield/lazygit</link>
      <description>&lt;p&gt;simple terminal UI for git commands&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.warp.dev/?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=lazygit_20231023"&gt; 
  &lt;div&gt; 
   &lt;img src="https://github.com/warpdotdev/brand-assets/raw/main/Github/Sponsor/Warp-Github-LG-02.png?raw=true" width="400" alt="Warp" /&gt; 
  &lt;/div&gt; &lt;b&gt;Warp, the intelligent terminal&lt;/b&gt; &lt;br /&gt; &lt;b&gt;Available for MacOS and Linux&lt;/b&gt; &lt;br /&gt; 
  &lt;div&gt; 
   &lt;sup&gt;Visit&amp;nbsp;warp.dev&amp;nbsp;to learn more.&lt;/sup&gt; 
  &lt;/div&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;hr /&gt; 
 &lt;a href="https://tuple.app/lazygit"&gt; 
  &lt;div&gt; 
   &lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/tuple.png" width="400" alt="Tuple" /&gt; 
  &lt;/div&gt; &lt;b&gt;Tuple, the premier screen sharing app for developers on macOS and Windows.&lt;/b&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;hr /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.subble.com"&gt; 
  &lt;div&gt; 
   &lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/subble.webp" width="400" alt="Subble" /&gt; 
  &lt;/div&gt; &lt;b&gt;I (Jesse) co-founded Subble to save your company time and money by finding unused and over-provisioned SaaS licences. Check it out!&lt;/b&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;img width="536" src="https://user-images.githubusercontent.com/8456633/174470852-339b5011-5800-4bb9-a628-ff230aa8cd4e.png" /&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;A simple terminal UI for git commands &lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/jesseduffield/lazygit/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/jesseduffield/lazygit/total" alt="GitHub Releases" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/jesseduffield/lazygit"&gt;&lt;img src="https://goreportcard.com/badge/github.com/jesseduffield/lazygit" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://app.codacy.com/gh/jesseduffield/lazygit/dashboard?utm_source=gh&amp;amp;utm_medium=referral&amp;amp;utm_content=&amp;amp;utm_campaign=Badge_grade"&gt;&lt;img src="https://app.codacy.com/project/badge/Grade/f46416b715d74622895657935fcada21" alt="Codacy Badge" /&gt;&lt;/a&gt; &lt;a href="https://app.codacy.com/gh/jesseduffield/lazygit/dashboard?utm_source=gh&amp;amp;utm_medium=referral&amp;amp;utm_content=&amp;amp;utm_campaign=Badge_coverage"&gt;&lt;img src="https://app.codacy.com/project/badge/Coverage/f46416b715d74622895657935fcada21" alt="Codacy Badge" /&gt;&lt;/a&gt; &lt;a href="https://golangci-lint.run/"&gt;&lt;img src="https://img.shields.io/badge/linted%20by-golangci--lint-brightgreen" alt="golangci-lint" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jesseduffield/lazygit/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/tag/jesseduffield/lazygit?color=blue" alt="GitHub tag" /&gt;&lt;/a&gt; &lt;a href="https://formulae.brew.sh/formula/lazygit"&gt;&lt;img src="https://img.shields.io/homebrew/v/lazygit?color=blue" alt="homebrew" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/commit_and_push-compressed.gif" alt="commit_and_push" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p align="center"&gt; Maintenance of this project is made possible by all the &lt;a href="https://github.com/jesseduffield/lazygit/graphs/contributors"&gt;contributors&lt;/a&gt; and &lt;a href="https://github.com/sponsors/jesseduffield"&gt;sponsors&lt;/a&gt;. If you'd like to sponsor this project and have your avatar or company logo appear below &lt;a href="https://github.com/sponsors/jesseduffield"&gt;click here&lt;/a&gt;. 💙 &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- sponsors --&gt;&lt;a href="https://github.com/intabulas"&gt;&lt;img src="https://github.com/intabulas.png" width="60px" alt="Mark Lussier" /&gt;&lt;/a&gt;&lt;a href="https://github.com/peppy"&gt;&lt;img src="https://github.com/peppy.png" width="60px" alt="Dean Herbert" /&gt;&lt;/a&gt;&lt;a href="https://github.com/piot"&gt;&lt;img src="https://github.com/piot.png" width="60px" alt="Peter Bjorklund" /&gt;&lt;/a&gt;&lt;a href="https://github.com/rgwood"&gt;&lt;img src="https://github.com/rgwood.png" width="60px" alt="Reilly Wood" /&gt;&lt;/a&gt;&lt;a href="https://github.com/oliverguenther"&gt;&lt;img src="https://github.com/oliverguenther.png" width="60px" alt="Oliver Günther" /&gt;&lt;/a&gt;&lt;a href="https://github.com/pawanjay176"&gt;&lt;img src="https://github.com/pawanjay176.png" width="60px" alt="Pawan Dhananjay" /&gt;&lt;/a&gt;&lt;a href="https://github.com/bdach"&gt;&lt;img src="https://github.com/bdach.png" width="60px" alt="Bartłomiej Dach" /&gt;&lt;/a&gt;&lt;a href="https://github.com/naoey"&gt;&lt;img src="https://github.com/naoey.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/carstengehling"&gt;&lt;img src="https://github.com/carstengehling.png" width="60px" alt="Carsten Gehling" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ceuk"&gt;&lt;img src="https://github.com/ceuk.png" width="60px" alt="CEUK" /&gt;&lt;/a&gt;&lt;a href="https://github.com/Xetera"&gt;&lt;img src="https://github.com/Xetera.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/HoldenLucas"&gt;&lt;img src="https://github.com/HoldenLucas.png" width="60px" alt="Holden Lucas" /&gt;&lt;/a&gt;&lt;a href="https://github.com/nartc"&gt;&lt;img src="https://github.com/nartc.png" width="60px" alt="Chau Tran" /&gt;&lt;/a&gt;&lt;a href="https://github.com/matejcik"&gt;&lt;img src="https://github.com/matejcik.png" width="60px" alt="matejcik" /&gt;&lt;/a&gt;&lt;a href="https://github.com/lucatume"&gt;&lt;img src="https://github.com/lucatume.png" width="60px" alt="theAverageDev (Luca Tumedei)" /&gt;&lt;/a&gt;&lt;a href="https://github.com/IvanZuy"&gt;&lt;img src="https://github.com/IvanZuy.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/nicholascloud"&gt;&lt;img src="https://github.com/nicholascloud.png" width="60px" alt="Nicholas Cloud" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ava1ar"&gt;&lt;img src="https://github.com/ava1ar.png" width="60px" alt="Aliaksandr Stelmachonak" /&gt;&lt;/a&gt;&lt;a href="https://github.com/minidfx"&gt;&lt;img src="https://github.com/minidfx.png" width="60px" alt="Burgy Benjamin" /&gt;&lt;/a&gt;&lt;a href="https://github.com/JoeKlemmer"&gt;&lt;img src="https://github.com/JoeKlemmer.png" width="60px" alt="Joe Klemmer" /&gt;&lt;/a&gt;&lt;a href="https://github.com/tobi"&gt;&lt;img src="https://github.com/tobi.png" width="60px" alt="Tobias Lütke" /&gt;&lt;/a&gt;&lt;a href="https://github.com/benbfortis"&gt;&lt;img src="https://github.com/benbfortis.png" width="60px" alt="Ben Beaumont" /&gt;&lt;/a&gt;&lt;a href="https://github.com/jakewarren"&gt;&lt;img src="https://github.com/jakewarren.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/tgpholly"&gt;&lt;img src="https://github.com/tgpholly.png" width="60px" alt="Holly" /&gt;&lt;/a&gt;&lt;a href="https://github.com/socketbox"&gt;&lt;img src="https://github.com/socketbox.png" width="60px" alt="Casey Boettcher" /&gt;&lt;/a&gt;&lt;a href="https://github.com/bitprophet"&gt;&lt;img src="https://github.com/bitprophet.png" width="60px" alt="Jeff Forcier" /&gt;&lt;/a&gt;&lt;a href="https://github.com/tayleighr"&gt;&lt;img src="https://github.com/tayleighr.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/Novakov"&gt;&lt;img src="https://github.com/Novakov.png" width="60px" alt="Maciej T. Nowak" /&gt;&lt;/a&gt;&lt;a href="https://github.com/nekhaevskiy"&gt;&lt;img src="https://github.com/nekhaevskiy.png" width="60px" alt="Yury" /&gt;&lt;/a&gt;&lt;a href="https://github.com/reivilibre"&gt;&lt;img src="https://github.com/reivilibre.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/andreaskurth"&gt;&lt;img src="https://github.com/andreaskurth.png" width="60px" alt="Andreas Kurth" /&gt;&lt;/a&gt;&lt;a href="https://github.com/BSteffaniak"&gt;&lt;img src="https://github.com/BSteffaniak.png" width="60px" alt="Braden Steffaniak" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ameddin73"&gt;&lt;img src="https://github.com/ameddin73.png" width="60px" alt="Alex Meddin" /&gt;&lt;/a&gt;&lt;a href="https://github.com/jordan-gillard"&gt;&lt;img src="https://github.com/jordan-gillard.png" width="60px" alt="Jordan Gillard" /&gt;&lt;/a&gt;&lt;a href="https://github.com/smangels"&gt;&lt;img src="https://github.com/smangels.png" width="60px" alt="Sebastian" /&gt;&lt;/a&gt;&lt;a href="https://github.com/amslezak"&gt;&lt;img src="https://github.com/amslezak.png" width="60px" alt="Andy Slezak" /&gt;&lt;/a&gt;&lt;a href="https://github.com/mkock"&gt;&lt;img src="https://github.com/mkock.png" width="60px" alt="Martin Kock" /&gt;&lt;/a&gt;&lt;a href="https://github.com/jessealama"&gt;&lt;img src="https://github.com/jessealama.png" width="60px" alt="Jesse Alama" /&gt;&lt;/a&gt;&lt;a href="https://github.com/danielkokott"&gt;&lt;img src="https://github.com/danielkokott.png" width="60px" alt="Daniel Kokott" /&gt;&lt;/a&gt;&lt;a href="https://github.com/heijmans"&gt;&lt;img src="https://github.com/heijmans.png" width="60px" alt="Jan Heijmans" /&gt;&lt;/a&gt;&lt;a href="https://github.com/knowald"&gt;&lt;img src="https://github.com/knowald.png" width="60px" alt="Kevin Nowald" /&gt;&lt;/a&gt;&lt;a href="https://github.com/omarluq"&gt;&lt;img src="https://github.com/omarluq.png" width="60px" alt="Omar Luq" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ethanjli"&gt;&lt;img src="https://github.com/ethanjli.png" width="60px" alt="Ethan Li" /&gt;&lt;/a&gt;&lt;a href="https://github.com/phubaba"&gt;&lt;img src="https://github.com/phubaba.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/logichaos"&gt;&lt;img src="https://github.com/logichaos.png" width="60px" alt="Maxi" /&gt;&lt;/a&gt;&lt;a href="https://github.com/neunkasulle"&gt;&lt;img src="https://github.com/neunkasulle.png" width="60px" alt="Jan Zenkner" /&gt;&lt;/a&gt;&lt;a href="https://github.com/RVxLab"&gt;&lt;img src="https://github.com/RVxLab.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/FrederickGeek8"&gt;&lt;img src="https://github.com/FrederickGeek8.png" width="60px" alt="Frederick Morlock" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ezdac"&gt;&lt;img src="https://github.com/ezdac.png" width="60px" alt="Maximilian Langenfeld" /&gt;&lt;/a&gt;&lt;a href="https://github.com/dbuls"&gt;&lt;img src="https://github.com/dbuls.png" width="60px" alt="Davis Buls" /&gt;&lt;/a&gt;&lt;a href="https://github.com/lppassos"&gt;&lt;img src="https://github.com/lppassos.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/neilcode"&gt;&lt;img src="https://github.com/neilcode.png" width="60px" alt="Neil Lambert" /&gt;&lt;/a&gt;&lt;a href="https://github.com/dhh"&gt;&lt;img src="https://github.com/dhh.png" width="60px" alt="David Heinemeier Hansson" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ethanfischer"&gt;&lt;img src="https://github.com/ethanfischer.png" width="60px" alt="Ethan Fischer" /&gt;&lt;/a&gt;&lt;a href="https://github.com/poshboytl"&gt;&lt;img src="https://github.com/poshboytl.png" width="60px" alt="Terry Tai" /&gt;&lt;/a&gt;&lt;a href="https://github.com/roesnera"&gt;&lt;img src="https://github.com/roesnera.png" width="60px" alt="Adam Roesner" /&gt;&lt;/a&gt;&lt;a href="https://github.com/seven1m"&gt;&lt;img src="https://github.com/seven1m.png" width="60px" alt="Tim Morgan" /&gt;&lt;/a&gt;&lt;a href="https://github.com/sgoridotla1"&gt;&lt;img src="https://github.com/sgoridotla1.png" width="60px" alt="Max Shypulniak" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ADIX7"&gt;&lt;img src="https://github.com/ADIX7.png" width="60px" alt="Kovács Ádám" /&gt;&lt;/a&gt;&lt;a href="https://github.com/slowdub"&gt;&lt;img src="https://github.com/slowdub.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/serranomorante"&gt;&lt;img src="https://github.com/serranomorante.png" width="60px" alt="Patricio Serrano" /&gt;&lt;/a&gt;&lt;a href="https://github.com/kiriDevs"&gt;&lt;img src="https://github.com/kiriDevs.png" width="60px" alt="Kiri" /&gt;&lt;/a&gt;&lt;a href="https://github.com/bjornevik"&gt;&lt;img src="https://github.com/bjornevik.png" width="60px" alt="John Even Bjørnevik" /&gt;&lt;/a&gt;&lt;a href="https://github.com/moberst"&gt;&lt;img src="https://github.com/moberst.png" width="60px" alt="Michael Oberst" /&gt;&lt;/a&gt;&lt;a href="https://github.com/stianh"&gt;&lt;img src="https://github.com/stianh.png" width="60px" alt="Stian Hegglund" /&gt;&lt;/a&gt;&lt;a href="https://github.com/adam-e-trepanier"&gt;&lt;img src="https://github.com/adam-e-trepanier.png" width="60px" alt="Adam Trepanier" /&gt;&lt;/a&gt;&lt;a href="https://github.com/arkalon76"&gt;&lt;img src="https://github.com/arkalon76.png" width="60px" alt="Kenth Fagerlund" /&gt;&lt;/a&gt;&lt;a href="https://github.com/Djuuu"&gt;&lt;img src="https://github.com/Djuuu.png" width="60px" alt="Julien Tardot" /&gt;&lt;/a&gt;&lt;a href="https://github.com/antikytheraton"&gt;&lt;img src="https://github.com/antikytheraton.png" width="60px" alt="Aaron Arredondo" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ellord"&gt;&lt;img src="https://github.com/ellord.png" width="60px" alt="Ellord Tayag" /&gt;&lt;/a&gt;&lt;a href="https://github.com/EdgarPost"&gt;&lt;img src="https://github.com/EdgarPost.png" width="60px" alt="Edgar Post-Buijs" /&gt;&lt;/a&gt;&lt;a href="https://github.com/sbc64"&gt;&lt;img src="https://github.com/sbc64.png" width="60px" alt="sbc64" /&gt;&lt;/a&gt;&lt;a href="https://github.com/caillou"&gt;&lt;img src="https://github.com/caillou.png" width="60px" alt="Pierre Spring" /&gt;&lt;/a&gt;&lt;a href="https://github.com/mebezac"&gt;&lt;img src="https://github.com/mebezac.png" width="60px" alt="Zac Clay" /&gt;&lt;/a&gt;&lt;a href="https://github.com/Tom94"&gt;&lt;img src="https://github.com/Tom94.png" width="60px" alt="Thomas Müller" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ccssmnn"&gt;&lt;img src="https://github.com/ccssmnn.png" width="60px" alt="Carl Assmann" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ognevsd"&gt;&lt;img src="https://github.com/ognevsd.png" width="60px" alt="Sergey Ognev" /&gt;&lt;/a&gt;&lt;a href="https://github.com/moodyhunter"&gt;&lt;img src="https://github.com/moodyhunter.png" width="60px" alt="Moody Liu" /&gt;&lt;/a&gt;&lt;a href="https://github.com/code-hunger"&gt;&lt;img src="https://github.com/code-hunger.png" width="60px" alt="Alex G" /&gt;&lt;/a&gt;&lt;a href="https://github.com/elithper"&gt;&lt;img src="https://github.com/elithper.png" width="60px" alt="Michael Howard" /&gt;&lt;/a&gt;&lt;a href="https://github.com/LasseBloch"&gt;&lt;img src="https://github.com/LasseBloch.png" width="60px" alt="Lasse Bloch Lauritsen" /&gt;&lt;/a&gt;&lt;a href="https://github.com/lmarburger"&gt;&lt;img src="https://github.com/lmarburger.png" width="60px" alt="Larry Marburger" /&gt;&lt;/a&gt;&lt;a href="https://github.com/dbrockman"&gt;&lt;img src="https://github.com/dbrockman.png" width="60px" alt="David Brockman" /&gt;&lt;/a&gt;&lt;a href="https://github.com/slavshik"&gt;&lt;img src="https://github.com/slavshik.png" width="60px" alt="Alexander Slavschik" /&gt;&lt;/a&gt;&lt;a href="https://github.com/aidalgol"&gt;&lt;img src="https://github.com/aidalgol.png" width="60px" alt="Aidan Gauland" /&gt;&lt;/a&gt;&lt;a href="https://github.com/mbienkowsk"&gt;&lt;img src="https://github.com/mbienkowsk.png" width="60px" alt="Maksym Bieńkowski" /&gt;&lt;/a&gt;&lt;a href="https://github.com/joshuawootonn"&gt;&lt;img src="https://github.com/joshuawootonn.png" width="60px" alt="Joshua Wootonn" /&gt;&lt;/a&gt;&lt;a href="https://github.com/I4nJ"&gt;&lt;img src="https://github.com/I4nJ.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/gurbindersingh"&gt;&lt;img src="https://github.com/gurbindersingh.png" width="60px" alt="Gurbinder Singh" /&gt;&lt;/a&gt;&lt;a href="https://github.com/sandviklee"&gt;&lt;img src="https://github.com/sandviklee.png" width="60px" alt="Simon Sandvik Lee" /&gt;&lt;/a&gt;&lt;a href="https://github.com/glagnar"&gt;&lt;img src="https://github.com/glagnar.png" width="60px" alt="Thomas Gilbert" /&gt;&lt;/a&gt;&lt;a href="https://github.com/skrzepto"&gt;&lt;img src="https://github.com/skrzepto.png" width="60px" alt="Szymon Mucha" /&gt;&lt;/a&gt;&lt;a href="https://github.com/TimShilov"&gt;&lt;img src="https://github.com/TimShilov.png" width="60px" alt="Tim Shilov" /&gt;&lt;/a&gt;&lt;a href="https://github.com/unnawut"&gt;&lt;img src="https://github.com/unnawut.png" width="60px" alt="Unnawut Leepaisalsuwanna" /&gt;&lt;/a&gt;&lt;a href="https://github.com/wortmanb"&gt;&lt;img src="https://github.com/wortmanb.png" width="60px" alt="Bret Wortman" /&gt;&lt;/a&gt;&lt;a href="https://github.com/andre-lameirinhas"&gt;&lt;img src="https://github.com/andre-lameirinhas.png" width="60px" alt="André Lameirinhas" /&gt;&lt;/a&gt;&lt;a href="https://github.com/SVappsLAB"&gt;&lt;img src="https://github.com/SVappsLAB.png" width="60px" alt="Scott Velez" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ooojustin"&gt;&lt;img src="https://github.com/ooojustin.png" width="60px" alt="justin" /&gt;&lt;/a&gt;&lt;a href="https://github.com/mayfieldiv"&gt;&lt;img src="https://github.com/mayfieldiv.png" width="60px" alt="Mayfield" /&gt;&lt;/a&gt;&lt;a href="https://github.com/somaholiday"&gt;&lt;img src="https://github.com/somaholiday.png" width="60px" alt="Soma Holiday" /&gt;&lt;/a&gt;
 &lt;!-- sponsors --&gt; &lt;/p&gt; 
&lt;h2&gt;Elevator Pitch&lt;/h2&gt; 
&lt;p&gt;Rant time: You've heard it before, git is &lt;em&gt;powerful&lt;/em&gt;, but what good is that power when everything is so damn hard to do? Interactive rebasing requires you to edit a goddamn TODO file in your editor? &lt;em&gt;Are you kidding me?&lt;/em&gt; To stage part of a file you need to use a command line program to step through each hunk and if a hunk can't be split down any further but contains code you don't want to stage, you have to edit an arcane patch file &lt;em&gt;by hand&lt;/em&gt;? &lt;em&gt;Are you KIDDING me?!&lt;/em&gt; Sometimes you get asked to stash your changes when switching branches only to realise that after you switch and unstash that there weren't even any conflicts and it would have been fine to just checkout the branch directly? &lt;em&gt;YOU HAVE GOT TO BE KIDDING ME!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;If you're a mere mortal like me and you're tired of hearing how powerful git is when in your daily life it's a powerful pain in your ass, lazygit might be for you.&lt;/p&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#sponsors"&gt;Sponsors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#elevator-pitch"&gt;Elevator Pitch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#table-of-contents"&gt;Table of contents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#stage-individual-lines"&gt;Stage individual lines&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#interactive-rebase"&gt;Interactive Rebase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#cherry-pick"&gt;Cherry-pick&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#bisect"&gt;Bisect&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#nuke-the-working-tree"&gt;Nuke the working tree&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#amend-an-old-commit"&gt;Amend an old commit&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#filter"&gt;Filter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#invoke-a-custom-command"&gt;Invoke a custom command&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#worktrees"&gt;Worktrees&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#rebase-magic-custom-patches"&gt;Rebase magic (custom patches)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#rebase-from-marked-base-commit"&gt;Rebase from marked base commit&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#undo"&gt;Undo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#commit-graph"&gt;Commit graph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#compare-two-commits"&gt;Compare two commits&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#installation"&gt;Installation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#binary-releases"&gt;Binary Releases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#dev-container-feature"&gt;Dev container&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#homebrew"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#macports"&gt;MacPorts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#void-linux"&gt;Void Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#scoop-windows"&gt;Scoop (Windows)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#arch-linux"&gt;Arch Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#fedora-and-rhel"&gt;Fedora and RHEL&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#solus-linux"&gt;Solus Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#debian-and-ubuntu"&gt;Debian and Ubuntu&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#funtoo-linux"&gt;Funtoo Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#gentoo-linux"&gt;Gentoo Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#freebsd"&gt;FreeBSD&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#termux"&gt;Termux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#conda"&gt;Conda&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#chocolatey-windows"&gt;Chocolatey (Windows)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#winget-windows-10-1709-or-later"&gt;Winget (Windows 10 1709 or later)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#manual"&gt;Manual&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#usage"&gt;Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#keybindings"&gt;Keybindings&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#changing-directory-on-exit"&gt;Changing Directory On Exit&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#undoredo"&gt;Undo/Redo&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#configuration"&gt;Configuration&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#custom-pagers"&gt;Custom Pagers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#custom-commands"&gt;Custom Commands&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#git-flow-support"&gt;Git flow support&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#contributing"&gt;Contributing&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#debugging-locally"&gt;Debugging Locally&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#donate"&gt;Donate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#faq"&gt;FAQ&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#what-do-the-commit-colors-represent"&gt;What do the commit colors represent?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#shameless-plug"&gt;Shameless Plug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#alternatives"&gt;Alternatives&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Lazygit is not my fulltime job but it is a hefty part time job so if you want to support the project please consider &lt;a href="https://github.com/sponsors/jesseduffield"&gt;sponsoring me&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Stage individual lines&lt;/h3&gt; 
&lt;p&gt;Press space on the selected line to stage it, or press &lt;code&gt;v&lt;/code&gt; to start selecting a range of lines. You can also press &lt;code&gt;a&lt;/code&gt; to select the entirety of the current hunk.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/stage_lines-compressed.gif" alt="stage_lines" /&gt;&lt;/p&gt; 
&lt;h3&gt;Interactive Rebase&lt;/h3&gt; 
&lt;p&gt;Press &lt;code&gt;i&lt;/code&gt; to start an interactive rebase. Then squash (&lt;code&gt;s&lt;/code&gt;), fixup (&lt;code&gt;f&lt;/code&gt;), drop (&lt;code&gt;d&lt;/code&gt;), edit (&lt;code&gt;e&lt;/code&gt;), move up (&lt;code&gt;ctrl+k&lt;/code&gt;) or move down (&lt;code&gt;ctrl+j&lt;/code&gt;) any of TODO commits, before continuing the rebase by bringing up the rebase options menu with &lt;code&gt;m&lt;/code&gt; and then selecting &lt;code&gt;continue&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also perform any these actions as a once-off (e.g. pressing &lt;code&gt;s&lt;/code&gt; on a commit to squash it) without explicitly starting a rebase.&lt;/p&gt; 
&lt;p&gt;This demo also uses shift+down to select a range of commits to move and fixup.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/interactive_rebase-compressed.gif" alt="interactive_rebase" /&gt;&lt;/p&gt; 
&lt;h3&gt;Cherry-pick&lt;/h3&gt; 
&lt;p&gt;Press &lt;code&gt;shift+c&lt;/code&gt; on a commit to copy it and press &lt;code&gt;shift+v&lt;/code&gt; to paste (cherry-pick) it.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/cherry_pick-compressed.gif" alt="cherry_pick" /&gt;&lt;/p&gt; 
&lt;h3&gt;Bisect&lt;/h3&gt; 
&lt;p&gt;Press &lt;code&gt;b&lt;/code&gt; in the commits view to mark a commit as good/bad in order to begin a git bisect.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/bisect-compressed.gif" alt="bisect" /&gt;&lt;/p&gt; 
&lt;h3&gt;Nuke the working tree&lt;/h3&gt; 
&lt;p&gt;For when you really want to just get rid of anything that shows up when you run &lt;code&gt;git status&lt;/code&gt; (and yes that includes dirty submodules) &lt;a href="https://www.youtube.com/watch?v=N4E2B_k2Bss"&gt;kidpix style&lt;/a&gt;, press &lt;code&gt;shift+d&lt;/code&gt; to bring up the reset options menu and then select the 'nuke' option.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/nuke_working_tree-compressed.gif" alt="Nuke working tree" /&gt;&lt;/p&gt; 
&lt;h3&gt;Amend an old commit&lt;/h3&gt; 
&lt;p&gt;Pressing &lt;code&gt;shift+a&lt;/code&gt; on any commit will amend that commit with the currently staged changes (running an interactive rebase in the background).&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/amend_old_commit-compressed.gif" alt="amend_old_commit" /&gt;&lt;/p&gt; 
&lt;h3&gt;Filter&lt;/h3&gt; 
&lt;p&gt;You can filter a view with &lt;code&gt;/&lt;/code&gt;. Here we filter down our branches view and then hit &lt;code&gt;enter&lt;/code&gt; to view its commits.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/filter-compressed.gif" alt="filter" /&gt;&lt;/p&gt; 
&lt;h3&gt;Invoke a custom command&lt;/h3&gt; 
&lt;p&gt;Lazygit has a very flexible &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Custom_Command_Keybindings.md"&gt;custom command system&lt;/a&gt;. In this example a custom command is defined which emulates the built-in branch checkout action.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/custom_command-compressed.gif" alt="custom_command" /&gt;&lt;/p&gt; 
&lt;h3&gt;Worktrees&lt;/h3&gt; 
&lt;p&gt;You can create worktrees to have multiple branches going at once without the need for stashing or creating WIP commits when switching between them. Press &lt;code&gt;w&lt;/code&gt; in the branches view to create a worktree from the selected branch and switch to it.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/worktree_create_from_branches-compressed.gif" alt="worktree_create_from_branches" /&gt;&lt;/p&gt; 
&lt;h3&gt;Rebase magic (custom patches)&lt;/h3&gt; 
&lt;p&gt;You can build a custom patch from an old commit and then remove the patch from the commit, split out a new commit, apply the patch in reverse to the index, and more.&lt;/p&gt; 
&lt;p&gt;In this example we have a redundant comment that we want to remove from an old commit. We hit &lt;code&gt;&amp;lt;enter&amp;gt;&lt;/code&gt; on the commit to view its files, then &lt;code&gt;&amp;lt;enter&amp;gt;&lt;/code&gt; on a file to focus the patch, then &lt;code&gt;&amp;lt;space&amp;gt;&lt;/code&gt; to add the comment line to our custom patch, and then &lt;code&gt;ctrl+p&lt;/code&gt; to view the custom patch options; selecting to remove the patch from the current commit.&lt;/p&gt; 
&lt;p&gt;Learn more in the &lt;a href="https://youtu.be/4XaToVut_hs"&gt;Rebase magic Youtube tutorial&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/custom_patch-compressed.gif" alt="custom_patch" /&gt;&lt;/p&gt; 
&lt;h3&gt;Rebase from marked base commit&lt;/h3&gt; 
&lt;p&gt;Say you're on a feature branch that was itself branched off of the develop branch, and you've decided you'd rather be branching off the master branch. You need a way to rebase only the commits from your feature branch. In this demo we check to see which was the last commit on the develop branch, then press &lt;code&gt;shift+b&lt;/code&gt; to mark that commit as our base commit, then press &lt;code&gt;r&lt;/code&gt; on the master branch to rebase onto it, only bringing across the commits from our feature branch. Then we push our changes with &lt;code&gt;shift+p&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/rebase_onto-compressed.gif" alt="rebase_onto" /&gt;&lt;/p&gt; 
&lt;h3&gt;Undo&lt;/h3&gt; 
&lt;p&gt;You can undo the last action by pressing &lt;code&gt;z&lt;/code&gt; and redo with &lt;code&gt;ctrl+z&lt;/code&gt;. Here we drop a couple of commits and then undo the actions. Undo uses the reflog which is specific to commits and branches so we can't undo changes to the working tree or stash.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Undoing.md"&gt;More info&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/undo-compressed.gif" alt="undo" /&gt;&lt;/p&gt; 
&lt;h3&gt;Commit graph&lt;/h3&gt; 
&lt;p&gt;When viewing the commit graph in an enlarged window (use &lt;code&gt;+&lt;/code&gt; and &lt;code&gt;_&lt;/code&gt; to cycle screen modes), the commit graph is shown. Colours correspond to the commit authors, and as you navigate down the graph, the parent commits of the selected commit are highlighted.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/commit_graph-compressed.gif" alt="commit_graph" /&gt;&lt;/p&gt; 
&lt;h3&gt;Compare two commits&lt;/h3&gt; 
&lt;p&gt;If you press &lt;code&gt;shift+w&lt;/code&gt; on a commit (or branch/ref) a menu will open that allows you to mark that commit so that any other commit you select will be diffed against it. Once you've selected the second commit, you'll see the diff in the main view and if you press &lt;code&gt;&amp;lt;enter&amp;gt;&lt;/code&gt; you'll see the files of the diff. You can press &lt;code&gt;shift+w&lt;/code&gt; to view the diff menu again to see options like reversing the diff direction or exiting diff mode. You can also exit diff mode by pressing &lt;code&gt;&amp;lt;escape&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/diff_commits-compressed.gif" alt="diff_commits" /&gt;&lt;/p&gt; 
&lt;h2&gt;Tutorials&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/CPLdltN7wgE"&gt;&lt;img src="https://i.imgur.com/sVEktDn.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/CPLdltN7wgE"&gt;15 Lazygit Features in 15 Minutes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/VDXvbHZYeKY"&gt;Basics Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/4XaToVut_hs"&gt;Rebase Magic Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/lazygit/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/lazygit.svg?columns=3" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Most of the above packages are maintained by third parties so be sure to vet them yourself and confirm that the maintainer is a trustworthy looking person who attends local sports games and gives back to their communities with barbeque fundraisers etc&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Binary Releases&lt;/h3&gt; 
&lt;p&gt;For Windows, Mac OS(10.12+) or Linux, you can download a binary release &lt;a href="https://raw.githubusercontent.com/jesseduffield/releases"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Dev container feature&lt;/h3&gt; 
&lt;p&gt;If you want to use lazygit in e.g. one of your GitHub Codespaces, there is a third-party &lt;a href="https://github.com/GeorgOfenbeck/features/tree/main/src/lazygit-linuxbinary"&gt;dev container feature&lt;/a&gt; based on the binary releases mentioned above.&lt;/p&gt; 
&lt;h3&gt;Homebrew&lt;/h3&gt; 
&lt;p&gt;It works with Linux, too.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MacPorts&lt;/h3&gt; 
&lt;p&gt;Latest version built from github releases. Tap:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo port install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Void Linux&lt;/h3&gt; 
&lt;p&gt;Packages for Void Linux are available in the distro repo&lt;/p&gt; 
&lt;p&gt;They follow upstream latest releases&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo xbps-install -S lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scoop (Windows)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;lazygit&lt;/code&gt; using &lt;a href="https://scoop.sh/"&gt;scoop&lt;/a&gt;. It's in the &lt;code&gt;extras&lt;/code&gt; bucket:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Add the extras bucket
scoop bucket add extras

# Install lazygit
scoop install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;gah (Linux and Mac OS)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;lazygit&lt;/code&gt; using &lt;a href="https://github.com/marverix/gah/"&gt;gah&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;gah install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Arch Linux&lt;/h3&gt; 
&lt;p&gt;Packages for Arch Linux are available via pacman and AUR (Arch User Repository).&lt;/p&gt; 
&lt;p&gt;There are two packages. The stable one which is built with the latest release and the git version which builds from the most recent commit.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stable: &lt;code&gt;sudo pacman -S lazygit&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Development: &lt;a href="https://aur.archlinux.org/packages/lazygit-git/"&gt;https://aur.archlinux.org/packages/lazygit-git/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Instruction of how to install AUR content can be found here: &lt;a href="https://wiki.archlinux.org/index.php/Arch_User_Repository"&gt;https://wiki.archlinux.org/index.php/Arch_User_Repository&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Fedora / Amazon Linux 2023 / CentOS Stream&lt;/h3&gt; 
&lt;p&gt;Packages for Fedora, Amazon Linux 2023 and CentOS Stream are available via &lt;a href="https://copr.fedorainfracloud.org/coprs/dejan/lazygit/"&gt;Copr&lt;/a&gt; (Cool Other Package Repo).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo dnf copr enable dejan/lazygit
sudo dnf install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These packages are built using the RPM spec file located here: &lt;a href="https://codeberg.org/dejan/rpm-lazygit"&gt;https://codeberg.org/dejan/rpm-lazygit&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You should be able to build RPMs for Fedora 41 or older, and other Fedora derivatives using the SRPM (Source RPM) file that you can grab from the latest COPR build.&lt;/p&gt; 
&lt;h3&gt;Solus Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo eopkg install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debian and Ubuntu&lt;/h3&gt; 
&lt;p&gt;For &lt;strong&gt;Debian 13 "Trixie", Sid&lt;/strong&gt;, and later, or &lt;strong&gt;Ubuntu 25.10 "Questing Quokka"&lt;/strong&gt; and later:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For &lt;strong&gt;Debian 12 "Bookworm", Ubuntu 25.04 "Plucky Puffin"&lt;/strong&gt; and earlier:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;LAZYGIT_VERSION=$(curl -s "https://api.github.com/repos/jesseduffield/lazygit/releases/latest" | \grep -Po '"tag_name": *"v\K[^"]*')
curl -Lo lazygit.tar.gz "https://github.com/jesseduffield/lazygit/releases/download/v${LAZYGIT_VERSION}/lazygit_${LAZYGIT_VERSION}_Linux_x86_64.tar.gz"
tar xf lazygit.tar.gz lazygit
sudo install lazygit -D -t /usr/local/bin/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Verify the correct installation of lazygit:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;lazygit --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Funtoo Linux&lt;/h3&gt; 
&lt;p&gt;Funtoo Linux has an autogenerated lazygit package in &lt;a href="https://github.com/funtoo/dev-kit/tree/1.4-release/dev-vcs/lazygit"&gt;dev-kit&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo emerge dev-vcs/lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Gentoo Linux&lt;/h3&gt; 
&lt;p&gt;Lazygit is not (yet) in main Gentoo portage, however an ebuild is available in &lt;a href="https://github.com/gentoo-mirror/guru/tree/master/dev-vcs/lazygit"&gt;GURU overlay&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can either add the overlay to your system and install lazygit as usual:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo eselect repository enable guru
sudo emaint sync -r guru
sudo emerge dev-vcs/lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;openSUSE&lt;/h3&gt; 
&lt;p&gt;The lazygit package is currently built in &lt;a href="https://build.opensuse.org/package/show/devel:languages:go/lazygit"&gt;devel:languages:go/lazygit&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To install lazygit on openSUSE Tumbleweed run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo zypper ar https://download.opensuse.org/repositories/devel:/languages:/go/openSUSE_Factory/devel:languages:go.repo
sudo zypper ref &amp;amp;&amp;amp; sudo zypper in lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install lazygit on openSUSE Leap run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;source /etc/os-release
sudo zypper ar https://download.opensuse.org/repositories/devel:/languages:/go/$VERSION_ID/devel:languages:go.repo
sudo zypper ref &amp;amp;&amp;amp; sudo zypper in lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;NixOS&lt;/h3&gt; 
&lt;h4&gt;Using lazygit from nixpkgs&lt;/h4&gt; 
&lt;p&gt;On NixOS, lazygit is packaged with nix and distributed via nixpkgs. You can try lazygit without installing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;nix-shell -p lazygit
# or with flakes enabled
nix run nixpkgs#lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or you can add lazygit to your &lt;code&gt;configuration.nix&lt;/code&gt; using the &lt;code&gt;environment.systemPackages&lt;/code&gt; option. More details can be found via NixOS search &lt;a href="https://search.nixos.org/"&gt;page&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Using the official lazygit flake&lt;/h4&gt; 
&lt;p&gt;This repository includes a nix flake that provides the latest development version and additional development tools:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run lazygit directly from the repository:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;nix run github:jesseduffield/lazygit
# or from a local clone
nix run .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Build lazygit from source:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;nix build github:jesseduffield/lazygit
# or from a local clone
nix build .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development environment:&lt;/strong&gt; For contributors, the flake provides a development shell with Go toolchain, development tools, and dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;nix develop github:jesseduffield/lazygit
# or from a local clone
nix develop
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The development shell includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go toolchain&lt;/li&gt; 
 &lt;li&gt;git and make&lt;/li&gt; 
 &lt;li&gt;Proper environment variables for development&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Using in other flakes:&lt;/strong&gt; The flake also provides an overlay for easy integration into other flake-based projects:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;{
  inputs.lazygit.url = "github:jesseduffield/lazygit";

  outputs = { self, nixpkgs, lazygit }: {
    # Use the overlay
    nixpkgs.overlays = [ lazygit.overlays.default ];
  };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Flox&lt;/h3&gt; 
&lt;p&gt;Lazygit can be installed into a Flox environment as follows.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;flox install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about Flox can be found on &lt;a href="https://flox.dev/"&gt;their website&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;FreeBSD&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pkg install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Termux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;apt install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Conda&lt;/h3&gt; 
&lt;p&gt;Released versions are available for different platforms, see &lt;a href="https://anaconda.org/conda-forge/lazygit"&gt;https://anaconda.org/conda-forge/lazygit&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;conda install -c conda-forge lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Go&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/jesseduffield/lazygit@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please note: If you get an error claiming that lazygit cannot be found or is not defined, you may need to add &lt;code&gt;~/go/bin&lt;/code&gt; to your $PATH (MacOS/Linux), or &lt;code&gt;%HOME%\go\bin&lt;/code&gt; (Windows). Not to be mistaken for &lt;code&gt;C:\Go\bin&lt;/code&gt; (which is for Go's own binaries, not apps like lazygit).&lt;/p&gt; 
&lt;h3&gt;Chocolatey (Windows)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;lazygit&lt;/code&gt; using &lt;a href="https://chocolatey.org/"&gt;Chocolatey&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;choco install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Winget (Windows 10 1709 or later)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;lazygit&lt;/code&gt; using the &lt;code&gt;winget&lt;/code&gt; command in the Windows Terminal with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;winget install -e --id=JesseDuffield.lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual&lt;/h3&gt; 
&lt;p&gt;You'll need to &lt;a href="https://golang.org/doc/install"&gt;install Go&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/jesseduffield/lazygit.git
cd lazygit
go install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use &lt;code&gt;go run main.go&lt;/code&gt; to compile and run in one go (pun definitely intended)&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Call &lt;code&gt;lazygit&lt;/code&gt; in your terminal inside a git repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want, you can also add an alias for this with &lt;code&gt;echo "alias lg='lazygit'" &amp;gt;&amp;gt; ~/.zshrc&lt;/code&gt; (or whichever rc file you're using).&lt;/p&gt; 
&lt;h3&gt;Keybindings&lt;/h3&gt; 
&lt;p&gt;You can check out the list of keybindings &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/keybindings"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Changing Directory On Exit&lt;/h3&gt; 
&lt;p&gt;If you change repos in lazygit and want your shell to change directory into that repo on exiting lazygit, add this to your &lt;code&gt;~/.zshrc&lt;/code&gt; (or other rc file):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;lg()
{
    export LAZYGIT_NEW_DIR_FILE=~/.lazygit/newdir

    lazygit "$@"

    if [ -f $LAZYGIT_NEW_DIR_FILE ]; then
            cd "$(cat $LAZYGIT_NEW_DIR_FILE)"
            rm -f $LAZYGIT_NEW_DIR_FILE &amp;gt; /dev/null
    fi
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then &lt;code&gt;source ~/.zshrc&lt;/code&gt; and from now on when you call &lt;code&gt;lg&lt;/code&gt; and exit you'll switch directories to whatever you were in inside lazygit. To override this behaviour you can exit using &lt;code&gt;shift+Q&lt;/code&gt; rather than just &lt;code&gt;q&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Undo/Redo&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Undoing.md"&gt;docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Config.md"&gt;configuration docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Custom Pagers&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Custom_Pagers.md"&gt;docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Custom Commands&lt;/h3&gt; 
&lt;p&gt;If lazygit is missing a feature, there's a good chance you can implement it yourself with a custom command!&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Custom_Command_Keybindings.md"&gt;docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Git flow support&lt;/h3&gt; 
&lt;p&gt;Lazygit supports &lt;a href="https://github.com/nvie/gitflow"&gt;Gitflow&lt;/a&gt; if you have it installed. To understand how the Gitflow model works check out Vincent Driessen's original &lt;a href="https://nvie.com/posts/a-successful-git-branching-model/"&gt;post&lt;/a&gt; explaining it. To view Gitflow options from within Lazygit, press &lt;code&gt;i&lt;/code&gt; from within the branches view.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We love your input! Please check out the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;. For contributor discussion about things not better discussed here in the repo, join the &lt;a href="https://discord.gg/ehwFt2t4wt"&gt;discord channel&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/ehwFt2t4wt"&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/discord.png" width="75" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out this &lt;a href="https://www.youtube.com/watch?v=kNavnhzZHtk"&gt;video&lt;/a&gt; walking through the creation of a small feature in lazygit if you want an idea of where to get started.&lt;/p&gt; 
&lt;h3&gt;Debugging Locally&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;lazygit --debug&lt;/code&gt; in one terminal tab and &lt;code&gt;lazygit --logs&lt;/code&gt; in another to view the program and its log output side by side&lt;/p&gt; 
&lt;h2&gt;Donate&lt;/h2&gt; 
&lt;p&gt;If you would like to support the development of lazygit, consider &lt;a href="https://github.com/sponsors/jesseduffield"&gt;sponsoring me&lt;/a&gt; (github is matching all donations dollar-for-dollar for 12 months)&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;What do the commit colors represent?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Green: the commit is included in the master branch&lt;/li&gt; 
 &lt;li&gt;Yellow: the commit is not included in the master branch&lt;/li&gt; 
 &lt;li&gt;Red: the commit has not been pushed to the upstream branch&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Shameless Plug&lt;/h2&gt; 
&lt;p&gt;If you want to see what I (Jesse) am up to in terms of development, follow me on &lt;a href="https://twitter.com/DuffieldJesse"&gt;twitter&lt;/a&gt; or check out my &lt;a href="https://jesseduffield.com/"&gt;blog&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Alternatives&lt;/h2&gt; 
&lt;p&gt;If you find that lazygit doesn't quite satisfy your requirements, these may be a better fit:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Extrawurst/gitui"&gt;GitUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonas/tig"&gt;tig&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>